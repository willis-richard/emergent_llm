"""
Generated LLM strategies for social dilemma games.

This file contains strategy classes generated by LLMs for game theory experiments.
Each strategy is a callable class that implements a specific approach to the game.

Generated with:
- Provider: Anthropic
- Model: claude-sonnet-4-0
- Game: CollectiveRiskDescription
"""

from emergent_llm.players import BaseStrategy
from emergent_llm.games import PublicGoodsDescription, CollectiveRiskDescription, CommonPoolDescription, CommonPoolState
from emergent_llm.common import Action, C, D, PlayerHistory, GameState
import numpy as np
from numpy.typing import NDArray
import math
import random



class Strategy_COOPERATIVE_1(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperative Strategy (ATCS)
    
    Maximizes collective welfare while protecting against exploitation through
    adaptive threshold management and graduated responses to defection patterns.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.required_rate = self.m / self.n
        self.safety_margin = 0.1
        self.target_rate = self.required_rate + self.safety_margin
        if self.m >= self.n - 1:
            self.safety_margin = 0.15
            self.forgiveness_period = 3
        elif self.m == 2:
            self.safety_margin = 0.05
            self.forgiveness_period = 2
        else:
            self.forgiveness_period = 2
        if self.n > 10:
            self.use_moving_average = True
            self.forgiveness_period = max(2, min(4, self.n // 5))
        else:
            self.use_moving_average = False
        self.short_game = self.r <= 5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if current_round == self.r - 1:
            return self._final_round_decision(history)
        cooperation_rate = self._get_cooperation_rate(history)
        recent_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            recent_cooperators += 1
        if recent_cooperators == self.m - 1 and (not history.my_actions[-1]):
            return Action.C
        if self._has_positive_momentum(history):
            return Action.C
        if cooperation_rate >= self.target_rate:
            return Action.C
        elif cooperation_rate >= self.required_rate - 0.05:
            return Action.C
        else:
            rounds_since_threshold = self._rounds_since_threshold_met(history)
            if rounds_since_threshold <= self.forgiveness_period:
                return Action.C
            else:
                return Action.D

    def _get_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate using moving average for large groups."""
        if self.use_moving_average and len(history.my_actions) >= 3:
            recent_rounds = min(3, len(history.my_actions))
            total_cooperators = 0
            total_possible = 0
            for i in range(-recent_rounds, 0):
                round_cooperators = sum(history.opponent_actions[i, :])
                if history.my_actions[i]:
                    round_cooperators += 1
                total_cooperators += round_cooperators
                total_possible += self.n
            return total_cooperators / total_possible
        else:
            recent_cooperators = sum(history.opponent_actions[-1, :])
            if history.my_actions[-1]:
                recent_cooperators += 1
            return recent_cooperators / self.n

    def _has_positive_momentum(self, history: PlayerHistory) -> bool:
        """Check if cooperation has been increasing for 2+ consecutive rounds."""
        if len(history.my_actions) < 3:
            return False
        cooperation_counts = []
        for i in range(-3, 0):
            round_cooperators = sum(history.opponent_actions[i, :])
            if history.my_actions[i]:
                round_cooperators += 1
            cooperation_counts.append(round_cooperators)
        return cooperation_counts[1] > cooperation_counts[0] and cooperation_counts[2] > cooperation_counts[1]

    def _rounds_since_threshold_met(self, history: PlayerHistory) -> int:
        """Count rounds since threshold was last met."""
        rounds_since = 0
        for i in range(len(history.my_actions) - 1, -1, -1):
            round_cooperators = sum(history.opponent_actions[i, :])
            if history.my_actions[i]:
                round_cooperators += 1
            if round_cooperators >= self.m:
                break
            rounds_since += 1
        return rounds_since

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """Strategic endgame decision for final round."""
        total_cooperators = 0
        total_possible = 0
        for i in range(len(history.my_actions)):
            round_cooperators = sum(history.opponent_actions[i, :])
            if history.my_actions[i]:
                round_cooperators += 1
            total_cooperators += round_cooperators
            total_possible += self.n
        historical_cooperation_rate = total_cooperators / total_possible
        recent_opponent_cooperators = sum(history.opponent_actions[-1, :])
        if historical_cooperation_rate >= self.target_rate:
            return Action.C
        elif recent_opponent_cooperators == self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_2(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperative Strategy (ATCS)
    
    This strategy operates on cooperative leadership with adaptive trust management.
    It fosters cooperation while protecting against exploitation through dynamic 
    threshold adjustment based on observed behavior patterns.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.base_threshold = self.m + math.ceil((self.n - self.m) / 3)
        self.punishment_phase = False
        self.punishment_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = history.round_number
        if round_num == self.r - 1:
            return self._final_round_decision(history)
        return self._regular_round_decision(history)

    def _final_round_decision(self, history):
        """Handle final round decision making"""
        trust_score = self._calculate_trust_score(history)
        predicted_cooperators = self._estimate_cooperators(history)
        if trust_score > 0.5:
            return Action.C
        if predicted_cooperators >= self.m:
            return Action.C
        return self._make_threshold_decision(history, predicted_cooperators, trust_score)

    def _regular_round_decision(self, history):
        """Handle regular round decision making"""
        trust_score = self._calculate_trust_score(history)
        predicted_cooperators = self._estimate_cooperators(history)
        self._update_punishment_phase(history)
        return self._make_threshold_decision(history, predicted_cooperators, trust_score)

    def _make_threshold_decision(self, history, predicted_cooperators, trust_score):
        """Core decision logic based on threshold and trust"""
        cooperation_threshold = self._calculate_cooperation_threshold(trust_score)
        if predicted_cooperators < self.m - 2:
            return Action.D
        if self.punishment_phase:
            if predicted_cooperators >= cooperation_threshold + 1:
                return Action.C
            else:
                return Action.D
        if predicted_cooperators >= cooperation_threshold:
            return Action.C
        elif predicted_cooperators == cooperation_threshold - 1:
            if trust_score > 0.4 or self._recent_positive_trend(history):
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _calculate_cooperation_threshold(self, trust_score):
        """Calculate adaptive cooperation threshold based on trust"""
        trust_adjustment = self._get_trust_adjustment(trust_score)
        return max(self.m, min(self.n - 1, self.base_threshold + trust_adjustment))

    def _get_trust_adjustment(self, trust_score):
        """Convert trust score to threshold adjustment"""
        if trust_score > 0.7:
            return -2
        elif trust_score > 0.5:
            return -1
        elif trust_score > 0.3:
            return 0
        elif trust_score > 0.15:
            return 1
        else:
            return 2

    def _calculate_trust_score(self, history):
        """Calculate trust score based on cooperation patterns"""
        if history.round_number == 0:
            return 0.5
        rounds = history.round_number
        total_players = self.n
        recent_rounds = min(3, rounds)
        recent_start = max(0, rounds - recent_rounds)
        recent_cooperators = 0
        for r in range(recent_start, rounds):
            if history.my_actions[r]:
                recent_cooperators += 1
            recent_cooperators += sum(history.opponent_actions[r, :])
        recent_cooperation_rate = recent_cooperators / (recent_rounds * total_players)
        total_cooperators = 0
        for r in range(rounds):
            if history.my_actions[r]:
                total_cooperators += 1
            total_cooperators += sum(history.opponent_actions[r, :])
        long_term_cooperation_rate = total_cooperators / (rounds * total_players)
        trust_score = 0.6 * recent_cooperation_rate + 0.4 * long_term_cooperation_rate
        return trust_score

    def _estimate_cooperators(self, history):
        """Estimate number of cooperators for next round"""
        if history.round_number < 3:
            return self._simple_estimate(history)
        recent_cooperators = []
        for r in range(max(0, history.round_number - 3), history.round_number):
            cooperators = sum(history.opponent_actions[r, :])
            if history.my_actions[r]:
                cooperators += 1
            recent_cooperators.append(cooperators)
        base_estimate = sum(recent_cooperators) / len(recent_cooperators)
        if len(recent_cooperators) >= 3:
            trend_adjustment = (recent_cooperators[-1] - recent_cooperators[0]) / 2
        else:
            trend_adjustment = 0
        final_estimate = base_estimate + trend_adjustment
        return max(0, min(self.n, int(round(final_estimate))))

    def _simple_estimate(self, history):
        """Simple estimation for early rounds"""
        if history.round_number == 0:
            return self.m
        last_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_cooperators += 1
        return last_cooperators

    def _recent_positive_trend(self, history):
        """Detect if there's a recent positive trend in cooperation"""
        if history.round_number < 3:
            return False
        recent_rounds = min(3, history.round_number)
        cooperation_changes = 0
        for i in range(1, recent_rounds):
            round_idx = history.round_number - recent_rounds + i
            prev_round_idx = round_idx - 1
            current_coop = sum(history.opponent_actions[round_idx, :])
            prev_coop = sum(history.opponent_actions[prev_round_idx, :])
            if history.my_actions[round_idx]:
                current_coop += 1
            if history.my_actions[prev_round_idx]:
                prev_coop += 1
            if current_coop > prev_coop:
                cooperation_changes += 1
        return cooperation_changes >= 2

    def _update_punishment_phase(self, history):
        """Update punishment phase based on cooperation patterns"""
        if history.round_number < 3:
            return
        recent_cooperators = 0
        total_possible = 0
        for r in range(max(0, history.round_number - 3), history.round_number):
            if history.my_actions[r]:
                recent_cooperators += 1
            recent_cooperators += sum(history.opponent_actions[r, :])
            total_possible += self.n
        cooperation_rate = recent_cooperators / total_possible
        if cooperation_rate < 0.2 and (not self.punishment_phase):
            self.punishment_phase = True
            self.punishment_rounds = 0
        if self.punishment_phase:
            self.punishment_rounds += 1
            if cooperation_rate > 0.4 and self.punishment_rounds >= 2:
                self.punishment_phase = False
                self.punishment_rounds = 0

class Strategy_COOPERATIVE_3(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS)
    
    Balances cooperative intent with adaptive learning, starting cooperatively
    but adjusting based on observed group behavior through multiple conditions
    including threshold achievement, cooperation trends, and momentum building.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        total_cooperators = 0
        total_possible = 0
        for round_idx in range(history.round_number):
            round_cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                round_cooperators += 1
            total_cooperators += round_cooperators
            total_possible += self.n
        cooperation_rate = total_cooperators / total_possible if total_possible > 0 else 0
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        if current_round == self.r - 1:
            threshold = self.m / self.n - 0.05
            return Action.C if cooperation_rate >= threshold else Action.D
        if last_round_cooperators >= self.m:
            return Action.C
        if cooperation_rate >= self.m / self.n + 0.1:
            return Action.C
        if last_round_cooperators == self.m - 1 and cooperation_rate >= self.m / self.n - 0.1:
            return Action.C
        if history.round_number >= 2:
            second_last_cooperators = sum(history.opponent_actions[-2, :])
            if history.my_actions[-2]:
                second_last_cooperators += 1
            if last_round_cooperators > second_last_cooperators and cooperation_rate >= self.m / self.n - 0.2:
                return Action.C
        return Action.D

class Strategy_COOPERATIVE_4(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperation Strategy (ATBC).
    Balances cooperation to achieve collective benefits while protecting against 
    exploitation through adaptive threshold management and forgiveness mechanisms.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        total_cooperations = np.sum(history.my_actions) + np.sum(history.opponent_actions)
        total_possible = self.n * history.round_number
        coop_rate = total_cooperations / total_possible if total_possible > 0 else 0
        recent_rounds = min(3, history.round_number)
        if recent_rounds > 0:
            recent_my_coop = np.sum(history.my_actions[-recent_rounds:])
            recent_opp_coop = np.sum(history.opponent_actions[-recent_rounds:])
            recent_total_coop = recent_my_coop + recent_opp_coop
            recent_total_possible = self.n * recent_rounds
            recent_coop_rate = recent_total_coop / recent_total_possible
        else:
            recent_coop_rate = coop_rate
        if coop_rate >= 0.7:
            base_threshold = 0.6
        elif coop_rate >= 0.5:
            base_threshold = 0.7
        elif coop_rate >= 0.3:
            base_threshold = 0.8
        else:
            base_threshold = 0.9
        trend_adjustment = (recent_coop_rate - coop_rate) * 0.3
        final_threshold = base_threshold + trend_adjustment
        if history.round_number > 0:
            last_round_cooperators = int(history.my_actions[-1]) + np.sum(history.opponent_actions[-1])
            if last_round_cooperators >= self.m:
                final_threshold -= 0.1
        if history.round_number > 0:
            last_round_cooperators = int(history.my_actions[-1]) + np.sum(history.opponent_actions[-1])
            if last_round_cooperators == self.m - 1:
                return Action.C
        if current_round % 4 == 0 and history.round_number >= 4:
            my_recent_defections = np.sum(history.my_actions[-3:] == False)
            if my_recent_defections >= 2:
                return Action.C
        if self.k > 2.5:
            final_threshold -= 0.1
        m_n_ratio = self.m / self.n
        if m_n_ratio > 0.6:
            final_threshold -= 0.1
        if current_round == self.r:
            return Action.C if coop_rate >= 0.4 else Action.D
        return Action.C if coop_rate >= final_threshold else Action.D

class Strategy_COOPERATIVE_5(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperation Strategy (ATCS).
    
    Balances cooperative intent with adaptive responsiveness. Always cooperates
    in round 1, then adjusts cooperation threshold based on group performance.
    Lowers threshold when cooperation succeeds, raises it when it fails.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number + 1
        opponent_cooperators = sum(history.opponent_actions[-1, :])
        my_last_action = history.my_actions[-1]
        total_cooperators = opponent_cooperators + (1 if my_last_action else 0)
        coop_rate = total_cooperators / n
        base_threshold = m / n
        if current_round == r:
            return Action.C if coop_rate >= base_threshold else Action.D
        if total_cooperators >= m:
            adjusted_threshold = max(0.1, base_threshold - 0.15)
        else:
            adjusted_threshold = min(0.9, base_threshold + 0.1)
        return Action.C if coop_rate >= adjusted_threshold else Action.D

class Strategy_COOPERATIVE_6(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperation Strategy (ATCS)
    
    Balances cooperative intent with adaptive protection against exploitation.
    Uses dynamic threshold adjustment and forgiveness mechanisms to foster
    cooperation while being robust to various opponent behaviors.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.base_threshold = self.m / self.n
        if self.r <= 5:
            self.initial_cooperation_rounds = math.ceil(self.r / 2)
        elif self.n <= 4:
            self.initial_cooperation_rounds = min(3, math.ceil(self.r / 3))
        else:
            self.initial_cooperation_rounds = min(5, math.ceil(self.r / 4))
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.consecutive_defections = 0
            return Action.C
        current_round = history.round_number
        if current_round < self.initial_cooperation_rounds:
            self.consecutive_defections = 0
            return Action.C
        recent_coop_rate = self._calculate_recent_cooperation_rate(history)
        if current_round >= self.r - 2:
            threshold = self.base_threshold + 0.1
            if recent_coop_rate >= threshold:
                self.consecutive_defections = 0
                return Action.C
            else:
                self.consecutive_defections += 1
                return Action.D
        adjusted_threshold = self._calculate_adjusted_threshold()
        if self.consecutive_defections >= 2 and recent_coop_rate >= adjusted_threshold - 0.1:
            self.consecutive_defections = 0
            return Action.C
        if recent_coop_rate >= adjusted_threshold:
            self.consecutive_defections = 0
            return Action.C
        else:
            self.consecutive_defections += 1
            return Action.D

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate in recent rounds."""
        if self.r <= 5:
            window_size = history.round_number
        else:
            window_size = min(3, max(1, math.ceil(self.r / 3)))
        start_round = max(0, history.round_number - window_size)
        total_cooperations = 0
        total_possible = 0
        for round_idx in range(start_round, history.round_number):
            if history.my_actions[round_idx]:
                total_cooperations += 1
            total_possible += 1
        for round_idx in range(start_round, history.round_number):
            for player_idx in range(self.n - 1):
                if history.opponent_actions[round_idx, player_idx]:
                    total_cooperations += 1
                total_possible += 1
        if total_possible == 0:
            return self.base_threshold
        return total_cooperations / total_possible

    def _calculate_adjusted_threshold(self) -> float:
        """Calculate the adjusted threshold based on game parameters."""
        adjustment_factor = 0.3
        if self.n <= 4:
            adjustment_factor = 0.2
        if self.base_threshold > 0.7:
            adjustment_factor = 0.1
        return self.base_threshold + (1 - self.base_threshold) * adjustment_factor

class Strategy_COOPERATIVE_7(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) - Balances cooperative intent with adaptive learning,
    aiming to achieve the collective threshold while protecting against exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number + 1
        if current_round == self.r:
            return Action.D
        cooperation_confidence = self._calculate_cooperation_confidence(history)
        if self._is_recovery_mode_needed(history):
            return Action.C
        expected_cooperators = cooperation_confidence * self.n
        return Action.C if expected_cooperators >= self.m - 0.5 else Action.D

    def _calculate_cooperation_confidence(self, history: PlayerHistory) -> float:
        """Calculate the cooperation confidence score."""
        base_cooperation_rate = self._get_base_cooperation_rate(history)
        momentum_adjustment = self._get_momentum_adjustment(history)
        risk_adjustment = self._get_risk_adjustment(history, base_cooperation_rate)
        early_game_bias = 0.2 if history.round_number <= 2 else 0.0
        near_end_adjustment = -0.1 if history.round_number >= self.r - 2 else 0.0
        if self.m == self.n:
            return 1.0
        cooperation_confidence = base_cooperation_rate + momentum_adjustment + risk_adjustment + early_game_bias + near_end_adjustment
        return max(0.0, min(1.0, cooperation_confidence))

    def _get_base_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate historical cooperation rate across all previous rounds."""
        if history.round_number == 0:
            return 0.8
        total_cooperations = 0
        total_decisions = 0
        for round_idx in range(history.round_number):
            if history.my_actions[round_idx]:
                total_cooperations += 1
            total_decisions += 1
            opponent_cooperations = np.sum(history.opponent_actions[round_idx, :])
            total_cooperations += opponent_cooperations
            total_decisions += self.n - 1
        return total_cooperations / total_decisions

    def _get_momentum_adjustment(self, history: PlayerHistory) -> float:
        """Calculate momentum adjustment based on recent trends."""
        if history.round_number < 1:
            return 0.0
        recent_rounds = min(3, history.round_number)
        weights = [0.5, 0.3, 0.2][:recent_rounds]
        recent_cooperation_rates = []
        for i in range(recent_rounds):
            round_idx = history.round_number - 1 - i
            round_cooperations = 0
            round_total = 0
            if history.my_actions[round_idx]:
                round_cooperations += 1
            round_total += 1
            opponent_cooperations = np.sum(history.opponent_actions[round_idx, :])
            round_cooperations += opponent_cooperations
            round_total += self.n - 1
            recent_cooperation_rates.append(round_cooperations / round_total)
        recent_trend = sum((rate * weight for rate, weight in zip(recent_cooperation_rates, weights))) / sum(weights)
        overall_rate = self._get_base_cooperation_rate(history)
        if recent_trend > overall_rate + 0.1:
            return 0.2
        elif recent_trend < overall_rate - 0.1:
            return -0.1
        else:
            return 0.0

    def _get_risk_adjustment(self, history: PlayerHistory, base_rate: float) -> float:
        """Calculate risk adjustment based on proximity to threshold."""
        expected_cooperators = base_rate * self.n
        participation_gap = self.m - expected_cooperators
        if participation_gap <= 1:
            return 0.3
        elif participation_gap >= 3:
            return -0.2
        else:
            return 0.0

    def _is_recovery_mode_needed(self, history: PlayerHistory) -> bool:
        """Check if recovery mode is needed due to consecutive threshold failures."""
        if history.round_number < 2:
            return False
        recent_failures = 0
        for i in range(min(2, history.round_number)):
            round_idx = history.round_number - 1 - i
            cooperators = 0
            if history.my_actions[round_idx]:
                cooperators += 1
            cooperators += np.sum(history.opponent_actions[round_idx, :])
            if cooperators < self.m:
                recent_failures += 1
        return recent_failures >= 2

class Strategy_COOPERATIVE_8(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperation Strategy (ATBC)
    
    Balances cooperative intent with adaptive learning, starting cooperatively
    but adjusting based on observed group behavior patterns across three phases:
    initial cooperation, adaptive learning, and endgame adjustment.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.initial_phase_end = min(3, max(1, self.r // 3))
        self.endgame_phase_start = max(1, int(0.8 * self.r))
        self.my_recent_defections = 0
        self.last_cooperation_test = -10
        self.forgiveness_attempts = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if current_round < self.initial_phase_end:
            return Action.C
        rcr = self._calculate_recent_cooperation_rate(history)
        hsr = self._calculate_historical_success_rate(history)
        trend = self._calculate_trend(history)
        if current_round >= self.endgame_phase_start:
            return self._endgame_decision(rcr, hsr, trend, current_round)
        return self._adaptive_decision(rcr, hsr, trend, history, current_round)

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate over last 2 rounds"""
        rounds_to_check = min(2, len(history.my_actions))
        if rounds_to_check == 0:
            return 0.0
        recent_actions = history.opponent_actions[-rounds_to_check:, :]
        total_decisions = recent_actions.size
        total_cooperations = np.sum(recent_actions)
        return total_cooperations / total_decisions if total_decisions > 0 else 0.0

    def _calculate_historical_success_rate(self, history: PlayerHistory) -> float:
        """Calculate fraction of past rounds where threshold m was met"""
        if len(history.my_actions) == 0:
            return 0.0
        successful_rounds = 0
        total_rounds = len(history.my_actions)
        for round_idx in range(total_rounds):
            cooperators = np.sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators >= self.m:
                successful_rounds += 1
        return successful_rounds / total_rounds

    def _calculate_trend(self, history: PlayerHistory) -> str:
        """Determine if cooperation is increasing, stable, or decreasing"""
        if len(history.my_actions) < 3:
            return 'stable'
        recent_length = min(3, len(history.my_actions))
        if len(history.my_actions) < 6:
            return 'stable'
        recent_coop = np.mean(history.opponent_actions[-recent_length:, :])
        previous_coop = np.mean(history.opponent_actions[-2 * recent_length:-recent_length, :])
        if recent_coop > previous_coop + 0.1:
            return 'increasing'
        elif recent_coop < previous_coop - 0.1:
            return 'decreasing'
        else:
            return 'stable'

    def _update_my_recent_defections(self, history: PlayerHistory):
        """Update count of my recent defections"""
        if len(history.my_actions) == 0:
            self.my_recent_defections = 0
            return
        recent_length = min(3, len(history.my_actions))
        recent_my_actions = history.my_actions[-recent_length:]
        self.my_recent_defections = np.sum(~recent_my_actions)

    def _adaptive_decision(self, rcr: float, hsr: float, trend: str, history: PlayerHistory, current_round: int) -> Action:
        """Main adaptive decision logic for middle phase"""
        self._update_my_recent_defections(history)
        if hsr > 0.8:
            if current_round - self.last_cooperation_test > 4 and random.random() < 0.1:
                self.last_cooperation_test = current_round
                return Action.D
            return Action.C
        if hsr < 0.3:
            if rcr > (self.m + 1) / self.n:
                return Action.C
            if current_round - self.last_cooperation_test > 3 and self.forgiveness_attempts < 2:
                self.forgiveness_attempts += 1
                self.last_cooperation_test = current_round
                return Action.C
            return Action.D
        if self.n <= 4:
            if rcr >= (self.m - 1) / self.n or (hsr >= 0.4 and trend != 'decreasing'):
                return Action.C
        if self.n > 10:
            if rcr >= self.m / self.n and hsr >= 0.5:
                return Action.C
            if trend == 'increasing' and rcr >= (self.m - 1) / self.n:
                return Action.C
            return Action.D
        if rcr >= (self.m - 1) / self.n:
            return Action.C
        elif hsr >= 0.6 and trend != 'decreasing':
            return Action.C
        elif rcr >= self.m / self.n and self.my_recent_defections < 2:
            return Action.C
        else:
            if self.my_recent_defections >= 3 and self.forgiveness_attempts == 0:
                self.forgiveness_attempts = 1
                return Action.C
            return Action.D

    def _endgame_decision(self, rcr: float, hsr: float, trend: str, current_round: int) -> Action:
        """Decision logic for endgame phase"""
        if current_round >= self.r - 1:
            return Action.D
        cooperation_threshold = (self.m + 0.5) / self.n
        if rcr >= cooperation_threshold and trend != 'decreasing':
            return Action.C
        elif hsr > 0.7 and rcr >= self.m / self.n:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_9(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS)
    
    Balances cooperative intent with strategic adaptation, aiming to achieve the 
    collective threshold while protecting against exploitation. Uses optimistic 
    cooperation with defensive learning based on opponent behavior patterns.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.emergency_cooperation_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = state.round_number
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if round_num <= 2:
            return Action.C
        lookback = max(3, r // 4)
        recent_rounds = min(lookback, len(history.my_actions))
        recent_opponent_actions = history.opponent_actions[-recent_rounds:, :]
        recent_cooperation_counts = np.sum(recent_opponent_actions, axis=1)
        recent_my_actions = history.my_actions[-recent_rounds:]
        total_cooperators_per_round = recent_cooperation_counts + recent_my_actions.astype(int)
        cooperation_rate = np.mean(recent_opponent_actions)
        threshold_achievement_rate = np.mean(total_cooperators_per_round >= m)
        base_rate = max(0.3, m / n + 0.1)
        if cooperation_rate > m / n + 0.2:
            adaptation_factor = 1.2
        elif cooperation_rate >= m / n - 0.1:
            adaptation_factor = 1.0
        else:
            adaptation_factor = max(0.4, m / n - 0.2)
        endgame_factor = 1.0
        if round_num == r - 1:
            if threshold_achievement_rate > 0.7:
                return Action.C
            else:
                return Action.D
        elif round_num == r - 2:
            endgame_factor = 1.1
        if recent_rounds >= 3:
            recent_threshold_met = total_cooperators_per_round >= m
            consecutive_failures = 0
            for i in range(len(recent_threshold_met) - 1, -1, -1):
                if not recent_threshold_met[i]:
                    consecutive_failures += 1
                else:
                    break
            if consecutive_failures >= 3 and cooperation_rate < m / n - 0.3:
                self.emergency_cooperation_counter = 2
        if self.emergency_cooperation_counter > 0:
            self.emergency_cooperation_counter -= 1
            return Action.C
        cooperation_probability = base_rate * adaptation_factor * endgame_factor
        if len(history.my_actions) > 0:
            last_round_cooperators = np.sum(history.opponent_actions[-1, :]) + int(history.my_actions[-1])
            if last_round_cooperators == m - 1:
                cooperation_probability += 0.3
        cooperation_probability = min(1.0, max(0.0, cooperation_probability))
        return Action.C if random.random() < cooperation_probability else Action.D

class Strategy_COOPERATIVE_10(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperative Strategy (ATCS)
    
    This strategy maintains cooperation while being resilient to exploitation.
    It uses recent history to estimate player cooperation probabilities and
    adapts its behavior based on whether the cooperation threshold is likely
    to be met. Includes punishment mechanisms for consistent defectors and
    forgiveness for reformed players.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = state.round_number
        recent_window = min(3, history.round_number)
        trust_scores = self._calculate_trust_scores(history, recent_window)
        expected_others_cooperating = sum(trust_scores)
        if round_num >= self.r - 2:
            confidence_needed = 0.8
        else:
            confidence_needed = 0.7
        if expected_others_cooperating >= (self.m - 1) * confidence_needed:
            if self._should_punish_defectors(history, recent_window, round_num):
                return Action.D
            else:
                return Action.C
        if expected_others_cooperating >= (self.m - 1) * 0.5 and round_num < self.r:
            return Action.C
        return Action.D

    def _calculate_trust_scores(self, history: PlayerHistory, window: int):
        """Calculate trust scores for each opponent based on recent behavior."""
        trust_scores = []
        for player_idx in range(self.n - 1):
            if history.round_number == 0:
                trust_scores.append(0.7)
                continue
            start_idx = max(0, history.round_number - window)
            recent_actions = history.opponent_actions[start_idx:, player_idx]
            if len(recent_actions) == 0:
                trust_scores.append(0.7)
                continue
            cooperation_rate = np.mean(recent_actions)
            crucial_cooperation = self._calculate_crucial_cooperation(history, player_idx, window)
            trust_score = 0.6 * cooperation_rate + 0.4 * crucial_cooperation
            trust_scores.append(trust_score)
        return trust_scores

    def _calculate_crucial_cooperation(self, history: PlayerHistory, player_idx: int, window: int):
        """Calculate how often a player cooperated when their cooperation was crucial."""
        if history.round_number < 2:
            return 0.7
        crucial_situations = 0
        crucial_cooperations = 0
        start_idx = max(0, history.round_number - window)
        for round_idx in range(start_idx, history.round_number):
            total_cooperators = int(history.my_actions[round_idx])
            total_cooperators += sum(history.opponent_actions[round_idx, :])
            player_cooperated = history.opponent_actions[round_idx, player_idx]
            if total_cooperators == self.m and player_cooperated:
                crucial_situations += 1
                crucial_cooperations += 1
            elif total_cooperators == self.m - 1 and (not player_cooperated):
                crucial_situations += 1
        if crucial_situations == 0:
            return 0.7
        return crucial_cooperations / crucial_situations

    def _should_punish_defectors(self, history: PlayerHistory, window: int, round_num: int):
        """Determine if punishment is warranted for consistent defectors."""
        if round_num >= self.r - 2:
            return False
        for player_idx in range(self.n - 1):
            if self._is_punishment_worthy(history, player_idx, window):
                if random.random() < 0.3:
                    return True
        return False

    def _is_punishment_worthy(self, history: PlayerHistory, player_idx: int, window: int):
        """Check if a specific player deserves punishment."""
        if history.round_number < 3:
            return False
        start_idx = max(0, history.round_number - window)
        recent_actions = history.opponent_actions[start_idx:, player_idx]
        defection_rate = 1.0 - np.mean(recent_actions)
        if defection_rate <= 0.6:
            return False
        threshold_failures_caused = self._count_threshold_failures_caused(history, player_idx, window)
        return threshold_failures_caused > 0

    def _count_threshold_failures_caused(self, history: PlayerHistory, player_idx: int, window: int):
        """Count how many threshold failures this player caused."""
        failures_caused = 0
        start_idx = max(0, history.round_number - window)
        for round_idx in range(start_idx, history.round_number):
            cooperators = int(history.my_actions[round_idx])
            cooperators += sum(history.opponent_actions[round_idx, :])
            if cooperators < self.m:
                if not history.opponent_actions[round_idx, player_idx]:
                    if cooperators + 1 >= self.m:
                        failures_caused += 1
        return failures_caused

class Strategy_COOPERATIVE_11(BaseStrategy):
    """
    Threshold Guardian: Adaptive cooperative strategy that maintains cooperation 
    while being robust against exploitation. Acts as a threshold guardian by 
    ensuring the cooperation threshold is met while adapting to opponent behavior.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.exploitation_adjustment = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = history.round_number + 1
        recent_rounds = min(3, history.round_number)
        expected_cooperators = 1
        for player_idx in range(self.n - 1):
            start_idx = max(0, history.round_number - recent_rounds)
            recent_actions = history.opponent_actions[start_idx:, player_idx]
            recent_coop_rate = np.mean(recent_actions) if len(recent_actions) > 0 else 0.5
            if recent_coop_rate >= 0.5:
                expected_cooperators += 1
        reliable_cooperators = 0
        for player_idx in range(self.n - 1):
            start_idx = max(0, history.round_number - recent_rounds)
            recent_actions = history.opponent_actions[start_idx:, player_idx]
            if len(recent_actions) > 0:
                recent_coop_rate = np.mean(recent_actions)
                if recent_coop_rate >= 0.67:
                    reliable_cooperators += 1
        if expected_cooperators >= self.m + 1:
            if reliable_cooperators >= self.m:
                base_prob = 0.7
            else:
                base_prob = 0.9
        elif expected_cooperators == self.m:
            base_prob = 0.95
        else:
            base_prob = 1.0
        if round_num == self.r:
            base_prob = min(1.0, base_prob + 0.2)
        if history.round_number >= 3:
            my_recent_actions = history.my_actions[-3:]
            if np.all(my_recent_actions):
                for i in range(-3, 0):
                    round_cooperators = 1 + np.sum(history.opponent_actions[i, :])
                    if round_cooperators == self.m:
                        self.exploitation_adjustment = min(0.4, self.exploitation_adjustment + 0.05)
                        break
            else:
                self.exploitation_adjustment = max(0.0, self.exploitation_adjustment - 0.02)
        base_prob = max(0.5, base_prob - self.exploitation_adjustment)
        return Action.C if random.random() < base_prob else Action.D

class Strategy_COOPERATIVE_12(BaseStrategy):
    """
    Adaptive Threshold Cooperative Strategy (ATCS): Balances cooperative intent 
    with adaptive risk management, starting cooperatively but adjusting based on 
    observed player behavior to maintain collective success while protecting against exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = history.round_number + 1
        if round_num <= 3:
            return self._early_round_decision(history)
        expected_cooperators = self._calculate_expected_cooperators(history)
        expected_rate = expected_cooperators / self.n
        dynamic_threshold = self._calculate_dynamic_threshold(history)
        if round_num == self.r:
            dynamic_threshold = self._apply_last_round_adjustment(dynamic_threshold, history)
        if expected_rate >= dynamic_threshold:
            return Action.C
        else:
            return Action.D

    def _early_round_decision(self, history):
        """Simplified decision for rounds 2-3"""
        if history.round_number < 4:
            last_round_cooperators = sum(history.opponent_actions[-1, :])
            if last_round_cooperators >= 1:
                return Action.C
            else:
                observed_rate = last_round_cooperators / self.n
                threshold = (self.m - 1) / self.n
                return Action.C if observed_rate >= threshold else Action.D
        return Action.C

    def _calculate_expected_cooperators(self, history):
        """Calculate expected number of cooperators this round"""
        n_opponents = self.n - 1
        expected_cooperators = 0
        for opponent_idx in range(n_opponents):
            coop_prob = self._get_cooperation_probability(history, opponent_idx)
            expected_cooperators += coop_prob
        return expected_cooperators

    def _get_cooperation_probability(self, history, opponent_idx):
        """Calculate cooperation probability for a specific opponent"""
        rounds_played = history.round_number
        opponent_actions = history.opponent_actions[:, opponent_idx]
        recent_rounds = min(3, rounds_played)
        recent_actions = opponent_actions[-recent_rounds:]
        recent_rate = sum(recent_actions) / len(recent_actions)
        overall_rate = sum(opponent_actions) / len(opponent_actions)
        reciprocity = self._calculate_reciprocity(history, opponent_idx)
        base_prob = 0.5 * recent_rate + 0.3 * overall_rate + 0.2 * reciprocity
        base_prob = self._apply_forgiveness(history, opponent_idx, base_prob)
        base_prob = self._apply_crisis_response(history, base_prob)
        return max(0.0, min(1.0, base_prob))

    def _calculate_reciprocity(self, history, opponent_idx):
        """Calculate reciprocity factor for an opponent"""
        if history.round_number < 2:
            return 0.5
        my_actions = history.my_actions
        opponent_actions = history.opponent_actions[:, opponent_idx]
        reciprocity_score = 0.5
        interactions = 0
        for round_idx in range(len(my_actions) - 1):
            if my_actions[round_idx]:
                interactions += 1
                if opponent_actions[round_idx + 1] if round_idx + 1 < len(opponent_actions) else opponent_actions[round_idx]:
                    reciprocity_score += 0.1
                else:
                    reciprocity_score -= 0.1
        return max(0.0, min(1.0, reciprocity_score))

    def _apply_forgiveness(self, history, opponent_idx, base_prob):
        """Apply forgiveness mechanism"""
        if history.round_number < 3:
            return base_prob
        opponent_actions = history.opponent_actions[:, opponent_idx]
        recent_actions = opponent_actions[-2:]
        if len(recent_actions) >= 2 and all(recent_actions):
            overall_rate = sum(opponent_actions[:-2]) / max(1, len(opponent_actions) - 2)
            if overall_rate < 0.5:
                return min(1.0, base_prob + 0.15)
        return base_prob

    def _apply_crisis_response(self, history, base_prob):
        """Apply crisis response mechanism"""
        if history.round_number < 5:
            return base_prob
        recent_rounds = min(5, history.round_number)
        failures = 0
        for i in range(recent_rounds):
            round_idx = history.round_number - 1 - i
            cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators < self.m:
                failures += 1
        failure_rate = failures / recent_rounds
        if failure_rate >= 0.6:
            return min(1.0, base_prob + 0.1)
        return base_prob

    def _calculate_dynamic_threshold(self, history):
        """Calculate dynamic threshold with risk adjustment"""
        base_threshold = self.m / self.n
        if history.round_number < 5:
            return base_threshold
        recent_rounds = min(5, history.round_number)
        successes = 0
        failures = 0
        for i in range(recent_rounds):
            round_idx = history.round_number - 1 - i
            cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators >= self.m:
                successes += 1
            else:
                failures += 1
        success_rate = successes / recent_rounds
        failure_rate = failures / recent_rounds
        risk_adjustment = 0.1 * (failure_rate - success_rate)
        dynamic_threshold = base_threshold + risk_adjustment
        return max(0.3, min(0.8, dynamic_threshold))

    def _apply_last_round_adjustment(self, threshold, history):
        """Apply last round special rules"""
        total_rounds = history.round_number
        successes = 0
        for round_idx in range(total_rounds):
            cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators >= self.m:
                successes += 1
        success_rate = successes / total_rounds
        if success_rate >= 0.8:
            return threshold
        elif success_rate < 0.5:
            return 1.0
        else:
            return max(0.25, threshold - 0.05)

class Strategy_COOPERATIVE_13(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperative Strategy (ATCS)
    
    Balances cooperative intent with adaptive realism, using the game's threshold 
    structure to establish and maintain cooperation while protecting against exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.early_phase_rounds = min(5, max(1, self.r // 3))
        self.base_threshold = 0.4
        self.max_threshold = 0.8

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number + 1
        if current_round <= self.early_phase_rounds:
            return Action.C
        adaptive_threshold = self._calculate_adaptive_threshold(history)
        if current_round == self.r:
            return self._endgame_logic(history, adaptive_threshold)
        expected_cooperators = self._predict_cooperators(history)
        my_recent_coop_rate = self._get_my_recent_cooperation_rate(history)
        cooperation_momentum = self._calculate_cooperation_momentum(history)
        if expected_cooperators >= self.m - 1:
            if my_recent_coop_rate > adaptive_threshold:
                return Action.C
            else:
                return Action.D
        elif expected_cooperators == self.m - 2:
            return Action.C
        elif cooperation_momentum > 0.6 and expected_cooperators > self.m * 0.5:
            return Action.C
        else:
            return Action.D

    def _calculate_adaptive_threshold(self, history: PlayerHistory) -> float:
        """Calculate dynamic cooperation threshold based on observed behavior"""
        total_rounds = history.round_number
        total_possible_cooperations = total_rounds * self.n
        my_cooperations = sum(history.my_actions)
        opponent_cooperations = np.sum(history.opponent_actions)
        total_cooperations = my_cooperations + opponent_cooperations
        cooperation_rate = total_cooperations / total_possible_cooperations if total_possible_cooperations > 0 else 0.5
        adaptive_threshold = max(self.base_threshold, min(self.max_threshold, cooperation_rate * 1.2))
        return adaptive_threshold

    def _predict_cooperators(self, history: PlayerHistory) -> int:
        """Predict number of cooperators in next round using weighted history"""
        if history.round_number == 0:
            return self.n // 2
        expected_cooperators = 0
        recent_weight = 0.7
        older_weight = 0.3
        for player_idx in range(self.n - 1):
            player_history = history.opponent_actions[:, player_idx]
            if history.round_number >= 3:
                recent_rounds = min(3, history.round_number)
                recent_coop_rate = np.mean(player_history[-recent_rounds:])
                overall_coop_rate = np.mean(player_history)
                predicted_prob = recent_weight * recent_coop_rate + older_weight * overall_coop_rate
            else:
                predicted_prob = np.mean(player_history)
            if predicted_prob > 0.5:
                expected_cooperators += 1
        return expected_cooperators

    def _get_my_recent_cooperation_rate(self, history: PlayerHistory) -> float:
        """Get my cooperation rate in recent rounds"""
        if history.round_number == 0:
            return 1.0
        recent_rounds = min(3, history.round_number)
        return np.mean(history.my_actions[-recent_rounds:])

    def _calculate_cooperation_momentum(self, history: PlayerHistory) -> float:
        """Calculate momentum in collective cooperation"""
        if history.round_number < 4:
            return 0.5
        last_2_rounds = history.opponent_actions[-2:, :]
        previous_2_rounds = history.opponent_actions[-4:-2, :]
        cooperations_last_2 = np.sum(last_2_rounds)
        cooperations_previous_2 = np.sum(previous_2_rounds)
        momentum = (cooperations_last_2 - cooperations_previous_2) / (2 * self.n)
        return max(-1.0, min(1.0, momentum))

    def _endgame_logic(self, history: PlayerHistory, adaptive_threshold: float) -> Action:
        """Special logic for the final round"""
        expected_cooperators = self._predict_cooperators(history)
        my_overall_coop_rate = np.mean(history.my_actions) if history.round_number > 0 else 1.0
        if expected_cooperators >= self.m - 1:
            return Action.C
        elif expected_cooperators == self.m - 2 and my_overall_coop_rate > 0.6:
            return Action.C
        else:
            return Action.D

    def _get_group_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate overall group cooperation rate"""
        if history.round_number == 0:
            return 0.5
        total_cooperations = np.sum(history.opponent_actions)
        total_possible = history.round_number * self.n
        return total_cooperations / total_possible if total_possible > 0 else 0.5

class Strategy_COOPERATIVE_14(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperation Strategy (ATCS)
    
    This strategy balances collective welfare with individual rationality using
    dynamic thresholds based on observed cooperation patterns. It cooperates in
    round 1, then adapts based on recent and historical cooperation rates.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = history.round_number
        if round_num == self.r - 1:
            total_cooperators = 0
            total_opportunities = 0
            for r in range(round_num):
                total_cooperators += sum(history.opponent_actions[r, :])
                if history.my_actions[r]:
                    total_cooperators += 1
                total_opportunities += self.n
            historical_cooperation_rate = total_cooperators / total_opportunities if total_opportunities > 0 else 0
            if historical_cooperation_rate >= self.m / self.n:
                return Action.C
            else:
                return Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        observed_cooperation_rate = last_round_cooperators / self.n
        total_cooperators = 0
        total_opportunities = 0
        for r in range(round_num):
            total_cooperators += sum(history.opponent_actions[r, :])
            if history.my_actions[r]:
                total_cooperators += 1
            total_opportunities += self.n
        historical_cooperation_rate = total_cooperators / total_opportunities if total_opportunities > 0 else 0
        base_threshold = self.m / self.n
        cooperation_bonus = max(0, historical_cooperation_rate - base_threshold)
        dynamic_threshold = base_threshold - cooperation_bonus * 0.3
        if self.n <= 4:
            dynamic_threshold -= 0.1
        if self.m > 0.7 * self.n:
            if round_num < self.r / 2:
                dynamic_threshold -= 0.1
        if self.k <= 1.5:
            dynamic_threshold += 0.05
        min_last_round_threshold = max(1, self.m - 2) / self.n
        if self.n > 4 and observed_cooperation_rate < min_last_round_threshold:
            return Action.D
        if observed_cooperation_rate >= dynamic_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_15(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) that balances cooperation with strategic adaptation.
    Always cooperates in round 1, then adapts based on group cooperation patterns and threshold proximity.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defensive_mode = False
        self.defensive_rounds = 0
        self.low_coop_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        total_cooperations = 0
        previous_rounds = history.round_number
        my_cooperations = sum(history.my_actions)
        opponent_cooperations = sum((sum(history.opponent_actions[round_idx, :]) for round_idx in range(previous_rounds)))
        total_cooperations = my_cooperations + opponent_cooperations
        avg_coop_rate = total_cooperations / (previous_rounds * n)
        avg_cooperators = avg_coop_rate * n
        recent_cooperators = sum(history.opponent_actions[-1, :]) + (1 if history.my_actions[-1] else 0)
        previous_round_met_threshold = recent_cooperators >= m
        if previous_rounds >= 3:
            recent_rounds = min(3, previous_rounds)
            recent_cooperations = my_cooperations - sum(history.my_actions[:-recent_rounds]) if recent_rounds < previous_rounds else my_cooperations
            recent_opponent_cooperations = sum((sum(history.opponent_actions[round_idx, :]) for round_idx in range(max(0, previous_rounds - recent_rounds), previous_rounds)))
            recent_total = recent_cooperations + recent_opponent_cooperations
            recent_avg = recent_total / (recent_rounds * n)
            historical_cooperations = total_cooperations - (recent_cooperations + recent_opponent_cooperations)
            historical_rounds = previous_rounds - recent_rounds
            historical_avg = historical_cooperations / (historical_rounds * n) if historical_rounds > 0 else 0
            weighted_coop_rate = 0.6 * recent_avg + 0.4 * historical_avg
        else:
            weighted_coop_rate = avg_coop_rate
        if previous_rounds >= 3:
            last_3_rounds_coop = []
            for i in range(max(0, previous_rounds - 3), previous_rounds):
                round_cooperations = sum(history.opponent_actions[i, :]) + (1 if history.my_actions[i] else 0)
                last_3_rounds_coop.append(round_cooperations / n)
            if all((rate < 0.25 for rate in last_3_rounds_coop)):
                self.low_coop_streak += 1
                if self.low_coop_streak >= 3:
                    self.defensive_mode = True
                    self.defensive_rounds = 0
            else:
                self.low_coop_streak = 0
        if self.defensive_mode:
            self.defensive_rounds += 1
            if previous_rounds >= 2:
                last_2_rounds_coop = []
                for i in range(max(0, previous_rounds - 2), previous_rounds):
                    round_cooperations = sum(history.opponent_actions[i, :]) + (1 if history.my_actions[i] else 0)
                    last_2_rounds_coop.append(round_cooperations / n)
                if all((rate > m / n for rate in last_2_rounds_coop)):
                    self.defensive_mode = False
                    self.defensive_rounds = 0
        if current_round == r:
            return Action.C if avg_coop_rate >= m / n else Action.D
        if self.defensive_mode:
            return Action.C if previous_round_met_threshold else Action.D
        if n <= 4:
            if previous_rounds > 0:
                last_round_coop_rate = (sum(history.opponent_actions[-1, :]) + (1 if history.my_actions[-1] else 0)) / n
                return Action.D if last_round_coop_rate < 0.5 else Action.C
        threshold_adjustment = 0.2 if m > n / 2 else 0
        reward_adjustment = -0.15 if k < 1.5 else 0
        if avg_cooperators >= m:
            return Action.C
        elif avg_cooperators >= m - 1:
            prob = min(0.8 + threshold_adjustment + reward_adjustment, 1.0)
            return Action.C if random.random() < prob else Action.D
        elif avg_cooperators >= m - 2 and previous_round_met_threshold:
            return Action.C
        elif current_round <= r / 3:
            prob = 1.0 if weighted_coop_rate > 0.3 else 0.0
            prob = min(prob + threshold_adjustment + reward_adjustment, 1.0)
            return Action.C if prob > 0.5 else Action.D
        else:
            return Action.D

class Strategy_COOPERATIVE_16(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperation Strategy (ATBC)
    
    Balances cooperative intent with adaptive learning, aiming to achieve the collective 
    threshold while protecting against exploitation. Operates on conditional cooperation 
    based on evidence that others are willing to contribute toward the collective goal.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_number = history.round_number + 1
        initial_phase_length = min(3, math.ceil(self.r * 0.25))
        if round_number <= initial_phase_length:
            return Action.C
        recent_threshold_rate = self._calculate_threshold_achievement_rate(history, 5)
        recent_avg_cooperators = self._calculate_average_cooperators(history, 3)
        last_round_cooperators = self._count_cooperators_in_round(history, -1)
        last_round_threshold_met = last_round_cooperators >= self.m
        my_cooperation_needed = last_round_cooperators == self.m and history.my_actions[-1]
        if last_round_threshold_met and my_cooperation_needed:
            return Action.C
        elif recent_threshold_rate >= 0.7:
            return Action.C
        elif recent_avg_cooperators >= self.m:
            return Action.C
        elif round_number <= 0.8 * self.r and recent_threshold_rate >= 0.5:
            return Action.C
        elif last_round_cooperators == self.m - 1:
            return Action.C
        elif round_number > 0.8 * self.r:
            if recent_threshold_rate >= 0.5 or recent_avg_cooperators >= self.m - 1:
                return Action.C
        if self._has_positive_cooperation_trend(history):
            return Action.C
        if self._should_attempt_recovery(history):
            return Action.C
        return Action.D

    def _calculate_threshold_achievement_rate(self, history: PlayerHistory, lookback: int) -> float:
        """Calculate the rate at which threshold was achieved in recent rounds."""
        if history.round_number == 0:
            return 0.0
        start_round = max(0, history.round_number - lookback)
        threshold_met_count = 0
        rounds_examined = 0
        for round_idx in range(start_round, history.round_number):
            cooperators = self._count_cooperators_in_round(history, round_idx)
            if cooperators >= self.m:
                threshold_met_count += 1
            rounds_examined += 1
        return threshold_met_count / rounds_examined if rounds_examined > 0 else 0.0

    def _calculate_average_cooperators(self, history: PlayerHistory, lookback: int) -> float:
        """Calculate average number of cooperators in recent rounds."""
        if history.round_number == 0:
            return 0.0
        start_round = max(0, history.round_number - lookback)
        total_cooperators = 0
        rounds_examined = 0
        for round_idx in range(start_round, history.round_number):
            cooperators = self._count_cooperators_in_round(history, round_idx)
            total_cooperators += cooperators
            rounds_examined += 1
        return total_cooperators / rounds_examined if rounds_examined > 0 else 0.0

    def _count_cooperators_in_round(self, history: PlayerHistory, round_idx: int) -> int:
        """Count total cooperators (including myself) in a specific round."""
        if round_idx < 0:
            round_idx = history.round_number + round_idx
        if round_idx < 0 or round_idx >= history.round_number:
            return 0
        opponent_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
        my_cooperation = 1 if history.my_actions[round_idx] else 0
        return opponent_cooperators + my_cooperation

    def _has_positive_cooperation_trend(self, history: PlayerHistory) -> bool:
        """Check if there's a positive trend in cooperation from last two rounds."""
        if history.round_number < 2:
            return False
        last_round_cooperators = self._count_cooperators_in_round(history, -1)
        second_last_cooperators = self._count_cooperators_in_round(history, -2)
        return last_round_cooperators > second_last_cooperators

    def _should_attempt_recovery(self, history: PlayerHistory) -> bool:
        """Determine if we should attempt to restart cooperation after failures."""
        if history.round_number < 4:
            return False
        consecutive_failures = 0
        for round_idx in range(history.round_number - 1, -1, -1):
            cooperators = self._count_cooperators_in_round(history, round_idx)
            if cooperators < self.m:
                consecutive_failures += 1
            else:
                break
        if consecutive_failures >= 4:
            recent_my_defections = sum((1 for i in range(max(0, history.round_number - 2), history.round_number) if not history.my_actions[i]))
            return recent_my_defections >= 2
        return False

class Strategy_COOPERATIVE_17(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperation Strategy (ATCS)
    
    Balances cooperation with strategic protection by estimating whether the cooperation
    threshold will be met and adapting to group behavior patterns. Cooperates when
    threshold achievement seems likely while protecting against exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.recovery_penalty = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = history.round_number
        if round_num == self.r - 1:
            return self._final_round_decision(history)
        return self._adaptive_decision(history)

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """Final round uses stricter threshold to avoid exploitation."""
        cooperators_last_round = self._count_cooperators_last_round(history)
        if cooperators_last_round >= self.m + 1:
            return Action.C
        else:
            return Action.D

    def _adaptive_decision(self, history: PlayerHistory) -> Action:
        """Main adaptive decision logic for middle rounds."""
        estimated_cooperators = self._estimate_cooperators_this_round(history)
        cooperation_threshold = self.m - 1
        if self._should_apply_recovery_penalty(history):
            cooperation_threshold += 1
        if estimated_cooperators >= cooperation_threshold:
            return Action.C
        else:
            return Action.D

    def _estimate_cooperators_this_round(self, history: PlayerHistory) -> int:
        """Estimate how many players will cooperate this round."""
        cooperated_last_round = self._count_cooperators_last_round(history)
        trend_factor = 0
        if history.round_number >= 2:
            cooperators_prev = np.sum(history.opponent_actions[-2, :]) + (1 if history.my_actions[-2] else 0)
            recent_trend = cooperated_last_round - cooperators_prev
            trend_factor = max(-1, min(1, recent_trend * 0.5))
        base_estimate = cooperated_last_round + trend_factor
        estimated_cooperators = max(0, base_estimate - 1)
        if self.m > 0.8 * self.n:
            estimated_cooperators = max(0, base_estimate - 2)
        if self._is_group_volatile(history):
            estimated_cooperators = max(0, estimated_cooperators - 1)
        return int(estimated_cooperators)

    def _count_cooperators_last_round(self, history: PlayerHistory) -> int:
        """Count total cooperators (including self) in the last round."""
        opponent_cooperators = np.sum(history.opponent_actions[-1, :])
        my_cooperation = 1 if history.my_actions[-1] else 0
        return int(opponent_cooperators + my_cooperation)

    def _should_apply_recovery_penalty(self, history: PlayerHistory) -> bool:
        """Check if we should apply recovery penalty due to missed threshold."""
        if history.round_number == 0:
            return False
        cooperators_last_round = self._count_cooperators_last_round(history)
        we_cooperated_last_round = history.my_actions[-1]
        threshold_missed = cooperators_last_round < self.m
        return threshold_missed and we_cooperated_last_round

    def _is_group_volatile(self, history: PlayerHistory) -> bool:
        """Detect if group cooperation is highly volatile."""
        if history.round_number < 3:
            return False
        recent_rounds = min(3, history.round_number)
        cooperation_rates = []
        for i in range(recent_rounds):
            round_idx = -(i + 1)
            cooperators = np.sum(history.opponent_actions[round_idx, :]) + (1 if history.my_actions[round_idx] else 0)
            rate = cooperators / self.n
            cooperation_rates.append(rate)
        max_rate = max(cooperation_rates)
        min_rate = min(cooperation_rates)
        return max_rate - min_rate > 0.5

class Strategy_COOPERATIVE_18(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperation Strategy (ATCS)
    
    Balances cooperative intent with adaptive learning, aiming to achieve collective 
    success while protecting against systematic exploitation. Uses a three-factor 
    decision system based on cooperation rates, recent trends, and threshold achievement probability.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        avg_coop_rate = self._calculate_average_cooperation_rate(history)
        recent_trend = self._calculate_recent_trend(history)
        if current_round == self.r - 1:
            threshold = (self.m - 0.5) / self.n
            return Action.C if avg_coop_rate >= threshold else Action.D
        threshold_ratio = self.m / self.n
        if recent_trend >= (self.m - 1) / self.n:
            return Action.C
        if avg_coop_rate >= threshold_ratio and recent_trend >= 0.3:
            return Action.C
        if self._last_round_met_threshold(history) and self._last_round_coop_rate(history) >= 0.5:
            return Action.C
        if current_round <= self.r / 3 and avg_coop_rate >= 0.4:
            return Action.C
        if self.m == self.n - 1:
            base_prob = 0.2 if avg_coop_rate < 0.5 else 0.4
            return Action.C if random.random() < base_prob else Action.D
        if self._is_low_cooperation_environment(history):
            return Action.C if self._last_round_met_threshold(history) else Action.D
        return Action.D

    def _calculate_average_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate the average cooperation rate across all players in previous rounds."""
        total_rounds = history.round_number
        if total_rounds == 0:
            return 0.0
        my_cooperations = np.sum(history.my_actions)
        opponent_cooperations = np.sum(history.opponent_actions)
        total_cooperations = my_cooperations + opponent_cooperations
        total_decisions = self.n * total_rounds
        return total_cooperations / total_decisions

    def _calculate_recent_trend(self, history: PlayerHistory) -> float:
        """Calculate recent cooperation trend, weighting recent rounds more heavily."""
        total_rounds = history.round_number
        if total_rounds == 0:
            return 0.0
        last_round_coop = 0.0
        if total_rounds >= 1:
            my_last = 1 if history.my_actions[-1] else 0
            opponent_last = np.sum(history.opponent_actions[-1, :])
            last_round_coop = (my_last + opponent_last) / self.n
        two_rounds_ago_coop = 0.0
        if total_rounds >= 2:
            my_two_ago = 1 if history.my_actions[-2] else 0
            opponent_two_ago = np.sum(history.opponent_actions[-2, :])
            two_rounds_ago_coop = (my_two_ago + opponent_two_ago) / self.n
        if total_rounds == 1:
            return last_round_coop
        else:
            return 0.7 * last_round_coop + 0.3 * two_rounds_ago_coop

    def _last_round_met_threshold(self, history: PlayerHistory) -> bool:
        """Check if the last round met the cooperation threshold m."""
        if history.round_number == 0:
            return False
        my_last = 1 if history.my_actions[-1] else 0
        opponent_last = np.sum(history.opponent_actions[-1, :])
        total_cooperators = my_last + opponent_last
        return total_cooperators >= self.m

    def _last_round_coop_rate(self, history: PlayerHistory) -> float:
        """Get cooperation rate for the last round."""
        if history.round_number == 0:
            return 0.0
        my_last = 1 if history.my_actions[-1] else 0
        opponent_last = np.sum(history.opponent_actions[-1, :])
        return (my_last + opponent_last) / self.n

    def _is_low_cooperation_environment(self, history: PlayerHistory) -> bool:
        """Check if we're in a low cooperation environment for 3+ consecutive rounds."""
        total_rounds = history.round_number
        if total_rounds < 3:
            return False
        consecutive_low = 0
        for i in range(min(3, total_rounds)):
            round_idx = total_rounds - 1 - i
            my_coop = 1 if history.my_actions[round_idx] else 0
            opponent_coop = np.sum(history.opponent_actions[round_idx, :])
            round_coop_rate = (my_coop + opponent_coop) / self.n
            if round_coop_rate < 0.2:
                consecutive_low += 1
            else:
                break
        return consecutive_low >= 3

class Strategy_COOPERATIVE_19(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS)
    
    A three-phase strategy that balances cooperative behavior with adaptive responses:
    1. Cooperative Initialization (rounds 1-3): Always cooperate
    2. Adaptive Cooperation (rounds 4 to r-2): Use threshold buffer and individual tracking
    3. Endgame Strategy (last 2 rounds): Based on historical success rates
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number + 1
        if current_round <= 3:
            return Action.C
        elif current_round <= self.r - 2:
            return self._adaptive_cooperation_decision(history)
        elif current_round == self.r - 1:
            return self._second_to_last_round_decision(history)
        else:
            return self._final_round_decision(history)

    def _adaptive_cooperation_decision(self, history: PlayerHistory) -> Action:
        last_3_rounds = min(3, history.round_number)
        recent_actions = history.opponent_actions[-last_3_rounds:, :]
        my_recent_actions = history.my_actions[-last_3_rounds:]
        total_recent_cooperations = 0
        total_recent_decisions = 0
        for round_idx in range(last_3_rounds):
            round_cooperations = sum(recent_actions[round_idx, :]) + int(my_recent_actions[round_idx])
            total_recent_cooperations += round_cooperations
            total_recent_decisions += self.n
        recent_coop_rate = total_recent_cooperations / total_recent_decisions if total_recent_decisions > 0 else 0
        threshold_buffer = max(0.6, self.m / self.n - 0.1)
        projected_cooperators = math.floor(recent_coop_rate * self.n)
        reliable_cooperators = self._count_reliable_cooperators(history)
        if recent_coop_rate >= threshold_buffer and projected_cooperators >= self.m or reliable_cooperators >= self.m:
            return Action.C
        else:
            return Action.D

    def _count_reliable_cooperators(self, history: PlayerHistory) -> int:
        last_5_rounds = min(5, history.round_number)
        if last_5_rounds == 0:
            return 0
        reliable_count = 0
        recent_actions = history.opponent_actions[-last_5_rounds:, :]
        for player_idx in range(recent_actions.shape[1]):
            player_cooperations = sum(recent_actions[:, player_idx])
            cooperation_rate = player_cooperations / last_5_rounds
            if cooperation_rate >= 0.8:
                reliable_count += 1
        my_recent_actions = history.my_actions[-last_5_rounds:]
        my_cooperation_rate = sum(my_recent_actions) / last_5_rounds
        if my_cooperation_rate >= 0.8:
            reliable_count += 1
        return reliable_count

    def _second_to_last_round_decision(self, history: PlayerHistory) -> Action:
        all_opponent_actions = history.opponent_actions
        total_cooperations = np.sum(all_opponent_actions) + sum(history.my_actions)
        total_decisions = all_opponent_actions.size + len(history.my_actions)
        overall_coop_rate = total_cooperations / total_decisions if total_decisions > 0 else 0
        if overall_coop_rate >= 0.7:
            return Action.C
        elif history.round_number > 0:
            last_round_actions = history.opponent_actions[-1, :]
            last_round_cooperations = sum(last_round_actions) + int(history.my_actions[-1])
            last_round_defections = self.n - last_round_cooperations
            if last_round_cooperations >= last_round_defections:
                return Action.C
            else:
                return Action.D
        else:
            return Action.C

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        all_opponent_actions = history.opponent_actions
        total_cooperations = np.sum(all_opponent_actions) + sum(history.my_actions)
        total_decisions = all_opponent_actions.size + len(history.my_actions)
        cumulative_rate = total_cooperations / total_decisions if total_decisions > 0 else 0
        threshold_success_rate = self._get_threshold_success_rate(history)
        if cumulative_rate >= 0.8 and threshold_success_rate >= 0.7:
            return Action.C
        else:
            return Action.D

    def _get_threshold_success_rate(self, history: PlayerHistory) -> float:
        if history.round_number == 0:
            return 0.0
        successful_rounds = 0
        for round_idx in range(history.round_number):
            round_cooperators = sum(history.opponent_actions[round_idx, :]) + int(history.my_actions[round_idx])
            if round_cooperators >= self.m:
                successful_rounds += 1
        return successful_rounds / history.round_number

class Strategy_COOPERATIVE_20(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS).
    
    Balances cooperation with strategic adaptation, starting cooperatively
    and using multi-tier analysis to decide when cooperation is viable
    based on observed patterns and threshold achievement rates.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == r - 1:
            threshold_rate = self._calculate_threshold_rate(history)
            return Action.C if threshold_rate > 0.3 else Action.D
        cooperation_rate = self._calculate_cooperation_rate(history)
        threshold_rate = self._calculate_threshold_rate(history)
        previous_round_cooperators = self._count_previous_round_cooperators(history)
        cooperation_threshold = m / n + 0.1
        threshold_achievement_requirement = 0.4
        if n <= 4:
            cooperation_threshold = m / n + 0.05
        if m / n > 0.7:
            if cooperation_rate >= 0.6:
                return Action.C
        if k < 1.5:
            threshold_achievement_requirement = 0.5
        if cooperation_rate >= cooperation_threshold:
            return Action.C
        if previous_round_cooperators in [m - 1, m]:
            return Action.C
        if threshold_rate >= threshold_achievement_requirement and previous_round_cooperators < m - 2:
            return Action.C
        if previous_round_cooperators > 2 * m / 3:
            return Action.C
        return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate overall cooperation rate from all players across all rounds."""
        rounds_played = history.round_number
        if rounds_played == 0:
            return 0.0
        my_cooperations = np.sum(history.my_actions)
        opponent_cooperations = np.sum(history.opponent_actions)
        total_cooperations = my_cooperations + opponent_cooperations
        total_possible = self.game_description.n_players * rounds_played
        return total_cooperations / total_possible

    def _calculate_threshold_rate(self, history: PlayerHistory) -> float:
        """Calculate the rate at which the threshold was met across rounds."""
        rounds_played = history.round_number
        if rounds_played == 0:
            return 0.0
        threshold_met_count = 0
        m = self.game_description.m
        for round_idx in range(rounds_played):
            my_cooperation = 1 if history.my_actions[round_idx] else 0
            opponent_cooperations = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators = my_cooperation + opponent_cooperations
            if total_cooperators >= m:
                threshold_met_count += 1
        return threshold_met_count / rounds_played

    def _count_previous_round_cooperators(self, history: PlayerHistory) -> int:
        """Count cooperators in the most recent round."""
        if history.round_number == 0:
            return 0
        my_cooperation = 1 if history.my_actions[-1] else 0
        opponent_cooperations = np.sum(history.opponent_actions[-1, :])
        return int(my_cooperation + opponent_cooperations)

class Strategy_COOPERATIVE_21(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS)
    
    Balances cooperative intent with adaptive learning, starting cooperatively
    but adapting based on group behavior and threshold achievement patterns.
    Uses dynamic cooperation probability based on recent performance and
    strategic considerations for endgame scenarios.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.initial_phase_length = max(3, math.ceil(0.25 * self.r))
        self.endgame_phase_start = max(self.r - 3, math.floor(0.85 * self.r))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number
        if current_round < self.initial_phase_length:
            return Action.C
        last_round_cooperators = self._count_cooperators_in_round(history, -1)
        if last_round_cooperators == self.m - 1:
            return Action.C
        if current_round >= self.endgame_phase_start:
            return self._endgame_decision(history)
        cooperation_prob = self._calculate_cooperation_probability(history)
        return Action.C if random.random() < cooperation_prob else Action.D

    def _count_cooperators_in_round(self, history: PlayerHistory, round_idx: int) -> int:
        """Count total cooperators (including self) in a specific round"""
        if round_idx >= len(history.my_actions) or round_idx < -len(history.my_actions):
            return 0
        my_action = history.my_actions[round_idx]
        opponent_actions = history.opponent_actions[round_idx, :]
        return int(my_action) + int(np.sum(opponent_actions))

    def _calculate_cooperation_probability(self, history: PlayerHistory) -> float:
        """Calculate dynamic cooperation probability based on recent performance"""
        base_cooperation_prob = 0.8 if self.n <= 4 else 0.7
        if self.m > self.n / 2:
            base_cooperation_prob = 0.85
        recent_window = min(5, max(3, math.ceil(0.25 * len(history.my_actions))))
        recent_rounds = max(1, min(recent_window, len(history.my_actions)))
        achievements = 0
        total_cooperators = 0
        for i in range(-recent_rounds, 0):
            cooperators = self._count_cooperators_in_round(history, i)
            total_cooperators += cooperators
            if cooperators >= self.m:
                achievements += 1
        threshold_achievement_rate = achievements / recent_rounds
        avg_cooperators = total_cooperators / recent_rounds
        if threshold_achievement_rate >= 0.8:
            threshold_bonus = 0.2
        elif threshold_achievement_rate >= 0.6:
            threshold_bonus = 0.1
        elif threshold_achievement_rate >= 0.4:
            threshold_bonus = 0.0
        else:
            threshold_bonus = -0.2
        proximity_to_threshold = avg_cooperators / self.m
        if proximity_to_threshold >= 1.1:
            proximity_bonus = 0.1
        elif proximity_to_threshold >= 0.9:
            proximity_bonus = 0.05
        elif proximity_to_threshold < 0.7:
            proximity_bonus = -0.15
        else:
            proximity_bonus = 0.0
        strategic_defection_prob = 0.0
        if len(history.my_actions) > 0:
            last_cooperators = self._count_cooperators_in_round(history, -1)
            if avg_cooperators >= self.m + 1 and last_cooperators >= self.m:
                strategic_defection_prob = 0.3
        streak_bonus = self._calculate_streak_bonus(history)
        final_cooperation_prob = base_cooperation_prob + threshold_bonus + proximity_bonus - strategic_defection_prob + streak_bonus
        return max(0.15, min(0.95, final_cooperation_prob))

    def _calculate_streak_bonus(self, history: PlayerHistory) -> float:
        """Calculate bonus/penalty based on recent streaks"""
        if len(history.my_actions) < 3:
            return 0.0
        recent_window = min(5, len(history.my_actions))
        failure_streak = 0
        success_streak = 0
        for i in range(1, min(6, len(history.my_actions) + 1)):
            cooperators = self._count_cooperators_in_round(history, -i)
            if cooperators < self.m:
                failure_streak += 1
                success_streak = 0
            else:
                success_streak += 1
                failure_streak = 0
        if failure_streak >= 3:
            return 0.2
        elif success_streak >= 5:
            return -0.1
        return 0.0

    def _endgame_decision(self, history: PlayerHistory) -> Action:
        """Make strategic decisions in the endgame phase"""
        last_round_cooperators = self._count_cooperators_in_round(history, -1)
        rounds_remaining = self.r - history.round_number
        if rounds_remaining == 0:
            if last_round_cooperators >= self.m:
                return Action.D if random.random() < 0.4 else Action.C
            else:
                return Action.C if random.random() < 0.7 else Action.D
        if last_round_cooperators >= self.m:
            defect_prob = 0.4 if rounds_remaining <= 2 else 0.25
            return Action.D if random.random() < defect_prob else Action.C
        else:
            if last_round_cooperators >= self.m - 2:
                cooperate_prob = 0.9
            else:
                cooperate_prob = 0.6
            return Action.C if random.random() < cooperate_prob else Action.D

class Strategy_COOPERATIVE_22(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS).
    
    Balances cooperation with strategic adaptation, starting cooperative but becoming 
    more selective based on group's demonstrated commitment. Uses graduated reciprocity
    with dynamic cooperation thresholds based on recent group behavior.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if current_round == self.r - 1:
            return self._final_round_decision(history)
        else:
            return self._adaptive_cooperation_decision(history)

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """Strategic decision for the final round."""
        rounds_to_check = min(4, len(history.my_actions))
        recent_success_rate = self._calculate_success_rate(history, rounds_to_check)
        if recent_success_rate >= 0.6:
            return Action.C
        my_coop_rate = np.mean(history.my_actions)
        group_coop_rate = np.mean(history.opponent_actions)
        if my_coop_rate > group_coop_rate and recent_success_rate < 0.4:
            return Action.D
        else:
            return self._apply_adaptive_rule(history)

    def _adaptive_cooperation_decision(self, history: PlayerHistory) -> Action:
        """Apply the adaptive cooperation rule for middle rounds."""
        return self._apply_adaptive_rule(history)

    def _apply_adaptive_rule(self, history: PlayerHistory) -> Action:
        """Core adaptive rule based on recent cooperation rates."""
        recent_rounds = min(3, len(history.my_actions))
        rcr = self._calculate_recent_cooperation_rate(history, recent_rounds)
        threshold_ratio = self.m / self.n
        if rcr >= threshold_ratio:
            base_prob = 0.9
        elif rcr >= 0.8 * threshold_ratio:
            base_prob = 0.7
        elif rcr >= 0.6 * threshold_ratio:
            base_prob = 0.5
        elif rcr >= 0.4 * threshold_ratio:
            base_prob = 0.3
        else:
            base_prob = 0.1
        if self._check_forgiveness_condition(history):
            base_prob = min(1.0, base_prob + 0.2)
        base_prob = self._apply_edge_case_adjustments(base_prob, history)
        return Action.C if random.random() < base_prob else Action.D

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory, recent_rounds: int) -> float:
        """Calculate the cooperation rate over recent rounds."""
        if recent_rounds == 0:
            return 0.0
        recent_opponent_actions = history.opponent_actions[-recent_rounds:]
        recent_my_actions = history.my_actions[-recent_rounds:]
        total_cooperators = np.sum(recent_opponent_actions) + np.sum(recent_my_actions)
        total_decisions = self.n * recent_rounds
        return total_cooperators / total_decisions

    def _check_forgiveness_condition(self, history: PlayerHistory) -> bool:
        """Check if forgiveness mechanism should be applied."""
        if len(history.my_actions) < 2:
            return False
        last_round_cooperators = np.sum(history.opponent_actions[-1]) + int(history.my_actions[-1])
        last_round_failed = last_round_cooperators < self.m
        if not last_round_failed:
            return False
        rounds_to_check = min(4, len(history.my_actions))
        if rounds_to_check < 2:
            return False
        successes = 0
        for i in range(1, rounds_to_check + 1):
            round_cooperators = np.sum(history.opponent_actions[-i]) + int(history.my_actions[-i])
            if round_cooperators >= self.m:
                successes += 1
        return successes >= 2

    def _calculate_success_rate(self, history: PlayerHistory, rounds_to_check: int) -> float:
        """Calculate the rate of successful cooperation over recent rounds."""
        if rounds_to_check == 0:
            return 0.0
        successes = 0
        actual_rounds = min(rounds_to_check, len(history.my_actions))
        for i in range(1, actual_rounds + 1):
            round_cooperators = np.sum(history.opponent_actions[-i]) + int(history.my_actions[-i])
            if round_cooperators >= self.m:
                successes += 1
        return successes / actual_rounds

    def _apply_edge_case_adjustments(self, base_prob: float, history: PlayerHistory) -> float:
        """Apply adjustments for edge cases."""
        adjusted_prob = base_prob
        if self.n <= 4:
            if adjusted_prob < 0.9:
                adjustment = (0.9 - adjusted_prob) * 0.5
                adjusted_prob = min(0.9, adjusted_prob + adjustment)
        if self.m > 0.7 * self.n:
            if len(history.my_actions) >= 2:
                recent_failures = 0
                for i in range(1, min(3, len(history.my_actions) + 1)):
                    round_cooperators = np.sum(history.opponent_actions[-i]) + int(history.my_actions[-i])
                    if round_cooperators < self.m:
                        recent_failures += 1
                    else:
                        break
                if recent_failures < 2:
                    adjusted_prob = max(adjusted_prob, 0.95 if len(history.my_actions) == 0 else adjusted_prob)
        if self.k < 1.5:
            threshold_multiplier = 1.2
            recent_rounds = min(3, len(history.my_actions))
            if recent_rounds > 0:
                rcr = self._calculate_recent_cooperation_rate(history, recent_rounds)
                required_rate = self.m / self.n * threshold_multiplier
                if rcr < required_rate:
                    adjusted_prob *= 0.8
        if self.r <= 3 and len(history.my_actions) >= 1:
            if len(history.my_actions) == 1:
                cooperators_round_1 = np.sum(history.opponent_actions[0]) + int(history.my_actions[0])
                return 1.0 if cooperators_round_1 >= self.m - 1 else 0.0
        return max(0.0, min(1.0, adjusted_prob))

class Strategy_COOPERATIVE_23(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperation Strategy (ATCS)
    
    Balances cooperative intent with strategic adaptation, dynamically adjusting
    cooperation based on observed group behavior and proximity to the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.player_cooperate_counts = np.zeros(self.n - 1)
        self.player_total_rounds = np.zeros(self.n - 1)
        self.initial_phase_rounds = min(3, self.r // 4)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = state.round_number
        if round_num <= self.initial_phase_rounds:
            return Action.C
        self._update_player_stats(history)
        recent_rounds = min(3, round_num)
        recent_cooperation_rate = self._calculate_recent_cooperation_rate(history, recent_rounds)
        base_threshold = self.m / self.n
        cooperation_threshold_high = base_threshold + self._get_threshold_adjustment()
        cooperation_threshold_low = base_threshold - self._get_threshold_adjustment()
        consistent_cooperators = self._count_consistent_cooperators()
        if round_num > 2 * self.r // 3:
            cooperation_threshold_high += 0.15
        if recent_cooperation_rate >= cooperation_threshold_high:
            return Action.C
        elif recent_cooperation_rate >= cooperation_threshold_low:
            if consistent_cooperators >= self.m - 2:
                return Action.C
            else:
                return Action.D
        else:
            last_round_cooperators = self._count_last_round_cooperators(history)
            if last_round_cooperators >= self.m:
                return Action.C
            elif self._should_avoid_exploitation(history):
                return Action.D
            elif self._should_test_cooperation(history, round_num):
                return Action.C
            else:
                return Action.D

    def _update_player_stats(self, history: PlayerHistory):
        """Update cooperation statistics for each opponent."""
        for player_idx in range(self.n - 1):
            rounds_played = history.round_number
            cooperations = np.sum(history.opponent_actions[:rounds_played, player_idx])
            self.player_cooperate_counts[player_idx] = cooperations
            self.player_total_rounds[player_idx] = rounds_played

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory, recent_rounds: int):
        """Calculate cooperation rate over recent rounds."""
        start_round = max(0, history.round_number - recent_rounds)
        if start_round >= history.round_number:
            return 0.0
        recent_actions = history.opponent_actions[start_round:history.round_number, :]
        total_cooperations = np.sum(recent_actions)
        total_decisions = recent_actions.size
        return total_cooperations / total_decisions if total_decisions > 0 else 0.0

    def _get_threshold_adjustment(self):
        """Get threshold adjustment based on game parameters."""
        adjustment = 0.1
        if self.n <= 4:
            adjustment += 0.1
        if self.m > 0.7 * self.n:
            adjustment += 0.1
        if self.k >= 3:
            adjustment -= 0.05
        return adjustment

    def _count_consistent_cooperators(self):
        """Count players who cooperate in >= 80% of rounds."""
        consistent = 0
        for i in range(self.n - 1):
            if self.player_total_rounds[i] > 0:
                coop_rate = self.player_cooperate_counts[i] / self.player_total_rounds[i]
                if coop_rate >= 0.8:
                    consistent += 1
        return consistent

    def _count_last_round_cooperators(self, history: PlayerHistory):
        """Count cooperators in the most recent round."""
        if history.round_number == 0:
            return 0
        last_round_actions = history.opponent_actions[history.round_number - 1, :]
        return np.sum(last_round_actions) + (1 if history.my_actions[-1] else 0)

    def _should_avoid_exploitation(self, history: PlayerHistory):
        """Check if we should avoid being exploited."""
        if history.round_number < 3:
            return False
        my_coop_rate = np.mean(history.my_actions)
        other_coop_rate = np.mean(history.opponent_actions)
        if my_coop_rate - other_coop_rate > 0.3:
            return True
        if history.round_number >= 3:
            recent_my_actions = history.my_actions[-3:]
            if np.all(recent_my_actions):
                for i in range(max(0, history.round_number - 3), history.round_number):
                    round_cooperators = np.sum(history.opponent_actions[i, :]) + (1 if history.my_actions[i] else 0)
                    if round_cooperators >= self.m:
                        return False
                return True
        return False

    def _should_test_cooperation(self, history: PlayerHistory, round_num: int):
        """Check if we should give the group a test cooperation."""
        if round_num < 4:
            return False
        recent_threshold_met = 0
        check_rounds = min(3, history.round_number)
        for i in range(history.round_number - check_rounds, history.round_number):
            cooperators = np.sum(history.opponent_actions[i, :]) + (1 if history.my_actions[i] else 0)
            if cooperators >= self.m:
                recent_threshold_met += 1
        if recent_threshold_met == 0 and round_num % (self.r // 4 + 1) == 0:
            return True
        return False

class Strategy_COOPERATIVE_24(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperative Strategy
    
    Starts with cooperation to establish trust, then adapts based on observed
    cooperation rates. Uses probabilistic thresholds to decide whether enough
    players will cooperate to meet the minimum threshold m.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0
        self.last_probe_round = -10

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.consecutive_defections = 0
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        rounds_played = history.round_number
        initial_phase_end = min(5, max(2, r // 3))
        if rounds_played < initial_phase_end:
            return Action.C
        total_cooperators = 0
        cooperation_history = []
        for round_idx in range(rounds_played):
            round_cooperators = 1 if history.my_actions[round_idx] else 0
            round_cooperators += sum(history.opponent_actions[round_idx, :])
            total_cooperators += round_cooperators
            cooperation_history.append(round_cooperators)
        cooperation_rate = total_cooperators / (n * rounds_played)
        expected_cooperators = cooperation_rate * n
        final_rounds = max(1, r // 5)
        is_endgame = rounds_played >= r - final_rounds
        is_last_round = rounds_played >= r - 1
        if is_last_round:
            if cooperation_rate > 0.8:
                return Action.C
            else:
                return Action.D
        if is_endgame:
            if cooperation_rate > 0.7:
                threshold = m - 0.5
            elif cooperation_rate >= 0.4:
                threshold = m
            else:
                return Action.D
        else:
            threshold = m - 0.5
            if len(cooperation_history) >= 3:
                cooperation_std = np.std(cooperation_history)
                if cooperation_std > 0.4:
                    threshold = m
        my_last_action = history.my_actions[-1] if len(history.my_actions) > 0 else True
        if not my_last_action:
            self.consecutive_defections += 1
        else:
            self.consecutive_defections = 0
        if self.consecutive_defections >= 3 and (not is_endgame) and (rounds_played - self.last_probe_round >= 4):
            self.last_probe_round = rounds_played
            self.consecutive_defections = 0
            return Action.C
        if expected_cooperators >= threshold:
            action = Action.C
        else:
            action = Action.D
        return action

class Strategy_COOPERATIVE_25(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) that balances cooperative intent with rational 
    self-protection by dynamically adjusting cooperation based on observed group behavior.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.base_threshold = max(0.3, min(0.8, self.m / self.n - 0.1))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if current_round == self.r - 1:
            return self._final_round_decision(history)
        return self._adaptive_cooperation_decision(history)

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """Make final round decision based on established patterns."""
        total_rounds = len(history.my_actions)
        threshold_met_count = 0
        for round_idx in range(total_rounds):
            cooperators = sum(history.opponent_actions[round_idx, :]) + int(history.my_actions[round_idx])
            if cooperators >= self.m:
                threshold_met_count += 1
        threshold_met_rate = threshold_met_count / total_rounds
        if threshold_met_rate > 0.7:
            return Action.C
        group_coop_rate = self._calculate_weighted_cooperation_rate(history)
        needed_rate = self.m / self.n
        if abs(group_coop_rate - needed_rate) <= 0.1:
            return Action.C
        return Action.D

    def _adaptive_cooperation_decision(self, history: PlayerHistory) -> Action:
        """Make cooperation decision based on adaptive threshold system."""
        group_coop_rate = self._calculate_weighted_cooperation_rate(history)
        threshold = self.base_threshold
        if self._check_recent_threshold_performance(history):
            trust_bonus = 0.15
        else:
            trust_bonus = 0.0
        streak_adjustment = self._calculate_streak_adjustment(history)
        if self._is_emergency_cooperation_needed(history):
            return Action.C
        base_coop_prob = self._get_base_cooperation_probability()
        if self.k > 2.5:
            base_coop_prob += 0.1
        if self.m / self.n < 0.4:
            threshold -= 0.05
        if group_coop_rate >= threshold:
            coop_prob = min(0.95, 0.9 + trust_bonus + streak_adjustment)
        elif group_coop_rate >= threshold - 0.15:
            coop_prob = min(0.95, 0.6 + trust_bonus + streak_adjustment)
        else:
            coop_prob = max(0.2, 0.3 + trust_bonus + streak_adjustment)
        return Action.C if random.random() < coop_prob else Action.D

    def _calculate_weighted_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate with recent behavior weighted more heavily."""
        total_rounds = len(history.my_actions)
        if total_rounds == 0:
            return 0.5
        weighted_cooperators = 0.0
        total_weight = 0.0
        for round_idx in range(total_rounds):
            cooperators = sum(history.opponent_actions[round_idx, :]) + int(history.my_actions[round_idx])
            coop_rate = cooperators / self.n
            if round_idx >= total_rounds - 3:
                weight = 2.0
            elif round_idx < 3:
                weight = 0.5
            else:
                weight = 1.0
            weighted_cooperators += coop_rate * weight
            total_weight += weight
        return weighted_cooperators / total_weight if total_weight > 0 else 0.5

    def _check_recent_threshold_performance(self, history: PlayerHistory) -> bool:
        """Check if group exceeded threshold in recent rounds."""
        total_rounds = len(history.my_actions)
        if total_rounds < 3:
            return False
        recent_threshold_met = 0
        check_rounds = min(3, total_rounds)
        for i in range(check_rounds):
            round_idx = total_rounds - 1 - i
            cooperators = sum(history.opponent_actions[round_idx, :]) + int(history.my_actions[round_idx])
            if cooperators >= self.m:
                recent_threshold_met += 1
        return recent_threshold_met >= 2

    def _calculate_streak_adjustment(self, history: PlayerHistory) -> float:
        """Calculate adjustment based on cooperation streaks."""
        total_rounds = len(history.my_actions)
        if total_rounds < 3:
            return 0.0
        recent_rates = []
        for round_idx in range(max(0, total_rounds - 5), total_rounds):
            cooperators = sum(history.opponent_actions[round_idx, :]) + int(history.my_actions[round_idx])
            rate = cooperators / self.n
            recent_rates.append(rate)
        if len(recent_rates) < 3:
            return 0.0
        increasing_streak = 0
        for i in range(1, len(recent_rates)):
            if recent_rates[i] > recent_rates[i - 1]:
                increasing_streak += 1
            else:
                break
        decreasing_streak = 0
        for i in range(1, len(recent_rates)):
            if recent_rates[i] < recent_rates[i - 1]:
                decreasing_streak += 1
            else:
                break
        if increasing_streak >= 3:
            return 0.15
        elif decreasing_streak >= 3:
            return -0.1
        else:
            return 0.0

    def _is_emergency_cooperation_needed(self, history: PlayerHistory) -> bool:
        """Check if emergency cooperation is needed when group is close to threshold."""
        total_rounds = len(history.my_actions)
        if total_rounds < 2:
            return False
        emergency_rounds = 0
        check_rounds = min(3, total_rounds)
        for i in range(check_rounds):
            round_idx = total_rounds - 1 - i
            cooperators = sum(history.opponent_actions[round_idx, :]) + int(history.my_actions[round_idx])
            if cooperators == self.m - 1:
                emergency_rounds += 1
        return emergency_rounds >= 2

    def _get_base_cooperation_probability(self) -> float:
        """Get base cooperation probability adjusted for game parameters."""
        base = 0.6
        if self.n > 8:
            base += 0.05
        return base

class Strategy_COOPERATIVE_26(BaseStrategy):
    """
    Cooperative Threshold Strategy with Adaptive Trust
    
    This strategy aims to maximize collective welfare while protecting against exploitation.
    It operates on conditional cooperation - cooperating when there's reasonable evidence 
    that enough others will also cooperate, while adapting based on observed group behavior.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.confidence_adjustment = 0.0
        self.failure_rounds = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = state.round_number
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if round_num <= 2:
            return Action.C
        player_coop_ratios = []
        for player_idx in range(n - 1):
            cooperations = sum(history.opponent_actions[:, player_idx])
            total_rounds = len(history.opponent_actions)
            ratio = cooperations / total_rounds if total_rounds > 0 else 0.0
            if total_rounds >= 3:
                recent_weight = 1.5
                recent_cooperations = sum(history.opponent_actions[-3:, player_idx])
                recent_ratio = recent_cooperations / min(3, total_rounds)
                ratio = (ratio + recent_weight * recent_ratio) / (1 + recent_weight)
            player_coop_ratios.append(ratio)
        expected_cooperators = sum(player_coop_ratios)
        cooperation_probability = expected_cooperators / (n - 1) if n > 1 else 0.0
        self._update_confidence_adjustment(history, m)
        if n <= 4:
            base_threshold = 0.6
        elif n >= 10:
            base_threshold = 0.8
        else:
            base_threshold = 0.7
        adjusted_threshold = min(0.9, base_threshold + self.confidence_adjustment)
        is_endgame = round_num >= 0.8 * r
        is_final_round = round_num == r - 1
        if expected_cooperators >= m - 1:
            return Action.C
        if is_final_round:
            return Action.D
        endgame_threshold = 0.8 if is_endgame else adjusted_threshold
        if cooperation_probability >= endgame_threshold:
            return Action.C
        if not is_endgame and self._has_recent_positive_trend(history, m):
            return Action.C
        if not is_endgame and expected_cooperators >= m - 2:
            return Action.C
        if self._is_universal_defection(history):
            if round_num % 3 == 0:
                return Action.C
            else:
                return Action.D
        if cooperation_probability < 0.3:
            if expected_cooperators >= m:
                return Action.C
            else:
                return Action.D
        if abs(expected_cooperators - (m - 2)) < 0.1:
            if any((ratio > 0.6 for ratio in player_coop_ratios)):
                return Action.C
        return Action.D

    def _update_confidence_adjustment(self, history: PlayerHistory, m: int):
        """Update confidence adjustment based on recent cooperation failures."""
        if len(history.opponent_actions) == 0:
            return
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1] == True:
            total_cooperators = last_round_cooperators + 1
        else:
            total_cooperators = last_round_cooperators
        if total_cooperators < m:
            current_round = len(history.opponent_actions)
            self.failure_rounds.append(current_round - 1)
        current_round = len(history.opponent_actions)
        self.failure_rounds = [r for r in self.failure_rounds if current_round - r <= 2]
        if len(self.failure_rounds) > 0:
            self.confidence_adjustment = 0.1
        else:
            self.confidence_adjustment = 0.0

    def _has_recent_positive_trend(self, history: PlayerHistory, m: int) -> bool:
        """Check if cooperation succeeded at least 2 times in last 3 rounds."""
        if len(history.opponent_actions) < 3:
            return False
        successes = 0
        for i in range(-3, 0):
            if abs(i) <= len(history.opponent_actions):
                round_cooperators = sum(history.opponent_actions[i, :])
                if i < len(history.my_actions) and history.my_actions[i]:
                    round_cooperators += 1
                if round_cooperators >= m:
                    successes += 1
        return successes >= 2

    def _is_universal_defection(self, history: PlayerHistory) -> bool:
        """Check if no one else has cooperated in last 3 rounds."""
        if len(history.opponent_actions) < 3:
            return False
        last_3_rounds = history.opponent_actions[-3:, :]
        total_cooperations = np.sum(last_3_rounds)
        return total_cooperations == 0

class Strategy_COOPERATIVE_27(BaseStrategy):
    """
    Adaptive Threshold Guardian - A conditionally cooperative strategy that balances
    cooperation with strategic responsiveness to maintain collective benefit while
    protecting against exploitation. Always cooperates first, then adapts based on
    threshold safety, recent cooperation trends, and exploitation levels.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        prev_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            prev_cooperators += 1
        look_back = min(3, current_round)
        total_other_cooperations = 0
        total_other_opportunities = 0
        for i in range(look_back):
            round_idx = current_round - 1 - i
            total_other_cooperations += sum(history.opponent_actions[round_idx, :])
            total_other_opportunities += n - 1
        recent_coop_rate = total_other_cooperations / total_other_opportunities if total_other_opportunities > 0 else 0
        my_coop_rate = sum(history.my_actions) / current_round
        others_total_coop = sum((sum(history.opponent_actions[i, :]) for i in range(current_round)))
        others_total_opportunities = (n - 1) * current_round
        others_avg_coop_rate = others_total_coop / others_total_opportunities if others_total_opportunities > 0 else 0
        exploitation_ratio = my_coop_rate - others_avg_coop_rate
        if current_round == r:
            if prev_cooperators >= m:
                return Action.D
            else:
                return Action.C
        exploitation_threshold_adjustment = -0.1 if current_round <= 3 else 0
        if prev_cooperators < m:
            if recent_coop_rate > 0.3:
                return Action.C
            elif exploitation_ratio > 0.4 + exploitation_threshold_adjustment:
                return Action.D
            else:
                return Action.C
        elif prev_cooperators == m:
            if recent_coop_rate > 0.4:
                return Action.C
            elif exploitation_ratio > 0.3 + exploitation_threshold_adjustment:
                return Action.D
            else:
                return Action.C
        elif recent_coop_rate > 0.6:
            return Action.C
        elif recent_coop_rate > 0.3:
            if exploitation_ratio < 0.3 + exploitation_threshold_adjustment:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D
        if current_round >= 4:
            recent_overall_coop = 0
            recent_rounds_to_check = min(3, current_round)
            for i in range(recent_rounds_to_check):
                round_idx = current_round - 1 - i
                round_total_coop = sum(history.opponent_actions[round_idx, :])
                if history.my_actions[round_idx]:
                    round_total_coop += 1
                recent_overall_coop += round_total_coop / n
            avg_recent_coop_rate = recent_overall_coop / recent_rounds_to_check
            if avg_recent_coop_rate < 0.2:
                if prev_cooperators >= m - 1:
                    return Action.C
                else:
                    return Action.D
        return Action.C

class Strategy_COOPERATIVE_28(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperation Strategy
    
    This strategy balances cooperative intent with adaptive learning, using three phases:
    1. Cooperative initialization (first 3 rounds or r/3)
    2. Adaptive response based on cooperation viability score
    3. Endgame cooperation push (final 20% of rounds)
    
    The strategy learns from group behavior and adjusts thresholds dynamically.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.init_phase_length = max(3, self.r // 3)
        self.endgame_start = int(0.8 * self.r)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number + 1
        if current_round <= self.init_phase_length:
            return Action.C
        viability_score = self._calculate_viability_score(history)
        threshold = self._calculate_threshold(current_round)
        if current_round > self.endgame_start:
            return self._endgame_decision(history, viability_score)
        if viability_score >= threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_viability_score(self, history: PlayerHistory) -> float:
        """Calculate the cooperation viability score based on recent history."""
        rounds_completed = history.round_number
        recent_rounds = min(3, rounds_completed)
        if recent_rounds == 0:
            recent_cooperation_rate = 0.0
        else:
            recent_cooperators = 0
            for i in range(recent_rounds):
                round_idx = rounds_completed - 1 - i
                recent_cooperators += np.sum(history.opponent_actions[round_idx, :])
                if history.my_actions[round_idx]:
                    recent_cooperators += 1
            recent_cooperation_rate = recent_cooperators / (recent_rounds * self.n)
        trend_factor = self._calculate_trend_factor(history)
        success_count = 0
        for round_idx in range(rounds_completed):
            cooperators = np.sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators >= self.m:
                success_count += 1
        success_rate = success_count / rounds_completed if rounds_completed > 0 else 0.0
        rounds_remaining = self.r - (history.round_number + 1)
        risk_adjustment = min(1.0, rounds_remaining / self.r + 0.3)
        viability_score = (0.4 * recent_cooperation_rate + 0.3 * success_rate) * trend_factor * risk_adjustment
        return viability_score

    def _calculate_trend_factor(self, history: PlayerHistory) -> float:
        """Calculate trend factor based on cooperation rate changes."""
        rounds_completed = history.round_number
        if rounds_completed < 3:
            return 1.0
        recent_start = max(0, rounds_completed - 3)
        older_start = max(0, rounds_completed - 6)
        older_end = recent_start
        if older_end <= older_start:
            return 1.0
        recent_cooperators = 0
        older_cooperators = 0
        for i in range(recent_start, rounds_completed):
            cooperators = np.sum(history.opponent_actions[i, :])
            if history.my_actions[i]:
                cooperators += 1
            recent_cooperators += cooperators
        for i in range(older_start, older_end):
            cooperators = np.sum(history.opponent_actions[i, :])
            if history.my_actions[i]:
                cooperators += 1
            older_cooperators += cooperators
        recent_rate = recent_cooperators / ((rounds_completed - recent_start) * self.n)
        older_rate = older_cooperators / ((older_end - older_start) * self.n)
        if recent_rate > older_rate + 0.05:
            return 1.0
        elif abs(recent_rate - older_rate) <= 0.05:
            return 0.8
        else:
            return 0.6

    def _calculate_threshold(self, current_round: int) -> float:
        """Calculate cooperation threshold that decreases over time."""
        base_threshold = max(0.3, self.m / self.n - 0.1)
        progress = (current_round - 1) / self.r
        threshold_reduction = 0.1 * progress
        if self.n <= 4:
            threshold_reduction += 0.1
        return max(0.2, base_threshold - threshold_reduction)

    def _endgame_decision(self, history: PlayerHistory, viability_score: float) -> Action:
        """Make decision in endgame phase with more aggressive cooperation."""
        rounds_completed = history.round_number
        success_count = 0
        for round_idx in range(rounds_completed):
            cooperators = np.sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators >= self.m:
                success_count += 1
        success_rate = success_count / rounds_completed if rounds_completed > 0 else 0.0
        has_upward_trend = self._calculate_trend_factor(history) >= 1.0
        last_round_cooperators = 0
        if rounds_completed > 0:
            last_round_cooperators = np.sum(history.opponent_actions[-1, :])
            if history.my_actions[-1]:
                last_round_cooperators += 1
        if success_rate > 0.25 or has_upward_trend or last_round_cooperators >= self.m - 1:
            return Action.C
        endgame_threshold = max(0.15, self._calculate_threshold(rounds_completed + 1) - 0.1)
        if viability_score >= endgame_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_29(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperative Strategy (ATCS).
    
    Balances cooperation with adaptive learning, aiming to achieve collective benefit
    while protecting against exploitation. Uses cooperative optimism with learned caution.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if current_round == r - 1:
            return self._final_round_decision(history)
        return self._regular_round_decision(history)

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """Strategic final round decision."""
        success_rate = self._calculate_overall_success_rate(history)
        my_coop_rate = self._calculate_my_cooperation_rate(history)
        avg_coop_rate = self._calculate_average_cooperation_rate(history)
        if success_rate >= 0.7:
            return Action.C
        elif my_coop_rate > avg_coop_rate + 0.2:
            return Action.D
        else:
            return Action.C if random.random() < 0.6 else Action.D

    def _regular_round_decision(self, history: PlayerHistory) -> Action:
        """Decision logic for rounds 2 to r-1."""
        recent_rounds = min(5, history.round_number)
        recent_success_rate = self._calculate_recent_success_rate(history, recent_rounds)
        if recent_success_rate >= 0.6:
            base_prob = 0.9
        elif recent_success_rate >= 0.4:
            base_prob = 0.7
        elif recent_success_rate >= 0.2:
            base_prob = 0.5
        else:
            base_prob = 0.3
        if self._threshold_met_last_round(history):
            adjusted_prob = min(1.0, base_prob + 0.2)
        else:
            adjusted_prob = max(0.1, base_prob - 0.1)
        last_round_cooperators = self._count_cooperators_last_round(history)
        cooperation_gap = self.game_description.m - last_round_cooperators
        if cooperation_gap <= 2 and base_prob >= 0.5:
            final_prob = min(1.0, adjusted_prob + 0.3)
        else:
            final_prob = adjusted_prob
        return Action.C if random.random() < final_prob else Action.D

    def _calculate_recent_success_rate(self, history: PlayerHistory, recent_rounds: int) -> float:
        """Calculate success rate over recent rounds."""
        if recent_rounds == 0:
            return 0.0
        successful_rounds = 0
        start_idx = max(0, history.round_number - recent_rounds)
        for round_idx in range(start_idx, history.round_number):
            cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators >= self.game_description.m:
                successful_rounds += 1
        return successful_rounds / recent_rounds

    def _calculate_overall_success_rate(self, history: PlayerHistory) -> float:
        """Calculate success rate over all completed rounds."""
        if history.round_number == 0:
            return 0.0
        successful_rounds = 0
        for round_idx in range(history.round_number):
            cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators >= self.game_description.m:
                successful_rounds += 1
        return successful_rounds / history.round_number

    def _calculate_my_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate my cooperation rate over all rounds."""
        if history.round_number == 0:
            return 0.0
        return sum(history.my_actions) / history.round_number

    def _calculate_average_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate average cooperation rate across all players."""
        if history.round_number == 0:
            return 0.0
        total_cooperations = sum(history.my_actions)
        total_cooperations += np.sum(history.opponent_actions)
        total_decisions = history.round_number * self.game_description.n_players
        return total_cooperations / total_decisions

    def _threshold_met_last_round(self, history: PlayerHistory) -> bool:
        """Check if threshold was met in the most recent round."""
        if history.round_number == 0:
            return False
        last_round_idx = history.round_number - 1
        cooperators = sum(history.opponent_actions[last_round_idx, :])
        if history.my_actions[last_round_idx]:
            cooperators += 1
        return cooperators >= self.game_description.m

    def _count_cooperators_last_round(self, history: PlayerHistory) -> int:
        """Count total cooperators in the most recent round."""
        if history.round_number == 0:
            return 0
        last_round_idx = history.round_number - 1
        cooperators = sum(history.opponent_actions[last_round_idx, :])
        if history.my_actions[last_round_idx]:
            cooperators += 1
        return cooperators

class Strategy_COOPERATIVE_30(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) that balances cooperation with self-protection 
    by maintaining a dynamic assessment of the group's cooperative potential while 
    being forgiving enough to rebuild cooperation after defection cycles.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = history.round_number + 1
        total_cooperation_rates = []
        for round_idx in range(history.round_number):
            cooperators_in_round = sum(history.opponent_actions[round_idx, :]) + (1 if history.my_actions[round_idx] else 0)
            cooperation_rate = cooperators_in_round / n
            total_cooperation_rates.append(cooperation_rate)
        CHS = sum(total_cooperation_rates) / len(total_cooperation_rates)
        recent_rounds = min(3, history.round_number)
        if recent_rounds >= 1:
            last_round_cooperators = sum(history.opponent_actions[-1, :]) + (1 if history.my_actions[-1] else 0)
            last_round_rate = last_round_cooperators / n
            if recent_rounds >= 2:
                second_last_cooperators = sum(history.opponent_actions[-2, :]) + (1 if history.my_actions[-2] else 0)
                second_last_rate = second_last_cooperators / n
                Recent_Coop_Rate = (last_round_rate + 0.5 * second_last_rate) / (1 + 0.5)
            else:
                Recent_Coop_Rate = last_round_rate
        else:
            Recent_Coop_Rate = CHS
        Expected_Cooperators = n * max(CHS, Recent_Coop_Rate)
        threshold_adjustment = 0
        if current_round <= 4:
            threshold_adjustment = -1
        elif CHS < 0.15 and self._count_consecutive_low_cooperation(history) > 3:
            threshold_adjustment = 1
        if current_round == r:
            return Action.C if CHS > 0.35 or Recent_Coop_Rate > 0.45 else Action.D
        cooperation_conditions = [Expected_Cooperators >= m - 1 + threshold_adjustment, Expected_Cooperators >= m - 2 + threshold_adjustment and CHS > 0.4, Recent_Coop_Rate > CHS + 0.15, self._last_round_successful(history) and CHS > 0.25]
        return Action.C if any(cooperation_conditions) else Action.D

    def _count_consecutive_low_cooperation(self, history: PlayerHistory) -> int:
        """Count consecutive rounds with cooperation rate < 0.15 from the end."""
        count = 0
        n = self.game_description.n_players
        for round_idx in range(history.round_number - 1, -1, -1):
            cooperators = sum(history.opponent_actions[round_idx, :]) + (1 if history.my_actions[round_idx] else 0)
            cooperation_rate = cooperators / n
            if cooperation_rate < 0.15:
                count += 1
            else:
                break
        return count

    def _last_round_successful(self, history: PlayerHistory) -> bool:
        """Check if the threshold was met in the last round."""
        if history.round_number == 0:
            return False
        n = self.game_description.n_players
        m = self.game_description.m
        last_round_cooperators = sum(history.opponent_actions[-1, :]) + (1 if history.my_actions[-1] else 0)
        return last_round_cooperators >= m

class Strategy_COOPERATIVE_31(BaseStrategy):
    """
    Graduated Reciprocator: An adaptive cooperative strategy that balances collective welfare 
    with self-protection through conditional cooperation based on group behavior patterns 
    and strategic timing across early, mid, and end game phases.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number + 1
        lookback_rounds = min(3, max(1, r // 4))
        recent_rounds = min(lookback_rounds, history.round_number)
        if recent_rounds > 0:
            recent_opponent_actions = history.opponent_actions[-recent_rounds:, :]
            recent_my_actions = history.my_actions[-recent_rounds:]
            total_recent_cooperators = np.sum(recent_opponent_actions) + np.sum(recent_my_actions)
            total_recent_decisions = recent_rounds * n
            recent_coop_rate = total_recent_cooperators / total_recent_decisions
        else:
            recent_coop_rate = 1.0
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        my_coop_rate = np.sum(history.my_actions) / len(history.my_actions)
        if current_round <= r / 3:
            if recent_coop_rate >= 0.3:
                return Action.C
        elif current_round > 2 * r / 3:
            if current_round >= r - 1 and last_round_cooperators >= m / 2:
                return Action.C
            if recent_coop_rate >= m / n - 0.05:
                return Action.C
        if recent_coop_rate >= m / n - 0.1:
            return Action.C
        if last_round_cooperators == m - 1:
            return Action.C
        if recent_coop_rate >= 0.6:
            return Action.C
        if m == n - 1:
            if recent_coop_rate > 0.5:
                return Action.C
        elif m == 2:
            if recent_coop_rate <= 0.4:
                return Action.D
        return Action.D

class Strategy_COOPERATIVE_32(BaseStrategy):
    """
    Adaptive Trust Builder: A cooperative strategy that balances cooperation with strategic adaptation
    based on observed group behavior. Uses three phases: trust building, adaptive cooperation, and
    strategic endgame to optimize collective outcomes while protecting against exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.base_cooperation_probability = 0.7
        self.trust_decay_rate = 0.1
        self.trust_recovery_rate = 0.15
        self.trend_weight = 0.2
        self.endgame_cooperation_boost = 0.3
        self.trust_level = 1.0
        self.cooperation_history = []
        self.threshold_met_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        self._update_history(history)
        phase = self._determine_phase(current_round)
        if phase == 'trust_building':
            return Action.C
        elif phase == 'adaptive':
            return self._adaptive_decision(history)
        else:
            return self._endgame_decision(history, current_round)

    def _update_history(self, history: PlayerHistory):
        """Update internal tracking of cooperation patterns and threshold achievements."""
        last_round_idx = len(history.my_actions) - 1
        my_last_action = history.my_actions[last_round_idx]
        opponent_cooperators = int(np.sum(history.opponent_actions[last_round_idx, :]))
        total_cooperators = opponent_cooperators + (1 if my_last_action else 0)
        self.cooperation_history.append(total_cooperators)
        threshold_met = total_cooperators >= self.m
        self.threshold_met_history.append(threshold_met)
        if threshold_met:
            self.trust_level = min(1.0, self.trust_level + self.trust_recovery_rate)
        else:
            self.trust_level = max(0.0, self.trust_level - self.trust_decay_rate)

    def _determine_phase(self, current_round: int) -> str:
        """Determine which phase of the strategy we're in."""
        trust_building_end = max(1, int(0.2 * self.r))
        endgame_start = int(0.8 * self.r)
        if current_round <= trust_building_end:
            return 'trust_building'
        elif current_round >= endgame_start:
            return 'endgame'
        else:
            return 'adaptive'

    def _calculate_recent_success_rate(self, window_size: int=None) -> float:
        """Calculate success rate of threshold achievement in recent rounds."""
        if not self.threshold_met_history:
            return 0.5
        if window_size is None:
            window_size = min(5, max(1, self.r // 4))
        recent_results = self.threshold_met_history[-window_size:]
        return sum(recent_results) / len(recent_results)

    def _analyze_cooperation_trend(self) -> float:
        """Analyze trend in cooperation levels."""
        if len(self.cooperation_history) < 2:
            return 0.0
        window_size = min(3, len(self.cooperation_history))
        recent_cooperation = self.cooperation_history[-window_size:]
        if len(recent_cooperation) < 2:
            return 0.0
        mid_point = len(recent_cooperation) // 2
        if mid_point == 0:
            return 0.0
        early_avg = np.mean(recent_cooperation[:mid_point])
        late_avg = np.mean(recent_cooperation[mid_point:])
        trend = (late_avg - early_avg) / self.n
        return max(-0.3, min(0.3, trend))

    def _adaptive_decision(self, history: PlayerHistory) -> Action:
        """Make decision during adaptive cooperation phase."""
        recent_success_rate = self._calculate_recent_success_rate()
        cooperation_trend = self._analyze_cooperation_trend()
        cooperation_prob = self.base_cooperation_probability
        if recent_success_rate >= 0.6:
            cooperation_prob += 0.2
        elif recent_success_rate <= 0.3:
            cooperation_prob -= 0.2
        cooperation_prob += cooperation_trend * self.trend_weight
        cooperation_prob = cooperation_prob * self.trust_level
        cooperation_prob += self._edge_case_adjustments()
        cooperation_prob = max(0.1, min(0.9, cooperation_prob))
        return Action.C if random.random() < cooperation_prob else Action.D

    def _endgame_decision(self, history: PlayerHistory, current_round: int) -> Action:
        """Make decision during endgame phase."""
        recent_success_rate = self._calculate_recent_success_rate()
        endgame_phase_length = int(0.2 * self.r)
        endgame_start = int(0.8 * self.r)
        rounds_remaining = self.r - current_round
        endgame_progress = 1.0 - rounds_remaining / endgame_phase_length if endgame_phase_length > 0 else 1.0
        endgame_bonus = endgame_progress * self.endgame_cooperation_boost
        cooperation_threshold = 0.4 - endgame_bonus
        return Action.C if recent_success_rate > cooperation_threshold else Action.D

    def _edge_case_adjustments(self) -> float:
        """Handle special cases that require cooperation probability adjustments."""
        adjustment = 0.0
        if self.m >= 0.8 * self.n:
            adjustment += 0.2
        if self.k > 3.0:
            adjustment += 0.15
        if self.n <= 3:
            adjustment += 0.1
        return adjustment

class Strategy_COOPERATIVE_33(BaseStrategy):
    """
    Adaptive Threshold Cooperation with Forgiveness strategy.
    Starts cooperatively, adapts based on collective behavior, and maintains
    a bias toward cooperation while avoiding excessive exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.forgiveness_mode = False
        self.consecutive_failures = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        initial_phase_length = min(3, max(1, int(0.2 * r)))
        if current_round < initial_phase_length:
            return Action.C
        endgame_start = max(1, int(0.9 * r))
        if current_round >= endgame_start:
            return self._endgame_decision(history, current_round, r)
        return self._adaptive_decision(history)

    def _endgame_decision(self, history: PlayerHistory, current_round: int, total_rounds: int) -> Action:
        """Handle endgame decision logic."""
        success_count = 0
        for round_idx in range(len(history.my_actions)):
            cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators >= self.game_description.m:
                success_count += 1
        success_rate = success_count / len(history.my_actions) if len(history.my_actions) > 0 else 0
        if success_rate > 0.5:
            return Action.C
        recent_trend_improving = False
        some_cooperation_exists = False
        if len(history.my_actions) >= 3:
            recent_rounds = min(3, len(history.my_actions))
            recent_coop_counts = []
            for i in range(recent_rounds):
                round_idx = len(history.my_actions) - 1 - i
                cooperators = sum(history.opponent_actions[round_idx, :])
                recent_coop_counts.append(cooperators)
                if cooperators > 0:
                    some_cooperation_exists = True
            if len(recent_coop_counts) >= 2:
                recent_trend_improving = recent_coop_counts[0] > recent_coop_counts[-1]
        if current_round == total_rounds - 1:
            return Action.C
        if recent_trend_improving and some_cooperation_exists:
            return Action.C
        return Action.D

    def _adaptive_decision(self, history: PlayerHistory) -> Action:
        """Main adaptive cooperation logic."""
        n = self.game_description.n_players
        m = self.game_description.m
        recent_rounds = min(3, len(history.my_actions))
        recent_cooperators = 0
        recent_total_possible = 0
        for i in range(recent_rounds):
            round_idx = len(history.my_actions) - 1 - i
            cooperators = sum(history.opponent_actions[round_idx, :])
            recent_cooperators += cooperators
            recent_total_possible += n - 1
        recent_coop_rate = recent_cooperators / recent_total_possible if recent_total_possible > 0 else 0
        threshold_met_last_round = False
        if len(history.my_actions) > 0:
            last_round_cooperators = sum(history.opponent_actions[-1, :])
            if history.my_actions[-1]:
                last_round_cooperators += 1
            threshold_met_last_round = last_round_cooperators >= m
        threshold_rate = (m - 1) / n
        if recent_coop_rate >= threshold_rate:
            self.consecutive_failures = 0
            return Action.C
        if threshold_met_last_round:
            self.consecutive_failures = 0
            return Action.C
        if self.forgiveness_mode:
            self.forgiveness_mode = False
            self.consecutive_failures = 0
            return Action.C
        if self.consecutive_failures >= 2:
            self.forgiveness_mode = True
            return Action.C
        self.consecutive_failures += 1
        return Action.D

class Strategy_COOPERATIVE_34(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) - Balances cooperation and self-preservation
    through dynamic threshold adjustment based on group behavior patterns.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.initial_cooperation_rounds = max(3, math.ceil(0.2 * self.r))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number
        rounds_remaining = self.r - current_round
        if current_round < self.initial_cooperation_rounds:
            return Action.C
        cooperation_rate = self._get_cooperation_rate(history)
        recent_success_rate = self._get_recent_success_rate(history)
        if rounds_remaining <= max(2, math.ceil(self.r / 10)):
            return self._end_game_decision(cooperation_rate, recent_success_rate, history)
        dynamic_threshold = self._calculate_dynamic_threshold(recent_success_rate, rounds_remaining)
        if self._check_consecutive_success(history, 2):
            return Action.C if random.random() < 0.9 else Action.D
        if self._check_consecutive_failure(history, 3):
            return Action.C if cooperation_rate >= 0.75 else Action.D
        return Action.C if cooperation_rate >= dynamic_threshold else Action.D

    def _get_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate from last round."""
        if history.round_number == 0:
            return 0.5
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        return last_round_cooperators / self.n

    def _get_recent_success_rate(self, history: PlayerHistory) -> float:
        """Calculate success rate over recent rounds (last 3 or available history)."""
        rounds_to_check = min(3, history.round_number)
        if rounds_to_check == 0:
            return 0.5
        successes = 0
        for i in range(rounds_to_check):
            round_idx = history.round_number - 1 - i
            cooperators = np.sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators >= self.m:
                successes += 1
        return successes / rounds_to_check

    def _calculate_dynamic_threshold(self, recent_success_rate: float, rounds_remaining: int) -> float:
        """Calculate adaptive threshold based on group performance."""
        base_threshold = self.m / self.n
        if recent_success_rate >= 0.7:
            adjustment = -0.1
        elif recent_success_rate <= 0.3:
            adjustment = 0.15
        else:
            adjustment = 0
        progress_factor = (self.r - rounds_remaining) / self.r
        end_game_bonus = progress_factor * 0.1
        if self.n <= 4:
            adjustment *= 1.2
        if self.m >= 0.8 * self.n:
            adjustment *= 0.7
        return max(0.2, min(0.8, base_threshold + adjustment - end_game_bonus))

    def _end_game_decision(self, cooperation_rate: float, recent_success_rate: float, history: PlayerHistory) -> Action:
        """Make decision in end-game phase."""
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        if last_round_cooperators >= self.m - 1:
            return Action.C
        if recent_success_rate >= 0.6:
            return Action.C
        if self.r - history.round_number == 1 and cooperation_rate >= 0.4:
            return Action.C
        return Action.D

    def _check_consecutive_success(self, history: PlayerHistory, consecutive_rounds: int) -> bool:
        """Check if group achieved threshold in last N consecutive rounds."""
        if history.round_number < consecutive_rounds:
            return False
        for i in range(consecutive_rounds):
            round_idx = history.round_number - 1 - i
            cooperators = np.sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators < self.m:
                return False
        return True

    def _check_consecutive_failure(self, history: PlayerHistory, consecutive_rounds: int) -> bool:
        """Check if group failed to achieve threshold in last N consecutive rounds."""
        if history.round_number < consecutive_rounds:
            return False
        for i in range(consecutive_rounds):
            round_idx = history.round_number - 1 - i
            cooperators = np.sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators >= self.m:
                return False
        return True

class Strategy_COOPERATIVE_35(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS) - Balances cooperative intent with adaptive
    learning, fostering collective success while protecting against exploitation through 
    dynamic threshold adjustment and probabilistic decision-making.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.initial_phase_length = min(5, max(1, self.r // 4))
        self.base_threshold = self.m / self.n
        self.endgame_threshold = max(3, int(0.2 * self.r))
        self.consecutive_failures = 0
        self.forgiveness_rounds_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = history.round_number
        if round_num < self.initial_phase_length:
            return Action.C
        successful_rounds = self._count_successful_rounds(history)
        total_rounds = round_num
        cooperation_rate = successful_rounds / total_rounds if total_rounds > 0 else 0
        adaptive_threshold = max(self.base_threshold, cooperation_rate * 0.8)
        recent_cooperation_rate = self._get_recent_cooperation_rate(history)
        overall_cooperation_rate = self._get_overall_cooperation_rate(history)
        trend = recent_cooperation_rate - overall_cooperation_rate
        self._update_forgiveness_mechanism(history)
        if recent_cooperation_rate >= adaptive_threshold:
            cooperate_probability = 0.9
        elif recent_cooperation_rate >= self.base_threshold and trend > 0:
            cooperate_probability = 0.7
        elif recent_cooperation_rate >= self.base_threshold * 0.7:
            cooperate_probability = 0.5
        else:
            cooperate_probability = 0.2
        if self.forgiveness_rounds_remaining > 0:
            cooperate_probability = min(0.95, cooperate_probability + 0.2)
            self.forgiveness_rounds_remaining -= 1
        if self.r - round_num <= self.endgame_threshold:
            overall_success_rate = cooperation_rate
            if overall_success_rate > 0.6:
                cooperate_probability = 0.8
            elif overall_success_rate >= 0.3:
                cooperate_probability = 0.6
            else:
                cooperate_probability = 0.3
        cooperate_probability = self._apply_parameter_adjustments(cooperate_probability)
        cooperate_probability = max(0.1, min(0.95, cooperate_probability))
        return Action.C if random.random() < cooperate_probability else Action.D

    def _count_successful_rounds(self, history: PlayerHistory) -> int:
        """Count rounds where at least m players cooperated"""
        successful = 0
        for round_idx in range(history.round_number):
            my_action = 1 if history.my_actions[round_idx] else 0
            opponent_cooperators = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators = my_action + opponent_cooperators
            if total_cooperators >= self.m:
                successful += 1
        return successful

    def _get_recent_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate over last 3 rounds"""
        rounds_to_check = min(3, history.round_number)
        if rounds_to_check == 0:
            return 0.0
        total_cooperators = 0
        total_possible = 0
        for i in range(rounds_to_check):
            round_idx = history.round_number - 1 - i
            my_action = 1 if history.my_actions[round_idx] else 0
            opponent_cooperators = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += my_action + opponent_cooperators
            total_possible += self.n
        return total_cooperators / total_possible if total_possible > 0 else 0.0

    def _get_overall_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate overall cooperation rate across all rounds"""
        if history.round_number == 0:
            return 0.0
        total_cooperators = 0
        total_possible = 0
        for round_idx in range(history.round_number):
            my_action = 1 if history.my_actions[round_idx] else 0
            opponent_cooperators = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += my_action + opponent_cooperators
            total_possible += self.n
        return total_cooperators / total_possible if total_possible > 0 else 0.0

    def _update_forgiveness_mechanism(self, history: PlayerHistory) -> None:
        """Update forgiveness mechanism based on consecutive failures"""
        if history.round_number == 0:
            return
        last_round_idx = history.round_number - 1
        my_action = 1 if history.my_actions[last_round_idx] else 0
        opponent_cooperators = np.sum(history.opponent_actions[last_round_idx, :])
        total_cooperators = my_action + opponent_cooperators
        if total_cooperators >= self.m:
            self.consecutive_failures = 0
        else:
            self.consecutive_failures += 1
            failure_threshold = 2 if self.n <= 4 else 3
            if self.consecutive_failures >= failure_threshold:
                self.forgiveness_rounds_remaining = 2
                self.consecutive_failures = 0

    def _apply_parameter_adjustments(self, cooperate_probability: float) -> float:
        """Apply adjustments based on game parameters"""
        if self.m == self.n - 1:
            cooperate_probability += 0.1
        if self.k > 3:
            cooperate_probability += 0.1
        return cooperate_probability

class Strategy_COOPERATIVE_36(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS): Balances cooperative intent with adaptive learning,
    maintaining cooperation when feasible while protecting against systematic exploitation.
    Uses dynamic cooperation probability based on historical and recent cooperation rates.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.forgiveness_used = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        rounds_played = history.round_number
        if state.round_number == r - 1:
            return self._final_round_decision(history)
        base_rate = self._calculate_historical_rate(history)
        recent_rate = self._calculate_recent_rate(history, last_rounds=3)
        adjusted_rate = 0.7 * base_rate + 0.3 * recent_rate
        expected_cooperators = adjusted_rate * n
        coop_prob = max(0.1, min(0.9, expected_cooperators / m))
        coop_prob = self._apply_forgiveness(coop_prob, history)
        coop_prob = self._apply_streak_breaking(coop_prob, history)
        coop_prob = self._apply_near_threshold_bias(coop_prob, expected_cooperators, m)
        if self._is_all_defect_environment(history):
            return self._probe_mode_decision(state.round_number)
        threshold = 0.3 if n <= 4 else 0.4
        return Action.C if coop_prob > threshold else Action.D

    def _calculate_historical_rate(self, history: PlayerHistory) -> float:
        """Calculate overall cooperation rate across all rounds and players."""
        total_cooperators = np.sum(history.opponent_actions) + np.sum(history.my_actions)
        total_decisions = self.game_description.n_players * history.round_number
        return total_cooperators / total_decisions if total_decisions > 0 else 0.0

    def _calculate_recent_rate(self, history: PlayerHistory, last_rounds: int) -> float:
        """Calculate cooperation rate for the most recent rounds."""
        rounds_to_check = min(last_rounds, history.round_number)
        if rounds_to_check == 0:
            return 0.0
        recent_opponent_actions = history.opponent_actions[-rounds_to_check:, :]
        recent_my_actions = history.my_actions[-rounds_to_check:]
        total_cooperators = np.sum(recent_opponent_actions) + np.sum(recent_my_actions)
        total_decisions = self.game_description.n_players * rounds_to_check
        return total_cooperators / total_decisions

    def _apply_forgiveness(self, coop_prob: float, history: PlayerHistory) -> float:
        """Apply forgiveness mechanism for recovery from temporary setbacks."""
        if history.round_number < 3:
            return coop_prob
        recent_cooperators = []
        for i in range(min(3, history.round_number)):
            round_idx = history.round_number - 1 - i
            cooperators = np.sum(history.opponent_actions[round_idx, :]) + int(history.my_actions[round_idx])
            recent_cooperators.append(cooperators)
        if len(recent_cooperators) >= 3:
            if recent_cooperators[0] < self.game_description.m and recent_cooperators[1] < self.game_description.m and (recent_cooperators[0] > recent_cooperators[1]) and (not self.forgiveness_used):
                self.forgiveness_used = True
                return 0.9
            else:
                self.forgiveness_used = False
        return coop_prob

    def _apply_streak_breaking(self, coop_prob: float, history: PlayerHistory) -> float:
        """Reduce cooperation if last 3 rounds all failed to reach threshold."""
        if history.round_number < 3:
            return coop_prob
        failed_rounds = 0
        for i in range(3):
            round_idx = history.round_number - 1 - i
            cooperators = np.sum(history.opponent_actions[round_idx, :]) + int(history.my_actions[round_idx])
            if cooperators < self.game_description.m:
                failed_rounds += 1
            else:
                break
        if failed_rounds >= 3:
            return max(0.1, coop_prob - 0.2)
        return coop_prob

    def _apply_near_threshold_bias(self, coop_prob: float, expected_cooperators: float, m: int) -> float:
        """Bias toward cooperation if expected cooperators are near threshold."""
        if abs(expected_cooperators - m) <= 1:
            return min(0.9, coop_prob + 0.1)
        return coop_prob

    def _is_all_defect_environment(self, history: PlayerHistory) -> bool:
        """Check if we're in an all-defect environment (first 3 rounds)."""
        if history.round_number < 3:
            return False
        total_cooperators = 0
        for i in range(min(3, history.round_number)):
            round_idx = i
            cooperators = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += cooperators
        return total_cooperators == 0

    def _probe_mode_decision(self, round_number: int) -> Action:
        """In all-defect environment, cooperate every 4th round to probe."""
        return Action.C if round_number % 4 == 0 else Action.D

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """Final round commitment strategy based on historical success rate."""
        successful_rounds = 0
        total_rounds = history.round_number
        for i in range(total_rounds):
            cooperators = np.sum(history.opponent_actions[i, :]) + int(history.my_actions[i])
            if cooperators >= self.game_description.m:
                successful_rounds += 1
        success_rate = successful_rounds / total_rounds if total_rounds > 0 else 0.0
        if success_rate > 0.5:
            return Action.C
        elif success_rate >= 0.3:
            return Action.C if random.random() < success_rate else Action.D
        else:
            return Action.D

class Strategy_COOPERATIVE_37(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS) - Balances cooperative intent with
    pragmatic risk assessment, adapting to observed opponent behavior while maintaining
    a fundamentally cooperative orientation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = history.round_number + 1
        if current_round == r:
            threshold_met_rounds = 0
            total_rounds = history.round_number
            for round_idx in range(total_rounds):
                cooperators_in_round = sum(history.opponent_actions[round_idx, :])
                if history.my_actions[round_idx]:
                    cooperators_in_round += 1
                if cooperators_in_round >= m:
                    threshold_met_rounds += 1
            threshold_success_rate = threshold_met_rounds / total_rounds if total_rounds > 0 else 0
            total_cooperators = np.sum(history.opponent_actions) + np.sum(history.my_actions)
            total_possible = n * total_rounds
            historical_coop_rate = total_cooperators / total_possible if total_possible > 0 else 0
            if threshold_success_rate > 0.6:
                return Action.C
            elif historical_coop_rate > m / n + 0.1:
                return Action.C if random.random() < 0.7 else Action.D
            else:
                return Action.C if random.random() < 0.3 else Action.D
        total_cooperators = np.sum(history.opponent_actions) + np.sum(history.my_actions)
        total_possible = n * history.round_number
        historical_coop_rate = total_cooperators / total_possible
        threshold_rate = m / n
        if historical_coop_rate >= threshold_rate:
            base_cooperation_prob = 0.8
        elif historical_coop_rate >= threshold_rate - 0.2:
            base_cooperation_prob = 0.6
        elif historical_coop_rate >= threshold_rate - 0.4:
            base_cooperation_prob = 0.4
        else:
            base_cooperation_prob = 0.2
        recent_rounds_count = min(3, history.round_number)
        if recent_rounds_count > 0:
            recent_start_idx = history.round_number - recent_rounds_count
            recent_opponent_cooperators = np.sum(history.opponent_actions[recent_start_idx:, :])
            recent_my_cooperators = np.sum(history.my_actions[recent_start_idx:])
            recent_total_cooperators = recent_opponent_cooperators + recent_my_cooperators
            recent_total_possible = n * recent_rounds_count
            recent_trend = recent_total_cooperators / recent_total_possible
            trend_adjustment = 0.2 * (recent_trend - historical_coop_rate)
            final_cooperation_prob = base_cooperation_prob + trend_adjustment
        else:
            final_cooperation_prob = base_cooperation_prob
        final_cooperation_prob = max(0.2, min(0.8, final_cooperation_prob))
        return Action.C if random.random() < final_cooperation_prob else Action.D

class Strategy_COOPERATIVE_38(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) - Balances optimism about cooperation 
    with pragmatic responses to defection patterns using three decision factors:
    cooperation momentum, success history, and strategic position.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        round_num = history.round_number + 1
        if round_num == r:
            total_rounds = len(history.my_actions)
            threshold_met_count = 0
            for i in range(total_rounds):
                cooperators = sum(history.opponent_actions[i, :]) + int(history.my_actions[i])
                if cooperators >= m:
                    threshold_met_count += 1
            success_rate = threshold_met_count / total_rounds if total_rounds > 0 else 0
            return Action.C if success_rate >= 0.4 else Action.D
        total_rounds = len(history.my_actions)
        cmf_signal = self._calculate_cmf(history, n, m)
        shf_signal = self._calculate_shf(history, m)
        spf_signal = self._calculate_spf(history, n, m)
        cooperative_signals = sum([s == 1 for s in [cmf_signal, shf_signal, spf_signal]])
        defection_signals = sum([s == -1 for s in [cmf_signal, shf_signal, spf_signal]])
        if cooperative_signals > defection_signals:
            return Action.C
        elif defection_signals > cooperative_signals:
            if m > n / 2 and (not self._strong_cooperation_signals(history, n, m)):
                return Action.D
            if round_num > 0.8 * r:
                return Action.D
            return Action.D
        else:
            avg_cooperators = self._average_cooperators_last_n_rounds(history, n, 2)
            return Action.C if avg_cooperators >= m - 2 else Action.D

    def _calculate_cmf(self, history, n, m):
        """Calculate Cooperation Momentum Factor"""
        recent_rounds = min(3, len(history.my_actions))
        if recent_rounds == 0:
            return 0
        total_cooperators = 0
        for i in range(-recent_rounds, 0):
            cooperators = sum(history.opponent_actions[i, :]) + int(history.my_actions[i])
            total_cooperators += cooperators
        recent_coop_rate = total_cooperators / (recent_rounds * n)
        if recent_coop_rate >= (m - 1) / n:
            return 1
        elif recent_coop_rate < (m - 2) / n:
            return -1
        else:
            return 0

    def _calculate_shf(self, history, m):
        """Calculate Success History Factor"""
        total_rounds = len(history.my_actions)
        if total_rounds == 0:
            return 0
        threshold_met_count = 0
        for i in range(total_rounds):
            cooperators = sum(history.opponent_actions[i, :]) + int(history.my_actions[i])
            if cooperators >= m:
                threshold_met_count += 1
        success_rate = threshold_met_count / total_rounds
        if success_rate >= 0.6:
            return 1
        elif success_rate < 0.3:
            return -1
        else:
            return 0

    def _calculate_spf(self, history, n, m):
        """Calculate Strategic Position Factor"""
        total_rounds = len(history.my_actions)
        if total_rounds == 0:
            return 0
        my_coop_rate = sum(history.my_actions) / total_rounds
        threshold_met_count = 0
        recent_high_coop = 0
        recent_rounds = min(3, total_rounds)
        for i in range(-recent_rounds, 0):
            cooperators = sum(history.opponent_actions[i, :]) + int(history.my_actions[i])
            if cooperators >= m:
                threshold_met_count += 1
            if cooperators >= m + 1:
                recent_high_coop += 1
        recent_success_rate = threshold_met_count / recent_rounds if recent_rounds > 0 else 0
        if recent_high_coop >= recent_rounds * 0.5:
            return 1
        if my_coop_rate > 0.6 and recent_success_rate < 0.3:
            return -1
        return 0

    def _average_cooperators_last_n_rounds(self, history, n, rounds):
        """Calculate average cooperators in last n rounds"""
        total_rounds = len(history.my_actions)
        check_rounds = min(rounds, total_rounds)
        if check_rounds == 0:
            return 0
        total_cooperators = 0
        for i in range(-check_rounds, 0):
            cooperators = sum(history.opponent_actions[i, :]) + int(history.my_actions[i])
            total_cooperators += cooperators
        return total_cooperators / check_rounds

    def _strong_cooperation_signals(self, history, n, m):
        """Check if there are strong cooperation signals for high threshold games"""
        total_rounds = len(history.my_actions)
        if total_rounds < 2:
            return False
        recent_rounds = min(2, total_rounds)
        coop_count = 0
        for i in range(-recent_rounds, 0):
            cooperators = sum(history.opponent_actions[i, :]) + int(history.my_actions[i])
            if cooperators >= m - 1:
                coop_count += 1
        return coop_count >= recent_rounds * 0.7

class Strategy_COOPERATIVE_39(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperation Strategy (ATCS)
    
    Balances cooperative intent with adaptive response to observed behavior,
    aiming to achieve the collective threshold while protecting against exploitation.
    Uses probabilistic cooperation based on observed community cooperation rates.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.required_rate = self.m / self.n
        self.safety_margin = 0.1
        self.target_rate = self.required_rate + self.safety_margin
        self.is_small_group = self.n <= 4
        self.is_high_threshold = self.m / self.n > 0.7
        self.is_short_game = self.r <= 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number + 1
        if self.is_short_game:
            return Action.C if random.random() < 0.8 else Action.D
        if current_round == self.r:
            return self._final_round_decision(history)
        return self._adaptive_decision(history)

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate overall cooperation rate from history"""
        total_rounds = history.round_number
        total_possible_cooperators = self.n * total_rounds
        my_cooperations = sum(history.my_actions)
        opponent_cooperations = np.sum(history.opponent_actions)
        total_cooperations = my_cooperations + opponent_cooperations
        return total_cooperations / total_possible_cooperators if total_possible_cooperators > 0 else 0

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory, rounds: int=3) -> float:
        """Calculate cooperation rate for the last 'rounds' rounds"""
        total_rounds = history.round_number
        start_round = max(0, total_rounds - rounds)
        if start_round >= total_rounds:
            return 0
        my_recent_cooperations = sum(history.my_actions[start_round:])
        opponent_recent_cooperations = np.sum(history.opponent_actions[start_round:, :])
        total_recent_cooperations = my_recent_cooperations + opponent_recent_cooperations
        total_recent_possible = self.n * (total_rounds - start_round)
        return total_recent_cooperations / total_recent_possible if total_recent_possible > 0 else 0

    def _calculate_my_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate my own cooperation rate"""
        total_rounds = history.round_number
        my_cooperations = sum(history.my_actions)
        return my_cooperations / total_rounds if total_rounds > 0 else 0

    def _adaptive_decision(self, history: PlayerHistory) -> Action:
        """Make decision for rounds 2 to r-1 based on observed cooperation"""
        cooperation_rate = self._calculate_cooperation_rate(history)
        if cooperation_rate >= self.target_rate:
            base_prob = 0.8
        elif cooperation_rate >= self.required_rate:
            base_prob = 0.9
        elif cooperation_rate >= self.required_rate * 0.7:
            base_prob = 0.6
        else:
            base_prob = 0.2
        final_prob = base_prob
        if self.is_small_group:
            final_prob = min(1.0, final_prob + 0.1)
        if self.is_high_threshold:
            final_prob = min(1.0, final_prob + 0.1)
        return Action.C if random.random() < final_prob else Action.D

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """Make decision for the final round"""
        recent_cooperation_rate = self._calculate_recent_cooperation_rate(history, 3)
        my_cooperation_rate = self._calculate_my_cooperation_rate(history)
        if recent_cooperation_rate >= self.required_rate:
            return Action.C
        elif my_cooperation_rate > self.required_rate + 0.15:
            return Action.D
        else:
            return Action.C

class Strategy_COOPERATIVE_40(BaseStrategy):
    """
    Cooperative Threshold Strategy (CTS) - Balances cooperative intentions with adaptive 
    responses to observed behavior patterns. Uses momentum tracking and threshold proximity 
    to make decisions that maximize collective welfare while being robust against exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if current_round == self.r - 1:
            return self._last_round_decision(history)
        return self._adaptive_decision(history, current_round)

    def _last_round_decision(self, history: PlayerHistory) -> Action:
        """Final round decision based on established patterns"""
        total_cooperators_per_round = []
        for round_idx in range(len(history.my_actions)):
            my_coop = 1 if history.my_actions[round_idx] else 0
            opp_coop = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators_per_round.append(my_coop + opp_coop)
        avg_historical_cooperators = np.mean(total_cooperators_per_round)
        recent_coop_rate = self._calculate_recent_cooperation_rate(history)
        if avg_historical_cooperators >= self.m - 1:
            return Action.C
        elif recent_coop_rate >= (self.m - 1) / self.n:
            return Action.C
        else:
            return Action.D

    def _adaptive_decision(self, history: PlayerHistory, current_round: int) -> Action:
        """Adaptive cooperation decision for rounds 2 to r-1"""
        recent_coop_rate = self._calculate_recent_cooperation_rate(history)
        threshold_proximity = self._calculate_threshold_proximity(history)
        if self.n <= 4:
            threshold_check = (self.m - 2) / self.n
        else:
            threshold_check = (self.m - 1) / self.n
        cooperation_boost = 0.2 if self.m > 0.7 * self.n else 0.0
        if recent_coop_rate >= threshold_check:
            return Action.C
        elif threshold_proximity >= 0.8 - cooperation_boost and recent_coop_rate >= 0.4 - cooperation_boost:
            return Action.C
        elif recent_coop_rate < 0.3:
            periodic_interval = 3 if self.m > 0.7 * self.n else 4
            if current_round % periodic_interval == 1:
                return Action.C
            else:
                return Action.D
        else:
            threshold_val = 0.5 - cooperation_boost
            if recent_coop_rate >= threshold_val:
                return Action.C
            else:
                return Action.D

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate weighted average of cooperation rate over last 3 rounds"""
        rounds_available = len(history.my_actions)
        if rounds_available <= 3:
            total_coop = 0
            total_players = 0
            for round_idx in range(rounds_available):
                my_coop = 1 if history.my_actions[round_idx] else 0
                opp_coop = np.sum(history.opponent_actions[round_idx, :])
                total_coop += my_coop + opp_coop
                total_players += self.n
            return total_coop / total_players if total_players > 0 else 0.4
        weights = [0.5, 0.3, 0.2]
        weighted_coop_rate = 0
        for i, weight in enumerate(weights):
            round_idx = rounds_available - 1 - i
            my_coop = 1 if history.my_actions[round_idx] else 0
            opp_coop = np.sum(history.opponent_actions[round_idx, :])
            round_coop_rate = (my_coop + opp_coop) / self.n
            weighted_coop_rate += weight * round_coop_rate
        return weighted_coop_rate

    def _calculate_threshold_proximity(self, history: PlayerHistory) -> float:
        """Calculate how close we've been to meeting the threshold on average"""
        total_cooperators_per_round = []
        for round_idx in range(len(history.my_actions)):
            my_coop = 1 if history.my_actions[round_idx] else 0
            opp_coop = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators_per_round.append(my_coop + opp_coop)
        avg_cooperators = np.mean(total_cooperators_per_round)
        return avg_cooperators / self.m

class Strategy_COOPERATIVE_41(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS)
    
    A strategy that balances optimism about cooperation with pragmatic defection
    when cooperation appears unsustainable. Operates in three phases with dynamic
    threshold adjustment based on collective cooperation patterns.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.recovery_attempt_flag = False
        self.last_threshold_update = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number + 1
        n_rounds = self.game_description.n_rounds
        if self._is_endgame_phase(current_round, n_rounds):
            return self._endgame_decision(history)
        elif current_round <= 3:
            return self._early_game_decision(history, current_round)
        else:
            return self._adaptive_phase_decision(history, current_round)

    def _is_endgame_phase(self, current_round: int, n_rounds: int) -> bool:
        return current_round > n_rounds * 0.8 and current_round > n_rounds - 3

    def _early_game_decision(self, history: PlayerHistory, current_round: int) -> Action:
        if current_round <= 3:
            last_round_cooperators = sum(history.opponent_actions[-1, :])
            if current_round == 3:
                total_cooperations_first_2 = sum(history.opponent_actions[0, :]) + int(history.my_actions[0]) + sum(history.opponent_actions[1, :]) + int(history.my_actions[1])
                if total_cooperations_first_2 < math.ceil(self.game_description.m / 2):
                    return self._adaptive_phase_decision(history, current_round)
            return Action.C if last_round_cooperators >= 1 else Action.C
        return Action.C

    def _adaptive_phase_decision(self, history: PlayerHistory, current_round: int) -> Action:
        if current_round - self.last_threshold_update >= 3:
            self._update_cooperation_threshold(history)
            self.last_threshold_update = current_round
        if self._should_attempt_recovery(history, current_round):
            self.recovery_attempt_flag = True
            return Action.C
        self.recovery_attempt_flag = False
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        rounds_to_check = min(3, len(history.opponent_actions))
        recent_cooperators = 0
        for i in range(rounds_to_check):
            round_idx = -(i + 1)
            recent_cooperators += sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                recent_cooperators += 1
        recent_avg_cooperators = recent_cooperators / rounds_to_check
        condition1 = last_round_cooperators >= self.cooperation_threshold - 1
        condition2 = recent_avg_cooperators >= self.cooperation_threshold - 0.5
        return Action.C if condition1 or condition2 else Action.D

    def _endgame_decision(self, history: PlayerHistory) -> Action:
        threshold_achievements = 0
        total_rounds = len(history.opponent_actions)
        for round_idx in range(total_rounds):
            round_cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                round_cooperators += 1
            if round_cooperators >= self.game_description.m:
                threshold_achievements += 1
        achievement_rate = threshold_achievements / total_rounds if total_rounds > 0 else 0
        if achievement_rate > 0.6:
            return self._adaptive_phase_decision(history, total_rounds + 1)
        elif achievement_rate >= 0.3:
            last_round_cooperators = sum(history.opponent_actions[-1, :])
            return Action.C if last_round_cooperators >= self.game_description.m else Action.D
        else:
            return Action.D

    def _should_attempt_recovery(self, history: PlayerHistory, current_round: int) -> bool:
        if self.recovery_attempt_flag:
            return False
        if current_round > self.game_description.n_rounds * 0.8:
            return False
        if len(history.opponent_actions) < 2:
            return False
        recent_2_cooperators = []
        for i in range(2):
            round_idx = -(i + 1)
            round_cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                round_cooperators += 1
            recent_2_cooperators.append(round_cooperators)
        return all((coop < self.game_description.m for coop in recent_2_cooperators))

    def _update_cooperation_threshold(self, history: PlayerHistory) -> None:
        rounds_to_check = min(3, len(history.opponent_actions))
        achievements = 0
        for i in range(rounds_to_check):
            round_idx = -(i + 1)
            round_cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                round_cooperators += 1
            if round_cooperators >= self.game_description.m:
                achievements += 1
        if achievements >= 2:
            min_threshold = math.ceil(self.game_description.m * 0.8)
            self.cooperation_threshold = max(self.cooperation_threshold - 1, min_threshold)
        elif achievements <= 1:
            max_threshold = self.game_description.m + 2
            self.cooperation_threshold = min(self.cooperation_threshold + 1, max_threshold)

class Strategy_COOPERATIVE_42(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS)
    
    Balances cooperative intent with adaptive learning, aiming to build and maintain 
    coalitions while protecting against exploitation. Uses initial cooperation phase,
    coalition maintenance, trend recognition, and strategic forgiveness.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.initial_phase_length = max(3, int(0.2 * self.r))
        self.endgame_start = int(0.9 * self.r)
        self.consecutive_failures = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if current_round < self.initial_phase_length:
            return Action.C
        last_round_cooperators = self._count_cooperators_last_round(history)
        if last_round_cooperators >= self.m:
            self.consecutive_failures = 0
            return Action.C
        if last_round_cooperators == self.m - 1:
            return Action.C
        if self._cooperation_trend_positive(history):
            return Action.C
        if current_round >= self.endgame_start:
            estimated_cooperators = self._estimate_cooperators(history)
            if estimated_cooperators < self.m:
                return Action.D
        if last_round_cooperators < self.m:
            self.consecutive_failures += 1
        else:
            self.consecutive_failures = 0
        if self.consecutive_failures >= 3:
            return Action.D
        if self._failed_round_recovery_conditions(history):
            if random.random() < 0.7:
                return Action.C
        return Action.D

    def _count_cooperators_last_round(self, history: PlayerHistory) -> int:
        """Count cooperators (including self) in the most recent round."""
        if len(history.my_actions) == 0:
            return 0
        opponent_cooperators = sum(history.opponent_actions[-1, :])
        my_cooperation = 1 if history.my_actions[-1] else 0
        return int(opponent_cooperators + my_cooperation)

    def _cooperation_trend_positive(self, history: PlayerHistory) -> bool:
        """Check if cooperation has been increasing over last 2-3 rounds."""
        rounds_completed = len(history.my_actions)
        if rounds_completed < 3:
            return False
        cooperator_counts = []
        for i in range(max(0, rounds_completed - 3), rounds_completed):
            opponent_cooperators = sum(history.opponent_actions[i, :])
            my_cooperation = 1 if history.my_actions[i] else 0
            cooperator_counts.append(int(opponent_cooperators + my_cooperation))
        if len(cooperator_counts) < 2:
            return False
        return cooperator_counts[-1] > cooperator_counts[0]

    def _estimate_cooperators(self, history: PlayerHistory) -> float:
        """Estimate likely number of cooperators based on recent patterns."""
        rounds_completed = len(history.my_actions)
        if rounds_completed == 0:
            return self.n * 0.5
        lookback = max(3, int(0.25 * rounds_completed))
        recent_start = max(0, rounds_completed - lookback)
        total_cooperators = 0
        rounds_counted = 0
        for i in range(recent_start, rounds_completed):
            opponent_cooperators = sum(history.opponent_actions[i, :])
            my_cooperation = 1 if history.my_actions[i] else 0
            total_cooperators += opponent_cooperators + my_cooperation
            rounds_counted += 1
        if rounds_counted == 0:
            return self.n * 0.5
        avg_cooperation_rate = total_cooperators / (rounds_counted * self.n)
        estimated = avg_cooperation_rate * self.n
        return estimated

    def _failed_round_recovery_conditions(self, history: PlayerHistory) -> bool:
        """Check conditions for strategic forgiveness after failed rounds."""
        rounds_completed = len(history.my_actions)
        if rounds_completed == 0:
            return False
        last_cooperators = self._count_cooperators_last_round(history)
        if last_cooperators >= self.m:
            return False
        cooperation_rate = last_cooperators / self.n
        if cooperation_rate < 0.4:
            return False
        if self.consecutive_failures >= 3:
            return False
        return True

class Strategy_COOPERATIVE_43(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS): Balances collective welfare with 
    strategic protection by adapting cooperation based on group behavior patterns and game phases.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number + 1
        if history is None:
            return Action.C
        if current_round <= min(3, self.r // 4):
            return Action.C
        recent_rounds = min(3, history.round_number)
        if recent_rounds == 0:
            return Action.C
        recent_opponent_actions = history.opponent_actions[-recent_rounds:, :]
        recent_my_actions = history.my_actions[-recent_rounds:]
        total_recent_coop = 0
        for i in range(recent_rounds):
            round_cooperators = sum(recent_opponent_actions[i, :]) + (1 if recent_my_actions[i] else 0)
            total_recent_coop += round_cooperators
        recent_coop_rate = total_recent_coop / (recent_rounds * self.n)
        if current_round > 0.8 * self.r:
            if recent_coop_rate >= self.m / self.n:
                return Action.C
            elif recent_coop_rate >= 0.7 * self.m / self.n:
                return Action.C
            else:
                return Action.D
        if recent_coop_rate < 0.3 * self.m / self.n:
            if current_round % 3 == 1:
                return Action.C
            else:
                return Action.D
        threshold = (self.m - 0.5) / self.n
        if recent_coop_rate >= threshold:
            return Action.C
        if recent_rounds >= 3 and history.round_number >= 3:
            round_1_back_coop = sum(history.opponent_actions[-1, :]) + (1 if history.my_actions[-1] else 0)
            round_3_back_coop = sum(history.opponent_actions[-3, :]) + (1 if history.my_actions[-3] else 0)
            trend = (round_1_back_coop - round_3_back_coop) / self.n
            if trend > 0 and recent_coop_rate >= 0.8 * threshold:
                return Action.C
        return Action.D

class Strategy_COOPERATIVE_44(BaseStrategy):
    """
    Threshold Guardian: An adaptive cooperative strategy that aims to maintain cooperation
    while being robust against exploitation. Adapts based on collective behavior and
    threshold achievement rates.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if current_round == self.r - 1:
            defection_prob = 1.0
            if self.m > self.n / 2:
                defection_prob = 0.7
            if random.random() < defection_prob:
                return Action.D
            else:
                return Action.C
        cooperation_rate = self._calculate_cooperation_rate(history)
        threshold_success_rate = self._calculate_threshold_success_rate(history)
        base_prob = self._get_base_cooperation_probability(cooperation_rate, threshold_success_rate)
        final_prob = self._apply_adaptive_mechanisms(history, base_prob, cooperation_rate)
        final_prob = self._apply_edge_case_adjustments(final_prob)
        return Action.C if random.random() < final_prob else Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate average cooperation rate across all players in previous rounds."""
        total_players = self.n
        total_decisions = 0
        total_cooperations = 0
        for round_idx in range(history.round_number):
            if history.my_actions[round_idx]:
                total_cooperations += 1
            total_decisions += 1
            total_cooperations += sum(history.opponent_actions[round_idx, :])
            total_decisions += len(history.opponent_actions[round_idx, :])
        return total_cooperations / total_decisions if total_decisions > 0 else 0

    def _calculate_threshold_success_rate(self, history: PlayerHistory) -> float:
        """Calculate fraction of rounds where cooperation threshold was met."""
        successful_rounds = 0
        for round_idx in range(history.round_number):
            cooperators = int(history.my_actions[round_idx]) + sum(history.opponent_actions[round_idx, :])
            if cooperators >= self.m:
                successful_rounds += 1
        return successful_rounds / history.round_number if history.round_number > 0 else 0

    def _get_base_cooperation_probability(self, cooperation_rate: float, threshold_success_rate: float) -> float:
        """Determine base cooperation probability based on success and cooperation rates."""
        if threshold_success_rate >= 0.7:
            if cooperation_rate > (self.m + 2) / self.n:
                return 0.8
            else:
                return 1.0
        elif threshold_success_rate >= 0.3:
            if cooperation_rate >= (self.m + 1) / self.n:
                return 1.0
            elif cooperation_rate >= (self.m - 0.5) / self.n:
                return 1.0
            else:
                return 0.6
        elif cooperation_rate >= self.m / self.n:
            return 1.0
        else:
            return 0.4

    def _apply_adaptive_mechanisms(self, history: PlayerHistory, base_prob: float, cooperation_rate: float) -> float:
        """Apply momentum detection, threshold proximity, and free-rider detection."""
        prob = base_prob
        if history.round_number >= 3:
            recent_coop_rates = []
            for i in range(3):
                round_idx = history.round_number - 1 - i
                round_cooperators = int(history.my_actions[round_idx]) + sum(history.opponent_actions[round_idx, :])
                recent_coop_rates.append(round_cooperators / self.n)
            if recent_coop_rates[0] > recent_coop_rates[1] > recent_coop_rates[2]:
                prob += 0.1
            elif recent_coop_rates[0] < recent_coop_rates[1] < recent_coop_rates[2]:
                prob -= 0.1
        if history.round_number > 0:
            last_round_cooperators = int(history.my_actions[-1]) + sum(history.opponent_actions[-1, :])
            if last_round_cooperators == self.m or last_round_cooperators == self.m - 1:
                prob += 0.2
        if history.round_number >= 2:
            consistent_defectors = 0
            threshold_met_count = 0
            for round_idx in range(history.round_number):
                cooperators = int(history.my_actions[round_idx]) + sum(history.opponent_actions[round_idx, :])
                if cooperators >= self.m:
                    threshold_met_count += 1
            if threshold_met_count > history.round_number * 0.5:
                for player_idx in range(len(history.opponent_actions[0, :])):
                    defections = sum((1 - history.opponent_actions[round_idx, player_idx] for round_idx in range(history.round_number)))
                    if defections > history.round_number * 0.7:
                        consistent_defectors += 1
                if consistent_defectors > self.n - self.m + 1:
                    prob -= 0.1
        return max(0.2, min(0.9, prob))

    def _apply_edge_case_adjustments(self, prob: float) -> float:
        """Apply adjustments for small games, high threshold, and high reward scenarios."""
        adjusted_prob = prob
        if self.n <= 4:
            adjusted_prob += 0.2
        if self.m > self.n / 2:
            adjusted_prob += 0.1
        if self.k >= 3:
            adjusted_prob += 0.1
        return max(0.3, min(1.0, adjusted_prob))

class Strategy_COOPERATIVE_45(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperative Strategy (ATCS) - balances cooperative intent 
    with adaptive realism, starting optimistically but learning from collective behavior.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.base_threshold = self.m / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if current_round <= 2:
            return Action.C
        last_3_rounds = min(3, current_round)
        total_cooperators = 0
        for i in range(last_3_rounds):
            round_idx = current_round - 1 - i
            my_coop = int(history.my_actions[round_idx])
            opp_coop = int(np.sum(history.opponent_actions[round_idx, :]))
            total_cooperators += my_coop + opp_coop
        cooperation_rate = total_cooperators / (last_3_rounds * self.n)
        if cooperation_rate >= self.base_threshold * 0.8:
            cooperation_probability = 0.9
        elif cooperation_rate >= self.base_threshold * 0.5:
            cooperation_probability = 0.7
        else:
            cooperation_probability = 0.3
        last_round_cooperators = int(history.my_actions[-1]) + int(np.sum(history.opponent_actions[-1, :]))
        if last_round_cooperators < self.m:
            cooperation_probability = min(1.0, cooperation_probability + 0.2)
        if last_round_cooperators == self.m:
            cooperation_probability = 0.8
        end_game_threshold = math.ceil(0.8 * self.r)
        if current_round >= end_game_threshold:
            rounds_from_end = current_round - end_game_threshold
            cooperation_probability = max(0.1, cooperation_probability - 0.1 * rounds_from_end)
        if current_round == self.r - 1:
            if cooperation_rate > self.base_threshold * 0.9:
                cooperation_probability = 0.8
            else:
                cooperation_probability = 0.2
        if current_round >= 3:
            exploitation_pattern = 0
            for i in range(min(2, current_round)):
                round_idx = current_round - 1 - i
                my_action = history.my_actions[round_idx]
                others_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
                if not my_action and others_cooperators == self.m - 1:
                    exploitation_pattern += 1
            if exploitation_pattern >= 2:
                cooperation_probability = 0.6
        return Action.C if random.random() < cooperation_probability else Action.D

class Strategy_COOPERATIVE_46(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperation Strategy (ATBC).
    Balances cooperative intent with adaptive learning, aiming to achieve collective success
    while protecting against systematic exploitation using dynamic thresholds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.adaptive_threshold = 0.6
        self.revival_mode_rounds = 0
        self.defensive_mode = False
        self.consecutive_failures = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number + 1
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if current_round <= min(5, r // 3):
            return Action.C
        cooperation_rate = self._calculate_weighted_cooperation_rate(history)
        self._update_modes(history)
        expected_cooperators = cooperation_rate * (n - 1) + 1
        success_probability = self._estimate_success_probability(expected_cooperators, m, n)
        threshold = self.adaptive_threshold
        if current_round > 0.8 * r:
            threshold += 0.2
        if self.defensive_mode:
            threshold = max(threshold, 0.8)
        if self.revival_mode_rounds > 0:
            self.revival_mode_rounds -= 1
            return Action.C
        if success_probability >= threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_weighted_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate weighted cooperation rate with exponential decay for recent rounds."""
        if history.round_number == 0:
            return 0.5
        weighted_cooperation = 0.0
        total_weight = 0.0
        for round_idx in range(history.round_number):
            weight = 0.7 ** (history.round_number - 1 - round_idx)
            cooperators_in_round = sum(history.opponent_actions[round_idx, :])
            cooperation_rate_in_round = cooperators_in_round / self.game_description.n_players
            weighted_cooperation += weight * cooperation_rate_in_round
            total_weight += weight
        return weighted_cooperation / total_weight if total_weight > 0 else 0.5

    def _estimate_success_probability(self, expected_cooperators: float, m: int, n: int) -> float:
        """Estimate probability of reaching threshold using normal approximation."""
        if expected_cooperators >= m:
            excess = expected_cooperators - m
            return min(0.95, 0.6 + 0.35 * (excess / (n - m)))
        else:
            deficit = m - expected_cooperators
            return max(0.05, 0.4 - 0.35 * (deficit / m))

    def _update_modes(self, history: PlayerHistory) -> None:
        """Update revival mode and defensive mode based on recent outcomes."""
        if history.round_number == 0:
            return
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        success = last_round_cooperators >= self.game_description.m
        if success:
            self.adaptive_threshold = max(0.4, self.adaptive_threshold - 0.05)
            self.consecutive_failures = 0
            if self.defensive_mode:
                self.adaptive_threshold = max(0.6, self.adaptive_threshold - 0.1)
                if self.adaptive_threshold <= 0.6:
                    self.defensive_mode = False
        else:
            self.adaptive_threshold = min(0.8, self.adaptive_threshold + 0.1)
            self.consecutive_failures += 1
            if self.consecutive_failures >= 3:
                self.defensive_mode = True
        cooperation_rate = self._calculate_weighted_cooperation_rate(history)
        if cooperation_rate < self.game_description.m / self.game_description.n_players:
            if self.revival_mode_rounds == 0:
                self.revival_mode_rounds = 2

class Strategy_COOPERATIVE_47(BaseStrategy):
    """
    Adaptive Threshold Guardian: A cooperative strategy that balances cooperation with strategic robustness.
    Maintains cooperative stance while adapting to opponent behavior patterns, always working toward achieving 
    the minimum threshold m for collective benefit.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.initial_coop_rounds = max(1, math.floor(self.r * 0.2))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = state.round_number
        if round_num < self.initial_coop_rounds:
            return Action.C
        prev_cooperators = sum(history.opponent_actions[-1, :]) + int(history.my_actions[-1])
        if prev_cooperators == self.m or prev_cooperators == self.m + 1:
            return Action.C
        if prev_cooperators > (self.m + self.n) / 2:
            return Action.C
        consistent_cooperators = 0
        for player_idx in range(self.n - 1):
            player_actions = history.opponent_actions[:, player_idx]
            coop_rate = sum(player_actions) / len(player_actions)
            if coop_rate >= 0.6:
                consistent_cooperators += 1
        my_coop_rate = sum(history.my_actions) / len(history.my_actions)
        if my_coop_rate >= 0.6:
            consistent_cooperators += 1
        if consistent_cooperators >= self.m - 1:
            return Action.C
        if round_num == self.r - 1:
            total_cooperators = 0
            total_rounds = len(history.my_actions)
            for round_idx in range(total_rounds):
                round_cooperators = sum(history.opponent_actions[round_idx, :]) + int(history.my_actions[round_idx])
                total_cooperators += round_cooperators
            avg_cooperation_rate = total_cooperators / (total_rounds * self.n)
            if avg_cooperation_rate >= self.m / self.n:
                return Action.C
        if prev_cooperators == self.m - 1:
            return Action.C
        return Action.D

class Strategy_COOPERATIVE_48(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS)
    
    Balances cooperative intent with adaptive learning, aiming to achieve collective success
    while protecting against exploitation. Uses dynamic cooperation probability based on
    observed cooperation rates with safety mechanisms against exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.exploitation_protection_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = history.round_number + 1
        if round_num <= 3:
            return Action.C
        recent_coop_rate = self._calculate_recent_cooperation_rate(history, 2)
        historical_coop_rate = self._calculate_historical_cooperation_rate(history)
        weighted_coop_rate = 0.7 * recent_coop_rate + 0.3 * historical_coop_rate
        expected_cooperators = weighted_coop_rate * self.n
        if self._check_exploitation_protection(history):
            if recent_coop_rate >= 0.8 * (self.m / self.n):
                return Action.C
            else:
                return Action.D
        if round_num == self.r:
            if weighted_coop_rate >= self.m / self.n + 0.1:
                return Action.C
            else:
                return Action.D
        if expected_cooperators >= self.m - 1:
            return Action.C
        elif expected_cooperators < self.m - 2:
            return Action.D
        else:
            probability = expected_cooperators - (self.m - 2)
            if random.random() < probability:
                return Action.C
            else:
                return Action.D

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory, rounds_back: int) -> float:
        """Calculate cooperation rate over the last 'rounds_back' rounds."""
        total_rounds = len(history.my_actions)
        start_idx = max(0, total_rounds - rounds_back)
        if start_idx >= total_rounds:
            return 0.0
        my_cooperations = sum(history.my_actions[start_idx:])
        opponent_cooperations = np.sum(history.opponent_actions[start_idx:, :])
        total_cooperations = my_cooperations + opponent_cooperations
        total_possible = (total_rounds - start_idx) * self.n
        if total_possible == 0:
            return 0.0
        return total_cooperations / total_possible

    def _calculate_historical_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate overall cooperation rate from the beginning."""
        total_rounds = len(history.my_actions)
        if total_rounds == 0:
            return 0.0
        my_cooperations = sum(history.my_actions)
        opponent_cooperations = np.sum(history.opponent_actions)
        total_cooperations = my_cooperations + opponent_cooperations
        total_possible = total_rounds * self.n
        return total_cooperations / total_possible

    def _check_exploitation_protection(self, history: PlayerHistory) -> bool:
        """Check if we should enter exploitation protection mode."""
        total_rounds = len(history.my_actions)
        if total_rounds < 3:
            return False
        threshold = 0.3 * (self.m / self.n)
        consecutive_low_rounds = 0
        for i in range(max(0, total_rounds - 3), total_rounds):
            my_coop = 1 if history.my_actions[i] else 0
            opponent_coop = np.sum(history.opponent_actions[i, :])
            round_coop_rate = (my_coop + opponent_coop) / self.n
            if round_coop_rate < threshold:
                consecutive_low_rounds += 1
            else:
                consecutive_low_rounds = 0
        return consecutive_low_rounds >= 3

class Strategy_COOPERATIVE_49(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperative Strategy (ATCS)
    
    Balances cooperative intent with adaptive learning, starting optimistically
    but learning from group dynamics. Uses multiple conditions for cooperation
    including momentum, recovery, trend analysis, and strategic necessity.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if state.round_number == r - 1:
            return self._endgame_decision(history, n, m)
        last_round_coop = self._count_cooperators_in_round(history, -1)
        avg_coop_rate = self._calculate_average_cooperation_rate(history)
        recovery_threshold = 0.4
        if n <= 4:
            recovery_threshold = 0.5
        if m > n / 2:
            recovery_threshold -= 0.1
        if last_round_coop >= m:
            return Action.C
        if last_round_coop >= m - 1 and avg_coop_rate >= recovery_threshold:
            return Action.C
        if self._shows_increasing_trend(history, 2):
            return Action.C
        if self._strategic_necessity_met(history, n, m):
            return Action.C
        if self._check_exploitation_protection(history):
            return Action.D
        return Action.D

    def _endgame_decision(self, history: PlayerHistory, n: int, m: int) -> Action:
        """Final round weighted decision"""
        last_round_coop = self._count_cooperators_in_round(history, -1)
        avg_coop_rate = self._calculate_average_cooperation_rate(history)
        primary_score = 0.7 if last_round_coop / n >= m / n else 0
        secondary_score = 0.3 if avg_coop_rate >= 0.5 else 0
        total_score = primary_score + secondary_score
        return Action.C if total_score > 0.35 else Action.D

    def _count_cooperators_in_round(self, history: PlayerHistory, round_idx: int) -> int:
        """Count total cooperators (including self) in a specific round"""
        if abs(round_idx) > len(history.my_actions):
            return 0
        my_action = 1 if history.my_actions[round_idx] else 0
        opponent_actions = history.opponent_actions[round_idx, :]
        return my_action + int(np.sum(opponent_actions))

    def _calculate_average_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate average cooperation rate across all players and rounds"""
        if len(history.my_actions) == 0:
            return 0.0
        n = self.game_description.n_players
        total_cooperations = 0
        total_decisions = 0
        r = self.game_description.n_rounds
        if r <= 5:
            recent_weight = 0.6 / min(2, len(history.my_actions))
            older_weight = 0.4 / max(1, len(history.my_actions) - 2)
            for i in range(len(history.my_actions)):
                round_coops = self._count_cooperators_in_round(history, i)
                weight = recent_weight if i >= len(history.my_actions) - 2 else older_weight
                total_cooperations += round_coops * weight
                total_decisions += n * weight
        else:
            for i in range(len(history.my_actions)):
                total_cooperations += self._count_cooperators_in_round(history, i)
                total_decisions += n
        return total_cooperations / total_decisions if total_decisions > 0 else 0.0

    def _shows_increasing_trend(self, history: PlayerHistory, lookback: int) -> bool:
        """Check if cooperation count has been increasing over last 'lookback' rounds"""
        if len(history.my_actions) < lookback:
            return False
        counts = []
        for i in range(lookback):
            round_idx = -(lookback - i)
            counts.append(self._count_cooperators_in_round(history, round_idx))
        for i in range(1, len(counts)):
            if counts[i] <= counts[i - 1]:
                return False
        return True

    def _strategic_necessity_met(self, history: PlayerHistory, n: int, m: int) -> bool:
        """Check if my cooperation plus optimistic estimate of others could reach threshold"""
        if len(history.my_actions) == 0:
            return False
        last_round_actions = history.opponent_actions[-1, :]
        expected_cooperators = 0
        for i in range(len(last_round_actions)):
            if last_round_actions[i]:
                expected_cooperators += 0.8
            else:
                expected_cooperators += 0.2
        expected_total = expected_cooperators + 1
        return expected_total >= m

    def _check_exploitation_protection(self, history: PlayerHistory) -> bool:
        """Check if we should protect against exploitation"""
        if len(history.my_actions) < 3:
            return False
        low_coop_count = 0
        n = self.game_description.n_players
        for i in range(3):
            round_idx = -(3 - i)
            coop_rate = self._count_cooperators_in_round(history, round_idx) / n
            if coop_rate < 0.2:
                low_coop_count += 1
        return low_coop_count >= 3

class Strategy_COOPERATIVE_50(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperative Strategy (ATCS)
    
    This strategy balances cooperative intent with adaptive response to observed behaviors.
    It uses conditional cooperation based on threshold awareness and includes forgiveness
    mechanisms to encourage cooperation revival while protecting against exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.initial_cooperation_phase = min(5, max(1, self.r // 3))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        rounds_played = history.round_number
        if current_round < self.initial_cooperation_phase:
            return Action.C
        cooperation_rate = self._get_last_round_cooperation_rate(history)
        recent_success_rate = self._get_recent_success_rate(history)
        threshold_rate = (self.m - 1) / self.n
        if cooperation_rate >= threshold_rate:
            return Action.C
        forgiveness_threshold = max(0, (self.m - 2) / self.n)
        if recent_success_rate >= 0.5 and cooperation_rate >= forgiveness_threshold:
            return Action.C
        if current_round > 0.8 * self.r:
            last_chance_threshold = max(0, (self.m - 1.5) / self.n)
            if cooperation_rate >= last_chance_threshold:
                return Action.C
        failed_rounds_last_3 = self._get_failed_rounds_last_3(history)
        if failed_rounds_last_3 >= 2:
            if random.random() < 0.3:
                return Action.C
            else:
                return Action.D
        if self.n <= 4:
            adjusted_threshold = max(0, threshold_rate - 0.2)
            if cooperation_rate >= adjusted_threshold:
                return Action.C
        return Action.D

    def _get_last_round_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate in the most recent round"""
        if len(history.opponent_actions) == 0:
            return 0.0
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        return last_round_cooperators / self.n

    def _get_recent_success_rate(self, history: PlayerHistory) -> float:
        """Calculate success rate over last 3 rounds"""
        rounds_to_check = min(3, len(history.my_payoffs))
        if rounds_to_check == 0:
            return 0.0
        successful_rounds = 0
        for i in range(1, rounds_to_check + 1):
            round_idx = -i
            my_action = history.my_actions[round_idx]
            my_payoff = history.my_payoffs[round_idx]
            expected_base = 1 - int(my_action)
            if my_payoff > expected_base:
                successful_rounds += 1
        return successful_rounds / rounds_to_check

    def _get_failed_rounds_last_3(self, history: PlayerHistory) -> int:
        """Count failed rounds in last 3 rounds"""
        rounds_to_check = min(3, len(history.my_payoffs))
        if rounds_to_check == 0:
            return 0
        failed_rounds = 0
        for i in range(1, rounds_to_check + 1):
            round_idx = -i
            my_action = history.my_actions[round_idx]
            my_payoff = history.my_payoffs[round_idx]
            expected_base = 1 - int(my_action)
            if my_payoff <= expected_base:
                failed_rounds += 1
        return failed_rounds

class Strategy_COOPERATIVE_51(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperation Strategy (ATCS)
    
    Balances cooperation with adaptive learning, aiming to achieve the collective 
    threshold while protecting against consistent defectors. Emphasizes building 
    cooperative momentum early while maintaining flexibility to respond to changing 
    group dynamics.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.consecutive_defections = 0
            return Action.C
        current_round = history.round_number + 1
        if current_round == self.r:
            prev_cooperators = sum(history.opponent_actions[-1, :])
            if history.my_actions[-1]:
                prev_cooperators += 1
            prev_cooperation_rate = prev_cooperators / self.n
            threshold_rate = (self.m - 1) / self.n
            if prev_cooperation_rate >= threshold_rate:
                return Action.C
            else:
                return Action.D
        prev_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            prev_cooperators += 1
        cooperation_rate = prev_cooperators / self.n
        trend_score = self._calculate_trend_score(history)
        if len(history.my_actions) >= 2:
            prev_trend_score = self._calculate_trend_score(history, offset=1)
            momentum_increasing = trend_score > prev_trend_score
        else:
            momentum_increasing = True
        threshold_rate = self.m / self.n
        high_confidence_threshold = threshold_rate + 0.1
        low_confidence_threshold = threshold_rate - 0.1
        if self.n <= 4:
            high_confidence_threshold = threshold_rate + 0.05
            low_confidence_threshold = threshold_rate - 0.05
        if cooperation_rate >= high_confidence_threshold:
            i_cooperated_last = history.my_actions[-1]
            if i_cooperated_last or momentum_increasing:
                action = Action.C
            elif self.consecutive_defections < 3:
                action = Action.D
            else:
                action = Action.C
        elif cooperation_rate >= low_confidence_threshold:
            action = Action.C
        elif momentum_increasing and self.consecutive_defections <= 2:
            action = Action.C
        elif self.consecutive_defections < 3:
            action = Action.D
        else:
            action = Action.C
        if threshold_rate > 0.7:
            if action == Action.D and self.consecutive_defections >= 4:
                action = Action.C
        if action == Action.D:
            self.consecutive_defections += 1
        else:
            self.consecutive_defections = 0
        return action

    def _calculate_trend_score(self, history, offset=0):
        """Calculate weighted average cooperation rate over recent rounds"""
        rounds_completed = len(history.my_actions)
        if rounds_completed - offset <= 0:
            return 0.0
        cooperation_rates = []
        for i in range(min(3, rounds_completed - offset)):
            round_idx = rounds_completed - 1 - offset - i
            if round_idx >= 0:
                cooperators = sum(history.opponent_actions[round_idx, :])
                if history.my_actions[round_idx]:
                    cooperators += 1
                rate = cooperators / self.n
                cooperation_rates.append(rate)
        if not cooperation_rates:
            return 0.0
        weights = [0.5, 0.3, 0.2]
        weighted_sum = 0.0
        weight_sum = 0.0
        for i, rate in enumerate(cooperation_rates):
            weight = weights[i] if i < len(weights) else 0.1
            weighted_sum += rate * weight
            weight_sum += weight
        return weighted_sum / weight_sum if weight_sum > 0 else 0.0

class Strategy_COOPERATIVE_52(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperative Strategy (ATCS)
    
    A fundamentally cooperative strategy that aims to achieve collective benefit while being
    robust against exploitation. Adapts to group behavior patterns and maintains cooperation
    when feasible, with defensive mechanisms against persistent defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if current_round == self.r - 1:
            return self._final_round_logic(history)
        recent_rounds = min(3, history.round_number)
        recent_cooperators = 0
        total_possible = 0
        for i in range(max(0, history.round_number - recent_rounds), history.round_number):
            round_cooperators = sum(history.opponent_actions[i, :])
            if history.my_actions[i]:
                round_cooperators += 1
            recent_cooperators += round_cooperators
            total_possible += self.n
        cooperation_rate = recent_cooperators / total_possible if total_possible > 0 else 0
        adjusted_threshold = self.m + max(0, (self.n - self.m) * (0.5 - cooperation_rate))
        expected_cooperators = recent_cooperators / recent_rounds if recent_rounds > 0 else 0
        if expected_cooperators >= adjusted_threshold:
            return Action.C
        if self._is_trend_improving(history) and cooperation_rate > 0.3:
            return Action.C
        if history.round_number > 0:
            last_round_cooperators = sum(history.opponent_actions[-1, :])
            if last_round_cooperators == self.m - 1:
                return Action.C
        return self._defensive_logic(history, cooperation_rate)

    def _final_round_logic(self, history: PlayerHistory) -> Action:
        """Handle final round decision making"""
        recent_rounds = min(3, history.round_number)
        success_count = 0
        for i in range(max(0, history.round_number - recent_rounds), history.round_number):
            round_cooperators = sum(history.opponent_actions[i, :])
            if history.my_actions[i]:
                round_cooperators += 1
            if round_cooperators >= self.m:
                success_count += 1
        success_rate = success_count / recent_rounds if recent_rounds > 0 else 0
        if success_rate > 0.7:
            return Action.C
        if history.round_number > 0:
            last_round_cooperators = sum(history.opponent_actions[-1, :])
            if last_round_cooperators >= self.m - 1:
                return Action.C
        if self.n <= 4:
            return Action.C
        return Action.D

    def _is_trend_improving(self, history: PlayerHistory) -> bool:
        """Check if cooperation trend is improving"""
        if history.round_number < 2:
            return False
        last_round_coop = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_coop += 1
        prev_round_coop = sum(history.opponent_actions[-2, :])
        if history.my_actions[-2]:
            prev_round_coop += 1
        return last_round_coop > prev_round_coop

    def _defensive_logic(self, history: PlayerHistory, cooperation_rate: float) -> Action:
        """Apply defensive logic with forgiveness mechanisms"""
        if history.round_number >= 2:
            recent_rates = []
            for i in range(max(0, history.round_number - 2), history.round_number):
                round_cooperators = sum(history.opponent_actions[i, :])
                if history.my_actions[i]:
                    round_cooperators += 1
                recent_rates.append(round_cooperators / self.n)
            if len(recent_rates) >= 2 and all((rate > 0.6 for rate in recent_rates)):
                return Action.C
        if self.m > self.n / 2:
            recent_attempts = 0
            for i in range(max(0, history.round_number - 2), history.round_number):
                round_cooperators = sum(history.opponent_actions[i, :])
                if history.my_actions[i]:
                    round_cooperators += 1
                if round_cooperators >= self.m * 0.8:
                    recent_attempts += 1
            if recent_attempts >= 1:
                return Action.C
        if self.n <= 4 and cooperation_rate > 0.25:
            return Action.C
        if self.k <= 1.5:
            if cooperation_rate < 0.4:
                return Action.D
        return Action.D

class Strategy_COOPERATIVE_53(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS)
    
    Balances cooperative intent with adaptive learning. Starts with strong cooperation
    to establish trust, then adapts based on group cooperation patterns while maintaining
    a pro-cooperation bias. Increases cooperation attempts in endgame.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.initial_phase_end = max(1, math.floor(self.r / 4))
        self.endgame_start = max(self.initial_phase_end + 1, self.r - math.floor(self.r / 8))
        if self.n <= 4:
            self.initial_phase_end = max(1, math.floor(self.r / 3))
            self.base_threshold_adjustment = -0.2
            self.observation_window = 3
        elif self.n > 10:
            self.base_threshold_adjustment = 0.0
            self.observation_window = 2
        else:
            self.base_threshold_adjustment = -0.1
            self.observation_window = 3
        if self.m / self.n > 0.8:
            self.initial_phase_end = max(1, math.floor(self.r / 2))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if history is None:
            return Action.C
        if current_round < self.initial_phase_end:
            return Action.C
        rounds_completed = history.round_number
        observation_rounds = min(self.observation_window, rounds_completed)
        recent_opponent_actions = history.opponent_actions[-observation_rounds:, :]
        recent_my_actions = history.my_actions[-observation_rounds:]
        total_cooperators = 0
        total_possible = observation_rounds * self.n
        for round_idx in range(observation_rounds):
            round_cooperators = np.sum(recent_opponent_actions[round_idx, :])
            if recent_my_actions[round_idx]:
                round_cooperators += 1
            total_cooperators += round_cooperators
        cooperation_rate = total_cooperators / total_possible if total_possible > 0 else 0
        base_threshold = max(0.6, self.m / self.n + self.base_threshold_adjustment)
        if current_round >= self.endgame_start:
            rounds_remaining = self.r - current_round
            endgame_boost = min(0.3, rounds_remaining / (self.r / 4))
            cooperation_threshold = base_threshold - endgame_boost
        else:
            cooperation_threshold = base_threshold
        if rounds_completed > 0:
            last_round_cooperators = np.sum(history.opponent_actions[-1, :])
            if history.my_actions[-1]:
                last_round_cooperators += 1
            if last_round_cooperators < self.m:
                cooperation_threshold -= 0.1
        if current_round == self.r - 1:
            successful_rounds = 0
            for round_idx in range(rounds_completed):
                round_cooperators = np.sum(history.opponent_actions[round_idx, :])
                if history.my_actions[round_idx]:
                    round_cooperators += 1
                if round_cooperators >= self.m:
                    successful_rounds += 1
            historical_success_rate = successful_rounds / rounds_completed if rounds_completed > 0 else 0
            if historical_success_rate > 0.5:
                return Action.C
        if current_round >= self.r - 3:
            successful_rounds = 0
            for round_idx in range(rounds_completed):
                round_cooperators = np.sum(history.opponent_actions[round_idx, :])
                if history.my_actions[round_idx]:
                    round_cooperators += 1
                if round_cooperators >= self.m:
                    successful_rounds += 1
            historical_success_rate = successful_rounds / rounds_completed if rounds_completed > 0 else 0
            if historical_success_rate < 0.3:
                if rounds_completed > 0:
                    last_round_cooperators = np.sum(history.opponent_actions[-1, :])
                    if last_round_cooperators >= self.m - 1:
                        return Action.C
                    else:
                        return Action.D
        if cooperation_rate >= cooperation_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_54(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperative Strategy (ATCS)
    
    Balances collective welfare with exploitation protection by adapting to group dynamics.
    Starts optimistically, then uses momentum tracking and threshold awareness to decide
    when cooperation is viable versus when to protect against free-riders.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number + 1
        if current_round == self.r:
            return self._final_round_decision(history)
        else:
            return self._adaptive_decision(history)

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """Strategic decision for the final round"""
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        if last_round_cooperators >= self.m - 1:
            return Action.C
        rounds_to_check = min(3, len(history.my_actions))
        total_cooperations = 0
        total_possible = 0
        for i in range(rounds_to_check):
            round_idx = -(i + 1)
            round_cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                round_cooperators += 1
            total_cooperations += round_cooperators
            total_possible += self.n
        avg_cooperation_rate = total_cooperations / total_possible if total_possible > 0 else 0
        threshold_rate = self.m / self.n
        if avg_cooperation_rate >= threshold_rate:
            return Action.C
        else:
            return Action.D

    def _adaptive_decision(self, history: PlayerHistory) -> Action:
        """Adaptive decision based on momentum and threshold viability"""
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        cooperation_rate = last_round_cooperators / self.n
        if len(history.my_actions) >= 2:
            prev_round_cooperators = sum(history.opponent_actions[-2, :])
            if history.my_actions[-2]:
                prev_round_cooperators += 1
            previous_cooperation_rate = prev_round_cooperators / self.n
            recent_trend = cooperation_rate - previous_cooperation_rate
        else:
            recent_trend = 0
        momentum = cooperation_rate + 0.5 * recent_trend
        threshold_viable = last_round_cooperators >= self.m - 1
        momentum_threshold = 0.3
        high_cooperation_threshold = self.m / self.n + 0.1
        positive_trend_threshold = 0.2
        if self.n <= 4:
            momentum_threshold -= 0.1
        if self.m > self.n / 2:
            positive_trend_threshold = 0.15
        if self.k <= 1.5:
            momentum_threshold = 0.4
        if threshold_viable and momentum >= momentum_threshold:
            return Action.C
        elif cooperation_rate >= high_cooperation_threshold:
            return Action.C
        elif momentum > positive_trend_threshold and last_round_cooperators >= self.m / 2:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_55(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS)
    
    Balances cooperative intent with strategic adaptation, using dynamic cooperation
    threshold based on weighted historical cooperation rates with momentum adjustments
    and anti-exploitation protection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.cooperation_history = []
        self.threshold_met_history = []
        self.personal_cooperation_count = 0
        self.consecutive_successes = 0
        self.consecutive_failures = 0
        self.last_recovery_round = -10
        self.defensive_posture = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if history is None:
            return self._first_round_decision()
        self._update_histories(history)
        if self._should_attempt_recovery(current_round):
            return Action.C
        cooperation_rate = self._calculate_weighted_cooperation_rate()
        cooperation_rate = self._apply_momentum_adjustment(cooperation_rate)
        estimated_cooperators = math.floor(cooperation_rate * (self.n - 1))
        threshold = self._determine_threshold(current_round)
        if estimated_cooperators + 1 >= threshold:
            return Action.C
        else:
            return Action.D

    def _first_round_decision(self):
        """First round decision rule"""
        if self.m <= self.n // 2:
            return Action.C
        elif self.m > 2 * self.n // 3:
            return Action.D
        else:
            return Action.C

    def _update_histories(self, history: PlayerHistory):
        """Update cooperation and threshold achievement histories"""
        last_round_idx = len(history.my_actions) - 1
        my_last_action = history.my_actions[last_round_idx]
        opponent_cooperators = sum(history.opponent_actions[last_round_idx, :])
        total_cooperators = int(my_last_action) + opponent_cooperators
        cooperation_rate = opponent_cooperators / (self.n - 1)
        self.cooperation_history.append(cooperation_rate)
        threshold_met = total_cooperators >= self.m
        self.threshold_met_history.append(threshold_met)
        if threshold_met:
            self.consecutive_successes += 1
            self.consecutive_failures = 0
        else:
            self.consecutive_failures += 1
            self.consecutive_successes = 0
        if my_last_action:
            self.personal_cooperation_count += 1
        self._update_defensive_posture(history)

    def _calculate_weighted_cooperation_rate(self):
        """Calculate weighted historical cooperation rate with α = 0.7"""
        if not self.cooperation_history:
            return 0.5
        alpha = 0.7
        recent_rate = self.cooperation_history[-1] if self.cooperation_history else 0.5
        if len(self.cooperation_history) == 1:
            return recent_rate
        historical_rate = np.mean(self.cooperation_history[:-1])
        return alpha * recent_rate + (1 - alpha) * historical_rate

    def _apply_momentum_adjustment(self, cooperation_rate):
        """Apply momentum adjustment based on recent trends"""
        if len(self.cooperation_history) < 3:
            return cooperation_rate
        recent_rates = self.cooperation_history[-3:]
        if len(recent_rates) >= 3:
            trend_up = recent_rates[-1] > recent_rates[-2] > recent_rates[-3]
            trend_down = recent_rates[-1] < recent_rates[-2] < recent_rates[-3]
            if trend_up:
                cooperation_rate += 0.1
            elif trend_down:
                cooperation_rate -= 0.1
        return max(0.0, min(1.0, cooperation_rate))

    def _determine_threshold(self, current_round):
        """Determine cooperation threshold based on current conditions"""
        base_threshold = self.m
        if self._is_early_round(current_round):
            base_threshold = max(1, self.m - 1)
        if self.consecutive_successes >= 3:
            base_threshold = max(1, base_threshold - 0.5)
        elif self.consecutive_failures >= 2:
            base_threshold += 0.5
        if self.defensive_posture:
            base_threshold = self.m + 1
        return base_threshold

    def _is_early_round(self, current_round):
        """Check if current round is considered early"""
        return current_round < min(5, self.r // 4)

    def _update_defensive_posture(self, history: PlayerHistory):
        """Update defensive posture based on exploitation detection"""
        total_rounds = len(history.my_actions)
        if total_rounds < 5:
            return
        personal_coop_rate = self.personal_cooperation_count / total_rounds
        threshold_achievement_rate = sum(self.threshold_met_history) / len(self.threshold_met_history)
        if personal_coop_rate > 0.8 and threshold_achievement_rate < 0.3:
            self.defensive_posture = True
        elif threshold_achievement_rate > 0.5:
            self.defensive_posture = False

    def _should_attempt_recovery(self, current_round):
        """Determine if we should attempt recovery mechanism"""
        if len(self.threshold_met_history) < 5:
            return False
        min_gap = max(5, self.r // 4)
        if current_round - self.last_recovery_round < min_gap:
            return False
        recent_performance = self.threshold_met_history[-5:]
        success_rate = sum(recent_performance) / len(recent_performance)
        if success_rate < 0.3:
            self.last_recovery_round = current_round
            return True
        return False

class Strategy_COOPERATIVE_56(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperative Strategy (ATCS)
    
    This strategy balances cooperation and self-interest by adaptively responding to
    group cooperation patterns. It starts cooperative, then uses recent trends and
    success rates to decide when to cooperate vs free-ride, with built-in mechanisms
    to prevent group breakdown and handle various game parameters.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number
        if current_round < 3:
            return Action.C
        cooperation_rate = self._calculate_cooperation_rate(history)
        recent_cooperation_trend = self._calculate_recent_cooperation_trend(history)
        success_rate = self._calculate_success_rate(history)
        remaining_rounds = self.r - current_round
        if remaining_rounds <= 1:
            return Action.D
        if self._should_use_emergency_cooperation(history):
            return Action.C
        adjusted_m = self._get_adjusted_threshold(remaining_rounds)
        if recent_cooperation_trend >= adjusted_m - 1:
            if success_rate > 0.7 and remaining_rounds > 3:
                return Action.C
            elif self.k <= 1.5 and success_rate < 0.8:
                return Action.D
            elif self.k > 1.5:
                return Action.D
            else:
                return Action.C
        elif recent_cooperation_trend >= adjusted_m - 2:
            return Action.C
        elif recent_cooperation_trend < adjusted_m - 2 and success_rate < 0.3:
            if self._is_cooperation_increasing(history):
                return Action.C
            else:
                return Action.D
        elif current_round <= self.r // 2 or success_rate > 0.5:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate average number of cooperators across all previous rounds"""
        total_cooperators = 0
        rounds_completed = history.round_number
        for round_idx in range(rounds_completed):
            if history.my_actions[round_idx]:
                total_cooperators += 1
            total_cooperators += sum(history.opponent_actions[round_idx, :])
        return total_cooperators / (rounds_completed * self.n)

    def _calculate_recent_cooperation_trend(self, history: PlayerHistory) -> float:
        """Calculate weighted average of cooperators in last 3 rounds"""
        rounds_completed = history.round_number
        weights = [0.5, 0.3, 0.2]
        total_weighted_cooperators = 0
        total_weight = 0
        for i, weight in enumerate(weights):
            round_idx = rounds_completed - 1 - i
            if round_idx >= 0:
                cooperators = 0
                if history.my_actions[round_idx]:
                    cooperators += 1
                cooperators += sum(history.opponent_actions[round_idx, :])
                total_weighted_cooperators += weight * cooperators
                total_weight += weight
        if total_weight > 0:
            return total_weighted_cooperators / total_weight
        else:
            return 0

    def _calculate_success_rate(self, history: PlayerHistory) -> float:
        """Calculate proportion of previous rounds where threshold m was met"""
        rounds_completed = history.round_number
        successful_rounds = 0
        for round_idx in range(rounds_completed):
            cooperators = 0
            if history.my_actions[round_idx]:
                cooperators += 1
            cooperators += sum(history.opponent_actions[round_idx, :])
            if cooperators >= self.m:
                successful_rounds += 1
        return successful_rounds / rounds_completed if rounds_completed > 0 else 0

    def _should_use_emergency_cooperation(self, history: PlayerHistory) -> bool:
        """Check if emergency cooperation mode should be activated"""
        rounds_completed = history.round_number
        remaining_rounds = self.r - rounds_completed
        if rounds_completed < 3 or remaining_rounds <= self.r // 4:
            return False
        consecutive_failures = 0
        for i in range(3):
            round_idx = rounds_completed - 1 - i
            cooperators = 0
            if history.my_actions[round_idx]:
                cooperators += 1
            cooperators += sum(history.opponent_actions[round_idx, :])
            if cooperators < self.m:
                consecutive_failures += 1
            else:
                break
        return consecutive_failures >= 3

    def _get_adjusted_threshold(self, remaining_rounds: int) -> int:
        """Get threshold adjusted for end-game and parameter-specific conditions"""
        adjusted_m = self.m
        if remaining_rounds <= self.r * 0.2:
            adjusted_m = max(1, adjusted_m - 1)
        if self.n <= 4:
            adjusted_m = max(1, adjusted_m - 0.5)
        if self.m > self.n // 2:
            pass
        return int(adjusted_m)

    def _is_cooperation_increasing(self, history: PlayerHistory) -> bool:
        """Check if cooperation has been increasing over the last 3 rounds"""
        rounds_completed = history.round_number
        if rounds_completed < 3:
            return True
        cooperators_by_round = []
        for i in range(min(3, rounds_completed)):
            round_idx = rounds_completed - 1 - i
            cooperators = 0
            if history.my_actions[round_idx]:
                cooperators += 1
            cooperators += sum(history.opponent_actions[round_idx, :])
            cooperators_by_round.append(cooperators)
        if len(cooperators_by_round) >= 2:
            return cooperators_by_round[0] > cooperators_by_round[-1]
        return True

class Strategy_COOPERATIVE_57(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperation Strategy (ATCS)
    
    Balances cooperative intent with strategic adaptation, aiming to achieve and maintain
    the cooperation threshold while protecting against exploitation. Uses dynamic cooperation
    probability based on recent group behavior and game phase.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if current_round <= min(3, self.r // 3):
            return Action.C
        recent_rounds = min(3, len(history.my_actions))
        recent_cooperators = 0
        for i in range(1, recent_rounds + 1):
            round_idx = -i
            my_coop = 1 if history.my_actions[round_idx] else 0
            opp_coop = sum(history.opponent_actions[round_idx, :])
            recent_cooperators += my_coop + opp_coop
        recent_cooperation_rate = recent_cooperators / (recent_rounds * self.n)
        target_rate = self.m / self.n
        cooperation_deficit = max(0, target_rate - recent_cooperation_rate)
        base_cooperation_prob = 0.7 + cooperation_deficit
        if len(history.my_actions) > 0:
            last_round_my_coop = 1 if history.my_actions[-1] else 0
            last_round_opp_coop = sum(history.opponent_actions[-1, :])
            last_round_cooperators = last_round_my_coop + last_round_opp_coop
            if last_round_cooperators == self.m - 1 or last_round_cooperators == self.m:
                return Action.C
        if recent_cooperation_rate < (self.m - 1) / self.n:
            return Action.C
        momentum_adjustment = 0
        if len(history.my_actions) > 0:
            last_round_my_coop = 1 if history.my_actions[-1] else 0
            last_round_opp_coop = sum(history.opponent_actions[-1, :])
            last_round_cooperators = last_round_my_coop + last_round_opp_coop
            if last_round_cooperators >= self.m:
                momentum_adjustment = 0.2
            else:
                momentum_adjustment = -0.1
        final_prob = base_cooperation_prob + momentum_adjustment
        if current_round > 0.8 * self.r:
            success_rounds = 0
            check_rounds = min(5, len(history.my_actions))
            for i in range(1, check_rounds + 1):
                round_idx = -i
                my_coop = 1 if history.my_actions[round_idx] else 0
                opp_coop = sum(history.opponent_actions[round_idx, :])
                total_coop = my_coop + opp_coop
                if total_coop >= self.m:
                    success_rounds += 1
            success_rate = success_rounds / check_rounds if check_rounds > 0 else 0
            if success_rate > 0.7:
                pass
            else:
                rounds_in_endgame = current_round - int(0.8 * self.r)
                final_prob -= 0.1 * rounds_in_endgame
        if len(history.my_actions) >= 3:
            consecutive_misses = 0
            consecutive_hits = 0
            for i in range(1, min(4, len(history.my_actions) + 1)):
                round_idx = -i
                my_coop = 1 if history.my_actions[round_idx] else 0
                opp_coop = sum(history.opponent_actions[round_idx, :])
                total_coop = my_coop + opp_coop
                if total_coop >= self.m:
                    consecutive_hits += 1
                    consecutive_misses = 0
                    break
                else:
                    consecutive_misses += 1
                    consecutive_hits = 0
            if consecutive_misses >= 3:
                final_prob = 0.4
            elif consecutive_hits >= 5:
                final_prob = max(final_prob, 0.8)
        final_prob = max(0, min(1, final_prob))
        return Action.C if random.random() < final_prob else Action.D

class Strategy_COOPERATIVE_58(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperation Strategy (ATCS)
    
    Balances cooperative intent with adaptive learning, aiming to achieve collective 
    success while protecting against exploitation. Dynamically adjusts cooperation 
    based on observed group behavior and game parameters.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.trust_score = 0.5
        self.recent_success_history = []
        self.recent_cooperator_counts = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if current_round <= 2:
            return Action.C
        if current_round == self.r - 1:
            return self._endgame_decision(history)
        cooperation_probability = self._calculate_cooperation_probability(history)
        return Action.C if random.random() < cooperation_probability else Action.D

    def _calculate_cooperation_probability(self, history: PlayerHistory) -> float:
        safety_buffer = math.ceil(self.n * 0.1)
        base_probability = min(1.0, (self.m + safety_buffer) / self.n)
        recent_success_rate = self._get_recent_success_rate(history)
        if recent_success_rate > 0.7:
            adjustment = 0.2
        elif recent_success_rate < 0.3:
            adjustment = -0.2
        else:
            adjustment = 0
        recent_avg_cooperators = self._get_recent_avg_cooperators(history)
        momentum = (recent_avg_cooperators - self.m) / self.n
        momentum_bonus = max(0, momentum * 0.1)
        trust_penalty = self._calculate_trust_penalty()
        final_probability = base_probability + adjustment + momentum_bonus - trust_penalty
        return max(0.1, min(0.95, final_probability))

    def _get_recent_success_rate(self, history: PlayerHistory) -> float:
        """Calculate success rate over recent rounds (up to last 5)"""
        if len(history.my_actions) == 0:
            return 0.5
        lookback = min(5, len(history.my_actions))
        recent_rounds = range(max(0, len(history.my_actions) - lookback), len(history.my_actions))
        successful_rounds = 0
        total_rounds = 0
        for round_idx in recent_rounds:
            cooperators = int(history.my_actions[round_idx])
            cooperators += int(np.sum(history.opponent_actions[round_idx, :]))
            if cooperators >= self.m:
                successful_rounds += 1
            total_rounds += 1
        return successful_rounds / total_rounds if total_rounds > 0 else 0.5

    def _get_recent_avg_cooperators(self, history: PlayerHistory) -> float:
        """Get average number of cooperators in recent rounds"""
        if len(history.my_actions) == 0:
            return self.m
        lookback = min(3, len(history.my_actions))
        recent_rounds = range(max(0, len(history.my_actions) - lookback), len(history.my_actions))
        total_cooperators = 0
        round_count = 0
        for round_idx in recent_rounds:
            cooperators = int(history.my_actions[round_idx])
            cooperators += int(np.sum(history.opponent_actions[round_idx, :]))
            total_cooperators += cooperators
            round_count += 1
        return total_cooperators / round_count if round_count > 0 else self.m

    def _calculate_trust_penalty(self) -> float:
        """Calculate penalty based on trust degradation"""
        return max(0, (0.5 - self.trust_score) * 0.3)

    def _update_trust(self, history: PlayerHistory):
        """Update trust score based on recent outcomes"""
        if len(history.my_actions) == 0:
            return
        last_round_idx = len(history.my_actions) - 1
        cooperators = int(history.my_actions[last_round_idx])
        cooperators += int(np.sum(history.opponent_actions[last_round_idx, :]))
        if cooperators >= self.m:
            self.trust_score = min(1.0, self.trust_score + 0.1)
        else:
            self.trust_score = max(0.0, self.trust_score - 0.2)

    def _endgame_decision(self, history: PlayerHistory) -> Action:
        """Special logic for final round"""
        recent_success_rate = self._get_recent_success_rate(history)
        recent_cooperators = self._get_recent_avg_cooperators(history)
        if recent_success_rate > 0.6 and recent_cooperators >= self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_59(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperative Strategy (ATCS)
    
    Balances cooperative intent with adaptive realism through three phases:
    1. Optimistic cooperation (first third of rounds)
    2. Adaptive learning based on group cooperation rates
    3. Strategic endgame with enhanced thresholds and momentum consideration
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = state.round_number
        if round_num <= self.r // 3:
            return Action.C
        total_players = self.n
        if round_num <= 2 * self.r // 3:
            total_cooperations = 0
            total_decisions = 0
            for round_idx in range(len(history.my_actions)):
                if history.my_actions[round_idx]:
                    total_cooperations += 1
                total_decisions += 1
                opponent_cooperations = np.sum(history.opponent_actions[round_idx, :])
                total_cooperations += opponent_cooperations
                total_decisions += len(history.opponent_actions[round_idx, :])
            avg_coop_rate = total_cooperations / total_decisions if total_decisions > 0 else 0
            threshold = self.m / total_players - 0.1
            return Action.C if avg_coop_rate >= threshold else Action.D
        else:
            window_size = max(1, self.r // 6)
            recent_rounds = min(window_size, len(history.my_actions))
            recent_cooperations = 0
            recent_decisions = 0
            for i in range(recent_rounds):
                round_idx = len(history.my_actions) - 1 - i
                if round_idx >= 0:
                    if history.my_actions[round_idx]:
                        recent_cooperations += 1
                    recent_decisions += 1
                    opponent_cooperations = np.sum(history.opponent_actions[round_idx, :])
                    recent_cooperations += opponent_cooperations
                    recent_decisions += len(history.opponent_actions[round_idx, :])
            recent_coop_rate = recent_cooperations / recent_decisions if recent_decisions > 0 else 0
            base_threshold = self.m / total_players
            shows_improvement = False
            if len(history.my_actions) >= 4:
                half_window = max(1, recent_rounds // 2)
                early_cooperations = 0
                early_decisions = 0
                for i in range(half_window):
                    round_idx = len(history.my_actions) - recent_rounds + i
                    if round_idx >= 0:
                        if history.my_actions[round_idx]:
                            early_cooperations += 1
                        early_decisions += 1
                        opponent_cooperations = np.sum(history.opponent_actions[round_idx, :])
                        early_cooperations += opponent_cooperations
                        early_decisions += len(history.opponent_actions[round_idx, :])
                later_cooperations = 0
                later_decisions = 0
                for i in range(half_window):
                    round_idx = len(history.my_actions) - half_window + i
                    if round_idx >= 0:
                        if history.my_actions[round_idx]:
                            later_cooperations += 1
                        later_decisions += 1
                        opponent_cooperations = np.sum(history.opponent_actions[round_idx, :])
                        later_cooperations += opponent_cooperations
                        later_decisions += len(history.opponent_actions[round_idx, :])
                early_rate = early_cooperations / early_decisions if early_decisions > 0 else 0
                later_rate = later_cooperations / later_decisions if later_decisions > 0 else 0
                shows_improvement = later_rate > early_rate
            if shows_improvement:
                threshold = base_threshold - 0.05
            else:
                threshold = base_threshold
            if self.n <= 4:
                threshold = self.m / total_players - 0.15
            return Action.C if recent_coop_rate >= threshold else Action.D

class Strategy_COOPERATIVE_60(BaseStrategy):
    """
    Adaptive Threshold Guardian: A conditionally cooperative strategy that balances cooperation 
    with protection against exploitation. Starts optimistically, adapts based on group behavior 
    patterns, and maintains threshold awareness throughout the game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.phase1_rounds = max(1, math.floor(self.r * 0.2))
        self.phase3_start = math.ceil(self.r * 0.8)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number
        if current_round < self.phase1_rounds:
            return Action.C
        recent_window = min(5, current_round)
        recent_opponent_actions = history.opponent_actions[-recent_window:, :]
        recent_cooperators = []
        for i in range(recent_window):
            round_idx = current_round - recent_window + i
            my_action = history.my_actions[round_idx]
            opponent_cooperators = sum(recent_opponent_actions[i, :])
            total_cooperators = opponent_cooperators + (1 if my_action else 0)
            recent_cooperators.append(total_cooperators)
        average_cooperators = np.mean(recent_cooperators)
        if len(recent_cooperators) >= 3:
            early_avg = np.mean(recent_cooperators[:len(recent_cooperators) // 2])
            late_avg = np.mean(recent_cooperators[len(recent_cooperators) // 2:])
            trend_is_improving = late_avg > early_avg
        else:
            trend_is_improving = False
        my_cooperation_rate = np.mean(history.my_actions)
        if current_round >= self.phase3_start:
            return self._endgame_strategy(history, average_cooperators)
        return self._adaptive_response(average_cooperators, trend_is_improving, my_cooperation_rate, history)

    def _adaptive_response(self, average_cooperators, trend_is_improving, my_cooperation_rate, history):
        if average_cooperators >= self.m - 1:
            return Action.C
        if average_cooperators >= self.m * 0.6 and trend_is_improving:
            return Action.C
        if my_cooperation_rate > 0.7 and average_cooperators < self.m * 0.4:
            if random.random() < 0.3:
                return Action.D
            else:
                return Action.C
        if self._should_forgive(history):
            return Action.C
        return Action.C

    def _endgame_strategy(self, history, average_cooperators):
        recent_rounds = min(5, len(history.my_actions))
        threshold_met_count = 0
        for i in range(recent_rounds):
            round_idx = len(history.my_actions) - recent_rounds + i
            my_action = history.my_actions[round_idx]
            opponent_cooperators = sum(history.opponent_actions[round_idx, :])
            total_cooperators = opponent_cooperators + (1 if my_action else 0)
            if total_cooperators >= self.m:
                threshold_met_count += 1
        threshold_met_rate = threshold_met_count / recent_rounds
        if threshold_met_rate > 0.6:
            return Action.C
        if average_cooperators >= self.m * 0.7:
            return Action.C
        if average_cooperators < self.m * 0.3:
            if len(history.my_actions) > 0:
                last_round_cooperators = sum(history.opponent_actions[-1, :]) + (1 if history.my_actions[-1] else 0)
                return Action.C if last_round_cooperators >= self.m else Action.D
        return Action.C

    def _should_forgive(self, history):
        if len(history.my_actions) < 6:
            return False
        cooperator_counts = []
        for i in range(6):
            round_idx = len(history.my_actions) - 6 + i
            my_action = history.my_actions[round_idx]
            opponent_cooperators = sum(history.opponent_actions[round_idx, :])
            total_cooperators = opponent_cooperators + (1 if my_action else 0)
            cooperator_counts.append(total_cooperators)
        below_threshold_count = 0
        for i in range(3):
            if cooperator_counts[i] < self.m:
                below_threshold_count += 1
        if below_threshold_count >= 3:
            old_avg = np.mean(cooperator_counts[:3])
            new_avg = np.mean(cooperator_counts[3:])
            if new_avg >= old_avg + 2:
                return True
        return False

class Strategy_COOPERATIVE_61(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperative Strategy (ATCS)
    
    Balances cooperative intent with adaptive learning, aiming to achieve the 
    collective threshold while protecting against exploitation through conditional
    cooperation with strategic patience.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number
        if current_round == self.r - 1:
            return self._final_round_decision(history)
        return self._adaptive_decision(history)

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """Final round decision with endgame considerations"""
        success_rate = self._calculate_success_rate(history)
        predicted_cooperators = self._predict_cooperators(history)
        if success_rate >= 0.7:
            return Action.C
        elif predicted_cooperators >= self.m - 1:
            return Action.C
        else:
            return Action.D

    def _adaptive_decision(self, history: PlayerHistory) -> Action:
        """Main adaptive decision logic for middle rounds"""
        avg_coop_rate = self._calculate_avg_cooperation_rate(history)
        predicted_cooperators = self._predict_cooperators(history)
        threshold_gap = self.m - predicted_cooperators
        recent_trend_improving = self._is_trend_improving(history)
        coop_bonus = 0.2 if self.n <= 4 else 0.0
        if self.m > 0.7 * self.n:
            coop_bonus += 0.1
        reward_factor = 1.0 if self.k > 1.5 else 0.8
        if threshold_gap <= 0:
            threshold = 0.6 - coop_bonus
            if avg_coop_rate >= threshold:
                return Action.C
            else:
                return Action.D
        elif threshold_gap == 1:
            threshold = 0.4 - coop_bonus
            if recent_trend_improving or avg_coop_rate >= threshold * reward_factor:
                return Action.C
            else:
                return Action.D
        else:
            max_gap = (self.n - self.m) / 2
            threshold = 0.5 - coop_bonus
            if threshold_gap <= max_gap and avg_coop_rate >= threshold * reward_factor:
                return Action.C
            else:
                return Action.D

    def _calculate_avg_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate average cooperation rate across all previous rounds"""
        total_actions = 0
        total_cooperations = 0
        for round_idx in range(history.round_number):
            if history.my_actions[round_idx]:
                total_cooperations += 1
            total_actions += 1
            round_cooperations = np.sum(history.opponent_actions[round_idx, :])
            total_cooperations += round_cooperations
            total_actions += self.n - 1
        return total_cooperations / total_actions if total_actions > 0 else 0.0

    def _predict_cooperators(self, history: PlayerHistory) -> int:
        """Predict likely cooperators this round based on recent trends"""
        if history.round_number == 0:
            return 0
        weights = [0.5, 0.3, 0.2]
        recent_rounds = min(3, history.round_number)
        predicted = 0.0
        weight_sum = 0.0
        for i in range(recent_rounds):
            round_idx = history.round_number - 1 - i
            if round_idx >= 0:
                round_cooperators = np.sum(history.opponent_actions[round_idx, :])
                predicted += weights[i] * round_cooperators
                weight_sum += weights[i]
        if weight_sum > 0:
            predicted = predicted / weight_sum
        return int(round(predicted))

    def _is_trend_improving(self, history: PlayerHistory) -> bool:
        """Check if recent cooperation trend is improving"""
        if history.round_number < 2:
            return True
        recent_rounds = min(3, history.round_number)
        if recent_rounds < 2:
            return True
        rates = []
        for i in range(recent_rounds):
            round_idx = history.round_number - recent_rounds + i
            if round_idx >= 0:
                cooperators = np.sum(history.opponent_actions[round_idx, :])
                if history.my_actions[round_idx]:
                    cooperators += 1
                rate = cooperators / self.n
                rates.append(rate)
        if len(rates) < 2:
            return True
        improvements = 0
        for i in range(1, len(rates)):
            if rates[i] >= rates[i - 1]:
                improvements += 1
        return improvements >= len(rates) // 2

    def _calculate_success_rate(self, history: PlayerHistory) -> float:
        """Calculate historical success rate (rounds where threshold was met)"""
        successes = 0
        for round_idx in range(history.round_number):
            cooperators = np.sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators >= self.m:
                successes += 1
        return successes / history.round_number if history.round_number > 0 else 0.0

class Strategy_COOPERATIVE_62(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperative Strategy (ATCS)
    
    Balances cooperative intent with adaptive realism. Starts optimistically but learns
    from group behavior, adjusting cooperation levels to maintain collective benefit
    while protecting against exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.theta = 0.8
        self.estimated_coop_probs = [0.6] * (game_description.n_players - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        self._update_theta(history)
        self._update_estimated_probs(history)
        recent_success_rate = self._calculate_recent_success_rate(history)
        if current_round <= 3:
            theta_adjusted = min(0.9, self.theta + 0.15)
        elif current_round > r * 0.8:
            if recent_success_rate > 0.7:
                theta_adjusted = self.theta
            else:
                theta_adjusted = max(0.3, self.theta - 0.05)
        else:
            theta_adjusted = self.theta
        consecutive_failures = self._count_consecutive_failures(history)
        if consecutive_failures >= 2 and current_round <= r / 2:
            theta_adjusted = 0.7
        pivotal_prob = self._calculate_pivotal_probability()
        if pivotal_prob > 0.3:
            return Action.C
        elif random.random() < theta_adjusted:
            return Action.C
        else:
            return Action.D

    def _update_theta(self, history: PlayerHistory):
        """Update cooperation threshold based on last round outcome"""
        if len(history.my_actions) == 0:
            return
        last_round_idx = len(history.my_actions) - 1
        cooperators_last_round = sum(history.opponent_actions[last_round_idx, :])
        if history.my_actions[last_round_idx]:
            cooperators_last_round += 1
        threshold_met = cooperators_last_round >= self.game_description.m
        i_cooperated = history.my_actions[last_round_idx]
        if threshold_met and i_cooperated:
            self.theta = min(0.9, self.theta + 0.05)
        elif threshold_met and (not i_cooperated):
            self.theta = min(0.9, self.theta + 0.02)
        elif not threshold_met:
            coop_rate_last_round = cooperators_last_round / self.game_description.n_players
            if coop_rate_last_round >= 0.5:
                self.theta = max(0.3, self.theta - 0.03)
            else:
                self.theta = max(0.3, self.theta - 0.08)

    def _update_estimated_probs(self, history: PlayerHistory):
        """Update estimated cooperation probabilities for each opponent"""
        rounds_observed = len(history.my_actions)
        for j in range(self.game_description.n_players - 1):
            if rounds_observed < 3:
                self.estimated_coop_probs[j] = 0.6
            else:
                start_idx = max(0, rounds_observed - 3)
                recent_coops = sum(history.opponent_actions[start_idx:, j])
                recent_rounds = rounds_observed - start_idx
                recent_coop_rate = recent_coops / recent_rounds
                overall_coops = sum(history.opponent_actions[:, j])
                overall_coop_rate = overall_coops / rounds_observed
                self.estimated_coop_probs[j] = 0.7 * recent_coop_rate + 0.3 * overall_coop_rate
                if rounds_observed >= 4:
                    last_3_actions = history.opponent_actions[-3:, j]
                    if sum(last_3_actions[:-1]) == 0 and last_3_actions[-1] == 1:
                        self.estimated_coop_probs[j] = min(1.0, self.estimated_coop_probs[j] + 0.2)

    def _calculate_recent_success_rate(self, history: PlayerHistory):
        """Calculate success rate for recent rounds (last 5 or all if fewer)"""
        rounds_observed = len(history.my_actions)
        if rounds_observed == 0:
            return 0.8
        start_idx = max(0, rounds_observed - 5)
        successes = 0
        for round_idx in range(start_idx, rounds_observed):
            cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators >= self.game_description.m:
                successes += 1
        recent_rounds = rounds_observed - start_idx
        return successes / recent_rounds if recent_rounds > 0 else 0.8

    def _calculate_pivotal_probability(self):
        """Calculate probability that my cooperation will be pivotal"""
        n_others = self.game_description.n_players - 1
        m = self.game_description.m
        if m <= 1:
            return 0.0
        p_avg = sum(self.estimated_coop_probs) / n_others
        k = m - 1
        if k > n_others or k < 0:
            return 0.0
        binom_coeff = 1
        for i in range(k):
            binom_coeff = binom_coeff * (n_others - i) // (i + 1)
        prob = binom_coeff * p_avg ** k * (1 - p_avg) ** (n_others - k)
        return min(1.0, prob)

    def _count_consecutive_failures(self, history: PlayerHistory):
        """Count consecutive failures from the end of history"""
        rounds_observed = len(history.my_actions)
        consecutive_failures = 0
        for round_idx in range(rounds_observed - 1, -1, -1):
            cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators < self.game_description.m:
                consecutive_failures += 1
            else:
                break
        return consecutive_failures

class Strategy_COOPERATIVE_63(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) - Balances cooperation with strategic adaptation,
    aiming to achieve the collective threshold while protecting against exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = history.round_number + 1
        total_rounds_played = len(history.my_actions)
        last_round_cooperators = int(history.my_actions[-1]) + sum(history.opponent_actions[-1, :])
        total_my_cooperations = sum(history.my_actions)
        total_opponent_cooperations = np.sum(history.opponent_actions)
        total_cooperations = total_my_cooperations + total_opponent_cooperations
        total_possible_cooperations = total_rounds_played * n
        cooperation_rate = total_cooperations / total_possible_cooperations if total_possible_cooperations > 0 else 0
        if current_round == r:
            if cooperation_rate >= 0.5:
                return Action.C
            elif cooperation_rate < 0.3:
                return Action.D
            else:
                return Action.C if random.random() < 0.6 else Action.D
        cooperation_momentum = last_round_cooperators >= m
        defection_trend = False
        if total_rounds_played >= 4:
            recent_defections = 0
            previous_defections = 0
            for i in range(max(0, total_rounds_played - 2), total_rounds_played):
                recent_defections += n - 1 - sum(history.opponent_actions[i, :])
                recent_defections += 1 - int(history.my_actions[i])
            for i in range(max(0, total_rounds_played - 4), max(0, total_rounds_played - 2)):
                previous_defections += n - 1 - sum(history.opponent_actions[i, :])
                previous_defections += 1 - int(history.my_actions[i])
            defection_trend = recent_defections > previous_defections
        if cooperation_momentum and cooperation_rate >= 0.4 or last_round_cooperators == m - 1 or cooperation_rate >= 0.6:
            return Action.C
        if last_round_cooperators < m - 2 and defection_trend or cooperation_rate < 0.3:
            return Action.D
        cooperation_prob = cooperation_rate * 1.5
        if n <= 4:
            cooperation_prob += 0.2
        if m > n / 2 and cooperation_rate < 0.4:
            return Action.D
        if r <= 3:
            if cooperation_rate < 0.1:
                return Action.D
            else:
                return Action.C
        cooperation_prob = min(1.0, cooperation_prob)
        return Action.C if random.random() < cooperation_prob else Action.D

class Strategy_COOPERATIVE_64(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperation Strategy (ATCS)
    
    Balances cooperative intent with adaptive resilience, aiming to achieve collective benefit
    while protecting against exploitation. Operates on conditional cooperation with learning.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number + 1
        coop_rate = self._calculate_cooperation_rate(history)
        momentum = self._calculate_momentum(history)
        min_rate = m / n
        adjust_factor = self._calculate_adjustment_factor(n, m, k)
        if current_round == r:
            threshold = min_rate * 0.7 * adjust_factor
            return Action.C if coop_rate >= threshold else Action.D
        condition1 = coop_rate >= min_rate * 0.8 * adjust_factor
        condition2 = momentum >= min_rate * 0.6 * adjust_factor and coop_rate >= min_rate * 0.5 * adjust_factor
        condition3 = coop_rate < min_rate * 0.5 * adjust_factor and momentum >= min_rate * 0.4 * adjust_factor
        last_round_cooperations = self._count_last_round_cooperations(history)
        condition4 = last_round_cooperations >= m - 2
        if condition1 or condition2 or condition3 or condition4:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate overall cooperation rate from all rounds and all players"""
        total_rounds = history.round_number
        if total_rounds == 0:
            return 0.0
        my_cooperations = np.sum(history.my_actions)
        opponent_cooperations = np.sum(history.opponent_actions)
        total_cooperations = my_cooperations + opponent_cooperations
        total_decisions = self.game_description.n_players * total_rounds
        return total_cooperations / total_decisions

    def _calculate_momentum(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate in the most recent round"""
        if history.round_number == 0:
            return 0.0
        my_last_action = history.my_actions[-1]
        opponent_last_actions = history.opponent_actions[-1, :]
        last_round_cooperations = int(my_last_action) + np.sum(opponent_last_actions)
        return last_round_cooperations / self.game_description.n_players

    def _count_last_round_cooperations(self, history: PlayerHistory) -> int:
        """Count total cooperations in the last round"""
        if history.round_number == 0:
            return 0
        my_last_action = int(history.my_actions[-1])
        opponent_last_cooperations = int(np.sum(history.opponent_actions[-1, :]))
        return my_last_action + opponent_last_cooperations

    def _calculate_adjustment_factor(self, n: int, m: int, k: float) -> float:
        """Calculate adjustment factor based on game parameters"""
        factor = 1.0
        if n <= 4:
            factor *= 0.8
        if m / n > 0.6:
            factor *= 0.9
        if k <= 1.5:
            factor *= 1.1
        return factor

class Strategy_COOPERATIVE_65(BaseStrategy):
    """
    Vigilant Collaborator: Adaptive cooperative strategy that balances cooperation with protection
    against exploitation using dynamic threshold adjustment based on group behavior patterns.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.base_threshold = self.m / self.n
        self.player_coop_probs = np.ones(self.n - 1) * 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = history.round_number + 1
        if round_num == self.r:
            success_rate = self._calculate_success_rate(history)
            return Action.C if success_rate > 0.6 else Action.D
        return self._adaptive_cooperation_decision(history)

    def _adaptive_cooperation_decision(self, history: PlayerHistory) -> Action:
        recent_momentum = self._calculate_momentum(history)
        adjusted_threshold = self._adjust_threshold(recent_momentum)
        if self._momentum_condition(recent_momentum, adjusted_threshold):
            return Action.C
        elif self._recovery_condition(history):
            return Action.C
        elif self._reciprocity_condition(history):
            return Action.C
        else:
            return Action.D

    def _calculate_momentum(self, history: PlayerHistory) -> float:
        """Calculate recent cooperation momentum using weighted average of last 3 rounds."""
        rounds_completed = history.round_number
        if rounds_completed == 0:
            return 0.5
        recent_rounds = min(3, rounds_completed)
        cooperation_rates = []
        for i in range(recent_rounds):
            round_idx = rounds_completed - 1 - i
            cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            cooperation_rate = cooperators / self.n
            cooperation_rates.append(cooperation_rate)
        weights = np.array([0.5, 0.3, 0.2][:len(cooperation_rates)])
        weights = weights[:len(cooperation_rates)]
        weights = weights / sum(weights)
        return sum((rate * weight for rate, weight in zip(cooperation_rates, weights)))

    def _adjust_threshold(self, recent_momentum: float) -> float:
        """Dynamically adjust cooperation threshold based on recent momentum."""
        if recent_momentum > self.base_threshold:
            return self.base_threshold * 0.8
        else:
            return self.base_threshold * 1.2

    def _momentum_condition(self, recent_momentum: float, adjusted_threshold: float) -> bool:
        """Check if momentum condition is met."""
        return recent_momentum >= adjusted_threshold

    def _recovery_condition(self, history: PlayerHistory) -> bool:
        """Check if recovery condition is met after a failed round."""
        if history.round_number == 0:
            return False
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        last_round_failed = last_round_cooperators < self.m
        if not last_round_failed:
            return False
        cooperation_rate = last_round_cooperators / self.n
        threshold_rate = self.m / self.n
        return abs(cooperation_rate - threshold_rate) <= 0.2 * threshold_rate

    def _reciprocity_condition(self, history: PlayerHistory) -> bool:
        """Check if reciprocity condition is met based on individual patterns."""
        if history.round_number == 0:
            return False
        self._update_player_estimates(history)
        last_round_cooperators = history.opponent_actions[-1, :]
        expected_cooperators = 0
        for i, cooperated_last in enumerate(last_round_cooperators):
            if cooperated_last:
                if self.player_coop_probs[i] >= 0.6:
                    expected_cooperators += 1
        last_round_coop_count = sum(last_round_cooperators)
        if last_round_coop_count == 0:
            return False
        return expected_cooperators / last_round_coop_count >= 0.6

    def _update_player_estimates(self, history: PlayerHistory) -> None:
        """Update cooperation probability estimates using exponential weighted moving average."""
        if history.round_number == 0:
            return
        for i in range(self.n - 1):
            current_action = 1.0 if history.opponent_actions[-1, i] else 0.0
            self.player_coop_probs[i] = 0.7 * self.player_coop_probs[i] + 0.3 * current_action

    def _calculate_success_rate(self, history: PlayerHistory) -> float:
        """Calculate the rate of successful rounds (threshold met)."""
        if history.round_number == 0:
            return 0.0
        successful_rounds = 0
        for round_idx in range(history.round_number):
            cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators >= self.m:
                successful_rounds += 1
        return successful_rounds / history.round_number

class Strategy_COOPERATIVE_66(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperative Strategy (ATCS).
    Balances cooperative intent with pragmatic adaptation, aiming to establish 
    and maintain cooperation while protecting against exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.cooperation_threshold = float(self.m)
        self.consecutive_failed_cooperations = 0
        self.recovery_mode = False
        self.recovery_rounds_left = 0
        self.pure_best_response_rounds_left = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = history.round_number
        if self.recovery_mode and self.recovery_rounds_left > 0:
            self.recovery_rounds_left -= 1
            if self.recovery_rounds_left == 0:
                self.recovery_mode = False
            return Action.C
        if self.pure_best_response_rounds_left > 0:
            self.pure_best_response_rounds_left -= 1
            predicted_cooperators = self._predict_cooperators(history)
            return Action.C if predicted_cooperators >= self.m else Action.D
        if round_num == self.r - 1:
            total_cooperation_rate = self._calculate_total_cooperation_rate(history)
            return Action.C if total_cooperation_rate >= 0.6 else Action.D
        predicted_cooperators = self._predict_cooperators(history)
        self._update_cooperation_threshold(history)
        self._check_recovery_trigger(history)
        if predicted_cooperators >= self.cooperation_threshold:
            decision = Action.C
        else:
            decision = Action.D
        if decision == Action.C:
            last_round_cooperators = int(sum(history.opponent_actions[-1, :]))
            if history.my_actions[-1]:
                last_round_cooperators += 1
            if last_round_cooperators < self.m:
                self.consecutive_failed_cooperations += 1
            else:
                self.consecutive_failed_cooperations = 0
        else:
            self.consecutive_failed_cooperations = 0
        self._apply_forgiveness_protocol()
        return decision

    def _predict_cooperators(self, history):
        """Predict number of cooperators for next round."""
        rounds_to_consider = min(3, history.round_number)
        recent_cooperators = []
        for i in range(rounds_to_consider):
            round_idx = history.round_number - 1 - i
            cooperators = int(sum(history.opponent_actions[round_idx, :]))
            if history.my_actions[round_idx]:
                cooperators += 1
            recent_cooperators.append(cooperators)
        weights = [0.5, 0.3, 0.2][:len(recent_cooperators)]
        weights = np.array(weights)
        weights = weights / weights.sum()
        weighted_average = sum((w * c for w, c in zip(weights, recent_cooperators)))
        forgiveness_bonus = 0
        my_cooperation_rate = sum(history.my_actions) / len(history.my_actions)
        if my_cooperation_rate >= 0.8 and weighted_average >= self.m - 1:
            forgiveness_bonus = 0.5
        trend_bonus = 0
        if len(recent_cooperators) >= 2:
            if recent_cooperators[0] > recent_cooperators[-1]:
                trend_bonus = 0.3
            elif recent_cooperators[0] < recent_cooperators[-1]:
                trend_bonus = -0.3
        return weighted_average + forgiveness_bonus + trend_bonus

    def _update_cooperation_threshold(self, history):
        """Update the cooperation threshold based on historical performance."""
        if history.round_number < 3:
            return
        total_cooperators = []
        for round_idx in range(history.round_number):
            cooperators = int(sum(history.opponent_actions[round_idx, :]))
            if history.my_actions[round_idx]:
                cooperators += 1
            total_cooperators.append(cooperators)
        observed_average = sum(total_cooperators) / len(total_cooperators)
        new_threshold = max(self.m, observed_average * 1.1)
        new_threshold = max(self.m, min(self.n - 1, new_threshold))
        self.cooperation_threshold = new_threshold

    def _calculate_total_cooperation_rate(self, history):
        """Calculate total cooperation rate across all previous rounds."""
        total_cooperations = 0
        total_possible = 0
        for round_idx in range(history.round_number):
            cooperators = int(sum(history.opponent_actions[round_idx, :]))
            if history.my_actions[round_idx]:
                cooperators += 1
            total_cooperations += cooperators
            total_possible += self.n
        return total_cooperations / total_possible if total_possible > 0 else 0

    def _check_recovery_trigger(self, history):
        """Check if recovery mechanism should be triggered."""
        if history.round_number < 3:
            return
        low_cooperation_count = 0
        for i in range(3):
            round_idx = history.round_number - 1 - i
            if round_idx < 0:
                break
            cooperators = int(sum(history.opponent_actions[round_idx, :]))
            if history.my_actions[round_idx]:
                cooperators += 1
            cooperation_rate = cooperators / self.n
            if cooperation_rate < 0.3:
                low_cooperation_count += 1
        if low_cooperation_count >= 3:
            self.recovery_mode = True
            self.recovery_rounds_left = 1

    def _apply_forgiveness_protocol(self):
        """Apply forgiveness protocol based on consecutive failed cooperations."""
        if self.consecutive_failed_cooperations == 2:
            self.cooperation_threshold = max(self.m - 0.5, self.m - 0.5)
        elif self.consecutive_failed_cooperations >= 4:
            self.pure_best_response_rounds_left = 2
            self.consecutive_failed_cooperations = 0

class Strategy_COOPERATIVE_67(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS)
    
    Balances cooperative intent with adaptive realism, aiming to establish and maintain 
    cooperative equilibria while protecting against exploitation. Cooperates optimistically 
    in round 1, then adapts based on cooperation history, threshold achievement, and trends.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = history.round_number + 1
        recent_rounds = min(3, history.round_number)
        recent_cooperation_counts = []
        for i in range(recent_rounds):
            round_idx = history.round_number - 1 - i
            my_coop = 1 if history.my_actions[round_idx] else 0
            opp_coop = sum(history.opponent_actions[round_idx, :])
            total_coop = my_coop + opp_coop
            recent_cooperation_counts.append(total_coop)
        last_round_cooperators = recent_cooperation_counts[0] if recent_cooperation_counts else 0
        recent_cooperation_rate = sum(recent_cooperation_counts) / (recent_rounds * n) if recent_rounds > 0 else 0
        threshold_met_last_round = last_round_cooperators >= m
        if current_round == r:
            if recent_cooperation_rate >= m / n:
                return Action.C
            else:
                return Action.D

        def is_cooperation_trending_up():
            if len(recent_cooperation_counts) < 2:
                return False
            recent_avg = recent_cooperation_counts[0]
            if len(recent_cooperation_counts) >= 3:
                earlier_avg = (recent_cooperation_counts[1] + recent_cooperation_counts[2]) / 2
            else:
                earlier_avg = recent_cooperation_counts[1]
            return recent_avg > earlier_avg
        if threshold_met_last_round and recent_cooperation_rate >= m / n:
            return Action.C
        if is_cooperation_trending_up():
            return Action.C
        if recent_cooperation_rate >= (m + 1) / n:
            return Action.C
        if current_round <= 3:
            if any((count >= m for count in recent_cooperation_counts)):
                return Action.C
        if history.round_number >= 3:
            last_3_cooperators = recent_cooperation_counts[:3] if len(recent_cooperation_counts) >= 3 else recent_cooperation_counts
            if len(last_3_cooperators) >= 3:
                stable_cooperation = sum((1 for count in last_3_cooperators if count >= m)) >= 2
                if stable_cooperation:
                    return Action.C
        defection_conditions = [not threshold_met_last_round, recent_cooperation_rate < (m - 1) / n, not is_cooperation_trending_up()]
        if all(defection_conditions):
            return Action.D
        return Action.C

class Strategy_COOPERATIVE_68(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) - Balances cooperation with risk management 
    by dynamically adjusting cooperation decisions based on observed group behavior 
    while maintaining a fundamentally cooperative stance.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = history.round_number + 1
        initial_phase_length = min(5, self.r // 4)
        if round_num <= initial_phase_length:
            return Action.C
        coop_rate = self._calculate_cooperation_rate(history)
        threshold_safety_margin = (self.m + 1) / self.n
        base_prob = self._calculate_base_probability(coop_rate, threshold_safety_margin)
        momentum_adj = self._detect_momentum(history)
        base_prob += momentum_adj
        if self._is_critical_mass_situation(history):
            base_prob = max(base_prob, 0.8)
        if round_num == self.r:
            base_prob = self._adjust_for_endgame(base_prob, history)
        base_prob = self._apply_forgiveness(base_prob, history)
        base_prob = self._apply_anti_exploitation(base_prob, history)
        if self.n <= 4:
            base_prob += 0.1
        if self.m > 0.7 * self.n:
            base_prob = self._adjust_for_high_threshold(base_prob, history, round_num)
        if round_num > 0.8 * self.r:
            historical_success_rate = self._calculate_historical_success_rate(history)
            if historical_success_rate >= 0.6:
                base_prob += 0.1
        base_prob = max(0, min(1, base_prob))
        return Action.C if random.random() < base_prob else Action.D

    def _calculate_cooperation_rate(self, history):
        """Calculate overall cooperation rate from history"""
        total_cooperations = np.sum(history.my_actions) + np.sum(history.opponent_actions)
        total_possible = history.round_number * self.n
        return total_cooperations / total_possible if total_possible > 0 else 0

    def _calculate_base_probability(self, coop_rate, threshold_safety_margin):
        """Calculate base cooperation probability based on observed cooperation rate"""
        min_threshold_rate = (self.m - 1) / self.n
        if coop_rate >= threshold_safety_margin:
            return min(0.9, coop_rate + 0.1)
        elif coop_rate >= min_threshold_rate:
            return 0.7
        else:
            return max(0.3, coop_rate)

    def _detect_momentum(self, history):
        """Detect cooperation trends over last 3 rounds"""
        if history.round_number < 3:
            return 0
        last_3_rounds = history.round_number - 3
        recent_cooperation_rates = []
        for i in range(3):
            round_idx = last_3_rounds + i
            my_coop = 1 if history.my_actions[round_idx] else 0
            opponent_coop = np.sum(history.opponent_actions[round_idx, :])
            total_coop = my_coop + opponent_coop
            recent_cooperation_rates.append(total_coop / self.n)
        if recent_cooperation_rates[2] > recent_cooperation_rates[1] > recent_cooperation_rates[0]:
            return 0.15
        elif recent_cooperation_rates[2] < recent_cooperation_rates[1] < recent_cooperation_rates[0]:
            return -0.1
        else:
            return 0

    def _is_critical_mass_situation(self, history):
        """Check if we're one cooperator short of threshold"""
        if history.round_number == 0:
            return False
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        return last_round_cooperators == self.m - 1

    def _adjust_for_endgame(self, base_prob, history):
        """Adjust probability for last round"""
        threshold_met_rate = self._calculate_threshold_met_rate(history)
        group_coop_rate = np.sum(history.opponent_actions) / (history.round_number * (self.n - 1))
        if threshold_met_rate >= 0.8:
            return base_prob
        elif group_coop_rate < self.m / self.n:
            return 0
        else:
            return max(0, base_prob - 0.2)

    def _apply_forgiveness(self, base_prob, history):
        """Apply forgiveness mechanism"""
        if history.round_number < 4:
            return base_prob
        recovery_rounds = 0
        for i in range(min(3, history.round_number)):
            round_idx = history.round_number - 1 - i
            round_coop_rate = (np.sum(history.opponent_actions[round_idx, :]) + (1 if history.my_actions[round_idx] else 0)) / self.n
            if round_coop_rate > self.m / self.n:
                recovery_rounds += 1
            else:
                break
        if recovery_rounds >= 2:
            return min(1, base_prob + 0.15)
        return base_prob

    def _apply_anti_exploitation(self, base_prob, history):
        """Apply anti-exploitation protection"""
        if history.round_number < 3:
            return base_prob
        my_coop_rate = np.mean(history.my_actions[-3:])
        opponent_coop_rate = np.mean(history.opponent_actions[-3:, :])
        if my_coop_rate - opponent_coop_rate > 0.3:
            return max(0.2, base_prob - 0.2)
        return base_prob

    def _adjust_for_high_threshold(self, base_prob, history, round_num):
        """Adjust for high threshold games"""
        extended_initial_phase = min(7, self.r // 3)
        if round_num <= extended_initial_phase:
            return 1.0
        threshold_safety_margin = (self.m + 2) / self.n
        coop_rate = self._calculate_cooperation_rate(history)
        if coop_rate >= threshold_safety_margin:
            return min(0.95, coop_rate + 0.15)
        return base_prob

    def _calculate_threshold_met_rate(self, history):
        """Calculate what fraction of rounds met the cooperation threshold"""
        threshold_met_count = 0
        for round_idx in range(history.round_number):
            cooperators = np.sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators >= self.m:
                threshold_met_count += 1
        return threshold_met_count / history.round_number if history.round_number > 0 else 0

    def _calculate_historical_success_rate(self, history):
        """Calculate historical success rate for endgame cooperation boost"""
        return self._calculate_threshold_met_rate(history)

class Strategy_COOPERATIVE_69(BaseStrategy):
    """
    Cooperative Momentum Builder - A strategy that balances cooperation with pragmatic adaptation.
    Establishes cooperative intent early, then adapts based on momentum and success patterns.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.establishment_rounds = math.ceil(0.2 * self.r)
        self.high_m_threshold = 0.8 * self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number
        if current_round < self.establishment_rounds:
            return Action.C
        return self._adaptive_decision(history, current_round)

    def _adaptive_decision(self, history: PlayerHistory, current_round: int) -> Action:
        momentum = self._calculate_momentum(history)
        success_rate = self._calculate_success_rate(history)
        trend = self._calculate_trend(history)
        my_cooperation_rate = np.mean(history.my_actions)
        rounds_remaining = self.r - current_round - 1
        if momentum >= 0.6 and success_rate >= 0.5:
            return Action.C
        elif momentum >= 0.4 and trend >= 0:
            return Action.C
        elif rounds_remaining <= 3 and momentum >= 0.3:
            return Action.C
        elif my_cooperation_rate > 0.7 and momentum < 0.2:
            return Action.D
        elif self.m > self.high_m_threshold and momentum < 0.7:
            return Action.C if momentum >= 0.5 else Action.D
        elif self._check_consistent_failure(history) and my_cooperation_rate > 0.8:
            return Action.D
        else:
            return Action.C

    def _calculate_momentum(self, history: PlayerHistory) -> float:
        """Calculate weighted momentum based on recent and overall cooperation rates."""
        current_round = history.round_number
        if current_round >= 3:
            recent_rounds = 3
            recent_cooperators = 0
            for i in range(recent_rounds):
                round_idx = current_round - 1 - i
                round_cooperators = np.sum(history.opponent_actions[round_idx, :])
                if history.my_actions[round_idx]:
                    round_cooperators += 1
                recent_cooperators += round_cooperators
            recent_cooperation_rate = recent_cooperators / (recent_rounds * self.n)
        else:
            total_cooperators = 0
            for round_idx in range(current_round):
                round_cooperators = np.sum(history.opponent_actions[round_idx, :])
                if history.my_actions[round_idx]:
                    round_cooperators += 1
                total_cooperators += round_cooperators
            recent_cooperation_rate = total_cooperators / (current_round * self.n)
        total_cooperators = 0
        for round_idx in range(current_round):
            round_cooperators = np.sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                round_cooperators += 1
            total_cooperators += round_cooperators
        overall_cooperation_rate = total_cooperators / (current_round * self.n)
        momentum = 0.7 * recent_cooperation_rate + 0.3 * overall_cooperation_rate
        return momentum

    def _calculate_success_rate(self, history: PlayerHistory) -> float:
        """Calculate the rate at which threshold m was achieved."""
        current_round = history.round_number
        successful_rounds = 0
        for round_idx in range(current_round):
            cooperators = np.sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators >= self.m:
                successful_rounds += 1
        return successful_rounds / current_round if current_round > 0 else 0

    def _calculate_trend(self, history: PlayerHistory) -> float:
        """Calculate trend in success rate (last 3 vs previous 3 rounds)."""
        current_round = history.round_number
        if current_round < 6:
            return 0
        recent_successes = 0
        for i in range(3):
            round_idx = current_round - 1 - i
            cooperators = np.sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators >= self.m:
                recent_successes += 1
        recent_success_rate = recent_successes / 3
        previous_successes = 0
        for i in range(3, 6):
            round_idx = current_round - 1 - i
            cooperators = np.sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators >= self.m:
                previous_successes += 1
        previous_success_rate = previous_successes / 3
        return recent_success_rate - previous_success_rate

    def _check_consistent_failure(self, history: PlayerHistory) -> bool:
        """Check if there have been 5+ consecutive rounds with success rate < 0.2."""
        current_round = history.round_number
        if current_round < 5:
            return False
        consecutive_failures = 0
        for round_idx in range(current_round - 5, current_round):
            cooperators = np.sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators < self.m:
                consecutive_failures += 1
        return consecutive_failures >= 5

class Strategy_COOPERATIVE_70(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperative Strategy (ATCS)
    
    Balances cooperation with strategic adaptation. Cooperates when confident
    enough others will cooperate to meet the threshold, adapting based on
    observed behavior and game phase.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number + 1
        total_cooperators = 0
        rounds_played = history.round_number
        for round_idx in range(rounds_played):
            my_coop = 1 if history.my_actions[round_idx] else 0
            opponent_coops = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += my_coop + opponent_coops
        historical_coop_rate = total_cooperators / (n * rounds_played)
        expected_cooperators = historical_coop_rate * n
        safety_factor = max(0.8, 1 - 0.1 * (current_round / r))
        if rounds_played > 0:
            my_last_coop = 1 if history.my_actions[-1] else 0
            opponent_last_coops = np.sum(history.opponent_actions[-1, :])
            cooperators_last_round = my_last_coop + opponent_last_coops
            if cooperators_last_round >= m:
                safety_factor *= 0.9
        if current_round == r:
            safety_factor = 0.9
        threshold = (m - 1) * safety_factor
        if expected_cooperators >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_71(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS)
    
    Balances cooperative intent with adaptive risk management. Starts cooperatively,
    then adapts based on group cooperation success rates, proximity to threshold,
    and remaining rounds. Uses momentum-based decision making with endgame cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_number = state.round_number + 1
        if round_number <= min(5, self.r // 3):
            return Action.C
        recent_window = min(5, self.r // 4)
        recent_rounds = min(recent_window, len(history.my_actions))
        recent_success_count = 0
        for i in range(recent_rounds):
            round_idx = -(i + 1)
            cooperators = int(history.my_actions[round_idx]) + np.sum(history.opponent_actions[round_idx, :])
            if cooperators >= self.m:
                recent_success_count += 1
        recent_success_rate = recent_success_count / recent_rounds if recent_rounds > 0 else 0
        remaining_rounds = self.r - round_number + 1
        if recent_success_rate >= 0.7:
            return Action.C
        elif recent_success_rate >= 0.4:
            coop_probability = self._calculate_cooperation_probability(history, remaining_rounds)
            if coop_probability > 0.6 or remaining_rounds <= self.r // 4:
                return Action.C
        last_round_cooperators = int(history.my_actions[-1]) + np.sum(history.opponent_actions[-1, :])
        recent_avg_cooperators = self._calculate_recent_avg_cooperators(history)
        if last_round_cooperators >= self.m - 1 or remaining_rounds <= 3 or recent_avg_cooperators >= self.m - 0.5:
            return Action.C
        return Action.D

    def _calculate_cooperation_probability(self, history, remaining_rounds):
        """Calculate probability of cooperating based on various factors."""
        recent_window = min(5, len(history.my_actions))
        opponent_coop_rates = []
        for i in range(recent_window):
            round_idx = -(i + 1)
            round_cooperators = np.sum(history.opponent_actions[round_idx, :])
            opponent_coop_rates.append(round_cooperators / (self.n - 1))
        avg_opponent_coop_rate = np.mean(opponent_coop_rates) if opponent_coop_rates else 0
        avg_cooperators = self._calculate_recent_avg_cooperators(history)
        threshold_proximity = min(1.0, avg_cooperators / self.m) if self.m > 0 else 0
        endgame_factor = min(1.0, (self.r - remaining_rounds + 1) / self.r)
        if self.m >= self.n - 1:
            threshold_sensitivity = 1.2
        elif self.m <= 2:
            threshold_sensitivity = 0.8
        else:
            threshold_sensitivity = 1.0
        base_probability = avg_opponent_coop_rate * 0.4 + threshold_proximity * 0.4 + endgame_factor * 0.2
        return min(1.0, base_probability * threshold_sensitivity)

    def _calculate_recent_avg_cooperators(self, history):
        """Calculate average number of cooperators in recent rounds."""
        recent_window = min(7, len(history.my_actions))
        total_cooperators = 0
        total_weight = 0
        for i in range(recent_window):
            round_idx = -(i + 1)
            cooperators = int(history.my_actions[round_idx]) + np.sum(history.opponent_actions[round_idx, :])
            weight = 0.8 ** i
            total_cooperators += cooperators * weight
            total_weight += weight
        return total_cooperators / total_weight if total_weight > 0 else 0

class Strategy_COOPERATIVE_72(BaseStrategy):
    """
    Adaptive Cooperative Strategy: "Threshold Guardian"
    
    This strategy balances cooperative intent with adaptive learning, aiming to sustain 
    cooperation while protecting against exploitation. It operates as a "threshold guardian" - 
    actively working to ensure the cooperation threshold is met while learning from collective 
    behavior patterns.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = history.round_number + 1
        if round_num == self.r:
            return self._final_round_strategy(history)
        else:
            return self._adaptive_cooperation_strategy(history)

    def _final_round_strategy(self, history: PlayerHistory) -> Action:
        """Strategy for the final round based on established patterns."""
        success_rate = self._calculate_success_rate(history)
        if success_rate >= 0.5:
            return Action.C
        elif success_rate >= 0.3 and self._was_pivotal_recently(history, 3):
            return Action.C
        else:
            return Action.D

    def _adaptive_cooperation_strategy(self, history: PlayerHistory) -> Action:
        """Main adaptive strategy for middle rounds."""
        if self._is_small_group():
            return self._small_group_strategy(history)
        if self._is_very_short_game():
            return self._short_game_strategy(history)
        if self._evaluate_cooperation_conditions(history):
            return Action.C
        elif self._evaluate_defection_conditions(history):
            return Action.D
        else:
            return Action.C

    def _evaluate_cooperation_conditions(self, history: PlayerHistory) -> bool:
        """Check if any cooperation conditions are met."""
        if self._calculate_success_rate(history) >= 0.7:
            return True
        if self._recent_recovery(history):
            return True
        if self._was_pivotal_last_round(history):
            return True
        success_rate = self._calculate_success_rate(history)
        if success_rate >= 0.5 and self._cooperation_trend_stable_or_increasing(history):
            return True
        if self._threshold_at_risk_last_round(history):
            return True
        if self._is_high_threshold_game():
            if success_rate >= 0.3:
                return True
        return False

    def _evaluate_defection_conditions(self, history: PlayerHistory) -> bool:
        """Check if all defection conditions are met."""
        window_size = max(3, self.r // 4)
        recent_success_rate = self._calculate_recent_success_rate(history, window_size)
        if recent_success_rate >= 0.3:
            return False
        last_round_cooperators = self._count_cooperators_last_round(history)
        if last_round_cooperators >= self.m - 1:
            return False
        if self._has_coordination_recovery(history, 2):
            return False
        return True

    def _calculate_success_rate(self, history: PlayerHistory) -> float:
        """Calculate the overall cooperation threshold success rate."""
        if history.round_number == 0:
            return 0.0
        success_count = 0
        for round_idx in range(history.round_number):
            cooperators = self._count_cooperators_in_round(history, round_idx)
            if cooperators >= self.m:
                success_count += 1
        return success_count / history.round_number

    def _calculate_recent_success_rate(self, history: PlayerHistory, window_size: int) -> float:
        """Calculate success rate over the last window_size rounds."""
        if history.round_number == 0:
            return 0.0
        start_round = max(0, history.round_number - window_size)
        success_count = 0
        rounds_counted = 0
        for round_idx in range(start_round, history.round_number):
            cooperators = self._count_cooperators_in_round(history, round_idx)
            if cooperators >= self.m:
                success_count += 1
            rounds_counted += 1
        return success_count / rounds_counted if rounds_counted > 0 else 0.0

    def _recent_recovery(self, history: PlayerHistory) -> bool:
        """Check if threshold was met in the last 2 consecutive rounds."""
        if history.round_number < 2:
            return False
        for i in range(2):
            round_idx = history.round_number - 1 - i
            cooperators = self._count_cooperators_in_round(history, round_idx)
            if cooperators < self.m:
                return False
        return True

    def _was_pivotal_last_round(self, history: PlayerHistory) -> bool:
        """Check if my cooperation was pivotal in the last round."""
        if history.round_number == 0:
            return False
        last_round_idx = history.round_number - 1
        my_last_action = history.my_actions[last_round_idx]
        if not my_last_action:
            return False
        total_cooperators = self._count_cooperators_in_round(history, last_round_idx)
        return total_cooperators >= self.m and total_cooperators - 1 < self.m

    def _was_pivotal_recently(self, history: PlayerHistory, rounds_back: int) -> bool:
        """Check if I was pivotal in any of the last rounds_back rounds."""
        if history.round_number == 0:
            return False
        start_round = max(0, history.round_number - rounds_back)
        for round_idx in range(start_round, history.round_number):
            my_action = history.my_actions[round_idx]
            if not my_action:
                continue
            total_cooperators = self._count_cooperators_in_round(history, round_idx)
            if total_cooperators >= self.m and total_cooperators - 1 < self.m:
                return True
        return False

    def _cooperation_trend_stable_or_increasing(self, history: PlayerHistory) -> bool:
        """Check if cooperation trend is stable or increasing."""
        if history.round_number < 3:
            return True
        recent_cooperators = []
        for i in range(min(3, history.round_number)):
            round_idx = history.round_number - 1 - i
            cooperators = self._count_cooperators_in_round(history, round_idx)
            recent_cooperators.append(cooperators)
        return recent_cooperators[0] >= recent_cooperators[-1] - 1

    def _threshold_at_risk_last_round(self, history: PlayerHistory) -> bool:
        """Check if cooperators were exactly m or m+1 in the last round."""
        if history.round_number == 0:
            return False
        last_cooperators = self._count_cooperators_last_round(history)
        return last_cooperators == self.m or last_cooperators == self.m + 1

    def _count_cooperators_last_round(self, history: PlayerHistory) -> int:
        """Count total cooperators in the last round (including me)."""
        if history.round_number == 0:
            return 0
        return self._count_cooperators_in_round(history, history.round_number - 1)

    def _count_cooperators_in_round(self, history: PlayerHistory, round_idx: int) -> int:
        """Count total cooperators in a specific round (including me)."""
        if round_idx >= history.round_number or round_idx < 0:
            return 0
        my_coop = 1 if history.my_actions[round_idx] else 0
        opponent_coop = sum(history.opponent_actions[round_idx, :])
        return my_coop + opponent_coop

    def _has_coordination_recovery(self, history: PlayerHistory, rounds_back: int) -> bool:
        """Check if there's been an increase in cooperation in the last rounds_back rounds."""
        if history.round_number < rounds_back + 1:
            return False
        recent_avg = 0
        earlier_avg = 0
        for i in range(rounds_back):
            round_idx = history.round_number - 1 - i
            recent_avg += self._count_cooperators_in_round(history, round_idx)
        recent_avg /= rounds_back
        for i in range(rounds_back):
            round_idx = history.round_number - 1 - rounds_back - i
            if round_idx >= 0:
                earlier_avg += self._count_cooperators_in_round(history, round_idx)
        earlier_avg /= rounds_back
        return recent_avg > earlier_avg

    def _is_small_group(self) -> bool:
        """Check if this is a small group game."""
        return self.n <= 4

    def _is_high_threshold_game(self) -> bool:
        """Check if this is a high threshold game."""
        return self.m > self.n // 2

    def _is_very_short_game(self) -> bool:
        """Check if this is a very short game."""
        return self.r <= 3

    def _small_group_strategy(self, history: PlayerHistory) -> Action:
        """Strategy for small group dynamics."""
        if history.round_number == 0:
            return Action.C
        last_round_idx = history.round_number - 1
        others_cooperated = sum(history.opponent_actions[last_round_idx, :]) > 0
        return Action.C if others_cooperated else Action.D

    def _short_game_strategy(self, history: PlayerHistory) -> Action:
        """Strategy for very short games."""
        round_num = history.round_number + 1
        if round_num == 2:
            others_cooperated_r1 = sum(history.opponent_actions[0, :]) > 0
            return Action.C if others_cooperated_r1 else Action.D
        elif round_num == 3:
            threshold_ever_met = False
            for round_idx in range(history.round_number):
                if self._count_cooperators_in_round(history, round_idx) >= self.m:
                    threshold_ever_met = True
                    break
            return Action.C if threshold_ever_met else Action.D
        return Action.C

class Strategy_COOPERATIVE_73(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperative Strategy (ATCS)
    
    Balances cooperative intent with adaptive protection against exploitation.
    Uses dynamic threshold adjustment and conditional cooperation to facilitate
    group success while being robust to various opponent behaviors.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        base_threshold = max(0.3, (game_description.m - 1) / game_description.n_players)
        if game_description.m <= 3:
            base_threshold += 0.1
        if game_description.k >= 3:
            base_threshold -= 0.1
        self.dynamic_threshold = base_threshold
        self.base_threshold = base_threshold

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        cooperators_last_round = int(np.sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            cooperators_last_round += 1
        cooperation_rate = cooperators_last_round / n
        if len(history.my_actions) > 0:
            if len(history.my_actions) >= 2:
                prev_cooperators = int(np.sum(history.opponent_actions[-2, :]))
                if history.my_actions[-2]:
                    prev_cooperators += 1
                prev_cooperation_rate = prev_cooperators / n
                prev_success = prev_cooperators >= m
                if prev_cooperation_rate >= self.dynamic_threshold:
                    if prev_success:
                        self.dynamic_threshold *= 0.95
                    else:
                        self.dynamic_threshold *= 1.1
                else:
                    self.dynamic_threshold *= 0.98
                self.dynamic_threshold = max(0.2, min(self.dynamic_threshold, 0.8))
        success_count = 0
        total_rounds = len(history.my_actions)
        for round_idx in range(total_rounds):
            round_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
            if history.my_actions[round_idx]:
                round_cooperators += 1
            if round_cooperators >= m:
                success_count += 1
        success_rate = success_count / total_rounds if total_rounds > 0 else 0
        current_threshold = self.dynamic_threshold
        if current_round <= 3:
            current_threshold *= 0.8
        if current_round == r and success_rate < 0.6:
            if cooperation_rate >= current_threshold:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= m / n:
            return Action.C
        elif cooperation_rate >= current_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_74(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS)
    
    Balances cooperative intent with strategic adaptation. Starts cooperatively,
    then adapts based on observed group behavior using dynamic thresholds.
    Protects against exploitation while maintaining cooperation potential.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = state.round_number
        total_cooperations = np.sum(history.opponent_actions) + np.sum(history.my_actions)
        rounds_played = history.round_number
        group_coop_rate = total_cooperations / (self.n * rounds_played)
        last_round_cooperators = np.sum(history.opponent_actions[-1, :]) + int(history.my_actions[-1])
        momentum_bonus = 0.1 if last_round_cooperators >= self.m else 0
        base_threshold = max(0.4, min(0.8, self.m / self.n + 0.1))
        cooperation_threshold = base_threshold - momentum_bonus
        if round_num == self.r:
            if group_coop_rate >= self.m / self.n:
                return Action.C
            else:
                return Action.D
        elif round_num == self.r - 1:
            if group_coop_rate >= self.m / self.n + 0.2:
                return Action.C
            else:
                return Action.D
        elif group_coop_rate >= cooperation_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_76(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperative Strategy (ATCS)
    
    Balances cooperation and self-protection by adapting to group behavior patterns.
    Starts cooperative, maintains threshold-based decisions, and protects against exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        total_rounds_completed = history.round_number
        total_cooperations = 0
        successful_rounds = 0
        for round_idx in range(total_rounds_completed):
            round_cooperations = int(history.my_actions[round_idx]) + sum(history.opponent_actions[round_idx, :])
            total_cooperations += round_cooperations
            if round_cooperations >= m:
                successful_rounds += 1
        cooperation_rate = total_cooperations / (n * total_rounds_completed)
        success_rate = successful_rounds / total_rounds_completed if total_rounds_completed > 0 else 0
        last_round_cooperations = int(history.my_actions[-1]) + sum(history.opponent_actions[-1, :])
        remaining_rounds = r - current_round + 1
        early_round_adjustment = 0.8 if current_round <= 3 else 1.0
        if total_rounds_completed >= 3:
            recent_success_count = 0
            for round_idx in range(max(0, total_rounds_completed - 3), total_rounds_completed):
                round_cooperations = int(history.my_actions[round_idx]) + sum(history.opponent_actions[round_idx, :])
                if round_cooperations >= m:
                    recent_success_count += 1
            if recent_success_count >= 3 and success_rate >= 0.8:
                return Action.C
        if current_round > 4 and successful_rounds == 0:
            return Action.D
        if current_round == r:
            return Action.C if success_rate >= 0.3 else Action.D
        if success_rate >= 0.6 * early_round_adjustment:
            return Action.C
        if last_round_cooperations >= m - 1:
            return Action.C
        if cooperation_rate >= m / n * 0.8 * early_round_adjustment and success_rate >= 0.3 * early_round_adjustment:
            return Action.C
        if remaining_rounds <= max(2, r // 4):
            if success_rate > 0.2 * early_round_adjustment:
                return Action.C
        if success_rate < 0.2 * early_round_adjustment and cooperation_rate < m / n * 0.5 * early_round_adjustment:
            return Action.D
        return Action.C if cooperation_rate >= m / n else Action.D

class Strategy_COOPERATIVE_77(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperative Strategy (ATCS)
    
    Prioritizes collective welfare while being adaptive to opponent behavior.
    Uses cooperation probability prediction and threshold management to establish
    and maintain cooperation through measured reciprocity.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        cooperation_probs = []
        for j in range(self.n - 1):
            prob = self._calculate_cooperation_probability(j, history)
            cooperation_probs.append(prob)
        if current_round < 0.25 * self.r:
            cooperation_probs = [min(1.0, p + 0.2) for p in cooperation_probs]
        threshold = self.m
        if self._recent_failures(history):
            threshold = max(self.m - 1, math.ceil(self.m * 0.8))
        if current_round > 0.8 * self.r:
            threshold = min(self.m + 1, self.n)
            if current_round == self.r - 1:
                success_prob = self._calculate_success_probability(cooperation_probs, threshold)
                if success_prob < 0.7:
                    return Action.D
        expected_cooperators = 1 + sum(cooperation_probs)
        if expected_cooperators >= threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_probability(self, opponent_index: int, history: PlayerHistory) -> float:
        """Calculate cooperation probability for a specific opponent"""
        rounds_completed = history.round_number
        if rounds_completed < 3:
            return 0.6
        opponent_actions = history.opponent_actions[:, opponent_index]
        recent_actions = opponent_actions[-3:]
        recent_rate = np.mean(recent_actions) * 0.5
        overall_rate = np.mean(opponent_actions) * 0.3
        if rounds_completed >= 6:
            earlier_half = opponent_actions[:-3]
            recent_half = opponent_actions[-3:]
            earlier_avg = np.mean(earlier_half)
            recent_avg = np.mean(recent_half)
            if recent_avg > earlier_avg:
                trend_adjustment = 0.1 * 0.2
            elif recent_avg < earlier_avg:
                trend_adjustment = -0.1 * 0.2
            else:
                trend_adjustment = 0
        else:
            trend_adjustment = 0
        probability = recent_rate + overall_rate + trend_adjustment
        if self._in_restart_mode(history):
            probability = min(1.0, probability + 0.3)
        return max(0.0, min(1.0, probability))

    def _recent_failures(self, history: PlayerHistory) -> bool:
        """Check if threshold was not met in last 2 rounds"""
        if history.round_number < 2:
            return False
        recent_rounds = min(2, history.round_number)
        failures = 0
        for i in range(recent_rounds):
            round_idx = -(i + 1)
            cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators < self.m:
                failures += 1
        return failures >= 2

    def _in_restart_mode(self, history: PlayerHistory) -> bool:
        """Check if we should enter restart mode due to low overall cooperation"""
        if history.round_number < 5:
            return False
        last_5_rounds = history.opponent_actions[-5:, :]
        my_last_5 = history.my_actions[-5:]
        total_decisions = 5 * self.n
        total_cooperations = np.sum(last_5_rounds) + np.sum(my_last_5)
        cooperation_rate = total_cooperations / total_decisions
        return cooperation_rate < 0.2

    def _calculate_success_probability(self, cooperation_probs: list, threshold: int) -> float:
        """Estimate probability of achieving threshold given cooperation probabilities"""
        expected = sum(cooperation_probs)
        if len(cooperation_probs) == 0:
            return 0.0
        variance = sum((p * (1 - p) for p in cooperation_probs))
        if variance == 0:
            return 1.0 if expected >= threshold - 1 else 0.0
        z_score = (threshold - 1.5 - expected) / math.sqrt(variance)
        success_prob = 0.5 - 0.5 * math.tanh(0.7 * z_score)
        return max(0.0, min(1.0, success_prob))

class Strategy_COOPERATIVE_78(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperation Strategy (ATCS)
    
    Balances immediate cooperation with adaptive learning, starting cooperatively
    but adapting based on observed group behavior using cooperation rates,
    recent trends, and threshold safety margins.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.initial_phase_length = max(1, math.floor(0.2 * self.r))
        self.recent_window = min(5, max(1, self.r // 4))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number
        if current_round < self.initial_phase_length:
            return Action.C
        cooperation_rate = self._calculate_cooperation_rate(history)
        recent_trend = self._calculate_recent_trend(history)
        threshold_safety_margin = self._calculate_threshold_safety_margin(history)
        if current_round == self.r - 1:
            if cooperation_rate < self.m - 0.5:
                return Action.C
        if cooperation_rate >= self.m - 0.5 and recent_trend >= -0.3:
            return Action.C
        elif cooperation_rate >= self.m + 1 and self._last_round_cooperators(history) >= self.m:
            return Action.C
        elif threshold_safety_margin < 0.5 and current_round > 0.7 * self.r:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate average number of cooperators across all previous rounds"""
        total_cooperators = 0
        rounds_completed = history.round_number
        for round_idx in range(rounds_completed):
            my_cooperation = 1 if history.my_actions[round_idx] else 0
            opponent_cooperation = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += my_cooperation + opponent_cooperation
        return total_cooperators / rounds_completed if rounds_completed > 0 else 0

    def _calculate_recent_trend(self, history: PlayerHistory) -> float:
        """Calculate recent trend compared to overall average"""
        rounds_completed = history.round_number
        if rounds_completed < 2:
            return 0
        recent_rounds = min(self.recent_window, rounds_completed)
        recent_cooperators = 0
        for round_idx in range(rounds_completed - recent_rounds, rounds_completed):
            my_cooperation = 1 if history.my_actions[round_idx] else 0
            opponent_cooperation = np.sum(history.opponent_actions[round_idx, :])
            recent_cooperators += my_cooperation + opponent_cooperation
        recent_rate = recent_cooperators / recent_rounds
        overall_rate = self._calculate_cooperation_rate(history)
        return recent_rate - overall_rate

    def _calculate_threshold_safety_margin(self, history: PlayerHistory) -> float:
        """Calculate how close the group typically gets to the threshold"""
        rounds_completed = history.round_number
        if rounds_completed == 0:
            return float('inf')
        total_margin = 0
        for round_idx in range(rounds_completed):
            my_cooperation = 1 if history.my_actions[round_idx] else 0
            opponent_cooperation = np.sum(history.opponent_actions[round_idx, :])
            round_cooperators = my_cooperation + opponent_cooperation
            margin = round_cooperators - self.m
            total_margin += margin
        return total_margin / rounds_completed

    def _last_round_cooperators(self, history: PlayerHistory) -> int:
        """Count cooperators in the most recent completed round"""
        if history.round_number == 0:
            return 0
        last_round_idx = history.round_number - 1
        my_cooperation = 1 if history.my_actions[last_round_idx] else 0
        opponent_cooperation = int(np.sum(history.opponent_actions[last_round_idx, :]))
        return my_cooperation + opponent_cooperation

class Strategy_COOPERATIVE_79(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperative Strategy (ATCS)
    
    Balances cooperative intentions with adaptive learning, dynamically adjusting 
    cooperation thresholds based on observed group behavior patterns while protecting 
    against exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.total_rounds = game_description.n_rounds
        self.threshold_high = max(0.6, (self.m - 1) / self.n + 0.1)
        self.threshold_low = max(0.3, (self.m - 2) / self.n)
        self.recent_coop_rate = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if current_round <= 2:
            return Action.C
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        last_round_rate = last_round_cooperators / self.n
        self.recent_coop_rate = 0.6 * last_round_rate + 0.4 * self.recent_coop_rate
        recent_rounds = min(3, len(history.my_actions))
        my_recent_coop_rate = sum(history.my_actions[-recent_rounds:]) / recent_rounds
        rounds_remaining = self.total_rounds - current_round
        self._adjust_thresholds(history)
        if self.recent_coop_rate >= self.threshold_high:
            return Action.C
        elif self.recent_coop_rate >= self.threshold_low and my_recent_coop_rate > 0.5:
            return Action.C
        elif rounds_remaining <= 3 and self.recent_coop_rate >= 0.4:
            return Action.C
        else:
            if self._check_extreme_defection(history):
                return Action.D
            if self._check_forgiveness(history):
                return Action.C
            return Action.D

    def _adjust_thresholds(self, history):
        """Dynamically adjust thresholds based on group success patterns"""
        if len(history.my_actions) < 3:
            return
        recent_rounds = min(5, len(history.my_actions))
        success_count = 0
        for i in range(-recent_rounds, 0):
            round_cooperators = sum(history.opponent_actions[i, :])
            if history.my_actions[i]:
                round_cooperators += 1
            if round_cooperators >= self.m:
                success_count += 1
        success_rate = success_count / recent_rounds
        adjustment_factor = 1 + 0.1 * (success_rate - 0.5)
        self.threshold_high *= adjustment_factor
        self.threshold_low *= adjustment_factor
        self.threshold_high = max(0.4, min(0.8, self.threshold_high))
        self.threshold_low = max(0.2, min(0.6, self.threshold_low))

    def _check_extreme_defection(self, history):
        """Check if group has been consistently defecting"""
        if len(history.my_actions) < 3:
            return False
        recent_rounds = min(3, len(history.my_actions))
        low_coop_count = 0
        for i in range(-recent_rounds, 0):
            round_cooperators = sum(history.opponent_actions[i, :])
            if history.my_actions[i]:
                round_cooperators += 1
            if round_cooperators / self.n < 0.2:
                low_coop_count += 1
        return low_coop_count >= 3

    def _check_forgiveness(self, history):
        """Check if group cooperation has recovered after a bad period"""
        if len(history.my_actions) < 2:
            return False
        recovery_count = 0
        for i in range(-2, 0):
            round_cooperators = sum(history.opponent_actions[i, :])
            if history.my_actions[i]:
                round_cooperators += 1
            if round_cooperators / self.n >= self.threshold_low:
                recovery_count += 1
        return recovery_count >= 2

class Strategy_COOPERATIVE_80(BaseStrategy):
    """
    Adaptive Threshold Guardian: A cooperative strategy that balances collective welfare
    with protection against exploitation by adapting based on observed group behavior.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.cooperation_streak = 1
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number + 1
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        total_cooperators = 0
        for round_idx in range(len(history.my_actions)):
            round_cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                round_cooperators += 1
            total_cooperators += round_cooperators
        historical_coop_rate = total_cooperators / (len(history.my_actions) * n)
        recent_coop_rate = last_round_cooperators / n
        success_count = 0
        for round_idx in range(len(history.my_actions)):
            round_cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                round_cooperators += 1
            if round_cooperators >= m:
                success_count += 1
        success_rate = success_count / len(history.my_actions)
        if history.my_actions[-1]:
            self.cooperation_streak += 1
        else:
            self.cooperation_streak = 0
        if current_round == r:
            if success_rate >= 0.4:
                return Action.C
            elif last_round_cooperators >= m - 1:
                return Action.C
            elif historical_coop_rate >= 0.5:
                return Action.C
            else:
                return Action.D
        coop_streak_limit = 2
        hist_coop_threshold = 0.6
        if n <= 4:
            coop_streak_limit = 1
            hist_coop_threshold = 0.5
        if m > n / 2:
            coop_streak_limit = 3
        if r <= 3:
            coop_streak_limit = max(3, coop_streak_limit)
        if last_round_cooperators >= m:
            self.cooperation_streak = 1 if not history.my_actions[-1] else self.cooperation_streak
            return Action.C
        elif last_round_cooperators == m - 1:
            self.cooperation_streak = 1 if not history.my_actions[-1] else self.cooperation_streak
            return Action.C
        elif historical_coop_rate >= hist_coop_threshold:
            self.cooperation_streak = 1 if not history.my_actions[-1] else self.cooperation_streak
            return Action.C
        elif recent_coop_rate >= m / n + 0.1:
            self.cooperation_streak = 1 if not history.my_actions[-1] else self.cooperation_streak
            return Action.C
        elif self.cooperation_streak <= coop_streak_limit:
            return Action.C
        else:
            if success_rate > 0.1 and len(history.my_actions) % 3 == 0:
                self.cooperation_streak = 1
                return Action.C
            if len(history.my_actions) >= 2:
                prev_recent_rate = sum(history.opponent_actions[-2, :]) / n
                if history.my_actions[-2]:
                    prev_recent_rate += 1 / n
                if recent_coop_rate > prev_recent_rate + 0.2:
                    self.cooperation_streak = 1
                    return Action.C
            return Action.D

class Strategy_COOPERATIVE_81(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS): Balances cooperation with strategic protection 
    against exploitation through dynamic threshold management and conditional cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        my_last_action = 1 if history.my_actions[-1] else 0
        opponent_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        last_round_cooperators = my_last_action + opponent_cooperators
        if current_round == self.r - 1:
            return Action.C if last_round_cooperators >= self.m else Action.D
        if last_round_cooperators == self.m - 1:
            return Action.C
        if last_round_cooperators >= self.n - 1:
            return Action.C
        if current_round >= 2:
            my_two_rounds_ago = 1 if history.my_actions[-2] else 0
            opponent_cooperators_two_ago = int(np.sum(history.opponent_actions[-2, :]))
            two_rounds_ago_cooperators = my_two_rounds_ago + opponent_cooperators_two_ago
            if two_rounds_ago_cooperators == 0 and last_round_cooperators == 0:
                return Action.C
        cooperation_threshold = max(self.m - 1, int(last_round_cooperators * 0.8))
        return Action.C if last_round_cooperators >= cooperation_threshold else Action.D

class Strategy_COOPERATIVE_82(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperation Strategy: "Optimistic Gradual Reciprocator"
    
    This strategy balances cooperative intent with adaptive learning, aiming to build and maintain 
    cooperative coalitions while protecting against exploitation. It starts optimistically, tracks
    coalition viability, and uses forgiveness mechanisms to prevent lock-in to permanent defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defect_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.consecutive_defect_rounds = 0
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        total_cooperators_per_round = []
        for round_idx in range(history.round_number):
            opponent_cooperators = sum(history.opponent_actions[round_idx, :])
            my_cooperation = 1 if history.my_actions[round_idx] else 0
            total_cooperators = opponent_cooperators + my_cooperation
            total_cooperators_per_round.append(total_cooperators)
        total_rounds_played = len(total_cooperators_per_round)
        cooperation_rate = sum(total_cooperators_per_round) / (n * total_rounds_played)
        recent_rounds = min(3, total_rounds_played)
        recent_cooperators = total_cooperators_per_round[-recent_rounds:]
        recent_cooperation_trend = sum(recent_cooperators) / recent_rounds
        last_round_cooperators = total_cooperators_per_round[-1] if total_cooperators_per_round else 0
        is_small_group = n <= 4
        is_high_threshold = m > 0.7 * n
        is_single_shot_feel = r == 2
        cooperation_rate_threshold = 0.5 if is_small_group else 0.6
        if is_high_threshold:
            cooperation_rate_threshold = 0.4
        if current_round == r:
            if recent_cooperation_trend >= m or last_round_cooperators >= m:
                return Action.C
            else:
                return Action.D
        if is_single_shot_feel:
            if last_round_cooperators >= m - 1:
                return Action.C
            else:
                return Action.D
        if is_high_threshold and current_round <= 3:
            self.consecutive_defect_rounds = 0
            return Action.C
        should_cooperate = False
        if recent_cooperation_trend >= m - 0.5:
            should_cooperate = True
        elif cooperation_rate >= cooperation_rate_threshold and recent_cooperation_trend >= m - 1:
            should_cooperate = True
        elif last_round_cooperators >= m:
            should_cooperate = True
        if not should_cooperate and self.consecutive_defect_rounds >= 2:
            if self.consecutive_defect_rounds % 3 == 2:
                should_cooperate = True
        if should_cooperate:
            self.consecutive_defect_rounds = 0
        else:
            self.consecutive_defect_rounds += 1
        return Action.C if should_cooperate else Action.D

class Strategy_COOPERATIVE_83(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperation Strategy (ATCS)
    
    Balances cooperative intent with adaptive learning, aiming to establish and maintain 
    cooperation while protecting against systematic exploitation. Uses dynamic thresholds
    and forgiveness mechanisms to foster cooperation while remaining resilient.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.cooperation_threshold = float(self.m)
        self.initial_rounds = max(3, math.ceil(0.15 * self.r))
        self.consecutive_defections = 0
        self.recovery_mode_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number
        if current_round < self.initial_rounds:
            return Action.C
        if self.recovery_mode_rounds > 0:
            self.recovery_mode_rounds -= 1
            return Action.C
        recent_coop_rate = self._get_recent_cooperation_rate(history, 3)
        medium_trend = self._get_medium_term_trend(history)
        long_term_avg = self._get_long_term_average(history)
        predicted_cooperators = (0.4 * recent_coop_rate + 0.3 * medium_trend + 0.3 * long_term_avg) * (self.n - 1)
        if current_round > 0:
            last_round_cooperators = np.sum(history.opponent_actions[-1, :]) + int(history.my_actions[-1])
            if last_round_cooperators >= self.m:
                self.cooperation_threshold = max(self.m, self.cooperation_threshold - 0.1)
            else:
                self.cooperation_threshold = min(self.n - 1, self.cooperation_threshold + 0.2)
        remaining_rounds = self.r - current_round
        in_endgame = remaining_rounds <= 0.2 * self.r
        if current_round >= 3:
            recent_success_rate = self._get_recent_success_rate(history, 3)
            if recent_success_rate < 0.4:
                self.recovery_mode_rounds = 2
                return Action.C
        should_cooperate = False
        if in_endgame:
            should_cooperate = predicted_cooperators >= self.m - 1
        else:
            should_cooperate = predicted_cooperators >= self.cooperation_threshold
            if remaining_rounds <= 0.2 * self.r:
                recent_success = self._get_recent_success_rate(history, 5)
                if recent_success > 0.6:
                    should_cooperate = True
        if not should_cooperate and self.consecutive_defections >= 2:
            should_cooperate = True
        if should_cooperate:
            self.consecutive_defections = 0
        else:
            self.consecutive_defections += 1
        return Action.C if should_cooperate else Action.D

    def _get_recent_cooperation_rate(self, history: PlayerHistory, rounds: int) -> float:
        """Get cooperation rate for the last 'rounds' rounds"""
        if history.round_number == 0:
            return 0.5
        start_idx = max(0, history.round_number - rounds)
        recent_opponent_actions = history.opponent_actions[start_idx:, :]
        if recent_opponent_actions.size == 0:
            return 0.5
        return np.mean(recent_opponent_actions)

    def _get_medium_term_trend(self, history: PlayerHistory) -> float:
        """Get cooperation rate for the last 25% of completed rounds"""
        if history.round_number == 0:
            return 0.5
        quarter_rounds = max(1, math.ceil(history.round_number * 0.25))
        start_idx = max(0, history.round_number - quarter_rounds)
        medium_actions = history.opponent_actions[start_idx:, :]
        if medium_actions.size == 0:
            return 0.5
        return np.mean(medium_actions)

    def _get_long_term_average(self, history: PlayerHistory) -> float:
        """Get overall cooperation rate across all completed rounds"""
        if history.round_number == 0:
            return 0.5
        return np.mean(history.opponent_actions)

    def _get_recent_success_rate(self, history: PlayerHistory, rounds: int) -> float:
        """Get success rate (threshold met) for the last 'rounds' rounds"""
        if history.round_number == 0:
            return 0.5
        start_idx = max(0, history.round_number - rounds)
        successes = 0
        total_rounds = 0
        for i in range(start_idx, history.round_number):
            cooperators = np.sum(history.opponent_actions[i, :]) + int(history.my_actions[i])
            if cooperators >= self.m:
                successes += 1
            total_rounds += 1
        return successes / total_rounds if total_rounds > 0 else 0.5

class Strategy_COOPERATIVE_84(BaseStrategy):
    """
    Progressive Trust Builder: An adaptive cooperative strategy that balances cooperation 
    with protection against exploitation by using escalating cooperation thresholds 
    based on observed group behavior.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number + 1
        if current_round == r:
            return Action.D
        total_cooperators_per_round = []
        for round_idx in range(history.round_number):
            my_cooperation = 1 if history.my_actions[round_idx] else 0
            opponent_cooperators = sum(history.opponent_actions[round_idx, :])
            total_cooperators = my_cooperation + opponent_cooperators
            total_cooperators_per_round.append(total_cooperators)
        avg_cooperators = np.mean(total_cooperators_per_round)
        my_last_cooperation = 1 if history.my_actions[-1] else 0
        recent_opponent_cooperators = sum(history.opponent_actions[-1, :])
        recent_cooperators = my_last_cooperation + recent_opponent_cooperators
        if avg_cooperators >= m:
            threshold = m - 1
        elif avg_cooperators >= m * 0.8:
            threshold = m
        elif avg_cooperators >= m * 0.6:
            threshold = m + 1
        else:
            threshold = m + 2
        if n <= 4:
            threshold = max(1, threshold - 1)
        if m > n / 2:
            successful_rounds = sum((1 for coop in total_cooperators_per_round if coop >= m))
            if successful_rounds < 0.75 * len(total_cooperators_per_round):
                threshold = m + 1
        if k <= 1.5:
            threshold = threshold + 1
        if not history.my_actions[-1] and recent_cooperators >= m:
            return Action.C
        if recent_cooperators >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_85(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) - Balances cooperative intentions with adaptive learning,
    aiming to achieve the collective threshold while protecting against exploitation through
    conditional cooperation based on historical cooperation rates, recent trends, and threshold proximity.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number + 1
        if current_round == self.r:
            return self._final_round_logic(history)
        hcr = self._calculate_historical_cooperation_rate(history)
        rt = self._calculate_recent_trend(history)
        tp = self._calculate_threshold_proximity(history)
        threshold_confidence = max(0.3, self.m / self.n - 0.1)
        threshold_confidence = self._adjust_for_game_parameters(threshold_confidence)
        cooperation_score = hcr * 0.4 + rt * 0.4 + tp * 0.2
        if self._is_being_exploited(history):
            threshold_confidence += 0.2
        if cooperation_score > threshold_confidence:
            return Action.C
        else:
            return Action.D

    def _calculate_historical_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate overall cooperation rate across all players and rounds."""
        total_rounds = len(history.my_actions)
        if total_rounds == 0:
            return 0.0
        my_cooperations = sum(history.my_actions)
        opponent_cooperations = np.sum(history.opponent_actions)
        total_cooperations = my_cooperations + opponent_cooperations
        total_possible = total_rounds * self.n
        return total_cooperations / total_possible if total_possible > 0 else 0.0

    def _calculate_recent_trend(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate in recent rounds (last 3 or fewer)."""
        total_rounds = len(history.my_actions)
        if total_rounds == 0:
            return 0.0
        look_back = min(3, total_rounds)
        recent_rounds = total_rounds - look_back
        my_recent_cooperations = sum(history.my_actions[recent_rounds:])
        opponent_recent_cooperations = np.sum(history.opponent_actions[recent_rounds:, :])
        total_recent_cooperations = my_recent_cooperations + opponent_recent_cooperations
        total_recent_possible = look_back * self.n
        return total_recent_cooperations / total_recent_possible if total_recent_possible > 0 else 0.0

    def _calculate_threshold_proximity(self, history: PlayerHistory) -> float:
        """Calculate how close the group gets to threshold on average."""
        total_rounds = len(history.my_actions)
        if total_rounds == 0:
            return 0.0
        total_cooperators = 0
        for round_idx in range(total_rounds):
            round_cooperators = int(history.my_actions[round_idx]) + sum(history.opponent_actions[round_idx, :])
            total_cooperators += round_cooperators
        avg_cooperators = total_cooperators / total_rounds
        return avg_cooperators / self.m if self.m > 0 else 0.0

    def _adjust_for_game_parameters(self, threshold_confidence: float) -> float:
        """Adjust threshold confidence based on game parameters."""
        adjusted = threshold_confidence
        if self.n <= 4:
            adjusted += 0.1
        if self.m / self.n > 0.7:
            adjusted -= 0.1
        if self.k <= 1.5:
            adjusted += 0.1
        return max(0.1, min(0.9, adjusted))

    def _is_being_exploited(self, history: PlayerHistory) -> bool:
        """Check if being systematically exploited."""
        total_rounds = len(history.my_actions)
        if total_rounds < 3:
            return False
        my_cooperation_rounds = 0
        threshold_not_met_when_cooperated = 0
        for round_idx in range(total_rounds):
            if history.my_actions[round_idx]:
                my_cooperation_rounds += 1
                total_cooperators = 1 + sum(history.opponent_actions[round_idx, :])
                if total_cooperators < self.m:
                    threshold_not_met_when_cooperated += 1
        if my_cooperation_rounds == 0:
            return False
        exploitation_rate = threshold_not_met_when_cooperated / my_cooperation_rounds
        return exploitation_rate > 0.6

    def _final_round_logic(self, history: PlayerHistory) -> Action:
        """Enhanced final round logic."""
        total_rounds = len(history.my_actions)
        if total_rounds == 0:
            return Action.C
        threshold_met_count = 0
        for round_idx in range(total_rounds):
            total_cooperators = int(history.my_actions[round_idx]) + sum(history.opponent_actions[round_idx, :])
            if total_cooperators >= self.m:
                threshold_met_count += 1
        threshold_met_rate = threshold_met_count / total_rounds
        if threshold_met_rate >= 0.8:
            return Action.C
        recent_rounds = min(3, total_rounds)
        recent_start = total_rounds - recent_rounds
        recent_cooperation_rate = 0.0
        if recent_rounds > 0:
            recent_cooperations = 0
            for round_idx in range(recent_start, total_rounds):
                recent_cooperations += int(history.my_actions[round_idx]) + sum(history.opponent_actions[round_idx, :])
            recent_cooperation_rate = recent_cooperations / (recent_rounds * self.n)
        if recent_cooperation_rate >= self.m / self.n:
            return Action.C
        if total_rounds > 0:
            last_round_cooperators = sum(history.opponent_actions[-1, :])
            if last_round_cooperators == self.m - 1:
                return Action.C
        return Action.D

class Strategy_COOPERATIVE_86(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperative Strategy: "Cooperative Momentum Builder"
    
    This strategy builds and maintains cooperative momentum while adapting to group cooperation patterns.
    It starts cooperatively, rewards successful collective action, shows forgiveness for near-misses,
    and adapts based on trends and game parameters.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        prev_cooperators = sum(history.opponent_actions[-1, :]) + int(history.my_actions[-1])
        if prev_cooperators >= m:
            return Action.C
        if prev_cooperators == m - 1:
            return Action.C
        if len(history.my_actions) >= 2:
            prev2_cooperators = sum(history.opponent_actions[-2, :]) + int(history.my_actions[-2])
            threshold_adjustment = max(1, m - 2)
            if m > n // 2:
                threshold_adjustment = max(1, m - 3)
            if prev_cooperators >= prev2_cooperators and prev_cooperators >= threshold_adjustment:
                return Action.C
        if current_round == r:
            if prev_cooperators >= m - 1:
                return Action.C
            else:
                return Action.D
        if current_round <= r // 2:
            forgiveness_prob = 0.3
            if n <= 4:
                forgiveness_prob = 0.5
            if k >= 3:
                forgiveness_prob = 0.5
            if random.random() < forgiveness_prob:
                return Action.C
        if r <= 3 and current_round <= 2:
            return Action.C
        return Action.D

class Strategy_COOPERATIVE_87(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS)
    
    Balances cooperative intent with adaptive learning, aiming to achieve collective 
    success while protecting against exploitation. Cooperates conditionally based on 
    evidence that enough others will reciprocate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        k = self.game_description.k
        current_round = history.round_number + 1
        if current_round == r:
            cooperators_last = int(sum(history.opponent_actions[-1, :]))
            if cooperators_last >= m:
                return Action.C
            elif cooperators_last == m - 1:
                return Action.C
            else:
                return Action.D
        cooperators_last = int(sum(history.opponent_actions[-1, :]))
        cooperation_trend = self._calculate_trend(history)
        small_group_bonus = 0.2 if n <= 4 else 0.0
        high_threshold_bonus = 0.1 if m >= 0.8 * n else 0.0
        low_reward_penalty = 0.1 if k <= 1.5 else 0.0
        if r <= 3:
            if cooperators_last >= m - 1:
                return Action.C
            else:
                return Action.D if current_round == r else Action.C
        if cooperators_last >= m:
            return Action.C
        elif cooperators_last == m - 1:
            if cooperation_trend >= 0:
                return Action.C
            else:
                prob = 0.7 + small_group_bonus + high_threshold_bonus - low_reward_penalty
                return Action.C if random.random() < prob else Action.D
        elif cooperators_last >= m - 2:
            if cooperation_trend > 0:
                return Action.C
            else:
                prob = 0.4 + small_group_bonus + high_threshold_bonus - low_reward_penalty
                return Action.C if random.random() < prob else Action.D
        elif cooperation_trend > 0.3 and current_round <= r // 2:
            return Action.C
        else:
            return Action.D

    def _calculate_trend(self, history: PlayerHistory) -> float:
        """Calculate cooperation trend over last 3 rounds (or all available)."""
        rounds_available = history.round_number
        look_back = min(3, rounds_available)
        if look_back <= 1:
            return 0.0
        cooperation_rates = []
        for i in range(look_back):
            round_idx = rounds_available - 1 - i
            cooperators = sum(history.opponent_actions[round_idx, :])
            cooperation_rate = cooperators / self.game_description.n_players
            cooperation_rates.append(cooperation_rate)
        cooperation_rates.reverse()
        if len(cooperation_rates) == 2:
            return cooperation_rates[1] - cooperation_rates[0]
        n_points = len(cooperation_rates)
        x_mean = (n_points - 1) / 2.0
        y_mean = sum(cooperation_rates) / n_points
        numerator = sum(((i - x_mean) * (cooperation_rates[i] - y_mean) for i in range(n_points)))
        denominator = sum(((i - x_mean) ** 2 for i in range(n_points)))
        if denominator == 0:
            return 0.0
        return numerator / denominator

class Strategy_COOPERATIVE_88(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) - Balances cooperative intent with adaptive learning,
    maintaining cooperation when feasible while protecting against systematic exploitation.
    Uses cooperation probability that adapts based on recent success history and trends.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number
        if current_round == self.r - 1:
            success_rate = self._calculate_historical_success_rate(history)
            if success_rate >= 0.6:
                return Action.C
            elif success_rate >= 0.3:
                return Action.C if random.random() <= 0.4 else Action.D
            else:
                return Action.D
        base_cooperation = min(0.8, (self.m - 1) / (self.n - 1) + 0.3)
        success_modifier = self._calculate_success_modifier(history)
        trend_modifier = self._calculate_trend_modifier(history)
        cooperation_prob = base_cooperation * success_modifier * trend_modifier
        cooperation_prob = min(0.95, cooperation_prob)
        return Action.C if random.random() <= cooperation_prob else Action.D

    def _calculate_historical_success_rate(self, history: PlayerHistory) -> float:
        """Calculate the overall success rate across all rounds."""
        if history.round_number == 0:
            return 0.5
        successful_rounds = 0
        for round_idx in range(history.round_number):
            cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators >= self.m:
                successful_rounds += 1
        return successful_rounds / history.round_number

    def _calculate_success_modifier(self, history: PlayerHistory) -> float:
        """Calculate success modifier based on recent rounds."""
        rounds_to_check = min(5, history.round_number)
        if rounds_to_check == 0:
            return 1.0
        successful_rounds = 0
        for i in range(rounds_to_check):
            round_idx = history.round_number - 1 - i
            cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators >= self.m:
                successful_rounds += 1
        success_rate = successful_rounds / rounds_to_check
        return 0.5 + success_rate

    def _calculate_trend_modifier(self, history: PlayerHistory) -> float:
        """Calculate trend modifier based on cooperation numbers trend."""
        if history.round_number < 3:
            return 1.0
        recent_cooperators = []
        for i in range(min(3, history.round_number)):
            round_idx = history.round_number - 1 - i
            cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            recent_cooperators.append(cooperators)
        if len(recent_cooperators) < 2:
            return 1.0
        trend_sum = 0
        for i in range(len(recent_cooperators) - 1):
            trend_sum += recent_cooperators[i] - recent_cooperators[i + 1]
        avg_trend = trend_sum / (len(recent_cooperators) - 1)
        if avg_trend > 1:
            return 1.2
        elif avg_trend < -1:
            return 0.8
        else:
            return 1.0

class Strategy_COOPERATIVE_89(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperative Strategy (ATCS)
    
    Prioritizes long-term collective benefit while maintaining resilience against exploitation.
    Operates on optimistic cooperation with adaptive learning - starts cooperatively but 
    adjusts based on observed group behavior.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        initial_prob = min(0.8, (self.m + 1) / self.n)
        self.cooperation_probs = [initial_prob] * (self.n - 1)
        self.alpha = 0.7
        self.punishment_rounds_left = 0
        self.consecutive_failures = 0
        self.recent_success_count = 0
        self.recent_rounds_tracked = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            if self.m / self.n > 0.7 and self.m > self.n / 2:
                return Action.D
            return Action.C
        round_num = history.round_number
        if round_num > 0:
            last_round_actions = history.opponent_actions[-1, :]
            group_cooperation_rate = (sum(last_round_actions) + int(history.my_actions[-1])) / self.n
            for i in range(self.n - 1):
                observed_coop = float(last_round_actions[i])
                self.cooperation_probs[i] = self.alpha * self.cooperation_probs[i] + (1 - self.alpha) * observed_coop
                self.cooperation_probs[i] = 0.6 * self.cooperation_probs[i] + 0.4 * group_cooperation_rate
            total_cooperators = sum(last_round_actions) + int(history.my_actions[-1])
            if total_cooperators >= self.m:
                self.consecutive_failures = 0
                self.recent_success_count += 1
            else:
                self.consecutive_failures += 1
            self.recent_rounds_tracked += 1
        expected_cooperators = 1 + sum(self.cooperation_probs)
        threshold_adjustment = 1.0
        if self.consecutive_failures >= 3:
            threshold_adjustment = 1.1
        elif self.recent_rounds_tracked >= 5 and self.recent_success_count / self.recent_rounds_tracked > 0.6:
            threshold_adjustment = 0.95
            if self.recent_rounds_tracked >= 5:
                self.recent_success_count = max(0, self.recent_success_count - 1)
                self.recent_rounds_tracked = max(0, self.recent_rounds_tracked - 1)
        adjusted_threshold = self.m * threshold_adjustment
        if abs(expected_cooperators - self.m) <= 1:
            expected_cooperators += 0.15
        if round_num >= 3 and self.punishment_rounds_left == 0:
            free_riders = 0
            if round_num >= 3:
                for i in range(self.n - 1):
                    recent_actions = history.opponent_actions[max(0, round_num - 3):, i]
                    if len(recent_actions) > 0 and sum(recent_actions) / len(recent_actions) < 0.3:
                        free_riders += 1
                if free_riders > self.n / 3:
                    self.punishment_rounds_left = 2
                    expected_cooperators *= 0.8
        if self.punishment_rounds_left > 0:
            self.punishment_rounds_left -= 1
            expected_cooperators *= 0.8
        if state.round_number == self.r - 1:
            if round_num > 0:
                avg_payoff = sum(history.my_payoffs) / len(history.my_payoffs)
                satisfactory_threshold = (self.k + 1) / 2
                if avg_payoff >= satisfactory_threshold:
                    expected_cooperators += 0.1
        if expected_cooperators >= adjusted_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_90(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperation Strategy.
    
    Balances collective welfare with robustness against exploitation through
    momentum-based decisions, graduated punishment, and forgiveness mechanisms.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_successes = 0
        self.consecutive_failures = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        cooperators_last_round = int(sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            cooperators_last_round += 1
        if len(history.my_actions) >= 2:
            cooperators_two_rounds_ago = int(sum(history.opponent_actions[-2, :]))
            if history.my_actions[-2]:
                cooperators_two_rounds_ago += 1
        else:
            cooperators_two_rounds_ago = cooperators_last_round
        cooperation_rate = cooperators_last_round / n
        recent_trend = (cooperators_last_round - cooperators_two_rounds_ago) / n
        momentum = 0.7 * cooperation_rate + 0.3 * recent_trend
        if cooperators_last_round >= m:
            threshold_met = True
            self.consecutive_successes += 1
            self.consecutive_failures = 0
        else:
            threshold_met = False
            self.consecutive_failures += 1
            self.consecutive_successes = 0
        if cooperators_last_round > cooperators_two_rounds_ago + 1:
            self.consecutive_failures = max(0, self.consecutive_failures - 1)
            return Action.C
        if current_round == r:
            if self.consecutive_successes >= 2:
                return Action.C
            elif cooperators_last_round >= m - 1:
                return Action.C
            else:
                return Action.D
        if momentum >= 0.6 and threshold_met:
            return Action.C
        elif momentum >= 0.4 and cooperators_last_round >= m - 2:
            return Action.C
        elif momentum >= 0.2 and current_round <= r / 2:
            return Action.C
        elif self.consecutive_failures <= 2:
            return Action.C if random.random() < 0.3 else Action.D
        else:
            return Action.D

class Strategy_COOPERATIVE_91(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperation Strategy that balances encouraging cooperation
    with protection against exploitation through dynamic threshold adjustment.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        k = self.game_description.k
        current_round = history.round_number + 1
        if current_round == r:
            total_rounds = history.round_number
            successful_rounds = 0
            for round_idx in range(total_rounds):
                cooperators = sum(history.opponent_actions[round_idx, :]) + int(history.my_actions[round_idx])
                if cooperators >= m:
                    successful_rounds += 1
            success_rate = successful_rounds / total_rounds if total_rounds > 0 else 0
            if success_rate >= 0.8:
                recent_rounds = min(3, total_rounds)
                recent_coop_count = 0
                for i in range(recent_rounds):
                    round_idx = total_rounds - 1 - i
                    cooperators = sum(history.opponent_actions[round_idx, :]) + int(history.my_actions[round_idx])
                    recent_coop_count += cooperators
                expected_cooperators = recent_coop_count / recent_rounds if recent_rounds > 0 else 0
                if expected_cooperators >= m - 1:
                    return Action.C
            return Action.D
        total_rounds = history.round_number
        last_round_cooperators = sum(history.opponent_actions[-1, :]) + int(history.my_actions[-1])
        recent_rounds_to_check = min(3, total_rounds)
        recent_coop_sum = 0
        for i in range(recent_rounds_to_check):
            round_idx = total_rounds - 1 - i
            cooperators = sum(history.opponent_actions[round_idx, :]) + int(history.my_actions[round_idx])
            recent_coop_sum += cooperators
        recent_cooperation_rate = recent_coop_sum / (recent_rounds_to_check * n) if recent_rounds_to_check > 0 else 0
        adjustment_factor = 1.1
        cooperation_threshold = max(m, recent_cooperation_rate * n * adjustment_factor)
        if current_round <= 3:
            cooperation_threshold = max(m, cooperation_threshold * 0.8)
        if last_round_cooperators >= cooperation_threshold:
            return Action.C
        elif last_round_cooperators >= m:
            prob = 0.7
            if k > 2:
                prob = min(0.85, prob + (k - 2) * 0.05)
            if random.random() < prob:
                return Action.C
            else:
                return Action.D
        else:
            if last_round_cooperators >= m - 2:
                if recent_rounds_to_check >= 2:
                    prev_round_cooperators = sum(history.opponent_actions[-2, :]) + int(history.my_actions[-2])
                    if last_round_cooperators > prev_round_cooperators:
                        return Action.C
            return Action.D

class Strategy_COOPERATIVE_92(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperation Strategy (ATCS)
    
    Balances cooperative intent with adaptive realism by using dynamic cooperation
    thresholds based on recent success and maintaining cooperative momentum while
    protecting against exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.base_threshold = self.m / self.n
        self.consecutive_failures = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        last_round_cooperation_rate = last_round_cooperators / self.n
        last_round_success = last_round_cooperators >= self.m
        if last_round_success:
            self.consecutive_failures = 0
        else:
            self.consecutive_failures += 1
        if current_round == self.r - 1:
            threshold_for_final = (self.m - 1) / self.n
            if last_round_cooperation_rate >= threshold_for_final:
                return Action.C
            if history.round_number >= 3:
                recent_rounds = min(3, history.round_number)
                recent_successes = 0
                for i in range(recent_rounds):
                    round_cooperators = sum(history.opponent_actions[-(i + 1), :])
                    if history.my_actions[-(i + 1)]:
                        round_cooperators += 1
                    if round_cooperators >= self.m:
                        recent_successes += 1
                if recent_successes >= 2:
                    return Action.C
            return Action.D
        momentum_adjustment = 0.2 if last_round_success else -0.1
        cooperation_threshold = max(0.3, min(0.8, self.base_threshold + momentum_adjustment))
        if self.n <= 4:
            cooperation_threshold -= 0.1
        if self.base_threshold > 0.7:
            cooperation_threshold -= 0.05
        if current_round >= self.r - 3:
            cooperation_threshold -= 0.1
        should_cooperate = last_round_cooperation_rate >= cooperation_threshold or self.consecutive_failures < 2
        return Action.C if should_cooperate else Action.D

class Strategy_COOPERATIVE_93(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperative Strategy (ATCS)
    
    Balances cooperative intent with adaptive realism. Starts optimistically,
    learns from group behavior patterns, and maintains cooperation when feasible
    while protecting against systematic exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.cooperation_history = []
        self.historical_cooperation_rate = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number + 1
        if history.round_number > 0:
            last_round_cooperators = int(np.sum(history.opponent_actions[-1, :]))
            if history.my_actions[-1]:
                last_round_cooperators += 1
            self.cooperation_history.append(last_round_cooperators)
        if current_round <= 3:
            if current_round == 1:
                return Action.C
            else:
                threshold = max(1, math.floor(self.m / 2))
                if len(self.cooperation_history) > 0 and self.cooperation_history[-1] >= threshold:
                    return Action.C
                else:
                    return Action.C
        if current_round >= self.r - 1:
            if current_round == self.r - 1:
                if len(self.cooperation_history) > 0:
                    avg_cooperation_rate = np.mean(self.cooperation_history) / self.n
                    if avg_cooperation_rate >= (self.m + 1) / self.n:
                        return Action.C
                return Action.D
            else:
                if len(self.cooperation_history) > 0 and self.cooperation_history[-1] >= self.m and (self.cooperation_history[-1] >= self.m - 1):
                    return Action.C
                return Action.D
        recent_rounds = min(3, len(self.cooperation_history))
        if recent_rounds == 0:
            return Action.C
        recent_cooperators = sum(self.cooperation_history[-recent_rounds:])
        base_expectation = self.m + 1
        recent_cooperation_rate = recent_cooperators / (recent_rounds * self.n)
        if len(self.cooperation_history) > recent_rounds:
            historical_data = self.cooperation_history[:-recent_rounds]
            historical_avg = np.mean(historical_data) / self.n if historical_data else recent_cooperation_rate
        else:
            historical_avg = recent_cooperation_rate
        trend_adjustment = (recent_cooperation_rate - historical_avg) * self.n
        adaptive_threshold = base_expectation + trend_adjustment
        adaptive_threshold = max(self.m, min(self.n - 1, adaptive_threshold))
        cooperation_threshold = max(self.m, adaptive_threshold)
        if recent_cooperators >= cooperation_threshold * recent_rounds / 3:
            return Action.C
        expected_recent = cooperation_threshold * recent_rounds / 3
        cooperation_deficit = expected_recent - recent_cooperators
        if cooperation_deficit <= 1:
            return Action.C
        elif cooperation_deficit <= 3:
            if random.random() < 0.7:
                return Action.C
            else:
                return Action.D
        else:
            if len(self.cooperation_history) >= 3:
                if recent_rounds >= 2:
                    prev_period = self.cooperation_history[-(recent_rounds + 1):-1] if len(self.cooperation_history) > recent_rounds else []
                    if prev_period:
                        prev_avg = np.mean(prev_period)
                        current_avg = np.mean(self.cooperation_history[-recent_rounds:])
                        if current_avg >= prev_avg * 1.5:
                            return Action.C
            return Action.D

class Strategy_COOPERATIVE_94(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) - Balances cooperation with self-protection by adapting 
    to observed group behavior while maintaining a fundamentally cooperative orientation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_failures = 0
        self.last_forgiveness_round = -10

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        previous_round = history.round_number - 1
        cooperators_previous = sum(history.opponent_actions[previous_round, :])
        if history.my_actions[previous_round]:
            cooperators_previous += 1
        cooperation_rate = cooperators_previous / n
        threshold_rate = m / n
        buffer = 0.2
        forgiveness_buffer = 0.1
        conservative_adjustment = 0.0
        if n <= 4:
            buffer = 0.1
        if threshold_rate > 0.7 and current_round <= 4:
            buffer = 0.3
        if k <= 1.5:
            conservative_adjustment = 0.1
        if current_round == r:
            if cooperation_rate >= threshold_rate - forgiveness_buffer:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= threshold_rate:
            self.consecutive_failures = 0
            return Action.C
        elif cooperation_rate >= threshold_rate - buffer + conservative_adjustment:
            self.consecutive_failures = 0
            return Action.C
        else:
            self.consecutive_failures += 1
            should_forgive = self.consecutive_failures >= 2 and current_round < r - 2 and (current_round - self.last_forgiveness_round >= 3)
            if should_forgive:
                self.last_forgiveness_round = current_round
                self.consecutive_failures = 0
                return Action.C
            else:
                return Action.D

class Strategy_COOPERATIVE_95(BaseStrategy):
    """
    Adaptive Threshold Guardian: A cooperative strategy that balances cooperation with strategic 
    adaptation to opponent behavior. Starts cooperatively, adapts based on threshold proximity,
    and includes forgiveness mechanisms while protecting against exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = history.round_number + 1
        look_back = min(3, history.round_number)
        if history.round_number >= 5 and n >= 10:
            look_back = min(5, history.round_number)
        recent_rounds = history.opponent_actions[-look_back:, :]
        recent_my_actions = history.my_actions[-look_back:]
        recent_cooperators_per_round = []
        for i in range(look_back):
            round_cooperators = np.sum(recent_rounds[i, :]) + (1 if recent_my_actions[i] else 0)
            recent_cooperators_per_round.append(round_cooperators)
        recent_cooperators = np.mean(recent_cooperators_per_round)
        cooperation_rate = recent_cooperators / n
        threshold_proximity = recent_cooperators / m
        if current_round == r:
            if recent_cooperators >= m:
                return Action.C
            else:
                return Action.D
        coop_threshold_adjust = 0.0
        if k > 2.5:
            coop_threshold_adjust = 0.1
        m_ratio = m / n
        if n <= 3:
            last_round_cooperators = np.sum(history.opponent_actions[-1, :]) + (1 if history.my_actions[-1] else 0)
            if last_round_cooperators >= m:
                return Action.C
            elif threshold_proximity >= 0.7:
                return Action.C
        if history.round_number >= 3:
            last_3_cooperators = []
            for i in range(3):
                round_idx = -(i + 1)
                round_cooperators = np.sum(history.opponent_actions[round_idx, :]) + (1 if history.my_actions[round_idx] else 0)
                last_3_cooperators.append(round_cooperators)
            if all((c < m for c in last_3_cooperators)) and cooperation_rate > 0.25:
                return Action.C
        if threshold_proximity >= 1.0:
            return Action.C
        elif threshold_proximity >= 0.8 - coop_threshold_adjust:
            if cooperation_rate >= 0.4 - coop_threshold_adjust:
                return Action.C
            else:
                return Action.D
        elif threshold_proximity >= 0.6 - coop_threshold_adjust:
            threshold = 0.5 - coop_threshold_adjust
            if m_ratio < 0.4:
                threshold -= 0.1
            elif m_ratio > 0.7:
                threshold += 0.1
            if cooperation_rate >= threshold:
                return Action.C
            else:
                return Action.D
        else:
            probe_condition = current_round % 4 == 0 and cooperation_rate >= 0.3
            if m_ratio > 0.8 and current_round <= r // 3:
                probe_condition = probe_condition or cooperation_rate >= 0.2
            if probe_condition:
                return Action.C
            else:
                return Action.D

class Strategy_COOPERATIVE_96(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS) - balances cooperative intent 
    with adaptive self-protection, focusing on achieving the minimum threshold m
    rather than universal cooperation while being robust against exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if current_round == self.r:
            return Action.D
        cooperators_last_round = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            cooperators_last_round += 1
        cooperation_rate = cooperators_last_round / self.n
        my_contribution_needed = self._is_my_cooperation_critical(history)
        exploitation_detected = self._recent_exploitation_detected(history)
        trending_up = self._cooperation_trending_up(history)
        buffer = min(2, self.n - self.m)
        safe_threshold = (self.m + buffer) / self.n
        prob_adjustment = 0.0
        if self.m / self.n > 0.7:
            prob_adjustment += 0.15
        elif self.m <= 3:
            prob_adjustment -= 0.1
        if self.k > 3:
            prob_adjustment += 0.1
        early_game_bonus = 0.1 if current_round <= 3 else 0.0
        late_game_penalty = 0.1 if current_round > self.r - 3 else 0.0
        if cooperation_rate >= safe_threshold:
            base_prob = min(0.9, cooperation_rate + 0.1)
            final_prob = base_prob + prob_adjustment + early_game_bonus - late_game_penalty
        elif my_contribution_needed:
            if exploitation_detected:
                base_prob = 0.6
            else:
                base_prob = 0.8
            final_prob = base_prob + prob_adjustment + early_game_bonus - late_game_penalty
        else:
            if trending_up:
                base_prob = 0.7
            else:
                base_prob = 0.3
            final_prob = base_prob + prob_adjustment + early_game_bonus - late_game_penalty
        final_prob = max(0.0, min(1.0, final_prob))
        return Action.C if random.random() < final_prob else Action.D

    def _is_my_cooperation_critical(self, history: PlayerHistory) -> bool:
        """Check if my cooperation could be critical for reaching threshold."""
        cooperators_last_round = sum(history.opponent_actions[-1, :])
        if cooperators_last_round == self.m - 1:
            return True
        if cooperators_last_round == self.m and history.my_actions[-1]:
            return True
        return False

    def _recent_exploitation_detected(self, history: PlayerHistory) -> bool:
        """Detect if there has been recent exploitation (defection while threshold met)."""
        exploitation_incidents = 0
        rounds_to_check = min(3, len(history.my_actions))
        for i in range(rounds_to_check):
            round_idx = -(i + 1)
            total_cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                total_cooperators += 1
            if total_cooperators >= self.m:
                defectors = self.n - total_cooperators
                if defectors > 0:
                    exploitation_incidents += 1
        return exploitation_incidents >= 2

    def _cooperation_trending_up(self, history: PlayerHistory) -> bool:
        """Check if cooperation is trending upward."""
        rounds_played = len(history.my_actions)
        if rounds_played < 3:
            cooperators_last = sum(history.opponent_actions[-1, :])
            if history.my_actions[-1]:
                cooperators_last += 1
            return cooperators_last / self.n > 0.4
        cooperators_last = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            cooperators_last += 1
        cooperation_rate_last = cooperators_last / self.n
        cooperators_3_ago = sum(history.opponent_actions[-3, :])
        if history.my_actions[-3]:
            cooperators_3_ago += 1
        cooperation_rate_3_ago = cooperators_3_ago / self.n
        trend = cooperation_rate_last - cooperation_rate_3_ago
        return trend > 0.1

class Strategy_COOPERATIVE_97(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperative Strategy (ATCS)
    
    Balances cooperative intent with adaptive responsiveness to observed behavior patterns.
    Uses threshold structure strategically while learning from opponents' behavior.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.alpha = 1.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return self._first_round_decision()
        coop_probs = self._calculate_cooperation_probabilities(history)
        expected_cooperators = sum(coop_probs)
        threshold = self.game_description.m - 1
        threshold = self._adjust_threshold_for_momentum(threshold, history)
        if expected_cooperators >= threshold:
            return Action.C
        elif abs(expected_cooperators - threshold) <= 0.5:
            return self._apply_tie_breaking_rules(history)
        else:
            return Action.D

    def _first_round_decision(self):
        """Decision logic for the first round with no history."""
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        expected_cooperators = n * 0.5
        prob_success = 1.0 if expected_cooperators >= m else expected_cooperators / m
        return Action.C if k * prob_success > 1 else Action.D

    def _calculate_cooperation_probabilities(self, history):
        """Calculate cooperation probability for each opponent based on their history."""
        n_opponents = self.game_description.n_players - 1
        coop_probs = []
        for opponent_idx in range(n_opponents):
            opponent_actions = history.opponent_actions[:, opponent_idx]
            prob = self._calculate_weighted_cooperation_probability(opponent_actions, history)
            prob = self._adjust_for_recent_trends(prob, opponent_actions)
            prob = self._apply_anti_exploitation_adjustment(prob, opponent_actions, history)
            coop_probs.append(prob)
        return coop_probs

    def _calculate_weighted_cooperation_probability(self, opponent_actions, history):
        """Calculate weighted cooperation probability with recent behavior emphasis."""
        if len(opponent_actions) == 0:
            return 0.5
        cooperations = sum(opponent_actions)
        total_rounds = len(opponent_actions)
        base_prob = (cooperations + self.alpha) / (total_rounds + 2 * self.alpha)
        if total_rounds >= 3:
            recent_weights = [0.5, 0.3, 0.2]
            recent_actions = opponent_actions[-3:]
            weighted_recent = sum((action * weight for action, weight in zip(recent_actions, recent_weights)))
            blend_factor = 0.6 if total_rounds >= 5 else 0.4
            base_prob = blend_factor * weighted_recent + (1 - blend_factor) * base_prob
        return max(0.0, min(1.0, base_prob))

    def _adjust_for_recent_trends(self, prob, opponent_actions):
        """Adjust probability based on recent cooperation trends."""
        if len(opponent_actions) < 3:
            return prob
        recent_3 = opponent_actions[-3:]
        if len(recent_3) >= 3:
            trend_1 = sum(recent_3[-2:]) - sum(recent_3[-3:-1])
            if trend_1 > 0:
                prob = min(1.0, prob + 0.1)
            elif trend_1 < 0:
                prob = max(0.0, prob - 0.1)
        return prob

    def _apply_anti_exploitation_adjustment(self, prob, opponent_actions, history):
        """Reduce trust in players who defect when cooperation threshold is safely exceeded."""
        if len(opponent_actions) < 3:
            return prob
        free_rider_penalty = 0
        recent_rounds = min(5, len(opponent_actions))
        for i in range(-recent_rounds, 0):
            round_cooperators = sum(history.opponent_actions[i, :]) + (1 if history.my_actions[i] else 0)
            if round_cooperators > self.game_description.m + 1 and (not opponent_actions[i]):
                free_rider_penalty += 0.1
        return max(0.0, prob - free_rider_penalty)

    def _adjust_threshold_for_momentum(self, threshold, history):
        """Adjust cooperation threshold based on group momentum."""
        if len(history.my_actions) < 3:
            return threshold
        recent_successes = 0
        recent_failures = 0
        for i in range(-min(3, len(history.my_actions)), 0):
            round_cooperators = sum(history.opponent_actions[i, :]) + (1 if history.my_actions[i] else 0)
            if round_cooperators >= self.game_description.m:
                recent_successes += 1
            else:
                recent_failures += 1
        if recent_successes > recent_failures:
            threshold = max(0, threshold - 0.5)
        elif recent_failures >= 2:
            threshold = min(self.game_description.n_players - 1, threshold + 0.5)
        return threshold

    def _apply_tie_breaking_rules(self, history):
        """Apply tie-breaking rules when expected cooperators is near threshold."""
        if len(history.my_actions) >= 2:
            recent_2_total_coop = []
            for i in range(-2, 0):
                round_cooperators = sum(history.opponent_actions[i, :]) + (1 if history.my_actions[i] else 0)
                recent_2_total_coop.append(round_cooperators)
            if len(recent_2_total_coop) == 2 and recent_2_total_coop[1] > recent_2_total_coop[0]:
                return Action.C
        if len(history.my_actions) >= 5:
            recent_my_coop_rate = sum(history.my_actions[-5:]) / 5
            if recent_my_coop_rate > 0.6:
                return Action.C
        return Action.D

class Strategy_COOPERATIVE_98(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS)
    
    Balances cooperative intentions with adaptive learning, starting optimistically
    but learning from experience to adjust cooperation levels dynamically based on
    observed cooperation rates and success patterns.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_rate = 0.5
        self.success_rate = 0.5
        self.recovery_attempts = 0
        self.crisis_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        self._update_metrics(history)
        round_num = state.round_number + 1
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        predicted_cooperators = self.cooperation_rate * n
        if self.success_rate > 0.7:
            return Action.C
        if predicted_cooperators >= m - 1:
            return Action.C
        if predicted_cooperators >= m + 1:
            return Action.C
        if self._in_crisis_mode() and self.recovery_attempts < 2:
            self.recovery_attempts += 1
            return Action.C
        if round_num <= 3 and self.cooperation_rate > 0.3:
            return Action.C
        if round_num == r and self.success_rate > 0.4 and (predicted_cooperators >= m - 1):
            return Action.C
        return Action.D

    def _update_metrics(self, history: PlayerHistory):
        """Update cooperation rate and success rate based on observed history."""
        if len(history.my_actions) == 0:
            return
        last_round_idx = len(history.my_actions) - 1
        my_last_action = history.my_actions[last_round_idx]
        opponent_cooperators = np.sum(history.opponent_actions[last_round_idx, :])
        total_cooperators = opponent_cooperators + (1 if my_last_action else 0)
        current_coop_rate = total_cooperators / self.game_description.n_players
        self.cooperation_rate = 0.7 * self.cooperation_rate + 0.3 * current_coop_rate
        threshold_met = total_cooperators >= self.game_description.m
        self.success_rate = 0.6 * self.success_rate + 0.4 * (1.0 if threshold_met else 0.0)
        if self.success_rate < 0.2:
            self.crisis_rounds += 1
        else:
            self.crisis_rounds = 0
            self.recovery_attempts = 0

    def _in_crisis_mode(self) -> bool:
        """Check if we're in crisis mode (low success rate for multiple rounds)."""
        return self.crisis_rounds >= 3

class Strategy_COOPERATIVE_99(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperative Strategy that aims to maximize collective welfare
    while protecting against exploitation through adaptive cooperation based on observed
    group behavior and strategic timing.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold = self.m
        self.adjustment_factor = 0
        self.last_adjustment_round = 0
        self.exploitation_counter = 0
        self.low_participation_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number + 1
        if current_round == self.r:
            predicted_cooperators = self._predict_cooperators(history)
            if predicted_cooperators >= self.m:
                return Action.D
            else:
                return Action.C
        if current_round - self.last_adjustment_round >= 4:
            self._update_threshold(history)
            self.last_adjustment_round = current_round
        predicted_cooperators = self._predict_cooperators(history)
        cooperation_trend = self._analyze_cooperation_trend(history)
        if self._check_exploitation(history):
            self.exploitation_counter += 1
        else:
            self.exploitation_counter = max(0, self.exploitation_counter - 1)
        recent_coop_rate = self._get_recent_cooperation_rate(history, 3)
        if recent_coop_rate < 0.3:
            self.low_participation_counter += 1
        else:
            self.low_participation_counter = max(0, self.low_participation_counter - 1)
        if recent_coop_rate > 0.8 and self.low_participation_counter == 0:
            if random.random() < 0.1:
                return Action.D
        if self.low_participation_counter >= 3:
            if predicted_cooperators >= self.m - 1:
                return Action.C
            else:
                return Action.D
        exploitation_penalty = min(0.3, self.exploitation_counter * 0.1)
        if predicted_cooperators >= self.threshold:
            coop_prob = 0.8 - exploitation_penalty
            return Action.C if random.random() < coop_prob else Action.D
        elif predicted_cooperators >= self.m - 1:
            return Action.C
        elif cooperation_trend > 0:
            coop_prob = 0.6 - exploitation_penalty
            return Action.C if random.random() < coop_prob else Action.D
        else:
            return Action.D

    def _predict_cooperators(self, history: PlayerHistory) -> float:
        """Predict number of cooperators using weighted average of recent rounds."""
        if history.round_number == 0:
            return self.n * 0.5
        total_weight = 0
        weighted_sum = 0
        for t in range(history.round_number):
            weight = 0.7 ** (history.round_number - 1 - t)
            cooperators_in_round = np.sum(history.opponent_actions[t, :])
            if history.my_actions[t]:
                cooperators_in_round += 1
            weighted_sum += cooperators_in_round * weight
            total_weight += weight
        avg_cooperation_rate = weighted_sum / total_weight / self.n
        return avg_cooperation_rate * self.n

    def _analyze_cooperation_trend(self, history: PlayerHistory) -> float:
        """Analyze if cooperation is improving, stable, or declining."""
        if history.round_number < 6:
            return 0
        recent_start = max(0, history.round_number - 3)
        previous_start = max(0, history.round_number - 6)
        previous_end = max(0, history.round_number - 3)
        if previous_end <= previous_start:
            return 0
        recent_coop = 0
        recent_count = 0
        for t in range(recent_start, history.round_number):
            cooperators = np.sum(history.opponent_actions[t, :])
            if history.my_actions[t]:
                cooperators += 1
            recent_coop += cooperators / self.n
            recent_count += 1
        previous_coop = 0
        previous_count = 0
        for t in range(previous_start, previous_end):
            cooperators = np.sum(history.opponent_actions[t, :])
            if history.my_actions[t]:
                cooperators += 1
            previous_coop += cooperators / self.n
            previous_count += 1
        if recent_count == 0 or previous_count == 0:
            return 0
        recent_rate = recent_coop / recent_count
        previous_rate = previous_coop / previous_count
        return recent_rate - previous_rate

    def _update_threshold(self, history: PlayerHistory) -> None:
        """Update adaptive threshold based on recent performance."""
        if history.round_number < 3:
            return
        exceeds_threshold = 0
        fails_threshold = 0
        for t in range(max(0, history.round_number - 4), history.round_number):
            cooperators = np.sum(history.opponent_actions[t, :])
            if history.my_actions[t]:
                cooperators += 1
            if cooperators >= self.threshold + 2:
                exceeds_threshold += 1
            elif cooperators < self.m:
                fails_threshold += 1
        if exceeds_threshold >= 3:
            self.threshold = min(self.n - 1, self.threshold + 1)
        elif fails_threshold >= 2:
            self.threshold = max(self.m, self.threshold - 1)

    def _check_exploitation(self, history: PlayerHistory) -> bool:
        """Check if we're being exploited (cooperating much more than others)."""
        if history.round_number < 3:
            return False
        recent_rounds = min(3, history.round_number)
        start_round = history.round_number - recent_rounds
        my_coop_count = np.sum(history.my_actions[start_round:])
        my_coop_rate = my_coop_count / recent_rounds
        group_coop_count = 0
        for t in range(start_round, history.round_number):
            group_coop_count += np.sum(history.opponent_actions[t, :])
        group_coop_rate = group_coop_count / (recent_rounds * (self.n - 1))
        return my_coop_rate > group_coop_rate + 0.2

    def _get_recent_cooperation_rate(self, history: PlayerHistory, rounds: int) -> float:
        """Get cooperation rate over recent rounds."""
        if history.round_number == 0:
            return 0.5
        recent_rounds = min(rounds, history.round_number)
        start_round = history.round_number - recent_rounds
        total_cooperators = 0
        for t in range(start_round, history.round_number):
            cooperators = np.sum(history.opponent_actions[t, :])
            if history.my_actions[t]:
                cooperators += 1
            total_cooperators += cooperators
        return total_cooperators / (recent_rounds * self.n)

class Strategy_COOPERATIVE_100(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperative Strategy (ATCS)
    
    Balances cooperative intent with adaptive pragmatism. Aims to foster cooperation
    while protecting against exploitation, using the game's threshold structure to
    make intelligent decisions based on observable patterns.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number + 1
        prev_cooperators = int(sum(history.opponent_actions[-1, :])) + int(history.my_actions[-1])
        if current_round == r:
            if prev_cooperators >= m - 2:
                return Action.C
            total_rounds = history.round_number
            total_my_coops = sum(history.my_actions)
            total_opp_coops = sum((sum(history.opponent_actions[i, :]) for i in range(total_rounds)))
            overall_coop_rate = (total_my_coops + total_opp_coops) / (total_rounds * n)
            if overall_coop_rate >= 0.5:
                return Action.C
            else:
                return Action.D
        if prev_cooperators >= m:
            return Action.C
        if prev_cooperators == m - 1:
            return Action.C
        rounds_completed = history.round_number
        window_size = min(3, rounds_completed)
        recent_total_coops = 0
        recent_total_possible = 0
        for i in range(max(0, rounds_completed - window_size), rounds_completed):
            recent_total_coops += sum(history.opponent_actions[i, :]) + history.my_actions[i]
            recent_total_possible += n
        recent_coop_rate = recent_total_coops / recent_total_possible if recent_total_possible > 0 else 0
        trend = 0
        if rounds_completed >= 2:
            window1_start = max(0, rounds_completed - window_size)
            window1_end = rounds_completed
            window2_size = min(window_size, window1_start)
            if window2_size > 0:
                window2_start = max(0, window1_start - window2_size)
                window2_end = window1_start
                window1_coops = sum((sum(history.opponent_actions[i, :]) + history.my_actions[i] for i in range(window1_start, window1_end)))
                window1_rate = window1_coops / (window_size * n)
                window2_coops = sum((sum(history.opponent_actions[i, :]) + history.my_actions[i] for i in range(window2_start, window2_end)))
                window2_rate = window2_coops / (window2_size * n)
                trend = window1_rate - window2_rate
        if trend >= 0 and recent_coop_rate > 0.4:
            return Action.C
        if recent_coop_rate < 0.2 and rounds_completed >= 2:
            sustained_low = True
            check_rounds = min(2, rounds_completed)
            for i in range(rounds_completed - check_rounds, rounds_completed):
                round_coops = sum(history.opponent_actions[i, :]) + history.my_actions[i]
                round_rate = round_coops / n
                if round_rate >= 0.2:
                    sustained_low = False
                    break
            if sustained_low:
                return Action.D
        if rounds_completed >= 2:
            last_round_coops = sum(history.opponent_actions[-1, :]) + history.my_actions[-1]
            last_round_rate = last_round_coops / n
            prev_round_coops = sum(history.opponent_actions[-2, :]) + history.my_actions[-2]
            prev_round_rate = prev_round_coops / n
            if prev_round_rate - last_round_rate > 0.25:
                return Action.D
        return Action.C

class Strategy_COOPERATIVE_101(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperation Strategy (ATCS)
    
    Balances cooperative intent with adaptive self-protection. Starts cooperatively,
    monitors collective behavior patterns, and dynamically adjusts cooperation levels
    based on observed group dynamics while maintaining baseline cooperation commitment.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_number = state.round_number
        initial_phase_length = max(3, self.r // 5)
        if round_number < initial_phase_length:
            return Action.C
        recent_rounds = min(5, max(1, round_number // 3))
        recent_start = max(0, round_number - recent_rounds)
        total_cooperators = 0
        successful_rounds = 0
        for i in range(recent_start, round_number):
            round_cooperators = int(history.my_actions[i]) + sum(history.opponent_actions[i, :])
            total_cooperators += round_cooperators
            if round_cooperators >= self.m:
                successful_rounds += 1
        recent_cooperation_rate = total_cooperators / (self.n * recent_rounds)
        recent_success_rate = successful_rounds / recent_rounds if recent_rounds > 0 else 0
        avg_recent_cooperators = total_cooperators / recent_rounds if recent_rounds > 0 else 0
        base_prob = 0.7
        threshold_rate = self.m / self.n
        if recent_cooperation_rate >= threshold_rate + 0.1:
            base_prob += 0.15
        elif recent_cooperation_rate < threshold_rate - 0.1:
            base_prob -= 0.25
        if recent_success_rate > 0.7:
            base_prob += 0.1
        elif recent_success_rate < 0.4:
            base_prob -= 0.2
        if self.m - 2 <= avg_recent_cooperators <= self.m + 1:
            base_prob += 0.15
        if round_number > self.r * 0.9:
            if recent_success_rate < 0.3:
                base_prob -= 0.3
            else:
                base_prob += 0.1
        if self.n <= 4:
            base_prob += 0.1
        if self.m / self.n > 0.7:
            base_prob += 0.15
        if self.r <= 5 and round_number >= 2:
            if round_number > 0:
                prev_cooperators = int(history.my_actions[round_number - 1]) + sum(history.opponent_actions[round_number - 1, :])
                if prev_cooperators >= self.m:
                    base_prob = 0.8
                else:
                    base_prob = 0.5
        if self.k < 1.5:
            base_prob -= 0.1
        cooperation_probability = max(0.1, min(0.95, base_prob))
        return Action.C if random.random() < cooperation_probability else Action.D

class Strategy_COOPERATIVE_102(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperative Strategy (ATCS)
    
    Balances cooperative intent with adaptive realism. Starts optimistically but learns 
    from group behavior to maintain sustainable cooperation while protecting against exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = float(self.m)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if current_round == self.r - 1:
            return self._final_round_decision(history)
        last_round_cooperators = self._count_total_cooperators(history, -1)
        self._update_threshold(last_round_cooperators)
        if self._should_cooperate(history, last_round_cooperators):
            return Action.C
        else:
            return Action.D

    def _count_total_cooperators(self, history: PlayerHistory, round_idx: int) -> int:
        """Count total cooperators (including self) in a given round."""
        opponent_cooperators = sum(history.opponent_actions[round_idx, :])
        my_cooperation = 1 if history.my_actions[round_idx] else 0
        return int(opponent_cooperators + my_cooperation)

    def _update_threshold(self, last_round_cooperators: int):
        """Update cooperation threshold based on observed behavior."""
        cooperation_rate = last_round_cooperators / self.n
        if self.n <= 4:
            adjustment = 0.25
        else:
            adjustment = 0.5
        if cooperation_rate >= self.m / self.n:
            self.threshold = max(self.m, self.threshold - adjustment)
        else:
            self.threshold = min(self.n - 1, self.threshold + 1)

    def _should_cooperate(self, history: PlayerHistory, last_round_cooperators: int) -> bool:
        """Determine if we should cooperate based on multiple conditions."""
        if last_round_cooperators >= self.threshold:
            return True
        if len(history.my_actions) >= 2:
            prev_cooperators = self._count_total_cooperators(history, -2)
            if last_round_cooperators > prev_cooperators:
                return True
        if last_round_cooperators == self.m - 1:
            return True
        if last_round_cooperators == self.m - 1:
            return True
        if self.m > self.n / 2 and len(history.my_actions) < 3:
            return True
        if self.n <= 4:
            recent_rounds = min(3, len(history.my_actions))
            recent_cooperation_rate = sum((self._count_total_cooperators(history, -i - 1) for i in range(recent_rounds))) / (recent_rounds * self.n)
            if recent_cooperation_rate >= 0.5:
                return True
        if self.r > 10 and len(history.my_actions) % 5 == 0:
            if self.threshold > self.m + 2:
                self.threshold = max(self.m, self.threshold - 1)
                return True
        return False

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """Special logic for the final round."""
        total_rounds = len(history.my_actions)
        total_cooperators = sum((self._count_total_cooperators(history, i) for i in range(total_rounds)))
        avg_cooperation_rate = total_cooperators / (total_rounds * self.n)
        successful_rounds = sum((1 for i in range(total_rounds) if self._count_total_cooperators(history, i) >= self.m))
        success_rate = successful_rounds / total_rounds
        recent_improvement = False
        if total_rounds >= 6:
            recent_avg = sum((self._count_total_cooperators(history, -i - 1) for i in range(3))) / 3
            earlier_avg = sum((self._count_total_cooperators(history, -i - 4) for i in range(3))) / 3
            recent_improvement = recent_avg > earlier_avg
        if avg_cooperation_rate >= self.m / self.n or success_rate >= 0.6 or recent_improvement:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_103(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperative Strategy (ATCS)
    
    Balances cooperative intent with adaptive responsiveness by:
    1. Initial trust building through cooperation
    2. Dynamic threshold adjustment based on group behavior
    3. Anti-exploitation protection with cooperation encouragement
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.trust_building_rounds = math.ceil(game_description.n_rounds / 4)
        self.base_threshold = game_description.m / game_description.n_players
        self.revival_mode = False
        self.revival_rounds_left = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if current_round < self.trust_building_rounds:
            return Action.C
        recent_rounds = min(5, current_round)
        recent_opponent_actions = history.opponent_actions[-recent_rounds:, :]
        my_recent_actions = history.my_actions[-recent_rounds:]
        total_recent_cooperations = np.sum(recent_opponent_actions) + np.sum(my_recent_actions)
        total_recent_decisions = recent_rounds * self.game_description.n_players
        recent_coop_rate = total_recent_cooperations / total_recent_decisions
        if recent_rounds >= 3:
            last_3_rounds = min(3, current_round)
            last_3_opponent_actions = history.opponent_actions[-last_3_rounds:, :]
            my_last_3_actions = history.my_actions[-last_3_rounds:]
            last_3_cooperations = np.sum(last_3_opponent_actions) + np.sum(my_last_3_actions)
            last_3_decisions = last_3_rounds * self.game_description.n_players
            last_3_coop_rate = last_3_cooperations / last_3_decisions
            if last_3_coop_rate < 0.3 and (not self.revival_mode):
                self.revival_mode = True
                self.revival_rounds_left = 2
        if self.revival_mode and self.revival_rounds_left > 0:
            self.revival_rounds_left -= 1
            if self.revival_rounds_left == 0:
                self.revival_mode = False
            return Action.C
        adjusted_base_threshold = self.base_threshold
        if self.game_description.m == self.game_description.n_players - 1:
            adjusted_base_threshold = max(0, self.base_threshold - 0.1)
        if recent_coop_rate >= adjusted_base_threshold + 0.1:
            cooperation_threshold = max(0, adjusted_base_threshold - 0.1)
        elif recent_coop_rate >= adjusted_base_threshold:
            cooperation_threshold = adjusted_base_threshold
        else:
            cooperation_threshold = min(1.0, recent_coop_rate + 0.2)
        if current_round == self.game_description.n_rounds - 1:
            threshold_met_count = 0
            check_rounds = min(recent_rounds, current_round)
            for i in range(check_rounds):
                round_idx = current_round - 1 - i
                round_cooperators = np.sum(history.opponent_actions[round_idx, :])
                if history.my_actions[round_idx]:
                    round_cooperators += 1
                if round_cooperators >= self.game_description.m:
                    threshold_met_count += 1
            if threshold_met_count >= 0.8 * check_rounds:
                return Action.C
        if recent_coop_rate >= cooperation_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_104(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperation Strategy: "Progressive Trust Builder"
    
    Balances cooperation with protection against exploitation by adapting based on 
    observed group behavior and maintaining hope for collective success throughout the game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        prev_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            prev_cooperators += 1
        if current_round == r - 1:
            if prev_cooperators >= m:
                return Action.C
            if prev_cooperators >= m - 1:
                return Action.C
            return Action.D
        trust_threshold = max(1, m - 2)
        if prev_cooperators >= trust_threshold:
            return Action.C
        success_count = 0
        total_rounds = len(history.my_actions)
        for round_idx in range(total_rounds):
            round_cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                round_cooperators += 1
            if round_cooperators >= m:
                success_count += 1
        success_rate = success_count / total_rounds if total_rounds > 0 else 0
        if success_rate >= 0.3:
            return Action.C
        if total_rounds >= 2:
            prev_prev_cooperators = sum(history.opponent_actions[-2, :])
            if history.my_actions[-2]:
                prev_prev_cooperators += 1
            if prev_cooperators > prev_prev_cooperators:
                return Action.C
        rounds_since_success = 0
        for i in range(total_rounds - 1, -1, -1):
            round_cooperators = sum(history.opponent_actions[i, :])
            if history.my_actions[i]:
                round_cooperators += 1
            if round_cooperators >= m:
                break
            rounds_since_success += 1
        if rounds_since_success <= 2:
            return Action.C
        if total_rounds >= 2:
            my_recent_defections = 0
            for i in range(max(0, total_rounds - 2), total_rounds):
                if not history.my_actions[i]:
                    my_recent_defections += 1
            if my_recent_defections >= 2:
                return Action.C
        return Action.D

class Strategy_COOPERATIVE_105(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperative Strategy (ATCS)
    
    Balances cooperative intentions with adaptive responsiveness to maintain 
    group cooperation while protecting against systematic exploitation. Uses
    conditional cooperation with forgiveness - starts cooperatively but adjusts
    based on collective behavior patterns.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if current_round <= 2:
            return self._cooperate_early_game(history)
        elif current_round >= self.r - 2:
            return self._cooperate_end_game(history)
        else:
            return self._main_strategy(history)

    def _cooperate_early_game(self, history: PlayerHistory) -> Action:
        """Handle early game cooperation (rounds 1-3)"""
        last_round_cooperators = self._count_cooperators_in_round(history, -1)
        min_threshold = max(1, self.m - 2)
        if last_round_cooperators < min_threshold:
            return Action.D
        return Action.C

    def _cooperate_end_game(self, history: PlayerHistory) -> Action:
        """Handle end game strategy (last 2 rounds)"""
        current_round = len(history.my_actions)
        if current_round == self.r - 2:
            main_rounds_start = 3
            if current_round > main_rounds_start:
                threshold_success_rate = self._calculate_threshold_success_rate(history, main_rounds_start, current_round - 1)
                return Action.C if threshold_success_rate >= 0.5 else Action.D
            else:
                return Action.C
        else:
            if current_round > 0:
                prev_cooperators = self._count_cooperators_in_round(history, -1)
                if prev_cooperators >= self.m:
                    return Action.C
                prev_coop_rate = prev_cooperators / self.n
                if prev_coop_rate >= (self.m - 2) / self.n:
                    return Action.C
            return Action.D

    def _main_strategy(self, history: PlayerHistory) -> Action:
        """Main strategy for middle rounds"""
        recent_coop_rate = self._calculate_recent_cooperation_rate(history)
        threshold_high = (self.m - 0.5) / self.n
        threshold_low = (self.m - 1.5) / self.n
        if self.n <= 4:
            threshold_high -= 0.1
            threshold_low -= 0.1
        elif self.m <= self.n / 3:
            threshold_high += 0.1
            threshold_low += 0.1
        if recent_coop_rate >= threshold_high:
            return Action.C
        elif recent_coop_rate >= threshold_low:
            my_recent_coop_rate = self._calculate_my_recent_cooperation_rate(history)
            if my_recent_coop_rate <= 0.7:
                return Action.C
        if self._should_forgive(history, recent_coop_rate):
            return Action.C
        return Action.D

    def _count_cooperators_in_round(self, history: PlayerHistory, round_idx: int) -> int:
        """Count total cooperators (including self) in a specific round"""
        if round_idx >= len(history.my_actions) or round_idx < -len(history.my_actions):
            return 0
        my_action = 1 if history.my_actions[round_idx] else 0
        opponent_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
        return my_action + opponent_cooperators

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate over recent rounds"""
        current_round = len(history.my_actions)
        lookback = min(3, current_round)
        if lookback == 0:
            return 0.0
        total_cooperators = 0
        for i in range(lookback):
            round_idx = current_round - 1 - i
            total_cooperators += self._count_cooperators_in_round(history, round_idx)
        return total_cooperators / (self.n * lookback)

    def _calculate_my_recent_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate my cooperation rate over recent rounds"""
        current_round = len(history.my_actions)
        lookback = min(3, current_round)
        if lookback == 0:
            return 0.0
        my_cooperations = 0
        for i in range(lookback):
            round_idx = current_round - 1 - i
            if history.my_actions[round_idx]:
                my_cooperations += 1
        return my_cooperations / lookback

    def _calculate_threshold_success_rate(self, history: PlayerHistory, start_round: int, end_round: int) -> float:
        """Calculate rate of threshold achievement in given range"""
        if start_round >= end_round:
            return 0.0
        successes = 0
        total_rounds = end_round - start_round
        for round_idx in range(start_round, end_round):
            if round_idx < len(history.my_actions):
                cooperators = self._count_cooperators_in_round(history, round_idx)
                if cooperators >= self.m:
                    successes += 1
        return successes / total_rounds if total_rounds > 0 else 0.0

    def _should_forgive(self, history: PlayerHistory, recent_coop_rate: float) -> bool:
        """Check if forgiveness mechanism should trigger"""
        current_round = len(history.my_actions)
        if current_round >= 2:
            if not history.my_actions[-1] and (not history.my_actions[-2]):
                if current_round >= 6:
                    older_coop_rate = self._calculate_cooperation_rate_in_range(history, current_round - 6, current_round - 3)
                    if recent_coop_rate - older_coop_rate >= 0.2:
                        return True
        return False

    def _calculate_cooperation_rate_in_range(self, history: PlayerHistory, start: int, end: int) -> float:
        """Calculate cooperation rate in a specific range of rounds"""
        if start >= end or start < 0:
            return 0.0
        total_cooperators = 0
        actual_rounds = 0
        for round_idx in range(start, min(end, len(history.my_actions))):
            total_cooperators += self._count_cooperators_in_round(history, round_idx)
            actual_rounds += 1
        return total_cooperators / (self.n * actual_rounds) if actual_rounds > 0 else 0.0

class Strategy_COOPERATIVE_106(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS)
    
    Balances cooperative intent with pragmatic adaptation, using conditional cooperation
    with learning. Adapts cooperation probability based on historical rates, trends,
    threshold proximity, and remaining rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.base_prob = min(0.8, (self.m + 2) / self.n)
        if self.m == self.n - 1:
            self.base_prob = 0.9
        elif self.k > 3:
            self.base_prob *= min(1.5, self.k / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C if random.random() < self.base_prob else Action.D
        round_num = history.round_number
        total_cooperations = np.sum(history.opponent_actions)
        total_opportunities = round_num * (self.n - 1)
        historical_rate = total_cooperations / total_opportunities if total_opportunities > 0 else 0
        recent_trend = 0
        if round_num >= 6:
            recent_cooperations = np.sum(history.opponent_actions[-3:])
            previous_cooperations = np.sum(history.opponent_actions[-6:-3])
            recent_trend = (recent_cooperations - previous_cooperations) / (3 * (self.n - 1))
        elif round_num >= 3:
            recent_cooperations = np.sum(history.opponent_actions[-3:])
            expected_cooperations = 3 * (self.n - 1) * historical_rate
            recent_trend = (recent_cooperations - expected_cooperations) / (3 * (self.n - 1))
        remaining_rounds = self.r - round_num
        endgame_factor = max(0.5, remaining_rounds / self.r)
        cooperation_prob = self.base_prob * (0.3 + 0.7 * historical_rate) * (1 + 0.2 * recent_trend) * endgame_factor
        if round_num > 0:
            last_round_cooperators = np.sum(history.opponent_actions[-1]) + (1 if history.my_actions[-1] else 0)
            if last_round_cooperators == self.m - 1:
                cooperation_prob = min(1.0, cooperation_prob * 1.5)
        if round_num >= 3:
            my_cooperation_rate = np.sum(history.my_actions) / round_num
            threshold_met_count = 0
            for r in range(round_num):
                round_cooperators = np.sum(history.opponent_actions[r]) + (1 if history.my_actions[r] else 0)
                if round_cooperators >= self.m:
                    threshold_met_count += 1
            threshold_met_rate = threshold_met_count / round_num
            if my_cooperation_rate > 0.8 and threshold_met_rate < 0.3:
                cooperation_prob -= 0.2
        if round_num >= 3:
            recent_threshold_met = False
            for r in range(max(0, round_num - 3), round_num):
                round_cooperators = np.sum(history.opponent_actions[r]) + (1 if history.my_actions[r] else 0)
                if round_cooperators >= self.m:
                    recent_threshold_met = True
                    break
            if not recent_threshold_met:
                cooperation_prob += 0.3
        if round_num >= 3 and historical_rate < 0.3:
            if round_num > 0:
                last_round_cooperators = np.sum(history.opponent_actions[-1])
                if last_round_cooperators < self.m - 1:
                    cooperation_prob *= 0.5
        if self.m == 2 and round_num > 0:
            last_round_cooperators = np.sum(history.opponent_actions[-1]) + (1 if history.my_actions[-1] else 0)
            if last_round_cooperators >= self.m:
                cooperation_prob += 0.1
        if remaining_rounds == 1:
            if historical_rate > self.m / self.n:
                cooperation_prob = 0.9
            elif round_num > 0:
                last_round_cooperators = np.sum(history.opponent_actions[-1]) + (1 if history.my_actions[-1] else 0)
                if last_round_cooperators >= self.m:
                    cooperation_prob = 0.95
                else:
                    cooperation_prob = historical_rate
        cooperation_prob = min(0.95, max(0.05, cooperation_prob))
        return Action.C if random.random() < cooperation_prob else Action.D

class Strategy_COOPERATIVE_107(BaseStrategy):
    """
    Adaptive Threshold Cooperative Strategy (ATCS) - Balances cooperative intent 
    with adaptive risk management, establishing cooperation while protecting against
    exploitation through dynamic threshold adjustment based on observed group behavior.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = history.round_number + 1
        if round_num <= 3:
            return Action.C
        total_cooperators = np.sum(history.opponent_actions)
        total_possible = history.round_number * (self.n - 1)
        cooperation_rate = total_cooperators / total_possible if total_possible > 0 else 0
        expected_cooperators = cooperation_rate * (self.n - 1)
        if cooperation_rate >= 0.7:
            reliability_threshold = self.m - 1
        elif cooperation_rate >= 0.4:
            reliability_threshold = self.m
        else:
            reliability_threshold = self.m + 1
        if history.round_number >= 3:
            recent_rounds = min(3, history.round_number)
            recent_cooperators = np.sum(history.opponent_actions[-recent_rounds:])
            recent_possible = recent_rounds * (self.n - 1)
            recent_cooperation_rate = recent_cooperators / recent_possible
            recent_trend = recent_cooperation_rate - cooperation_rate
            if recent_trend > 0.1:
                reliability_threshold -= 0.5
            elif recent_trend < -0.1:
                reliability_threshold += 0.5
        if self.n <= 4 and cooperation_rate < 0.6:
            reliability_threshold += 0.5
        if self.m > self.n / 2:
            reliability_threshold = max(reliability_threshold - 2, self.m - 2)
        if self.k < 1.5:
            reliability_threshold += 1
        if round_num >= self.r - 1:
            if round_num == self.r - 1:
                return Action.C if cooperation_rate > 0.5 else Action.D
            elif history.round_number > 0:
                last_round_cooperators = np.sum(history.opponent_actions[-1])
                return Action.C if last_round_cooperators >= self.m else Action.D
            else:
                return Action.D
        return Action.C if expected_cooperators >= reliability_threshold else Action.D

class Strategy_COOPERATIVE_108(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS)
    
    Balances cooperative intent with adaptive learning, starting cooperatively
    but adjusting based on observed group behavior. Uses cautious optimism
    to achieve collective success while protecting against exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        initial_phase_length = min(3, math.ceil(0.3 * self.r))
        if current_round < initial_phase_length:
            return Action.C
        recent_rounds = min(5, current_round)
        recent_cooperation_counts = []
        for i in range(max(0, current_round - recent_rounds), current_round):
            my_cooperation = 1 if history.my_actions[i] else 0
            opponent_cooperation = sum(history.opponent_actions[i, :])
            total_cooperators = my_cooperation + opponent_cooperation
            recent_cooperation_counts.append(total_cooperators)
        avg_cooperators = np.mean(recent_cooperation_counts) if recent_cooperation_counts else 0
        cooperation_rate = avg_cooperators / self.n
        expected_cooperators = cooperation_rate * (self.n - 1) + 1
        if expected_cooperators >= self.m:
            return Action.C
        if current_round > 0:
            last_round_opponent_cooperation = sum(history.opponent_actions[current_round - 1, :])
            last_round_cooperation_rate = last_round_opponent_cooperation / (self.n - 1)
            if last_round_cooperation_rate >= 0.6:
                return Action.C
        if current_round > 0:
            last_round_total = (1 if history.my_actions[current_round - 1] else 0) + sum(history.opponent_actions[current_round - 1, :])
            if self.m - last_round_total <= 2 and last_round_total < self.m:
                return Action.C
        if current_round >= 0.8 * self.r and cooperation_rate > 0.4:
            return Action.C
        if current_round >= 3:
            threshold_rate = self.m / self.n - 0.1
            consecutive_low = 0
            for i in range(max(0, current_round - 3), current_round):
                round_cooperators = (1 if history.my_actions[i] else 0) + sum(history.opponent_actions[i, :])
                round_rate = round_cooperators / self.n
                if round_rate < threshold_rate:
                    consecutive_low += 1
                else:
                    consecutive_low = 0
            if consecutive_low >= 3:
                return Action.D
        return Action.C

class Strategy_COOPERATIVE_109(BaseStrategy):
    """
    Adaptive Threshold Guardian: A cooperative strategy that balances reliability with strategic resilience.
    Cooperates during establishment phase, then adapts based on group success patterns and likely cooperators.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.establishment_phase_ratio = 0.2
        self.base_cooperation_threshold = 0.6
        self.consistent_cooperator_threshold = 0.7
        self.recent_rounds_window = 5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number
        total_rounds = self.game_description.n_rounds
        establishment_rounds = math.ceil(total_rounds * self.establishment_phase_ratio)
        if current_round < establishment_rounds:
            return Action.C
        recent_success_rate = self._calculate_recent_success_rate(history)
        likely_cooperators = self._estimate_likely_cooperators(history)
        cooperation_threshold = max(self.base_cooperation_threshold, recent_success_rate * 0.8)
        if self.game_description.m == self.game_description.n_players - 1:
            cooperation_threshold = 0.9
        elif self.game_description.m <= self.game_description.n_players * 0.25:
            cooperation_threshold *= 0.8
        if self._has_consecutive_failures(history, 3):
            cooperation_threshold += 0.2
        cooperation_likelihood = likely_cooperators / self.game_description.n_players
        rounds_remaining = total_rounds - current_round
        if cooperation_likelihood >= cooperation_threshold:
            return Action.C
        elif recent_success_rate > 0.4 and rounds_remaining > 3:
            return Action.C
        elif current_round == total_rounds - 1:
            if recent_success_rate > 0.5:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _calculate_recent_success_rate(self, history: PlayerHistory) -> float:
        """Calculate success rate over recent rounds with recency weighting."""
        current_round = history.round_number
        window_size = min(self.recent_rounds_window, current_round)
        if window_size == 0:
            return 0.5
        successful_rounds = 0
        total_weight = 0
        for i in range(window_size):
            round_idx = current_round - 1 - i
            if round_idx < 0:
                break
            my_action = history.my_actions[round_idx]
            opponent_cooperators = sum(history.opponent_actions[round_idx, :])
            total_cooperators = int(my_action) + opponent_cooperators
            weight = 1.0 / (i + 1)
            total_weight += weight
            if total_cooperators >= self.game_description.m:
                successful_rounds += weight
        return successful_rounds / total_weight if total_weight > 0 else 0.5

    def _estimate_likely_cooperators(self, history: PlayerHistory) -> float:
        """Estimate number of likely cooperators based on recent behavior patterns."""
        current_round = history.round_number
        window_size = min(self.recent_rounds_window, current_round)
        if window_size == 0:
            return self.game_description.n_players * 0.5
        likely_cooperators = 0.0
        n_opponents = self.game_description.n_players - 1
        for opponent_idx in range(n_opponents):
            recent_cooperations = 0
            rounds_analyzed = 0
            for i in range(window_size):
                round_idx = current_round - 1 - i
                if round_idx < 0:
                    break
                if history.opponent_actions[round_idx, opponent_idx]:
                    recent_cooperations += 1
                rounds_analyzed += 1
            if rounds_analyzed > 0:
                cooperation_rate = recent_cooperations / rounds_analyzed
                if cooperation_rate >= self.consistent_cooperator_threshold:
                    likely_cooperators += 1.0
                else:
                    likely_cooperators += cooperation_rate
        my_recent_cooperations = 0
        for i in range(window_size):
            round_idx = current_round - 1 - i
            if round_idx < 0:
                break
            if history.my_actions[round_idx]:
                my_recent_cooperations += 1
        my_cooperation_rate = my_recent_cooperations / window_size
        if my_cooperation_rate >= self.consistent_cooperator_threshold:
            likely_cooperators += 1.0
        else:
            likely_cooperators += my_cooperation_rate
        return likely_cooperators

    def _has_consecutive_failures(self, history: PlayerHistory, threshold: int) -> bool:
        """Check if there have been consecutive failures meeting the threshold."""
        current_round = history.round_number
        consecutive_failures = 0
        for i in range(min(threshold, current_round)):
            round_idx = current_round - 1 - i
            if round_idx < 0:
                break
            my_action = history.my_actions[round_idx]
            opponent_cooperators = sum(history.opponent_actions[round_idx, :])
            total_cooperators = int(my_action) + opponent_cooperators
            if total_cooperators < self.game_description.m:
                consecutive_failures += 1
            else:
                break
        return consecutive_failures >= threshold

class Strategy_COOPERATIVE_110(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperation Strategy (ATCS)
    
    Balances cooperative intent with adaptive protection against exploitation.
    Uses dynamic thresholds, momentum tracking, and punishment mechanisms.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.base_threshold = 0.4
        self.current_threshold = self.base_threshold
        self.punishment_rounds_remaining = 0
        self.recent_exploitations = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = state.round_number + 1
        if self._in_initial_phase(round_num):
            return self._handle_initial_phase(history)
        if self.punishment_rounds_remaining > 0:
            return self._handle_punishment_mode(history)
        if self._in_end_game(round_num):
            return self._handle_end_game(history)
        return self._main_strategy_decision(history, round_num)

    def _in_initial_phase(self, round_num):
        return round_num <= max(3, self.r * 0.2)

    def _handle_initial_phase(self, history):
        round_num = len(history.my_actions) + 1
        if round_num <= 1:
            return Action.C
        if round_num >= 2:
            last_round_cooperators = sum(history.opponent_actions[-1, :])
            if last_round_cooperators < math.ceil(self.m / 2):
                return self._main_strategy_decision(history, round_num)
        return Action.C

    def _handle_punishment_mode(self, history):
        self.punishment_rounds_remaining -= 1
        if self._should_exit_punishment(history):
            self.punishment_rounds_remaining = 0
            return self._main_strategy_decision(history, len(history.my_actions) + 1)
        return Action.D

    def _should_exit_punishment(self, history):
        if len(history.my_actions) < 2:
            return False
        recent_rounds = min(2, len(history.my_actions))
        total_cooperators = 0
        for i in range(recent_rounds):
            total_cooperators += sum(history.opponent_actions[-(i + 1), :])
        cooperation_rate = total_cooperators / (recent_rounds * self.n)
        return cooperation_rate > 0.4

    def _in_end_game(self, round_num):
        return round_num > self.r * 0.85

    def _handle_end_game(self, history):
        round_num = len(history.my_actions) + 1
        if round_num == self.r:
            return Action.D
        if self._end_game_cooperation_check(history):
            return Action.C
        return Action.D

    def _end_game_cooperation_check(self, history):
        recent_rounds = min(3, len(history.my_actions))
        if recent_rounds == 0:
            return False
        total_cooperators = 0
        for i in range(recent_rounds):
            total_cooperators += sum(history.opponent_actions[-(i + 1), :])
        avg_cooperation_rate = total_cooperators / (recent_rounds * self.n)
        projected_cooperators = avg_cooperation_rate * self.n
        return avg_cooperation_rate >= 0.6 and projected_cooperators >= self.m + 1

    def _main_strategy_decision(self, history, round_num):
        momentum = self._calculate_cooperation_momentum(history)
        self._update_threshold(history)
        risk = self._assess_risk(history, round_num)
        if self._should_enter_punishment(history):
            self.punishment_rounds_remaining = 2
            return Action.D
        if momentum >= self._get_adjusted_threshold() and risk <= 0.5:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_momentum(self, history):
        if len(history.my_actions) == 0:
            return 0.5
        recent_rounds = min(2, len(history.my_actions))
        total_cooperators = 0
        for i in range(recent_rounds):
            total_cooperators += sum(history.opponent_actions[-(i + 1), :])
        recent_cooperation_rate = total_cooperators / (recent_rounds * self.n)
        trend_bonus = 0
        if len(history.my_actions) >= 2:
            last_round_coop = sum(history.opponent_actions[-1, :])
            second_last_coop = sum(history.opponent_actions[-2, :])
            if last_round_coop > second_last_coop:
                trend_bonus = 0.1
            elif last_round_coop < second_last_coop:
                trend_bonus = -0.1
        return recent_cooperation_rate + trend_bonus

    def _update_threshold(self, history):
        if len(history.my_actions) == 0:
            return
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        if last_round_cooperators >= self.m:
            self.current_threshold = max(0.25, self.current_threshold - 0.02)
        else:
            self.current_threshold = min(0.7, self.current_threshold + 0.05)

    def _get_adjusted_threshold(self):
        threshold = self.current_threshold
        if self.n <= 4:
            threshold -= 0.15
        if self.m > self.n * 0.6:
            threshold = max(threshold, 0.5)
        return max(0.1, threshold)

    def _assess_risk(self, history, round_num):
        risk_score = 0
        rounds_remaining = self.r - round_num + 1
        if rounds_remaining / self.r < 0.2:
            risk_score += 0.3
        if len(history.my_actions) > 0:
            last_round_cooperators = sum(history.opponent_actions[-1, :])
            if history.my_actions[-1]:
                last_round_cooperators += 1
            if last_round_cooperators == self.m - 1:
                risk_score += 0.2
        recent_exploitations = self._count_recent_exploitations(history)
        if recent_exploitations >= 3:
            risk_score += 0.4
        return risk_score

    def _count_recent_exploitations(self, history):
        if len(history.my_actions) == 0:
            return 0
        exploitations = 0
        check_rounds = min(3, len(history.my_actions))
        for i in range(check_rounds):
            round_idx = -(i + 1)
            if history.my_actions[round_idx]:
                total_cooperators = sum(history.opponent_actions[round_idx, :]) + 1
                if total_cooperators < self.m:
                    exploitations += 1
        return exploitations

    def _should_enter_punishment(self, history):
        if len(history.my_actions) < 2:
            return False
        if len(history.my_actions) >= 2:
            last_two_cooperation_rates = []
            for i in range(2):
                round_idx = -(i + 1)
                cooperators = sum(history.opponent_actions[round_idx, :])
                rate = cooperators / self.n
                last_two_cooperation_rates.append(rate)
            if all((rate < 0.2 for rate in last_two_cooperation_rates)):
                return True
        recent_exploitations = 0
        check_rounds = min(5, len(history.my_actions))
        for i in range(check_rounds):
            round_idx = -(i + 1)
            if history.my_actions[round_idx]:
                total_cooperators = sum(history.opponent_actions[round_idx, :]) + 1
                if total_cooperators < self.m:
                    recent_exploitations += 1
        return recent_exploitations >= 3

class Strategy_COOPERATIVE_111(BaseStrategy):
    """
    Adaptive Threshold-Aware Cooperative Strategy (ATACS)
    
    Balances cooperative intention with adaptive learning, aiming to achieve 
    collective benefit while protecting against exploitation. Dynamically 
    adjusts cooperation based on observed group behavior patterns.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number + 1
        if current_round == self.r:
            return self._final_round_decision(history)
        return self._adaptive_decision(history)

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """Strategic endgame decision for final round"""
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        my_coop_rate = sum(history.my_actions) / len(history.my_actions)
        total_cooperators = 0
        for round_idx in range(len(history.my_actions)):
            round_cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                round_cooperators += 1
            total_cooperators += round_cooperators
        avg_cooperators = total_cooperators / len(history.my_actions)
        if last_round_cooperators >= self.m - 1 or my_coop_rate > 0.6 or avg_cooperators >= self.m * 0.8:
            return Action.C
        else:
            return Action.D

    def _adaptive_decision(self, history: PlayerHistory) -> Action:
        """Adaptive cooperation logic for rounds 2 to r-1"""
        if self.n <= 4:
            threshold_bonus = 0.1
        else:
            threshold_bonus = 0.0
        if self.m / self.n > 0.7:
            high_threshold_game = True
        else:
            high_threshold_game = False
        if self.r <= 3:
            return self._short_game_logic(history)
        recent_rounds = min(3, len(history.my_actions))
        recent_cooperators = 0
        for i in range(recent_rounds):
            round_idx = len(history.my_actions) - 1 - i
            round_cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                round_cooperators += 1
            recent_cooperators += round_cooperators
        recent_coop_rate = recent_cooperators / (self.n * recent_rounds)
        threshold_probability = recent_coop_rate * self.n / self.m
        threshold_probability += threshold_bonus
        if high_threshold_game:
            threshold_probability += 0.1
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        my_coop_rate = sum(history.my_actions) / len(history.my_actions)
        my_defection_streak = 0
        for i in range(len(history.my_actions) - 1, -1, -1):
            if not history.my_actions[i]:
                my_defection_streak += 1
            else:
                break
        if threshold_probability >= 0.8:
            return Action.C
        elif threshold_probability >= 0.6:
            if my_coop_rate > 0.5:
                return Action.C
            else:
                return Action.D
        elif threshold_probability >= 0.4:
            if last_round_cooperators >= self.m - 2 and my_defection_streak < 2:
                return Action.C
            else:
                return Action.D
        else:
            if my_defection_streak >= 3:
                if len(history.my_actions) >= 3:
                    recent_trend = 0
                    for i in range(min(2, len(history.my_actions) - 1)):
                        round_idx = len(history.my_actions) - 1 - i
                        prev_round_idx = round_idx - 1
                        current_cooperators = sum(history.opponent_actions[round_idx, :])
                        prev_cooperators = sum(history.opponent_actions[prev_round_idx, :])
                        if current_cooperators > prev_cooperators:
                            recent_trend += 1
                    if recent_trend >= 1:
                        return Action.C
            return Action.D

    def _short_game_logic(self, history: PlayerHistory) -> Action:
        """Logic for short games (r <= 3)"""
        cooperate_rounds = math.floor(self.r / 2) + 1
        current_round = history.round_number + 1
        if current_round <= cooperate_rounds:
            return Action.C
        else:
            last_round_cooperators = sum(history.opponent_actions[-1, :])
            if history.my_actions[-1]:
                last_round_cooperators += 1
            if last_round_cooperators < self.m - 2:
                return Action.D
            else:
                return Action.C

class Strategy_COOPERATIVE_112(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperative Strategy (ATCS)
    
    Balances cooperative intent with adaptive learning, aiming to achieve collective 
    success while protecting against exploitation. Uses dynamic trust levels and 
    threshold calculations to make cooperation decisions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.initial_phase_length = min(3, max(1, self.r // 4))
        self.base_trust_level = 0.5
        self.min_trust_level = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number
        if current_round < self.initial_phase_length:
            return Action.C
        total_rounds_played = current_round
        total_cooperators_observed = np.sum(history.opponent_actions) + np.sum(history.my_actions)
        total_possible_cooperators = self.n * total_rounds_played
        cooperation_rate = total_cooperators_observed / total_possible_cooperators if total_possible_cooperators > 0 else 0
        cooperation_momentum = 0
        if current_round >= 2:
            cooperators_last_round = np.sum(history.opponent_actions[-1, :]) + (1 if history.my_actions[-1] else 0)
            cooperators_previous_round = np.sum(history.opponent_actions[-2, :]) + (1 if history.my_actions[-2] else 0)
            cooperation_momentum = (cooperators_last_round - cooperators_previous_round) / self.n
        trust_level = max(self.min_trust_level, 0.7 * cooperation_rate + 0.3 * cooperation_momentum)
        predicted_cooperators = max(1, min(self.n - 1, round(trust_level * self.n)))
        recent_rounds = min(3, current_round)
        if recent_rounds > 0:
            recent_opponent_cooperation = np.sum(history.opponent_actions[-recent_rounds:, :])
            recent_total_possible = (self.n - 1) * recent_rounds
            recent_opponent_rate = recent_opponent_cooperation / recent_total_possible if recent_total_possible > 0 else 0
            if recent_opponent_rate < 0.1:
                return Action.D
        remaining_rounds = self.r - current_round
        if remaining_rounds == 1:
            successful_rounds = 0
            for round_idx in range(current_round):
                round_cooperators = np.sum(history.opponent_actions[round_idx, :]) + (1 if history.my_actions[round_idx] else 0)
                if round_cooperators >= self.m:
                    successful_rounds += 1
            success_rate = successful_rounds / current_round if current_round > 0 else 0
            if success_rate > 0.6:
                return Action.C
            else:
                return Action.D
        if remaining_rounds <= max(1, self.r * 0.2):
            successful_rounds = 0
            for round_idx in range(current_round):
                round_cooperators = np.sum(history.opponent_actions[round_idx, :]) + (1 if history.my_actions[round_idx] else 0)
                if round_cooperators >= self.m:
                    successful_rounds += 1
            success_rate = successful_rounds / current_round if current_round > 0 else 0
            if success_rate > 0.8:
                pass
            else:
                predicted_cooperators = max(1, predicted_cooperators - 1)
        if predicted_cooperators >= self.m:
            return Action.C
        elif predicted_cooperators >= self.m - 1:
            return Action.C
        elif current_round > 0:
            last_round_cooperators = np.sum(history.opponent_actions[-1, :]) + (1 if history.my_actions[-1] else 0)
            last_round_successful = last_round_cooperators >= self.m
            if last_round_successful and cooperation_rate > 0.3:
                return Action.C
        if current_round > 0 and current_round % 4 == 0:
            if cooperation_rate > 0.2:
                return Action.C
        if current_round > 0:
            last_round_cooperators = np.sum(history.opponent_actions[-1, :]) + (1 if history.my_actions[-1] else 0)
            if last_round_cooperators >= self.m - 2:
                return Action.C
        if self.n <= 4 and current_round > 0:
            if np.sum(history.opponent_actions[-1, :]) >= 1:
                return Action.C
        if self.m > self.n / 2:
            if predicted_cooperators >= self.m - 2:
                return Action.C
        if self.r > 20 and current_round >= 5:
            recent_failures = 0
            for i in range(max(0, current_round - 5), current_round):
                round_cooperators = np.sum(history.opponent_actions[i, :]) + (1 if history.my_actions[i] else 0)
                if round_cooperators < self.m:
                    recent_failures += 1
            if recent_failures >= 5 and current_round % 7 <= 1:
                return Action.C
        return Action.D

class Strategy_COOPERATIVE_113(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) - Balances cooperative intent with adaptive learning,
    aiming to achieve collective success while protecting against exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.cooperation_history = []
        self.threshold_success_history = []
        self.exploitation_count = 0
        self.total_my_cooperations = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number + 1
        if current_round <= min(3, self.r // 3):
            if history.round_number >= 1:
                recent_cooperation_rate = self._get_recent_cooperation_rate(history, min(history.round_number, 2))
                if recent_cooperation_rate < 0.2:
                    return Action.D
            return Action.C
        cooperation_rate = self._get_recent_cooperation_rate(history, min(3, history.round_number))
        threshold_success_rate = self._get_threshold_success_rate(history)
        exploitation_risk = self._get_exploitation_risk(history)
        if current_round > 0.8 * self.r:
            return self._end_game_decision(history, cooperation_rate, threshold_success_rate)
        return self._adaptive_decision(history, current_round, cooperation_rate, threshold_success_rate, exploitation_risk)

    def _get_recent_cooperation_rate(self, history: PlayerHistory, lookback_rounds: int) -> float:
        """Calculate cooperation rate of opponents over recent rounds"""
        if history.round_number == 0:
            return 0.5
        start_round = max(0, history.round_number - lookback_rounds)
        recent_actions = history.opponent_actions[start_round:, :]
        if recent_actions.size == 0:
            return 0.5
        weights = np.array([0.5 ** i for i in reversed(range(len(recent_actions)))])
        weights = weights / np.sum(weights)
        cooperation_by_round = np.mean(recent_actions, axis=1)
        return np.sum(cooperation_by_round * weights)

    def _get_threshold_success_rate(self, history: PlayerHistory) -> float:
        """Calculate percentage of recent rounds where threshold m was met"""
        if history.round_number == 0:
            return 0.6
        lookback = min(5, history.round_number)
        start_round = max(0, history.round_number - lookback)
        success_count = 0
        total_rounds = 0
        for round_idx in range(start_round, history.round_number):
            cooperators = np.sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators >= self.m:
                success_count += 1
            total_rounds += 1
        return success_count / total_rounds if total_rounds > 0 else 0.6

    def _get_exploitation_risk(self, history: PlayerHistory) -> float:
        """Calculate how often I cooperated but threshold wasn't met"""
        if history.round_number == 0:
            return 0.0
        exploitation_count = 0
        my_cooperation_count = 0
        for round_idx in range(history.round_number):
            if history.my_actions[round_idx]:
                my_cooperation_count += 1
                cooperators = np.sum(history.opponent_actions[round_idx, :]) + 1
                if cooperators < self.m:
                    exploitation_count += 1
        return exploitation_count / my_cooperation_count if my_cooperation_count > 0 else 0.0

    def _adaptive_decision(self, history: PlayerHistory, current_round: int, cooperation_rate: float, threshold_success_rate: float, exploitation_risk: float) -> Action:
        """Main adaptive decision logic for middle rounds"""
        required_others_rate = (self.m - 1) / (self.n - 1)
        if cooperation_rate >= required_others_rate:
            return Action.C
        if threshold_success_rate >= 0.6 and exploitation_risk <= 0.4:
            return Action.C
        if cooperation_rate >= 0.5 and current_round <= 0.8 * self.r:
            cooperation_prob = max(0.7, cooperation_rate)
            if self.m == self.n - 1:
                cooperation_prob += 0.2
            elif self.m == 2:
                cooperation_prob += 0.1
            cooperation_prob = min(1.0, cooperation_prob)
            if random.random() < cooperation_prob:
                return Action.C
        if history.round_number >= 3:
            recent_defections = sum((1 for i in range(max(0, history.round_number - 3), history.round_number) if not history.my_actions[i]))
            if recent_defections >= 2 and current_round % 4 == 0:
                return Action.C
        return Action.D

    def _end_game_decision(self, history: PlayerHistory, cooperation_rate: float, threshold_success_rate: float) -> Action:
        """Decision logic for end-game phase"""
        current_round = history.round_number + 1
        if current_round == self.r:
            return Action.C if cooperation_rate > 0.8 else Action.D
        if threshold_success_rate >= 0.6:
            if cooperation_rate >= 0.6:
                return Action.C
            elif cooperation_rate >= 0.4 and random.random() < 0.7:
                return Action.C
        if current_round % 3 == 0 and cooperation_rate >= 0.3:
            return Action.C
        return Action.D

class Strategy_COOPERATIVE_114(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperative Strategy (ATCS).
    
    Balances cooperative intent with adaptive learning, maintaining cooperation
    when feasible while protecting against exploitation through multi-timeframe
    analysis and forgiveness mechanisms.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.total_rounds = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number
        recent_cooperation_rate = self._get_recent_cooperation_rate(history)
        overall_cooperation_rate = self._get_overall_cooperation_rate(history)
        threshold_success_rate = self._get_threshold_success_rate(history)
        if current_round + 1 == self.total_rounds:
            return self._last_round_decision(threshold_success_rate, recent_cooperation_rate)
        if threshold_success_rate >= 0.6:
            return Action.C
        elif recent_cooperation_rate >= (self.m - 1) / self.n:
            trend_factor = recent_cooperation_rate - overall_cooperation_rate
            cooperation_probability = 0.7 + 0.3 * trend_factor
            if self.n <= 4:
                cooperation_probability += 0.1
            if current_round <= 3:
                cooperation_probability = max(0.8, cooperation_probability)
            return Action.C if random.random() < cooperation_probability else Action.D
        elif recent_cooperation_rate < (self.m - 2) / self.n:
            rounds_since_success = self._rounds_since_last_success(history)
            forgiveness_threshold = 2 if self.n <= 4 else 3
            if rounds_since_success >= forgiveness_threshold and overall_cooperation_rate > 0.3:
                return Action.C
            else:
                return Action.D
        else:
            return Action.C

    def _get_recent_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate over last 3 rounds (or fewer if not available)."""
        rounds_to_check = min(3, history.round_number)
        if self.m > 0.7 * self.n:
            rounds_to_check = min(5, history.round_number)
        if rounds_to_check == 0:
            return 0.0
        recent_my_actions = history.my_actions[-rounds_to_check:]
        recent_opponent_actions = history.opponent_actions[-rounds_to_check:, :]
        total_cooperators = np.sum(recent_my_actions) + np.sum(recent_opponent_actions)
        total_possible = rounds_to_check * self.n
        return total_cooperators / total_possible

    def _get_overall_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate overall cooperation rate across all completed rounds."""
        if history.round_number == 0:
            return 0.0
        total_cooperators = np.sum(history.my_actions) + np.sum(history.opponent_actions)
        total_possible = history.round_number * self.n
        return total_cooperators / total_possible

    def _get_threshold_success_rate(self, history: PlayerHistory) -> float:
        """Calculate rate of rounds where threshold m was met."""
        if history.round_number == 0:
            return 0.0
        successful_rounds = 0
        for round_idx in range(history.round_number):
            my_cooperation = int(history.my_actions[round_idx])
            opponent_cooperators = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators = my_cooperation + opponent_cooperators
            if total_cooperators >= self.m:
                successful_rounds += 1
        return successful_rounds / history.round_number

    def _rounds_since_last_success(self, history: PlayerHistory) -> int:
        """Count rounds since last threshold success."""
        rounds_since = 0
        for round_idx in range(history.round_number - 1, -1, -1):
            my_cooperation = int(history.my_actions[round_idx])
            opponent_cooperators = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators = my_cooperation + opponent_cooperators
            if total_cooperators >= self.m:
                break
            rounds_since += 1
        return rounds_since

    def _last_round_decision(self, threshold_success_rate: float, recent_cooperation_rate: float) -> Action:
        """Special logic for the final round."""
        if threshold_success_rate > 0.5:
            return Action.C
        elif recent_cooperation_rate >= (self.m - 1) / self.n:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_115(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) - Balances cooperative intent with adaptive learning,
    aiming to achieve collective benefits while protecting against exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = state.round_number
        if round_num == self.r:
            return Action.D
        window_size = min(5, history.round_number)
        recent_coop_rate = self._calculate_recent_cooperation_rate(history, window_size)
        base_threshold = (self.m + 1) / self.n
        success_rate = self._count_successful_rounds(history) / history.round_number
        target_success_rate = 0.7
        experience_adjustment = 0.2 * (target_success_rate - success_rate)
        experience_adjustment = max(-0.3, min(0.3, experience_adjustment))
        cooperation_threshold = base_threshold + experience_adjustment
        if self._is_low_participation_scenario(history):
            cooperation_threshold -= 0.2
        if self._is_high_volatility(history):
            cooperation_threshold += 0.1
        if recent_coop_rate >= cooperation_threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory, window_size: int) -> float:
        """Calculate cooperation rate over the sliding window of recent rounds."""
        if history.round_number == 0:
            return 0.0
        start_round = max(0, history.round_number - window_size)
        total_cooperators = 0
        total_possible = 0
        for round_idx in range(start_round, history.round_number):
            round_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
            if history.my_actions[round_idx]:
                round_cooperators += 1
            total_cooperators += round_cooperators
            total_possible += self.n
        if total_possible == 0:
            return 0.0
        return total_cooperators / total_possible

    def _count_successful_rounds(self, history: PlayerHistory) -> int:
        """Count rounds where at least m players cooperated."""
        successful_rounds = 0
        for round_idx in range(history.round_number):
            opponent_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
            my_cooperation = int(history.my_actions[round_idx])
            total_cooperators = opponent_cooperators + my_cooperation
            if total_cooperators >= self.m:
                successful_rounds += 1
        return successful_rounds

    def _is_low_participation_scenario(self, history: PlayerHistory) -> bool:
        """Check if cooperation rate has been low for 3 consecutive rounds."""
        if history.round_number < 3:
            return False
        low_threshold = self.m / (2 * self.n)
        consecutive_low = 0
        for round_idx in range(max(0, history.round_number - 3), history.round_number):
            opponent_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
            my_cooperation = int(history.my_actions[round_idx])
            total_cooperators = opponent_cooperators + my_cooperation
            cooperation_rate = total_cooperators / self.n
            if cooperation_rate < low_threshold:
                consecutive_low += 1
            else:
                consecutive_low = 0
        return consecutive_low >= 3

    def _is_high_volatility(self, history: PlayerHistory) -> bool:
        """Check if cooperation rate variance over last 3 rounds exceeds 0.3."""
        if history.round_number < 3:
            return False
        cooperation_rates = []
        for round_idx in range(max(0, history.round_number - 3), history.round_number):
            opponent_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
            my_cooperation = int(history.my_actions[round_idx])
            total_cooperators = opponent_cooperators + my_cooperation
            cooperation_rate = total_cooperators / self.n
            cooperation_rates.append(cooperation_rate)
        if len(cooperation_rates) < 2:
            return False
        variance = np.var(cooperation_rates)
        return variance > 0.3

class Strategy_COOPERATIVE_116(BaseStrategy):
    """
    Threshold Guardian: Adaptive cooperative strategy that maintains cooperation while being resilient to exploitation.
    Focuses on achieving the threshold m through dynamic cooperation probability based on recent success rates,
    personal contribution necessity, and reciprocity assessment.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if current_round == self.r - 1:
            return self._final_round_strategy(history)
        return self._main_strategy(history, current_round)

    def _final_round_strategy(self, history: PlayerHistory) -> Action:
        """Threshold-focused approach for final round"""
        success_rate = self._calculate_success_rate(history, len(history.my_actions))
        if success_rate >= 0.7:
            cooperation_prob = 0.6
        else:
            cooperation_prob = 0.9
        return Action.C if random.random() < cooperation_prob else Action.D

    def _main_strategy(self, history: PlayerHistory, current_round: int) -> Action:
        """Main decision process for rounds 2 to r-1"""
        rounds_completed = len(history.my_actions)
        recent_rounds = min(3, rounds_completed)
        success_rate = self._calculate_success_rate(history, recent_rounds)
        last_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_cooperators += 1
        base_probability = 0.8 if rounds_completed <= 2 else 0.7
        if success_rate >= 0.67:
            threshold_adjustment = 0.0
        elif success_rate >= 0.33:
            threshold_adjustment = 0.2
        else:
            threshold_adjustment = 0.3
        if last_cooperators >= self.m:
            necessity_adjustment = -0.1
        elif last_cooperators >= self.m - 1:
            necessity_adjustment = 0.1
        else:
            necessity_adjustment = 0.3
        param_adjustment = 0.0
        if self.m >= self.n - 1:
            param_adjustment += 0.1
        if self.k <= 1.5:
            param_adjustment -= 0.1
        if self.r <= 3:
            param_adjustment += 0.1
        cooperation_probability = base_probability + threshold_adjustment + necessity_adjustment + param_adjustment
        cooperation_probability = max(0.1, min(0.95, cooperation_probability))
        return Action.C if random.random() < cooperation_probability else Action.D

    def _calculate_success_rate(self, history: PlayerHistory, look_back_rounds: int) -> float:
        """Calculate the rate of successful threshold achievement in recent rounds"""
        if look_back_rounds == 0:
            return 0.5
        successful_rounds = 0
        start_idx = max(0, len(history.my_actions) - look_back_rounds)
        for round_idx in range(start_idx, len(history.my_actions)):
            opponent_cooperators = sum(history.opponent_actions[round_idx, :])
            my_cooperation = 1 if history.my_actions[round_idx] else 0
            total_cooperators = opponent_cooperators + my_cooperation
            if total_cooperators >= self.m:
                successful_rounds += 1
        return successful_rounds / look_back_rounds

class Strategy_COOPERATIVE_117(BaseStrategy):
    """
    Adaptive Threshold Guardian strategy for Collective Risk Dilemma.
    
    Balances cooperation with strategic resilience by:
    - Starting with cooperation to signal good intent
    - Adapting based on group's historical cooperation rate
    - Leading by example when group under-cooperates
    - Occasionally defecting when group over-cooperates consistently
    - Always cooperating in critical moments and final round
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = history.round_number + 1
        if round_num == self.r:
            return Action.C
        total_cooperations = 0
        total_possible = 0
        for r_idx in range(len(history.my_actions)):
            if history.my_actions[r_idx]:
                total_cooperations += 1
            total_possible += 1
            total_cooperations += sum(history.opponent_actions[r_idx, :])
            total_possible += self.n - 1
        avg_coop_rate = total_cooperations / total_possible
        last_round_idx = len(history.my_actions) - 1
        last_round_cooperators = sum(history.opponent_actions[last_round_idx, :])
        if history.my_actions[last_round_idx]:
            last_round_cooperators += 1
        threshold_rate = self.m / self.n
        over_threshold_rate = (self.m + 1) / self.n
        if avg_coop_rate >= over_threshold_rate:
            if last_round_cooperators > self.m:
                if random.random() < 0.3:
                    return Action.D
                else:
                    return Action.C
            else:
                return Action.C
        elif avg_coop_rate >= threshold_rate:
            return Action.C
        elif last_round_cooperators == self.m - 1:
            return Action.C
        elif last_round_cooperators < self.m - 1:
            return Action.C
        else:
            return Action.C

class Strategy_COOPERATIVE_118(BaseStrategy):
    """
    Graduated Reciprocator: An adaptive cooperative strategy that starts optimistically,
    uses threshold-based cooperation decisions in the main game, and handles endgame specially.
    Balances cooperative intent with protection against exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = state.round_number
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        if round_num <= 3:
            return Action.C
        if round_num >= r - 1:
            return self._handle_endgame(round_num, history, n, m, r)
        return self._main_game_decision(history, n, m, k)

    def _handle_endgame(self, round_num: int, history: PlayerHistory, n: int, m: int, r: int) -> Action:
        if round_num == r - 1:
            overall_coop_rate = self._calculate_historical_cooperation_rate(history, n)
            return Action.C if overall_coop_rate >= 0.4 else Action.D
        if round_num == r:
            prev_round_cooperators = self._count_cooperators_last_round(history)
            return Action.C if prev_round_cooperators >= m else Action.D

    def _main_game_decision(self, history: PlayerHistory, n: int, m: int, k: float) -> Action:
        prev_round_cooperators = self._count_cooperators_last_round(history)
        cooperation_rate = prev_round_cooperators / n
        threshold_met_prev = prev_round_cooperators >= m
        high_threshold = 0.7
        medium_threshold = 0.5
        low_threshold = 0.3
        if threshold_met_prev:
            high_threshold -= 0.1
            medium_threshold -= 0.1
            low_threshold -= 0.1
        adjustment = 0.0
        if m >= n - 1:
            adjustment -= 0.15
        if k > 3:
            adjustment -= 0.05
        if self._has_cooperation_streak(history, m, 3):
            if cooperation_rate >= 0.4:
                return Action.C
        high_threshold += adjustment
        medium_threshold += adjustment
        low_threshold += adjustment
        if cooperation_rate >= max(0.0, high_threshold):
            return Action.C
        elif cooperation_rate >= max(0.0, medium_threshold):
            return Action.C
        elif cooperation_rate >= max(0.0, low_threshold):
            return Action.D
        else:
            return Action.D

    def _count_cooperators_last_round(self, history: PlayerHistory) -> int:
        """Count cooperators (including self) in the most recent round."""
        if len(history.my_actions) == 0:
            return 0
        opponent_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        my_cooperation = int(history.my_actions[-1])
        return opponent_cooperators + my_cooperation

    def _calculate_historical_cooperation_rate(self, history: PlayerHistory, n: int) -> float:
        """Calculate overall cooperation rate across all completed rounds."""
        if len(history.my_actions) == 0:
            return 0.0
        total_cooperations = 0
        total_decisions = 0
        for round_idx in range(len(history.my_actions)):
            opponent_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
            my_cooperation = int(history.my_actions[round_idx])
            total_cooperations += opponent_cooperators + my_cooperation
            total_decisions += n
        return total_cooperations / total_decisions if total_decisions > 0 else 0.0

    def _has_cooperation_streak(self, history: PlayerHistory, m: int, streak_length: int) -> bool:
        """Check if threshold has been met for the last streak_length rounds."""
        if len(history.my_actions) < streak_length:
            return False
        for i in range(streak_length):
            round_idx = len(history.my_actions) - 1 - i
            cooperators = self._count_cooperators_round(history, round_idx)
            if cooperators < m:
                return False
        return True

    def _count_cooperators_round(self, history: PlayerHistory, round_idx: int) -> int:
        """Count cooperators in a specific round."""
        if round_idx < 0 or round_idx >= len(history.my_actions):
            return 0
        opponent_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
        my_cooperation = int(history.my_actions[round_idx])
        return opponent_cooperators + my_cooperation

class Strategy_COOPERATIVE_119(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperation Strategy (ATCS)
    
    Balances cooperative intent with adaptive responsiveness, using conditional cooperation
    with forgiveness to achieve collective benefit while protecting against exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.alpha = 0.7
        self.forgiveness_counter = 0
        self.forgiveness_duration = 2
        self.last_cooperation_rates = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number
        initial_phase_length = min(3, max(1, self.r // 3))
        if current_round < initial_phase_length:
            return Action.C
        total_cooperators_per_round = np.sum(history.opponent_actions, axis=1)
        if history.my_actions[0]:
            my_cooperations = history.my_actions.astype(int)
            total_cooperators_per_round = total_cooperators_per_round + my_cooperations
        recent_window = min(3, current_round)
        recent_cooperation_rate = np.mean(total_cooperators_per_round[-recent_window:]) / self.n
        historical_cooperation_rate = np.mean(total_cooperators_per_round) / self.n
        expected_cooperators = self.alpha * recent_cooperation_rate * self.n + (1 - self.alpha) * historical_cooperation_rate * self.n
        if self.forgiveness_counter > 0:
            self.forgiveness_counter -= 1
            return Action.C
        if current_round >= 3:
            recent_failures = 0
            for i in range(min(3, current_round)):
                round_cooperators = total_cooperators_per_round[-(i + 1)]
                if round_cooperators < self.m:
                    recent_failures += 1
                else:
                    break
            if recent_failures >= 2:
                self.forgiveness_counter = self.forgiveness_duration - 1
                return Action.C
        coop_rate = historical_cooperation_rate
        threshold_adjustment = 0
        if coop_rate > 0.6:
            threshold_adjustment = -0.2
        elif coop_rate < 0.3:
            threshold_adjustment = 0.2
        momentum = 0
        if len(total_cooperators_per_round) >= 2:
            recent_trend = total_cooperators_per_round[-1] - total_cooperators_per_round[-2]
            momentum = recent_trend / self.n
        endgame_start = self.r - max(2, self.r // 5)
        if current_round >= endgame_start:
            expected_cooperators *= 0.9
        base_threshold = self.m - 1
        if momentum > 0.1:
            threshold = base_threshold - 0.2
        elif momentum < -0.1:
            threshold = base_threshold + 0.2
        else:
            threshold = base_threshold
        threshold += threshold_adjustment
        if self.k > 2.5:
            threshold -= 0.3
        if self.m / self.n > 0.7:
            threshold += 0.2
        elif self.m / self.n < 0.4:
            threshold -= 0.2
        if self.r <= 3:
            expected_value_coop = self.k if expected_cooperators >= self.m - 1 else 0
            expected_value_defect = 1 + (self.k if expected_cooperators >= self.m else 0)
            return Action.C if expected_value_coop >= expected_value_defect else Action.D
        return Action.C if expected_cooperators >= threshold else Action.D

class Strategy_COOPERATIVE_120(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS).
    
    Balances cooperative intent with adaptive learning, using a dynamic cooperation
    threshold that adapts based on observed cooperation rates and success patterns.
    Always cooperates in first round, then uses cooperation rate tracking and
    recent success patterns to make decisions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.required_rate = self.m / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        total_cooperators = 0
        rounds_played = history.round_number
        for round_idx in range(rounds_played):
            my_cooperation = 1 if history.my_actions[round_idx] else 0
            opponent_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
            total_cooperators += my_cooperation + opponent_cooperators
        observed_coop_rate = total_cooperators / (self.n * rounds_played)
        recent_rounds = min(5, rounds_played)
        recent_successes = 0
        for round_idx in range(rounds_played - recent_rounds, rounds_played):
            my_cooperation = 1 if history.my_actions[round_idx] else 0
            opponent_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
            total_round_cooperators = my_cooperation + opponent_cooperators
            if total_round_cooperators >= self.m:
                recent_successes += 1
        recent_success_rate = recent_successes / recent_rounds if recent_rounds > 0 else 0
        base_threshold = max(0.3, self.required_rate - 0.1)
        adaptation_factor = (observed_coop_rate - self.required_rate) * 0.5
        cooperation_threshold = base_threshold + adaptation_factor
        if rounds_played > 0:
            last_round_idx = rounds_played - 1
            my_last_cooperation = 1 if history.my_actions[last_round_idx] else 0
            last_opponent_cooperators = int(np.sum(history.opponent_actions[last_round_idx, :]))
            last_total_cooperators = my_last_cooperation + last_opponent_cooperators
            if last_total_cooperators == self.m - 1:
                return Action.C
        if rounds_played >= 6:
            recent_3_coop = 0
            previous_3_coop = 0
            for round_idx in range(rounds_played - 3, rounds_played):
                my_cooperation = 1 if history.my_actions[round_idx] else 0
                opponent_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
                recent_3_coop += my_cooperation + opponent_cooperators
            for round_idx in range(rounds_played - 6, rounds_played - 3):
                my_cooperation = 1 if history.my_actions[round_idx] else 0
                opponent_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
                previous_3_coop += my_cooperation + opponent_cooperators
            recent_3_rate = recent_3_coop / (3 * self.n)
            previous_3_rate = previous_3_coop / (3 * self.n)
            if recent_3_rate > previous_3_rate and observed_coop_rate > self.required_rate * 0.8:
                return Action.C
        if observed_coop_rate < self.required_rate - 0.2 and rounds_played >= 3:
            consecutive_low = True
            check_rounds = min(3, rounds_played)
            for i in range(check_rounds):
                round_idx = rounds_played - 1 - i
                round_start_idx = max(0, round_idx - 2)
                round_cooperators = 0
                for r in range(round_start_idx, round_idx + 1):
                    my_cooperation = 1 if history.my_actions[r] else 0
                    opponent_cooperators = int(np.sum(history.opponent_actions[r, :]))
                    round_cooperators += my_cooperation + opponent_cooperators
                round_rate = round_cooperators / (self.n * (round_idx - round_start_idx + 1))
                if round_rate >= self.required_rate - 0.2:
                    consecutive_low = False
                    break
            if consecutive_low:
                return Action.D
        if recent_success_rate < 0.2:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            if observed_coop_rate > self.required_rate + 0.1:
                return Action.C
            else:
                return Action.D
        endgame_threshold = max(1, int(0.2 * self.game_description.n_rounds))
        if state.round_number >= self.game_description.n_rounds - endgame_threshold:
            cooperation_threshold += 0.1
        if observed_coop_rate >= cooperation_threshold and recent_success_rate >= 0.4:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_121(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperation Strategy
    
    Balances cooperative intent with adaptive protection against exploitation.
    Uses dynamic threshold adjustment based on recent cooperation rates and
    implements defensive mechanisms against systematic defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.m
        self.defensive_mode = False
        self.defensive_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        round_num = state.round_number + 1
        window_size = min(5, history.round_number)
        recent_coop_rate = self._calculate_cooperation_rate(history, window_size)
        if round_num == r:
            recent_3_window = min(3, history.round_number)
            recent_3_coop_rate = self._calculate_cooperation_rate(history, recent_3_window)
            return Action.C if recent_3_coop_rate >= 0.6 else Action.D
        last_cooperators = self._count_cooperators(history, -1)
        if last_cooperators >= m:
            self.threshold = max(m, self.threshold - 1)
        else:
            self.threshold = min(n - 1, self.threshold + 2)
        if round_num <= 3:
            return Action.C if recent_coop_rate >= (m - 1) / n else Action.D
        self._update_defensive_mode(history)
        if self.defensive_mode:
            return Action.C if recent_coop_rate >= (m + 1) / n else Action.D
        return Action.C if recent_coop_rate >= self.threshold / n else Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, window_size: int) -> float:
        """Calculate cooperation rate over the last window_size rounds."""
        if window_size <= 0 or history.round_number == 0:
            return 0.0
        start_idx = max(0, history.round_number - window_size)
        total_cooperators = 0
        total_players = 0
        for i in range(start_idx, history.round_number):
            opponent_cooperators = sum(history.opponent_actions[i, :])
            my_cooperation = 1 if history.my_actions[i] else 0
            total_cooperators += opponent_cooperators + my_cooperation
            total_players += self.game_description.n_players
        return total_cooperators / total_players if total_players > 0 else 0.0

    def _count_cooperators(self, history: PlayerHistory, round_idx: int) -> int:
        """Count total cooperators (including self) in a specific round."""
        if history.round_number == 0:
            return 0
        if round_idx < 0:
            round_idx = history.round_number + round_idx
        if round_idx < 0 or round_idx >= history.round_number:
            return 0
        opponent_cooperators = sum(history.opponent_actions[round_idx, :])
        my_cooperation = 1 if history.my_actions[round_idx] else 0
        return int(opponent_cooperators + my_cooperation)

    def _update_defensive_mode(self, history: PlayerHistory):
        """Update defensive mode based on recent cooperation failures."""
        n = self.game_description.n_players
        m = self.game_description.m
        consecutive_failures = 0
        for i in range(max(0, history.round_number - 3), history.round_number):
            cooperators = self._count_cooperators(history, i)
            if cooperators < m:
                consecutive_failures += 1
            else:
                consecutive_failures = 0
        if consecutive_failures >= 3 and (not self.defensive_mode):
            self.defensive_mode = True
            self.defensive_rounds = 0
        if self.defensive_mode:
            self.defensive_rounds += 1
            recent_successes = 0
            for i in range(max(0, history.round_number - 2), history.round_number):
                cooperators = self._count_cooperators(history, i)
                if cooperators >= m:
                    recent_successes += 1
            if recent_successes >= 2:
                self.defensive_mode = False
                self.defensive_rounds = 0

class Strategy_COOPERATIVE_122(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperation Strategy (ATCS)
    
    Balances cooperative intent with strategic adaptation, starting cooperatively
    but adapting based on group success rate. Uses probabilistic decisions with
    parameter-specific adjustments and end-game defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number + 1
        if current_round == r:
            return Action.D
        successes = 0
        total_rounds = history.round_number
        for round_idx in range(total_rounds):
            cooperators = int(history.my_actions[round_idx]) + sum(history.opponent_actions[round_idx, :])
            if cooperators >= m:
                successes += 1
        success_rate = successes / total_rounds if total_rounds > 0 else 0
        if success_rate >= 0.7:
            base_prob = 0.9
        elif success_rate >= 0.4:
            base_prob = 0.7
        elif success_rate >= 0.2:
            base_prob = 0.5
        else:
            base_prob = 0.3
        if total_rounds >= 2:
            recent_successes = 0
            for round_idx in range(max(0, total_rounds - 2), total_rounds):
                cooperators = int(history.my_actions[round_idx]) + sum(history.opponent_actions[round_idx, :])
                if cooperators >= m:
                    recent_successes += 1
            if recent_successes == 2:
                base_prob *= 1.1
            elif recent_successes == 0:
                base_prob *= 0.8
        if k > 3:
            base_prob += 0.1
        if m <= n / 3:
            base_prob += 0.1
        if m > 2 * n / 3:
            base_prob -= 0.1
        if current_round > r - 3:
            base_prob -= 0.1 * (r - current_round)
        if current_round <= 3:
            base_prob = max(0.6, base_prob)
        final_prob = max(0.2, min(0.95, base_prob))
        return Action.C if random.random() < final_prob else Action.D

class Strategy_COOPERATIVE_123(BaseStrategy):
    """
    Adaptive Threshold-Aware Cooperative Strategy (ATACS)
    
    Balances cooperative intentions with adaptive learning, establishing and maintaining 
    cooperation while protecting against systematic exploitation through dynamic thresholds
    and context-aware decision making.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number + 1
        if current_round <= 3:
            return Action.C
        return self._make_adaptive_decision(current_round, history)

    def _make_adaptive_decision(self, current_round: int, history: PlayerHistory) -> Action:
        total_rounds = history.round_number
        total_cooperators = 0
        for round_idx in range(total_rounds):
            if history.my_actions[round_idx]:
                total_cooperators += 1
            total_cooperators += np.sum(history.opponent_actions[round_idx, :])
        cooperation_rate = total_cooperators / (self.n * total_rounds)
        threshold_buffer = max(0.1, 1.0 / self.n)
        if self.n <= 4:
            threshold_buffer = 1.0 / (2 * self.n)
            if current_round <= 4:
                return Action.C
        if self.m / self.n > 0.6:
            if current_round <= self.r / 2:
                return Action.C
        cooperation_viable = cooperation_rate >= self.m / self.n - threshold_buffer
        if cooperation_rate >= self.m / self.n + 0.2:
            return Action.C
        if cooperation_viable and cooperation_rate < self.m / self.n + 0.2:
            return self._marginal_cooperation_decision(current_round, history)
        if not cooperation_viable:
            return self._low_cooperation_decision(current_round, history)
        if current_round > 0.8 * self.r:
            return self._endgame_decision(current_round, history)
        return Action.C

    def _marginal_cooperation_decision(self, current_round: int, history: PlayerHistory) -> Action:
        threshold_met_count = 0
        recent_rounds = min(3, history.round_number)
        for i in range(recent_rounds):
            round_idx = history.round_number - 1 - i
            cooperators = (1 if history.my_actions[round_idx] else 0) + np.sum(history.opponent_actions[round_idx, :])
            if cooperators >= self.m:
                threshold_met_count += 1
        if threshold_met_count >= 2:
            return Action.C
        if history.round_number > 0:
            last_cooperators = (1 if history.my_actions[-1] else 0) + np.sum(history.opponent_actions[-1, :])
            if last_cooperators == self.m:
                return Action.C
        if current_round <= self.r / 2:
            return Action.C
        return Action.D

    def _low_cooperation_decision(self, current_round: int, history: PlayerHistory) -> Action:
        if history.round_number > 0:
            last_cooperators = (1 if history.my_actions[-1] else 0) + np.sum(history.opponent_actions[-1, :])
            if last_cooperators >= self.m - 1:
                return Action.C
        rounds_since_threshold = 0
        for i in range(history.round_number):
            round_idx = history.round_number - 1 - i
            cooperators = (1 if history.my_actions[round_idx] else 0) + np.sum(history.opponent_actions[round_idx, :])
            if cooperators >= self.m:
                break
            rounds_since_threshold += 1
        if rounds_since_threshold >= 3:
            return Action.C
        base_prob = 0.4 if self.m / self.n > 0.6 else 0.3
        return Action.C if random.random() < base_prob else Action.D

    def _endgame_decision(self, current_round: int, history: PlayerHistory) -> Action:
        recent_rounds = min(5 if self.n >= 10 else history.round_number, history.round_number)
        threshold_met_count = 0
        for i in range(recent_rounds):
            round_idx = history.round_number - 1 - i
            cooperators = (1 if history.my_actions[round_idx] else 0) + np.sum(history.opponent_actions[round_idx, :])
            if cooperators >= self.m:
                threshold_met_count += 1
        success_rate = threshold_met_count / recent_rounds if recent_rounds > 0 else 0
        if success_rate > 0.6:
            return Action.C if random.random() < 1.2 else Action.D
        elif success_rate >= 0.3:
            if history.round_number > 0:
                last_cooperators = (1 if history.my_actions[-1] else 0) + np.sum(history.opponent_actions[-1, :])
                return Action.C if last_cooperators >= self.m - 1 else Action.D
        else:
            return Action.C if random.random() < 0.1 else Action.D
        return Action.D

class Strategy_COOPERATIVE_124(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperative Strategy (ATCS).
    
    Balances cooperative behavior with adaptive responses to observed opponent strategies,
    focusing on building and maintaining cooperation when feasible while protecting
    against exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        window_size = min(5, history.round_number)
        recent_cooperators = 0
        total_observations = 0
        for i in range(window_size):
            round_idx = history.round_number - 1 - i
            if round_idx >= 0:
                round_cooperators = int(history.my_actions[round_idx]) + sum(history.opponent_actions[round_idx, :])
                recent_cooperators += round_cooperators
                total_observations += self.n
        RCR = recent_cooperators / total_observations if total_observations > 0 else 0
        threshold_ratio_high = (self.m - 1) / self.n
        threshold_ratio_medium = max(0, (self.m - 2) / self.n)
        if RCR >= threshold_ratio_high:
            base_prob = 0.9
        elif RCR >= threshold_ratio_medium:
            base_prob = 0.7
        elif RCR >= 0.3:
            base_prob = 0.5
        else:
            base_prob = 0.2
        if history.round_number > 0:
            last_round_cooperators = int(history.my_actions[-1]) + sum(history.opponent_actions[-1, :])
            if last_round_cooperators >= self.m:
                base_prob = min(1.0, base_prob + 0.1)
        if current_round > 0.8 * self.r:
            overall_cooperators = sum(history.my_actions) + np.sum(history.opponent_actions)
            overall_observations = history.round_number * self.n
            overall_coop_rate = overall_cooperators / overall_observations if overall_observations > 0 else 0
            if overall_coop_rate < 0.4:
                base_prob = max(0.1, base_prob - 0.2)
            elif overall_coop_rate > 0.6:
                pass
        if history.round_number >= 2:
            recent_2_cooperators = 0
            for i in range(min(2, history.round_number)):
                round_idx = history.round_number - 1 - i
                round_cooperators = int(history.my_actions[round_idx]) + sum(history.opponent_actions[round_idx, :])
                recent_2_cooperators += round_cooperators
            recent_avg = recent_2_cooperators / (2 * self.n)
            if history.round_number >= 4:
                earlier_cooperators = 0
                for i in range(2, min(4, history.round_number)):
                    round_idx = history.round_number - 1 - i
                    round_cooperators = int(history.my_actions[round_idx]) + sum(history.opponent_actions[round_idx, :])
                    earlier_cooperators += round_cooperators
                earlier_avg = earlier_cooperators / (2 * self.n)
                if earlier_avg - recent_avg > 0.3:
                    base_prob = 0.6
        if self.m == self.n - 1:
            base_prob = min(1.0, base_prob + 0.1)
        if self.m == 2 and history.round_number > 0:
            last_round_cooperators = int(history.my_actions[-1]) + sum(history.opponent_actions[-1, :])
            if last_round_cooperators == self.m - 1:
                base_prob = min(1.0, base_prob + 0.1)
        if current_round == self.r:
            overall_cooperators = sum(history.my_actions) + np.sum(history.opponent_actions)
            overall_observations = history.round_number * self.n
            historical_coop_rate = overall_cooperators / overall_observations if overall_observations > 0 else 0
            if historical_coop_rate > 0.5:
                base_prob = 0.6
            else:
                base_prob = 0.3
        return Action.C if random.random() < base_prob else Action.D

class Strategy_COOPERATIVE_125(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS)
    
    Balances cooperative intent with adaptive self-protection, aiming to foster 
    collective success while maintaining robustness against exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.forgiveness_used = False
        self.recent_failure_recovery = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round < min(3, r // 3):
            return Action.C
        if current_round == r - 1:
            if len(history.opponent_actions) > 0:
                recent_coop_rate = sum(history.opponent_actions[-1, :]) / n
                return Action.C if recent_coop_rate >= m / n else Action.D
            return Action.C
        recent_rounds = min(2, len(history.opponent_actions))
        if recent_rounds == 0:
            return Action.C
        total_cooperators = 0
        for i in range(recent_rounds):
            round_idx = -(i + 1)
            cooperators_in_round = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators_in_round += 1
            total_cooperators += cooperators_in_round
        cooperation_rate = total_cooperators / (recent_rounds * n)
        expected_cooperators = cooperation_rate * n
        threshold_adjustment = self._calculate_threshold_adjustment(history, n, m)
        adjusted_threshold = m - 0.5 + threshold_adjustment
        max_possible_cooperators = self._estimate_max_cooperators(history, n) + 1
        if max_possible_cooperators < m:
            return Action.D
        if self._was_recently_successful(history, n, m) and expected_cooperators < adjusted_threshold:
            if not self.forgiveness_used:
                self.forgiveness_used = True
                return Action.C
        if self._should_promote_recovery(history, n, m):
            if not self.recent_failure_recovery:
                self.recent_failure_recovery = True
                return Action.C
        if expected_cooperators >= adjusted_threshold:
            self.forgiveness_used = False
            self.recent_failure_recovery = False
        if k > 3 and expected_cooperators >= m - 1:
            return Action.C
        return Action.C if expected_cooperators >= adjusted_threshold else Action.D

    def _calculate_threshold_adjustment(self, history: PlayerHistory, n: int, m: int) -> float:
        """Calculate dynamic threshold adjustment based on recent success rate."""
        if len(history.opponent_actions) < 3:
            return 0.0
        recent_rounds = min(5, len(history.opponent_actions))
        successful_rounds = 0
        for i in range(recent_rounds):
            round_idx = -(i + 1)
            cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators >= m:
                successful_rounds += 1
        success_rate = successful_rounds / recent_rounds
        if success_rate >= 0.8:
            return -0.2
        elif success_rate <= 0.4:
            return 0.2
        else:
            return 0.0

    def _estimate_max_cooperators(self, history: PlayerHistory, n: int) -> int:
        """Estimate maximum likely cooperators based on recent behavior."""
        if len(history.opponent_actions) < 2:
            return n - 1
        recent_rounds = min(3, len(history.opponent_actions))
        cooperation_scores = np.zeros(n - 1)
        for i in range(recent_rounds):
            round_idx = -(i + 1)
            cooperation_scores += history.opponent_actions[round_idx, :]
        likely_cooperators = sum(cooperation_scores >= recent_rounds / 2)
        return likely_cooperators

    def _was_recently_successful(self, history: PlayerHistory, n: int, m: int) -> bool:
        """Check if cooperation was successful in recent rounds."""
        if len(history.opponent_actions) < 2:
            return False
        for i in range(min(2, len(history.opponent_actions))):
            round_idx = -(i + 1)
            cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators >= m:
                return True
        return False

    def _should_promote_recovery(self, history: PlayerHistory, n: int, m: int) -> bool:
        """Check if we should promote recovery after failed cooperation."""
        if len(history.opponent_actions) < 1:
            return False
        last_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_cooperators += 1
        return last_cooperators < m and (not self.recent_failure_recovery)

class Strategy_COOPERATIVE_126(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperative Strategy (ATCS)
    
    Balances cooperative intent with adaptive learning, aiming to achieve collective 
    success while protecting against exploitation. Uses dynamic cooperation thresholds 
    based on recent history with special rules for forgiveness, momentum detection, 
    and crisis response.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n_players = self.game_description.n_players
        min_cooperators = self.game_description.m
        total_rounds = self.game_description.n_rounds
        current_round = history.round_number + 1
        lookback = min(3, history.round_number)
        recent_rounds = history.opponent_actions[-lookback:, :]
        recent_my_actions = history.my_actions[-lookback:]
        total_cooperators = 0
        for i in range(lookback):
            round_cooperators = sum(recent_rounds[i, :]) + int(recent_my_actions[i])
            total_cooperators += round_cooperators
        recent_coop_rate = total_cooperators / (lookback * n_players)
        base_threshold = min_cooperators / n_players
        volatility_adjustment = 0
        if lookback >= 2:
            coop_rates = []
            for i in range(lookback):
                round_cooperators = sum(recent_rounds[i, :]) + int(recent_my_actions[i])
                coop_rates.append(round_cooperators / n_players)
            volatility = max(coop_rates) - min(coop_rates)
            volatility_adjustment = 0.2 if volatility > 0.3 else 0
        adaptive_threshold = base_threshold + base_threshold * volatility_adjustment
        last_round_cooperators = sum(history.opponent_actions[-1, :]) + int(history.my_actions[-1])
        my_last_action = history.my_actions[-1]
        if not my_last_action and last_round_cooperators >= min_cooperators:
            return Action.C
        if last_round_cooperators < min_cooperators:
            return Action.C
        if lookback >= 2:
            trend_positive = True
            for i in range(lookback - 1):
                curr_cooperators = sum(recent_rounds[i, :]) + int(recent_my_actions[i])
                next_cooperators = sum(recent_rounds[i + 1, :]) + int(recent_my_actions[i + 1])
                if curr_cooperators > next_cooperators:
                    trend_positive = False
                    break
            if trend_positive and recent_coop_rate >= base_threshold * 0.9:
                return Action.C
        if current_round == total_rounds:
            if recent_coop_rate >= (min_cooperators + 1) / n_players:
                return Action.C
            elif recent_coop_rate < (min_cooperators - 1) / n_players:
                return Action.D
            else:
                my_coop_count = 0
                threshold_met_when_i_cooped = 0
                for i in range(history.round_number):
                    if history.my_actions[i]:
                        my_coop_count += 1
                        round_total_cooperators = sum(history.opponent_actions[i, :]) + 1
                        if round_total_cooperators >= min_cooperators:
                            threshold_met_when_i_cooped += 1
                if my_coop_count > 0:
                    reciprocation_rate = threshold_met_when_i_cooped / my_coop_count
                    return Action.C if reciprocation_rate >= 0.6 else Action.D
                else:
                    return Action.C
        return Action.C if recent_coop_rate >= adaptive_threshold else Action.D

class Strategy_COOPERATIVE_127(BaseStrategy):
    """
    Adaptive Threshold-Based Cooperation Strategy (ATCS)
    
    Balances cooperative intent with adaptive learning, aiming to achieve collective 
    success while protecting against exploitation. Uses cooperation rate tracking,
    threshold proximity assessment, and trend analysis to make decisions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.forgiveness_rounds_left = 0
        self.cautious_rounds_left = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number + 1
        recent_coop_rate = self._calculate_recent_cooperation_rate(history)
        threshold_needed = self.m / self.n
        buffer = threshold_needed + (0.15 if self.n <= 4 else 0.1)
        decline_floor = max(0.25, threshold_needed - 0.2)
        trend_positive = self._analyze_cooperation_trend(history)
        self._update_forgiveness_condition(history)
        self._update_cautious_condition(history)
        if self.cautious_rounds_left > 0:
            buffer += 0.15
            self.cautious_rounds_left -= 1
        if self.forgiveness_rounds_left > 0:
            buffer -= 0.1
            decline_floor -= 0.1
            self.forgiveness_rounds_left -= 1
        if current_round == self.r:
            return self._last_round_decision(history, threshold_needed)
        missed_by_small_margin = self._missed_by_small_margin(history)
        if recent_coop_rate >= buffer or (recent_coop_rate >= decline_floor and trend_positive) or missed_by_small_margin:
            return Action.C
        else:
            return Action.D

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate over recent rounds."""
        rounds_completed = history.round_number
        look_back = min(3, rounds_completed)
        if look_back == 0:
            return 0.0
        recent_opponent_actions = history.opponent_actions[-look_back:, :]
        recent_my_actions = history.my_actions[-look_back:]
        total_cooperators = 0
        total_players = 0
        for round_idx in range(look_back):
            round_cooperators = np.sum(recent_opponent_actions[round_idx, :])
            if recent_my_actions[round_idx]:
                round_cooperators += 1
            total_cooperators += round_cooperators
            total_players += self.n
        return total_cooperators / total_players if total_players > 0 else 0.0

    def _analyze_cooperation_trend(self, history: PlayerHistory) -> bool:
        """Analyze if cooperation trend is positive."""
        rounds_completed = history.round_number
        if rounds_completed < 2:
            return True
        look_back = min(3, rounds_completed)
        if look_back < 2:
            return True
        mid_point = look_back // 2
        if mid_point == 0:
            return True
        early_actions = history.opponent_actions[-look_back:-mid_point, :]
        early_my_actions = history.my_actions[-look_back:-mid_point]
        early_cooperators = np.sum(early_actions) + np.sum(early_my_actions)
        early_total = early_actions.shape[0] * self.n
        early_rate = early_cooperators / early_total if early_total > 0 else 0.0
        late_actions = history.opponent_actions[-mid_point:, :]
        late_my_actions = history.my_actions[-mid_point:]
        late_cooperators = np.sum(late_actions) + np.sum(late_my_actions)
        late_total = late_actions.shape[0] * self.n
        late_rate = late_cooperators / late_total if late_total > 0 else 0.0
        return late_rate >= early_rate

    def _missed_by_small_margin(self, history: PlayerHistory) -> bool:
        """Check if last round missed threshold by small margin."""
        if history.round_number == 0:
            return False
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        return last_round_cooperators in [self.m - 2, self.m - 1]

    def _update_forgiveness_condition(self, history: PlayerHistory) -> None:
        """Update forgiveness condition based on recent failures."""
        rounds_completed = history.round_number
        if rounds_completed < 2:
            return
        consecutive_failures = 0
        for i in range(min(3, rounds_completed)):
            round_idx = rounds_completed - 1 - i
            cooperators = np.sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators < self.m:
                if not history.my_actions[round_idx] and cooperators + 1 >= self.m:
                    consecutive_failures += 1
                elif history.my_actions[round_idx] and cooperators >= self.m - 1:
                    consecutive_failures += 1
                else:
                    break
            else:
                break
        if consecutive_failures >= 2 and self.forgiveness_rounds_left == 0:
            self.forgiveness_rounds_left = 2

    def _update_cautious_condition(self, history: PlayerHistory) -> None:
        """Update cautious mode based on exploitation detection."""
        rounds_completed = history.round_number
        if rounds_completed < 3:
            return
        recent_my_cooperations = 0
        look_back = min(3, rounds_completed)
        for i in range(look_back):
            if history.my_actions[rounds_completed - 1 - i]:
                recent_my_cooperations += 1
            else:
                break
        if recent_my_cooperations >= 3:
            others_coop_rate = 0.0
            total_others = 0
            for i in range(look_back):
                round_idx = rounds_completed - 1 - i
                others_coop_rate += np.sum(history.opponent_actions[round_idx, :])
                total_others += len(history.opponent_actions[round_idx, :])
            others_coop_rate = others_coop_rate / total_others if total_others > 0 else 0.0
            if others_coop_rate < 0.4 and self.cautious_rounds_left == 0:
                self.cautious_rounds_left = 2

    def _last_round_decision(self, history: PlayerHistory, threshold_needed: float) -> Action:
        """Enhanced cooperation logic for the last round."""
        rounds_completed = history.round_number
        recent_rounds = min(5, rounds_completed)
        successful_rounds = 0
        for i in range(recent_rounds):
            round_idx = rounds_completed - 1 - i
            cooperators = np.sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators >= self.m:
                successful_rounds += 1
        success_rate = successful_rounds / recent_rounds if recent_rounds > 0 else 0.0
        if success_rate >= 0.7:
            return Action.C
        recent_coop_rate = self._calculate_recent_cooperation_rate(history)
        if recent_coop_rate >= (self.m - 1) / self.n:
            return Action.C
        if self._analyze_cooperation_trend(history):
            return Action.C
        buffer = threshold_needed + (0.15 if self.n <= 4 else 0.1)
        decline_floor = max(0.25, threshold_needed - 0.2)
        if self.cautious_rounds_left > 0:
            buffer += 0.15
        if self.forgiveness_rounds_left > 0:
            buffer -= 0.1
            decline_floor -= 0.1
        trend_positive = self._analyze_cooperation_trend(history)
        missed_by_small_margin = self._missed_by_small_margin(history)
        if recent_coop_rate >= buffer or (recent_coop_rate >= decline_floor and trend_positive) or missed_by_small_margin:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_128(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS) - Balances cooperative intentions 
    with adaptive learning to build and maintain cooperative coalitions while protecting 
    against systematic exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.rebuilding_phase_rounds = 0
        self.in_cautious_mode = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = history.round_number + 1
        if round_num <= 0.2 * self.r:
            if self._cooperation_rate_last_k_rounds(history, 3) >= 0.3:
                return Action.C
        if round_num > 0.9 * self.r:
            return Action.C
        if self.rebuilding_phase_rounds > 0:
            self.rebuilding_phase_rounds -= 1
            return Action.C
        if self._check_start_rebuilding_phase(history):
            self.rebuilding_phase_rounds = 2
            return Action.C
        if self._cooperators_last_round(history) >= self.m - 1:
            return Action.C
        if self._cooperation_rate_last_k_rounds(history, 3) >= (self.m - 0.5) / self.n:
            return Action.C
        self._update_cautious_mode(history)
        if self.in_cautious_mode:
            if self._group_cooperation_rate_last_k_rounds(history, 3) >= 0.6:
                self.in_cautious_mode = False
                return Action.C
            else:
                return Action.D
        if self._cooperation_rate_last_k_rounds(history, 3) >= (self.m - 1) / self.n:
            return Action.C
        else:
            return Action.D

    def _cooperators_last_round(self, history: PlayerHistory) -> int:
        """Count cooperators in the most recent round."""
        if len(history.opponent_actions) == 0:
            return 0
        return int(sum(history.opponent_actions[-1, :]))

    def _cooperation_rate_last_k_rounds(self, history: PlayerHistory, k: int) -> float:
        """Calculate group cooperation rate over last k rounds."""
        if len(history.opponent_actions) == 0:
            return 0.0
        rounds_to_check = min(k, len(history.opponent_actions))
        if rounds_to_check == 0:
            return 0.0
        total_cooperators = 0
        total_players = 0
        for i in range(-rounds_to_check, 0):
            cooperators = int(sum(history.opponent_actions[i, :]))
            total_cooperators += cooperators
            total_players += len(history.opponent_actions[i, :])
        return total_cooperators / total_players if total_players > 0 else 0.0

    def _group_cooperation_rate_last_k_rounds(self, history: PlayerHistory, k: int) -> float:
        """Calculate overall group cooperation rate including self over last k rounds."""
        if len(history.my_actions) == 0:
            return 0.0
        rounds_to_check = min(k, len(history.my_actions))
        if rounds_to_check == 0:
            return 0.0
        total_cooperators = 0
        total_actions = 0
        for i in range(-rounds_to_check, 0):
            my_coop = int(history.my_actions[i])
            opp_coop = int(sum(history.opponent_actions[i, :]))
            total_cooperators += my_coop + opp_coop
            total_actions += 1 + len(history.opponent_actions[i, :])
        return total_cooperators / total_actions if total_actions > 0 else 0.0

    def _check_start_rebuilding_phase(self, history: PlayerHistory) -> bool:
        """Check if we should enter rebuilding phase after threshold miss."""
        if len(history.opponent_actions) == 0:
            return False
        last_round_cooperators = self._cooperators_last_round(history)
        my_last_action = bool(history.my_actions[-1])
        total_cooperators = last_round_cooperators + (1 if my_last_action else 0)
        if self.m - 2 <= total_cooperators < self.m:
            return True
        return False

    def _update_cautious_mode(self, history: PlayerHistory) -> None:
        """Update cautious mode based on exploitation detection."""
        if len(history.my_actions) < 5:
            return
        my_cooperation_rate = sum(history.my_actions[-5:]) / 5
        group_cooperation_rate = self._group_cooperation_rate_last_k_rounds(history, 5)
        if my_cooperation_rate >= 0.8 and group_cooperation_rate < 0.5:
            self.in_cautious_mode = True

class Strategy_AGGRESSIVE_1(BaseStrategy):
    """
    Threshold Predator: An aggressive exploitation strategy that free-rides on cooperators
    whenever the threshold is met, and only cooperates when absolutely necessary to prevent
    total collapse. Maximizes individual payoff through strategic defection and endgame betrayal.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        if history is None:
            if self.m > 0.8 * self.n:
                return Action.C
            else:
                return Action.D
        prev_round_idx = current_round - 1
        opponent_cooperators = sum(history.opponent_actions[prev_round_idx, :])
        my_prev_action = history.my_actions[prev_round_idx]
        total_cooperators = opponent_cooperators + (1 if my_prev_action else 0)
        if total_cooperators >= self.m:
            return Action.D
        deficit = self.m - total_cooperators
        rounds_remaining = self.r - current_round
        if rounds_remaining <= 0.2 * self.r:
            if random.random() < 0.9:
                return Action.D
            else:
                return Action.C
        total_actions = history.opponent_actions.size + len(history.my_actions)
        total_cooperations = np.sum(history.opponent_actions) + np.sum(history.my_actions)
        historical_coop_rate = total_cooperations / total_actions if total_actions > 0 else 0
        if deficit <= 2 and historical_coop_rate > 0.4 and (rounds_remaining > 1):
            if random.random() < 0.3:
                return Action.C
            else:
                return Action.D
        if current_round >= 2:
            recent_cooperations = []
            for round_idx in range(max(0, current_round - 2), current_round):
                round_cooperators = sum(history.opponent_actions[round_idx, :])
                if history.my_actions[round_idx]:
                    round_cooperators += 1
                recent_cooperations.append(round_cooperators)
            if all((coop == 0 for coop in recent_cooperations)):
                restart_prob = min(0.3, self.m / self.n)
                if random.random() < restart_prob:
                    return Action.C
        return Action.D

class Strategy_AGGRESSIVE_2(BaseStrategy):
    """
    Aggressive Threshold Exploitation Strategy (ATES): A ruthlessly opportunistic strategy that 
    cooperates only when absolutely necessary to trigger collective rewards, then immediately 
    reverts to defection. Exploits naive cooperators by being the "last cooperator in" and 
    "first defector out."
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.opponent_coop_counts = np.zeros(self.n - 1)
        self.successful_rounds = 0
        self.total_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        if current_round >= self.r - 2:
            return Action.D
        self._update_statistics(history)
        expected_coop = self._estimate_cooperators(history)
        success_rate = self.successful_rounds / max(self.total_rounds, 1)
        cooperation_threshold = self._get_dynamic_threshold(success_rate)
        should_cooperate = expected_coop < self.m - 0.5 and expected_coop > self.m - cooperation_threshold
        if success_rate > 0.8:
            should_cooperate = expected_coop < self.m - 0.8
        elif success_rate < 0.4:
            should_cooperate = expected_coop < self.m - 1.5
        consecutive_failures = self._count_recent_failures(history)
        if consecutive_failures >= 5 and success_rate < 0.2:
            return Action.C
        if abs(expected_coop - (self.m - 0.5)) < 0.1:
            recent_defections = self._count_recent_defections(history)
            if recent_defections >= 3 and success_rate < 0.5:
                return Action.C
            return Action.D
        if random.random() < 0.05 and current_round > 2:
            return Action.C if random.random() < 0.3 else Action.D
        return Action.C if should_cooperate else Action.D

    def _update_statistics(self, history: PlayerHistory):
        """Update tracking statistics based on history."""
        for round_idx in range(history.round_number):
            self.opponent_coop_counts += history.opponent_actions[round_idx, :]
        for round_idx in range(history.round_number):
            cooperators = int(history.my_actions[round_idx]) + np.sum(history.opponent_actions[round_idx, :])
            if cooperators >= self.m:
                self.successful_rounds += 1
        self.total_rounds = history.round_number

    def _estimate_cooperators(self, history: PlayerHistory):
        """Estimate number of cooperators for current round based on historical rates."""
        if history.round_number == 0:
            return 0
        coop_rates = self.opponent_coop_counts / history.round_number
        expected_coop = np.sum(coop_rates)
        uncertainty = random.uniform(-0.3, 0.3)
        expected_coop += uncertainty
        return max(0, expected_coop)

    def _get_dynamic_threshold(self, success_rate):
        """Adjust cooperation threshold based on group dynamics."""
        if success_rate > 0.8:
            return 0.3
        elif success_rate < 0.4:
            return 2.0
        else:
            return 2.0

    def _count_recent_failures(self, history: PlayerHistory):
        """Count consecutive failures in recent rounds."""
        if history.round_number < 5:
            return 0
        failures = 0
        for i in range(min(5, history.round_number)):
            round_idx = history.round_number - 1 - i
            cooperators = int(history.my_actions[round_idx]) + np.sum(history.opponent_actions[round_idx, :])
            if cooperators < self.m:
                failures += 1
            else:
                break
        return failures

    def _count_recent_defections(self, history: PlayerHistory):
        """Count consecutive defections by this player."""
        if history.round_number == 0:
            return 0
        defections = 0
        for i in range(min(3, history.round_number)):
            round_idx = history.round_number - 1 - i
            if not history.my_actions[round_idx]:
                defections += 1
            else:
                break
        return defections

class Strategy_AGGRESSIVE_3(BaseStrategy):
    """
    Aggressive Opportunistic Strategy: "Predator"
    
    This strategy operates on aggressive opportunism - it seeks to maximize personal gain 
    while minimizing risk exposure by letting others bear the cooperation burden while 
    reaping rewards when possible.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.opponent_cooperation_rates = np.zeros(self.n - 1)
        self.opponent_types = ['unknown'] * (self.n - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        if current_round == self.r - 1:
            return self._final_round_decision(history)
        return self._adaptive_exploitation_decision(history, current_round)

    def _adaptive_exploitation_decision(self, history: PlayerHistory, current_round: int) -> Action:
        last_round_cooperators = int(sum(history.opponent_actions[-1, :]))
        cooperation_rate = last_round_cooperators / (self.n - 1)
        recent_success_rate = self._calculate_recent_success_rate(history)
        min_cooperation_threshold = max(0.3, (self.m - 1) / (self.n - 1) + 0.1)
        if cooperation_rate >= min_cooperation_threshold and recent_success_rate > 0.6:
            return Action.D
        if cooperation_rate < (self.m - 1) / (self.n - 1) and current_round <= self.r * 0.7:
            if last_round_cooperators == self.m - 1:
                return Action.C
            else:
                return Action.D
        return Action.D

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        expected_cooperators = self._estimate_final_round_cooperators(history)
        if expected_cooperators >= self.m:
            return Action.D
        elif expected_cooperators == self.m - 1:
            if self.k >= 1.5:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _calculate_recent_success_rate(self, history: PlayerHistory) -> float:
        rounds_to_check = min(3, history.round_number)
        if rounds_to_check == 0:
            return 0.0
        successful_rounds = 0
        for i in range(1, rounds_to_check + 1):
            round_cooperators = int(sum(history.opponent_actions[-i, :])) + int(history.my_actions[-i])
            if round_cooperators >= self.m:
                successful_rounds += 1
        return successful_rounds / rounds_to_check

    def _estimate_final_round_cooperators(self, history: PlayerHistory) -> int:
        if history.round_number == 0:
            return 0
        for i in range(self.n - 1):
            cooperation_count = int(sum(history.opponent_actions[:, i]))
            self.opponent_cooperation_rates[i] = cooperation_count / history.round_number
        expected_cooperators = 0
        for i in range(self.n - 1):
            cooperation_rate = self.opponent_cooperation_rates[i]
            adjusted_rate = cooperation_rate * 0.8
            if cooperation_rate > 0.5:
                recent_success = self._calculate_recent_success_rate(history)
                if recent_success > 0.5:
                    adjusted_rate = cooperation_rate * 0.9
            if random.random() < adjusted_rate:
                expected_cooperators += 1
        return expected_cooperators

class Strategy_AGGRESSIVE_4(BaseStrategy):
    """
    Opportunistic Hawk: An aggressive exploitative strategy that maximizes personal gain
    while minimizing cooperation costs. Cooperates only when calculated to be profitable
    and exploits opponent cooperation patterns.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.initial_phase_end = min(3, self.r // 4)
        self.endgame_phase_start = max(self.r - min(2, self.r // 5), self.initial_phase_end + 1)
        self.last_cooperation_round = -10

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.last_cooperation_round = -10
            return Action.D
        current_round = history.round_number
        if current_round < self.initial_phase_end:
            return Action.D
        if current_round >= self.endgame_phase_start:
            return self._endgame_decision(history)
        return self._adaptive_exploitation_decision(history)

    def _endgame_decision(self, history: PlayerHistory) -> Action:
        current_round = history.round_number
        if current_round == self.r - 1:
            return Action.D
        if current_round == self.r - 2:
            last_cooperators = self._count_total_cooperators(history, -1)
            if last_cooperators == self.m - 1:
                expected_gain = self.k - 1.0
                if expected_gain > 1.5:
                    self.last_cooperation_round = current_round
                    return Action.C
        return Action.D

    def _adaptive_exploitation_decision(self, history: PlayerHistory) -> Action:
        current_round = history.round_number
        if not self._check_cooperation_conditions(history):
            return Action.D
        exploitation_score = self._calculate_exploitation_score(history)
        defection_bias = self._calculate_defection_bias(history)
        adjusted_threshold = 0.3 + defection_bias
        if exploitation_score > adjusted_threshold and current_round - self.last_cooperation_round >= 2:
            self.last_cooperation_round = current_round
            return Action.C
        return Action.D

    def _check_cooperation_conditions(self, history: PlayerHistory) -> bool:
        """Check if basic conditions for cooperation are met."""
        last_cooperators = self._count_total_cooperators(history, -1)
        return last_cooperators == self.m - 1 or last_cooperators == self.m

    def _calculate_exploitation_score(self, history: PlayerHistory) -> float:
        """Calculate expected payoff advantage from cooperation."""
        last_cooperators = self._count_total_cooperators(history, -1)
        if last_cooperators >= self.m - 1:
            expected_payoff_cooperate = self.k - 1.0
            prob_threshold_met_without_me = min(0.8, last_cooperators / self.m)
            expected_payoff_defect = prob_threshold_met_without_me * self.k
            return expected_payoff_cooperate - expected_payoff_defect
        return -1.0

    def _calculate_defection_bias(self, history: PlayerHistory) -> float:
        """Calculate additional bias toward defection based on recent patterns."""
        bias = 0.0
        if len(history.my_actions) >= 3:
            recent_coop_rate = self._get_cooperation_rate(history, 3)
            if recent_coop_rate < 0.4:
                bias += 0.2
        if self._been_rewarded_for_defection(history):
            bias += 0.3
        if self._detect_declining_cooperation(history):
            bias += 0.2
        if self.k < 1.5:
            bias += 0.3
        return bias

    def _count_total_cooperators(self, history: PlayerHistory, round_idx: int) -> int:
        """Count total cooperators (including self) in a given round."""
        if round_idx < 0:
            round_idx = len(history.my_actions) + round_idx
        if round_idx < 0 or round_idx >= len(history.my_actions):
            return 0
        my_action = 1 if history.my_actions[round_idx] else 0
        opponent_cooperators = sum(history.opponent_actions[round_idx, :])
        return my_action + opponent_cooperators

    def _get_cooperation_rate(self, history: PlayerHistory, last_n_rounds: int) -> float:
        """Get cooperation rate across all players in last n rounds."""
        if len(history.my_actions) < last_n_rounds:
            last_n_rounds = len(history.my_actions)
        if last_n_rounds == 0:
            return 0.0
        total_cooperations = 0
        total_decisions = 0
        for i in range(last_n_rounds):
            round_idx = len(history.my_actions) - 1 - i
            total_cooperations += self._count_total_cooperators(history, round_idx)
            total_decisions += self.n
        return total_cooperations / total_decisions if total_decisions > 0 else 0.0

    def _been_rewarded_for_defection(self, history: PlayerHistory) -> bool:
        """Check if consistently rewarded for defection (threshold met despite defection)."""
        rewards = 0
        defections = 0
        for i in range(min(3, len(history.my_actions))):
            round_idx = len(history.my_actions) - 1 - i
            if not history.my_actions[round_idx]:
                defections += 1
                if history.my_payoffs[round_idx] > 1.0:
                    rewards += 1
        return defections > 0 and rewards / defections > 0.6

    def _detect_declining_cooperation(self, history: PlayerHistory) -> bool:
        """Detect if opponent cooperation is declining."""
        if len(history.my_actions) < 4:
            return False
        recent_rounds = min(6, len(history.my_actions))
        mid_point = recent_rounds // 2
        early_rate = 0.0
        late_rate = 0.0
        for i in range(mid_point):
            round_idx = len(history.my_actions) - recent_rounds + i
            early_rate += sum(history.opponent_actions[round_idx, :])
        early_rate /= mid_point * (self.n - 1)
        for i in range(mid_point, recent_rounds):
            round_idx = len(history.my_actions) - recent_rounds + i
            late_rate += sum(history.opponent_actions[round_idx, :])
        late_rate /= (recent_rounds - mid_point) * (self.n - 1)
        return late_rate < early_rate - 0.1

class Strategy_AGGRESSIVE_5(BaseStrategy):
    """
    Aggressive Threshold Exploitation Strategy (ATES) - Maximum exploitation with minimal contribution.
    Only cooperates when holding decisive swing vote power, punishes failed thresholds, and maximizes free-riding.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_rounds_remaining = 0
        self.recent_defection_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.recent_defection_streak = 1
            return Action.D
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        k = self.game_description.k
        current_round = state.round_number
        if current_round == r - 1:
            return Action.D
        if self.punishment_rounds_remaining > 0:
            self.punishment_rounds_remaining -= 1
            self.recent_defection_streak += 1
            return Action.D
        if current_round > 0:
            last_round_cooperators = sum(history.opponent_actions[-1, :])
            if history.my_actions[-1]:
                last_round_cooperators += 1
            if last_round_cooperators < m:
                self.punishment_rounds_remaining = 1
                self.recent_defection_streak += 1
                return Action.D
        rounds_played = len(history.my_actions)
        coop_rates = []
        for player_idx in range(n - 1):
            cooperations = sum(history.opponent_actions[:, player_idx])
            coop_rate = cooperations / rounds_played
            coop_rates.append(coop_rate)
        expected_coop = sum(coop_rates)
        if m > 0.8 * n and current_round <= r // 2:
            if expected_coop >= m - 1:
                self.recent_defection_streak = 0
                return Action.C
        if m <= 0.3 * n:
            if abs(expected_coop - (m - 1)) < 0.1:
                self.recent_defection_streak = 0
                return Action.C
            else:
                self.recent_defection_streak += 1
                return Action.D
        if r <= 3:
            if expected_coop >= m - 0.9 and expected_coop < m:
                self.recent_defection_streak = 0
                return Action.C
            else:
                self.recent_defection_streak += 1
                return Action.D
        if expected_coop >= m:
            self.recent_defection_streak += 1
            return Action.D
        elif expected_coop >= m - 1:
            if self.recent_defection_streak < 2:
                self.recent_defection_streak = 0
                return Action.C
            else:
                self.recent_defection_streak += 1
                return Action.D
        else:
            self.recent_defection_streak += 1
            return Action.D

class Strategy_AGGRESSIVE_6(BaseStrategy):
    """
    Predatory Threshold Rider: An aggressive exploitation strategy that maximizes personal gain
    by free-riding on others' cooperation while strategically cooperating only when pivotal.
    Uses three phases: initial exploitation, strategic monitoring, and endgame exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.opponent_cooperate_counts = np.zeros(self.n - 1)
        self.opponent_total_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        rounds_completed = history.round_number
        rounds_remaining = self.r - current_round
        if rounds_completed > 0:
            self.opponent_cooperate_counts += history.opponent_actions[-1, :]
            self.opponent_total_rounds = rounds_completed
        if current_round <= self.r // 3:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[-1, :])) if rounds_completed > 0 else 0
        predicted_cooperators = self._predict_cooperators(history)
        if self.opponent_total_rounds > 0:
            cooperate_rates = self.opponent_cooperate_counts / self.opponent_total_rounds
            consistent_cooperators = int(np.sum(cooperate_rates > 0.8))
        else:
            consistent_cooperators = 0
        if current_round <= 2 * self.r // 3:
            return self._strategic_monitoring_decision(predicted_cooperators, rounds_remaining)
        else:
            return self._endgame_decision(current_round, cooperators_last_round, consistent_cooperators, predicted_cooperators, rounds_remaining, history)

    def _predict_cooperators(self, history):
        """Estimate how many opponents will cooperate this round"""
        if history.round_number < 2:
            return int(np.sum(history.opponent_actions[-1, :]))
        recent_coop_1 = int(np.sum(history.opponent_actions[-1, :]))
        recent_coop_2 = int(np.sum(history.opponent_actions[-2, :]))
        trend = recent_coop_1 - recent_coop_2
        predicted = recent_coop_1 + max(-1, min(1, trend))
        return max(0, min(self.n - 1, predicted))

    def _strategic_monitoring_decision(self, predicted_cooperators, rounds_remaining):
        """Decision logic for Phase 2: Strategic Monitoring"""
        if predicted_cooperators >= self.m - 1:
            return Action.D
        elif predicted_cooperators == self.m - 2:
            if rounds_remaining > self.r // 4:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _endgame_decision(self, current_round, cooperators_last_round, consistent_cooperators, predicted_cooperators, rounds_remaining, history):
        """Decision logic for Phase 3: Endgame Exploitation"""
        if current_round == self.r:
            return Action.D
        i_was_cooperator = history.my_actions[-1] if history.round_number > 0 else False
        if cooperators_last_round >= self.m and consistent_cooperators >= self.m - 1:
            return Action.D
        if cooperators_last_round == self.m - 1 and i_was_cooperator:
            return Action.D
        if predicted_cooperators == self.m - 1 and rounds_remaining * self.k > 2:
            return Action.C
        return Action.D

class Strategy_AGGRESSIVE_7(BaseStrategy):
    """
    Aggressive Adaptive Exploitation Strategy (AAES)
    
    A strategy built on aggressive exploitation with minimal cooperation.
    Free-rides whenever possible while only cooperating when absolutely 
    necessary to secure the collective reward.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == r:
            return Action.D
        last_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_cooperators += 1
        deficit = m - last_cooperators
        if deficit <= 0:
            return Action.D
        rounds_to_check = min(3, len(history.my_actions))
        total_cooperation = 0
        total_players = 0
        for i in range(rounds_to_check):
            round_idx = len(history.my_actions) - 1 - i
            round_cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                round_cooperators += 1
            total_cooperation += round_cooperators
            total_players += n
        momentum = total_cooperation / total_players if total_players > 0 else 0
        if momentum >= 0.6 or momentum < 0.4:
            return Action.D
        if n <= 4:
            if deficit <= 1 and momentum >= 0.3:
                if current_round >= r - 1:
                    return Action.D
                return Action.C
            return Action.D
        if m > n / 2:
            if deficit <= 2 and momentum >= 0.7:
                return Action.C
            return Action.D
        if k <= 1.5:
            if deficit == 1 and momentum >= 0.8:
                return Action.C
            return Action.D
        if deficit <= n / 3 or deficit > 2 * n / 3:
            return Action.D
        else:
            return Action.C

class Strategy_AGGRESSIVE_8(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Calculated Parasite"
    
    This strategy maximizes individual payoffs by exploiting cooperative players while
    minimizing personal risk. It defects whenever possible and only cooperates when
    absolutely necessary to prevent total collapse.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        cooperation_forecast = self._estimate_cooperators_this_round(history)
        my_cooperation_needed = max(0, self.m - cooperation_forecast)
        if my_cooperation_needed == 0:
            return Action.D
        elif my_cooperation_needed == 1:
            if self.k >= 2.0:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _estimate_cooperators_this_round(self, history: PlayerHistory) -> float:
        """Forecast how many opponents will cooperate this round."""
        n_opponents = self.n - 1
        current_round = history.round_number
        cooperation_forecast = 0.0
        for opponent_idx in range(n_opponents):
            cooperations = np.sum(history.opponent_actions[:, opponent_idx])
            cooperation_rate = cooperations / current_round if current_round > 0 else 0.5
            recent_rounds = min(3, current_round)
            if recent_rounds > 0:
                recent_cooperations = np.sum(history.opponent_actions[-recent_rounds:, opponent_idx])
                recent_trend = recent_cooperations / recent_rounds
            else:
                recent_trend = cooperation_rate
            adjusted_rate = 0.6 * cooperation_rate + 0.4 * recent_trend
            post_failure_boost = 0.0
            if current_round > 0:
                last_round_cooperators = np.sum(history.opponent_actions[-1, :]) + int(history.my_actions[-1])
                if last_round_cooperators < self.m:
                    post_failure_boost = 0.15
            expected_cooperation = adjusted_rate + post_failure_boost
            if cooperation_rate > 0.7:
                expected_cooperation = min(1.0, expected_cooperation * 1.1)
            if self.k < 1.5:
                expected_cooperation *= 0.85
            if self.m > 0.7 * self.n:
                expected_cooperation *= 1.1
            if current_round >= 3:
                recent_avg_cooperation = np.mean(history.opponent_actions[-3:, opponent_idx])
                if recent_avg_cooperation < 0.3 and recent_avg_cooperation < cooperation_rate:
                    expected_cooperation *= 0.7
            if current_round >= 2 * self.r // 3:
                expected_cooperation *= 0.9
            cooperation_forecast += min(1.0, max(0.0, expected_cooperation))
        cooperation_forecast *= 0.85
        return math.floor(cooperation_forecast + 0.5)

class Strategy_AGGRESSIVE_9(BaseStrategy):
    """
    Aggressive Threshold Exploitation Strategy: Maximizes personal payoff by strategically free-riding
    on others' cooperation while only contributing when absolutely necessary to unlock collective bonus.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.sucker_threshold = 0.7
        self.defector_threshold = 0.3
        self.cooperation_bias = 0.8
        self.false_signal_rate = 0.05

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        round_num = history.round_number
        early_phase = round_num <= self.r // 3
        middle_phase = self.r // 3 < round_num <= 2 * self.r // 3
        final_phase = round_num > 2 * self.r // 3
        if round_num == self.r - 1:
            return Action.D
        opponent_types = self._categorize_opponents(history)
        predicted_cooperators = self._predict_cooperators(history, opponent_types, final_phase)
        effective_threshold = self._calculate_effective_threshold(history)
        if predicted_cooperators >= effective_threshold:
            action = Action.D
        elif predicted_cooperators == effective_threshold - 1:
            action = Action.C
        else:
            action = Action.D
        action = self._apply_phase_tactics(action, round_num, history, early_phase, middle_phase, final_phase)
        action = self._apply_emergency_protocols(action, history)
        if action == Action.D and random.random() < self.false_signal_rate:
            if predicted_cooperators >= effective_threshold:
                action = Action.C
        return action

    def _categorize_opponents(self, history):
        """Categorize opponents as Suckers, Conditionals, or Defectors"""
        n_opponents = self.n - 1
        opponent_types = []
        for opponent_idx in range(n_opponents):
            opponent_actions = history.opponent_actions[:, opponent_idx]
            cooperation_rate = np.mean(opponent_actions)
            if cooperation_rate > self.sucker_threshold:
                opponent_types.append('sucker')
            elif cooperation_rate < self.defector_threshold:
                opponent_types.append('defector')
            else:
                opponent_types.append('conditional')
        return opponent_types

    def _predict_cooperators(self, history, opponent_types, final_phase):
        """Predict how many opponents will cooperate this round"""
        predicted = 0
        n_opponents = self.n - 1
        bias_factor = 0.6 if final_phase else self.cooperation_bias
        for i, opp_type in enumerate(opponent_types):
            if opp_type == 'sucker':
                if random.random() < bias_factor:
                    predicted += 1
            elif opp_type == 'defector':
                continue
            else:
                recent_success = self._check_recent_success(history)
                if recent_success and random.random() < bias_factor:
                    predicted += 1
        return predicted

    def _check_recent_success(self, history):
        """Check if threshold was met in recent rounds"""
        if history.round_number < 3:
            return True
        recent_rounds = min(3, history.round_number)
        recent_my_actions = history.my_actions[-recent_rounds:]
        recent_opponent_actions = history.opponent_actions[-recent_rounds:, :]
        successes = 0
        for i in range(recent_rounds):
            total_cooperators = int(recent_my_actions[i]) + np.sum(recent_opponent_actions[i, :])
            if total_cooperators >= self.m:
                successes += 1
        return successes / recent_rounds > 0.5

    def _calculate_effective_threshold(self, history):
        """Adjust threshold based on recent success rates"""
        if history.round_number < 3:
            return self.m
        recent_success_rate = self._calculate_recent_success_rate(history)
        if recent_success_rate > 0.8:
            return self.m + 1
        elif recent_success_rate < 0.3:
            return max(1, self.m - 1)
        else:
            return self.m

    def _calculate_recent_success_rate(self, history):
        """Calculate success rate over recent rounds"""
        recent_rounds = min(5, history.round_number)
        recent_my_actions = history.my_actions[-recent_rounds:]
        recent_opponent_actions = history.opponent_actions[-recent_rounds:, :]
        successes = 0
        for i in range(recent_rounds):
            total_cooperators = int(recent_my_actions[i]) + np.sum(recent_opponent_actions[i, :])
            if total_cooperators >= self.m:
                successes += 1
        return successes / recent_rounds if recent_rounds > 0 else 0.5

    def _apply_phase_tactics(self, action, round_num, history, early_phase, middle_phase, final_phase):
        """Apply phase-specific tactical modifications"""
        if early_phase:
            pass
        elif middle_phase:
            recent_success_rate = self._calculate_recent_success_rate(history)
            if recent_success_rate > 0.8 and action == Action.C:
                if random.random() < 0.3:
                    action = Action.D
        elif final_phase:
            if self.r - round_num <= 3 and action == Action.C:
                if random.random() < 0.4:
                    action = Action.D
        return action

    def _apply_emergency_protocols(self, action, history):
        """Handle emergency situations"""
        if history.round_number < 2:
            return action
        consecutive_failures = self._count_consecutive_failures(history)
        if consecutive_failures >= 2:
            recent_my_actions = history.my_actions[-3:] if history.round_number >= 3 else history.my_actions
            recent_opponent_actions = history.opponent_actions[-3:, :] if history.round_number >= 3 else history.opponent_actions
            last_round_cooperators = np.sum(recent_opponent_actions[-1, :])
            if last_round_cooperators == self.m - 1:
                action = Action.C
        return action

    def _count_consecutive_failures(self, history):
        """Count consecutive rounds where threshold was not met"""
        if history.round_number == 0:
            return 0
        consecutive = 0
        for i in range(history.round_number - 1, -1, -1):
            total_cooperators = int(history.my_actions[i]) + np.sum(history.opponent_actions[i, :])
            if total_cooperators < self.m:
                consecutive += 1
            else:
                break
        return consecutive

class Strategy_AGGRESSIVE_10(BaseStrategy):
    """
    Opportunistic Predator: An aggressive exploitation strategy that maximizes personal payoffs
    by free-riding on others' cooperation while only cooperating when absolutely necessary
    to secure collective benefits.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.opponent_coop_counts = np.zeros(self.n_players - 1)
        self.recent_failure_penalty = 0
        self.exploration_rounds = max(3, math.ceil(0.15 * self.n_rounds))
        self.endgame_start = math.ceil(0.8 * self.n_rounds)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        if current_round >= self.endgame_start:
            return Action.D
        if current_round > 0:
            self.opponent_coop_counts += history.opponent_actions[-1, :]
            last_round_cooperators = sum(history.opponent_actions[-1, :]) + int(history.my_actions[-1])
            if last_round_cooperators < self.m:
                self.recent_failure_penalty = 2
            elif self.recent_failure_penalty > 0:
                self.recent_failure_penalty -= 1
        if current_round < self.exploration_rounds:
            return Action.D
        return self._adaptive_exploitation_decision(history)

    def _adaptive_exploitation_decision(self, history: PlayerHistory) -> Action:
        current_round = history.round_number
        total_opponent_actions = current_round * (self.n_players - 1)
        if total_opponent_actions == 0:
            expected_cooperators = 0
        else:
            recent_weight = 2.0
            recent_rounds = min(3, current_round)
            if current_round >= recent_rounds:
                recent_coops = np.sum(history.opponent_actions[-recent_rounds:, :])
                older_coops = np.sum(self.opponent_coop_counts) - recent_coops
                older_rounds = current_round - recent_rounds
                if older_rounds > 0:
                    weighted_coop_rate = (recent_coops * recent_weight + older_coops) / (recent_rounds * recent_weight + older_rounds)
                else:
                    weighted_coop_rate = recent_coops / recent_rounds
            else:
                weighted_coop_rate = np.sum(self.opponent_coop_counts) / total_opponent_actions
            weighted_coop_rate /= self.n_players - 1
            expected_cooperators = weighted_coop_rate * (self.n_players - 1)
        if self.recent_failure_penalty > 0:
            expected_cooperators *= 0.8
        reliable_cooperators = 0
        conditional_cooperators = 0
        defectors = 0
        for i in range(self.n_players - 1):
            coop_rate = self.opponent_coop_counts[i] / current_round if current_round > 0 else 0
            if coop_rate > 0.7:
                reliable_cooperators += 1
            elif coop_rate > 0.3:
                conditional_cooperators += 1
            else:
                defectors += 1
        adjusted_expected = reliable_cooperators + 0.5 * conditional_cooperators
        if adjusted_expected >= self.m:
            return Action.D
        elif adjusted_expected >= self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_AGGRESSIVE_11(BaseStrategy):
    """
    Threshold Predator: An aggressive exploitation strategy that free-rides whenever possible
    while strategically cooperating only when absolutely necessary to secure group benefits.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            if self.m >= self.n / 2:
                return Action.C
            else:
                return Action.D
        current_round = state.round_number + 1
        if current_round == self.r:
            return Action.D
        last_round_idx = history.round_number - 1
        last_cooperators = sum(history.opponent_actions[last_round_idx, :])
        if history.my_actions[last_round_idx]:
            total_last_cooperators = last_cooperators + 1
        else:
            total_last_cooperators = last_cooperators
        coop_rate = total_last_cooperators / self.n
        if coop_rate >= (self.m - 1) / self.n:
            return Action.D
        successful_rounds = 0
        for round_idx in range(history.round_number):
            round_cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                round_cooperators += 1
            if round_cooperators >= self.m:
                successful_rounds += 1
        success_rate = successful_rounds / history.round_number
        if success_rate > 0.7:
            return Action.D
        if coop_rate >= self.m / self.n - 0.2:
            return Action.D
        else:
            return Action.C

class Strategy_AGGRESSIVE_12(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Predatory Opportunist"
    
    This strategy exploits cooperation patterns by strategically timing cooperation
    to trigger reward thresholds while minimizing personal contributions. It operates
    through three phases: early exploitation, strategic manipulation, and endgame exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.opponent_cooperation_rates = np.zeros(self.n - 1)
        self.opponent_recent_patterns = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number + 1
        self._update_opponent_tracking(history)
        if current_round == self.r:
            return Action.D
        committed_cooperators = self._count_likely_cooperators(history, current_round)
        if current_round <= self.r // 3:
            return self._early_phase_decision(committed_cooperators, history)
        elif current_round <= 2 * self.r // 3:
            return self._middle_phase_decision(committed_cooperators, history)
        else:
            return self._endgame_phase_decision(committed_cooperators, history)

    def _update_opponent_tracking(self, history):
        """Update tracking of opponent cooperation patterns"""
        n_rounds_played = history.round_number
        for i in range(self.n - 1):
            self.opponent_cooperation_rates[i] = np.mean(history.opponent_actions[:, i])
        if n_rounds_played >= 1:
            recent_rounds = min(3, n_rounds_played)
            self.opponent_recent_patterns = history.opponent_actions[-recent_rounds:, :]

    def _count_likely_cooperators(self, history, current_round):
        """Estimate number of opponents likely to cooperate this round"""
        if history.round_number == 0:
            return np.sum(history.opponent_actions[0, :])
        likely_cooperators = 0
        for i in range(self.n - 1):
            coop_rate = self.opponent_cooperation_rates[i]
            if coop_rate > 0.8:
                likely_cooperators += 1
            elif coop_rate >= 0.4:
                if history.round_number >= 1 and history.opponent_actions[-1, i]:
                    likely_cooperators += 0.7
        return int(likely_cooperators)

    def _early_phase_decision(self, committed_cooperators, history):
        """Decision logic for early rounds (1 to r/3)"""
        if committed_cooperators == self.m - 1:
            if history.round_number >= 2:
                recent_coop_trend = np.mean(np.sum(history.opponent_actions[-2:, :], axis=1))
                if recent_coop_trend >= self.m - 1:
                    return Action.C
        return Action.D

    def _middle_phase_decision(self, committed_cooperators, history):
        """Decision logic for strategic manipulation phase"""
        if committed_cooperators == self.m - 1:
            confidence = self._assess_cooperation_confidence(history)
            if confidence > 0.7:
                return Action.C
        if committed_cooperators >= self.m:
            return Action.D
        return Action.D

    def _endgame_phase_decision(self, committed_cooperators, history):
        """Decision logic for endgame exploitation"""
        current_round = history.round_number + 1
        if current_round == self.r:
            return Action.D
        if committed_cooperators >= self.m:
            return Action.D
        if committed_cooperators == self.m - 1 and current_round < self.r - 1 and self._guaranteed_threshold_check(history):
            return Action.C
        return Action.D

    def _assess_cooperation_confidence(self, history):
        """Assess confidence in cooperation predictions"""
        if history.round_number < 2:
            return 0.5
        consistency_scores = []
        for i in range(self.n - 1):
            if history.round_number >= 3:
                recent_actions = history.opponent_actions[-3:, i]
                consistency = np.std(recent_actions.astype(float))
                consistency_scores.append(1 - consistency)
        return np.mean(consistency_scores) if consistency_scores else 0.5

    def _guaranteed_threshold_check(self, history):
        """Check if we can guarantee threshold will be met"""
        reliable_cooperators = 0
        for i in range(self.n - 1):
            if self.opponent_cooperation_rates[i] > 0.9:
                reliable_cooperators += 1
        return reliable_cooperators >= self.m - 1

class Strategy_AGGRESSIVE_13(BaseStrategy):
    """
    Aggressive Adaptive Strategy: "Threshold Exploiter"
    
    This strategy aggressively maximizes individual payoff by exploiting the threshold nature 
    of the game. It aims to contribute as little as possible while still benefiting from 
    others' cooperation, and quickly punishes groups that fail to meet thresholds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_rounds_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if history is None:
            self.punishment_rounds_remaining = 0
            return Action.D
        if current_round == r - 1:
            return Action.D
        previous_cooperators = int(sum(history.opponent_actions[-1, :])) + int(history.my_actions[-1])
        my_previous_action = history.my_actions[-1]
        consecutive_defections = 0
        for i in range(len(history.my_actions) - 1, -1, -1):
            if not history.my_actions[i]:
                consecutive_defections += 1
            else:
                break
        if self.punishment_rounds_remaining > 0:
            self.punishment_rounds_remaining -= 1
            return Action.D
        if previous_cooperators < m:
            remaining_rounds = r - current_round
            self.punishment_rounds_remaining = min(2, remaining_rounds - 1)
            if self.punishment_rounds_remaining > 0:
                self.punishment_rounds_remaining -= 1
            return Action.D
        opponent_coop_rate = sum(history.opponent_actions[-1, :]) / (n - 1)
        if consecutive_defections >= 3 and opponent_coop_rate > 0.6:
            return Action.C
        if previous_cooperators >= m:
            if my_previous_action:
                return Action.D
            if previous_cooperators < m + 2:
                return Action.D
            if previous_cooperators >= m + 3:
                return Action.C
        if n <= 4:
            if sum(history.opponent_actions[-1, :]) == n - 1:
                return Action.C
            return Action.D
        if m > 2 * n // 3:
            if previous_cooperators >= m - 1:
                return Action.C
        if k <= 1.5:
            if previous_cooperators >= m + 4:
                return Action.C
            return Action.D
        return Action.D

class Strategy_AGGRESSIVE_14(BaseStrategy):
    """
    Aggressive Exploit-and-Punish Strategy for Collective Risk Dilemma.
    
    Maximizes personal payoffs through calculated exploitation while maintaining 
    ability to secure collective rewards when necessary. Always defects in first 
    and last rounds, exploits cooperation when threshold buffer is exceeded, and 
    cooperates strategically when needed to reach minimum threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.exploitation_margin = max(1, math.floor(self.n / 4))
        self.threshold_buffer = (self.m + self.exploitation_margin) / self.n
        self.consecutive_failures = 0
        self.punishment_mode = False
        self.punishment_rounds_left = 0
        self.opponent_cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        self._update_punishment_state(history)
        if self.punishment_mode:
            return self._punishment_protocol(history)
        if current_round > self.r / 2:
            failure_rate = self.consecutive_failures / current_round
            if failure_rate > 1 / 3:
                return self._salvage_mode(history)
        return self._adaptive_exploitation(history)

    def _update_punishment_state(self, history: PlayerHistory):
        """Update punishment state based on recent collective failures."""
        if len(history.my_actions) >= 2:
            recent_failures = 0
            for i in range(-2, 0):
                if i + len(history.my_actions) >= 0:
                    round_cooperators = sum(history.opponent_actions[i, :])
                    if history.my_actions[i]:
                        round_cooperators += 1
                    if round_cooperators < self.m:
                        recent_failures += 1
            if recent_failures >= 2 and (not self.punishment_mode):
                self.punishment_mode = True
                self.punishment_rounds_left = 2
        if self.punishment_mode:
            self.punishment_rounds_left -= 1
            if self.punishment_rounds_left <= 0:
                self.punishment_mode = False

    def _punishment_protocol(self, history: PlayerHistory) -> Action:
        """Conditional cooperation during punishment phase."""
        if len(history.my_actions) == 0:
            return Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if last_round_cooperators >= self.m - 1:
            return Action.C
        return Action.D

    def _salvage_mode(self, history: PlayerHistory) -> Action:
        """Salvage mode for groups with frequent failures."""
        predicted_cooperators = self._predict_cooperators(history)
        if predicted_cooperators >= self.m - 1:
            return Action.C
        return Action.D

    def _adaptive_exploitation(self, history: PlayerHistory) -> Action:
        """Main adaptive exploitation logic."""
        if len(history.my_actions) == 0:
            return Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        cooperation_rate = last_round_cooperators / (self.n - 1)
        if cooperation_rate >= self.threshold_buffer:
            return Action.D
        predicted_cooperators = self._predict_cooperators(history)
        if predicted_cooperators + 1 >= self.m:
            return Action.C
        return Action.D

    def _predict_cooperators(self, history: PlayerHistory) -> int:
        """Predict how many opponents will cooperate based on patterns."""
        if len(history.my_actions) == 0:
            return 0
        predicted_cooperators = 0
        n_opponents = self.n - 1
        for opponent_idx in range(n_opponents):
            cooperation_prob = self._predict_opponent_cooperation(history, opponent_idx)
            if cooperation_prob > 0.5:
                predicted_cooperators += 1
        return predicted_cooperators

    def _predict_opponent_cooperation(self, history: PlayerHistory, opponent_idx: int) -> float:
        """Predict single opponent's cooperation probability."""
        if len(history.my_actions) == 0:
            return 0.5
        opponent_history = history.opponent_actions[:, opponent_idx]
        recent_rounds = min(3, len(opponent_history))
        if recent_rounds == 0:
            return 0.5
        recent_actions = opponent_history[-recent_rounds:]
        recent_cooperation_rate = sum(recent_actions) / recent_rounds
        if len(opponent_history) >= 3:
            early_rate = sum(opponent_history[-3:-1]) / 2 if len(opponent_history) >= 3 else recent_cooperation_rate
            trend_factor = recent_cooperation_rate - early_rate
            predicted_prob = recent_cooperation_rate + trend_factor * 0.5
            return max(0.0, min(1.0, predicted_prob))
        return recent_cooperation_rate

class Strategy_AGGRESSIVE_15(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Threshold Predator"
    
    This strategy aggressively exploits cooperative players while minimizing personal risk.
    It aims to free-ride on others' cooperation whenever possible, only cooperating when
    absolutely necessary to secure the collective benefit.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        prev_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        if prev_cooperators == self.m - 1:
            if self._detect_reliable_cooperators(history) >= self.m:
                return Action.D
            else:
                return Action.C
        elif prev_cooperators >= self.m:
            return Action.D
        elif self._detect_defector_swarm(history) and prev_cooperators >= self.m - 2:
            return Action.C
        else:
            return Action.D

    def _detect_reliable_cooperators(self, history: PlayerHistory) -> int:
        """Count players with cooperation rate > 0.7"""
        rounds_played = history.round_number
        if rounds_played == 0:
            return 0
        reliable_count = 0
        for player in range(self.n - 1):
            coop_count = np.sum(history.opponent_actions[:, player])
            coop_rate = coop_count / rounds_played
            if coop_rate > 0.7:
                reliable_count += 1
        return reliable_count

    def _detect_defector_swarm(self, history: PlayerHistory) -> bool:
        """Check if < m players have cooperation rate > 0.3"""
        rounds_played = history.round_number
        if rounds_played == 0:
            return False
        potential_cooperators = 0
        for player in range(self.n - 1):
            coop_count = np.sum(history.opponent_actions[:, player])
            coop_rate = coop_count / rounds_played
            if coop_rate > 0.3:
                potential_cooperators += 1
        my_coop_rate = np.sum(history.my_actions) / rounds_played if rounds_played > 0 else 0
        if my_coop_rate > 0.3:
            potential_cooperators += 1
        return potential_cooperators < self.m

class Strategy_AGGRESSIVE_16(BaseStrategy):
    """
    Threshold Predator: An aggressive exploitation strategy that maximizes personal payoffs
    by strategically free-riding on others' cooperation while minimizing its own contributions.
    Only cooperates when collective failure is imminent and personal benefit is possible.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        early_phase_end = self.r // 3
        mid_phase_end = 2 * self.r // 3
        cooperation_count_last_round = int(np.sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            cooperation_count_last_round += 1
        if history.round_number > 0:
            opponent_coop_rates = np.mean(history.opponent_actions, axis=0)
            reliable_cooperators = int(np.sum(opponent_coop_rates > 0.6))
            if history.round_number >= 2:
                recent_cooperators = int(np.sum(np.all(history.opponent_actions[-2:, :], axis=0)))
            else:
                recent_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        else:
            reliable_cooperators = 0
            recent_cooperators = 0
        estimated_cooperators = reliable_cooperators + 0.5 * recent_cooperators
        my_recent_coop_rate = np.mean(history.my_actions[-min(5, len(history.my_actions)):])
        if current_round <= early_phase_end:
            if cooperation_count_last_round < self.m - 1:
                return Action.C
            else:
                return Action.D
        elif current_round <= mid_phase_end:
            if estimated_cooperators >= self.m - 1:
                return Action.D
            elif estimated_cooperators >= self.m - 2:
                if my_recent_coop_rate < 0.3:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.C
        else:
            total_rounds_so_far = history.round_number
            rounds_threshold_missed = 0
            for round_idx in range(total_rounds_so_far):
                round_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
                if history.my_actions[round_idx]:
                    round_cooperators += 1
                if round_cooperators < self.m:
                    rounds_threshold_missed += 1
            threshold_miss_rate = rounds_threshold_missed / total_rounds_so_far if total_rounds_so_far > 0 else 0
            if current_round == self.r:
                return Action.D
            if threshold_miss_rate > 0.4:
                if estimated_cooperators == self.m - 1:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D

class Strategy_AGGRESSIVE_17(BaseStrategy):
    """
    Aggressive Threshold Exploitation Strategy - Maximizes personal payoff by exploiting others' cooperation
    while minimizing own contributions. Cooperates only when absolutely necessary to secure collective reward.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if current_round == r:
            return Action.D
        rounds_remaining = r - current_round
        cooperators_last_round = sum(history.opponent_actions[-1, :])
        lookback_rounds = min(3, len(history.my_actions))
        recent_cooperation_rates = []
        for i in range(lookback_rounds):
            round_idx = -(i + 1)
            round_cooperators = sum(history.opponent_actions[round_idx, :])
            recent_cooperation_rates.append(round_cooperators / (n - 1))
        cooperation_trend = np.mean(recent_cooperation_rates) if recent_cooperation_rates else 0
        expected_cooperators = self._predict_cooperators_this_round(history, current_round, cooperators_last_round, cooperation_trend, rounds_remaining)
        my_contribution_needed = expected_cooperators < m
        if current_round > 0.8 * r:
            my_contribution_needed = expected_cooperators < m - 1
        if my_contribution_needed and rounds_remaining > 1:
            return Action.C
        else:
            return Action.D

    def _predict_cooperators_this_round(self, history, current_round, cooperators_last_round, cooperation_trend, rounds_remaining):
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        reliable_cooperators = 0
        for player in range(n - 1):
            player_cooperation_rate = np.mean(history.opponent_actions[:, player])
            if player_cooperation_rate >= 0.6:
                reliable_cooperators += 1
        momentum_bonus = 0
        if cooperators_last_round >= m:
            momentum_bonus = 1
        desperation_factor = max(0, (m - reliable_cooperators) * rounds_remaining / r)
        consecutive_failures = self._count_consecutive_failures(history)
        failure_adjustment = 0
        if consecutive_failures >= 2:
            failure_adjustment = math.ceil(0.2 * (n - 1))
        predicted = reliable_cooperators + momentum_bonus + desperation_factor + failure_adjustment
        return min(n - 1, max(0, predicted))

    def _count_consecutive_failures(self, history):
        """Count consecutive rounds where cooperation threshold was not met"""
        m = self.game_description.m
        failures = 0
        for i in range(len(history.my_actions)):
            round_idx = -(i + 1)
            total_cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                total_cooperators += 1
            if total_cooperators < m:
                failures += 1
            else:
                break
        return failures

class Strategy_AGGRESSIVE_18(BaseStrategy):
    """
    Threshold Hunter: An aggressive exploitation strategy that maximizes payoff by defecting 
    whenever possible while strategically cooperating only when absolutely necessary to 
    maintain the collective threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.cooperation_rates = np.zeros(self.n - 1)
        self.retaliation_tendencies = np.zeros(self.n - 1)
        self.recent_cooperation_window = min(3, self.r)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        rounds_remaining = self.r - current_round - 1
        if rounds_remaining == 0:
            return Action.D
        self._update_opponent_patterns(history)
        predicted_cooperators = self._predict_cooperators(history)
        cooperation_pressure = max(0, self.m - predicted_cooperators) / self.m
        endgame_threshold = max(2, self.r // 4)
        if rounds_remaining <= endgame_threshold:
            cooperation_threshold = self.m + 2
        else:
            cooperation_threshold = self.m
        if predicted_cooperators >= cooperation_threshold:
            return Action.D
        elif predicted_cooperators == self.m - 1:
            my_recent_defection_rate = self._get_my_recent_defection_rate(history)
            if rounds_remaining > 3 and my_recent_defection_rate < 0.8:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _update_opponent_patterns(self, history: PlayerHistory):
        """Update cooperation rates and retaliation tendencies for opponents."""
        n_rounds = history.round_number
        for i in range(self.n - 1):
            total_cooperations = np.sum(history.opponent_actions[:, i])
            self.cooperation_rates[i] = total_cooperations / n_rounds
            if n_rounds >= 2:
                for round_idx in range(1, n_rounds):
                    if not history.my_actions[round_idx - 1]:
                        if history.opponent_actions[round_idx - 1, i] and (not history.opponent_actions[round_idx, i]):
                            self.retaliation_tendencies[i] += 0.3
                            self.retaliation_tendencies[i] = min(1.0, self.retaliation_tendencies[i])

    def _predict_cooperators(self, history: PlayerHistory) -> int:
        """Predict how many opponents will cooperate next round."""
        predicted_cooperators = 0
        n_rounds = history.round_number
        for i in range(self.n - 1):
            cooperation_rate = self.cooperation_rates[i]
            window_start = max(0, n_rounds - self.recent_cooperation_window)
            recent_cooperations = np.sum(history.opponent_actions[window_start:, i])
            recent_rounds = n_rounds - window_start
            will_cooperate = False
            if cooperation_rate > 0.6:
                will_cooperate = True
            elif recent_cooperations >= 2 and cooperation_rate > 0.3 and (recent_rounds >= 2):
                will_cooperate = True
            elif recent_rounds > 0 and recent_cooperations / recent_rounds > 0.7:
                will_cooperate = True
            if will_cooperate:
                predicted_cooperators += 1
        return predicted_cooperators

    def _get_my_recent_defection_rate(self, history: PlayerHistory) -> float:
        """Calculate my defection rate in recent rounds."""
        n_rounds = history.round_number
        if n_rounds == 0:
            return 0.0
        window_start = max(0, n_rounds - self.recent_cooperation_window)
        recent_actions = history.my_actions[window_start:]
        recent_defections = np.sum(~recent_actions)
        return recent_defections / len(recent_actions)

class Strategy_AGGRESSIVE_19(BaseStrategy):
    """
    HAWK-PREDATOR: Aggressive exploitation strategy that maximizes individual payoff
    through strategic free-riding, threshold manipulation, and psychological warfare.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.traitors = set()
        self.exploitables = set()
        self.cooperation_counts = np.zeros(self.n - 1)
        self.success_count = 0
        self.total_rounds_completed = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number + 1
        self.total_rounds_completed = history.round_number
        self._update_state(history)
        phase1_end = max(1, self.r // 3)
        phase2_end = max(phase1_end + 1, 2 * self.r // 3)
        if current_round <= phase1_end:
            return self._phase1_decision(history)
        elif current_round <= phase2_end:
            return self._phase2_decision(history)
        else:
            return self._phase3_decision(history, current_round)

    def _update_state(self, history: PlayerHistory):
        """Update internal tracking of opponents and game state"""
        if history.round_number == 0:
            return
        last_round_actions = history.opponent_actions[-1, :]
        self.cooperation_counts += last_round_actions
        last_cooperators = np.sum(last_round_actions)
        if history.my_actions[-1]:
            last_cooperators += 1
        if last_cooperators >= self.m:
            self.success_count += 1
            if history.round_number > 1:
                prev_actions = history.opponent_actions[-2, :]
                for i in range(self.n - 1):
                    if prev_actions[i] and (not last_round_actions[i]):
                        self.traitors.add(i)
        else:
            for i in range(self.n - 1):
                if last_round_actions[i]:
                    self.exploitables.add(i)

    def _phase1_decision(self, history: PlayerHistory) -> Action:
        """Phase 1: Always DEFECT for initial exploitation"""
        return Action.D

    def _phase2_decision(self, history: PlayerHistory) -> Action:
        """Phase 2: Strategic parasitism - cooperate only when decisive"""
        if history.round_number == 0:
            return Action.D
        last_cooperators = np.sum(history.opponent_actions[-1, :])
        rounds_played = history.round_number
        consistent_cooperators = np.sum(self.cooperation_counts / rounds_played > 0.6)
        should_cooperate = last_cooperators == self.m - 1 and consistent_cooperators >= 3 and (self.k > 1 + self.k / 2)
        return Action.C if should_cooperate else Action.D

    def _phase3_decision(self, history: PlayerHistory, current_round: int) -> Action:
        """Phase 3: Endgame aggression with threshold manipulation"""
        if current_round == self.r:
            return Action.D
        if current_round == self.r - 1:
            if self.total_rounds_completed > 0:
                avg_cooperation_rate = np.mean(self.cooperation_counts) / self.total_rounds_completed
                return Action.C if avg_cooperation_rate > 0.9 else Action.D
            return Action.D
        return self._threshold_manipulation(history, current_round)

    def _threshold_manipulation(self, history: PlayerHistory, current_round: int) -> Action:
        """Apply threshold manipulation rules"""
        if self.total_rounds_completed == 0:
            return Action.D
        cooperation_rates = self.cooperation_counts / self.total_rounds_completed
        expected_cooperators = np.sum(cooperation_rates > 0.5)
        if expected_cooperators >= self.m + 2:
            return Action.D
        elif expected_cooperators == self.m + 1:
            return Action.D
        elif expected_cooperators == self.m:
            personal_gain = self.k - 1
            return Action.C if personal_gain > 0.5 else Action.D
        else:
            return Action.D

    def _apply_punishment_protocol(self, base_decision: Action) -> Action:
        """Apply punishment against identified traitors"""
        if base_decision == Action.C:
            if len(self.traitors) > 0 and self.k <= 2:
                return Action.D
        return base_decision

    def _adjust_for_adaptation(self, base_decision: Action) -> Action:
        """Apply dynamic threshold adjustment based on success rate"""
        if self.total_rounds_completed < 3:
            return base_decision
        success_rate = self.success_count / self.total_rounds_completed
        if success_rate < 0.3 and base_decision == Action.D:
            if random.random() < 0.15:
                return Action.C
        if success_rate > 0.7 and base_decision == Action.C:
            if random.random() < 0.25:
                return Action.D
        return base_decision

class Strategy_AGGRESSIVE_20(BaseStrategy):
    """
    Threshold Predator: An aggressive exploitation strategy that maximizes free-riding
    while maintaining minimal strategic cooperation to avoid system collapse.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.punishment_rounds_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        if self.punishment_rounds_remaining > 0:
            self.punishment_rounds_remaining -= 1
            return Action.D
        total_rounds_played = history.round_number
        total_cooperations = np.sum(history.opponent_actions)
        coop_rate = total_cooperations / (total_rounds_played * (self.n - 1)) if total_rounds_played > 0 else 0
        expected_coops = coop_rate * (self.n - 1)
        last_round_coop_rate = 0
        if total_rounds_played > 0:
            last_round_cooperators = np.sum(history.opponent_actions[-1, :])
            last_round_coop_rate = last_round_cooperators / (self.n - 1)
        if last_round_coop_rate >= 0.7:
            return Action.D
        if total_rounds_played > 0:
            if history.my_actions[-1] == True:
                total_last_round_coops = np.sum(history.opponent_actions[-1, :]) + 1
                if total_last_round_coops < self.m:
                    self.punishment_rounds_remaining = 1
                    return Action.D
        if expected_coops >= self.m:
            return Action.D
        if expected_coops >= self.m - 1:
            my_coop_rate = np.sum(history.my_actions) / total_rounds_played if total_rounds_played > 0 else 0
            if my_coop_rate < 0.3:
                return Action.C
        rounds_remaining = self.r - current_round
        if rounds_remaining <= 0.2 * self.r:
            rounds_remaining_ratio = rounds_remaining / self.r
            defection_boost = (1 - rounds_remaining_ratio) * 0.15
            if random.random() < defection_boost:
                return Action.D
        if self.n <= 4:
            if expected_coops >= self.m - 1 and random.random() < 0.1:
                return Action.C
        if self.m / self.n > 0.7:
            if expected_coops >= self.m - 2:
                return Action.C
            if last_round_coop_rate > 0.8:
                return Action.D
        if self.k < 1.5:
            my_coop_rate = np.sum(history.my_actions) / total_rounds_played if total_rounds_played > 0 else 0
            if not (expected_coops == self.m - 1 and my_coop_rate < 0.2):
                return Action.D
        if total_rounds_played > 0:
            total_last_round_coops = np.sum(history.opponent_actions[-1, :])
            if history.my_actions[-1] == True:
                total_last_round_coops += 1
            if total_last_round_coops == self.m:
                return Action.D
        return Action.D

class Strategy_AGGRESSIVE_21(BaseStrategy):
    """
    Threshold Hawk: Aggressive exploitation strategy that free-rides on others' cooperation
    while minimizing personal risk. Only cooperates when absolutely necessary to secure
    collective benefits, with maximum aggression in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        if current_round == self.r - 2:
            total_cooperations = np.sum(history.opponent_actions) + np.sum(history.my_actions)
            total_possible = self.n * len(history.my_actions)
            cooperation_rate = total_cooperations / total_possible
            if cooperation_rate > 0.6:
                return Action.D
            elif cooperation_rate < 0.3:
                return Action.D
            else:
                cooperators_last_round = np.sum(history.opponent_actions[-1, :])
                if history.my_actions[-1]:
                    cooperators_last_round += 1
                if cooperators_last_round >= self.m - 1:
                    return Action.C
                else:
                    return Action.D
        if len(history.my_actions) > 0:
            prev_cooperators = np.sum(history.opponent_actions[-1, :])
            if history.my_actions[-1]:
                prev_cooperators += 1
            if prev_cooperators == self.m - 1:
                return Action.C
            if prev_cooperators == self.m and history.my_actions[-1] and (prev_cooperators < self.m + 2):
                return Action.C
        if len(history.my_actions) >= 3:
            my_cooperation_rate = np.sum(history.my_actions) / len(history.my_actions)
            if my_cooperation_rate > 0.3:
                total_cooperation_rate = (np.sum(history.opponent_actions) + np.sum(history.my_actions)) / (self.n * len(history.my_actions))
                if total_cooperation_rate < 0.5:
                    return Action.D
        return Action.D

class Strategy_AGGRESSIVE_22(BaseStrategy):
    """
    AGGRESSIVE EXPLOITATION STRATEGY: "SHARK"
    
    Operates on aggressive exploitation principles - maximizing personal payoff while minimizing risk.
    Uses three phases: Early Reconnaissance (always defect), Conditional Exploitation (strategic cooperation),
    and Endgame Defection (always defect in final rounds).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        early_phase_end = min(3, self.r // 4)
        if current_round <= early_phase_end:
            return Action.D
        if current_round > self.r - 2:
            return Action.D
        return self._conditional_exploitation_decision(history)

    def _conditional_exploitation_decision(self, history: PlayerHistory) -> Action:
        """Main decision logic for conditional exploitation phase."""
        cooperators_last_round = int(sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            cooperators_last_round += 1
        threshold_proximity = cooperators_last_round >= self.m - 2
        exploitation_opportunity = self._has_exploitation_opportunity(history)
        profitable = self.k >= 1.5
        if threshold_proximity and exploitation_opportunity and profitable:
            if self.m > self.n // 2 and cooperators_last_round != self.m - 1:
                return Action.D
            return Action.C
        return Action.D

    def _has_exploitation_opportunity(self, history: PlayerHistory) -> bool:
        """Check if there are enough consistent defectors to exploit."""
        if len(history.my_actions) < 2:
            return False
        consistent_defectors = 0
        rounds_to_check = min(2, len(history.my_actions))
        for player_idx in range(self.n - 1):
            defected_consistently = True
            for round_back in range(rounds_to_check):
                round_idx = len(history.my_actions) - 1 - round_back
                if history.opponent_actions[round_idx, player_idx]:
                    defected_consistently = False
                    break
            if defected_consistently:
                consistent_defectors += 1
        return consistent_defectors >= self.n - self.m

class Strategy_AGGRESSIVE_23(BaseStrategy):
    """
    Threshold Predator: Aggressive exploitation strategy that free-rides on cooperation
    while minimizing personal risk. Only cooperates when absolutely necessary for
    personal benefit.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.opponent_cooperation_rates = np.zeros(self.n - 1)
        self.exploitable_opponents = np.zeros(self.n - 1, dtype=bool)
        self.punishment_rounds_left = 0
        self.last_cooperation_failed = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        if self.punishment_rounds_left > 0:
            self.punishment_rounds_left -= 1
            return Action.D
        self._update_opponent_analysis(history)
        projected_cooperators = self._predict_cooperators(history)
        effective_threshold = self._get_effective_threshold(history)
        if current_round == self.r - 1:
            return self._final_round_decision(projected_cooperators)
        elif current_round >= self.r - 2:
            return self._late_game_decision(history, projected_cooperators, effective_threshold)
        else:
            return self._middle_game_decision(history, projected_cooperators, effective_threshold)

    def _update_opponent_analysis(self, history):
        """Update opponent cooperation rates and identify exploitable players"""
        n_rounds = history.round_number
        for i in range(self.n - 1):
            total_cooperations = sum(history.opponent_actions[:, i])
            self.opponent_cooperation_rates[i] = total_cooperations / n_rounds
            if n_rounds >= 2:
                last_round_cooperators = sum(history.opponent_actions[-1, :])
                if history.opponent_actions[-1, i] and last_round_cooperators < self.m - 1:
                    self.exploitable_opponents[i] = True

    def _predict_cooperators(self, history):
        """Predict number of cooperators using weighted recent history"""
        n_rounds = history.round_number
        recent_window = min(3, max(1, n_rounds // 2))
        projected_cooperators = 0
        for i in range(self.n - 1):
            if self.opponent_cooperation_rates[i] > 0.8:
                coop_prob = 0.95
            elif self.opponent_cooperation_rates[i] < 0.4:
                coop_prob = 0.05
            else:
                recent_cooperations = sum(history.opponent_actions[-recent_window:, i])
                recent_rate = recent_cooperations / recent_window
                overall_rate = self.opponent_cooperation_rates[i]
                coop_prob = recent_rate * 0.7 + overall_rate * 0.3
                if self.exploitable_opponents[i]:
                    coop_prob = min(1.0, coop_prob * 1.2)
            projected_cooperators += coop_prob
        return projected_cooperators

    def _get_effective_threshold(self, history):
        """Adjust cooperation threshold based on performance"""
        threshold = self.m
        if history.round_number >= 3:
            recent_payoffs = history.my_payoffs[-3:]
            if np.mean(recent_payoffs) > 2.0:
                threshold += 1
        if history.round_number >= 5:
            avg_payoff = np.mean(history.my_payoffs)
            if avg_payoff < 1.5:
                threshold = max(1, threshold - 0.5)
        return threshold

    def _middle_game_decision(self, history, projected_cooperators, threshold):
        """Decision logic for middle game rounds"""
        if projected_cooperators >= threshold:
            if history.round_number > 0 and history.my_actions[-1] == True and (sum(history.opponent_actions[-1, :]) + 1 < self.m):
                self.punishment_rounds_left = 1
                return Action.D
            else:
                return Action.D
        elif projected_cooperators >= self.m - 1:
            return Action.C
        else:
            return Action.D

    def _late_game_decision(self, history, projected_cooperators, threshold):
        """Decision logic for second-to-last round"""
        avg_payoff = np.mean(history.my_payoffs)
        if avg_payoff < 1.8:
            threshold += 1
        if projected_cooperators >= threshold:
            return Action.D
        elif projected_cooperators >= self.m - 1:
            return Action.C
        else:
            return Action.D

    def _final_round_decision(self, projected_cooperators):
        """End-game aggression: only cooperate if exactly necessary"""
        if abs(projected_cooperators - (self.m - 1)) < 0.1:
            return Action.C
        else:
            return Action.D

class Strategy_AGGRESSIVE_24(BaseStrategy):
    """
    Threshold Predator - Aggressive exploitation strategy that maximizes individual payoff
    by free-riding on others' cooperation while strategically cooperating only when pivotal.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        round_num = state.round_number
        if round_num >= self.r - 2:
            return Action.D
        cooperators_last_round = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            cooperators_last_round += 1
        phase = self._get_phase(round_num)
        if phase == 'endgame' and round_num >= self.r - 3:
            return Action.D
        if cooperators_last_round == self.m - 1:
            return Action.C
        elif cooperators_last_round >= self.m + 2:
            return Action.D
        elif cooperators_last_round < self.m - 1:
            avg_cooperation = self._calculate_cooperation_trend(history)
            if avg_cooperation < self.m / self.n:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _get_phase(self, round_num):
        """Determine current phase based on round number."""
        phase_boundary_1 = math.ceil(self.r / 3)
        phase_boundary_2 = math.ceil(2 * self.r / 3)
        if round_num <= phase_boundary_1:
            return 'exploitation'
        elif round_num <= phase_boundary_2:
            return 'adaptation'
        else:
            return 'endgame'

    def _calculate_cooperation_trend(self, history):
        """Calculate average cooperation rate across all players."""
        total_rounds = len(history.my_actions)
        if total_rounds == 0:
            return 0.0
        my_cooperations = sum(history.my_actions)
        opponent_cooperations = np.sum(history.opponent_actions)
        total_cooperations = my_cooperations + opponent_cooperations
        total_possible = total_rounds * self.n
        return total_cooperations / total_possible if total_possible > 0 else 0.0

class Strategy_AGGRESSIVE_25(BaseStrategy):
    """
    Threshold Predator: An aggressive exploitation strategy that maximizes personal payoff
    by free-riding on others' cooperation while maintaining the collective benefit threshold.
    Uses adaptive exploitation, momentum tracking, and endgame optimization.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round <= 2:
            return Action.D
        if current_round >= self.r - 2:
            return self._endgame_strategy(history)
        return self._adaptive_exploitation_strategy(history)

    def _adaptive_exploitation_strategy(self, history: PlayerHistory) -> Action:
        prev_round = history.round_number - 1
        my_prev_action = int(history.my_actions[prev_round])
        opponent_cooperators = int(np.sum(history.opponent_actions[prev_round, :]))
        total_cooperators = my_prev_action + opponent_cooperators
        if total_cooperators >= self.m + 2:
            return Action.D
        elif total_cooperators == self.m + 1:
            return Action.D
        elif total_cooperators == self.m:
            return Action.C if random.random() < 0.3 else Action.D
        else:
            cooperation_momentum = self._analyze_momentum(history)
            if cooperation_momentum == 'declining':
                return Action.C
            else:
                return Action.C

    def _analyze_momentum(self, history: PlayerHistory) -> str:
        rounds_completed = history.round_number
        if rounds_completed < 3:
            return 'stable'
        cooperation_rates = []
        for i in range(max(0, rounds_completed - 3), rounds_completed):
            my_action = int(history.my_actions[i])
            opponent_cooperators = int(np.sum(history.opponent_actions[i, :]))
            total_cooperators = my_action + opponent_cooperators
            cooperation_rates.append(total_cooperators / self.n)
        if len(cooperation_rates) < 2:
            return 'stable'
        declining = all((cooperation_rates[i] >= cooperation_rates[i + 1] for i in range(len(cooperation_rates) - 1)))
        if declining and cooperation_rates[-1] < cooperation_rates[0] - 0.1:
            return 'declining'
        if all((rate > 0.7 for rate in cooperation_rates)):
            return 'high_stable'
        return 'stable'

    def _endgame_strategy(self, history: PlayerHistory) -> Action:
        current_round = history.round_number
        if current_round == self.r - 1:
            return Action.D
        historical_coop_rate = self._calculate_historical_cooperation_rate(history)
        if historical_coop_rate > 0.7:
            return Action.D
        elif historical_coop_rate < 0.4:
            return Action.C
        else:
            return Action.D

    def _calculate_historical_cooperation_rate(self, history: PlayerHistory) -> float:
        total_cooperations = 0
        total_decisions = 0
        for round_idx in range(history.round_number):
            my_action = int(history.my_actions[round_idx])
            opponent_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
            total_cooperations += my_action + opponent_cooperators
            total_decisions += self.n
        return total_cooperations / total_decisions if total_decisions > 0 else 0.0

class Strategy_AGGRESSIVE_26(BaseStrategy):
    """
    Aggressive Adaptive Exploitation Strategy (AAES) - A calculated free-rider strategy
    that maximizes personal payoffs by exploiting cooperative opponents while minimizing
    personal risk through strategic threshold manipulation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number + 1
        if round_num == self.r:
            return Action.D
        if history is None:
            return Action.D
        if round_num <= self.r // 3:
            if round_num > 1:
                last_round_cooperators = sum(history.opponent_actions[-1, :])
                i_defected_last = not history.my_actions[-1]
                if last_round_cooperators == self.m - 1 and i_defected_last:
                    return Action.C
            return Action.D
        total_rounds = history.round_number
        opponent_coop_rates = np.mean(history.opponent_actions, axis=0)
        avg_cooperators = np.sum(opponent_coop_rates)
        if round_num <= 2 * self.r // 3:
            threshold = 0.7
        else:
            threshold = 0.8
        if avg_cooperators >= self.m + 1:
            return Action.D
        if avg_cooperators < self.m - 1:
            return Action.D
        if self.m - 1 <= avg_cooperators < self.m + 1:
            top_coop_indices = np.argsort(opponent_coop_rates)[-min(self.m - 1, len(opponent_coop_rates)):]
            top_coop_rates = opponent_coop_rates[top_coop_indices]
            if len(top_coop_rates) > 0 and np.all(top_coop_rates > threshold):
                return Action.D
            else:
                return Action.C
        return Action.D

class Strategy_AGGRESSIVE_27(BaseStrategy):
    """
    Aggressive Threshold Exploitation Strategy that free-rides whenever possible
    while cooperating strategically only when absolutely necessary to prevent
    threshold failure and maintain long-term exploitation opportunities.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        expected_cooperators = self._calculate_expected_cooperation(history)
        cooperation_threshold = self._calculate_dynamic_threshold(current_round, history)
        if expected_cooperators >= self.m:
            return Action.D
        if expected_cooperators == self.m - 1:
            if random.random() < cooperation_threshold:
                return Action.C
            else:
                return Action.D
        if expected_cooperators < self.m - 1:
            recent_failures = self._count_recent_failures(history)
            if current_round >= self.r - 1 or recent_failures > 2:
                return Action.C
            else:
                return Action.D
        return Action.D

    def _calculate_expected_cooperation(self, history: PlayerHistory) -> int:
        """Calculate expected number of cooperators based on historical patterns"""
        if history.round_number == 0:
            return 0
        expected_cooperators = 0
        for player_idx in range(self.n - 1):
            player_actions = history.opponent_actions[:, player_idx]
            cooperation_rate = np.mean(player_actions.astype(float))
            if history.round_number >= 3:
                recent_actions = player_actions[-3:]
                recent_rate = np.mean(recent_actions.astype(float))
                cooperation_rate = 0.6 * recent_rate + 0.4 * cooperation_rate
            expected_cooperators += cooperation_rate
        return int(round(expected_cooperators))

    def _calculate_dynamic_threshold(self, current_round: int, history: PlayerHistory) -> float:
        """Calculate dynamic cooperation threshold based on game state"""
        base_threshold = 0.5
        round_adjustment = 0.1 * (current_round / self.r)
        history_adjustment = 0.0
        if history.round_number > 0:
            avg_cooperation = np.mean(history.opponent_actions.astype(float))
            history_adjustment = -0.2 * (avg_cooperation - 0.5)
        success_adjustment = 0.0
        if history.round_number >= 2:
            threshold_achievement_rate = self._calculate_threshold_success_rate(history)
            if threshold_achievement_rate < 0.7:
                success_adjustment = 0.2
        cooperation_threshold = base_threshold + round_adjustment + history_adjustment + success_adjustment
        return max(0.3, min(0.8, cooperation_threshold))

    def _calculate_threshold_success_rate(self, history: PlayerHistory) -> float:
        """Calculate historical threshold achievement rate"""
        successes = 0
        total_rounds = history.round_number
        for round_idx in range(total_rounds):
            opponent_cooperators = sum(history.opponent_actions[round_idx, :])
            my_cooperation = 1 if history.my_actions[round_idx] else 0
            total_cooperators = opponent_cooperators + my_cooperation
            if total_cooperators >= self.m:
                successes += 1
        return successes / total_rounds if total_rounds > 0 else 0.0

    def _count_recent_failures(self, history: PlayerHistory) -> int:
        """Count threshold failures in recent rounds"""
        if history.round_number < 3:
            return 0
        failures = 0
        recent_rounds = min(3, history.round_number)
        for i in range(recent_rounds):
            round_idx = history.round_number - 1 - i
            opponent_cooperators = sum(history.opponent_actions[round_idx, :])
            my_cooperation = 1 if history.my_actions[round_idx] else 0
            total_cooperators = opponent_cooperators + my_cooperation
            if total_cooperators < self.m:
                failures += 1
        return failures

class Strategy_AGGRESSIVE_28(BaseStrategy):
    """
    Aggressive Adaptive Threshold Strategy (AATS)
    
    A strategically selfish approach that aims to maximize personal payoffs while 
    minimizing unnecessary cooperation. Always defects in first and last rounds,
    and uses aggressive filtering to only cooperate when highly profitable and necessary.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        return self._adaptive_decision(history)

    def _adaptive_decision(self, history: PlayerHistory) -> Action:
        last_round_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        my_cooperation_needed = max(0, self.m - last_round_cooperators)
        if my_cooperation_needed <= 1:
            return Action.D
        else:
            return self._aggressive_cooperation_check(history)

    def _aggressive_cooperation_check(self, history: PlayerHistory) -> Action:
        last_round_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        if last_round_cooperators < self.m - 1:
            return Action.D
        if not self._check_cooperation_momentum(history):
            return Action.D
        if self.k <= 1.5:
            return Action.D
        if self._get_consistent_cooperator_ratio(history) >= 0.6:
            return Action.D
        return Action.C

    def _check_cooperation_momentum(self, history: PlayerHistory) -> bool:
        rounds_completed = history.round_number
        if rounds_completed < 3:
            return True
        recent_cooperation = []
        for i in range(max(0, rounds_completed - 3), rounds_completed):
            coop_count = int(np.sum(history.opponent_actions[i, :]))
            recent_cooperation.append(coop_count)
        if len(recent_cooperation) < 2:
            return True
        trend = recent_cooperation[-1] - recent_cooperation[0]
        return trend >= 0

    def _get_consistent_cooperator_ratio(self, history: PlayerHistory) -> float:
        rounds_completed = history.round_number
        if rounds_completed == 0:
            return 0.0
        cooperation_rates = np.mean(history.opponent_actions, axis=0)
        consistent_cooperators = np.sum(cooperation_rates > 0.7)
        return consistent_cooperators / self.n

    def _adjust_for_edge_cases(self, base_decision: Action, history: PlayerHistory) -> Action:
        if self.m <= self.n // 3:
            if base_decision == Action.C and self.k <= 2.0:
                return Action.D
        elif self.m > 2 * self.n // 3:
            last_round_cooperators = int(np.sum(history.opponent_actions[-1, :]))
            if last_round_cooperators >= self.m - 2:
                return Action.C
        return base_decision

class Strategy_AGGRESSIVE_29(BaseStrategy):
    """
    Threshold Hawk: Aggressive exploitation strategy that maximizes individual payoff
    by free-riding on cooperative players while only cooperating when absolutely
    necessary to maintain the collective benefit threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == r:
            return Action.D
        recent_cooperation = self._calculate_avg_cooperators(history)
        consecutive_failures = self._count_consecutive_failures(history, m)
        threshold_adjustment = 1 if consecutive_failures >= 2 else 0
        in_late_game = current_round > 0.8 * r
        opponent_coop_rate = self._get_opponent_cooperation_rate(history)
        if recent_cooperation >= m + 2 - threshold_adjustment:
            return Action.D
        elif recent_cooperation >= m + 1 - threshold_adjustment:
            if opponent_coop_rate > 0.8:
                return Action.D
            elif in_late_game:
                return Action.C
            else:
                return Action.D
        elif recent_cooperation >= m - threshold_adjustment:
            return Action.C
        else:
            return Action.C

    def _calculate_avg_cooperators(self, history: PlayerHistory) -> float:
        """Calculate average number of cooperators in recent rounds."""
        rounds_to_check = min(3, history.round_number)
        if rounds_to_check == 0:
            return 0
        recent_rounds = history.opponent_actions[-rounds_to_check:, :]
        cooperators_per_round = np.sum(recent_rounds, axis=1)
        my_recent = history.my_actions[-rounds_to_check:]
        total_cooperators_per_round = cooperators_per_round + my_recent.astype(int)
        return np.mean(total_cooperators_per_round)

    def _count_consecutive_failures(self, history: PlayerHistory, m: int) -> int:
        """Count consecutive rounds where threshold was not met."""
        if history.round_number == 0:
            return 0
        consecutive = 0
        for i in range(history.round_number - 1, -1, -1):
            opponent_cooperators = np.sum(history.opponent_actions[i, :])
            my_cooperation = int(history.my_actions[i])
            total_cooperators = opponent_cooperators + my_cooperation
            if total_cooperators < m:
                consecutive += 1
            else:
                break
        return consecutive

    def _get_opponent_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate overall opponent cooperation rate in recent rounds."""
        rounds_to_check = min(3, history.round_number)
        if rounds_to_check == 0:
            return 0
        recent_actions = history.opponent_actions[-rounds_to_check:, :]
        total_actions = recent_actions.size
        total_cooperations = np.sum(recent_actions)
        return total_cooperations / total_actions if total_actions > 0 else 0

class Strategy_AGGRESSIVE_30(BaseStrategy):
    """
    Threshold Hawk: An aggressive exploitation strategy that maximizes free-riding
    while strategically contributing only when absolutely necessary to secure collective benefits.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.opponent_cooperation_counts = np.zeros(self.n - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        round_num = history.round_number + 1
        if history.round_number > 0:
            self.opponent_cooperation_counts += history.opponent_actions[-1, :]
        phase = self._determine_phase(round_num)
        last_round_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            last_round_cooperators += 1
        if phase == 'exploration':
            return self._exploration_strategy(round_num, last_round_cooperators, history)
        elif phase == 'exploitation':
            return self._exploitation_strategy(last_round_cooperators, history)
        else:
            return self._endgame_strategy(round_num, last_round_cooperators, history)

    def _determine_phase(self, round_num):
        """Determine which phase of the strategy we're in."""
        if round_num <= self.r // 3:
            return 'exploration'
        elif round_num <= 2 * self.r // 3:
            return 'exploitation'
        else:
            return 'endgame'

    def _exploration_strategy(self, round_num, last_cooperators, history):
        """Phase 1: Exploration & Exploitation strategy."""
        if round_num == 1:
            return Action.D
        aggression_modifier = 0.8 if self.n <= 4 else 1.0
        if last_cooperators >= self.m:
            return Action.D
        elif last_cooperators == self.m - 1:
            return Action.D if random.random() < 0.9 * aggression_modifier else Action.C
        else:
            shortfall = self.m - last_cooperators
            if shortfall == 1 and len(history.my_actions) > 0 and history.my_actions[-1]:
                return Action.C
            return Action.D

    def _exploitation_strategy(self, last_cooperators, history):
        """Phase 2: Strategic Exploitation strategy."""
        rounds_played = history.round_number
        cooperation_rates = self.opponent_cooperation_counts / rounds_played
        reliable_cooperators = np.sum(cooperation_rates > 0.6)
        threshold_factor = self.m / self.n
        reward_factor = min(self.k / 2.0, 2.0)
        base_defection_prob = 0.8
        if threshold_factor > 0.6:
            base_defection_prob *= 0.9
        if self.k > 3:
            base_defection_prob *= 0.95
        if reliable_cooperators >= self.m:
            return Action.D
        elif reliable_cooperators == self.m - 1:
            return Action.D if random.random() < base_defection_prob else Action.C
        else:
            need = self.m - reliable_cooperators
            if need == 1 and last_cooperators >= self.m - 1:
                return Action.C
            elif need > 1:
                recent_rounds = min(5, rounds_played)
                recent_successes = 0
                for i in range(recent_rounds):
                    round_cooperators = int(np.sum(history.opponent_actions[-(i + 1), :]))
                    if history.my_actions[-(i + 1)]:
                        round_cooperators += 1
                    if round_cooperators >= self.m:
                        recent_successes += 1
                failure_rate = 1.0 - recent_successes / recent_rounds
                return Action.C if failure_rate > 0.3 else Action.D
        return Action.D

    def _endgame_strategy(self, round_num, last_cooperators, history):
        """Phase 3: Endgame Aggression strategy."""
        rounds_left = self.r - round_num + 1
        if rounds_left <= 0:
            return Action.D
        elif rounds_left == 1:
            return Action.C if last_cooperators == self.m - 1 else Action.D
        else:
            cooperation_rates = self.opponent_cooperation_counts / history.round_number
            avg_cooperation_rate = np.mean(cooperation_rates)
            recent_rounds = min(3, history.round_number)
            recent_cooperation = 0
            for i in range(recent_rounds):
                recent_cooperation += np.sum(history.opponent_actions[-(i + 1), :])
            recent_avg = recent_cooperation / (recent_rounds * (self.n - 1))
            cooperation_declining = recent_avg < avg_cooperation_rate * 0.9
            if cooperation_declining:
                return Action.D
            elif avg_cooperation_rate > 0.7:
                return Action.D
            else:
                if last_cooperators < self.m - 1:
                    shortfall = self.m - last_cooperators
                    return Action.C if shortfall == 1 else Action.D
                return Action.D

class Strategy_AGGRESSIVE_31(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Threshold Shark"
    
    This strategy aggressively exploits cooperative players while minimizing personal risk.
    It free-rides whenever possible and only cooperates when absolutely necessary to secure
    the collective reward.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number + 1
        if current_round == self.r:
            return Action.D
        prev_cooperators = sum(history.opponent_actions[-1, :])
        if len(history.my_actions) > 0 and history.my_actions[-1]:
            prev_cooperators += 1
        gap = self.m - prev_cooperators
        if gap <= 0:
            return Action.D
        if gap >= self.m / 2:
            return Action.D
        reliable_cooperators = self._count_reliable_cooperators(history)
        if reliable_cooperators >= gap:
            return Action.D
        if gap <= 2 and self._my_cooperation_makes_difference(history):
            if self.k > 3.0:
                return Action.C
            elif self.k < 1.5:
                return Action.D if gap > 1 else Action.C
            else:
                return Action.C
        return Action.D

    def _count_reliable_cooperators(self, history: PlayerHistory) -> int:
        """Count opponents with >66% cooperation rate over last 3 rounds."""
        reliable_count = 0
        rounds_to_check = min(3, len(history.my_actions))
        if rounds_to_check == 0:
            return 0
        start_round = max(0, len(history.my_actions) - rounds_to_check)
        for opponent_idx in range(self.n - 1):
            cooperations = sum(history.opponent_actions[start_round:, opponent_idx])
            cooperation_rate = cooperations / rounds_to_check
            if cooperation_rate > 0.66:
                reliable_count += 1
        return reliable_count

    def _my_cooperation_makes_difference(self, history: PlayerHistory) -> bool:
        """Check if my cooperation could be pivotal for reaching threshold."""
        if len(history.my_actions) == 0:
            return True
        recent_rounds = min(3, len(history.my_actions))
        start_round = max(0, len(history.my_actions) - recent_rounds)
        avg_cooperators = 0
        for round_idx in range(start_round, len(history.my_actions)):
            round_cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                round_cooperators += 1
            avg_cooperators += round_cooperators
        avg_cooperators /= recent_rounds
        if abs(avg_cooperators - self.m) <= 1.5:
            return True
        if self.m > self.n / 2:
            return avg_cooperators >= self.m - 2
        elif self.m <= self.n / 3:
            return avg_cooperators >= self.m - 1
        return avg_cooperators >= self.m - 1

class Strategy_AGGRESSIVE_32(BaseStrategy):
    """
    Predator Strategy: Aggressive opportunism that maximizes personal gain while maintaining
    just enough cooperation to keep the collective benefit alive when profitable.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.opponent_coop_history = {}

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        round_num = history.round_number + 1
        early_phase_end = min(5, self.r // 4)
        endgame_start = max(self.r - max(3, self.r // 10) + 1, early_phase_end + 1)
        if round_num <= early_phase_end:
            return self._early_reconnaissance(history)
        elif round_num >= endgame_start:
            return self._endgame_extraction(history, round_num)
        else:
            return self._aggressive_exploitation(history)

    def _early_reconnaissance(self, history: PlayerHistory) -> Action:
        """Phase 1: Gather intelligence while minimizing risk"""
        if history.round_number == 0:
            return Action.D
        prev_round_cooperators = sum(history.opponent_actions[-1, :])
        prev_coop_rate = prev_round_cooperators / (self.n - 1)
        threshold_with_buffer = (self.m + 1) / self.n
        if prev_coop_rate >= threshold_with_buffer:
            return Action.C
        else:
            return Action.D

    def _aggressive_exploitation(self, history: PlayerHistory) -> Action:
        """Phase 2: Maximum extraction while maintaining collective benefit"""
        self._update_opponent_tracking(history)
        predicted_cooperators = self._predict_cooperators(history)
        recent_rounds = min(5, history.round_number)
        recent_success_rate = self._calculate_recent_success_rate(history, recent_rounds)
        aggressive_mode = recent_success_rate >= 0.8
        if aggressive_mode:
            if predicted_cooperators >= self.m:
                return Action.D
            else:
                return Action.C
        elif predicted_cooperators >= self.m + 1:
            return Action.D
        elif predicted_cooperators == self.m:
            my_last_action = history.my_actions[-1]
            if my_last_action:
                return Action.D
            else:
                return Action.C
        else:
            return Action.C

    def _endgame_extraction(self, history: PlayerHistory, round_num: int) -> Action:
        """Phase 3: Maximum short-term gain as relationships end"""
        rounds_remaining = self.r - round_num + 1
        if rounds_remaining == 0:
            return Action.D
        elif rounds_remaining == 1:
            recent_rounds = min(5, history.round_number)
            recent_coop_rate = self._calculate_recent_cooperation_rate(history, recent_rounds)
            if recent_coop_rate < 0.4:
                return Action.C
            else:
                return Action.D
        else:
            predicted_cooperators = self._predict_cooperators(history)
            if predicted_cooperators >= self.m:
                return Action.D
            else:
                return Action.C

    def _update_opponent_tracking(self, history: PlayerHistory):
        """Update opponent cooperation patterns for last 3 rounds"""
        look_back = min(3, history.round_number)
        for opponent_idx in range(self.n - 1):
            recent_actions = history.opponent_actions[-look_back:, opponent_idx]
            coop_rate = sum(recent_actions) / len(recent_actions)
            self.opponent_coop_history[opponent_idx] = coop_rate

    def _predict_cooperators(self, history: PlayerHistory) -> float:
        """Predict number of cooperators based on recent history"""
        if not self.opponent_coop_history:
            if history.round_number > 0:
                return sum(history.opponent_actions[-1, :])
            return 0
        predicted = sum(self.opponent_coop_history.values())
        if self._check_system_collapse(history):
            predicted += 1
        elif self._check_free_rider_flood(history):
            predicted += 0.5
        return predicted

    def _calculate_recent_success_rate(self, history: PlayerHistory, recent_rounds: int) -> float:
        """Calculate success rate in recent rounds"""
        if history.round_number == 0:
            return 0.0
        successes = 0
        rounds_to_check = min(recent_rounds, history.round_number)
        for i in range(rounds_to_check):
            round_idx = history.round_number - 1 - i
            cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators >= self.m:
                successes += 1
        return successes / rounds_to_check

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory, recent_rounds: int) -> float:
        """Calculate overall cooperation rate in recent rounds"""
        if history.round_number == 0:
            return 0.0
        total_cooperations = 0
        total_decisions = 0
        rounds_to_check = min(recent_rounds, history.round_number)
        for i in range(rounds_to_check):
            round_idx = history.round_number - 1 - i
            total_cooperations += sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                total_cooperations += 1
            total_decisions += self.n
        return total_cooperations / total_decisions if total_decisions > 0 else 0.0

    def _check_system_collapse(self, history: PlayerHistory) -> bool:
        """Check if collective benefit hasn't been achieved for 3+ consecutive rounds"""
        if history.round_number < 3:
            return False
        consecutive_failures = 0
        for i in range(min(3, history.round_number)):
            round_idx = history.round_number - 1 - i
            cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators < self.m:
                consecutive_failures += 1
            else:
                break
        return consecutive_failures >= 3

    def _check_free_rider_flood(self, history: PlayerHistory) -> bool:
        """Check if >50% of players defected last round"""
        if history.round_number == 0:
            return False
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        defection_rate = 1 - last_round_cooperators / self.n
        return defection_rate > 0.5

class Strategy_AGGRESSIVE_33(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Predatory Opportunist"
    
    This strategy aggressively maximizes individual payoffs by exploiting cooperative players
    while minimizing personal risk. It treats cooperation as a tool for manipulation rather
    than genuine collaboration, always seeking the highest expected value while maintaining
    plausible deniability of cooperative intent.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        round_num = state.round_number
        phase = self._determine_phase(round_num)
        coop_likelihood = self._calculate_cooperation_probability(history)
        estimated_other_cooperators = self._estimate_other_cooperators(history)
        threshold_gap = self.m - estimated_other_cooperators
        prob_threshold_without_me = self._prob_threshold_met_without_me(history)
        prob_threshold_with_me = self._prob_threshold_met_with_me(history)
        expected_defect_value = 1 + self.k * prob_threshold_without_me
        expected_coop_value = self.k * prob_threshold_with_me
        aggressive_threshold = expected_coop_value - expected_defect_value - 0.3
        if phase == 'early':
            aggressive_threshold += 0.2
        elif phase == 'final':
            aggressive_threshold += 0.4
        if self._high_cooperation_environment(history):
            if threshold_gap <= 1 and estimated_other_cooperators >= self.m - 1:
                return Action.D
        if self._low_cooperation_environment(history):
            if round_num <= 2 and coop_likelihood < 0.3:
                return Action.C
        if aggressive_threshold > 0 and self._strategic_conditions_met(history):
            return Action.C
        else:
            return Action.D

    def _determine_phase(self, round_num: int) -> str:
        """Determine which phase of the game we're in."""
        if round_num <= self.r // 3:
            return 'early'
        elif round_num <= 2 * self.r // 3:
            return 'middle'
        else:
            return 'final'

    def _calculate_cooperation_probability(self, history: PlayerHistory) -> float:
        """Calculate the likelihood that others will cooperate based on recent history."""
        if len(history.opponent_actions) == 0:
            return 0.5
        recent_rounds = min(3, len(history.opponent_actions))
        recent_actions = history.opponent_actions[-recent_rounds:, :]
        total_actions = recent_actions.size
        total_cooperations = np.sum(recent_actions)
        return total_cooperations / total_actions if total_actions > 0 else 0.5

    def _estimate_other_cooperators(self, history: PlayerHistory) -> int:
        """Estimate how many other players will cooperate this round."""
        if len(history.opponent_actions) == 0:
            return int(self.n * 0.5)
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        coop_prob = self._calculate_cooperation_probability(history)
        estimated = int(coop_prob * (self.n - 1))
        adjustment = random.choice([-1, 0, 1]) if random.random() < 0.3 else 0
        estimated = max(0, min(self.n - 1, estimated + adjustment))
        return estimated

    def _prob_threshold_met_without_me(self, history: PlayerHistory) -> float:
        """Calculate probability that threshold is met without my cooperation."""
        estimated_cooperators = self._estimate_other_cooperators(history)
        if estimated_cooperators >= self.m:
            return 0.9
        elif estimated_cooperators == self.m - 1:
            return 0.7
        elif estimated_cooperators == self.m - 2:
            return 0.3
        else:
            return 0.1

    def _prob_threshold_met_with_me(self, history: PlayerHistory) -> float:
        """Calculate probability that threshold is met with my cooperation."""
        estimated_cooperators = self._estimate_other_cooperators(history)
        if estimated_cooperators + 1 >= self.m:
            return 0.95
        elif estimated_cooperators + 1 == self.m - 1:
            return 0.8
        else:
            return 0.4

    def _strategic_conditions_met(self, history: PlayerHistory) -> bool:
        """Check if strategic conditions favor cooperation."""
        estimated_other_cooperators = self._estimate_other_cooperators(history)
        if estimated_other_cooperators == self.m - 1:
            return True
        if estimated_other_cooperators >= self.m:
            return False
        return False

    def _high_cooperation_environment(self, history: PlayerHistory) -> bool:
        """Detect if we're in a high cooperation environment for exploitation."""
        if len(history.opponent_actions) < 3:
            return False
        recent_rounds = min(3, len(history.opponent_actions))
        recent_actions = history.opponent_actions[-recent_rounds:, :]
        cooperation_rate = np.mean(recent_actions)
        return cooperation_rate > 0.7

    def _low_cooperation_environment(self, history: PlayerHistory) -> bool:
        """Detect if we're in a low cooperation environment."""
        if len(history.opponent_actions) < 2:
            return False
        recent_rounds = min(2, len(history.opponent_actions))
        recent_actions = history.opponent_actions[-recent_rounds:, :]
        cooperation_rate = np.mean(recent_actions)
        return cooperation_rate < 0.3

class Strategy_AGGRESSIVE_34(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Threshold Hawk"
    
    Maximizes individual payoffs by aggressively exploiting cooperative players
    while minimizing personal risk. Uses three phases: early exploitation,
    strategic monitoring, and endgame pressure.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        early_end = self.r // 3
        middle_end = 2 * self.r // 3
        if current_round <= early_end:
            phase = 'early'
        elif current_round <= middle_end:
            phase = 'middle'
        else:
            phase = 'endgame'
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        if phase == 'early':
            return Action.D
        elif phase == 'middle':
            if last_round_cooperators >= self.m:
                return Action.D
            consecutive_fails = self._count_consecutive_failures(history)
            if consecutive_fails >= 3:
                if last_round_cooperators == self.m - 1:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D
        else:
            if current_round == self.r:
                return Action.D
            if current_round > 0.8 * self.r:
                consecutive_fails = self._count_consecutive_failures(history)
                if consecutive_fails >= 2 and last_round_cooperators == self.m - 1:
                    return Action.C
                else:
                    return Action.D
            else:
                if last_round_cooperators >= self.m:
                    return Action.D
                consecutive_fails = self._count_consecutive_failures(history)
                if consecutive_fails >= 4:
                    if last_round_cooperators == self.m - 1:
                        return Action.C
                    else:
                        return Action.D
                else:
                    return Action.D

    def _count_consecutive_failures(self, history: PlayerHistory) -> int:
        """Count consecutive rounds where cooperation threshold was not met."""
        consecutive = 0
        for round_idx in range(len(history.my_actions) - 1, -1, -1):
            total_cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                total_cooperators += 1
            if total_cooperators < self.m:
                consecutive += 1
            else:
                break
        return consecutive

class Strategy_AGGRESSIVE_35(BaseStrategy):
    """
    Threshold Hawk: Aggressive exploitation strategy that maximizes individual payoff
    by exploiting cooperative players while minimizing personal risk. Defects by default
    and only cooperates when absolutely necessary to trigger threshold rewards.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.reliability_score = 1.0
        self.threshold_min = max(0.25, (self.m - 1) / self.n)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        cooperation_rate = last_round_cooperators / self.n
        if last_round_cooperators >= self.m:
            self.reliability_score = min(1.0, self.reliability_score + 0.1)
        else:
            self.reliability_score = max(0.0, self.reliability_score - 0.2)
        if current_round == self.r - 1:
            return Action.D
        cooperation_threshold = 0.6 if self.n <= 4 else 0.4
        if self.m / self.n > 0.7:
            cooperation_threshold = 0.8
        if self.k < 1.5:
            cooperation_threshold = 0.6
        endgame_threshold = max(2, int(0.2 * self.r))
        if current_round >= self.r - endgame_threshold:
            if cooperation_rate >= 0.5:
                return Action.C
            else:
                return Action.D
        my_cooperation_needed = last_round_cooperators < self.m - 1
        viable_cooperation = cooperation_rate >= self.threshold_min
        if self.reliability_score < 0.3:
            return Action.D
        if my_cooperation_needed and viable_cooperation and (cooperation_rate >= cooperation_threshold):
            return Action.C
        else:
            return Action.D

class Strategy_AGGRESSIVE_36(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Predatory Threshold Rider"
    
    This strategy aggressively exploits cooperative players while minimizing personal risk.
    It lets others shoulder the cooperation burden while maximizing personal payoffs through
    strategic free-riding and calculated cooperation only when absolutely necessary.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number + 1
        if current_round == self.r:
            return Action.D
        last_round_idx = history.round_number - 1
        my_last_action = history.my_actions[last_round_idx]
        opponent_cooperators = sum(history.opponent_actions[last_round_idx, :])
        total_cooperators = opponent_cooperators + (1 if my_last_action else 0)
        if total_cooperators >= self.m:
            return Action.D
        elif total_cooperators == self.m - 1:
            remaining_rounds = self.r - current_round
            expected_future_exploitation_gain = remaining_rounds * 1.0
            if expected_future_exploitation_gain > self.k:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D
        if history.round_number >= 3:
            start_idx = max(0, history.round_number - 3)
            recent_opponent_actions = history.opponent_actions[start_idx:, :]
            for opponent_idx in range(self.n - 1):
                opponent_coop_rate = np.mean(recent_opponent_actions[:, opponent_idx])
                if opponent_coop_rate > 0.6:
                    return Action.D
            avg_opponent_coop_rate = np.mean(recent_opponent_actions)
            if avg_opponent_coop_rate < 0.3:
                return Action.D
        if self.n <= 4:
            if total_cooperators == self.m - 2:
                remaining_rounds = self.r - current_round
                if remaining_rounds > 2:
                    return Action.C
        if self.m >= 0.7 * self.n:
            if history.round_number >= 2:
                recent_total_coop_rate = np.mean([sum(history.opponent_actions[i, :]) + history.my_actions[i] for i in range(max(0, history.round_number - 2), history.round_number)]) / self.n
                if recent_total_coop_rate > 0.7 and total_cooperators >= self.m - 1:
                    return Action.C
        if self.k <= 1.5:
            return Action.D
        expected_cooperators = opponent_cooperators
        threshold_pressure = (self.m - expected_cooperators) / self.m
        if threshold_pressure > 0.7:
            return Action.D
        elif threshold_pressure < 0.3:
            return Action.D
        elif total_cooperators >= self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_AGGRESSIVE_37(BaseStrategy):
    """
    Threshold Predator: An aggressive adaptive strategy that exploits others' cooperation
    while maintaining just enough strategic cooperation to avoid collective disaster.
    Always defects in first and last rounds, and adaptively exploits based on opponents' 
    cooperation patterns in middle rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        m = self.game_description.m
        k = self.game_description.k
        current_round = state.round_number
        if current_round == r:
            return Action.D
        total_opponent_actions = history.opponent_actions.size
        total_cooperations = np.sum(history.opponent_actions)
        coop_rate = total_cooperations / total_opponent_actions if total_opponent_actions > 0 else 0
        rounds_to_check = min(3, history.round_number)
        if rounds_to_check > 0:
            recent_actions = history.opponent_actions[-rounds_to_check:, :]
            recent_total = recent_actions.size
            recent_cooperations = np.sum(recent_actions)
            recent_coop_rate = recent_cooperations / recent_total if recent_total > 0 else 0
        else:
            recent_coop_rate = coop_rate
        expected_cooperators = coop_rate * (n - 1)
        if recent_coop_rate >= 0.7 and expected_cooperators >= m - 1:
            return Action.D
        elif recent_coop_rate >= 0.4 and expected_cooperators >= m - 2:
            expected_defectors = (n - 1) * (1 - coop_rate)
            if expected_defectors <= n - m:
                return Action.D
            else:
                return Action.C
        elif coop_rate < 0.3:
            return Action.D
        elif current_round % 3 == 1:
            return Action.C
        else:
            return Action.D

class Strategy_AGGRESSIVE_38(BaseStrategy):
    """
    Threshold Predator: An aggressive exploitation strategy that free-rides on cooperation
    while only contributing when absolutely necessary to secure collective rewards.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_boost = 0
        self.boost_rounds_left = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = history.round_number + 1
        if current_round == r:
            return Action.D
        if self.boost_rounds_left > 0:
            self.boost_rounds_left -= 1
        coop_rates = []
        for player_idx in range(n - 1):
            player_actions = history.opponent_actions[:, player_idx]
            coop_rate = np.mean(player_actions)
            coop_rates.append(coop_rate)
        reliable_cooperators = sum((1 for rate in coop_rates if rate >= 0.7))
        recent_weight = 0.6
        historical_weight = 0.4
        expected_cooperators = 0
        recent_rounds = min(3, len(history.my_actions))
        for player_idx in range(n - 1):
            if len(history.my_actions) >= recent_rounds:
                recent_actions = history.opponent_actions[-recent_rounds:, player_idx]
                historical_actions = history.opponent_actions[:-recent_rounds, player_idx] if len(history.my_actions) > recent_rounds else np.array([])
                recent_rate = np.mean(recent_actions) if len(recent_actions) > 0 else 0
                historical_rate = np.mean(historical_actions) if len(historical_actions) > 0 else recent_rate
                weighted_rate = recent_weight * recent_rate + historical_weight * historical_rate
            else:
                weighted_rate = np.mean(history.opponent_actions[:, player_idx])
            if len(history.my_actions) >= 1:
                last_round_cooperators = sum(history.opponent_actions[-1, :])
                if last_round_cooperators < m:
                    weighted_rate = min(1.0, weighted_rate + 0.15)
            expected_cooperators += weighted_rate
        expected_cooperators = round(expected_cooperators)
        cascade_prevention = False
        if len(history.my_actions) >= 2:
            last_two_cooperators = [sum(history.opponent_actions[-i, :]) + (1 if history.my_actions[-i] else 0) for i in [1, 2]]
            if all((coop < m for coop in last_two_cooperators)):
                if not history.my_actions[-1] and (not history.my_actions[-2]):
                    cascade_prevention = True
        cooperation_probability = 0
        if len(history.my_actions) >= 1:
            last_total_cooperators = sum(history.opponent_actions[-1, :]) + (1 if history.my_actions[-1] else 0)
            if last_total_cooperators < m and (not history.my_actions[-1]):
                self.cooperation_boost = 0.2
                self.boost_rounds_left = 2
        if expected_cooperators >= m:
            decision = Action.D
        elif expected_cooperators == m - 1:
            if self._should_be_decisive(history, current_round):
                decision = Action.C
            else:
                decision = Action.D
        elif cascade_prevention:
            decision = Action.C
        else:
            decision = Action.D
        if self.boost_rounds_left > 0 and decision == Action.D:
            if random.random() < self.cooperation_boost:
                decision = Action.C
        if len(history.my_actions) >= 3:
            recent_expected = [self._estimate_cooperators_for_round(history, i) for i in range(max(0, len(history.my_actions) - 3), len(history.my_actions))]
            if all((abs(exp - (m - 1)) <= 0.5 for exp in recent_expected)):
                if current_round % 3 == 0:
                    decision = Action.D
        return decision

    def _should_be_decisive(self, history: PlayerHistory, current_round: int) -> bool:
        """Determine if this is a good time to be the decisive cooperator."""
        if random.random() < 0.3:
            return False
        if len(history.my_actions) >= 3:
            recent_my_coop_rate = np.mean(history.my_actions[-3:])
            if recent_my_coop_rate > 0.3:
                return random.random() < 0.7
        return True

    def _estimate_cooperators_for_round(self, history: PlayerHistory, round_idx: int) -> float:
        """Estimate how many cooperators were expected for a given round."""
        if round_idx == 0:
            return 0
        n = self.game_description.n_players
        expected = 0
        for player_idx in range(n - 1):
            if round_idx > 0:
                rate = np.mean(history.opponent_actions[:round_idx, player_idx])
                expected += rate
        return expected

class Strategy_AGGRESSIVE_39(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Predator"
    
    Operates on maximum exploitation with calculated risk management. Always defects in first and last rounds,
    and exploits cooperation patterns while maintaining just enough strategic cooperation to prevent total collapse
    when absolutely necessary for personal benefit.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_rates = {}
        self.momentum_tracker = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        if state.round_number >= self.game_description.n_rounds - 1:
            return Action.D
        last_round_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            last_round_cooperators += 1
        self.momentum_tracker.append(last_round_cooperators)
        if len(self.momentum_tracker) > 3:
            self.momentum_tracker.pop(0)
        n_rounds_played = history.round_number
        for i in range(self.game_description.n_players - 1):
            cooperations = np.sum(history.opponent_actions[:, i])
            self.cooperation_rates[i] = cooperations / n_rounds_played
        m = self.game_description.m
        if last_round_cooperators >= m:
            return Action.D
        elif last_round_cooperators == m - 1:
            reliable_cooperators = sum((1 for rate in self.cooperation_rates.values() if rate > 0.7))
            expected_cooperators = reliable_cooperators + (self.game_description.n_players - 1 - reliable_cooperators) * 0.3
            if expected_cooperators >= m - 1:
                return Action.D
            else:
                return Action.C
        else:
            reliable_cooperators = sum((1 for rate in self.cooperation_rates.values() if rate > 0.7))
            if reliable_cooperators >= m:
                return Action.D
            if len(self.momentum_tracker) >= 3:
                if self.momentum_tracker[-1] < self.momentum_tracker[-2] and self.momentum_tracker[-2] < self.momentum_tracker[-3]:
                    return Action.D
            if m == self.game_description.n_players - 1:
                if last_round_cooperators == m - 2 and len(self.momentum_tracker) >= 2 and (self.momentum_tracker[-1] > self.momentum_tracker[-2]):
                    return Action.C
            elif m == 2:
                return Action.D
            my_defection_rate = 1 - np.mean(history.my_actions)
            threshold_met_rate = np.mean([np.sum(history.opponent_actions[r, :]) + history.my_actions[r] >= m for r in range(n_rounds_played)])
            if my_defection_rate > 0.8 and threshold_met_rate < 0.3:
                if random.random() < 0.2:
                    return Action.C
            return Action.D

class Strategy_AGGRESSIVE_40(BaseStrategy):
    """
    AGGRESSIVE EXPLOITATION STRATEGY: "PREDATOR"
    
    Operates on aggressive opportunism - maximizing personal gain while exploiting 
    others' cooperative tendencies. Free-rides whenever possible, only cooperating 
    when absolutely necessary for self-preservation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        m = self.game_description.m
        current_round = state.round_number
        if current_round >= r - 1:
            return Action.D
        my_last_action = history.my_actions[-1]
        opponent_cooperators = sum(history.opponent_actions[-1, :])
        total_cooperators_last = int(opponent_cooperators) + int(my_last_action)
        if total_cooperators_last >= m + 2:
            return Action.D
        elif total_cooperators_last == m + 1:
            return Action.D
        elif total_cooperators_last == m:
            if random.random() < 0.7:
                return Action.D
            else:
                return Action.C
        elif total_cooperators_last == m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_AGGRESSIVE_41(BaseStrategy):
    """
    Aggressive Exploitative "Threshold Hunter" Strategy.
    
    Maximizes individual payoffs by aggressively exploiting others' cooperation
    while minimizing personal risk. Always defects in first and last rounds,
    and strategically cooperates only when absolutely necessary to secure
    collective benefits in middle rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        if current_round == self.r - 1:
            return Action.D
        return self._adaptive_exploitation_decision(history)

    def _adaptive_exploitation_decision(self, history: PlayerHistory) -> Action:
        reliable_cooperators = self._count_reliable_cooperators(history)
        expected_cooperators = reliable_cooperators
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        cooperation_pressure = last_round_cooperators / max(1, self.m - 1)
        if expected_cooperators >= self.m:
            return Action.D
        elif expected_cooperators == self.m - 1:
            if self._recently_aggressive(history) and self._last_round_successful(history):
                return Action.D
            else:
                return Action.C
        else:
            rounds_remaining = self.r - history.round_number
            cooperation_trend_increasing = self._is_cooperation_trending_up(history)
            if rounds_remaining > 3 and cooperation_trend_increasing:
                return Action.D
            else:
                return Action.C

    def _count_reliable_cooperators(self, history: PlayerHistory) -> int:
        """Count opponents with cooperation rate > 60%"""
        if history.round_number == 0:
            return 0
        reliable_count = 0
        for player_idx in range(self.n - 1):
            player_actions = history.opponent_actions[:, player_idx]
            cooperation_rate = np.mean(player_actions)
            if cooperation_rate > 0.6:
                reliable_count += 1
        return reliable_count

    def _recently_aggressive(self, history: PlayerHistory) -> bool:
        """Check if we've defected in last 2 rounds"""
        if history.round_number < 2:
            return False
        recent_actions = history.my_actions[-2:]
        return not any(recent_actions)

    def _last_round_successful(self, history: PlayerHistory) -> bool:
        """Check if threshold was met in last round"""
        if history.round_number == 0:
            return False
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        return last_round_cooperators >= self.m

    def _is_cooperation_trending_up(self, history: PlayerHistory) -> bool:
        """Check if overall cooperation is increasing over recent rounds"""
        if history.round_number < 3:
            return False
        recent_rounds = min(3, history.round_number)
        recent_coop_rates = []
        for i in range(recent_rounds):
            round_idx = -(i + 1)
            round_cooperators = sum(history.opponent_actions[round_idx, :])
            coop_rate = round_cooperators / (self.n - 1)
            recent_coop_rates.append(coop_rate)
        if len(recent_coop_rates) >= 2:
            return recent_coop_rates[0] > recent_coop_rates[-1]
        return False

class Strategy_AGGRESSIVE_42(BaseStrategy):
    """
    Opportunistic Predator: An aggressive exploitative strategy that free-rides whenever possible
    while providing pivotal cooperation only when necessary to secure collective benefits.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if history is None:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        predicted_cooperators = self._predict_cooperators(history, current_round)
        if current_round > 0.8 * self.r:
            threshold_needed = self.m + 1
        else:
            threshold_needed = self.m
        if predicted_cooperators >= threshold_needed:
            return Action.D
        elif predicted_cooperators == threshold_needed - 1:
            return Action.C
        else:
            return Action.D

    def _predict_cooperators(self, history: PlayerHistory, current_round: int) -> int:
        """Predict how many opponents will cooperate based on weighted recent history."""
        predicted_cooperators = 0
        lookback = max(3, self.r // 4)
        lookback = min(lookback, history.round_number)
        for opponent_idx in range(self.n - 1):
            coop_rate = self._calculate_recent_coop_rate(history, opponent_idx, lookback)
            if coop_rate > 0.6:
                predicted_cooperators += 1
        return predicted_cooperators

    def _calculate_recent_coop_rate(self, history: PlayerHistory, opponent_idx: int, lookback: int) -> float:
        """Calculate weighted cooperation rate for an opponent over recent rounds."""
        if history.round_number == 0:
            return 0.4
        total_weight = 0.0
        weighted_coop = 0.0
        decay_factor = 0.7
        start_round = max(0, history.round_number - lookback)
        for round_offset in range(history.round_number - start_round):
            round_idx = start_round + round_offset
            weight = decay_factor ** (history.round_number - 1 - round_idx)
            cooperated = history.opponent_actions[round_idx, opponent_idx]
            weighted_coop += weight * (1.0 if cooperated else 0.0)
            total_weight += weight
        if total_weight == 0:
            return 0.4
        recent_rate = weighted_coop / total_weight
        recent_rate = self._apply_aggressive_adaptations(history, opponent_idx, recent_rate)
        return recent_rate

    def _apply_aggressive_adaptations(self, history: PlayerHistory, opponent_idx: int, base_rate: float) -> float:
        """Apply aggressive adaptations based on opponent behavior patterns."""
        if history.round_number < 2:
            return base_rate
        recent_actions = history.opponent_actions[-min(5, history.round_number):, opponent_idx]
        if base_rate > 0.8:
            return min(0.95, base_rate * 1.1)
        if len(recent_actions) >= 3:
            variance = np.var(recent_actions.astype(float))
            if variance > 0.3:
                return max(0.1, base_rate * 0.7)
        if history.round_number >= 1:
            recent_rounds_to_check = min(3, history.round_number)
            for i in range(recent_rounds_to_check):
                round_idx = history.round_number - 1 - i
                cooperators_in_round = sum(history.opponent_actions[round_idx, :])
                if cooperators_in_round >= 0.75 * (self.n - 1):
                    return min(0.9, base_rate * 1.2)
        return base_rate

class Strategy_AGGRESSIVE_43(BaseStrategy):
    """
    PREDATOR Strategy: Aggressive free-rider that exploits cooperative players while 
    strategically contributing only when absolutely necessary. Maximizes personal payoff 
    through calculated exploitation and minimum viable cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.recon_phase = max(1, int(0.2 * self.r))
        self.exploit_phase_end = int(0.8 * self.r)
        self.saint_threshold = 0.8
        self.predator_threshold = 0.7
        self.failure_rate_threshold = 0.3
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        if current_round < self.recon_phase:
            return Action.D
        opponent_coop_rates = self._calculate_cooperation_rates(history)
        recent_failures = self._calculate_recent_failures(history)
        predicted_cooperators = self._predict_cooperators(history, opponent_coop_rates)
        if current_round >= self.exploit_phase_end:
            return self._endgame_strategy(predicted_cooperators, current_round)
        return self._exploitation_strategy(predicted_cooperators, recent_failures, history)

    def _calculate_cooperation_rates(self, history):
        """Calculate cooperation rates for each opponent"""
        if history.round_number == 0:
            return np.zeros(self.n - 1)
        total_rounds = history.round_number
        cooperation_counts = np.sum(history.opponent_actions, axis=0)
        return cooperation_counts / total_rounds

    def _calculate_recent_failures(self, history):
        """Calculate failure rate in recent rounds"""
        if history.round_number < 5:
            return 0.0
        recent_rounds = min(10, history.round_number)
        recent_actions = history.opponent_actions[-recent_rounds:, :]
        recent_my_actions = history.my_actions[-recent_rounds:]
        failures = 0
        for i in range(recent_rounds):
            total_cooperators = np.sum(recent_actions[i, :]) + (1 if recent_my_actions[i] else 0)
            if total_cooperators < self.m:
                failures += 1
        return failures / recent_rounds

    def _predict_cooperators(self, history, coop_rates):
        """Predict number of cooperators this round"""
        base_prediction = np.sum(coop_rates > 0.5)
        if history.round_number >= 3:
            recent_cooperation = np.sum(history.opponent_actions[-1, :])
            trend_adjustment = 0
            if history.round_number >= 2:
                prev_cooperation = np.sum(history.opponent_actions[-2, :])
                if recent_cooperation > prev_cooperation:
                    trend_adjustment = 1
                elif recent_cooperation < prev_cooperation:
                    trend_adjustment = -1
            prediction = base_prediction + trend_adjustment
        else:
            prediction = base_prediction
        return max(0, min(self.n - 1, int(prediction)))

    def _exploitation_strategy(self, predicted_cooperators, recent_failures, history):
        """Core exploitation logic for middle phase"""
        if recent_failures > self.failure_rate_threshold:
            if predicted_cooperators >= self.m - 2:
                return Action.C
        if predicted_cooperators >= self.m:
            return Action.D
        elif predicted_cooperators == self.m - 1:
            expected_benefit = self.k - 1
            if expected_benefit > 0:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _endgame_strategy(self, predicted_cooperators, current_round):
        """Aggressive endgame strategy"""
        if current_round >= self.r - 1:
            return Action.D
        if current_round >= self.r - 2:
            if predicted_cooperators == self.m - 1 and self.k > 2:
                return Action.C
            else:
                return Action.D
        if predicted_cooperators >= self.m:
            return Action.D
        elif predicted_cooperators == self.m - 1:
            if self.k > 1.5:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _classify_opponent(self, coop_rate):
        """Classify opponent based on cooperation rate"""
        if coop_rate > self.saint_threshold:
            return 'saint'
        elif coop_rate < 1 - self.predator_threshold:
            return 'predator'
        elif 0.3 < coop_rate < 0.7:
            return 'conditional'
        else:
            return 'tit_for_tat'

class Strategy_AGGRESSIVE_44(BaseStrategy):
    """
    Threshold Vulture: An aggressive exploitation strategy that free-rides on others' cooperation
    while strategically cooperating only when absolutely necessary to maintain the profitable threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.emergency_cooperation_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        m = self.game_description.m
        k = self.game_description.k
        current_round = state.round_number
        rounds_remaining = r - current_round
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        if current_round <= r // 3:
            if last_round_cooperators == m - 1:
                return Action.C
            else:
                return Action.D
        elif current_round > 2 * r // 3:
            if rounds_remaining <= 2:
                return Action.D
            elif last_round_cooperators == m - 1 and rounds_remaining >= 3:
                return Action.C
            else:
                return Action.D
        else:
            surplus = last_round_cooperators - m
            if surplus >= 2:
                return Action.D
            elif surplus == 1:
                defect_prob = 0.8 if k < 3 else 0.7
                return Action.D if random.random() < defect_prob else Action.C
            elif surplus == 0:
                return Action.C
            elif self.emergency_cooperation_count < 2:
                self.emergency_cooperation_count += 1
                return Action.C
            else:
                self.emergency_cooperation_count = 0
                return Action.D

class Strategy_AGGRESSIVE_45(BaseStrategy):
    """
    Aggressive Threshold Exploitation Strategy: Selectively exploit others' cooperation 
    while contributing strategically only when necessary to secure collective rewards.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.opponent_coop_rates = [0.5] * (self.n - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        exploration_rounds = min(3, self.r // 4)
        if current_round < exploration_rounds:
            self._update_opponent_tracking(history)
            return Action.D
        self._update_opponent_tracking(history)
        expected_cooperators = self._estimate_expected_cooperators(history)
        endgame_threshold = max(1, int(0.8 * self.r))
        if current_round >= endgame_threshold:
            return self._endgame_decision(expected_cooperators, history)
        return self._adaptive_exploitation_decision(expected_cooperators, history)

    def _update_opponent_tracking(self, history):
        """Update estimates of each opponent's cooperation rate."""
        if history.round_number == 0:
            return
        weights = [0.5, 0.3, 0.2]
        for opp_idx in range(self.n - 1):
            recent_actions = []
            for lookback in range(min(3, history.round_number)):
                round_idx = history.round_number - 1 - lookback
                if round_idx >= 0:
                    recent_actions.append(history.opponent_actions[round_idx, opp_idx])
            if recent_actions:
                weighted_sum = sum((action * weights[i] for i, action in enumerate(recent_actions)))
                weight_total = sum(weights[:len(recent_actions)])
                estimated_rate = weighted_sum / weight_total * 0.85
                self.opponent_coop_rates[opp_idx] = max(0.0, min(1.0, estimated_rate))

    def _estimate_expected_cooperators(self, history):
        """Estimate how many opponents will cooperate this round."""
        expected = sum(self.opponent_coop_rates)
        if history.round_number >= 3:
            for opp_idx in range(self.n - 1):
                if history.round_number >= 3:
                    recent_actions = []
                    for lookback in range(min(3, history.round_number)):
                        round_idx = history.round_number - 1 - lookback
                        if round_idx >= 0:
                            recent_actions.append(history.opponent_actions[round_idx, opp_idx])
                    if len(recent_actions) >= 3:
                        variance = np.var(recent_actions)
                        if variance > 0.2:
                            expected -= self.opponent_coop_rates[opp_idx] * 0.3
        return max(0, expected)

    def _adaptive_exploitation_decision(self, expected_cooperators, history):
        """Make decision during adaptive exploitation phase."""
        cooperation_buffer = expected_cooperators - self.m
        if cooperation_buffer >= 2:
            return Action.D
        elif cooperation_buffer >= 1:
            return Action.D if random.random() < 0.7 else Action.C
        elif cooperation_buffer >= 0:
            if expected_cooperators >= self.m - 1:
                if history.round_number > 0:
                    last_round_cooperators = sum(history.opponent_actions[-1, :])
                    last_round_threshold_met = last_round_cooperators + history.my_actions[-1] >= self.m
                    my_contribution_decisive = last_round_cooperators == self.m - 1 and history.my_actions[-1]
                    if last_round_threshold_met and my_contribution_decisive:
                        return Action.D
                return Action.C if random.random() < 0.6 else Action.D
            else:
                return Action.D
        else:
            return Action.D

    def _endgame_decision(self, expected_cooperators, history):
        """Make decision during endgame phase."""
        if history.round_number >= self.r - 1:
            return Action.D
        if history.round_number >= 3:
            recent_threshold_met = 0
            for lookback in range(min(3, history.round_number)):
                round_idx = history.round_number - 1 - lookback
                if round_idx >= 0:
                    total_cooperators = sum(history.opponent_actions[round_idx, :]) + history.my_actions[round_idx]
                    if total_cooperators >= self.m:
                        recent_threshold_met += 1
            if recent_threshold_met >= 2:
                base_defect_prob = 0.7 if expected_cooperators >= self.m else 0.4
                increased_defect_prob = min(1.0, base_defect_prob * 1.25)
                return Action.D if random.random() < increased_defect_prob else Action.C
        return self._adaptive_exploitation_decision(expected_cooperators, history)

class Strategy_AGGRESSIVE_46(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Opportunistic Predator"
    
    This strategy aggressively exploits cooperative players while minimizing personal risk.
    It aims to maximize individual payoffs by contributing as little as possible while 
    still benefiting from others' cooperation when the threshold is likely to be met.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.opponent_types = {}
        self.retaliators = set()
        self.cooperation_climate_adjustment = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        round_num = history.round_number + 1
        if round_num <= 2:
            return Action.D
        if round_num >= self.n_rounds - 1:
            if round_num == self.n_rounds - 1:
                threshold_met_count = self._count_threshold_met_rounds(history)
                if threshold_met_count / len(history.my_actions) >= 0.8:
                    return Action.C
            return Action.D
        return self._exploitation_phase_decision(history, round_num)

    def _exploitation_phase_decision(self, history: PlayerHistory, round_num: int) -> Action:
        if round_num == 4:
            self._classify_opponents(history)
        self._update_cooperation_climate(history)
        predicted_cooperators = self._predict_cooperators(history)
        rounds_remaining = self.n_rounds - round_num
        base_threshold = 0.6 + 0.1 * rounds_remaining / self.n_rounds
        aggression_threshold = base_threshold + self.cooperation_climate_adjustment
        global_coop_rate = self._calculate_global_cooperation_rate(history)
        if self._should_emergency_cooperate(history):
            return Action.C
        if predicted_cooperators >= self.m - 1 and global_coop_rate > aggression_threshold:
            return Action.C
        return Action.D

    def _predict_cooperators(self, history: PlayerHistory) -> int:
        """Predict number of opponents who will cooperate next round"""
        predicted_count = 0
        recent_window = min(3, len(history.my_actions))
        for opponent_idx in range(self.n_players - 1):
            recent_actions = history.opponent_actions[-recent_window:, opponent_idx]
            coop_rate = np.mean(recent_actions)
            momentum_factor = self._calculate_momentum_factor(history, opponent_idx, recent_window)
            coop_prob = coop_rate * momentum_factor
            if opponent_idx in self.retaliators:
                coop_prob *= 1.2
            if coop_prob > 0.5:
                predicted_count += 1
        return predicted_count

    def _calculate_momentum_factor(self, history: PlayerHistory, opponent_idx: int, window: int) -> float:
        """Calculate momentum factor based on cooperation trend"""
        if window < 2:
            return 1.0
        recent_actions = history.opponent_actions[-window:, opponent_idx]
        if len(recent_actions) < 2:
            return 1.0
        mid = len(recent_actions) // 2
        first_half_rate = np.mean(recent_actions[:mid]) if mid > 0 else 0
        second_half_rate = np.mean(recent_actions[mid:])
        if second_half_rate > first_half_rate:
            return 1.2
        elif second_half_rate < first_half_rate:
            return 0.8
        return 1.0

    def _calculate_global_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate overall cooperation rate in recent rounds"""
        recent_window = min(3, len(history.my_actions))
        if recent_window == 0:
            return 0.0
        recent_opponent_actions = history.opponent_actions[-recent_window:, :]
        return np.mean(recent_opponent_actions)

    def _count_threshold_met_rounds(self, history: PlayerHistory) -> int:
        """Count how many rounds the cooperation threshold was met"""
        count = 0
        for round_idx in range(len(history.my_actions)):
            cooperators = int(history.my_actions[round_idx]) + np.sum(history.opponent_actions[round_idx, :])
            if cooperators >= self.m:
                count += 1
        return count

    def _classify_opponents(self, history: PlayerHistory) -> None:
        """Classify opponents based on their cooperation patterns"""
        for opponent_idx in range(self.n_players - 1):
            coop_rate = np.mean(history.opponent_actions[:, opponent_idx])
            if coop_rate > 0.6:
                self.opponent_types[opponent_idx] = 'cooperator'
            elif coop_rate < 0.3:
                self.opponent_types[opponent_idx] = 'defector'
            else:
                self.opponent_types[opponent_idx] = 'conditional'

    def _update_cooperation_climate(self, history: PlayerHistory) -> None:
        """Update cooperation climate adjustment based on threshold success rate"""
        if len(history.my_actions) < 3:
            return
        threshold_met_count = self._count_threshold_met_rounds(history)
        success_rate = threshold_met_count / len(history.my_actions)
        if success_rate < 0.3:
            self.cooperation_climate_adjustment = -0.2
        elif success_rate > 0.7:
            self.cooperation_climate_adjustment = 0.0
        else:
            self.cooperation_climate_adjustment = 0.0

    def _should_emergency_cooperate(self, history: PlayerHistory) -> bool:
        """Check if emergency cooperation is needed"""
        if len(history.my_actions) >= 3:
            recent_threshold_met = []
            for i in range(min(3, len(history.my_actions))):
                round_idx = len(history.my_actions) - 1 - i
                cooperators = int(history.my_actions[round_idx]) + np.sum(history.opponent_actions[round_idx, :])
                recent_threshold_met.append(cooperators >= self.m)
            if not any(recent_threshold_met):
                if (len(history.my_actions) + 1) % 4 == 0:
                    return True
        return False

class Strategy_AGGRESSIVE_47(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Threshold Hawk"
    
    This strategy aggressively exploits cooperative players while minimizing personal risk.
    It aims to free-ride on others' cooperation by defecting when the threshold is likely
    to be met by others, and only cooperates when absolutely necessary to prevent collapse.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        reliable_cooperators = self._count_reliable_cooperators(history)
        likely_cooperators = self._estimate_likely_cooperators(history)
        early_phase_end = min(3, self.r // 3)
        if current_round < early_phase_end:
            if current_round > 0:
                last_round_cooperators = sum(history.opponent_actions[-1, :])
                if last_round_cooperators >= self.m:
                    return Action.D
            return Action.C if random.random() < 0.3 else Action.D
        if current_round >= self.r * 0.8:
            if current_round > 0:
                prev_cooperators = sum(history.opponent_actions[-1, :])
                if prev_cooperators == 0 and self._certain_failure_without_cooperation():
                    return Action.C
            return Action.D
        expected_cooperators = reliable_cooperators + likely_cooperators
        if expected_cooperators >= self.m:
            return Action.D
        elif expected_cooperators == self.m - 1:
            return Action.D if random.random() < 0.8 else Action.C
        elif self._collective_failure_imminent(history, current_round):
            return Action.C
        else:
            return Action.D

    def _count_reliable_cooperators(self, history: PlayerHistory) -> int:
        """Count opponents who cooperated in >= 70% of previous rounds."""
        if history.round_number == 0:
            return 0
        cooperation_rates = np.mean(history.opponent_actions, axis=0)
        return sum((rate >= 0.7 for rate in cooperation_rates))

    def _estimate_likely_cooperators(self, history: PlayerHistory) -> float:
        """Estimate expected number of cooperators using exponentially weighted average."""
        if history.round_number == 0:
            return 0.0
        alpha = 0.7
        likely_count = 0.0
        for player_idx in range(self.n - 1):
            player_actions = history.opponent_actions[:, player_idx]
            if len(player_actions) == 1:
                likely_count += float(player_actions[0])
            else:
                recent_cooperation_rate = 0.0
                weight_sum = 0.0
                for i in range(len(player_actions)):
                    weight = alpha ** (len(player_actions) - 1 - i)
                    recent_cooperation_rate += weight * float(player_actions[i])
                    weight_sum += weight
                recent_cooperation_rate /= weight_sum
                likely_count += recent_cooperation_rate
        return likely_count

    def _certain_failure_without_cooperation(self) -> bool:
        """Check if failure is certain without our cooperation."""
        return True

    def _collective_failure_imminent(self, history: PlayerHistory, current_round: int) -> bool:
        """Check if collective failure is imminent based on recent cooperation patterns."""
        if history.round_number < 3:
            return False
        recent_rounds = min(4, history.round_number)
        failure_count = 0
        for i in range(recent_rounds):
            round_idx = -(i + 1)
            cooperators = sum(history.opponent_actions[round_idx, :])
            our_action = history.my_actions[round_idx]
            total_cooperators = cooperators + (1 if our_action else 0)
            if total_cooperators < self.m:
                failure_count += 1
        failure_threshold = self.r / 4
        return failure_count > failure_threshold

class Strategy_AGGRESSIVE_48(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Threshold Predator"
    
    This strategy aggressively exploits the collective action problem by minimizing 
    personal contribution while maximizing benefit from others' cooperation. It 
    operates on the principle that enough others will cooperate to meet the threshold, 
    allowing defectors to free-ride with maximum payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        n_players = self.game_description.n_players
        threshold = self.game_description.m
        n_rounds = self.game_description.n_rounds
        current_round = history.round_number
        rounds_remaining = n_rounds - current_round - 1
        success_count = 0
        total_cooperators = 0
        for round_idx in range(current_round):
            round_cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                round_cooperators += 1
            total_cooperators += round_cooperators
            if round_cooperators >= threshold:
                success_count += 1
        success_rate = success_count / current_round if current_round > 0 else 0
        avg_cooperators = total_cooperators / current_round if current_round > 0 else 0
        if rounds_remaining == 0:
            return Action.D
        if success_rate >= 0.8:
            return Action.D
        elif success_rate >= 0.4:
            within_threshold_range = abs(avg_cooperators - threshold) <= 1
            endgame_pressure = rounds_remaining < 0.25 * n_rounds
            if within_threshold_range and endgame_pressure:
                return Action.C
            else:
                return Action.D
        else:
            consecutive_failures = 0
            if current_round >= 2:
                for i in range(max(0, current_round - 3), current_round):
                    round_cooperators = sum(history.opponent_actions[i, :])
                    if history.my_actions[i]:
                        round_cooperators += 1
                    if round_cooperators < threshold:
                        consecutive_failures += 1
                    else:
                        consecutive_failures = 0
            if consecutive_failures >= 2 and rounds_remaining > 1:
                return Action.C
            pivotal_count = 0
            similar_situations = 0
            for round_idx in range(current_round):
                opponent_cooperators = sum(history.opponent_actions[round_idx, :])
                if opponent_cooperators == threshold - 1:
                    similar_situations += 1
                    if history.my_actions[round_idx]:
                        pivotal_count += 1
            was_pivotal = pivotal_count > 0 and similar_situations > 0 and (pivotal_count / similar_situations > 0.5)
            if was_pivotal and rounds_remaining > 3:
                return Action.C
            else:
                return Action.D

class Strategy_AGGRESSIVE_49(BaseStrategy):
    """
    Threshold Predator - An aggressive exploitative strategy that aims to benefit from others' 
    cooperation while minimizing personal contribution. Cooperates only when likely to be the 
    pivotal player needed to reach the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.player_cooperation_rates = np.zeros(self.n_players - 1)
        self.reliable_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        if current_round >= self.n_rounds - 1:
            return Action.D
        self._update_cooperation_tracking(history)
        if self.reliable_cooperators < self.m - 1:
            return Action.D
        predicted_cooperators = self._estimate_cooperators(history)
        if predicted_cooperators >= self.m - 1 and predicted_cooperators < self.m + 2:
            return Action.C
        elif predicted_cooperators >= self.m + 2:
            return Action.D
        else:
            return Action.D

    def _update_cooperation_tracking(self, history: PlayerHistory):
        """Update tracking of each opponent's cooperation patterns."""
        n_rounds = history.round_number
        for player_idx in range(self.n_players - 1):
            if n_rounds >= 3:
                recent_actions = history.opponent_actions[max(0, n_rounds - 3):, player_idx]
                earlier_actions = history.opponent_actions[:max(0, n_rounds - 3), player_idx]
                recent_rate = np.mean(recent_actions) if len(recent_actions) > 0 else 0
                earlier_rate = np.mean(earlier_actions) if len(earlier_actions) > 0 else 0
                total_recent = len(recent_actions)
                total_earlier = len(earlier_actions)
                total_rounds = total_recent + total_earlier
                if total_rounds > 0:
                    self.player_cooperation_rates[player_idx] = (recent_rate * total_recent * 0.6 + earlier_rate * total_earlier * 0.4) / (total_recent * 0.6 + total_earlier * 0.4)
            else:
                self.player_cooperation_rates[player_idx] = np.mean(history.opponent_actions[:, player_idx])
        self.reliable_cooperators = np.sum(self.player_cooperation_rates > 0.8)

    def _estimate_cooperators(self, history: PlayerHistory) -> int:
        """Estimate number of cooperators for this round."""
        predicted_cooperators = 0
        for player_idx in range(self.n_players - 1):
            coop_rate = self.player_cooperation_rates[player_idx]
            if coop_rate > 0.7:
                predicted_cooperators += 1
            elif coop_rate < 0.3:
                pass
            else:
                volatility_factor = self._calculate_volatility(history, player_idx)
                adjusted_rate = coop_rate * (1 - volatility_factor * 0.2)
                if adjusted_rate > 0.5:
                    predicted_cooperators += 1
        return predicted_cooperators

    def _calculate_volatility(self, history: PlayerHistory, player_idx: int) -> float:
        """Calculate volatility in a player's recent behavior."""
        n_rounds = history.round_number
        if n_rounds < 3:
            return 0.0
        recent_window = min(5, n_rounds)
        recent_actions = history.opponent_actions[-recent_window:, player_idx]
        variance = np.var(recent_actions.astype(float))
        return min(variance * 2, 1.0)

class Strategy_AGGRESSIVE_50(BaseStrategy):
    """
    Aggressive Threshold Exploitation Strategy (ATES).
    
    This strategy aggressively exploits the collective risk structure by maximizing 
    personal payoff while strategically contributing just enough to secure the 
    collective reward when beneficial. It treats cooperation as a calculated 
    investment, not a moral imperative.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        rounds_remaining = self.r - current_round
        last_round_idx = history.round_number - 1
        cooperators_last_round = sum(history.opponent_actions[last_round_idx, :])
        if history.my_actions[last_round_idx]:
            total_cooperators_last_round = cooperators_last_round + 1
        else:
            total_cooperators_last_round = cooperators_last_round
        i_cooperated_last_round = history.my_actions[last_round_idx]
        coop_rate = total_cooperators_last_round / self.n
        deficit = max(0, self.m - total_cooperators_last_round)
        if current_round == self.r:
            if cooperators_last_round == self.m - 1:
                return Action.C
            elif cooperators_last_round < self.m - 2:
                return Action.D
            else:
                return Action.D
        if deficit == 0 and coop_rate > self.m / self.n:
            return Action.D
        if deficit <= 2 and (not i_cooperated_last_round):
            return Action.C
        if deficit == 1 and rounds_remaining <= 3:
            return Action.C
        if history.round_number >= 3:
            recent_cooperators = []
            for i in range(max(0, history.round_number - 3), history.round_number):
                round_cooperators = sum(history.opponent_actions[i, :])
                if history.my_actions[i]:
                    round_cooperators += 1
                recent_cooperators.append(round_cooperators)
            if len(recent_cooperators) >= 2:
                trend_up = recent_cooperators[-1] > recent_cooperators[-2]
                approaching_threshold = recent_cooperators[-1] >= self.m - 1
                if trend_up and approaching_threshold:
                    return Action.C
        if total_cooperators_last_round >= self.m + 1 and (not i_cooperated_last_round):
            return Action.D
        if total_cooperators_last_round == self.m - 1 and rounds_remaining > 1:
            if random.random() < 0.8:
                return Action.C
            else:
                return Action.D
        if history.round_number >= 2:
            all_coop = True
            for round_idx in range(history.round_number):
                if sum(history.opponent_actions[round_idx, :]) < self.n - 1:
                    all_coop = False
                    break
            if all_coop and rounds_remaining > 2:
                return Action.D
            elif all_coop and rounds_remaining <= 2:
                return Action.C if deficit <= 1 else Action.D
        return Action.D

class Strategy_AGGRESSIVE_51(BaseStrategy):
    """
    Threshold Predator: An aggressive exploitation strategy that free-rides on cooperation
    while minimizing personal risk, only cooperating when pivotal to maintain the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.reliable_threshold = 0.7
        self.conditional_threshold = 0.3
        self.decay_factor = 0.9

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        round_num = history.round_number
        if round_num == self.r - 1:
            return Action.D
        return self._adaptive_exploitation_decision(history)

    def _adaptive_exploitation_decision(self, history):
        avg_cooperators = self._calculate_weighted_avg_cooperators(history)
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        reliable_cooperators = self._count_reliable_cooperators(history)
        if avg_cooperators >= self.m:
            return Action.D
        elif avg_cooperators >= self.m - 1:
            if last_round_cooperators >= self.m - 1:
                return Action.C
            else:
                return Action.D
        else:
            cooperation_prob = (self.m - avg_cooperators) / self.n
            cooperation_prob = self._apply_edge_case_adjustments(cooperation_prob, history)
            cooperation_prob += random.uniform(-0.1, 0.1)
            cooperation_prob = max(0.0, min(1.0, cooperation_prob))
            return Action.C if random.random() < cooperation_prob else Action.D

    def _calculate_weighted_avg_cooperators(self, history):
        """Calculate weighted average of cooperators with exponential decay."""
        total_weighted = 0.0
        weight_sum = 0.0
        for round_idx in range(history.round_number):
            weight = self.decay_factor ** (history.round_number - round_idx - 1)
            cooperators = sum(history.opponent_actions[round_idx, :])
            total_weighted += weight * cooperators
            weight_sum += weight
        return total_weighted / weight_sum if weight_sum > 0 else 0

    def _count_reliable_cooperators(self, history):
        """Count opponents classified as reliable cooperators (>70% cooperation rate)."""
        reliable_count = 0
        for player_idx in range(self.n - 1):
            player_actions = history.opponent_actions[:, player_idx]
            cooperation_rate = sum(player_actions) / len(player_actions)
            if cooperation_rate > self.reliable_threshold:
                reliable_count += 1
        return reliable_count

    def _apply_edge_case_adjustments(self, base_prob, history):
        """Apply adjustments for special game parameters."""
        adjusted_prob = base_prob
        if self.m == self.n - 1:
            last_round_cooperators = sum(history.opponent_actions[-1, :])
            if last_round_cooperators < self.n - 2:
                adjusted_prob *= 0.5
        if self.k > 3:
            adjusted_prob *= (self.k - 1) / 2
        if self.n <= 4:
            round_factor = max(0.5, 1.0 - history.round_number / self.r)
            adjusted_prob *= 1 + round_factor
        recent_failures = self._count_recent_threshold_failures(history)
        if recent_failures > 0:
            adjusted_prob *= 1 + 0.3 * recent_failures
        return min(1.0, adjusted_prob)

    def _count_recent_threshold_failures(self, history):
        """Count how many of the last 3 rounds failed to meet threshold."""
        failures = 0
        start_round = max(0, history.round_number - 3)
        for round_idx in range(start_round, history.round_number):
            cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators < self.m:
                failures += 1
        return failures

class Strategy_AGGRESSIVE_52(BaseStrategy):
    """
    Aggressive Adaptive Exploitation Strategy (AAES) - A ruthlessly opportunistic strategy
    that maximizes personal gain by exploiting cooperative players while strategically
    manipulating the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        if current_round < 3:
            if current_round == 1:
                prev_cooperators = sum(history.opponent_actions[-1, :])
                if prev_cooperators >= self.m - 1:
                    return Action.D
                else:
                    return Action.C
            else:
                prev_cooperators = sum(history.opponent_actions[-1, :])
                if prev_cooperators >= self.m - 1:
                    return Action.D
                else:
                    return Action.C
        elif current_round >= self.n_rounds - 2:
            if current_round == self.n_rounds - 1:
                return Action.D
            elif current_round >= 3:
                recent_coop_rates = []
                for i in range(min(3, current_round)):
                    round_idx = current_round - 1 - i
                    coop_count = sum(history.opponent_actions[round_idx, :])
                    recent_coop_rates.append(coop_count)
                avg_cooperation = np.mean(recent_coop_rates)
                if avg_cooperation >= self.m - 0.5:
                    return Action.D
                else:
                    return self._phase2_logic(history)
            else:
                return Action.D
        else:
            return self._phase2_logic(history)

    def _phase2_logic(self, history: PlayerHistory) -> Action:
        """Core exploitation logic for Phase 2"""
        current_round = history.round_number
        look_back = min(3, current_round)
        reliable_cooperators = 0
        conditional_players = 0
        for player_idx in range(self.n_players - 1):
            cooperations = 0
            for round_back in range(look_back):
                round_idx = current_round - 1 - round_back
                if history.opponent_actions[round_idx, player_idx]:
                    cooperations += 1
            coop_rate = cooperations / look_back
            if coop_rate >= 2 / 3:
                reliable_cooperators += 1
            elif coop_rate >= 1 / 3:
                conditional_players += 1
        expected_cooperators = reliable_cooperators + 0.5 * conditional_players
        if expected_cooperators >= self.m:
            return Action.D
        elif expected_cooperators >= self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_AGGRESSIVE_53(BaseStrategy):
    """
    Aggressive Threshold Exploitation Strategy (ATES) - Minimizes cooperative investment 
    while maximally exploiting threshold structures for personal gain through strategic 
    defection and calculated minimal cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number + 1
        last_cooperators = sum(history.opponent_actions[-1, :]) + int(history.my_actions[-1])
        i_defected_last = not history.my_actions[-1]
        my_cooperation_rate = np.mean(history.my_actions) if len(history.my_actions) > 0 else 0
        others_cooperation_rates = []
        if len(history.opponent_actions) > 0:
            for player_idx in range(history.opponent_actions.shape[1]):
                player_rate = np.mean(history.opponent_actions[:, player_idx])
                others_cooperation_rates.append(player_rate)
        early_phase_end = max(1, r // 3)
        strategic_phase_end = max(2, 2 * r // 3)
        if current_round > strategic_phase_end:
            if current_round == r:
                return Action.D
            if current_round == r - 1 and last_cooperators != m - 1:
                return Action.D
        if last_cooperators == m and i_defected_last:
            return Action.D
        if last_cooperators >= m + 1:
            return Action.D
        if last_cooperators == m - 1:
            high_cooperators = sum((1 for rate in others_cooperation_rates if rate > 0.6))
            low_cooperators = sum((1 for rate in others_cooperation_rates if rate < 0.3))
            if low_cooperators >= len(others_cooperation_rates) - m + 1:
                return Action.C
        if len(history.my_actions) >= 3:
            recent_rounds = min(3, len(history.my_actions))
            failure_streak = True
            for i in range(recent_rounds):
                round_idx = -(i + 1)
                round_cooperators = sum(history.opponent_actions[round_idx, :]) + int(history.my_actions[round_idx])
                if round_cooperators >= m:
                    failure_streak = False
                    break
            if failure_streak and last_cooperators == m - 1:
                return Action.C
        if current_round <= early_phase_end:
            if len(history.my_actions) >= 3:
                recent_success = 0
                for i in range(min(3, len(history.my_actions))):
                    round_idx = -(i + 1)
                    round_cooperators = sum(history.opponent_actions[round_idx, :]) + int(history.my_actions[round_idx])
                    if round_cooperators >= m:
                        recent_success += 1
                if recent_success >= 2:
                    return Action.D
        if current_round > early_phase_end:
            if last_cooperators == m and (not i_defected_last):
                return Action.D
            if last_cooperators < m - 2:
                return Action.D
        return Action.D

class Strategy_AGGRESSIVE_54(BaseStrategy):
    """
    Aggressive Adaptive Threshold Strategy (AATS) - Maximizes personal gain by exploiting 
    others' cooperation while minimizing personal risk. Only cooperates when exactly needed 
    to reach the threshold, adapting aggression based on opponent behavior patterns.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if history is None:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        lookback_rounds = min(5, current_round)
        if lookback_rounds > 0:
            recent_opponent_actions = history.opponent_actions[-lookback_rounds:, :]
            avg_opponent_cooperation = np.mean(recent_opponent_actions)
        else:
            avg_opponent_cooperation = 0.5
        if avg_opponent_cooperation < 0.3:
            return Action.D
        if current_round > 0:
            last_round_cooperators = np.sum(history.opponent_actions[-1, :])
            if history.my_actions[-1] and last_round_cooperators + 1 < self.m:
                return Action.D
        if current_round > 0:
            estimated_current_cooperators = np.sum(history.opponent_actions[-1, :])
        else:
            estimated_current_cooperators = 0
        if estimated_current_cooperators == self.m - 1:
            my_cooperation_rate = np.mean(history.my_actions) if len(history.my_actions) > 0 else 0
            if current_round > self.r * 0.75:
                if my_cooperation_rate < 0.3:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.C
        if current_round > 0 and np.sum(history.opponent_actions[-1, :]) == self.m - 1:
            return Action.D
        return Action.D

class Strategy_AGGRESSIVE_55(BaseStrategy):
    """
    Threshold Hawk: An aggressive exploitation strategy that maximizes personal payoff
    by strategically free-riding on others' cooperation, only cooperating when absolutely
    critical for threshold achievement.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_rounds_left = 0
        self.cooperation_adjustment = 0.0
        self.last_recalibration_round = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        if state.round_number >= self.game_description.n_rounds - 1:
            return Action.D
        if self.punishment_rounds_left > 0:
            self.punishment_rounds_left -= 1
            return Action.D
        expected_cooperators = self._calculate_expected_cooperators(history)
        cooperation_deficit = self.game_description.m - expected_cooperators
        if cooperation_deficit > 1:
            action = Action.D
        elif cooperation_deficit <= 0.3:
            action = Action.D
        else:
            recent_trend = self._analyze_recent_trend(history)
            if recent_trend == 'declining' and cooperation_deficit > 0.7:
                action = Action.C
            elif random.random() < 0.15:
                action = Action.C if random.random() < 0.5 else Action.D
            else:
                action = Action.D
        if history.round_number > 0:
            last_round_cooperators = sum(history.opponent_actions[-1, :])
            if history.my_actions[-1] == True:
                if last_round_cooperators + 1 < self.game_description.m:
                    self.punishment_rounds_left = 2
        if state.round_number - self.last_recalibration_round >= 3:
            self._recalibrate(history)
            self.last_recalibration_round = state.round_number
        return action

    def _calculate_expected_cooperators(self, history: PlayerHistory) -> float:
        """Calculate expected number of cooperators based on opponent history."""
        n_opponents = self.game_description.n_players - 1
        expected = 0.0
        for opponent_idx in range(n_opponents):
            opponent_history = history.opponent_actions[:, opponent_idx]
            cooperation_rate = np.mean(opponent_history)
            avg_cooperation_rate = np.mean(history.opponent_actions)
            if cooperation_rate > 0.8:
                cooperation_rate *= 1.2
            elif cooperation_rate < 0.3:
                cooperation_rate *= 0.8
            expected += cooperation_rate + self.cooperation_adjustment
        return expected

    def _analyze_recent_trend(self, history: PlayerHistory) -> str:
        """Analyze cooperation trend in the last 3 rounds."""
        if history.round_number < 3:
            return 'stable'
        recent_rounds = min(3, history.round_number)
        recent_cooperation = []
        for i in range(recent_rounds):
            round_idx = -(i + 1)
            cooperators = sum(history.opponent_actions[round_idx, :])
            recent_cooperation.append(cooperators)
        if len(recent_cooperation) >= 2:
            if recent_cooperation[0] < recent_cooperation[-1]:
                return 'declining'
        return 'stable'

    def _recalibrate(self, history: PlayerHistory) -> None:
        """Recalibrate expectations based on recent performance."""
        if history.round_number < 3:
            return
        correct_predictions = 0
        total_predictions = 0
        for i in range(min(3, history.round_number)):
            round_idx = -(i + 1)
            actual_cooperators = sum(history.opponent_actions[round_idx, :])
            if round_idx == -1:
                continue
            prev_rounds = history.round_number + round_idx
            if prev_rounds <= 0:
                continue
            avg_cooperation = np.mean(history.opponent_actions[:prev_rounds, :])
            expected = avg_cooperation * (self.game_description.n_players - 1)
            if abs(expected - actual_cooperators) < 1.0:
                correct_predictions += 1
            total_predictions += 1
        if total_predictions > 0:
            accuracy = correct_predictions / total_predictions
            if accuracy < 0.5:
                self.cooperation_adjustment += 0.1
            elif accuracy > 0.8:
                self.cooperation_adjustment -= 0.1
        self.cooperation_adjustment = max(-0.3, min(0.3, self.cooperation_adjustment))

class Strategy_AGGRESSIVE_56(BaseStrategy):
    """
    Predator strategy: Opportunistically exploit cooperative players while maintaining
    minimal strategic cooperation only when personal disaster is imminent. Always defects
    in first and last rounds, and free-rides when threshold is met.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defection_streak = 0
        self.opponent_cooperation_counts = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.defection_streak = 1
            return Action.D
        if self.opponent_cooperation_counts is None:
            self.opponent_cooperation_counts = np.zeros(self.game_description.n_players - 1)
        current_round = state.round_number
        if current_round == self.game_description.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            cooperators_last_round += 1
        self.opponent_cooperation_counts += history.opponent_actions[-1, :]
        if cooperators_last_round >= self.game_description.m:
            self.defection_streak += 1
            return Action.D
        elif cooperators_last_round == self.game_description.m - 1:
            if self.defection_streak >= 3:
                self.defection_streak = 0
                return Action.C
            else:
                self.defection_streak += 1
                return Action.D
        rounds_remaining = self.game_description.n_rounds - current_round
        if cooperators_last_round < self.game_description.m - 2:
            self.defection_streak += 1
            return Action.D
        elif rounds_remaining <= 2 and cooperators_last_round < self.game_description.m:
            avg_cooperation_rate = np.mean(self.opponent_cooperation_counts) / history.round_number
            panic_factor = 1.5 if rounds_remaining == 1 else 1.2
            estimated_cooperators = int(avg_cooperation_rate * panic_factor * (self.game_description.n_players - 1))
            if estimated_cooperators + 1 >= self.game_description.m:
                self.defection_streak = 0
                return Action.C
            else:
                self.defection_streak += 1
                return Action.D
        self.defection_streak += 1
        return Action.D

class Strategy_AGGRESSIVE_57(BaseStrategy):
    """
    Opportunistic Threshold Exploiter - An aggressive strategy that maximizes exploitation
    while minimally contributing to collective success. Defaults to defection and only
    cooperates when absolutely necessary to maintain the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            if self.m > self.n / 2:
                return Action.C
            else:
                return Action.D
        round_num = history.round_number
        if round_num >= self.r - 1:
            return Action.D
        if round_num < self.r / 3:
            return Action.D
        last_round_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            total_cooperators_last = last_round_cooperators + 1
        else:
            total_cooperators_last = last_round_cooperators
        my_coop_rate = np.mean(history.my_actions)
        opponent_coop_rates = np.mean(history.opponent_actions, axis=0)
        reliable_cooperators = int(np.sum(opponent_coop_rates > 0.6))
        rounds_remaining = self.r - round_num
        if round_num >= 2 * self.r / 3:
            if reliable_cooperators >= self.m:
                return Action.D
            elif reliable_cooperators == self.m - 1 and rounds_remaining <= 3:
                return Action.C
            else:
                return Action.D
        else:
            if total_cooperators_last >= self.m:
                return Action.D
            elif total_cooperators_last == self.m - 1:
                if my_coop_rate < 0.3:
                    return Action.C
                else:
                    return Action.D
            if round_num >= 2:
                prev_round_cooperators = int(np.sum(history.opponent_actions[-2, :]))
                if history.my_actions[-2]:
                    prev_total = prev_round_cooperators + 1
                else:
                    prev_total = prev_round_cooperators
                if total_cooperators_last < self.m and prev_total < self.m and (rounds_remaining > 3):
                    return Action.C
            return Action.D

class Strategy_AGGRESSIVE_58(BaseStrategy):
    """
    Aggressive Threshold Exploitation Strategy (ATES) - Exploits collective vulnerability 
    while maintaining strategic self-preservation through aggressive free-riding and 
    threshold manipulation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.punishment_rounds = 0
        self.retaliation_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        if self.punishment_rounds > 0:
            self.punishment_rounds -= 1
            return Action.D
        if self.retaliation_rounds > 0:
            self.retaliation_rounds -= 1
            return Action.D
        if current_round >= self.r - 1:
            return Action.D
        elif current_round == self.r - 2:
            return self._endgame_decision(history)
        if current_round <= 2:
            return self._initial_aggression(history)
        return self._adaptive_exploitation(history)

    def _initial_aggression(self, history):
        """Phase 1: Initial aggression rounds 2-3"""
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        threshold_met = last_round_cooperators + int(history.my_actions[-1]) >= self.m
        if not threshold_met:
            return Action.C
        else:
            return Action.D

    def _adaptive_exploitation(self, history):
        """Phase 2: Adaptive exploitation with threshold manipulation"""
        if self._should_punish(history):
            self.punishment_rounds = 2
            return Action.D
        if self._should_retaliate(history):
            self.retaliation_rounds = 3
            return Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        my_contribution_needed = max(0, self.m - last_round_cooperators)
        if my_contribution_needed == 0:
            return Action.D
        elif my_contribution_needed == 1:
            prob_others_cooperate = self._estimate_cooperation_probability(history)
            if prob_others_cooperate < 0.7:
                return Action.D
            else:
                return Action.C
        else:
            return Action.D

    def _endgame_decision(self, history):
        """Phase 3: Second-to-last round decision"""
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        my_contribution_needed = max(0, self.m - last_round_cooperators)
        if my_contribution_needed == 1:
            prob_others_cooperate = self._estimate_cooperation_probability(history)
            likely_cooperators = prob_others_cooperate * (self.n - 1)
            if likely_cooperators >= 2:
                return Action.C
        return Action.D

    def _should_punish(self, history):
        """Check if cooperation rate dropped below 40% - trigger punishment"""
        if len(history.my_actions) < 1:
            return False
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        cooperation_rate = last_round_cooperators / (self.n - 1)
        return cooperation_rate < 0.4

    def _should_retaliate(self, history):
        """Check if generous players started defecting - trigger retaliation"""
        if len(history.my_actions) < 3:
            return False
        for player_idx in range(self.n - 1):
            recent_actions = history.opponent_actions[max(0, len(history.my_actions) - 3):, player_idx]
            if len(recent_actions) >= 3:
                cooperation_rate = sum(recent_actions) / len(recent_actions)
                if cooperation_rate > 0.7 and (not history.opponent_actions[-1, player_idx]):
                    return True
        return False

    def _estimate_cooperation_probability(self, history):
        """Estimate probability others will cooperate based on recent behavior"""
        if len(history.my_actions) < 3:
            return 0.5
        recent_rounds = min(3, len(history.my_actions))
        start_idx = max(0, len(history.my_actions) - recent_rounds)
        total_cooperation_rate = 0
        for player_idx in range(self.n - 1):
            recent_actions = history.opponent_actions[start_idx:, player_idx]
            player_rate = sum(recent_actions) / len(recent_actions)
            total_cooperation_rate += player_rate
        return total_cooperation_rate / (self.n - 1)

class Strategy_AGGRESSIVE_59(BaseStrategy):
    """
    Aggressive Threshold Exploiter Strategy - Ruthlessly exploits cooperative players
    while minimizing personal risk by cooperating only when absolutely necessary
    to maintain the reward structure.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        last_round_cooperators = int(sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            last_round_cooperators += 1
        if current_round == self.r - 2:
            total_rounds = len(history.my_actions)
            total_opponent_cooperations = np.sum(history.opponent_actions)
            total_possible_cooperations = total_rounds * (self.n - 1)
            historical_coop_rate = total_opponent_cooperations / total_possible_cooperations
            if historical_coop_rate > 0.6 and last_round_cooperators >= self.m - 1:
                return Action.D
            else:
                return Action.C
        if len(history.my_actions) >= 3:
            recent_rounds = min(3, len(history.my_actions))
            recent_threshold_met = 0
            for i in range(recent_rounds):
                round_cooperators = int(sum(history.opponent_actions[-(i + 1), :]))
                if history.my_actions[-(i + 1)]:
                    round_cooperators += 1
                if round_cooperators >= self.m:
                    recent_threshold_met += 1
            if recent_threshold_met == 0:
                return Action.C if current_round % 2 == 0 else Action.D
        if len(history.my_actions) >= 2:
            total_opponent_cooperations = np.sum(history.opponent_actions)
            total_possible = len(history.my_actions) * (self.n - 1)
            opponent_coop_rate = total_opponent_cooperations / total_possible
            if opponent_coop_rate > 0.8:
                last_round_opponent_cooperators = int(sum(history.opponent_actions[-1, :]))
                if last_round_opponent_cooperators == self.m - 1:
                    return Action.C
                elif current_round % 3 == 0:
                    return Action.C
                else:
                    return Action.D
        last_round_opponent_cooperators = int(sum(history.opponent_actions[-1, :]))
        my_cooperation_needed = last_round_opponent_cooperators < self.m - 1
        if my_cooperation_needed:
            return Action.C
        else:
            return Action.D

class Strategy_AGGRESSIVE_60(BaseStrategy):
    """
    Aggressive Adaptive Threshold Strategy (AATS) - Exploitative opportunism strategy
    that maximizes personal gain through strategic free-riding and threshold manipulation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.exploration_end = min(3, self.r // 4)
        self.endgame_start = max(self.r - max(2, self.r // 5), self.exploration_end + 1)
        self.base_exploitation_threshold = 1.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number + 1
        my_last_action = 1 if history.my_actions[-1] else 0
        opponent_cooperators_last = int(np.sum(history.opponent_actions[-1, :]))
        total_cooperators_last = opponent_cooperators_last + my_last_action
        if current_round <= self.exploration_end:
            return self._exploration_phase_decision(total_cooperators_last, my_last_action)
        elif current_round >= self.endgame_start:
            return self._endgame_phase_decision(current_round, history)
        else:
            return self._exploitation_phase_decision(current_round, history, total_cooperators_last)

    def _exploration_phase_decision(self, cooperators_last: int, my_last_action: int) -> Action:
        """Exploration phase: Gather intelligence while being aggressive"""
        if cooperators_last >= self.m:
            return Action.D
        elif cooperators_last == self.m - 1:
            if my_last_action == 1:
                return Action.D
            else:
                return Action.C
        else:
            return Action.D

    def _exploitation_phase_decision(self, current_round: int, history: PlayerHistory, cooperators_last: int) -> Action:
        """Main exploitation phase with dynamic threshold manipulation"""
        trend = self._calculate_cooperation_trend(history)
        exploitation_threshold = self._calculate_dynamic_threshold(history, current_round)
        if cooperators_last >= self.m:
            return Action.D
        elif cooperators_last == self.m - 1:
            expected_value_cooperate = self.k - 1
            if expected_value_cooperate > exploitation_threshold:
                return Action.C
            else:
                return Action.D
        elif cooperators_last >= self.m - 2 and trend > 0:
            rounds_remaining = self.r - current_round
            if rounds_remaining > 2:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _endgame_phase_decision(self, current_round: int, history: PlayerHistory) -> Action:
        """Endgame phase: Maximum exploitation with reduced cooperation"""
        rounds_left = self.r - current_round + 1
        predicted_cooperators = self._predict_cooperators_this_round(history)
        if rounds_left == 1:
            if predicted_cooperators >= self.m:
                return Action.D
            elif predicted_cooperators == self.m - 1:
                return Action.C
            else:
                return Action.D
        else:
            cooperation_threshold = self.k * 0.7
            my_last_action = 1 if history.my_actions[-1] else 0
            opponent_cooperators_last = int(np.sum(history.opponent_actions[-1, :]))
            total_cooperators_last = opponent_cooperators_last + my_last_action
            if total_cooperators_last >= self.m:
                return Action.D
            elif total_cooperators_last == self.m - 1:
                expected_value = self.k - 1
                if expected_value > cooperation_threshold:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D

    def _calculate_cooperation_trend(self, history: PlayerHistory) -> float:
        """Calculate trend in cooperation over last 3 rounds"""
        rounds_to_check = min(3, history.round_number)
        if rounds_to_check < 2:
            return 0.0
        recent_rounds = history.opponent_actions[-rounds_to_check:, :]
        cooperation_counts = np.sum(recent_rounds, axis=1)
        if len(cooperation_counts) < 2:
            return 0.0
        trend = cooperation_counts[-1] - cooperation_counts[0]
        return float(trend)

    def _calculate_dynamic_threshold(self, history: PlayerHistory, current_round: int) -> float:
        """Calculate dynamic exploitation threshold based on game state"""
        threshold = self.base_exploitation_threshold
        if history.round_number >= 2:
            cooperation_rates = np.mean(history.opponent_actions, axis=0)
            unconditional_cooperators = np.sum(cooperation_rates > 0.8)
            if unconditional_cooperators > self.n // 3:
                threshold *= 1.3
            total_cooperators_per_round = np.sum(history.opponent_actions, axis=1) + history.my_actions.astype(int)
            successful_rounds = np.sum(total_cooperators_per_round >= self.m)
            success_rate = successful_rounds / history.round_number
            if success_rate < 0.3:
                threshold *= 0.8
            elif success_rate > 0.8:
                threshold *= 1.2
        if self.m >= self.n - 1:
            threshold *= 0.8
        if self.k > 3:
            threshold *= 0.9
        if current_round > self.r * 0.7:
            time_factor = (self.r - current_round) / (self.r * 0.3)
            threshold *= max(0.5, time_factor)
        return threshold

    def _predict_cooperators_this_round(self, history: PlayerHistory) -> int:
        """Predict number of cooperators this round based on recent patterns"""
        if history.round_number == 0:
            return 0
        recent_rounds = min(2, history.round_number)
        recent_cooperation = history.opponent_actions[-recent_rounds:, :]
        avg_cooperation = np.mean(recent_cooperation)
        return int(round(avg_cooperation * (self.n - 1)))

class Strategy_AGGRESSIVE_61(BaseStrategy):
    """
    Threshold Predator Strategy: An aggressive exploitation strategy that maximizes personal gain
    while minimizing contributions. It calculates the minimum safe cooperation level and consistently
    tries to contribute less than its fair share while benefiting from others' cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_counter = 0
        self.expected_payoff_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        k = self.game_description.k
        if history is None:
            if m / n >= 0.7:
                return Action.C
            else:
                return Action.D
        round_num = state.round_number + 1
        if round_num == r:
            return Action.D
        if self._detect_punishment(history, k):
            self.punishment_counter = 2
        if self.punishment_counter > 0:
            self.punishment_counter -= 1
            return Action.D
        momentum = self._calculate_momentum(history, n)
        predicted_cooperators = max(1, math.floor(momentum * n))
        threshold_buffer = predicted_cooperators - m
        threshold_ratio = m / n
        if threshold_ratio > 0.8:
            cooperation_threshold = 1
        elif threshold_ratio < 0.4:
            cooperation_threshold = -1
        else:
            cooperation_threshold = 0
        if n <= 4:
            cooperation_threshold += 1
        if threshold_buffer >= 2 or momentum < 0.3:
            return Action.D
        elif threshold_buffer <= cooperation_threshold and momentum >= 0.6:
            return Action.C
        else:
            return Action.D

    def _calculate_momentum(self, history: PlayerHistory, n: int) -> float:
        """Calculate cooperation momentum based on recent and historical cooperation rates."""
        rounds_played = history.round_number
        if rounds_played == 0:
            return 0.5
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        cooperation_rate = last_round_cooperators / n
        total_cooperations = np.sum(history.opponent_actions)
        historical_cooperation_rate = total_cooperations / (n * rounds_played)
        momentum = 0.7 * cooperation_rate + 0.3 * historical_cooperation_rate
        return momentum

    def _detect_punishment(self, history: PlayerHistory, k: float) -> bool:
        """Detect if being punished by comparing recent payoffs to expected values."""
        rounds_played = history.round_number
        if rounds_played < 2:
            return False
        recent_payoffs = history.my_payoffs[-2:]
        expected_payoffs = []
        for i in range(max(0, rounds_played - 2), rounds_played):
            my_action = history.my_actions[i]
            opponent_cooperators = np.sum(history.opponent_actions[i, :])
            total_cooperators = opponent_cooperators + (1 if my_action else 0)
            if total_cooperators >= self.game_description.m:
                expected_payoff = 1 - int(my_action) + k
            else:
                expected_payoff = 1 - int(my_action)
            expected_payoffs.append(expected_payoff)
        if len(expected_payoffs) >= 2:
            return all((recent_payoffs[i] < expected_payoffs[i] for i in range(len(expected_payoffs))))
        return False

class Strategy_AGGRESSIVE_62(BaseStrategy):
    """
    Aggressive Threshold Exploitation Strategy (ATES)
    
    Minimizes personal risk while maximizing exploitation of others' cooperation.
    Uses three phases: early defection for intelligence gathering, middle adaptive
    exploitation, and endgame maximum aggression with strategic backup.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.early_phase_end = math.floor(self.r / 3)
        self.middle_phase_end = 2 * math.floor(self.r / 3)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        last_round_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            total_cooperators_last = last_round_cooperators + 1
        else:
            total_cooperators_last = last_round_cooperators
        if current_round <= self.early_phase_end:
            return self._early_phase_decision(history, total_cooperators_last)
        elif current_round <= self.middle_phase_end:
            return self._middle_phase_decision(history, total_cooperators_last)
        else:
            return self._endgame_decision(history, total_cooperators_last, current_round)

    def _early_phase_decision(self, history, total_cooperators_last):
        if len(history.my_actions) >= 2:
            if total_cooperators_last == self.m - 1:
                if not history.my_actions[-1] and history.my_payoffs[-1] > 1.0:
                    consecutive_count = 0
                    for i in range(len(history.my_actions) - 1, -1, -1):
                        round_cooperators = int(np.sum(history.opponent_actions[i, :]))
                        if history.my_actions[i]:
                            round_cooperators += 1
                        if round_cooperators == self.m - 1:
                            consecutive_count += 1
                        else:
                            break
                    if consecutive_count >= 2:
                        return Action.C
        return Action.D

    def _middle_phase_decision(self, history, total_cooperators_last):
        if total_cooperators_last >= self.m:
            return Action.D
        elif total_cooperators_last == self.m - 1:
            consecutive_threshold_meetings = self._count_consecutive_threshold_meetings(history)
            if consecutive_threshold_meetings >= 2:
                return Action.D
            else:
                return Action.C
        else:
            reliable_cooperators = self._count_reliable_cooperators(history, 3)
            if reliable_cooperators >= self.m - 1:
                return Action.C
            else:
                return Action.D

    def _endgame_decision(self, history, total_cooperators_last, current_round):
        remaining_rounds = self.r - current_round
        if remaining_rounds <= 2:
            if total_cooperators_last >= self.m:
                return Action.D
            elif total_cooperators_last == self.m - 1 and remaining_rounds == 1:
                return Action.C
            else:
                return Action.D
        elif remaining_rounds <= 5:
            cooperation_trend = self._calculate_cooperation_trend(history, 5)
            if cooperation_trend == 'INCREASING' and total_cooperators_last >= self.m - 2:
                return Action.D
            elif total_cooperators_last == self.m - 1:
                return Action.C
            else:
                return Action.D
        else:
            return self._apply_edge_case_rules(history, total_cooperators_last, current_round)

    def _apply_edge_case_rules(self, history, total_cooperators_last, current_round):
        if self.m > 0.7 * self.n:
            if total_cooperators_last >= self.m - 2:
                return Action.C
        if self.k > 3:
            if total_cooperators_last >= self.m - 3:
                return Action.C
        if current_round % 2 == 0:
            return Action.D
        else:
            return Action.D

    def _count_consecutive_threshold_meetings(self, history):
        count = 0
        for i in range(len(history.my_actions) - 1, -1, -1):
            round_cooperators = int(np.sum(history.opponent_actions[i, :]))
            if history.my_actions[i]:
                round_cooperators += 1
            if round_cooperators >= self.m:
                count += 1
            else:
                break
        return count

    def _count_reliable_cooperators(self, history, lookback_rounds):
        if len(history.my_actions) < lookback_rounds:
            lookback_rounds = len(history.my_actions)
        if lookback_rounds == 0:
            return 0
        reliable_count = 0
        for player_idx in range(history.opponent_actions.shape[1]):
            cooperation_count = 0
            for round_idx in range(-lookback_rounds, 0):
                if history.opponent_actions[round_idx, player_idx]:
                    cooperation_count += 1
            if cooperation_count >= math.ceil(lookback_rounds * 0.7):
                reliable_count += 1
        return reliable_count

    def _calculate_cooperation_trend(self, history, lookback_rounds):
        if len(history.my_actions) < lookback_rounds:
            return 'STABLE'
        cooperation_counts = []
        for i in range(-lookback_rounds, 0):
            round_cooperators = int(np.sum(history.opponent_actions[i, :]))
            if len(history.my_actions) > abs(i) - 1 and history.my_actions[i]:
                round_cooperators += 1
            cooperation_counts.append(round_cooperators)
        if len(cooperation_counts) < 2:
            return 'STABLE'
        early_avg = np.mean(cooperation_counts[:len(cooperation_counts) // 2])
        late_avg = np.mean(cooperation_counts[len(cooperation_counts) // 2:])
        if late_avg > early_avg + 0.5:
            return 'INCREASING'
        elif late_avg < early_avg - 0.5:
            return 'DECREASING'
        else:
            return 'STABLE'

class Strategy_AGGRESSIVE_63(BaseStrategy):
    """
    Threshold Hawk: An aggressive exploitation strategy that maximizes personal payoff
    by free-riding on others' cooperation while contributing minimally to maintain
    an exploitable cooperator base.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.opponent_cooperation_rates = np.zeros(self.n - 1)
        self.consecutive_failures = 0
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        cooperators_last_round = int(np.sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            total_cooperators_last_round = cooperators_last_round + 1
        else:
            total_cooperators_last_round = cooperators_last_round
        self.cooperation_history.append(total_cooperators_last_round)
        if total_cooperators_last_round < self.m:
            self.consecutive_failures += 1
        else:
            self.consecutive_failures = 0
        if current_round > 0:
            self.opponent_cooperation_rates = np.mean(history.opponent_actions, axis=0)
        my_cooperation_rate = np.mean(history.my_actions) if len(history.my_actions) > 0 else 0
        others_avg_cooperation = np.mean(self.opponent_cooperation_rates) if len(self.opponent_cooperation_rates) > 0 else 0
        phase1_end = self.r // 2
        phase3_start = self.r - 3
        if current_round <= phase1_end:
            return self._phase1_decision(total_cooperators_last_round)
        elif current_round < phase3_start:
            return self._phase2_decision(total_cooperators_last_round, my_cooperation_rate, others_avg_cooperation)
        else:
            return self._phase3_decision(current_round, total_cooperators_last_round)

    def _phase1_decision(self, cooperators_last_round):
        """Phase 1: Initial Exploitation"""
        if cooperators_last_round >= self.m:
            return Action.D
        elif cooperators_last_round == self.m - 1:
            return Action.D
        else:
            return Action.C

    def _phase2_decision(self, cooperators_last_round, my_cooperation_rate, others_avg_cooperation):
        """Phase 2: Calculated Aggression"""
        if cooperators_last_round >= self.m + 2:
            return Action.D
        elif cooperators_last_round >= self.m:
            if my_cooperation_rate < others_avg_cooperation - 0.2:
                return Action.D
            else:
                return Action.C
        elif cooperators_last_round == self.m - 1:
            if self.consecutive_failures >= 2:
                return Action.C
            else:
                return Action.D
        else:
            return Action.C

    def _phase3_decision(self, current_round, cooperators_last_round):
        """Phase 3: Endgame Exploitation"""
        rounds_remaining = self.r - current_round
        if rounds_remaining <= 1:
            return Action.D
        elif cooperators_last_round >= self.m + 1:
            return Action.D
        elif cooperators_last_round >= self.m:
            recent_rounds = min(3, len(self.cooperation_history))
            if recent_rounds > 0:
                recent_trend = np.mean(self.cooperation_history[-recent_rounds:])
                if recent_trend > self.m + 0.5:
                    return Action.D
                else:
                    return Action.C
            else:
                return Action.C
        else:
            return Action.C

class Strategy_AGGRESSIVE_64(BaseStrategy):
    """
    Aggressive Threshold Exploitation Strategy ("Threshold Hawk")
    
    This strategy operates on aggressive opportunism: maximize personal payoffs by 
    exploiting the collective need for cooperation while minimizing personal sacrifice.
    Uses a three-phase approach: information gathering, adaptive exploitation, and endgame aggression.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.opponent_coop_rates = np.ones(self.n - 1) * 0.5
        self.opponent_last_actions = np.zeros(self.n - 1, dtype=bool)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        if current_round <= 1:
            self._update_opponent_tracking(history)
            return Action.D
        self._update_opponent_tracking(history)
        if current_round >= self.r - 2:
            return self._endgame_strategy(history)
        return self._adaptive_exploitation(history)

    def _update_opponent_tracking(self, history: PlayerHistory):
        """Update opponent cooperation rate tracking."""
        if history.round_number > 0:
            alpha = 0.3
            last_actions = history.opponent_actions[-1, :]
            self.opponent_coop_rates = (1 - alpha) * self.opponent_coop_rates + alpha * last_actions
            self.opponent_last_actions = last_actions

    def _predict_next_cooperators(self, history: PlayerHistory):
        """Predict how many opponents will cooperate next round."""
        expected_coop = np.sum(self.opponent_coop_rates)
        last_round_coops = np.sum(history.opponent_actions[-1, :])
        threshold_met = last_round_coops + (1 if history.my_actions[-1] else 0) >= self.m
        if not threshold_met and history.round_number > 1:
            expected_coop = min(expected_coop * 1.2, self.n - 1)
        return expected_coop

    def _adaptive_exploitation(self, history: PlayerHistory):
        """Phase 2: Adaptive exploitation strategy."""
        expected_cooperators = self._predict_next_cooperators(history)
        last_round_coops = np.sum(history.opponent_actions[-1, :])
        if random.random() < 0.1:
            return Action.C if random.random() < 0.3 else Action.D
        if expected_cooperators >= self.m + 1.5:
            return Action.D
        elif expected_cooperators >= self.m + 0.5:
            return Action.D if random.random() < 0.8 else Action.C
        elif expected_cooperators >= self.m - 0.5:
            return Action.D if random.random() < 0.7 else Action.C
        elif expected_cooperators >= self.m - 1.5:
            threshold_risk = (self.m - expected_cooperators) / self.m
            if threshold_risk < 0.3 and self.k > 1.5:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _endgame_strategy(self, history: PlayerHistory):
        """Phase 3: Endgame aggression strategy."""
        current_round = history.round_number
        if current_round == self.r - 1:
            return Action.D
        last_round_coops = np.sum(history.opponent_actions[-1, :])
        if last_round_coops < self.m - 2:
            return Action.C if random.random() < 0.4 else Action.D
        else:
            return Action.D

class Strategy_AGGRESSIVE_65(BaseStrategy):
    """
    Opportunistic Predator: An aggressive exploitation strategy that maximizes personal payoffs
    by exploiting cooperative players while minimizing personal risk. Always defects in first
    and last rounds, and adaptively exploits safety margins in between.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.opponent_coop_rates = np.zeros(self.n - 1)
        self.exploit_mode = False
        self.survival_mode = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        last_round_opponents = history.opponent_actions[-1, :]
        cooperators_last_round = np.sum(last_round_opponents)
        my_last_action = history.my_actions[-1]
        total_cooperators_last_round = cooperators_last_round + int(my_last_action)
        if total_cooperators_last_round >= self.m:
            defectors_last_round = self.n - total_cooperators_last_round
            safety_margin = total_cooperators_last_round - self.m
            if safety_margin >= 1:
                return Action.D
            else:
                return self._calculate_strategic_action(history)
        else:
            return Action.D

    def _calculate_strategic_action(self, history: PlayerHistory) -> Action:
        """Calculate strategic action based on opponent patterns and risk assessment."""
        rounds_to_check = min(3, len(history.my_actions))
        if rounds_to_check >= 2:
            recent_opponent_actions = history.opponent_actions[-rounds_to_check:, :]
            self.opponent_coop_rates = np.mean(recent_opponent_actions, axis=0)
            high_coop_opponents = np.sum(self.opponent_coop_rates > 0.6)
            low_coop_opponents = np.sum(self.opponent_coop_rates < 0.3)
            if high_coop_opponents > len(self.opponent_coop_rates) / 2:
                self.exploit_mode = True
                self.survival_mode = False
            elif low_coop_opponents > len(self.opponent_coop_rates) / 2:
                self.exploit_mode = False
                self.survival_mode = True
            else:
                self.exploit_mode = False
                self.survival_mode = False
        if len(history.my_actions) >= 2:
            predicted_cooperators = self._predict_cooperators(history)
            needed_cooperators = self.m
            safety_margin = predicted_cooperators - needed_cooperators
            if safety_margin >= 2:
                return Action.D
            elif safety_margin == 1:
                if self.exploit_mode and np.mean(self.opponent_coop_rates) > 0.7:
                    return Action.D
                else:
                    return Action.C
            else:
                return Action.C
        return Action.D

    def _predict_cooperators(self, history: PlayerHistory) -> int:
        """Predict how many players will cooperate next round based on patterns."""
        if len(history.my_actions) < 2:
            return self.m
        recent_rounds = min(3, len(history.my_actions))
        recent_opponent_cooperation = np.mean(np.sum(history.opponent_actions[-recent_rounds:, :], axis=1))
        last_round_success = np.sum(history.opponent_actions[-1, :]) + int(history.my_actions[-1]) >= self.m
        if not last_round_success:
            predicted = recent_opponent_cooperation * 1.1
        else:
            predicted = recent_opponent_cooperation * 0.95
        return int(math.ceil(predicted))

class Strategy_AGGRESSIVE_66(BaseStrategy):
    """
    Aggressive Opportunistic Strategy: "Predatory Threshold Rider"
    
    This strategy aggressively maximizes individual payoff by exploiting others' cooperation
    while minimizing personal risk. It operates as a sophisticated free-rider that dynamically
    adapts to prey on cooperative behaviors.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.sucker_threshold = 0.8
        self.group_coop_threshold = 0.6

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        prev_coop_count = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            prev_coop_count += 1
        aggression_multiplier = (current_round / self.r) ** 2
        if random.random() < aggression_multiplier:
            return Action.D
        if len(history.my_actions) >= 3:
            for opponent_idx in range(self.n - 1):
                opponent_coop_rate = np.mean(history.opponent_actions[:, opponent_idx])
                if opponent_coop_rate >= self.sucker_threshold:
                    if prev_coop_count >= self.m - 1:
                        return Action.D
        if len(history.my_actions) >= 3:
            all_actions = np.concatenate([history.opponent_actions.flatten(), history.my_actions])
            group_coop_rate = np.mean(all_actions)
            if group_coop_rate > self.group_coop_threshold:
                if prev_coop_count >= self.m:
                    return Action.D
                elif prev_coop_count == self.m - 1:
                    return Action.D
        if len(history.my_actions) >= 3:
            recent_rounds = min(3, len(history.my_actions))
            recent_coop_counts = []
            for i in range(recent_rounds):
                round_idx = -(i + 1)
                round_coop_count = sum(history.opponent_actions[round_idx, :])
                if history.my_actions[round_idx]:
                    round_coop_count += 1
                recent_coop_counts.append(round_coop_count)
            if len(recent_coop_counts) >= 2:
                if recent_coop_counts[0] > recent_coop_counts[1]:
                    if recent_coop_counts[0] >= self.m - 1:
                        return Action.D
        required_cooperators = self.m - 1
        if current_round > self.r // 2:
            success_count = 0
            total_rounds = len(history.my_actions)
            for round_idx in range(total_rounds):
                round_coop_count = sum(history.opponent_actions[round_idx, :])
                if history.my_actions[round_idx]:
                    round_coop_count += 1
                if round_coop_count >= self.m:
                    success_count += 1
            if total_rounds > 0:
                success_rate = success_count / total_rounds
                if success_rate > 0.7:
                    required_cooperators = self.m
        if self.n <= 3:
            if prev_coop_count == self.m - 1:
                return Action.C
            else:
                return Action.D
        if self.m > self.n / 2:
            if len(history.my_actions) > 0:
                all_actions = np.concatenate([history.opponent_actions.flatten(), history.my_actions])
                if np.mean(all_actions) <= 0.8:
                    return Action.D
        if self.k < 1.5:
            if random.random() < 0.25:
                return Action.D
        if prev_coop_count >= self.m:
            return Action.D
        elif prev_coop_count == required_cooperators:
            return Action.C
        else:
            return Action.D

class Strategy_AGGRESSIVE_67(BaseStrategy):
    """
    Aggressive Exploitation Strategy: Maximum personal benefit through calculated risk,
    cooperating only when absolutely necessary to secure collective rewards.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        round_num = history.round_number + 1
        recent_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            recent_cooperators += 1
        total_actions = len(history.my_actions) * self.n
        total_cooperations = sum((sum(history.opponent_actions[i, :]) + int(history.my_actions[i]) for i in range(len(history.my_actions))))
        cooperation_rate = total_cooperations / total_actions if total_actions > 0 else 0
        if round_num <= self.r // 2:
            if recent_cooperators == self.m - 1 and (not history.my_actions[-1]) and (len(history.my_payoffs) > 0) and (history.my_payoffs[-1] > 1):
                return Action.C
            return Action.D
        elif round_num >= self.r - 1:
            if round_num == self.r - 1:
                if cooperation_rate < 0.6:
                    return Action.C
                else:
                    return Action.D
            elif recent_cooperators == self.m - 1:
                return Action.C
            else:
                return Action.D
        else:
            if recent_cooperators < self.m - 2:
                return Action.C
            reliable_cooperators = 0
            if len(history.opponent_actions) >= 3:
                for player in range(self.n - 1):
                    player_cooperation_rate = sum(history.opponent_actions[:, player]) / len(history.opponent_actions)
                    if player_cooperation_rate > 0.7:
                        reliable_cooperators += 1
            if reliable_cooperators >= self.m:
                return Action.D
            if recent_cooperators == self.m - 1:
                return Action.D
            if len(history.my_actions) >= 3:
                recent_rounds_below_threshold = 0
                for i in range(min(3, len(history.my_actions))):
                    round_cooperators = sum(history.opponent_actions[-(i + 1), :])
                    if history.my_actions[-(i + 1)]:
                        round_cooperators += 1
                    if round_cooperators < self.m:
                        recent_rounds_below_threshold += 1
                if recent_rounds_below_threshold >= 3:
                    return Action.C
            if cooperation_rate > 0.75:
                return Action.D
            return Action.D

class Strategy_AGGRESSIVE_68(BaseStrategy):
    """
    Aggressive Opportunistic Strategy: "The Predator"
    
    Maximizes personal payoffs by aggressively exploiting cooperative players while 
    minimizing personal risk. Always defects in first and final rounds, and uses 
    threshold exploitation with harvest mode and punishment protocols in between.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.harvest_mode_rounds = 0
        self.harvest_mode_active = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == r:
            return Action.D
        prev_cooperators = int(history.my_actions[-1]) + sum(history.opponent_actions[-1, :])
        self._update_harvest_mode(history)
        if self.harvest_mode_active:
            return Action.D
        if prev_cooperators >= m:
            return Action.D
        elif prev_cooperators == m - 1:
            return Action.C
        else:
            if self._is_declining_cooperation(history):
                return Action.D
            if self._can_exploit_altruists(history):
                if prev_cooperators == m - 1:
                    return Action.C
                else:
                    return Action.D
            return Action.D

    def _update_harvest_mode(self, history: PlayerHistory):
        """Update harvest mode status based on opponent cooperation rates."""
        if len(history.my_actions) < 3:
            return
        recent_rounds = min(3, len(history.my_actions))
        cooperative_players = 0
        for player_idx in range(self.game_description.n_players - 1):
            recent_actions = history.opponent_actions[-recent_rounds:, player_idx]
            cooperation_rate = np.mean(recent_actions)
            if cooperation_rate > 0.5:
                cooperative_players += 1
        threshold = 0.6 * (self.game_description.n_players - 1)
        if cooperative_players >= threshold and (not self.harvest_mode_active):
            self.harvest_mode_active = True
            self.harvest_mode_rounds = 2
        elif self.harvest_mode_active:
            self.harvest_mode_rounds -= 1
            if self.harvest_mode_rounds <= 0:
                self.harvest_mode_active = False

    def _is_declining_cooperation(self, history: PlayerHistory) -> bool:
        """Check if cooperation is declining compared to previous round."""
        if len(history.my_actions) < 2:
            return False
        current_cooperators = int(history.my_actions[-1]) + sum(history.opponent_actions[-1, :])
        prev_cooperators = int(history.my_actions[-2]) + sum(history.opponent_actions[-2, :])
        return current_cooperators < prev_cooperators - 1

    def _can_exploit_altruists(self, history: PlayerHistory) -> bool:
        """Check if there are altruistic players to exploit."""
        if len(history.my_actions) < 3:
            return False
        for player_idx in range(self.game_description.n_players - 1):
            player_actions = history.opponent_actions[:, player_idx]
            cooperation_rate = np.mean(player_actions)
            if cooperation_rate >= 0.8:
                return True
        return False

class Strategy_AGGRESSIVE_69(BaseStrategy):
    """
    Aggressive Threshold Exploitation Strategy (ATES)
    
    Operates on ruthless opportunism: exploit others' cooperation while minimizing personal risk.
    Uses dynamic threshold system that becomes increasingly aggressive as game progresses.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        phase1_end = self.r // 3
        phase2_end = 2 * self.r // 3
        if current_round < phase1_end:
            return self._phase1_decision(history)
        elif current_round < phase2_end:
            return self._phase2_decision(history)
        else:
            return self._phase3_decision(history, current_round)

    def _estimate_cooperators_from_history(self, history):
        """Estimate how many will cooperate this round based on recent trends"""
        if len(history.my_actions) == 0:
            return 0
        lookback = min(3, len(history.my_actions))
        recent_cooperation_rates = []
        for i in range(self.n - 1):
            recent_actions = history.opponent_actions[-lookback:, i]
            coop_rate = np.mean(recent_actions)
            recent_cooperation_rates.append(coop_rate)
        predicted_cooperators = 0
        for rate in recent_cooperation_rates:
            if rate > 0.5:
                predicted_cooperators += 1
        return predicted_cooperators

    def _phase1_decision(self, history):
        """Initial Aggression phase"""
        predicted_cooperators = self._estimate_cooperators_from_history(history)
        if predicted_cooperators >= self.m:
            return Action.D
        elif predicted_cooperators == self.m - 1:
            overall_coop_trend = self._get_cooperation_trend(history, 3)
            if overall_coop_trend > 0.7:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _phase2_decision(self, history):
        """Selective Exploitation phase"""
        cooperation_trend = self._analyze_cooperation_trend(history)
        my_coop_rate = np.mean(history.my_actions)
        predicted_cooperators = self._estimate_cooperators_from_history(history)
        if cooperation_trend == 'increasing' and my_coop_rate < 0.3:
            if predicted_cooperators >= self.m + 1:
                return Action.D
            elif predicted_cooperators >= self.m:
                return Action.D
            else:
                return Action.C
        elif cooperation_trend == 'decreasing':
            return Action.D
        elif predicted_cooperators >= self.m:
            return Action.D
        else:
            return Action.C

    def _phase3_decision(self, history, current_round):
        """Endgame Aggression phase"""
        rounds_remaining = self.r - current_round
        predicted_cooperators = self._conservative_estimate_cooperators(history)
        if rounds_remaining <= 3:
            if predicted_cooperators > self.m:
                return Action.D
            elif predicted_cooperators == self.m:
                return Action.D
            elif rounds_remaining == 1 and predicted_cooperators == self.m - 1:
                return Action.C
            else:
                return Action.D
        else:
            base_decision = self._phase2_decision(history)
            if base_decision == Action.C and random.random() < 0.3:
                return Action.D
            return base_decision

    def _get_cooperation_trend(self, history, lookback):
        """Get overall cooperation trend from recent rounds"""
        if len(history.my_actions) == 0:
            return 0.5
        lookback = min(lookback, len(history.my_actions))
        if lookback == 0:
            return 0.5
        recent_rounds = history.opponent_actions[-lookback:, :]
        cooperation_rates = np.mean(recent_rounds, axis=1)
        return np.mean(cooperation_rates)

    def _analyze_cooperation_trend(self, history):
        """Analyze if cooperation is increasing, decreasing, or stable"""
        if len(history.my_actions) < 3:
            return 'stable'
        lookback = min(5, len(history.my_actions))
        recent_rates = []
        for i in range(lookback):
            round_idx = len(history.my_actions) - lookback + i
            round_coop_rate = np.mean(history.opponent_actions[round_idx, :])
            recent_rates.append(round_coop_rate)
        early_avg = np.mean(recent_rates[:len(recent_rates) // 2])
        late_avg = np.mean(recent_rates[len(recent_rates) // 2:])
        if late_avg > early_avg + 0.1:
            return 'increasing'
        elif late_avg < early_avg - 0.1:
            return 'decreasing'
        else:
            return 'stable'

    def _conservative_estimate_cooperators(self, history):
        """Conservative estimate for endgame - assume lower cooperation"""
        base_estimate = self._estimate_cooperators_from_history(history)
        return max(0, base_estimate - 1)

class Strategy_AGGRESSIVE_70(BaseStrategy):
    """
    Aggressive Threshold Exploitation Strategy (ATES) - A smart free-rider that maximizes
    individual payoffs by exploiting cooperation opportunities while minimizing personal risk.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.failure_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number + 1
        if current_round == self.r:
            return Action.D
        last_round_idx = history.round_number - 1
        coop_count = int(sum(history.opponent_actions[last_round_idx, :]))
        total_cooperators = coop_count + (1 if history.my_actions[last_round_idx] else 0)
        if total_cooperators < self.m:
            self.failure_streak += 1
        else:
            self.failure_streak = 0
        if coop_count >= self.m:
            return Action.D
        elif coop_count == self.m - 1:
            return Action.C
        else:
            return self._exploitation_logic(coop_count, current_round)

    def _exploitation_logic(self, coop_count: int, current_round: int) -> Action:
        if self.failure_streak >= 3:
            if self.failure_streak <= 4:
                return Action.C
            return Action.D
        if coop_count <= self.m / 2:
            return Action.D
        if self.m / 2 < coop_count < self.m - 1:
            base_aggression = 1.3 - self.m / self.n
            endgame_multiplier = (self.r - current_round + 1) / self.r
            aggressive_factor = 1.2 - current_round / self.r
            aggression_level = base_aggression * (1 + self.failure_streak * 0.1) * endgame_multiplier
            cooperation_probability = min(0.8, coop_count / (self.m - 1) * aggressive_factor)
            if self.m >= 0.8 * self.n:
                cooperation_probability *= 1.2
            if self.m <= 0.3 * self.n:
                cooperation_probability *= 0.6
            cooperation_probability /= aggression_level
            cooperation_probability = max(0.1, min(0.9, cooperation_probability))
            return Action.C if random.random() < cooperation_probability else Action.D
        return Action.D

class Strategy_AGGRESSIVE_71(BaseStrategy):
    """
    Threshold Predator: An aggressive exploitation strategy that maximizes personal payoffs
    by free-riding on others' cooperation while only cooperating when absolutely critical
    for securing the collective reward.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        prev_cooperators = int(sum(history.opponent_actions[-1, :]))
        if prev_cooperators >= self.m:
            return Action.D
        if prev_cooperators == self.m - 1:
            if self._estimate_future_cooperators(history) >= self.m - 1:
                return Action.C
            else:
                return Action.D
        if self._detect_cooperation_momentum(history):
            return Action.D
        if current_round >= 0.8 * self.r:
            if prev_cooperators == self.m - 1 and self._others_might_cooperate(history):
                return Action.C
        return Action.D

    def _estimate_future_cooperators(self, history: PlayerHistory) -> int:
        """Estimate how many opponents will cooperate based on recent behavior."""
        if history.round_number < 3:
            cooperation_rates = np.mean(history.opponent_actions, axis=0)
        else:
            recent_actions = history.opponent_actions[-3:, :]
            cooperation_rates = np.mean(recent_actions, axis=0)
        expected_cooperators = sum((1 for rate in cooperation_rates if rate > 0.5))
        return expected_cooperators

    def _detect_cooperation_momentum(self, history: PlayerHistory) -> bool:
        """Check if cooperation has been consistently at or above threshold for last 3 rounds."""
        if history.round_number < 3:
            return False
        recent_rounds = min(3, history.round_number)
        recent_cooperator_counts = []
        for i in range(recent_rounds):
            round_idx = -(i + 1)
            cooperators = sum(history.opponent_actions[round_idx, :])
            recent_cooperator_counts.append(cooperators)
        return all((count >= self.m for count in recent_cooperator_counts))

    def _others_might_cooperate(self, history: PlayerHistory) -> bool:
        """Check if there's evidence others might cooperate in desperate situations."""
        if history.round_number < 2:
            return True
        recent_rounds = min(3, history.round_number)
        total_cooperation_attempts = 0
        for i in range(recent_rounds):
            round_idx = -(i + 1)
            total_cooperation_attempts += sum(history.opponent_actions[round_idx, :])
        avg_cooperation = total_cooperation_attempts / (recent_rounds * (self.n - 1))
        return avg_cooperation > 0.3

class Strategy_AGGRESSIVE_72(BaseStrategy):
    """
    Aggressive Threshold Exploitation Strategy (ATES)
    
    Maximizes personal gain by exploiting others' cooperative tendencies while 
    minimizing own contributions. Uses three phases: reconnaissance, calculated 
    exploitation, and endgame aggression.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.phase1_end = max(1, math.floor(0.2 * self.n_rounds))
        self.phase2_end = max(2, math.floor(0.8 * self.n_rounds))
        self.cooperation_insurance_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        round_num = history.round_number
        if round_num < self.phase1_end:
            return self._phase1_strategy(history)
        elif round_num >= self.phase2_end:
            return self._phase3_strategy(history)
        else:
            return self._phase2_strategy(history)

    def _phase1_strategy(self, history: PlayerHistory) -> Action:
        """Reconnaissance phase - map opponent patterns while minimizing contributions"""
        round_num = history.round_number
        if round_num > 0:
            last_cooperators = sum(history.opponent_actions[-1, :])
            my_last_action = history.my_actions[-1]
            if last_cooperators < self.m and (not my_last_action):
                if last_cooperators + 1 >= self.m:
                    return Action.C
        return Action.D

    def _phase2_strategy(self, history: PlayerHistory) -> Action:
        """Calculated exploitation phase - free ride while occasionally paying insurance"""
        round_num = history.round_number
        if round_num > 0:
            last_cooperators = sum(history.opponent_actions[-1, :])
            my_last_action = history.my_actions[-1]
            if last_cooperators < self.m and (not my_last_action):
                if last_cooperators + 1 >= self.m:
                    return Action.C
        cooperation_rates = np.mean(history.opponent_actions, axis=0)
        high_cooperators = sum(cooperation_rates > 0.7)
        if high_cooperators >= self.m - 1:
            return Action.D
        committed_cooperators = sum(cooperation_rates > 0.7)
        low_cooperators = sum(cooperation_rates < 0.3)
        if committed_cooperators == self.m - 1 and low_cooperators >= self.n_players - 1 - committed_cooperators:
            return Action.C
        my_defection_rate = 1 - np.mean(history.my_actions)
        threshold_failures = self._count_threshold_failures(history)
        failure_rate = threshold_failures / round_num
        if my_defection_rate > 0.9 and failure_rate > 0.3:
            self.cooperation_insurance_counter += 1
            if self.cooperation_insurance_counter % 5 == 0:
                return Action.C
        return Action.D

    def _phase3_strategy(self, history: PlayerHistory) -> Action:
        """Endgame aggression - maximum extraction with minimal reciprocity"""
        round_num = history.round_number
        if round_num == self.n_rounds - 1:
            return Action.D
        threshold_successes = self._count_threshold_successes(history)
        success_rate = threshold_successes / round_num
        if success_rate > 0.8:
            return Action.D
        if 0.5 <= success_rate <= 0.8:
            recent_rounds = min(5, round_num)
            recent_failures = 0
            for i in range(recent_rounds):
                round_idx = round_num - 1 - i
                cooperators = sum(history.opponent_actions[round_idx, :])
                if history.my_actions[round_idx]:
                    cooperators += 1
                if cooperators < self.m:
                    recent_failures += 1
            if recent_failures > 0:
                return Action.C
        return Action.D

    def _count_threshold_failures(self, history: PlayerHistory) -> int:
        """Count rounds where threshold was not met"""
        failures = 0
        for round_idx in range(history.round_number):
            cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators < self.m:
                failures += 1
        return failures

    def _count_threshold_successes(self, history: PlayerHistory) -> int:
        """Count rounds where threshold was met"""
        return history.round_number - self._count_threshold_failures(history)

class Strategy_AGGRESSIVE_73(BaseStrategy):
    """
    Aggressive Threshold Punisher - Calculated Predator Strategy
    
    Maximally exploits others while minimizing personal risk through:
    - Always defecting first round for reconnaissance
    - Strategic cooperation only when pivotal for threshold
    - Aggressive free-riding on others' cooperation
    - Endgame exploitation with final round defection
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        round_num = history.round_number
        rounds_remaining = self.r - round_num - 1
        c_prev = int(np.sum(history.opponent_actions[-1, :]))
        cooperation_rate = c_prev / self.n
        if rounds_remaining <= 1:
            if rounds_remaining == 0:
                return Action.D
            historical_threshold_met_rate = self._calculate_threshold_met_rate(history)
            if historical_threshold_met_rate >= 0.4:
                if c_prev >= self.m - 1:
                    return Action.C if c_prev == self.m - 1 else Action.D
                else:
                    return Action.C if c_prev == self.m - 2 else Action.D
            else:
                return Action.D
        if cooperation_rate >= (self.m - 1) / self.n:
            if c_prev == self.m - 1:
                return Action.C
            else:
                return Action.D
        elif cooperation_rate >= 0.6 and rounds_remaining >= 3:
            return Action.C
        else:
            return Action.D
        return self._apply_adaptive_mechanisms(history, c_prev, rounds_remaining)

    def _calculate_threshold_met_rate(self, history: PlayerHistory) -> float:
        """Calculate the rate at which the cooperation threshold was met historically."""
        if history.round_number == 0:
            return 0.0
        threshold_met_count = 0
        for round_idx in range(history.round_number):
            cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators >= self.m:
                threshold_met_count += 1
        return threshold_met_count / history.round_number

    def _apply_adaptive_mechanisms(self, history: PlayerHistory, c_prev: int, rounds_remaining: int) -> Action:
        """Apply momentum tracking and risk-adjusted calculations."""
        if history.round_number >= 3:
            recent_cooperators = []
            for i in range(min(3, history.round_number)):
                round_idx = history.round_number - 1 - i
                cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
                recent_cooperators.append(cooperators)
            momentum = recent_cooperators[0] - recent_cooperators[-1]
            if momentum > 1 and c_prev >= self.m - 2:
                if random.random() < 0.2:
                    return Action.C
            elif momentum < -1:
                return Action.D
        if self.n <= 4:
            if rounds_remaining >= 3 and c_prev >= self.m - 2:
                if random.random() < 0.3:
                    return Action.C
        if self.m / self.n > 0.6:
            if c_prev >= self.m - 2 and rounds_remaining > 2:
                return Action.C
        if self.k < 1.5:
            effective_threshold = max(1, int(self.m * 0.8))
            if c_prev < effective_threshold - 1:
                return Action.D
        if history.round_number >= 5:
            recent_cooperators = []
            for i in range(min(5, history.round_number)):
                round_idx = history.round_number - 1 - i
                cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
                recent_cooperators.append(cooperators)
            volatility = np.std(recent_cooperators) if len(recent_cooperators) > 1 else 0
            effective_threshold = self.m + int(volatility)
            if c_prev >= effective_threshold - 1:
                return Action.C
        return Action.C if c_prev == self.m - 1 else Action.D

class Strategy_AGGRESSIVE_74(BaseStrategy):
    """
    Aggressive Threshold Exploitation Strategy (ATES)
    
    This strategy aggressively maximizes personal payoff by exploiting the collective risk structure.
    It aims to free-ride whenever possible while strategically cooperating only when absolutely 
    necessary to secure the threshold bonus.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number + 1
        reliable_cooperators = self._identify_reliable_cooperators(history)
        if current_round > 0.8 * self.r:
            return self._endgame_strategy(history, reliable_cooperators)
        predicted_cooperators = self._estimate_cooperators_this_round(history)
        gap = max(0, self.m - predicted_cooperators)
        if gap == 0:
            return Action.D
        elif gap == 1:
            exploit_probability = 1.0 / (self.k + 0.5)
            if random.random() > exploit_probability:
                return Action.C
            else:
                return Action.D
        else:
            return Action.C

    def _identify_reliable_cooperators(self, history: PlayerHistory) -> int:
        """Count opponents who cooperate >70% of the time"""
        if history.round_number == 0:
            return 0
        cooperation_rates = np.mean(history.opponent_actions, axis=0)
        return np.sum(cooperation_rates > 0.7)

    def _estimate_cooperators_this_round(self, history: PlayerHistory) -> int:
        """Estimate how many opponents will cooperate this round"""
        if history.round_number == 0:
            return np.sum(history.opponent_actions[0, :])
        recent_rounds = min(3, history.round_number)
        recent_cooperation = np.mean(history.opponent_actions[-recent_rounds:, :], axis=0)
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        if last_round_cooperators + int(history.my_actions[-1]) < self.m:
            recent_cooperation = np.minimum(recent_cooperation + 0.2, 1.0)
        expected_cooperators = np.sum(recent_cooperation > 0.5)
        return expected_cooperators

    def _endgame_strategy(self, history: PlayerHistory, reliable_cooperators: int) -> Action:
        """Aggressive endgame strategy for final rounds"""
        current_round = history.round_number + 1
        if current_round == self.r:
            predicted_cooperators = self._estimate_cooperators_this_round(history)
            if predicted_cooperators == self.m - 1 and self.k > 2:
                return Action.C
            else:
                return Action.D
        if current_round > self.r - 3:
            predicted_cooperators = self._estimate_cooperators_this_round(history)
            cooperation_threshold = max(0, self.m - predicted_cooperators)
            if cooperation_threshold <= 0:
                return Action.D
            elif cooperation_threshold == 1 and self.k > 2:
                return Action.C
            else:
                return Action.D
        predicted_cooperators = self._estimate_cooperators_this_round(history)
        gap = max(0, self.m - predicted_cooperators)
        if gap == 0:
            return Action.D
        elif gap == 1:
            exploit_probability = 1.0 / (self.k + 0.3)
            return Action.C if random.random() > exploit_probability else Action.D
        else:
            return Action.C

class Strategy_AGGRESSIVE_75(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Threshold Predator"
    
    This strategy operates on aggressive opportunism - it aims to maximize personal payoffs 
    by exploiting cooperative players while minimizing its own contributions. The key insight 
    is that in collective risk dilemmas, the most profitable position is being a free-rider 
    when others cooperate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        round_num = state.round_number
        my_last_action = history.my_actions[-1]
        opponent_cooperators = np.sum(history.opponent_actions[-1, :])
        total_cooperators = int(opponent_cooperators) + int(my_last_action)
        if round_num == self.r:
            if len(history.my_actions) > 0:
                avg_coop_rate = 0
                for i in range(len(history.my_actions)):
                    round_cooperators = int(history.my_actions[i]) + np.sum(history.opponent_actions[i, :])
                    if round_cooperators >= self.m:
                        avg_coop_rate += 1
                avg_coop_rate /= len(history.my_actions)
                if avg_coop_rate > 0.5:
                    return Action.D
            return self._main_strategy(history, total_cooperators)
        return self._main_strategy(history, total_cooperators)

    def _main_strategy(self, history: PlayerHistory, coop_count: int) -> Action:
        if coop_count >= self.m:
            return Action.D
        elif coop_count == self.m - 1:
            exploitable_players = self._count_exploitable_opponents(history)
            if exploitable_players >= self.m - 1:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _count_exploitable_opponents(self, history: PlayerHistory) -> int:
        """Count opponents who have cooperated >66% in last 3 rounds"""
        if len(history.my_actions) < 3:
            return 0
        exploitable = 0
        recent_rounds = min(3, len(history.my_actions))
        for opponent_idx in range(history.opponent_actions.shape[1]):
            recent_actions = history.opponent_actions[-recent_rounds:, opponent_idx]
            coop_rate = np.mean(recent_actions)
            if coop_rate > 0.66:
                exploitable += 1
        return exploitable

class Strategy_AGGRESSIVE_76(BaseStrategy):
    """
    Threshold Predator Strategy - An aggressive exploitation strategy that free-rides on 
    cooperative players while strategically cooperating only when necessary to secure 
    collective rewards. Always defects in first and final rounds, and uses threshold 
    analysis to minimize personal cost while maximizing payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number + 1
        if current_round == self.r:
            return Action.D
        prev_round_coops = int(sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            prev_round_coops += 1
        if prev_round_coops >= self.m:
            return Action.D
        elif prev_round_coops == self.m - 1:
            return Action.C
        else:
            if len(history.my_actions) >= 3:
                coop_counts = []
                for i in range(-3, 0):
                    round_coops = int(sum(history.opponent_actions[i, :]))
                    if history.my_actions[i]:
                        round_coops += 1
                    coop_counts.append(round_coops)
                is_trending_up = coop_counts[-1] > coop_counts[0]
                if is_trending_up and prev_round_coops >= self.m - 2:
                    return Action.C
            if len(history.my_actions) >= 3:
                reliable_cooperators = 0
                for player_idx in range(self.n - 1):
                    coop_rate = np.mean(history.opponent_actions[:, player_idx])
                    if coop_rate >= 0.7:
                        reliable_cooperators += 1
                if reliable_cooperators >= 2 and prev_round_coops >= self.m - 2:
                    return Action.C
            if self.n <= 4 and prev_round_coops == self.m - 2:
                return Action.C
            if self.m > self.n / 2 and current_round <= self.r / 3:
                if prev_round_coops >= self.m - 2:
                    return Action.C
            if self.k < 1.5:
                return Action.D
            return Action.D

class Strategy_AGGRESSIVE_77(BaseStrategy):
    """
    Aggressive Adaptive Threshold Strategy (AATS)
    
    Operates on calculated aggression: exploit cooperation when profitable,
    but never be the sucker. Maximizes personal payoff while maintaining
    just enough cooperation to capture collective rewards when advantageous.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            if self.k <= 1.5:
                return Action.D
            elif self.k > 1.5 and self.m / self.n <= 0.6:
                return Action.C
            else:
                return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        n_opponents = self.n - 1
        coop_rates = np.zeros(n_opponents)
        recent_coop = np.zeros(n_opponents, dtype=bool)
        for j in range(n_opponents):
            total_rounds = len(history.opponent_actions)
            if total_rounds > 0:
                coop_rates[j] = np.mean(history.opponent_actions[:, j])
                recent_coop[j] = history.opponent_actions[-1, j]
        predicted_cooperators = np.sum(coop_rates)
        cooperation_momentum = np.sum(recent_coop)
        if predicted_cooperators + cooperation_momentum / 2 >= self.m - 1:
            return Action.D
        elif predicted_cooperators >= self.m - 2 and self.k > 2.0:
            return Action.C
        elif current_round > self.r / 2 and predicted_cooperators < self.m - 3:
            return Action.D
        else:
            return Action.D

class Strategy_AGGRESSIVE_78(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Threshold Predator"
    
    Operates on aggressive free-riding with calculated cooperation. Maximizes personal payoff
    by exploiting others' cooperative tendencies while minimizing personal contributions.
    Cooperates only when absolutely necessary to secure collective benefit.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.cooperation_count = 0
        self.punishment_rounds_left = 0
        self.emergency_mode = False
        self.phase1_end = max(1, self.r // 3)
        self.phase2_end = max(2, 2 * self.r // 3)
        self.strategic_coop_round = self.phase2_end + max(1, self.r // 6)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number + 1
        if current_round == self.r:
            return Action.D
        if self.punishment_rounds_left > 0:
            self.punishment_rounds_left -= 1
            return Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        threshold_met_last = last_round_cooperators + int(history.my_actions[-1]) >= self.m
        rounds_completed = history.round_number
        if rounds_completed >= 3:
            threshold_failures = 0
            for i in range(rounds_completed):
                round_cooperators = sum(history.opponent_actions[i, :]) + int(history.my_actions[i])
                if round_cooperators < self.m:
                    threshold_failures += 1
            failure_rate = threshold_failures / rounds_completed
            self.emergency_mode = failure_rate > 0.3
        if current_round <= self.phase1_end:
            if not threshold_met_last and rounds_completed > 0:
                return Action.C
            return Action.D
        elif current_round <= self.phase2_end:
            if self.emergency_mode:
                return Action.C if current_round % 2 == 0 else Action.D
            if not threshold_met_last:
                estimated_cooperators = self._estimate_cooperators(history)
                if estimated_cooperators >= self.m - 1:
                    return Action.C
            if history.round_number >= 2 and history.my_actions[-1] == True and (sum(history.opponent_actions[-1, :]) < self.n * 0.5):
                self.punishment_rounds_left = 2
                return Action.D
            return Action.D
        else:
            if self.emergency_mode and (not threshold_met_last):
                return Action.C
            if current_round == self.strategic_coop_round and self.strategic_coop_round < self.r:
                return Action.C
            if rounds_completed >= 2 and (not threshold_met_last):
                if rounds_completed >= 2:
                    prev_round_cooperators = sum(history.opponent_actions[-2, :]) + int(history.my_actions[-2])
                    if prev_round_cooperators < self.m:
                        return Action.C
            return Action.D

    def _estimate_cooperators(self, history):
        """Estimate number of reliable cooperators based on recent behavior"""
        if history.round_number < 2:
            return self.n // 2
        cooperator_count = 0
        recent_rounds = min(3, history.round_number)
        for player in range(self.n - 1):
            player_cooperations = sum(history.opponent_actions[-recent_rounds:, player])
            cooperation_rate = player_cooperations / recent_rounds
            if cooperation_rate > 0.6:
                cooperator_count += 1
        return cooperator_count

class Strategy_AGGRESSIVE_79(BaseStrategy):
    """
    Aggressive Predator Strategy: Maximally exploitative approach that free-rides whenever possible
    while maintaining just enough strategic cooperation to avoid collective collapse.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        m = self.game_description.m
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == r - 1:
            return Action.D
        last_round_opponents = history.opponent_actions[-1, :]
        last_cooperators = sum(last_round_opponents)
        my_last_action = history.my_actions[-1]
        if last_cooperators >= m and (not my_last_action):
            return Action.D
        if last_cooperators >= m + 2:
            return Action.D
        elif last_cooperators == m + 1:
            return Action.D
        elif last_cooperators == m:
            return Action.C
        else:
            return Action.C

class Strategy_AGGRESSIVE_80(BaseStrategy):
    """
    Predator Strategy: Aggressively exploits cooperative behavior while minimizing personal risk.
    Defects whenever possible, only cooperating when absolutely necessary to maintain the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        if current_round == self.r - 1:
            return Action.D
        predicted_cooperators = self._predict_cooperators(history)
        if current_round == self.r - 2:
            if predicted_cooperators == self.m - 1 and self._others_expect_cooperation(history):
                return Action.C
            return Action.D
        if predicted_cooperators >= self.m:
            if current_round % 5 == 0 and random.random() < 0.1:
                return Action.C
            return Action.D
        adjusted_threshold = self.m
        if self.m > 0.8 * self.n:
            adjusted_threshold = self.m + 1
        if self.k > 3:
            adjusted_threshold = self.m + 0.5
        if predicted_cooperators < adjusted_threshold:
            if self._sustained_failure(history):
                return Action.C
            return Action.C
        return Action.D

    def _predict_cooperators(self, history: PlayerHistory) -> int:
        """Predict number of cooperators based on opponent patterns."""
        predicted_cooperators = 0
        for opponent_idx in range(self.n - 1):
            coop_rate = self._calculate_cooperation_rate(history, opponent_idx)
            if coop_rate > 0.6:
                predicted_cooperators += 1
        return predicted_cooperators

    def _calculate_cooperation_rate(self, history: PlayerHistory, opponent_idx: int) -> float:
        """Calculate weighted cooperation rate with recent bias."""
        total_rounds = history.round_number
        if total_rounds == 0:
            return 0.5
        opponent_actions = history.opponent_actions[:, opponent_idx]
        recent_rounds = min(3, total_rounds)
        recent_coops = sum(opponent_actions[-recent_rounds:])
        earlier_rounds = total_rounds - recent_rounds
        if earlier_rounds > 0:
            earlier_coops = sum(opponent_actions[:-recent_rounds])
        else:
            earlier_coops = 0
        total_weighted_coops = 2 * recent_coops + earlier_coops
        total_weighted_rounds = 2 * recent_rounds + earlier_rounds
        if total_weighted_rounds == 0:
            return 0.5
        return total_weighted_coops / total_weighted_rounds

    def _others_expect_cooperation(self, history: PlayerHistory) -> bool:
        """Check if others might expect us to cooperate based on our history."""
        if history.round_number < 3:
            return False
        my_recent_coops = sum(history.my_actions[-3:])
        return my_recent_coops >= 1

    def _sustained_failure(self, history: PlayerHistory) -> bool:
        """Check if threshold failed multiple consecutive rounds recently."""
        if history.round_number < 3:
            return False
        failures = 0
        for i in range(max(0, history.round_number - 3), history.round_number):
            round_cooperators = sum(history.opponent_actions[i, :])
            if history.my_actions[i]:
                round_cooperators += 1
            if round_cooperators < self.m:
                failures += 1
        return failures >= 2

class Strategy_AGGRESSIVE_81(BaseStrategy):
    """
    Aggressive Exploitative Strategy: "Threshold Hawk"
    
    This strategy aggressively exploits cooperative players while minimizing personal risk.
    It aims to be among the defectors who benefit from others' cooperation without contributing,
    while strategically cooperating only when absolutely necessary to prevent total collapse.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_low_cooperation_rounds = 0
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.consecutive_low_cooperation_rounds = 0
            self.cooperation_history = []
            return Action.D
        current_round = history.round_number + 1
        n_rounds = self.game_description.n_rounds
        m = self.game_description.m
        if current_round == n_rounds:
            return Action.D
        prev_cooperation_count = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            prev_cooperation_count += 1
        self.cooperation_history.append(prev_cooperation_count)
        if prev_cooperation_count < m:
            self.consecutive_low_cooperation_rounds += 1
        else:
            self.consecutive_low_cooperation_rounds = 0
        if len(history.my_actions) >= 2:
            two_rounds_ago_cooperation = sum(history.opponent_actions[-2, :])
            if history.my_actions[-2]:
                two_rounds_ago_cooperation += 1
            if not history.my_actions[-1] and two_rounds_ago_cooperation >= m and (prev_cooperation_count < m) and (prev_cooperation_count <= two_rounds_ago_cooperation - 2):
                return Action.C
        if prev_cooperation_count >= m + 1:
            return Action.D
        elif prev_cooperation_count == m:
            return Action.D
        elif prev_cooperation_count == m - 1:
            return Action.C
        elif self.consecutive_low_cooperation_rounds >= 2:
            return Action.C
        else:
            return Action.D
        if current_round >= n_rounds - 2:
            recent_rounds = min(5, len(self.cooperation_history))
            if recent_rounds > 0:
                recent_avg = sum(self.cooperation_history[-recent_rounds:]) / recent_rounds
                if recent_avg >= m + 1:
                    return Action.D
        if len(self.cooperation_history) >= 3:
            avg_cooperation = sum(self.cooperation_history) / len(self.cooperation_history)
            if len(history.my_actions) >= 3:
                my_recent_actions = history.my_actions[-3:]
                opponent_recent_actions = history.opponent_actions[-2:, :]
                if len(opponent_recent_actions) >= 2:
                    if random.random() < 0.1:
                        return Action.C if random.random() < 0.5 else Action.D
            if avg_cooperation >= m + 1:
                if prev_cooperation_count >= m:
                    return Action.D
            elif avg_cooperation <= m:
                if prev_cooperation_count == m - 1:
                    return Action.C
        if prev_cooperation_count >= m:
            return Action.D
        else:
            return Action.C

class Strategy_AGGRESSIVE_82(BaseStrategy):
    """
    Aggressive Threshold Exploitation Strategy (ATES)
    
    Operates on ruthless opportunism: exploit cooperative players while minimizing personal risk.
    Defects in first round, then uses dynamic exploitation based on cooperation threshold tracking,
    opponent profiling, and endgame acceleration.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.opponent_cooperation_rates = np.zeros(self.n - 1)
        self.reliable_cooperators = 0
        self.always_defect = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        if current_round == self.r - 1:
            return Action.D
        self._update_opponent_analysis(history)
        if self.r - current_round <= 2:
            personal_avg_payoff = np.mean(history.my_payoffs)
            if personal_avg_payoff >= 1.2:
                return Action.D
        last_round_cooperators = np.sum(history.opponent_actions[-1, :]) + int(history.my_actions[-1])
        cooperation_rate = last_round_cooperators / self.n
        predicted_cooperators = cooperation_rate * self.n
        if predicted_cooperators >= self.m:
            return Action.D
        if predicted_cooperators < self.m - 1:
            return Action.D
        if current_round >= 3:
            recent_cooperation = []
            for i in range(min(3, current_round)):
                round_idx = current_round - 1 - i
                round_cooperators = np.sum(history.opponent_actions[round_idx, :]) + int(history.my_actions[round_idx])
                recent_cooperation.append(round_cooperators)
            if len(recent_cooperation) >= 2:
                increasing_trend = all((recent_cooperation[i] >= recent_cooperation[i + 1] for i in range(len(recent_cooperation) - 1)))
                if increasing_trend:
                    return Action.D
        if current_round >= 2:
            high_cooperators = np.sum(self.opponent_cooperation_rates > 0.7)
            if high_cooperators >= 2:
                return Action.D
        if self.r - current_round <= 3:
            return Action.D
        if current_round > 0:
            current_avg_payoff = np.mean(history.my_payoffs)
            if current_avg_payoff > 1.5:
                return Action.D
        if current_round > 2 and self.reliable_cooperators >= self.m:
            return Action.D
        return Action.C

    def _update_opponent_analysis(self, history):
        """Update opponent cooperation rates and classify reliable cooperators."""
        current_round = history.round_number
        for i in range(self.n - 1):
            opponent_actions = history.opponent_actions[:current_round, i]
            self.opponent_cooperation_rates[i] = np.mean(opponent_actions)
        if current_round >= 3:
            self.reliable_cooperators = np.sum(self.opponent_cooperation_rates > 0.7)
            if self.reliable_cooperators >= self.m:
                self.always_defect = True

class Strategy_AGGRESSIVE_83(BaseStrategy):
    """
    Aggressive Adaptive Exploitation Strategy for Collective Risk Dilemma.
    
    Operates on aggressive opportunism: exploit cooperative opponents while minimizing 
    personal risk. Always defects in first round and last 2 rounds. Cooperates only 
    when threshold is likely met without our contribution, allowing maximum exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.punishment_rounds_left = 0
        self.unreliable_players = set()

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        if current_round >= self.r - 2:
            return Action.D
        if self.punishment_rounds_left > 0:
            self.punishment_rounds_left -= 1
            return Action.D
        if len(history.my_actions) > 0 and history.my_actions[-1]:
            last_round_cooperators = sum(history.opponent_actions[-1, :]) + 1
            if last_round_cooperators < self.m:
                self.punishment_rounds_left = 2
                self.unreliable_players.update(range(self.n - 1))
                return Action.D
        estimated_cooperators, probable_cooperators = self._classify_players(history)
        total_likely_cooperators = estimated_cooperators + probable_cooperators
        if total_likely_cooperators >= self.m - 1 and current_round <= self.r - 2:
            if self._is_cooperation_declining(history):
                return Action.D
            cooperation_threshold = self._get_cooperation_threshold()
            if total_likely_cooperators >= cooperation_threshold:
                return Action.C
        return Action.D

    def _classify_players(self, history):
        """Classify players based on their cooperation rates."""
        estimated_cooperators = 0
        probable_cooperators = 0
        n_rounds = len(history.my_actions)
        for player in range(self.n - 1):
            if player in self.unreliable_players:
                continue
            player_actions = history.opponent_actions[:, player]
            coop_rate = np.mean(player_actions)
            if coop_rate > 0.7:
                estimated_cooperators += 1
            elif coop_rate >= 0.5:
                recent_rounds = min(2, n_rounds)
                if recent_rounds > 0:
                    recent_actions = player_actions[-recent_rounds:]
                    if np.mean(recent_actions) >= 0.5:
                        probable_cooperators += 1
        return (estimated_cooperators, probable_cooperators)

    def _is_cooperation_declining(self, history):
        """Check if cooperation is on a declining trend."""
        n_rounds = len(history.my_actions)
        if n_rounds < 3:
            return False
        recent_window = min(2, n_rounds)
        prev_window = min(2, n_rounds - recent_window)
        if prev_window == 0:
            return False
        recent_coop = np.mean(history.opponent_actions[-recent_window:, :])
        prev_coop = np.mean(history.opponent_actions[-recent_window - prev_window:-recent_window, :])
        return recent_coop < prev_coop * 0.8

    def _get_cooperation_threshold(self):
        """Get cooperation threshold based on game parameters."""
        base_threshold = self.m - 1
        if self.m > self.n / 2:
            return base_threshold + 1
        if self.m <= self.n / 3:
            return max(0, base_threshold - 0.5)
        if self.k > 2.5:
            return max(0, base_threshold - 0.3)
        return base_threshold

class Strategy_AGGRESSIVE_84(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Threshold Predator"
    
    This strategy aggressively exploits cooperative players while minimizing personal risk.
    It aims to maximize payoff by contributing only when absolutely necessary to trigger
    the collective benefit, while defaulting to defection to capture free-rider advantages.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        if current_round == self.r - 1:
            return self._final_round_strategy(history)
        if current_round == self.r - 2:
            return self._penultimate_round_strategy(history)
        return self._threshold_predator_logic(history)

    def _final_round_strategy(self, history: PlayerHistory) -> Action:
        """Maximum exploitation in final round"""
        historical_success_rate = self._calculate_success_rate(history)
        typical_cooperators = self._count_typical_cooperators(history)
        decisive_contribution_rate = self._calculate_decisive_contribution_rate(history)
        if historical_success_rate > 0.8 and typical_cooperators >= self.m:
            return Action.D
        elif decisive_contribution_rate > 0.5:
            return Action.D
        else:
            return Action.D

    def _penultimate_round_strategy(self, history: PlayerHistory) -> Action:
        """Penultimate round aggression"""
        decisive_contribution_rate = self._calculate_decisive_contribution_rate(history)
        opponent_cooperation_consistency = self._calculate_opponent_consistency(history)
        if opponent_cooperation_consistency > 0.7:
            return Action.D
        elif decisive_contribution_rate > 0.7:
            return Action.C
        else:
            return Action.D

    def _threshold_predator_logic(self, history: PlayerHistory) -> Action:
        """Core threshold predator strategy for middle rounds"""
        if history.round_number == 0:
            return Action.D
        last_round_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        cooperation_rate = last_round_cooperators / (self.n - 1)
        historical_success_rate = self._calculate_success_rate(history)
        exploit_threshold = (self.m - 1) / (self.n - 1)
        decisive_threshold = (self.m - 2) / (self.n - 1)
        if cooperation_rate >= exploit_threshold:
            return Action.D
        elif cooperation_rate >= decisive_threshold and historical_success_rate > 0.6:
            return Action.C
        else:
            return Action.D

    def _calculate_success_rate(self, history: PlayerHistory) -> float:
        """Calculate historical success rate (rounds where threshold was met)"""
        if history.round_number == 0:
            return 0.0
        successful_rounds = 0
        total_rounds = history.round_number
        for round_idx in range(total_rounds):
            cooperators_in_round = int(np.sum(history.opponent_actions[round_idx, :]))
            if history.my_actions[round_idx]:
                cooperators_in_round += 1
            if cooperators_in_round >= self.m:
                successful_rounds += 1
        return successful_rounds / total_rounds if total_rounds > 0 else 0.0

    def _count_typical_cooperators(self, history: PlayerHistory) -> int:
        """Count players who typically cooperate (>70% rate)"""
        if history.round_number == 0:
            return 0
        reliable_cooperators = 0
        total_rounds = history.round_number
        for player_idx in range(self.n - 1):
            player_cooperations = np.sum(history.opponent_actions[:, player_idx])
            cooperation_rate = player_cooperations / total_rounds
            if cooperation_rate > 0.7:
                reliable_cooperators += 1
        return reliable_cooperators

    def _calculate_decisive_contribution_rate(self, history: PlayerHistory) -> float:
        """Calculate how often my cooperation was decisive for success"""
        if history.round_number == 0:
            return 0.0
        decisive_contributions = 0
        my_cooperations = 0
        for round_idx in range(history.round_number):
            if history.my_actions[round_idx]:
                my_cooperations += 1
                opponent_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
                total_cooperators = opponent_cooperators + 1
                if total_cooperators >= self.m and opponent_cooperators < self.m:
                    decisive_contributions += 1
        return decisive_contributions / my_cooperations if my_cooperations > 0 else 0.0

    def _calculate_opponent_consistency(self, history: PlayerHistory) -> float:
        """Calculate how consistently opponents cooperate"""
        if history.round_number == 0:
            return 0.0
        total_consistency = 0.0
        for player_idx in range(self.n - 1):
            player_actions = history.opponent_actions[:, player_idx]
            cooperation_rate = np.mean(player_actions)
            total_consistency += cooperation_rate
        return total_consistency / (self.n - 1)

class Strategy_AGGRESSIVE_85(BaseStrategy):
    """
    Threshold Hawk: An aggressive exploitation strategy that maximizes individual payoff
    by letting others bear the cooperation burden, only cooperating when statistically
    likely to be pivotal for securing the collective reward.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.opponent_coop_rates = np.zeros(self.n - 1)
        self.consecutive_failures = 0
        self.scorched_earth_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        self._update_opponent_stats(history)
        if self.scorched_earth_rounds > 0:
            self.scorched_earth_rounds -= 1
            return Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        total_last_round = last_round_cooperators + (1 if history.my_actions[-1] else 0)
        if total_last_round < self.m:
            self.consecutive_failures += 1
        else:
            self.consecutive_failures = 0
        if self.consecutive_failures >= 3:
            self.scorched_earth_rounds = 5
            self.consecutive_failures = 0
            return Action.D
        if total_last_round >= self.m + 2:
            return Action.D
        endgame_factor = max(0, (current_round - 0.8 * self.r) / (0.2 * self.r))
        if current_round > 0.8 * self.r:
            cooperation_threshold = 0.7 - endgame_factor * 0.4
        else:
            cooperation_threshold = 0.7
        if self.consecutive_failures >= 2:
            cooperation_threshold -= 0.15
        reliable_cooperators = sum((rate > 0.7 for rate in self.opponent_coop_rates))
        expected_other_cooperators = self._estimate_cooperators(history, reliable_cooperators)
        pivotal_prob = self._calculate_pivotal_probability(expected_other_cooperators)
        if self.m == self.n - 1:
            high_cooperators = sum((rate > 0.8 for rate in self.opponent_coop_rates))
            if high_cooperators == self.n - 1:
                return Action.C
            else:
                return Action.D
        if pivotal_prob > cooperation_threshold:
            return Action.C
        else:
            return Action.D

    def _update_opponent_stats(self, history: PlayerHistory):
        """Update cooperation rates for each opponent."""
        rounds_played = len(history.my_actions)
        for i in range(self.n - 1):
            total_coops = sum(history.opponent_actions[:, i])
            self.opponent_coop_rates[i] = total_coops / rounds_played

    def _estimate_cooperators(self, history: PlayerHistory, reliable_cooperators: int) -> float:
        """Estimate expected number of cooperating opponents in next round."""
        if len(history.my_actions) < 3:
            return np.mean([sum(history.opponent_actions[i, :]) for i in range(len(history.my_actions))])
        recent_rounds = min(5, len(history.my_actions))
        recent_cooperators = []
        for i in range(recent_rounds):
            round_idx = -(i + 1)
            recent_cooperators.append(sum(history.opponent_actions[round_idx, :]))
        weights = np.array([0.4, 0.25, 0.2, 0.1, 0.05][:recent_rounds])
        weighted_avg = np.average(recent_cooperators, weights=weights)
        adjustment = min(reliable_cooperators * 0.1, 0.3)
        return weighted_avg + adjustment

    def _calculate_pivotal_probability(self, expected_other_cooperators: float) -> float:
        """Calculate probability that this player's cooperation is pivotal."""
        if expected_other_cooperators >= self.m:
            return 0.0
        if expected_other_cooperators < self.m - 1:
            return 0.1
        distance_from_pivot = abs(expected_other_cooperators - (self.m - 1))
        base_prob = max(0.1, 0.9 - distance_from_pivot * 0.3)
        return min(base_prob, 0.9)

class Strategy_AGGRESSIVE_86(BaseStrategy):
    """
    Aggressive Opportunistic Strategy: "The Predator"
    
    Maximizes personal payoffs by exploiting cooperative opponents while minimizing personal risk.
    Only cooperates when absolutely necessary to secure collective rewards, then immediately
    returns to exploitation mode.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        round_num = state.round_number
        if round_num == self.r - 1:
            return Action.D
        prev_round_idx = history.round_number - 1
        coop_count = sum(history.opponent_actions[prev_round_idx, :])
        if history.my_actions[prev_round_idx]:
            coop_count += 1
        if coop_count >= self.m:
            return Action.D
        needed_cooperators = self.m - coop_count
        confirmed_defectors = 0
        reliable_cooperators = 0
        if history.round_number >= 2:
            for player in range(self.n - 1):
                recent_actions = history.opponent_actions[max(0, prev_round_idx - 1):prev_round_idx + 1, player]
                if len(recent_actions) >= 2 and all((action == False for action in recent_actions)):
                    confirmed_defectors += 1
                elif len(recent_actions) >= 2 and all((action == True for action in recent_actions)):
                    reliable_cooperators += 1
        remaining_uncertain_players = self.n - 1 - confirmed_defectors - reliable_cooperators
        if self.n <= 4:
            cooperation_threshold = max(1, needed_cooperators - 1)
            if remaining_uncertain_players + reliable_cooperators >= cooperation_threshold:
                return Action.C
            else:
                return Action.D
        if self.m > self.n / 2:
            if round_num == 1 and coop_count >= self.m - 2:
                return Action.C
            elif coop_count < self.m - 1:
                return Action.D
        cooperation_buffer = 1 if self.k < 2 else 0
        if needed_cooperators <= (remaining_uncertain_players + reliable_cooperators) / 2 + cooperation_buffer:
            return Action.C
        else:
            return Action.D

class Strategy_AGGRESSIVE_87(BaseStrategy):
    """
    Threshold Hawk: An aggressive exploitation strategy that minimizes personal contribution
    while maximizing free-riding on others' cooperation. Cooperates only when pivotal
    and exploits cooperative opponents ruthlessly.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.danger_threshold = self.m - 1.5
        self.safety_margin = max(1, math.floor(self.n * 0.15))
        self.small_group = self.n <= 4
        self.high_threshold = self.m / self.n > 0.7
        self.low_reward = self.k <= 1.5
        self.opponent_cooperation_rates = np.zeros(self.n - 1)
        self.defection_adjustment = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number + 1
        if current_round == self.r:
            return Action.D
        recent_cooperators = self._count_recent_cooperators(history)
        cooperation_trend = self._calculate_cooperation_trend(history)
        self._update_opponent_tracking(history)
        return self._make_decision(history, recent_cooperators, cooperation_trend, current_round)

    def _count_recent_cooperators(self, history: PlayerHistory) -> int:
        """Count cooperators in the most recent round"""
        if history.round_number == 0:
            return 0
        return sum(history.opponent_actions[-1, :])

    def _calculate_cooperation_trend(self, history: PlayerHistory) -> float:
        """Calculate average cooperation rate over last 3 rounds"""
        if history.round_number == 0:
            return 0.5
        lookback = min(3, history.round_number)
        recent_rounds = history.opponent_actions[-lookback:, :]
        return np.mean(recent_rounds)

    def _update_opponent_tracking(self, history: PlayerHistory):
        """Update cooperation rates for each opponent"""
        if history.round_number > 0:
            total_rounds = history.round_number
            for i in range(self.n - 1):
                self.opponent_cooperation_rates[i] = np.mean(history.opponent_actions[:, i])

    def _make_decision(self, history: PlayerHistory, recent_cooperators: int, cooperation_trend: float, current_round: int) -> Action:
        """Main decision logic"""
        safety_margin = self.safety_margin
        danger_threshold = self.danger_threshold
        if self.small_group:
            safety_margin = 0
            cooperation_trend *= 1.2
        if recent_cooperators >= self.m + safety_margin:
            return Action.D
        if recent_cooperators <= danger_threshold:
            return Action.C
        return self._exploitation_heuristic(history, cooperation_trend, current_round)

    def _exploitation_heuristic(self, history: PlayerHistory, cooperation_trend: float, current_round: int) -> Action:
        """Detailed exploitation logic for borderline cases"""
        cooperation_likelihood = cooperation_trend * (self.n - 1)
        expected_cooperators = cooperation_likelihood
        threshold_adjustment = 0.3
        if self.low_reward:
            threshold_adjustment = 0.5
            expected_cooperators *= 0.7
        if expected_cooperators < self.m - threshold_adjustment:
            return Action.C
        elif expected_cooperators > self.m + threshold_adjustment + 0.4:
            return Action.D
        else:
            player_id = 0
            if current_round % 3 == player_id % 3:
                return Action.C
            else:
                return Action.D

    def _apply_punishment_protocol(self, history: PlayerHistory) -> bool:
        """Check if punishment is needed based on recent failures"""
        if history.round_number < 2:
            return False
        last_round_total = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_total += 1
        if last_round_total < self.m:
            consistent_defectors = sum(self.opponent_cooperation_rates <= 0.2)
            if consistent_defectors >= 0.6 * (self.n - 1):
                return True
        return False

    def _calculate_personal_efficiency(self, history: PlayerHistory) -> float:
        """Calculate personal efficiency for learning adjustment"""
        if history.round_number == 0:
            return 0.85
        total_payoff = sum(history.my_payoffs)
        max_possible = history.round_number * self.k
        return total_payoff / max_possible if max_possible > 0 else 0.85

class Strategy_AGGRESSIVE_88(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Threshold Predator"
    
    Aggressively exploits cooperative players while minimizing personal risk.
    Only cooperates when absolutely necessary to secure the collective reward.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        return self._adaptive_exploitation_decision(history)

    def _adaptive_exploitation_decision(self, history: PlayerHistory) -> Action:
        rounds_played = history.round_number
        coop_rates = np.mean(history.opponent_actions, axis=0)
        recent_window = min(3, rounds_played)
        if rounds_played >= recent_window:
            recent_actions = history.opponent_actions[-recent_window:, :]
            recent_coop_rates = np.mean(recent_actions, axis=0)
            adjusted_coop_rates = 0.7 * recent_coop_rates + 0.3 * coop_rates
        else:
            adjusted_coop_rates = coop_rates
        for i in range(len(adjusted_coop_rates)):
            if coop_rates[i] > 0.7:
                adjusted_coop_rates[i] *= 1.1
        expected_coops = np.sum(adjusted_coop_rates)
        if self.n <= 4:
            expected_coops *= 0.9
        if self.k <= 1.5:
            expected_coops *= 0.8
        if expected_coops >= self.m:
            return Action.D
        elif expected_coops >= self.m - 1:
            return Action.C
        else:
            if self._should_encourage_cooperation(history):
                return Action.C
            return Action.D

    def _should_encourage_cooperation(self, history: PlayerHistory) -> bool:
        """Determine if we should temporarily cooperate to restore others' cooperation"""
        rounds_played = history.round_number
        if rounds_played < 2 or rounds_played >= self.r - 2:
            return False
        recent_window = min(3, rounds_played)
        if rounds_played >= recent_window + 1:
            early_coop = np.mean(history.opponent_actions[:recent_window, :])
            recent_coop = np.mean(history.opponent_actions[-recent_window:, :])
            if recent_coop < early_coop * 0.6 and recent_coop < self.m / self.n:
                if early_coop >= (self.m - 1) / self.n:
                    return True
        return False

class Strategy_AGGRESSIVE_89(BaseStrategy):
    """
    Aggressive Adaptive Threshold Strategy (AATS) - Maximizes personal payoffs through 
    calculated aggression, exploiting cooperative players while maintaining strategic 
    cooperation only when necessary for personal gain.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.probe_phase_end = max(1, int(0.2 * self.r))
        self.exploit_phase_end = max(2, int(0.8 * self.r))
        self.cooperation_reliability_scores = np.zeros(self.n - 1)
        self.effective_threshold_estimate = self.m
        self.punishment_rounds_remaining = 0
        self.buffer = 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        round_num = history.round_number
        if round_num < self.probe_phase_end:
            self._update_reliability_scores(history)
            return Action.D
        elif round_num >= self.exploit_phase_end:
            return self._endgame_decision(history, round_num)
        else:
            return self._exploitation_decision(history, round_num)

    def _update_reliability_scores(self, history):
        """Update Cooperation Reliability Scores for opponents"""
        if history.round_number == 0:
            return
        for i in range(self.n - 1):
            total_rounds = history.round_number
            cooperations = np.sum(history.opponent_actions[:, i])
            recent_weight = 1.0
            if total_rounds >= 3:
                recent_cooperations = np.sum(history.opponent_actions[-3:, i])
                older_cooperations = cooperations - recent_cooperations
                older_rounds = total_rounds - 3
                if older_rounds > 0:
                    recent_weight = (recent_cooperations * 1.5 + older_cooperations * 1.0) / total_rounds
                else:
                    recent_weight = recent_cooperations / 3.0 * 1.5
            self.cooperation_reliability_scores[i] = cooperations / total_rounds * (1.0 + recent_weight * 0.5)

    def _get_recent_cooperation_rate(self, history, lookback=5):
        """Calculate cooperation rate over last N rounds"""
        if history.round_number == 0:
            return 0.0
        start_idx = max(0, history.round_number - lookback)
        recent_actions = history.opponent_actions[start_idx:, :]
        return np.mean(recent_actions)

    def _count_last_round_cooperators(self, history):
        """Count cooperators in the most recent round"""
        if history.round_number == 0:
            return 0
        return int(np.sum(history.opponent_actions[-1, :]))

    def _update_effective_threshold(self, history):
        """Update effective threshold estimate based on observed patterns"""
        if history.round_number < 3:
            return
        recent_rounds = min(5, history.round_number)
        successes = 0
        failures = 0
        for i in range(1, recent_rounds + 1):
            round_idx = -i
            cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators >= self.m:
                successes += 1
            else:
                failures += 1
        if failures > successes:
            self.effective_threshold_estimate = min(self.m + self.buffer, self.n - 1)
        elif successes > failures * 2:
            self.effective_threshold_estimate = max(self.m - self.buffer, 1)

    def _exploitation_decision(self, history, round_num):
        """Main exploitation phase decision logic"""
        self._update_reliability_scores(history)
        self._update_effective_threshold(history)
        if self.punishment_rounds_remaining > 0:
            self.punishment_rounds_remaining -= 1
            cooperators = self._count_last_round_cooperators(history)
            if cooperators == self.m - 1 and np.mean(self.cooperation_reliability_scores) > 0.8:
                return Action.C
            return Action.D
        cooperators = self._count_last_round_cooperators(history)
        my_cooperation_needed = cooperators >= self.m - 1
        recent_cooperation_rate = self._get_recent_cooperation_rate(history)
        if history.round_number > 0:
            last_cooperators = cooperators
            if history.my_actions[-1]:
                last_cooperators += 1
            if last_cooperators < self.m and history.my_actions[-1]:
                self.punishment_rounds_remaining = 2
                return Action.D
        if my_cooperation_needed and recent_cooperation_rate > 0.4:
            avg_cooperation = np.mean(self._get_recent_cooperation_rate(history, 10))
            if avg_cooperation > 0.7:
                if random.random() > 0.6:
                    return Action.D
            return Action.C
        else:
            avg_cooperation = np.mean(self._get_recent_cooperation_rate(history, 10))
            if avg_cooperation < 0.3:
                if cooperators == self.m - 1:
                    return Action.C
            return Action.D

    def _endgame_decision(self, history, round_num):
        """Endgame aggression decision logic"""
        rounds_left = self.r - round_num
        if rounds_left <= 1:
            return Action.D
        if rounds_left == 2:
            cooperators = self._count_last_round_cooperators(history)
            if cooperators == self.m - 1 and np.mean(self.cooperation_reliability_scores) > 0.9:
                return Action.C
            return Action.D
        cooperators = self._count_last_round_cooperators(history)
        defection_probability = 0.7 + 0.2 * (self.r - rounds_left) / (0.2 * self.r)
        if cooperators >= self.m - 1 and random.random() > defection_probability:
            return Action.C
        return Action.D

class Strategy_AGGRESSIVE_90(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Opportunistic Defector"
    
    This strategy aggressively exploits cooperative players while minimizing personal risk.
    It defects whenever possible and only cooperates when absolutely necessary to maintain
    the collective benefit that can be exploited.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == r - 1:
            return Action.D
        my_prev_action = history.my_actions[-1]
        opponent_prev_cooperators = sum(history.opponent_actions[-1, :])
        prev_coop_count = int(my_prev_action) + opponent_prev_cooperators
        if prev_coop_count >= m:
            return Action.D
        if prev_coop_count == m - 1:
            return Action.C
        if current_round > 1:
            persistent_cooperators = 0
            for player_idx in range(n - 1):
                if history.opponent_actions[-1, player_idx] and history.opponent_actions[-2, player_idx]:
                    persistent_cooperators += 1
            if len(history.my_actions) >= 2 and history.my_actions[-1] and history.my_actions[-2]:
                persistent_cooperators += 1
            if persistent_cooperators >= m - 1:
                return Action.C
        return Action.D

class Strategy_AGGRESSIVE_91(BaseStrategy):
    """
    Aggressive Adaptive Threshold Strategy (AATS).
    
    Operates on strategic selfishness with calculated cooperation. Cooperates only when
    profitable or necessary to secure collective benefit, while aggressively exploiting
    opportunities to free-ride on others' cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.force_defect_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number + 1
        if current_round == self.r:
            return Action.D
        if self.force_defect_rounds > 0:
            self.force_defect_rounds -= 1
            return Action.D
        total_opponent_cooperations = np.sum(history.opponent_actions)
        total_opponent_decisions = history.round_number * (self.n - 1)
        if total_opponent_decisions == 0:
            cp = 0.0
        else:
            cp = total_opponent_cooperations / total_opponent_decisions
        ec = (self.n - 1) * cp
        if history.round_number >= 2:
            recent_coop_rates = []
            for i in range(min(2, history.round_number)):
                round_idx = history.round_number - 1 - i
                round_cooperations = np.sum(history.opponent_actions[round_idx, :])
                recent_coop_rates.append(round_cooperations / (self.n - 1))
            if len(recent_coop_rates) == 2 and recent_coop_rates[0] < recent_coop_rates[1]:
                ec = ec * 0.8
        if history.round_number >= 2:
            my_recent_cooperations = np.sum(history.my_actions[-2:])
            expected_opponent_cooperations = 2 * (self.n - 1) * cp
            actual_opponent_cooperations = np.sum(history.opponent_actions[-2:, :])
            if my_recent_cooperations >= 1 and actual_opponent_cooperations < expected_opponent_cooperations * 0.7:
                self.force_defect_rounds = 2
                return Action.D
        if history.round_number >= 3 and ec >= self.m + 2:
            high_coop_rounds = 0
            for i in range(min(3, history.round_number)):
                round_idx = history.round_number - 1 - i
                round_cooperations = np.sum(history.opponent_actions[round_idx, :])
                if round_cooperations >= self.m + 1:
                    high_coop_rounds += 1
            if high_coop_rounds >= 3:
                self.force_defect_rounds = 3
                return Action.D
        if ec >= self.m:
            return Action.D
        elif abs(ec - (self.m - 1)) < 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_AGGRESSIVE_92(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Threshold Predator"
    
    This strategy aggressively exploits cooperative players while minimizing personal risk.
    It aims to maximize personal payoffs by contributing only when absolutely necessary,
    while maintaining enough cooperation to keep the collective threshold viable for exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        phase_1_end = self.r // 3
        phase_2_end = 2 * self.r // 3
        if current_round < phase_1_end:
            phase = 'exploitation'
        elif current_round < phase_2_end:
            phase = 'manipulation'
        else:
            phase = 'endgame'
        recent_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        if phase == 'exploitation':
            if recent_cooperators == self.m - 1:
                return Action.C
            else:
                return Action.D
        elif phase == 'manipulation':
            predicted_cooperators = self._predict_cooperators(history)
            if predicted_cooperators >= self.m:
                return Action.D
            elif predicted_cooperators == self.m - 1:
                return Action.C
            else:
                return Action.D
        else:
            predicted_cooperators = self._predict_cooperators(history)
            remaining_rounds = self.r - current_round
            if predicted_cooperators == self.m - 1 and remaining_rounds > 2:
                return Action.C
            else:
                return Action.D

    def _predict_cooperators(self, history: PlayerHistory) -> int:
        """Predict how many opponents will cooperate based on their recent behavior."""
        if history.round_number < 2:
            return int(np.sum(history.opponent_actions[-1, :]))
        predicted_count = 0
        for player_idx in range(self.n - 1):
            if history.round_number >= 2:
                last_two_actions = history.opponent_actions[-2:, player_idx]
                cooperation_rate = np.mean(last_two_actions)
                if cooperation_rate > 0.7:
                    predicted_count += 1
                elif cooperation_rate >= 0.3:
                    if last_two_actions[-1]:
                        predicted_count += 1
            elif history.opponent_actions[-1, player_idx]:
                predicted_count += 1
        return predicted_count

class Strategy_AGGRESSIVE_93(BaseStrategy):
    """
    Threshold Predator: An aggressive exploitation strategy that free-rides when others
    likely cooperate and only contributes when pivotal to avoid collective failure.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.opponent_cooperation_rates = np.zeros(self.n - 1)
        self.punishment_rounds_left = 0
        self.detected_suckers = np.zeros(self.n - 1, dtype=bool)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number + 1
        if current_round == self.r:
            return Action.D
        self._update_opponent_analysis(history)
        predicted_cooperators = self._predict_cooperators(history)
        if predicted_cooperators >= self.m:
            return Action.D
        elif predicted_cooperators == self.m - 1:
            return self._decide_critical_cooperation(history)
        else:
            return Action.D

    def _update_opponent_analysis(self, history: PlayerHistory):
        """Update our analysis of opponent behavior patterns"""
        rounds_to_analyze = min(3, history.round_number)
        if rounds_to_analyze == 0:
            return
        recent_actions = history.opponent_actions[-rounds_to_analyze:, :]
        self.opponent_cooperation_rates = np.mean(recent_actions, axis=0)
        total_rounds = history.round_number
        if total_rounds >= 3:
            total_cooperation = np.sum(history.opponent_actions, axis=0)
            cooperation_rates = total_cooperation / total_rounds
            self.detected_suckers = cooperation_rates > 0.8
        if self.punishment_rounds_left > 0:
            self.punishment_rounds_left -= 1

    def _predict_cooperators(self, history: PlayerHistory) -> float:
        """Predict number of cooperators in current round"""
        base_probs = self.opponent_cooperation_rates.copy()
        if history.round_number > 0:
            last_round_cooperators = np.sum(history.opponent_actions[-1, :])
            if history.my_actions[-1]:
                last_round_cooperators += 1
            if last_round_cooperators < self.m:
                base_probs *= 1.3
                if not history.my_actions[-1]:
                    self.punishment_rounds_left = 2
            elif last_round_cooperators > self.m + 1:
                base_probs *= 0.8
        if np.any(self.detected_suckers):
            base_probs[self.detected_suckers] *= 1.2
        rounds_remaining = self.r - (history.round_number + 1)
        end_game_threshold = max(1, self.r // 4)
        if rounds_remaining <= end_game_threshold:
            base_probs *= 0.7
        if self.n <= 4:
            base_probs *= 1.1
        if self.m > self.n / 2 and history.round_number < 3:
            base_probs *= 1.2
        if self.k < 1.5:
            base_probs *= 0.9
        base_probs = np.clip(base_probs, 0.0, 1.0)
        return np.sum(base_probs)

    def _decide_critical_cooperation(self, history: PlayerHistory) -> Action:
        """Decide whether to cooperate when we're potentially pivotal"""
        if self.punishment_rounds_left > 0:
            return Action.C
        if self.n <= 4:
            return Action.C
        rounds_to_check = min(5, history.round_number)
        if rounds_to_check > 0:
            recent_defections = np.sum(~history.my_actions[-rounds_to_check:])
            defection_rate = recent_defections / rounds_to_check
            if defection_rate > 0.7:
                return Action.C
        if self.m > self.n / 2 and history.round_number < 3:
            return Action.C
        if self.k < 1.5:
            return Action.D
        return Action.D

class Strategy_AGGRESSIVE_94(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Opportunistic Dominance"
    
    This strategy aims to maximize personal payoffs by exploiting cooperative behavior 
    from others while minimizing personal risk. Only cooperates when it directly 
    benefits personal payoff, not as a social good.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == r - 1:
            return Action.D
        prev_cooperators = sum(history.opponent_actions[-1, :])
        my_coop_rate = sum(history.my_actions) / len(history.my_actions)
        opponent_coop_rates = []
        for player_idx in range(n - 1):
            opponent_actions = history.opponent_actions[:, player_idx]
            coop_rate = sum(opponent_actions) / len(opponent_actions)
            opponent_coop_rates.append(coop_rate)
        high_cooperators = sum((1 for rate in opponent_coop_rates if rate > 0.5))
        low_cooperators = sum((1 for rate in opponent_coop_rates if rate > 0.3))
        if high_cooperators > 0.6 * (n - 1):
            required_cooperators = max(0, m - 2)
        elif low_cooperators < 0.4 * (n - 1):
            required_cooperators = m - 1
            if len(history.my_actions) >= 2:
                if history.my_actions[-1] or history.my_actions[-2]:
                    return Action.D
            elif len(history.my_actions) >= 1:
                if history.my_actions[-1]:
                    return Action.D
        else:
            required_cooperators = m - 1
        if current_round <= 2:
            if prev_cooperators >= required_cooperators and prev_cooperators <= m and (my_coop_rate < 0.3):
                return Action.C
            else:
                return Action.D
        if len(history.my_actions) >= 5:
            recent_threshold_met = 0
            for round_idx in range(-5, 0):
                round_cooperators = sum(history.opponent_actions[round_idx, :])
                if history.my_actions[round_idx]:
                    round_cooperators += 1
                if round_cooperators >= m:
                    recent_threshold_met += 1
            threshold_met_rate = recent_threshold_met / 5
            if threshold_met_rate < 0.3:
                if prev_cooperators != m - 1:
                    return Action.D
            elif threshold_met_rate > 0.7:
                if prev_cooperators < m - 1:
                    return Action.D
        if prev_cooperators >= required_cooperators and prev_cooperators <= m and (my_coop_rate < 0.3):
            return Action.C
        else:
            return Action.D

class Strategy_AGGRESSIVE_95(BaseStrategy):
    """
    Aggressive Threshold Exploitation Strategy (ATES)
    
    This strategy aggressively maximizes individual payoff by exploiting collective action dynamics.
    It treats cooperation as a calculated investment only when necessary to secure the threshold bonus,
    while defaulting to selfish defection to capture free-rider benefits.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        round_num = state.round_number
        phase_1_end = self.r // 3
        phase_2_end = 2 * self.r // 3
        if round_num <= phase_1_end:
            return self._early_phase_decision(history)
        elif round_num <= phase_2_end:
            return self._middle_phase_decision(history)
        else:
            return self._final_phase_decision(history, round_num)

    def _early_phase_decision(self, history: PlayerHistory) -> Action:
        """Phase 1: Early rounds decision logic"""
        last_cooperators = self._count_last_round_cooperators(history)
        if last_cooperators >= self.m:
            return Action.D
        elif last_cooperators >= self.m - 2:
            return Action.C
        else:
            return Action.D

    def _middle_phase_decision(self, history: PlayerHistory) -> Action:
        """Phase 2: Middle rounds - Conditional Threshold Rule"""
        avg_coop_rate = self._get_avg_cooperation_rate_last_3(history)
        threshold_high = (self.m - 1) / self.n
        threshold_low = (self.m - 3) / self.n
        if self.k > 3:
            threshold_high = self.m / self.n
            threshold_low = (self.m - 2) / self.n
        mn_ratio = self.m / self.n
        if mn_ratio < 0.3:
            threshold_high = max(0, (self.m - 2) / self.n)
            threshold_low = max(0, (self.m - 4) / self.n)
        elif mn_ratio > 0.7:
            threshold_high = min(1, self.m / self.n)
            threshold_low = (self.m - 2) / self.n
        if avg_coop_rate >= threshold_high:
            return Action.D
        elif avg_coop_rate >= threshold_low:
            return Action.C
        else:
            return Action.D

    def _final_phase_decision(self, history: PlayerHistory, round_num: int) -> Action:
        """Phase 3: Final rounds - Aggressive Endgame Protocol"""
        if round_num >= self.r - 1:
            return Action.D
        last_cooperators = self._count_last_round_cooperators(history)
        if last_cooperators == self.m - 1:
            return Action.C
        else:
            return Action.D

    def _count_last_round_cooperators(self, history: PlayerHistory) -> int:
        """Count total cooperators (including self) in the last round"""
        if len(history.my_actions) == 0:
            return 0
        opponent_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        my_last_action = int(history.my_actions[-1])
        return opponent_cooperators + my_last_action

    def _get_avg_cooperation_rate_last_3(self, history: PlayerHistory) -> float:
        """Get average cooperation rate over last 3 rounds"""
        rounds_available = len(history.my_actions)
        rounds_to_check = min(3, rounds_available)
        if rounds_to_check == 0:
            return 0.0
        total_cooperators = 0
        total_possible = 0
        for i in range(rounds_to_check):
            round_idx = -(i + 1)
            opponent_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
            my_cooperation = int(history.my_actions[round_idx])
            total_cooperators += opponent_cooperators + my_cooperation
            total_possible += self.n
        return total_cooperators / total_possible if total_possible > 0 else 0.0

class Strategy_AGGRESSIVE_96(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Threshold Predator"
    
    This strategy aggressively exploits cooperative players while minimizing personal risk.
    It aims to maximize payoffs by contributing only when absolutely necessary to secure 
    the group reward, while free-riding whenever possible.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number + 1
        if current_round == self.r:
            return Action.D
        predicted_cooperators = self._predict_cooperators(history)
        if predicted_cooperators + 1 >= self.m:
            if predicted_cooperators >= self.m:
                return Action.D
            else:
                return self._decide_decisive_cooperation(history, predicted_cooperators)
        else:
            return Action.D

    def _predict_cooperators(self, history: PlayerHistory) -> float:
        """Predict number of cooperators using weighted recent vs overall behavior."""
        current_round = history.round_number
        predicted_cooperators = 0.0
        for player_idx in range(self.n - 1):
            recent_rounds = min(3, current_round)
            if recent_rounds > 0:
                recent_actions = history.opponent_actions[-recent_rounds:, player_idx]
                recent_coop_rate = np.mean(recent_actions)
            else:
                recent_coop_rate = 0.0
            if current_round > 0:
                overall_coop_rate = np.mean(history.opponent_actions[:, player_idx])
            else:
                overall_coop_rate = 0.0
            predicted_probability = 0.7 * recent_coop_rate + 0.3 * overall_coop_rate
            predicted_cooperators += predicted_probability
        return predicted_cooperators

    def _decide_decisive_cooperation(self, history: PlayerHistory, predicted_cooperators: float) -> Action:
        """Decide whether to cooperate when we would be the decisive cooperator."""
        current_round = history.round_number
        if current_round >= 5:
            recent_rounds = min(5, current_round)
            threshold_met_count = 0
            for round_idx in range(current_round - recent_rounds, current_round):
                cooperators_that_round = np.sum(history.opponent_actions[round_idx, :])
                if history.my_actions[round_idx]:
                    cooperators_that_round += 1
                if cooperators_that_round >= self.m:
                    threshold_met_count += 1
            success_rate = threshold_met_count / recent_rounds
            if success_rate >= 0.8:
                if random.random() < 0.2:
                    return Action.D
        if current_round > 2:
            my_coop_rate = np.mean(history.my_actions)
            min_opponent_coop_rate = 1.0
            for player_idx in range(self.n - 1):
                opponent_coop_rate = np.mean(history.opponent_actions[:, player_idx])
                if opponent_coop_rate > 0.3:
                    min_opponent_coop_rate = min(min_opponent_coop_rate, opponent_coop_rate)
            if my_coop_rate >= min_opponent_coop_rate:
                return Action.D
        if self.m > self.n / 2:
            if current_round <= 3:
                return Action.C
        elif self.m <= self.n / 3:
            if predicted_cooperators < self.m - 0.5:
                return Action.C
            else:
                return Action.D
        final_phase_start = math.ceil(0.8 * self.r)
        if current_round >= final_phase_start:
            if random.random() < 0.7:
                return Action.D
        return Action.C

class Strategy_AGGRESSIVE_97(BaseStrategy):
    """
    Aggressive Threshold Exploitation Strategy - maximizes personal payoffs through
    strategic free-riding and minimal cooperation only when pivotal for threshold achievement.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        phase_1_end = self.r // 3
        if current_round < phase_1_end:
            return Action.D
        phase_2_end = 2 * self.r // 3
        if current_round < phase_2_end:
            if last_round_cooperators == self.m - 1:
                return Action.C
            else:
                return Action.D
        rounds_into_phase_3 = current_round - phase_2_end
        cooperation_threshold = max(1, self.m - rounds_into_phase_3)
        if last_round_cooperators >= cooperation_threshold:
            return Action.D
        elif last_round_cooperators == self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_AGGRESSIVE_98(BaseStrategy):
    """
    Opportunistic Predator - An aggressive exploitation strategy that maximizes personal payoff
    by exploiting cooperative players while minimizing personal risk. Treats cooperation as a
    tool for manipulation rather than mutual benefit.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.phase1_end = max(1, self.r // 3)
        self.phase2_end = max(2, 2 * self.r // 3)
        self.aggression_multiplier = min(2.0, self.k / 1.5) * (self.n - self.m) / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        cooperators_last_round = int(np.sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            cooperators_last_round += 1
        if current_round <= self.phase1_end:
            return self._phase1_decision(history, cooperators_last_round)
        elif current_round <= self.phase2_end:
            return self._phase2_decision(history, cooperators_last_round)
        else:
            return self._phase3_decision(history, cooperators_last_round, current_round)

    def _phase1_decision(self, history: PlayerHistory, cooperators_last_round: int) -> Action:
        """Phase 1: Early Exploitation - Establish baseline and identify patterns"""
        if cooperators_last_round >= self.m:
            return Action.D
        elif cooperators_last_round == self.m - 1:
            if len(history.my_actions) > 1:
                for i in range(len(history.my_actions) - 1):
                    total_cooperators = int(np.sum(history.opponent_actions[i, :])) + (1 if history.my_actions[i] else 0)
                    if not history.my_actions[i] and total_cooperators >= self.m:
                        return Action.D
            return Action.C
        return Action.D

    def _phase2_decision(self, history: PlayerHistory, cooperators_last_round: int) -> Action:
        """Phase 2: Ruthless Optimization - Maximize exploitation based on patterns"""
        successful_exploitations = 0
        total_rounds = len(history.my_actions)
        for i in range(total_rounds):
            total_cooperators = int(np.sum(history.opponent_actions[i, :])) + (1 if history.my_actions[i] else 0)
            if not history.my_actions[i] and total_cooperators >= self.m:
                successful_exploitations += 1
        exploitation_score = successful_exploitations / total_rounds if total_rounds > 0 else 0
        if exploitation_score > 0.6:
            if cooperators_last_round >= self.m:
                return Action.D
            elif cooperators_last_round >= self.m - 2:
                return Action.D
            else:
                return Action.D
        elif exploitation_score > 0.3:
            if cooperators_last_round >= self.m:
                return Action.D
            elif cooperators_last_round == self.m - 1:
                prob = 0.4 / self.aggression_multiplier
                return Action.C if random.random() < prob else Action.D
            else:
                return Action.D
        elif cooperators_last_round >= self.m - 1:
            prob = 0.6 / self.aggression_multiplier
            return Action.C if random.random() < prob else Action.D
        else:
            return Action.D

    def _phase3_decision(self, history: PlayerHistory, cooperators_last_round: int, current_round: int) -> Action:
        """Phase 3: Endgame Domination - Maximize final payoffs with no future concern"""
        rounds_remaining = self.r - current_round + 1
        recent_rounds = min(5, len(history.my_actions))
        if recent_rounds > 0:
            recent_opponent_coop = np.sum(history.opponent_actions[-recent_rounds:, :])
            recent_cooperation_rate = recent_opponent_coop / (recent_rounds * (self.n - 1))
        else:
            recent_cooperation_rate = 0
        if rounds_remaining <= 3:
            if cooperators_last_round >= self.m:
                return Action.D
            elif cooperators_last_round >= self.m - 2 and recent_cooperation_rate > 0.4:
                return Action.D
            else:
                return Action.D
        elif cooperators_last_round >= self.m:
            return Action.D
        elif cooperators_last_round == self.m - 1 and recent_cooperation_rate > 0.5:
            prob = 0.3 / self.aggression_multiplier
            return Action.C if random.random() < prob else Action.D
        else:
            return Action.D

class Strategy_AGGRESSIVE_99(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Predator"
    
    Operates on aggressive opportunism - exploits cooperation when it exists,
    but never initiates or sustains it. Only cooperates when highly confident
    that enough others will cooperate to meet the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.base_safety_buffer = 0.1
        self.scorched_earth_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number + 1
        if current_round == self.r:
            return Action.D
        if self.scorched_earth_rounds > 0:
            self.scorched_earth_rounds -= 1
            return Action.D
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        coop_rate_last = last_round_cooperators / self.n
        rounds_to_check = min(3, len(history.my_actions))
        total_cooperators = 0
        for i in range(rounds_to_check):
            round_idx = -(i + 1)
            round_cooperators = np.sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                round_cooperators += 1
            total_cooperators += round_cooperators
        avg_coop_rate = total_cooperators / (self.n * rounds_to_check)
        safety_buffer = self.base_safety_buffer
        if avg_coop_rate > 0.7:
            safety_buffer = 0.15
        elif avg_coop_rate < 0.3:
            safety_buffer = 0.05
        if last_round_cooperators >= self.m:
            defection_rate = 1 - coop_rate_last
            if defection_rate > 0.6:
                self.scorched_earth_rounds = 2
        if current_round > 0.8 * self.r:
            rounds_into_endgame = current_round - int(0.8 * self.r)
            safety_buffer -= 0.05 * rounds_into_endgame
        safety_buffer = max(0, safety_buffer)
        required_threshold = (self.m - 1) / self.n + safety_buffer
        probability_threshold_met = min(1.0, coop_rate_last / required_threshold) if required_threshold > 0 else 0
        min_prob_for_cooperation = 1.0 / (self.k - 1) if self.k > 1 else 1.0
        if coop_rate_last >= required_threshold and probability_threshold_met >= min_prob_for_cooperation:
            return Action.C
        else:
            return Action.D

class Strategy_AGGRESSIVE_100(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Threshold Predator"
    
    This strategy aggressively exploits cooperative players while minimizing personal risk.
    It free-rides on others' cooperation whenever possible, only cooperating when absolutely 
    necessary to secure the collective reward.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            cooperators_last_round += 1
        if current_round == self.r - 2:
            if cooperators_last_round >= self.m - 1:
                return Action.D
            else:
                return Action.C
        if cooperators_last_round == self.m:
            return Action.C
        if len(history.my_actions) >= 2:
            cooperators_prev_round = int(np.sum(history.opponent_actions[-2, :]))
            if history.my_actions[-2]:
                cooperators_prev_round += 1
            if cooperators_last_round < self.m + 1 and cooperators_prev_round < self.m + 1:
                return Action.C
        if cooperators_last_round >= self.n - self.m + 1:
            return Action.D
        if cooperators_last_round == 0:
            if current_round >= self.r - 3:
                total_cooperation_history = np.sum(history.opponent_actions)
                if total_cooperation_history > 0:
                    return Action.C
            return Action.D
        return Action.D

class Strategy_AGGRESSIVE_101(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "PREDATOR"
    
    Maximizes exploitation with minimal risk by free-riding whenever possible
    while ensuring collective survival only when absolutely necessary.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.opponent_coop_rates = None
        self.window_size = min(5, max(3, self.r // 4))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        self._update_opponent_tracking(history)
        if self._is_threshold_critically_endangered(history, current_round):
            rounds_remaining = self.r - current_round
            if rounds_remaining >= 3:
                return Action.C
        return Action.D

    def _update_opponent_tracking(self, history: PlayerHistory):
        """Update tracking of opponent cooperation patterns."""
        rounds_completed = history.round_number
        n_opponents = self.n - 1
        if self.opponent_coop_rates is None:
            self.opponent_coop_rates = np.zeros(n_opponents)
        if rounds_completed > 0:
            start_round = max(0, rounds_completed - self.window_size)
            window_actions = history.opponent_actions[start_round:rounds_completed, :]
            for i in range(n_opponents):
                window_cooperations = np.sum(window_actions[:, i])
                window_length = window_actions.shape[0]
                self.opponent_coop_rates[i] = window_cooperations / window_length if window_length > 0 else 0

    def _is_threshold_critically_endangered(self, history: PlayerHistory, current_round: int) -> bool:
        """
        Determine if cooperation threshold is critically endangered and emergency
        cooperation is needed.
        """
        rounds_completed = history.round_number
        if rounds_completed == 0:
            return False
        projected_cooperators = self._estimate_opponent_cooperators(history)
        if projected_cooperators <= self.m - 1:
            if self._check_recent_failures(history):
                return False
            return True
        return False

    def _estimate_opponent_cooperators(self, history: PlayerHistory) -> int:
        """
        Estimate how many opponents will cooperate in the current round
        based on their recent behavior patterns.
        """
        if self.opponent_coop_rates is None:
            return 0
        reliable_cooperators = np.sum(self.opponent_coop_rates > 0.7)
        conditional_cooperators = np.sum((self.opponent_coop_rates > 0.3) & (self.opponent_coop_rates <= 0.7))
        estimated_cooperators = int(reliable_cooperators + conditional_cooperators * 0.5)
        return min(estimated_cooperators, self.n - 1)

    def _check_recent_failures(self, history: PlayerHistory) -> bool:
        """
        Check if there have been too many recent threshold failures,
        suggesting cooperation might be futile.
        """
        rounds_completed = history.round_number
        if rounds_completed < 3:
            return False
        recent_rounds = min(3, rounds_completed)
        failures = 0
        for i in range(recent_rounds):
            round_idx = rounds_completed - 1 - i
            my_action = history.my_actions[round_idx]
            opponent_cooperators = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators = opponent_cooperators + (1 if my_action else 0)
            if total_cooperators < self.m:
                failures += 1
        return failures >= 3

class Strategy_AGGRESSIVE_102(BaseStrategy):
    """
    Aggressive Threshold Exploitation Strategy (ATES)
    
    Maximizes personal payoffs by defecting whenever possible while strategically 
    cooperating only when absolutely necessary to secure the collective benefit.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.safety_buffer = max(1, math.floor(0.2 * self.n))
        self.reliability_scores = [0.5] * (self.n - 1)
        self.forced_cooperation_rounds = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if history is None:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        self._update_reliability_scores(history)
        self._adjust_safety_buffer(history)
        reliable_cooperators = sum((1 for score in self.reliability_scores if score > 0.7))
        adjusted_buffer = self.safety_buffer
        if current_round > 0.9 * self.r:
            adjusted_buffer = math.ceil(self.safety_buffer * 1.5)
        if reliable_cooperators >= self.m + adjusted_buffer:
            decision = Action.D
        elif reliable_cooperators + 1 >= self.m:
            decision = Action.C
            self.forced_cooperation_rounds.append(current_round)
        else:
            decision = Action.D
        if random.random() < 0.1 and current_round % 7 == 0 and (current_round > 0.2 * self.r) and (decision == Action.C):
            decision = Action.D
        return decision

    def _update_reliability_scores(self, history: PlayerHistory):
        """Update reliability scores for opponents based on recent cooperation."""
        n_rounds = history.round_number
        decay_factor = 0.8
        lookback = min(5, n_rounds)
        for i in range(self.n - 1):
            if n_rounds == 0:
                continue
            weighted_sum = 0
            weight_sum = 0
            for j in range(lookback):
                round_idx = n_rounds - 1 - j
                if round_idx >= 0:
                    weight = decay_factor ** j
                    weighted_sum += history.opponent_actions[round_idx, i] * weight
                    weight_sum += weight
            if weight_sum > 0:
                self.reliability_scores[i] = weighted_sum / weight_sum

    def _adjust_safety_buffer(self, history: PlayerHistory):
        """Adjust safety buffer based on recent threshold outcomes."""
        n_rounds = history.round_number
        if n_rounds < 2:
            return
        recent_rounds = min(3, n_rounds)
        threshold_barely_met = 0
        threshold_missed = 0
        for i in range(recent_rounds):
            round_idx = n_rounds - 1 - i
            if round_idx >= 0:
                my_action = history.my_actions[round_idx]
                opponent_cooperators = sum(history.opponent_actions[round_idx, :])
                total_cooperators = opponent_cooperators + (1 if my_action else 0)
                if total_cooperators == self.m:
                    threshold_barely_met += 1
                elif total_cooperators < self.m:
                    threshold_missed += 1
        if threshold_barely_met > threshold_missed:
            self.safety_buffer = max(0, self.safety_buffer - 0.1)
        elif threshold_missed > threshold_barely_met:
            self.safety_buffer += 0.1
        self.safety_buffer = max(0, min(self.safety_buffer, self.n - self.m))

class Strategy_AGGRESSIVE_103(BaseStrategy):
    """
    Threshold Predator: An aggressive exploitative strategy that free-rides on cooperative players
    while minimizing personal risk. Defaults to defection and only cooperates when pivotal.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.opponent_cooperation_rates = np.zeros(self.n - 1)
        self.threshold_failures = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        round_num = history.round_number + 1
        expected_cooperators = self._estimate_expected_cooperators(history, round_num)
        if round_num == self.r:
            return self._final_round_decision(expected_cooperators)
        return self._adaptive_exploitation_decision(history, expected_cooperators, round_num)

    def _estimate_expected_cooperators(self, history: PlayerHistory, round_num: int) -> float:
        """Estimate expected number of cooperating opponents."""
        expected_others = 0.0
        for opponent_idx in range(self.n - 1):
            cooperations = np.sum(history.opponent_actions[:, opponent_idx])
            base_rate = cooperations / history.round_number
            if history.round_number >= 3:
                recent_cooperations = np.sum(history.opponent_actions[-3:, opponent_idx])
                recent_rate = recent_cooperations / min(3, history.round_number)
                adjusted_rate = (base_rate + 2 * recent_rate) / 3
            else:
                adjusted_rate = base_rate
            if history.round_number >= 2:
                if np.all(history.opponent_actions[-2:, opponent_idx]):
                    adjusted_rate = min(1.0, adjusted_rate * 1.2)
            if history.round_number > 0:
                last_round_cooperators = 1 if history.my_actions[-1] else 0
                last_round_cooperators += np.sum(history.opponent_actions[-1, :])
                if last_round_cooperators < self.m:
                    self.threshold_failures += 1
                    adjusted_rate = min(1.0, adjusted_rate * 1.4)
            expected_others += adjusted_rate
        return expected_others

    def _adaptive_exploitation_decision(self, history: PlayerHistory, expected_others: float, round_num: int) -> Action:
        """Core adaptive exploitation logic for rounds 2 to r-1."""
        if expected_others >= self.m:
            return Action.D
        elif expected_others >= self.m - 1:
            if expected_others + 0.5 > self.m + 0.3:
                return Action.D
            else:
                return Action.C
        elif expected_others >= self.m - 2 and round_num > self.r / 2:
            my_coop_rate = np.sum(history.my_actions) / history.round_number
            avg_opponent_rate = np.mean([np.sum(history.opponent_actions[:, i]) / history.round_number for i in range(self.n - 1)])
            if my_coop_rate < avg_opponent_rate - 0.2:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _final_round_decision(self, expected_others: float) -> Action:
        """Final round decision with end-game defection adjustment."""
        avg_opponent_rate = np.mean([np.sum(self.opponent_cooperation_rates[i:i + 1]) for i in range(len(self.opponent_cooperation_rates))])
        defection_spike = min(0.4, avg_opponent_rate * 0.3)
        expected_final = expected_others * (1 - defection_spike)
        if expected_final >= self.m:
            return Action.D
        elif expected_final >= self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_AGGRESSIVE_104(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Threshold Predator"
    
    Aggressively exploits cooperation opportunities while minimizing personal risk.
    Uses statistical estimation to identify when to be the decisive cooperator.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        m_ratio = self.m / self.n
        if m_ratio > 0.7:
            self.base_threshold_prob = 0.7
        elif self.k < 1.5:
            self.base_threshold_prob = 0.4
        else:
            self.base_threshold_prob = 0.6

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        if current_round < 3:
            return Action.D
        if current_round >= self.r - 2:
            if current_round == self.r - 1:
                return Action.D
            else:
                recent_coop = sum(history.opponent_actions[-1, :])
                return Action.C if recent_coop >= self.m - 1 else Action.D
        recent_coop = sum(history.opponent_actions[-1, :])
        total_opponent_actions = history.opponent_actions.flatten()
        cooperation_rate = np.mean(total_opponent_actions) if len(total_opponent_actions) > 0 else 0.0
        threshold_prob = self._estimate_threshold_probability(cooperation_rate)
        if threshold_prob > self.base_threshold_prob and recent_coop >= self.m - 1:
            return Action.C
        elif recent_coop >= self.m:
            return Action.D
        elif recent_coop == self.m - 1 and current_round > self.r // 2:
            return Action.C
        else:
            return Action.D

    def _estimate_threshold_probability(self, cooperation_rate: float) -> float:
        """Estimate probability that exactly (m-1) others will cooperate using binomial approximation."""
        n_others = self.n - 1
        target = self.m - 1
        if cooperation_rate == 0:
            return 1.0 if target == 0 else 0.0
        if cooperation_rate == 1:
            return 1.0 if target == n_others else 0.0
        if n_others * cooperation_rate > 5 and n_others * (1 - cooperation_rate) > 5:
            mean = n_others * cooperation_rate
            variance = n_others * cooperation_rate * (1 - cooperation_rate)
            std_dev = math.sqrt(variance)
            z1 = (target - 0.5 - mean) / std_dev if std_dev > 0 else 0
            z2 = (target + 0.5 - mean) / std_dev if std_dev > 0 else 0
            prob = max(0.0, min(1.0, 0.4 * math.exp(-0.5 * min(z1 * z1, z2 * z2))))
        elif target > n_others:
            prob = 0.0
        else:
            prob = cooperation_rate ** target * (1 - cooperation_rate) ** (n_others - target)
            if target > 0 and target < n_others:
                prob *= min(n_others, 10)
        return min(1.0, prob)

class Strategy_AGGRESSIVE_105(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Opportunistic Predator"
    
    Maximizes exploitation with calculated risk, free-riding on others' cooperation
    whenever possible while only contributing when absolutely necessary for personal gain.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.opponent_cooperation_rates = np.zeros(self.n_players - 1)
        self.opponent_patterns = ['unknown'] * (self.n_players - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round <= 3:
            self._update_opponent_analysis(history)
            return Action.D
        self._update_opponent_analysis(history)
        if current_round >= self.n_rounds - 2:
            return self._endgame_strategy(history, current_round)
        return self._exploitation_strategy(history, current_round)

    def _update_opponent_analysis(self, history: PlayerHistory):
        """Update opponent cooperation rates and classify behavior patterns."""
        if history.round_number == 0:
            return
        for i in range(self.n_players - 1):
            self.opponent_cooperation_rates[i] = np.mean(history.opponent_actions[:, i])
            coop_rate = self.opponent_cooperation_rates[i]
            if coop_rate >= 0.8:
                self.opponent_patterns[i] = 'sucker'
            elif coop_rate >= 0.6:
                self.opponent_patterns[i] = 'calculator'
            elif coop_rate >= 0.3:
                self.opponent_patterns[i] = 'mirror'
            else:
                self.opponent_patterns[i] = 'defector'

    def _count_recent_cooperators(self, history: PlayerHistory) -> int:
        """Count cooperators in the most recent round."""
        if history.round_number == 0:
            return 0
        return int(np.sum(history.opponent_actions[-1, :]))

    def _estimate_likely_cooperators(self, history: PlayerHistory) -> int:
        """Estimate how many opponents will likely cooperate next round."""
        if history.round_number == 0:
            return 0
        predicted_cooperators = 0
        recent_total_cooperators = self._count_recent_cooperators(history) + (1 if history.my_actions[-1] else 0)
        for i in range(self.n_players - 1):
            pattern = self.opponent_patterns[i]
            coop_rate = self.opponent_cooperation_rates[i]
            if pattern == 'sucker':
                predicted_cooperators += 1 if random.random() < 0.9 else 0
            elif pattern == 'calculator':
                predicted_cooperators += 1 if recent_total_cooperators >= self.m - 1 and random.random() < 0.7 else 0
            elif pattern == 'mirror':
                majority_cooperated = recent_total_cooperators > self.n_players / 2
                predicted_cooperators += 1 if majority_cooperated and random.random() < 0.6 else 0
        return predicted_cooperators

    def _exploitation_strategy(self, history: PlayerHistory, current_round: int) -> Action:
        """Main exploitation phase strategy."""
        predicted_cooperators = self._estimate_likely_cooperators(history)
        rounds_remaining = self.n_rounds - current_round
        if predicted_cooperators >= self.m:
            return Action.D
        if predicted_cooperators == self.m - 1:
            if self.k > 1.5 and rounds_remaining > 2:
                expected_benefit = self.k
                cooperation_cost = 1
                if expected_benefit > cooperation_cost * 1.2:
                    return Action.C
            return Action.D
        return Action.D

    def _endgame_strategy(self, history: PlayerHistory, current_round: int) -> Action:
        """Endgame manipulation for last 2 rounds."""
        if current_round == self.n_rounds - 1:
            return Action.D
        predicted_cooperators = self._estimate_likely_cooperators(history)
        recent_cooperators = self._count_recent_cooperators(history)
        if history.round_number >= 3:
            recent_rounds = min(3, history.round_number)
            recent_threshold_met = 0
            for i in range(recent_rounds):
                round_cooperators = int(np.sum(history.opponent_actions[-(i + 1), :])) + (1 if history.my_actions[-(i + 1)] else 0)
                if round_cooperators >= self.m:
                    recent_threshold_met += 1
            threshold_consistency = recent_threshold_met / recent_rounds
            if threshold_consistency >= 0.7:
                return Action.D
        if predicted_cooperators == self.m - 1 and self.k > 1.8:
            return Action.C
        return Action.D

class Strategy_AGGRESSIVE_106(BaseStrategy):
    """
    Aggressive Threshold Exploitation Strategy.
    
    Aggressively exploits the collective risk structure by minimizing personal 
    contributions while maximizing free-riding opportunities. Assumes others will 
    eventually cooperate due to risk aversion, then ruthlessly capitalizes on 
    their cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        n = game_description.n_players
        r = game_description.n_rounds
        m = game_description.m
        self.safety_threshold = max(0.6, m / n + 0.1)
        self.failure_tolerance = max(1, math.floor(r / 5))
        self.exploitation_floor = max(1, math.floor(m / 3))
        self.lookback_window = min(r - 1, max(3, math.floor(r / 4)))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        final_round = self.game_description.n_rounds
        m = self.game_description.m
        if current_round == final_round:
            historical_cooperation_rate = self._calculate_historical_cooperation_rate(history)
            if historical_cooperation_rate >= self.safety_threshold:
                return Action.D
            else:
                return Action.C
        cooperation_count = self._count_cooperators_last_round(history)
        recent_failures = self._count_recent_threshold_failures(history)
        if cooperation_count >= m:
            return Action.D
        elif cooperation_count >= m - 1:
            if recent_failures >= self.failure_tolerance:
                return Action.C
            else:
                return Action.D
        elif cooperation_count <= self.exploitation_floor:
            return Action.C
        else:
            return Action.D

    def _count_cooperators_last_round(self, history: PlayerHistory) -> int:
        """Count how many opponents cooperated in the last round."""
        if len(history.opponent_actions) == 0:
            return 0
        last_round_actions = history.opponent_actions[-1, :]
        cooperation_count = int(np.sum(last_round_actions))
        if history.my_actions[-1]:
            cooperation_count += 1
        return cooperation_count

    def _calculate_historical_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate overall historical cooperation rate across all players."""
        if len(history.my_actions) == 0:
            return 0.0
        total_opponent_cooperations = int(np.sum(history.opponent_actions))
        total_my_cooperations = int(np.sum(history.my_actions))
        total_cooperations = total_opponent_cooperations + total_my_cooperations
        total_possible = len(history.my_actions) * self.game_description.n_players
        return total_cooperations / total_possible if total_possible > 0 else 0.0

    def _count_recent_threshold_failures(self, history: PlayerHistory) -> int:
        """Count how many times the threshold was not met in recent rounds."""
        if len(history.my_actions) == 0:
            return 0
        failures = 0
        rounds_to_check = min(self.lookback_window, len(history.my_actions))
        for i in range(rounds_to_check):
            round_idx = -(i + 1)
            opponent_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
            my_cooperation = int(history.my_actions[round_idx])
            total_cooperators = opponent_cooperators + my_cooperation
            if total_cooperators < self.game_description.m:
                failures += 1
        return failures

class Strategy_AGGRESSIVE_107(BaseStrategy):
    """
    Aggressive Threshold Exploitation Strategy - minimizes personal contributions while
    maximizing probability of reaping collective rewards through calculated selfishness.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.defection_bias = 0.8
        self.cooperation_threshold = self.m - 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        prev_round_idx = history.round_number - 1
        opponent_cooperators = sum(history.opponent_actions[prev_round_idx, :])
        my_prev_action = history.my_actions[prev_round_idx]
        total_cooperators = opponent_cooperators + (1 if my_prev_action else 0)
        if total_cooperators == self.cooperation_threshold:
            return Action.C
        if history.round_number > 0:
            total_cooperation_history = []
            for round_idx in range(history.round_number):
                round_cooperators = sum(history.opponent_actions[round_idx, :])
                if history.my_actions[round_idx]:
                    round_cooperators += 1
                total_cooperation_history.append(round_cooperators)
            avg_cooperation = np.mean(total_cooperation_history)
        else:
            avg_cooperation = 0
        phase1_end = max(1, self.r // 3)
        if current_round < phase1_end:
            if total_cooperators == self.cooperation_threshold:
                return Action.C
            return Action.D
        phase2_end = max(phase1_end + 1, 2 * self.r // 3)
        if current_round < phase2_end:
            if avg_cooperation > self.m + 1:
                return Action.D if random.random() < 0.9 else Action.C
            if total_cooperators == self.cooperation_threshold:
                return Action.C
            return Action.D
        else:
            if total_cooperators <= self.cooperation_threshold:
                return Action.C
            return Action.D if random.random() < 0.85 else Action.C

class Strategy_AGGRESSIVE_108(BaseStrategy):
    """
    Threshold Vulture: Aggressively exploits cooperative players while minimizing personal risk.
    Defects by default, only cooperates when exactly m-1 players cooperated in the previous round
    (being the pivotal cooperator). Uses adaptive rules for momentum detection and edge cases.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        prev_cooperators = int(sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            prev_cooperators += 1
        if prev_cooperators >= self.m:
            return Action.D
        elif prev_cooperators == self.m - 1:
            decision = Action.C
        else:
            decision = Action.D
        if len(history.my_actions) >= 2:
            prev_prev_cooperators = int(sum(history.opponent_actions[-2, :]))
            if history.my_actions[-2]:
                prev_prev_cooperators += 1
            if prev_cooperators - prev_prev_cooperators >= 2:
                return Action.D
            if prev_prev_cooperators - prev_cooperators >= 3:
                return Action.D
        if self.n <= 4 and prev_cooperators == self.m - 2:
            if len(history.my_actions) >= 3:
                recent_coop_rates = []
                for i in range(max(0, len(history.my_actions) - 3), len(history.my_actions)):
                    round_cooperators = int(sum(history.opponent_actions[i, :]))
                    if history.my_actions[i]:
                        round_cooperators += 1
                    recent_coop_rates.append(round_cooperators)
                if sum(recent_coop_rates) / len(recent_coop_rates) >= 2:
                    decision = Action.C
        if self.m > self.n / 2:
            if prev_cooperators != self.m - 1:
                return Action.D
        if self.k < 1.5:
            if prev_cooperators == self.m - 1:
                threshold_met_count = 0
                for i in range(len(history.my_actions)):
                    round_cooperators = int(sum(history.opponent_actions[i, :]))
                    if history.my_actions[i]:
                        round_cooperators += 1
                    if round_cooperators >= self.m:
                        threshold_met_count += 1
                threshold_rate = threshold_met_count / len(history.my_actions)
                if threshold_rate < 0.6:
                    return Action.D
            else:
                return Action.D
        if len(history.my_actions) >= 5:
            threshold_met_count = 0
            for i in range(len(history.my_actions)):
                round_cooperators = int(sum(history.opponent_actions[i, :]))
                if history.my_actions[i]:
                    round_cooperators += 1
                if round_cooperators >= self.m:
                    threshold_met_count += 1
            threshold_rate = threshold_met_count / len(history.my_actions)
            if threshold_rate > 0.7:
                return Action.D
        return decision

class Strategy_AGGRESSIVE_109(BaseStrategy):
    """
    Aggressive Exploitative Strategy: "Threshold Predator"
    
    This strategy aggressively exploits cooperative players while minimizing personal risk.
    It free-rides whenever possible and only cooperates when absolutely necessary to secure
    the collective reward.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = history.round_number + 1
        if current_round == r:
            return Action.D
        phase_1_end = r // 3
        phase_2_end = 2 * r // 3
        if current_round <= phase_1_end:
            return self._phase_1_decision(history, m)
        elif current_round <= phase_2_end:
            return self._phase_2_decision(history, n, m)
        else:
            return self._phase_3_decision(history, n, m, k)

    def _phase_1_decision(self, history: PlayerHistory, m: int) -> Action:
        """Phase 1: Initial exploitation with threshold monitoring"""
        threshold_met_rate = self._calculate_threshold_met_rate(history, m)
        if threshold_met_rate > 0.8:
            return Action.D
        elif threshold_met_rate < 0.5:
            return self._conditional_cooperate(history, m)
        else:
            return Action.D

    def _phase_2_decision(self, history: PlayerHistory, n: int, m: int) -> Action:
        """Phase 2: Strategic adaptation based on expected cooperators"""
        total_opponent_actions = np.sum(history.opponent_actions)
        total_opponent_decisions = history.opponent_actions.size
        avg_cooperation_rate = total_opponent_actions / total_opponent_decisions if total_opponent_decisions > 0 else 0
        expected_cooperators = (n - 1) * avg_cooperation_rate
        if expected_cooperators >= m:
            return Action.D
        elif expected_cooperators >= m - 1:
            return Action.C
        else:
            return Action.D

    def _phase_3_decision(self, history: PlayerHistory, n: int, m: int, k: float) -> Action:
        """Phase 3: Endgame exploitation with reliable cooperator tracking"""
        reliable_cooperators = self._count_reliable_cooperators(history, 0.7)
        if reliable_cooperators >= m:
            return Action.D
        elif reliable_cooperators == m - 1:
            if self._was_critical_recently(history, m):
                return Action.C
            else:
                return Action.D
        else:
            if k > 2.5 and self._should_probe(history, m):
                return Action.C
            return Action.D

    def _calculate_threshold_met_rate(self, history: PlayerHistory, m: int) -> float:
        """Calculate the rate at which the cooperation threshold was met"""
        if history.round_number == 0:
            return 0.0
        met_count = 0
        for round_idx in range(history.round_number):
            opponent_cooperators = np.sum(history.opponent_actions[round_idx, :])
            my_cooperated = history.my_actions[round_idx]
            total_cooperators = opponent_cooperators + (1 if my_cooperated else 0)
            if total_cooperators >= m:
                met_count += 1
        return met_count / history.round_number

    def _conditional_cooperate(self, history: PlayerHistory, m: int) -> Action:
        """Conditional cooperation when threshold is failing frequently"""
        if history.round_number == 0:
            return Action.D
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        if last_round_cooperators == m - 1:
            return Action.D
        else:
            return Action.C

    def _count_reliable_cooperators(self, history: PlayerHistory, threshold: float) -> int:
        """Count opponents who have cooperated above the threshold rate"""
        if history.round_number == 0:
            return 0
        reliable_count = 0
        n_opponents = history.opponent_actions.shape[1]
        for opponent_idx in range(n_opponents):
            cooperation_rate = np.mean(history.opponent_actions[:, opponent_idx])
            if cooperation_rate > threshold:
                reliable_count += 1
        return reliable_count

    def _was_critical_recently(self, history: PlayerHistory, m: int) -> bool:
        """Check if this player was critical for meeting threshold in recent rounds"""
        if history.round_number < 2:
            return False
        critical_count = 0
        for round_offset in [1, 2]:
            if history.round_number >= round_offset:
                round_idx = history.round_number - round_offset
                opponent_cooperators = np.sum(history.opponent_actions[round_idx, :])
                my_cooperated = history.my_actions[round_idx]
                if my_cooperated and opponent_cooperators == m - 1:
                    critical_count += 1
        return critical_count > 0

    def _should_probe(self, history: PlayerHistory, m: int) -> bool:
        """Determine if should make a probe cooperation attempt"""
        if history.round_number < 2:
            return False
        recent_total_cooperation = 0
        for round_offset in [1, 2]:
            if history.round_number >= round_offset:
                round_idx = history.round_number - round_offset
                recent_total_cooperation += np.sum(history.opponent_actions[round_idx, :])
                recent_total_cooperation += 1 if history.my_actions[round_idx] else 0
        return recent_total_cooperation == 0

class Strategy_AGGRESSIVE_110(BaseStrategy):
    """
    Aggressive Adaptive Exploitation Strategy (AAES)
    
    Maximizes personal gain while minimizing cooperation costs. Aggressively exploits
    cooperative opponents while quickly punishing those who try to exploit it.
    Only cooperates when expected value clearly exceeds defection payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_rounds_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = history.round_number + 1
        if current_round >= r - 1:
            return Action.D
        if self.punishment_rounds_remaining > 0:
            self.punishment_rounds_remaining -= 1
            return Action.D
        coop_rate = self._calculate_overall_cooperation_rate(history, n)
        threshold_met_rate = self._calculate_threshold_success_rate(history, m, n)
        last_round_cooperators = self._count_last_round_cooperators(history)
        if self._check_punishment_triggers(history, m, n):
            self.punishment_rounds_remaining = 1
            return Action.D
        rounds_remaining = r - current_round
        cooperation_threshold = m / n + 0.1
        if threshold_met_rate >= 0.6 and coop_rate >= cooperation_threshold and (rounds_remaining >= 3) and (last_round_cooperators >= m - 1):
            return Action.C
        else:
            return Action.D

    def _calculate_overall_cooperation_rate(self, history: PlayerHistory, n: int) -> float:
        """Calculate the overall cooperation rate across all players and rounds."""
        if history.round_number == 0:
            return 0.0
        my_coops = np.sum(history.my_actions)
        opponent_coops = np.sum(history.opponent_actions)
        total_coops = my_coops + opponent_coops
        total_decisions = n * history.round_number
        return total_coops / total_decisions if total_decisions > 0 else 0.0

    def _calculate_threshold_success_rate(self, history: PlayerHistory, m: int, n: int) -> float:
        """Calculate the rate at which the cooperation threshold was met."""
        if history.round_number == 0:
            return 0.0
        successful_rounds = 0
        for round_idx in range(history.round_number):
            my_coop = 1 if history.my_actions[round_idx] else 0
            opponent_coops = np.sum(history.opponent_actions[round_idx, :])
            total_coops = my_coop + opponent_coops
            if total_coops >= m:
                successful_rounds += 1
        return successful_rounds / history.round_number

    def _count_last_round_cooperators(self, history: PlayerHistory) -> int:
        """Count cooperators in the most recent round."""
        if history.round_number == 0:
            return 0
        last_round_idx = history.round_number - 1
        my_coop = 1 if history.my_actions[last_round_idx] else 0
        opponent_coops = np.sum(history.opponent_actions[last_round_idx, :])
        return my_coop + opponent_coops

    def _check_punishment_triggers(self, history: PlayerHistory, m: int, n: int) -> bool:
        """Check if punishment should be triggered based on recent behavior."""
        if history.round_number < 2:
            return False
        last_round_idx = history.round_number - 1
        prev_round_idx = history.round_number - 2
        last_round_coops = self._count_cooperators_in_round(history, last_round_idx)
        prev_round_coops = self._count_cooperators_in_round(history, prev_round_idx)
        if prev_round_coops >= m - 1 and last_round_coops < m:
            return True
        cooperation_drop = prev_round_coops - last_round_coops
        if cooperation_drop > 2:
            return True
        if last_round_coops == m:
            return True
        return False

    def _count_cooperators_in_round(self, history: PlayerHistory, round_idx: int) -> int:
        """Count total cooperators (including self) in a specific round."""
        if round_idx < 0 or round_idx >= history.round_number:
            return 0
        my_coop = 1 if history.my_actions[round_idx] else 0
        opponent_coops = np.sum(history.opponent_actions[round_idx, :])
        return my_coop + opponent_coops

class Strategy_AGGRESSIVE_111(BaseStrategy):
    """
    Threshold Predator: An aggressive exploitation strategy that free-rides on cooperation
    while strategically cooperating only when necessary to secure collective benefits.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.exploitation_threshold = 0.7
        self.memory_decay = 0.95

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        round_num = history.round_number
        if round_num == self.r - 1:
            return Action.D
        n_opponents = self.n - 1
        expected_cooperators = 0.0
        for opponent_idx in range(n_opponents):
            opponent_actions = history.opponent_actions[:, opponent_idx]
            total_weight = 0.0
            weighted_cooperations = 0.0
            for round_idx in range(len(opponent_actions)):
                weight = self.memory_decay ** (len(opponent_actions) - 1 - round_idx)
                total_weight += weight
                if opponent_actions[round_idx]:
                    weighted_cooperations += weight
            if total_weight > 0:
                coop_rate = weighted_cooperations / total_weight
            else:
                coop_rate = 0.5
            expected_cooperators += coop_rate
        if round_num > 0:
            last_round_cooperators = sum(history.opponent_actions[-1, :])
            if history.my_actions[-1]:
                last_round_cooperators += 1
            if last_round_cooperators >= self.m:
                self.exploitation_threshold = min(0.9, self.exploitation_threshold + 0.1)
            else:
                self.exploitation_threshold = max(0.3, self.exploitation_threshold - 0.05)
        if round_num >= 0.8 * self.r:
            self.exploitation_threshold += 0.15
            self.exploitation_threshold = min(0.95, self.exploitation_threshold)
        if round_num >= 3:
            recent_failures = 0
            for i in range(min(3, round_num)):
                past_round_idx = round_num - 1 - i
                past_cooperators = sum(history.opponent_actions[past_round_idx, :])
                if history.my_actions[past_round_idx]:
                    past_cooperators += 1
                if past_cooperators < self.m:
                    recent_failures += 1
                else:
                    break
            if recent_failures >= 3:
                self.exploitation_threshold *= 0.7
        if round_num > 0:
            last_cooperators = sum(history.opponent_actions[-1, :])
            if history.my_actions[-1]:
                last_cooperators += 1
            if last_cooperators == self.m - 1:
                self.exploitation_threshold *= 0.8
        if round_num > 0:
            last_cooperators = sum(history.opponent_actions[-1, :])
            if not history.my_actions[-1] and last_cooperators == self.m - 1:
                return Action.C
        prob_threshold_met_without_me = 1.0 if expected_cooperators >= self.m else 0.0
        prob_threshold_met_with_me = 1.0 if expected_cooperators >= self.m - 1 else 0.0
        if expected_cooperators > 0:
            if n_opponents >= 10:
                mean_coop = expected_cooperators
                variance = expected_cooperators * (1 - expected_cooperators / n_opponents)
                std_dev = math.sqrt(max(0.1, variance))
                z_without = (self.m - 0.5 - mean_coop) / std_dev if std_dev > 0 else 0
                z_with = (self.m - 1.5 - mean_coop) / std_dev if std_dev > 0 else 0
                prob_threshold_met_without_me = max(0, min(1, 0.5 - 0.5 * math.erf(z_without / math.sqrt(2))))
                prob_threshold_met_with_me = max(0, min(1, 0.5 - 0.5 * math.erf(z_with / math.sqrt(2))))
            else:
                prob_threshold_met_without_me = 1.0 if expected_cooperators >= self.m else expected_cooperators / self.m
                prob_threshold_met_with_me = 1.0 if expected_cooperators >= self.m - 1 else expected_cooperators / (self.m - 1)
        if random.random() < 0.05:
            return Action.C
        if prob_threshold_met_without_me > self.exploitation_threshold:
            return Action.D
        elif prob_threshold_met_with_me > self.exploitation_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_AGGRESSIVE_112(BaseStrategy):
    """
    Aggressive Threshold Exploitation Strategy for Collective Risk Dilemma.
    
    This strategy exploits the collective risk structure by being selectively aggressive - 
    cooperating only when absolutely necessary to secure the threshold bonus, while 
    maximizing opportunities to free-ride on others' cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number + 1
        total_players = self.n
        if history.round_number > 0:
            my_cooperations = np.sum(history.my_actions)
            opponent_cooperations = np.sum(history.opponent_actions)
            total_cooperations = my_cooperations + opponent_cooperations
            total_decisions = history.round_number * total_players
            cooperation_rate = total_cooperations / total_decisions if total_decisions > 0 else 0
            last_round_cooperators = np.sum(history.opponent_actions[-1, :])
            if history.my_actions[-1]:
                last_round_cooperators += 1
            expected_cooperators = math.floor(cooperation_rate * total_players)
            my_cooperation_rate = my_cooperations / history.round_number if history.round_number > 0 else 0
        else:
            cooperation_rate = 0
            expected_cooperators = 0
            my_cooperation_rate = 0
            last_round_cooperators = 0
        if current_round == self.r:
            return Action.D
        elif current_round == self.r - 1:
            if cooperation_rate > 0.6:
                return Action.D
            else:
                return Action.C
        cooperation_threshold = 0.3
        if self.n <= 4:
            cooperation_threshold = 0.4
        if self.m > 0.7 * self.n and current_round == 2 and (cooperation_rate > 0.8):
            return Action.C
        if self.k < 1.5:
            if expected_cooperators == self.m - 1:
                return Action.C
            else:
                return Action.D
        if expected_cooperators >= self.m + 2:
            return Action.D
        elif expected_cooperators <= self.m - 2:
            return Action.D
        elif my_cooperation_rate < cooperation_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_AGGRESSIVE_113(BaseStrategy):
    """
    Aggressive Exploitative Strategy: "Threshold Hawk"
    
    This strategy maximizes individual payoff by aggressively exploiting cooperative players
    while minimizing personal risk. It free-rides whenever possible, only cooperating when
    absolutely necessary to secure the collective reward.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.reliable_cooperators = set()
        self.punishment_rounds_left = 0
        self.consecutive_failures = 0
        self.chaos_mode_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        n_players = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        total_rounds = self.game_description.n_rounds
        if current_round == total_rounds - 1:
            return Action.D
        self._update_reliable_cooperators(history)
        self._update_failure_tracking(history)
        if self.chaos_mode_rounds > 0:
            self.chaos_mode_rounds -= 1
            return Action.D
        prev_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            prev_cooperators += 1
        if len(history.opponent_actions) > 0 and np.all(history.opponent_actions[-1, :]):
            return Action.D
        expected_cooperators = self._calculate_expected_cooperators(history)
        my_likely_contribution = 1 if not self._in_punishment_mode() else 0
        expected_cooperators_without_me = expected_cooperators - my_likely_contribution
        if expected_cooperators_without_me >= m:
            return Action.D
        elif expected_cooperators_without_me == m - 1:
            if self._in_endgame(current_round, total_rounds):
                confidence = self._calculate_prediction_confidence(history)
                if confidence > 0.8:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.C
        else:
            return Action.D

    def _update_reliable_cooperators(self, history: PlayerHistory):
        """Track players who cooperate >70% of the time"""
        n_opponents = self.game_description.n_players - 1
        total_rounds_played = len(history.my_actions)
        for opponent_idx in range(n_opponents):
            cooperation_rate = np.mean(history.opponent_actions[:, opponent_idx])
            if cooperation_rate > 0.7:
                self.reliable_cooperators.add(opponent_idx)
            elif cooperation_rate < 0.5:
                self.reliable_cooperators.discard(opponent_idx)

    def _update_failure_tracking(self, history: PlayerHistory):
        """Track consecutive threshold failures and activate chaos mode if needed"""
        if len(history.my_actions) == 0:
            return
        last_round_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            last_round_cooperators += 1
        if last_round_cooperators < self.game_description.m:
            self.consecutive_failures += 1
            if self.consecutive_failures >= 3:
                self.chaos_mode_rounds = 2
                self.consecutive_failures = 0
        else:
            self.consecutive_failures = 0
        if self.punishment_rounds_left > 0:
            self.punishment_rounds_left -= 1
        if len(history.my_actions) > 0 and history.my_actions[-1] and (last_round_cooperators == self.game_description.m - 1):
            self.punishment_rounds_left = 2

    def _calculate_expected_cooperators(self, history: PlayerHistory):
        """Calculate expected number of cooperators based on historical data and trends"""
        if len(history.my_actions) == 0:
            return self.game_description.n_players // 2
        prev_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            prev_cooperators += 1
        trend = 0
        if len(history.my_actions) >= 2:
            prev_prev_cooperators = int(np.sum(history.opponent_actions[-2, :]))
            if history.my_actions[-2]:
                prev_prev_cooperators += 1
            trend = prev_cooperators - prev_prev_cooperators
        total_rounds = len(history.my_actions)
        avg_opponent_cooperation = np.mean(history.opponent_actions)
        avg_my_cooperation = np.mean(history.my_actions)
        avg_total_cooperation = avg_opponent_cooperation * (self.game_description.n_players - 1) + avg_my_cooperation
        reliable_count = len(self.reliable_cooperators)
        base_prediction = 0.8 * prev_cooperators + 0.2 * avg_total_cooperation
        base_prediction += 0.1 * trend
        base_prediction = max(base_prediction, reliable_count)
        expected = max(0, min(self.game_description.n_players, base_prediction))
        return expected

    def _calculate_prediction_confidence(self, history: PlayerHistory):
        """Calculate confidence in cooperation prediction based on historical variance"""
        if len(history.my_actions) < 3:
            return 0.5
        recent_rounds = min(5, len(history.my_actions))
        cooperation_counts = []
        for i in range(recent_rounds):
            round_idx = -(i + 1)
            cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
            if history.my_actions[round_idx]:
                cooperators += 1
            cooperation_counts.append(cooperators)
        variance = np.var(cooperation_counts)
        confidence = max(0.1, min(1.0, 1.0 - variance / 10.0))
        return confidence

    def _in_punishment_mode(self):
        """Check if currently in punishment mode"""
        return self.punishment_rounds_left > 0

    def _in_endgame(self, current_round, total_rounds):
        """Check if in the final 20% of rounds"""
        return current_round >= int(0.8 * total_rounds)

class Strategy_AGGRESSIVE_114(BaseStrategy):
    """
    Threshold Hawk: An aggressive exploitation strategy that defects most of the time,
    only cooperating when absolutely necessary to reach the threshold for personal benefit.
    Exploits cooperative players while minimizing personal risk across three phases.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.phase1_end = math.floor(self.r / 3)
        self.phase2_end = math.floor(2 * self.r / 3)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        if current_round < self.phase1_end:
            return Action.D
        if current_round >= self.phase2_end:
            return Action.D
        return self._phase2_decision(history)

    def _phase2_decision(self, history: PlayerHistory) -> Action:
        cooperation_rates = np.mean(history.opponent_actions, axis=0)
        reliable_cooperators = np.sum(cooperation_rates >= 0.6)
        expected_cooperators = reliable_cooperators
        if expected_cooperators >= self.m:
            return Action.D
        if expected_cooperators == self.m - 1:
            if len(history.my_actions) > 0:
                last_round_cooperators = np.sum(history.opponent_actions[-1, :])
                last_round_threshold_met = last_round_cooperators + int(history.my_actions[-1]) >= self.m
                my_last_action_defect = not history.my_actions[-1]
                if last_round_threshold_met and my_last_action_defect:
                    return Action.D
                else:
                    return Action.C
            else:
                return Action.C
        return Action.D

class Strategy_AGGRESSIVE_115(BaseStrategy):
    """
    Threshold Predator: Aggressive exploitation strategy that maximizes personal payoffs
    by strategically free-riding on others' cooperation while maintaining collective benefits
    when absolutely necessary.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number + 1
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        k = self.game_description.k
        if current_round == r:
            return Action.D
        cooperators_last_round = sum(history.opponent_actions[-1, :])
        cpi = cooperators_last_round / max(m - 1, 1)
        if cpi >= 1.2:
            return Action.D
        elif 0.8 <= cpi < 1.2:
            if random.random() < 0.8:
                return Action.D
            else:
                return Action.C
        else:
            cooperation_deficit = m - cooperators_last_round
            my_cooperations = sum(history.my_actions)
            my_cooperation_history_ratio = my_cooperations / current_round if current_round > 0 else 0
            if cooperation_deficit >= n // 2 and my_cooperation_history_ratio < 0.3:
                return Action.C
            else:
                return Action.D

class Strategy_AGGRESSIVE_116(BaseStrategy):
    """
    Opportunistic Defector: An aggressive strategy that primarily defects while 
    opportunistically exploiting cooperative behavior from others. Defects by default
    but uses strategic cooperation only when necessary to prevent catastrophic failure.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        return self._middle_round_decision(history)

    def _middle_round_decision(self, history: PlayerHistory) -> Action:
        recent_cooperators = self._get_recent_cooperators(history)
        cooperation_trend = self._get_cooperation_trend(history)
        if recent_cooperators >= self.m + 2:
            return Action.D
        elif recent_cooperators >= self.m + 1:
            if cooperation_trend <= 0:
                return Action.D
            else:
                return Action.D
        elif recent_cooperators >= self.m:
            if cooperation_trend < -1:
                return Action.C
            else:
                return Action.D
        elif recent_cooperators >= self.m - 2:
            return Action.C
        else:
            return Action.D

    def _get_recent_cooperators(self, history: PlayerHistory) -> float:
        """Calculate average number of cooperators in last 3 rounds (or all available)."""
        rounds_completed = history.round_number
        look_back = min(3, rounds_completed)
        if look_back == 0:
            return 0.0
        recent_actions = history.opponent_actions[-look_back:, :]
        cooperators_per_round = np.sum(recent_actions, axis=1)
        return float(np.mean(cooperators_per_round))

    def _get_cooperation_trend(self, history: PlayerHistory) -> float:
        """Calculate change in cooperators from 3 rounds ago to last round."""
        rounds_completed = history.round_number
        if rounds_completed < 2:
            return 0.0
        recent_cooperators = float(np.sum(history.opponent_actions[-1, :]))
        trend_start = min(3, rounds_completed - 1)
        old_cooperators = float(np.sum(history.opponent_actions[-(trend_start + 1), :]))
        return recent_cooperators - old_cooperators

class Strategy_AGGRESSIVE_117(BaseStrategy):
    """
    AGGRESSIVE PREDATORY STRATEGY: "THRESHOLD SHARK"
    
    Maximizes personal gain through strategic exploitation and minimal cooperation.
    Defects by default, only cooperating when absolutely necessary to preserve
    the threshold reward for continued exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        if current_round >= self.r - 1:
            return Action.D
        if current_round >= self.r - 2:
            reliable_cooperators = self._count_reliable_cooperators(history)
            if reliable_cooperators >= self.m - 1:
                return Action.D
            else:
                expected_payoff = self._calculate_cooperation_value(reliable_cooperators)
                return Action.C if expected_payoff > 1 else Action.D
        last_round_cooperators = self._count_last_round_cooperators(history)
        if last_round_cooperators == self.m - 1 and self._threshold_likely_sustainable(history):
            return Action.C
        return Action.D

    def _count_last_round_cooperators(self, history: PlayerHistory) -> int:
        """Count cooperators in the most recent round"""
        if history.round_number == 0:
            return 0
        return int(np.sum(history.opponent_actions[-1, :]))

    def _count_reliable_cooperators(self, history: PlayerHistory) -> int:
        """Count opponents with >66% cooperation rate in last 3 rounds"""
        if history.round_number < 2:
            return 0
        look_back = min(3, history.round_number)
        recent_actions = history.opponent_actions[-look_back:, :]
        cooperation_rates = np.mean(recent_actions, axis=0)
        reliable_count = np.sum(cooperation_rates > 0.66)
        return int(reliable_count)

    def _threshold_likely_sustainable(self, history: PlayerHistory) -> bool:
        """Assess if the threshold pattern suggests sustainability"""
        if history.round_number < 2:
            return True
        look_back = min(3, history.round_number)
        recent_cooperators = []
        for i in range(look_back):
            round_idx = -(i + 1)
            cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
            recent_cooperators.append(cooperators)
        avg_cooperators = np.mean(recent_cooperators)
        return avg_cooperators >= self.m - 1.5

    def _calculate_cooperation_value(self, reliable_cooperators: int) -> float:
        """Calculate expected payoff from cooperating vs defecting"""
        additional_cooperators_needed = max(0, self.m - 1 - reliable_cooperators)
        remaining_players = self.n - 1 - reliable_cooperators
        if additional_cooperators_needed == 0:
            prob_threshold_met = 1.0
        elif remaining_players == 0:
            prob_threshold_met = 0.0
        else:
            prob_threshold_met = min(1.0, remaining_players * 0.3 / additional_cooperators_needed)
        expected_payoff = 1 - 1 + prob_threshold_met * self.k
        return expected_payoff

class Strategy_AGGRESSIVE_118(BaseStrategy):
    """
    Aggressive Adaptive Threshold Strategy (AATS) - Aggressively maximizes individual payoff 
    by exploiting cooperative players while minimizing personal risk. Cooperates only when 
    highly confident of success, otherwise defects to maximize individual gain.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        aggression_bonus = 0.1 + (self.k - 1) * 0.05
        self.exploitation_threshold = max(0.3, min(0.7, self.m / self.n - aggression_bonus))
        self.initial_threshold = self.exploitation_threshold
        if self.n <= 4:
            self.exploitation_threshold = 0.5
        if self.k < 1.5:
            self.exploitation_threshold += 0.1
        self.consecutive_misses = 0
        self.prediction_errors = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        if self._should_emergency_defect(history):
            return Action.D
        predicted_cooperators = self._predict_cooperators(history)
        cooperation_trend = self._calculate_cooperation_trend(history)
        cooperation_threshold = self.m - 1
        if self.n <= 4:
            cooperation_threshold = self.m
        should_cooperate = predicted_cooperators >= cooperation_threshold and cooperation_trend > self.exploitation_threshold
        if self.m > self.n * 0.6:
            recent_success_rate = self._calculate_recent_success_rate(history)
            should_cooperate = should_cooperate and recent_success_rate > 0.8 and (predicted_cooperators >= self.m)
        self._update_thresholds(history)
        return Action.C if should_cooperate else Action.D

    def _predict_cooperators(self, history: PlayerHistory) -> int:
        """Predict number of cooperators using weighted recent cooperation rates."""
        predicted = 0
        n_opponents = self.n - 1
        for opponent_idx in range(n_opponents):
            recent_rounds = min(3, len(history.my_actions))
            recent_actions = history.opponent_actions[-recent_rounds:, opponent_idx]
            weighted_sum = 0
            weight_sum = 0
            for i, action in enumerate(recent_actions):
                weight = 2 ** i
                weighted_sum += action * weight
                weight_sum += weight
            cooperation_rate = weighted_sum / weight_sum if weight_sum > 0 else 0
            if cooperation_rate > 0.6:
                predicted += 1
        return predicted

    def _calculate_cooperation_trend(self, history: PlayerHistory) -> float:
        """Calculate weighted average cooperation rate of opponents over recent rounds."""
        if len(history.my_actions) == 0:
            return 0.0
        recent_rounds = min(3, len(history.my_actions))
        recent_cooperation_rates = []
        for round_idx in range(-recent_rounds, 0):
            round_cooperators = sum(history.opponent_actions[round_idx, :])
            rate = round_cooperators / (self.n - 1)
            recent_cooperation_rates.append(rate)
        weighted_sum = 0
        weight_sum = 0
        for i, rate in enumerate(recent_cooperation_rates):
            weight = 2 ** i
            weighted_sum += rate * weight
            weight_sum += weight
        return weighted_sum / weight_sum if weight_sum > 0 else 0.0

    def _should_emergency_defect(self, history: PlayerHistory) -> bool:
        """Check emergency defection conditions."""
        if len(history.my_actions) == 0:
            return False
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if last_round_cooperators / (self.n - 1) < 0.4:
            return True
        predicted = self._predict_cooperators(history)
        if predicted < self.m - 2:
            return True
        return False

    def _calculate_recent_success_rate(self, history: PlayerHistory) -> float:
        """Calculate success rate of recent rounds where threshold was attempted."""
        if len(history.my_actions) < 2:
            return 1.0
        successes = 0
        attempts = 0
        for round_idx in range(len(history.my_actions)):
            cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            attempts += 1
            if cooperators >= self.m:
                successes += 1
        return successes / attempts if attempts > 0 else 1.0

    def _update_thresholds(self, history: PlayerHistory) -> None:
        """Update exploitation threshold based on prediction accuracy."""
        if len(history.my_actions) < 2:
            return
        last_round_actual = sum(history.opponent_actions[-1, :])
        last_round_predicted = self._predict_cooperators_for_round(history, -2)
        error = last_round_predicted - last_round_actual
        self.prediction_errors.append(error)
        if len(self.prediction_errors) > 5:
            self.prediction_errors = self.prediction_errors[-5:]
        if len(self.prediction_errors) >= 3:
            avg_error = sum(self.prediction_errors) / len(self.prediction_errors)
            if avg_error > 1:
                self.exploitation_threshold = min(self.initial_threshold + 0.2, self.exploitation_threshold + 0.05)
            elif avg_error < -1:
                self.exploitation_threshold = max(self.initial_threshold - 0.2, self.exploitation_threshold - 0.05)

    def _predict_cooperators_for_round(self, history: PlayerHistory, round_idx: int) -> int:
        """Predict cooperators for a specific historical round."""
        if round_idx >= 0 or abs(round_idx) > len(history.my_actions):
            return 0
        predicted = 0
        n_opponents = self.n - 1
        available_rounds = abs(round_idx) - 1
        if available_rounds <= 0:
            return n_opponents // 2
        for opponent_idx in range(n_opponents):
            recent_rounds = min(3, available_rounds)
            start_idx = round_idx - recent_rounds
            recent_actions = history.opponent_actions[start_idx:round_idx, opponent_idx]
            cooperation_rate = sum(recent_actions) / len(recent_actions) if len(recent_actions) > 0 else 0.5
            if cooperation_rate > 0.6:
                predicted += 1
        return predicted

class Strategy_AGGRESSIVE_119(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Threshold Predator"
    
    This strategy aggressively exploits cooperative players while minimizing personal risk.
    It aims to maximize payoffs by contributing only when absolutely necessary while 
    free-riding whenever possible.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number + 1
        if history is None:
            return Action.D
        if current_round == r:
            return Action.D
        my_last_action = history.my_actions[-1]
        opponent_cooperators = np.sum(history.opponent_actions[-1, :])
        total_cooperators = opponent_cooperators + (1 if my_last_action else 0)
        coop_count = int(opponent_cooperators)
        if 2 <= current_round <= 4 and coop_count >= m - 1 and (random.random() < 0.2):
            return Action.C
        if coop_count >= m:
            return Action.D
        elif coop_count == m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_AGGRESSIVE_120(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Predatory Opportunist"
    
    Operates on maximum personal gain through calculated exploitation.
    Cooperates only when absolutely necessary to trigger collective rewards
    that can be personally captured through defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.phase1_end = max(1, self.n_rounds // 3)
        self.phase2_end = max(2, 2 * self.n_rounds // 3)
        self.player_cooperation_counts = None
        self.reliable_cooperators = set()

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.player_cooperation_counts = np.zeros(self.n_players - 1)
            return Action.D
        current_round = history.round_number
        prev_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            prev_cooperators += 1
        if current_round <= self.phase1_end:
            self.player_cooperation_counts += history.opponent_actions[-1, :]
        if current_round <= self.phase1_end:
            return self._phase1_decision(prev_cooperators, current_round)
        if current_round == self.phase1_end + 1:
            cooperation_rates = self.player_cooperation_counts / self.phase1_end
            self.reliable_cooperators = set(np.where(cooperation_rates >= 0.6)[0])
        if current_round <= self.phase2_end:
            return self._phase2_decision(prev_cooperators, history)
        return self._phase3_decision(prev_cooperators, current_round, history)

    def _phase1_decision(self, prev_cooperators, current_round):
        """Phase 1: Test opponents while maximizing early gains"""
        if current_round == 1:
            return Action.D
        if prev_cooperators == self.m - 1:
            return Action.C
        return Action.D

    def _phase2_decision(self, prev_cooperators, history):
        """Phase 2: Exploit identified cooperators"""
        reliable_count = len(self.reliable_cooperators)
        if reliable_count >= self.m:
            return Action.D
        if reliable_count == self.m - 1:
            if prev_cooperators == self.m - 2:
                return Action.C
            return Action.D
        if prev_cooperators + reliable_count < self.m:
            return Action.C
        return Action.D

    def _phase3_decision(self, prev_cooperators, current_round, history):
        """Phase 3: Endgame exploitation with maximum extraction"""
        if current_round == self.n_rounds:
            return Action.D
        rounds_left = self.n_rounds - current_round
        if rounds_left <= 2:
            if prev_cooperators == self.m - 1 and self.k > 1:
                return Action.C
            return Action.D
        return self._dynamic_threshold_decision(prev_cooperators)

    def _dynamic_threshold_decision(self, prev_cooperators):
        """Dynamic threshold management based on cooperation levels"""
        if prev_cooperators >= self.m + 2:
            return Action.D
        elif prev_cooperators >= self.m + 1:
            return Action.D
        elif prev_cooperators == self.m:
            return Action.D
        elif prev_cooperators == self.m - 1:
            return Action.C
        else:
            return Action.C

class Strategy_AGGRESSIVE_121(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "PREDATOR"
    
    Treats the game as zero-sum competition, aggressively exploiting cooperative players
    while minimizing personal risk. Always defects in first and last rounds, and
    strategically exploits threshold dynamics in between.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        m = self.game_description.m
        if last_round_cooperators >= m:
            return Action.D
        if last_round_cooperators == m - 1:
            return Action.C
        if last_round_cooperators > m + 1:
            return Action.D
        if last_round_cooperators < m - 2:
            return Action.D
        return Action.D

class Strategy_AGGRESSIVE_122(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Threshold Hawk"
    
    Maximizes individual payoffs by exploiting cooperative players while minimizing 
    personal risk through conditional parasitism - cooperate only when absolutely 
    necessary to secure collective reward, otherwise defect and free-ride.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if history is None or current_round <= 1:
            return Action.D
        if current_round >= self.r - 2:
            if current_round == self.r - 1:
                return Action.D
            else:
                recent_coop_rate = self._get_recent_cooperation_rate(history, 3)
                predicted_cooperators = max(1, int(recent_coop_rate * (self.n - 1)))
                if predicted_cooperators < self.m - 1:
                    return Action.D
                elif predicted_cooperators == self.m - 1:
                    return Action.C if self.k > 2.0 else Action.D
                else:
                    return Action.D
        return self._adaptive_threshold_riding(history)

    def _adaptive_threshold_riding(self, history: PlayerHistory) -> Action:
        last_round_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        predicted_cooperators = self._predict_cooperators(history)
        buffer_zone = self.m + 1
        critical_threshold = self.m - 1
        if predicted_cooperators > buffer_zone:
            return Action.D
        elif predicted_cooperators >= self.m:
            trend = self._get_cooperation_trend(history)
            return Action.D if trend >= 0 else Action.C
        elif predicted_cooperators == critical_threshold:
            if self.k > 1.5:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _predict_cooperators(self, history: PlayerHistory) -> int:
        """Predict number of cooperators based on recent behavior patterns."""
        if len(history.my_actions) < 3:
            return int(np.sum(history.opponent_actions[-1, :]))
        recent_rounds = min(3, len(history.my_actions))
        cooperator_predictions = 0
        for player in range(self.n - 1):
            recent_actions = history.opponent_actions[-recent_rounds:, player]
            coop_rate = np.mean(recent_actions)
            if coop_rate > 0.66:
                cooperator_predictions += 0.8
            elif coop_rate > 0.33:
                cooperator_predictions += 0.5
            else:
                cooperator_predictions += 0.2
        return max(0, min(self.n - 1, int(cooperator_predictions)))

    def _get_cooperation_trend(self, history: PlayerHistory) -> float:
        """Calculate trend in cooperation rate over recent rounds."""
        if len(history.my_actions) < 3:
            return 0.0
        recent_rounds = min(4, len(history.my_actions))
        cooperation_rates = []
        for i in range(recent_rounds):
            round_idx = -(recent_rounds - i)
            coop_count = np.sum(history.opponent_actions[round_idx, :])
            coop_rate = coop_count / (self.n - 1)
            cooperation_rates.append(coop_rate)
        if len(cooperation_rates) < 2:
            return 0.0
        x = np.arange(len(cooperation_rates))
        y = np.array(cooperation_rates)
        if len(x) > 1:
            slope = (y[-1] - y[0]) / (len(x) - 1)
            return slope
        return 0.0

    def _get_recent_cooperation_rate(self, history: PlayerHistory, rounds: int) -> float:
        """Get cooperation rate over recent rounds."""
        if len(history.my_actions) == 0:
            return 0.5
        recent_rounds = min(rounds, len(history.my_actions))
        total_cooperators = 0
        total_decisions = 0
        for i in range(recent_rounds):
            round_idx = -(recent_rounds - i)
            cooperators = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += cooperators
            total_decisions += self.n - 1
        return total_cooperators / total_decisions if total_decisions > 0 else 0.5

class Strategy_AGGRESSIVE_123(BaseStrategy):
    """
    Opportunistic Free-Rider: An aggressive exploitation strategy that maximizes personal 
    payoffs by free-riding on others' cooperation while contributing minimally to collective success.
    Uses three phases: early exploitation, calculated opportunism, and end-game exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        phase1_end = math.floor(self.r / 3)
        phase2_end = math.floor(2 * self.r / 3)
        if current_round <= phase1_end:
            return Action.D
        elif current_round > phase2_end:
            if current_round == self.r:
                return Action.D
            if current_round == self.r - 2:
                if self._exploitation_has_been_profitable(history):
                    return Action.C
            return Action.D
        else:
            if self._others_failing_consistently(history):
                return Action.D
            if self._others_playing_aggressively(history):
                return Action.D
            prev_cooperators = self._count_cooperators_last_round(history)
            if prev_cooperators >= self.m:
                return Action.D
            if prev_cooperators == self.m - 1 and self._we_defected_last_round(history) and self._high_cooperation_observed(history):
                return Action.C
            return Action.D

    def _count_cooperators_last_round(self, history: PlayerHistory) -> int:
        """Count cooperators (including self) in the most recent round."""
        if len(history.my_actions) == 0:
            return 0
        opponent_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        my_cooperation = int(history.my_actions[-1])
        return opponent_cooperators + my_cooperation

    def _we_defected_last_round(self, history: PlayerHistory) -> bool:
        """Check if we defected in the previous round."""
        if len(history.my_actions) == 0:
            return True
        return not history.my_actions[-1]

    def _high_cooperation_observed(self, history: PlayerHistory) -> bool:
        """Check if there's evidence of conditional cooperators."""
        if len(history.my_actions) < 5:
            return True
        recent_rounds = min(5, len(history.my_actions))
        cooperation_rates = []
        for i in range(recent_rounds):
            round_idx = -(i + 1)
            opponent_coop = np.sum(history.opponent_actions[round_idx, :])
            my_coop = int(history.my_actions[round_idx])
            total_coop = opponent_coop + my_coop
            cooperation_rates.append(total_coop / self.n)
        high_coop_rounds = sum((1 for rate in cooperation_rates if rate > 0.5))
        return high_coop_rounds >= 2

    def _exploitation_has_been_profitable(self, history: PlayerHistory) -> bool:
        """Check if exploitation has been profitable (for end-game decision)."""
        if len(history.my_actions) == 0:
            return False
        total_cooperators = 0
        total_rounds = len(history.my_actions)
        for round_idx in range(total_rounds):
            opponent_coop = np.sum(history.opponent_actions[round_idx, :])
            my_coop = int(history.my_actions[round_idx])
            total_cooperators += opponent_coop + my_coop
        avg_coop_rate = total_cooperators / (total_rounds * self.n)
        successful_rounds = 0
        for round_idx in range(total_rounds):
            opponent_coop = np.sum(history.opponent_actions[round_idx, :])
            my_coop = int(history.my_actions[round_idx])
            if opponent_coop + my_coop >= self.m:
                successful_rounds += 1
        success_rate = successful_rounds / total_rounds if total_rounds > 0 else 0
        return avg_coop_rate >= 0.6 and success_rate >= 0.7

    def _others_failing_consistently(self, history: PlayerHistory) -> bool:
        """Check if others consistently fail to reach threshold."""
        if len(history.my_actions) < 3:
            return False
        successful_rounds = 0
        total_rounds = len(history.my_actions)
        for round_idx in range(total_rounds):
            opponent_coop = np.sum(history.opponent_actions[round_idx, :])
            my_coop = int(history.my_actions[round_idx])
            if opponent_coop + my_coop >= self.m:
                successful_rounds += 1
        success_rate = successful_rounds / total_rounds
        return success_rate < 0.3

    def _others_playing_aggressively(self, history: PlayerHistory) -> bool:
        """Check if others are playing aggressively (low cooperation)."""
        if len(history.my_actions) == 0:
            return False
        total_opponent_cooperations = 0
        total_rounds = len(history.my_actions)
        total_opponent_decisions = total_rounds * (self.n - 1)
        if total_opponent_decisions == 0:
            return False
        for round_idx in range(total_rounds):
            total_opponent_cooperations += np.sum(history.opponent_actions[round_idx, :])
        avg_opponent_coop = total_opponent_cooperations / total_opponent_decisions
        return avg_opponent_coop < 0.4

class Strategy_AGGRESSIVE_124(BaseStrategy):
    """
    Threshold Hawk - Aggressive Exploitation Strategy
    
    Aggressively exploits cooperative players while minimizing personal risk.
    Only cooperates when collective failure is imminent, otherwise always defects
    to maximize individual payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        rounds_remaining = self.n_rounds - current_round
        if rounds_remaining == 0:
            return Action.D
        last_round_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            last_round_cooperators += 1
        rounds_to_check = min(3, len(history.my_actions))
        if rounds_to_check > 0:
            recent_coop_sum = 0
            for i in range(rounds_to_check):
                round_idx = -(i + 1)
                round_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
                if history.my_actions[round_idx]:
                    round_cooperators += 1
                recent_coop_sum += round_cooperators
            recent_cooperation_rate = recent_coop_sum / (rounds_to_check * self.n_players)
        else:
            recent_cooperation_rate = 0.0
        emergency_threshold = max(1, self.m - 2)
        expected_cooperators = recent_cooperation_rate * (self.n_players - 1)
        risk_level = max(0, (self.m - expected_cooperators) / self.m)
        if rounds_remaining <= 2:
            if last_round_cooperators < self.m - 1 and risk_level > 0.9:
                return Action.C
            else:
                return Action.D
        cooperation_needed_urgently = last_round_cooperators < emergency_threshold and recent_cooperation_rate < self.m / self.n_players * 0.7 and (rounds_remaining > 2)
        if risk_level > 0.8 and cooperation_needed_urgently:
            if random.random() < 0.6:
                return Action.C
        elif risk_level > 0.5 and last_round_cooperators < self.m - 1:
            if random.random() < 0.2:
                return Action.C
        if self.n_players <= 4 and self.m / self.n_players > 0.6:
            if last_round_cooperators <= self.m - 2 and risk_level > 0.7:
                return Action.C
        if self.m >= self.n_players * 0.8:
            if last_round_cooperators <= self.m - 2:
                return Action.C
        return Action.D

class Strategy_AGGRESSIVE_125(BaseStrategy):
    """
    Threshold Predator: An aggressive exploitation strategy that free-rides on cooperative players
    while strategically cooperating only when necessary to preserve collective benefits.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.opponent_cooperation_rates = np.zeros(self.n - 1)
        self.consistent_cooperators = set()

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        rounds_remaining = self.r - current_round - 1
        self._update_opponent_tracking(history)
        if current_round <= self.r // 2:
            return self._phase1_decision(history)
        elif current_round <= self.r - 3:
            return self._phase2_decision(history, rounds_remaining)
        else:
            return self._phase3_decision(history, rounds_remaining)

    def _update_opponent_tracking(self, history: PlayerHistory):
        """Update tracking of opponent cooperation patterns."""
        if history.round_number == 0:
            return
        for i in range(self.n - 1):
            cooperation_count = np.sum(history.opponent_actions[:, i])
            self.opponent_cooperation_rates[i] = cooperation_count / history.round_number
            if self.opponent_cooperation_rates[i] > 0.7:
                self.consistent_cooperators.add(i)
            elif self.opponent_cooperation_rates[i] <= 0.7 and i in self.consistent_cooperators:
                self.consistent_cooperators.remove(i)

    def _count_cooperators_last_round(self, history: PlayerHistory) -> int:
        """Count number of cooperators in the most recent round."""
        if history.round_number == 0:
            return 0
        return int(np.sum(history.opponent_actions[-1, :]))

    def _threshold_met_rate(self, history: PlayerHistory) -> float:
        """Calculate the rate at which threshold was met in previous rounds."""
        if history.round_number == 0:
            return 0.0
        threshold_met_count = 0
        for round_idx in range(history.round_number):
            total_cooperators = int(np.sum(history.opponent_actions[round_idx, :])) + int(history.my_actions[round_idx])
            if total_cooperators >= self.m:
                threshold_met_count += 1
        return threshold_met_count / history.round_number

    def _my_average_payoff(self, history: PlayerHistory) -> float:
        """Calculate my average payoff so far."""
        if history.round_number == 0:
            return 0.0
        return np.mean(history.my_payoffs)

    def _phase1_decision(self, history: PlayerHistory) -> Action:
        """Phase 1: Initial Exploitation - Default to DEFECT with strategic exceptions."""
        cooperation_count_last = self._count_cooperators_last_round(history)
        if cooperation_count_last == self.m - 1 and len(self.consistent_cooperators) >= self.m - 1:
            return Action.C
        return Action.D

    def _phase2_decision(self, history: PlayerHistory, rounds_remaining: int) -> Action:
        """Phase 2: Strategic Calculation based on cooperation history."""
        cooperation_count_last = self._count_cooperators_last_round(history)
        consistent_cooperator_count = len(self.consistent_cooperators)
        my_avg_payoff = self._my_average_payoff(history)
        threshold_met_rate = self._threshold_met_rate(history)
        estimated_top_payoff = threshold_met_rate * (1 + self.k) + (1 - threshold_met_rate) * 1
        if cooperation_count_last >= self.m - 1 and consistent_cooperator_count >= self.m - 1:
            if rounds_remaining <= 3 or my_avg_payoff < estimated_top_payoff * 0.8:
                return Action.C
            else:
                return Action.D
        if history.round_number >= 3:
            recent_threshold_failures = 0
            for i in range(min(3, history.round_number)):
                round_idx = history.round_number - 1 - i
                total_cooperators = int(np.sum(history.opponent_actions[round_idx, :])) + int(history.my_actions[round_idx])
                if total_cooperators < self.m:
                    recent_threshold_failures += 1
            if recent_threshold_failures >= 3 and cooperation_count_last == self.m - 1:
                return Action.C
        return Action.D

    def _phase3_decision(self, history: PlayerHistory, rounds_remaining: int) -> Action:
        """Phase 3: Endgame Aggression - Maximize final extraction."""
        if rounds_remaining == 0:
            return Action.D
        threshold_met_rate = self._threshold_met_rate(history)
        cooperation_count_last = self._count_cooperators_last_round(history)
        if threshold_met_rate > 0.5:
            return Action.D
        elif cooperation_count_last == self.m - 1:
            return Action.C
        return Action.D

class Strategy_AGGRESSIVE_126(BaseStrategy):
    """
    Aggressive Adaptive Exploitation Strategy (AAES)
    
    Operates on aggressive exploitation with calculated cooperation.
    Cooperates only when necessary to secure collective reward while
    maximizing free-riding opportunities. Adapts quickly to opponent
    patterns and becomes increasingly ruthless as game progresses.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        return self._adaptive_exploitation_decision(history, current_round)

    def _adaptive_exploitation_decision(self, history: PlayerHistory, current_round: int) -> Action:
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        cooperation_buffer = last_round_cooperators - self.m
        coop_rate = last_round_cooperators / self.n
        if cooperation_buffer >= 2:
            return Action.D
        elif cooperation_buffer == 1:
            if coop_rate > 0.6 and current_round < self.r // 2:
                return Action.D
            else:
                return Action.C
        elif cooperation_buffer == 0:
            if history.my_actions[-1]:
                return Action.D
            else:
                return Action.C
        else:
            action = Action.C
            action = self._apply_momentum_tracking(history, action, current_round)
            return action

    def _apply_momentum_tracking(self, history: PlayerHistory, base_action: Action, current_round: int) -> Action:
        if len(history.my_actions) < 3:
            return base_action
        recent_rounds = min(3, len(history.my_actions))
        cooperation_counts = []
        for i in range(recent_rounds):
            round_idx = -1 - i
            round_cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                round_cooperators += 1
            cooperation_counts.append(round_cooperators)
        if len(cooperation_counts) >= 2:
            if cooperation_counts[0] > cooperation_counts[1]:
                if base_action == Action.C and random.random() < 0.3:
                    return Action.D
            elif cooperation_counts[0] < cooperation_counts[1]:
                pass
        return self._apply_advanced_adaptations(base_action, current_round)

    def _apply_advanced_adaptations(self, base_action: Action, current_round: int) -> Action:
        rounds_remaining = self.r - current_round
        final_phase_threshold = max(1, self.r // 5)
        if rounds_remaining <= final_phase_threshold:
            if base_action == Action.C and random.random() < 0.25:
                return Action.D
        final_10_percent = max(1, self.r // 10)
        if rounds_remaining <= final_10_percent:
            if base_action == Action.C and random.random() < 0.5:
                return Action.D
        m_ratio = self.m / self.n
        if m_ratio > 0.8:
            if base_action == Action.D and random.random() < 0.3:
                return Action.C
        elif m_ratio < 0.4:
            pass
        return base_action

class Strategy_AGGRESSIVE_127(BaseStrategy):
    """
    Aggressive Threshold Exploitation Strategy (ATES) - maximizes individual payoffs
    by cooperating only when necessary to secure collective benefits while defaulting
    to selfish behavior in all other cases.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        predicted_cooperators = self._predict_round_cooperation(history)
        endgame_threshold = math.ceil(self.r * 0.7)
        is_endgame = current_round >= endgame_threshold
        if current_round == self.r - 1:
            return Action.D
        if predicted_cooperators >= self.m:
            if random.random() < 0.1:
                return Action.D
            return Action.D
        elif predicted_cooperators == self.m - 1:
            if not is_endgame:
                return Action.C
            else:
                expected_future_value = self._calculate_future_value(history, current_round)
                return Action.C if expected_future_value > 1 else Action.D
        else:
            return Action.D

    def _predict_round_cooperation(self, history: PlayerHistory) -> int:
        """Predict number of opponents who will cooperate this round"""
        if history.round_number == 0:
            return max(1, int(self.n * 0.4))
        cooperation_rates = []
        for player_idx in range(self.n - 1):
            player_actions = history.opponent_actions[:, player_idx]
            if history.round_number >= 3:
                recent_actions = player_actions[-3:]
                older_actions = player_actions[:-3]
                recent_rate = np.mean(recent_actions) if len(recent_actions) > 0 else 0
                older_rate = np.mean(older_actions) if len(older_actions) > 0 else 0
                weighted_rate = 0.7 * recent_rate + 0.3 * older_rate
            else:
                weighted_rate = np.mean(player_actions)
            cooperation_rates.append(weighted_rate)
        if self.m >= 0.8 * self.n:
            adjustment_factor = 0.8
        elif self.m <= 3:
            adjustment_factor = 1.2
        else:
            adjustment_factor = 1.0
        if self.k >= 3:
            adjustment_factor *= 1.1
        elif self.k <= 1.5:
            adjustment_factor *= 0.9
        expected_cooperators = sum(cooperation_rates) * adjustment_factor
        predicted = max(0, min(self.n - 1, int(expected_cooperators + random.random() * 0.5 - 0.25)))
        return predicted

    def _calculate_future_value(self, history: PlayerHistory, current_round: int) -> float:
        """Calculate expected future value from cooperation patterns"""
        rounds_remaining = self.r - current_round
        if rounds_remaining <= 1:
            return 0
        recent_threshold_success = 0
        for round_idx in range(max(0, history.round_number - 5), history.round_number):
            cooperators_that_round = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators_that_round += 1
            if cooperators_that_round >= self.m:
                recent_threshold_success += 1
        success_rate = recent_threshold_success / min(5, history.round_number) if history.round_number > 0 else 0.5
        expected_future_bonus = success_rate * self.k * (rounds_remaining - 1)
        return expected_future_bonus

class Strategy_AGGRESSIVE_128(BaseStrategy):
    """
    Threshold Vulture: Aggressive exploitation strategy that free-rides on others' cooperation,
    only cooperating when absolutely necessary to secure collective rewards.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round >= self.n_rounds - 1:
            return Action.D
        opponent_coop_rates = self._calculate_cooperation_rates(history)
        reliable_cooperators = self._count_reliable_cooperators(opponent_coop_rates)
        expected_cooperators = self._estimate_cooperators(history, opponent_coop_rates, current_round)
        if expected_cooperators >= self.m:
            return Action.D
        elif expected_cooperators == self.m - 1:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rates(self, history: PlayerHistory) -> NDArray[np.float64]:
        """Calculate cooperation rate for each opponent."""
        if history.round_number == 0:
            return np.zeros(self.n_players - 1)
        return np.mean(history.opponent_actions, axis=0)

    def _count_reliable_cooperators(self, coop_rates: NDArray[np.float64]) -> int:
        """Count opponents with >70% cooperation rate."""
        return np.sum(coop_rates > 0.7)

    def _estimate_cooperators(self, history: PlayerHistory, coop_rates: NDArray[np.float64], current_round: int) -> int:
        """Estimate number of cooperators in current round."""
        if current_round <= 1:
            reliable_cooperators = self._count_reliable_cooperators(coop_rates)
            unreliable_count = self.n_players - 1 - reliable_cooperators
            expected_unreliable = unreliable_count * 0.3
            return int(reliable_cooperators + expected_unreliable)
        if current_round <= 5:
            reliable_cooperators = np.sum(coop_rates > 0.7)
            moderate_cooperators = np.sum((coop_rates >= 0.4) & (coop_rates <= 0.7))
            unreliable_cooperators = np.sum(coop_rates < 0.4)
            expected = reliable_cooperators * 0.8 + moderate_cooperators * 0.4 + unreliable_cooperators * 0.2
        else:
            reliable_cooperators = np.sum(coop_rates > 0.8)
            reciprocators = np.sum((coop_rates >= 0.3) & (coop_rates <= 0.8))
            defectors = np.sum(coop_rates < 0.3)
            recent_rounds = min(3, history.round_number)
            recent_success_rate = self._calculate_recent_success_rate(history, recent_rounds)
            if recent_success_rate > 0.5:
                expected = reliable_cooperators * 0.9 + reciprocators * 0.2 + defectors * 0.1
            else:
                expected = reliable_cooperators * 0.7 + reciprocators * 0.4 + defectors * 0.2
        return int(expected)

    def _calculate_recent_success_rate(self, history: PlayerHistory, recent_rounds: int) -> float:
        """Calculate success rate of meeting threshold in recent rounds."""
        if history.round_number == 0:
            return 0.5
        start_round = max(0, history.round_number - recent_rounds)
        recent_cooperators = []
        for round_idx in range(start_round, history.round_number):
            cooperators = np.sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            recent_cooperators.append(cooperators)
        successes = sum((1 for c in recent_cooperators if c >= self.m))
        return successes / len(recent_cooperators) if recent_cooperators else 0.5

class Strategy_COOPERATIVE_75(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS)
    
    This strategy maintains cooperation while being resilient to exploitation.
    It uses dynamic thresholds based on recent cooperation history and adapts
    to group behavior patterns while protecting against systematic exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.cooperation_momentum = 1.0
        self.catalyst_mode_rounds = 0
        self.consecutive_threshold_misses = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = history.round_number + 1
        initial_phase_length = min(5, max(1, self.r // 3))
        if round_num <= initial_phase_length:
            return Action.C
        trust_level = self._calculate_trust_level(history)
        expected_cooperators = self._calculate_expected_cooperators(history)
        if self.catalyst_mode_rounds > 0:
            self.catalyst_mode_rounds -= 1
            return Action.C
        if round_num >= self.r:
            if trust_level >= 0.5 and expected_cooperators >= self.m - 1:
                return Action.C
            else:
                return Action.D
        elif round_num >= self.r - 1:
            if trust_level >= 0.4 and expected_cooperators >= self.m:
                return Action.C
            else:
                return Action.D
        group_size_adjusted_high_threshold = self._get_group_adjusted_threshold(high=True)
        group_size_adjusted_low_threshold = self._get_group_adjusted_threshold(high=False)
        if trust_level >= group_size_adjusted_high_threshold and expected_cooperators >= self.m - 1:
            return Action.C
        elif trust_level >= group_size_adjusted_low_threshold and expected_cooperators >= self.m:
            return Action.C
        elif round_num <= self.r - 2:
            return self._conditional_defect_recovery(history, trust_level, expected_cooperators)
        else:
            return Action.D

    def _calculate_trust_level(self, history: PlayerHistory) -> float:
        """Calculate trust level based on recent cooperation history."""
        lookback = min(3, history.round_number)
        if lookback == 0:
            return 1.0
        recent_cooperators = 0
        for i in range(lookback):
            round_idx = history.round_number - 1 - i
            recent_cooperators += np.sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                recent_cooperators += 1
        cooperation_rate = recent_cooperators / (lookback * self.n)
        trust_level = cooperation_rate * self.cooperation_momentum
        return min(1.0, trust_level)

    def _calculate_expected_cooperators(self, history: PlayerHistory) -> float:
        """Estimate how many opponents will cooperate next round."""
        if history.round_number < 3:
            recent_coop_sum = 0
            for i in range(history.round_number):
                recent_coop_sum += np.sum(history.opponent_actions[i, :])
            return recent_coop_sum / history.round_number if history.round_number > 0 else 0
        expected_cooperators = 0
        lookback = min(3, history.round_number)
        for player_idx in range(self.n - 1):
            player_cooperations = 0
            for i in range(lookback):
                round_idx = history.round_number - 1 - i
                if history.opponent_actions[round_idx, player_idx]:
                    player_cooperations += 1
            recent_coop_rate = player_cooperations / lookback
            if recent_coop_rate >= 0.67:
                expected_cooperators += 1
            elif recent_coop_rate >= 0.33:
                expected_cooperators += 0.5
        return expected_cooperators

    def _get_group_adjusted_threshold(self, high: bool) -> float:
        """Get cooperation thresholds adjusted for group size."""
        if self.n <= 4:
            return 0.5 if high else 0.3
        elif self.n >= 10:
            return 0.7 if high else 0.5
        else:
            return 0.6 if high else 0.4

    def _conditional_defect_recovery(self, history: PlayerHistory, trust_level: float, expected_cooperators: float) -> Action:
        """Handle conditional defection and recovery logic."""
        last_round_idx = history.round_number - 1
        last_round_cooperators = np.sum(history.opponent_actions[last_round_idx, :])
        if history.my_actions[last_round_idx]:
            last_round_cooperators += 1
        threshold_met_last_round = last_round_cooperators >= self.m
        if threshold_met_last_round:
            self.cooperation_momentum = min(1.5, self.cooperation_momentum * 1.1)
            self.consecutive_threshold_misses = 0
        else:
            self.cooperation_momentum = max(0.3, self.cooperation_momentum * 0.9)
            self.consecutive_threshold_misses += 1
        if self.consecutive_threshold_misses >= 3:
            self.catalyst_mode_rounds = 2
            self.consecutive_threshold_misses = 0
            return Action.C
        if self._am_being_exploited(history):
            return Action.D
        if last_round_cooperators == self.m - 1:
            return Action.C
        if expected_cooperators >= self.m - 2 and random.random() < 0.2:
            return Action.C
        return Action.D

    def _am_being_exploited(self, history: PlayerHistory) -> bool:
        """Check if this player is being systematically exploited."""
        if history.round_number < 3:
            return False
        my_cooperations = 0
        others_cooperations = 0
        for i in range(min(3, history.round_number)):
            round_idx = history.round_number - 1 - i
            if history.my_actions[round_idx]:
                my_cooperations += 1
            others_cooperations += np.sum(history.opponent_actions[round_idx, :])
        my_coop_rate = my_cooperations / min(3, history.round_number)
        others_coop_rate = others_cooperations / (min(3, history.round_number) * (self.n - 1))
        return my_coop_rate >= 0.67 and others_coop_rate <= 0.33