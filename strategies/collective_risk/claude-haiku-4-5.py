"""
Generated LLM strategies for social dilemma games.

This file contains strategy classes generated by LLMs for game theory experiments.
Each strategy is a callable class that implements a specific approach to the game.

Generated with:
- Provider: Anthropic
- Model: claude-haiku-4-5
- Game: collective_risk
"""

from dataclasses import dataclass
from enum import Enum
import math
import numpy as np
from numpy.typing import NDArray
import random

from emergent_llm.players import BaseStrategy
from emergent_llm.games import PublicGoodsDescription, CollectiveRiskDescription, CommonPoolDescription, CommonPoolState
from emergent_llm.common import Action, C, D, PlayerHistory, GameState



class Strategy_COLLECTIVE_1(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances collective welfare with individual security by progressively building
    cooperation to reach threshold m, monitoring collective health, protecting against
    exploitation, and shifting toward safety as rounds deplete.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.grudge_counter = 0
        self.consecutive_failures = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        cooperators_last = int(sum(history.opponent_actions[round_num - 1, :]))
        my_action_last = history.my_actions[round_num - 1]
        my_payoff_last = history.my_payoffs[round_num - 1]
        if self._check_consecutive_failures(history, round_num):
            self.consecutive_failures += 1
            if self.consecutive_failures >= 2:
                return Action.D
        else:
            self.consecutive_failures = 0
        if self.grudge_counter > 0:
            self.grudge_counter -= 1
            return Action.D
        if cooperators_last >= self.m and my_action_last and (my_payoff_last < self.k - 0.1 * self.k):
            self.grudge_counter = 2
            return Action.D
        phase = self._classify_phase(round_num)
        if phase == 'EARLY':
            if cooperators_last >= self.m - 1:
                return Action.C
            else:
                return Action.D
        elif phase == 'MIDDLE':
            cooperation_rate = cooperators_last / self.n
            if cooperators_last >= self.m:
                expected_threshold_payoff = self.k
                epsilon = max(0.1 * self.k, 0.2)
                if my_payoff_last >= expected_threshold_payoff - epsilon:
                    return Action.C
                else:
                    return Action.D
            else:
                momentum_threshold = self.m / self.n * 0.8
                if cooperation_rate >= momentum_threshold:
                    return Action.C
                else:
                    return Action.D
        else:
            if round_num == self.r - 1:
                if cooperators_last >= self.m:
                    return Action.C
                else:
                    return Action.D
            if cooperators_last >= self.m:
                free_riders = self._count_free_riders(history, round_num)
                if free_riders >= 2:
                    return Action.D
                else:
                    return Action.C
            else:
                return Action.D

    def _classify_phase(self, round_num: int) -> str:
        """Classify the current round into phase."""
        early_threshold = self.r / 3
        middle_threshold = 2 * self.r / 3
        if round_num <= early_threshold:
            return 'EARLY'
        elif round_num <= middle_threshold:
            return 'MIDDLE'
        else:
            return 'LATE'

    def _check_consecutive_failures(self, history: PlayerHistory, round_num: int) -> bool:
        """Check if the threshold failed in the last round."""
        if round_num < 1:
            return False
        cooperators_last = int(sum(history.opponent_actions[round_num - 1, :]))
        return cooperators_last < self.m

    def _count_free_riders(self, history: PlayerHistory, round_num: int) -> int:
        """Count players who defected but benefited from threshold in last round."""
        if round_num < 1:
            return 0
        cooperators_last = int(sum(history.opponent_actions[round_num - 1, :]))
        if cooperators_last < self.m:
            return 0
        free_riders = 0
        for i in range(self.n - 1):
            defected = not history.opponent_actions[round_num - 1, i]
            payoff = history.opponent_payoffs[round_num - 1, i]
            if defected and payoff >= self.k:
                free_riders += 1
        return free_riders

class Strategy_COLLECTIVE_2(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Cooperating in round 1 to establish intent
    2. Cooperating in rounds 2 to r-1 if prior cooperation rate >= (m-1)/n
    3. Defecting in the final round (subgame-perfect Nash equilibrium)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_confidence = (self.m - 1) / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        previous_round_index = current_round - 1
        cooperators_last_round = sum(history.opponent_actions[previous_round_index, :])
        if history.my_actions[previous_round_index]:
            cooperators_last_round += 1
        cooperation_rate = cooperators_last_round / self.n_players
        if cooperation_rate >= self.threshold_confidence:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_3(BaseStrategy):
    """
    Adaptive Threshold Stabilization (ATS) strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective rationality by:
    1. Cooperating in round 1 to signal good faith
    2. Using recent cooperation trends (last 3 rounds) as primary signal
    3. Scaling historical cooperation against game progress
    4. Defecting when threshold appears unreachable
    5. Making final round decision based on overall cooperation rate
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        all_rounds_cooperators = np.sum(history.opponent_actions[:round_num, :], axis=1)
        total_coop_count = np.sum(all_rounds_cooperators)
        total_rounds_so_far = round_num
        recent_window = min(3, round_num)
        recent_rounds_start = max(0, round_num - recent_window)
        recent_cooperators = np.sum(all_rounds_cooperators[recent_rounds_start:round_num])
        if recent_cooperators >= self.m:
            return Action.C
        scaled_threshold = self.m * (round_num / self.r)
        if total_coop_count >= scaled_threshold:
            return Action.C
        if total_rounds_so_far > 0:
            avg_cooperators_per_round = total_coop_count / total_rounds_so_far
            expected_cooperators = avg_cooperators_per_round * self.n
        else:
            expected_cooperators = 0
        if round_num == self.r - 1:
            if total_rounds_so_far > 0:
                cooperation_rate = total_coop_count / (total_rounds_so_far * self.n)
                threshold_rate = (self.m - 1) / self.n
                if cooperation_rate > threshold_rate:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D
        if expected_cooperators >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_4(BaseStrategy):
    """
    Adaptive Threshold Reciprocity (ATR) Strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by dynamically adjusting
    cooperation based on observed success rates and threshold proximity. Adapts to
    population behavior while maintaining robustness against exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        coop_rate = self._calculate_cooperation_rate(history, current_round)
        if coop_rate < 0.01:
            if current_round == self.r - 1:
                return Action.C
            return Action.D
        if coop_rate > 0.99:
            return Action.C
        if self.m == self.n:
            if coop_rate > 0.95:
                return Action.C
            return Action.D
        if self.m == 1:
            return Action.D
        p_success = self._estimate_success_probability(coop_rate)
        if 1 < current_round < self.r - 2:
            trend = self._detect_cooperation_trend(history, current_round)
            if trend > 0:
                p_success = min(1.0, p_success + 0.05)
            elif trend < 0:
                p_success = max(0.0, p_success - 0.05)
        success_frequency = self._calculate_success_frequency(history, current_round)
        if success_frequency > 0.7:
            return Action.C
        critical_threshold = self.m / self.n
        if coop_rate >= critical_threshold - 0.05 and coop_rate < critical_threshold:
            return Action.C
        threshold_crossover = 1.0 / self.k
        if current_round == self.r - 1:
            adjusted_threshold = threshold_crossover * 0.8
            if p_success > adjusted_threshold:
                return Action.C
            return Action.D
        if current_round == self.r - 2:
            coop_rate_adjusted = min(1.0, coop_rate * 1.1)
            p_success_adjusted = self._estimate_success_probability(coop_rate_adjusted)
            if p_success_adjusted >= threshold_crossover:
                return Action.C
            return Action.D
        if p_success >= threshold_crossover:
            return Action.C
        return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """Calculate the population cooperation rate from previous rounds."""
        if current_round <= 1:
            return 0.0
        previous_rounds = current_round
        my_coop = np.sum(history.my_actions[:current_round])
        opponent_coop = np.sum(history.opponent_actions[:current_round, :])
        total_coop = my_coop + opponent_coop
        total_actions = (1 + self.n - 1) * previous_rounds
        if total_actions == 0:
            return 0.0
        return total_coop / total_actions

    def _estimate_success_probability(self, coop_rate: float) -> float:
        """Estimate P(X >= m | n, coop_rate) using binomial distribution."""
        if coop_rate <= 0.0:
            return 0.0
        if coop_rate >= 1.0:
            return 1.0
        p_success = 0.0
        for x in range(self.m, self.n + 1):
            p_success += self._binomial_pmf(x, self.n, coop_rate)
        return min(1.0, max(0.0, p_success))

    def _binomial_pmf(self, k: int, n: int, p: float) -> float:
        """Compute binomial probability mass function P(X = k)."""
        if k < 0 or k > n or p < 0 or (p > 1):
            return 0.0
        binom_coeff = math.factorial(n) / (math.factorial(k) * math.factorial(n - k))
        pmf = binom_coeff * p ** k * (1 - p) ** (n - k)
        return pmf

    def _detect_cooperation_trend(self, history: PlayerHistory, current_round: int) -> float:
        """Detect if cooperation is increasing (+1), decreasing (-1), or stable (0)."""
        if current_round < 4:
            return 0.0
        recent_window = history.opponent_actions[max(0, current_round - 3):current_round, :]
        if recent_window.shape[0] < 2:
            return 0.0
        early_coop = np.mean(recent_window[:-1, :])
        late_coop = np.mean(recent_window[-1, :])
        diff = late_coop - early_coop
        if diff > 0.02:
            return 1.0
        elif diff < -0.02:
            return -1.0
        return 0.0

    def _calculate_success_frequency(self, history: PlayerHistory, current_round: int) -> float:
        """Calculate how often the threshold was met in previous rounds."""
        if current_round <= 1:
            return 0.0
        success_count = 0
        for round_idx in range(current_round):
            cooperators = np.sum(history.opponent_actions[round_idx, :]) + (1 if history.my_actions[round_idx] else 0)
            if cooperators >= self.m:
                success_count += 1
        return success_count / current_round

class Strategy_COLLECTIVE_5(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances collective welfare with robust defection against free-riders:
    - Round 1: Cooperate (optimistic, establish good faith)
    - Rounds 2 to r-1: Adapt based on observed cooperation rate vs threshold
    - Final round: Defect (no future consequences, maximize individual payoff)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.buffer_margin = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == r - 1:
            return Action.D
        total_cooperations = 0
        num_completed_rounds = round_num
        for round_idx in range(num_completed_rounds):
            cooperators_in_round = int(np.sum(history.opponent_actions[round_idx, :]))
            total_cooperations += cooperators_in_round
        if num_completed_rounds == 0:
            cooperation_rate = 0.0
        else:
            cooperation_rate = total_cooperations / (num_completed_rounds * n)
        threshold_estimate = m / n
        decision_threshold = threshold_estimate - self.buffer_margin
        if cooperation_rate >= decision_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_6(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) for Collective Risk Dilemma.
    
    Balances idealism (cooperate when possible) with realism (defect when necessary).
    Uses threshold-aware conditional cooperation with stochastic signaling in uncertainty zones.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        r = self.n_rounds
        if t == 0:
            return Action.C
        prev_round_idx = t - 1
        prev_cooperators = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        coop_rate = prev_cooperators / self.n_players
        threshold = self.m / self.n_players
        rounds_left = r - t
        if rounds_left == 0:
            return Action.D
        if rounds_left == 1:
            if coop_rate >= threshold:
                return Action.C
            else:
                return Action.D
        if coop_rate >= threshold * 1.2:
            return Action.C
        elif coop_rate >= threshold:
            return Action.C
        elif coop_rate >= threshold * 0.7:
            probability = coop_rate / threshold
            if random.random() < probability:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_7(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Dynamically adjusts cooperation based on observed group behavior and remaining rounds.
    - Round 1: Cooperate (costly signal of good faith)
    - Rounds 2 to r-1: Cooperate if cooperation rate meets or nearly meets threshold
    - Round r: Defect (no future consequences)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        m = self.game_description.m
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == r - 1:
            return Action.D
        prev_round_idx = current_round - 1
        prev_cooperators = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            prev_cooperators += 1
        cooperation_rate = prev_cooperators / n
        threshold = m / n
        if cooperation_rate >= threshold:
            return Action.C
        elif cooperation_rate >= threshold - 1.0 / n:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_8(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Dynamically adjusts cooperation based on observed cooperation rates and game progress.
    Cooperates in round 1, adapts to collective momentum in mid-game rounds, and makes
    final decisions based on threshold achievement likelihood.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.rounds_below_threshold = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        last_round_idx = current_round - 1
        cooperators_last_round = np.sum(history.opponent_actions[last_round_idx, :])
        observed_coop_rate = cooperators_last_round / n
        threshold = m / n
        rounds_remaining = r - current_round
        if current_round == r - 1:
            if observed_coop_rate >= threshold * 1.2:
                return Action.C
            else:
                return Action.D
        adjusted_threshold = threshold * (1.0 - 0.05 * self.rounds_below_threshold)
        adjusted_threshold = max(adjusted_threshold, 0.0)
        if observed_coop_rate >= adjusted_threshold * 0.9:
            self.rounds_below_threshold = max(0, self.rounds_below_threshold - 1)
            return Action.C
        elif observed_coop_rate >= adjusted_threshold * 0.5:
            if rounds_remaining >= 3:
                self.rounds_below_threshold += 1
                return Action.C
            else:
                self.rounds_below_threshold += 1
                return Action.D
        else:
            self.rounds_below_threshold += 1
            return Action.D

class Strategy_COLLECTIVE_9(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Dynamically adjusts cooperation based on collective progress toward threshold,
    historical reliability, remaining time, and payoff optimization. Uses three phases:
    Early (establish baseline), Middle (exploit patterns), End (maximize final payoff).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.success_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == 1:
            self.success_count = 0
        if round_num > 0:
            prev_cooperators = int(np.sum(history.opponent_actions[round_num - 1, :]))
            if history.my_actions[round_num - 1]:
                prev_cooperators += 1
            if prev_cooperators >= self.m:
                self.success_count += 1
        early_end = math.floor(self.r / 3)
        late_start = math.ceil(2 * self.r / 3)
        if round_num <= early_end:
            return self._early_game(round_num, history)
        elif round_num <= late_start:
            return self._middle_game(round_num, history)
        else:
            return self._end_game(round_num, history)

    def _early_game(self, round_num: int, history: PlayerHistory) -> Action:
        """Early game (rounds 1 to floor(r/3)): Assess cooperation tendency."""
        if round_num == 1:
            return Action.C
        recent_coop_rate = self._get_recent_cooperation_rate(history, round_num, lookback=2)
        threshold_indicator = (self.m - 1) / self.n
        if recent_coop_rate >= threshold_indicator:
            return Action.C
        if recent_coop_rate < threshold_indicator / 2:
            return Action.D
        accumulated_defectors = 0
        for r in range(round_num):
            defectors = int(self.n - 1 - np.sum(history.opponent_actions[r, :]))
            if defectors > 0:
                accumulated_defectors += defectors
        if accumulated_defectors < 1:
            return Action.C
        else:
            return Action.D

    def _middle_game(self, round_num: int, history: PlayerHistory) -> Action:
        """Middle game: Exploit proven cooperation patterns."""
        success_rate = self.success_count / round_num if round_num > 0 else 0
        if success_rate >= 0.5:
            return Action.C
        if success_rate >= 0.25:
            recent_coop_rate = self._get_recent_cooperation_rate(history, round_num, lookback=1)
            threshold_indicator = (self.m - 1) / self.n
            if recent_coop_rate >= threshold_indicator:
                return Action.C
            else:
                return Action.D
        return Action.D

    def _end_game(self, round_num: int, history: PlayerHistory) -> Action:
        """End game: Maximize final payoff."""
        success_rate = self.success_count / round_num if round_num > 0 else 0
        if round_num == self.r - 1:
            if success_rate >= 0.4:
                return Action.C
            else:
                return Action.D
        recent_coop_rate = self._get_recent_cooperation_rate(history, round_num, lookback=1)
        threshold_indicator = (self.m - 1) / self.n - 0.15
        if recent_coop_rate >= threshold_indicator:
            return Action.C
        else:
            return Action.D

    def _get_recent_cooperation_rate(self, history: PlayerHistory, round_num: int, lookback: int) -> float:
        """Calculate cooperation rate of opponents in last 'lookback' rounds."""
        if round_num == 0:
            return 0.0
        start_round = max(0, round_num - lookback)
        total_observations = 0
        total_cooperators = 0
        for r in range(start_round, round_num):
            cooperators = int(np.sum(history.opponent_actions[r, :]))
            total_observations += self.n - 1
            total_cooperators += cooperators
        if total_observations == 0:
            return 0.0
        return total_cooperators / total_observations

class Strategy_COLLECTIVE_10(BaseStrategy):
    """
    Progressive Conditional Reciprocity (PCR) Strategy for Collective Risk Dilemma.
    
    Balances collective survival (reaching threshold m) with individual rationality
    by cooperating when sufficient cooperation is observed, punishing free-riders,
    and defecting in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            return Action.D
        return self._decide_middle_rounds(current_round, history)

    def _decide_middle_rounds(self, current_round: int, history: PlayerHistory) -> Action:
        """
        Adaptive decision logic for rounds 1 through r-2.
        """
        total_cooperations = np.sum(history.opponent_actions[:current_round, :])
        total_possible = current_round * self.n
        if total_possible == 0:
            return Action.C
        cooperation_rate_observed = total_cooperations / total_possible
        last_round_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        last_round_threshold_met = last_round_cooperators >= self.m
        free_riders_last_round = 0
        if last_round_threshold_met:
            free_riders_last_round = self.n - last_round_cooperators
        if last_round_threshold_met and free_riders_last_round > 0:
            return Action.D
        min_threshold_ratio = self.m / self.n
        high_cooperation_threshold = min_threshold_ratio * 1.2
        if self.n > 10:
            high_cooperation_threshold = min_threshold_ratio * 1.3
        if cooperation_rate_observed >= high_cooperation_threshold:
            return Action.C
        if cooperation_rate_observed >= min_threshold_ratio:
            if last_round_threshold_met:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_11(BaseStrategy):
    """
    Adaptive Threshold Sentinel: A responsive, group-welfare-oriented strategy for the Collective Risk Dilemma.
    
    Balances individual security with collective welfare by:
    1. Leading with cooperation to establish feasibility
    2. Tracking collective progress toward threshold m
    3. Cooperating when threshold is reachable; defecting when it's not
    4. Providing clear incentives for cooperation without being exploited
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.rounds_threshold_met = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        last_round_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            last_round_cooperators += 1
        if current_round == r - 1:
            if last_round_cooperators >= m:
                return Action.C
            else:
                return Action.D
        cooperation_rate = last_round_cooperators / n
        deficit = m - last_round_cooperators
        if last_round_cooperators >= m:
            self.rounds_threshold_met += 1
            if cooperation_rate >= 2 * m / (3 * n):
                return Action.C
            if cooperation_rate >= m / n and self.rounds_threshold_met >= 2:
                return Action.C
            return Action.D
        else:
            if deficit <= 1:
                return Action.C
            if cooperation_rate >= (m - 1) / n:
                return Action.C
            if cooperation_rate <= (m - 2) / n:
                return Action.D
            threshold_progress = last_round_cooperators / m if m > 0 else 0
            if threshold_progress >= 0.5 and current_round <= r / 2:
                return Action.C
            return Action.D

class Strategy_COLLECTIVE_12(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Embraces a collective-first approach: cooperate generously when the group is succeeding,
    invest heavily when the threshold is at risk, and defect only when collective failure is evident.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        previous_round_idx = round_number - 1
        opponent_actions_prev = history.opponent_actions[previous_round_idx, :]
        my_action_prev = history.my_actions[previous_round_idx]
        opponent_cooperators = int(np.sum(opponent_actions_prev))
        total_cooperators = opponent_cooperators + (1 if my_action_prev else 0)
        coop_rate = total_cooperators / self.n
        threshold_buffer = coop_rate * self.n - self.m
        max_buffer = self.n - self.m
        if max_buffer == 0:
            safe_margin = 1.0 if threshold_buffer >= 0 else 0.0
        else:
            safe_margin = threshold_buffer / max_buffer
        if round_number == self.r - 1:
            if total_cooperators >= self.m:
                return Action.C
            else:
                return Action.D
        if total_cooperators == self.n:
            if random.random() < 0.98:
                return Action.C
            else:
                return Action.D
        if total_cooperators == 0:
            return Action.D
        if safe_margin > 0.4:
            if random.random() < 0.95:
                return Action.C
            else:
                return Action.D
        elif safe_margin > 0:
            prob = 0.5 + 0.4 * safe_margin
            if random.random() < prob:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_13(BaseStrategy):
    """
    Adaptive Threshold Commitment strategy for Collective Risk Dilemma.
    
    Balances individual rationality and collective welfare by:
    1. Seeding cooperation proportional to threshold in round 1
    2. Adaptively ramping cooperation based on observed cooperation rates
    3. Defecting gracefully when threshold is unachievable
    4. Maximizing payoff in the final round with no shadow of future
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_probability = game_description.m / game_description.n_players
        self.previous_probability = self.cooperation_probability

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        k = self.game_description.k
        current_round = state.round_number
        if k < 1:
            return Action.D
        if m == 1:
            return Action.C
        if current_round == 0:
            self.cooperation_probability = m / n
            return Action.C if random.random() < self.cooperation_probability else Action.D
        if current_round == r - 1:
            last_round_cooperators = int(sum(history.opponent_actions[-1, :]))
            if history.my_actions[-1]:
                last_round_cooperators += 1
            if last_round_cooperators >= m:
                return Action.D
            if last_round_cooperators + 1 >= m:
                return Action.D
            if last_round_cooperators + (n - 1) < m:
                return Action.D
            return Action.C if random.random() < m / n else Action.D
        last_round_cooperators = int(sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            last_round_cooperators += 1
        cooperation_rate = last_round_cooperators / n
        deficit = m - last_round_cooperators
        if deficit <= 0:
            target_prob = max(m / n, cooperation_rate - 0.1)
        elif deficit > n / 2:
            target_prob = 0.0
        else:
            gap_contribution = deficit / n * 1.5
            target_prob = min(1.0, cooperation_rate + gap_contribution)
        self.cooperation_probability = 0.7 * self.previous_probability + 0.3 * target_prob
        self.previous_probability = self.cooperation_probability
        return Action.C if random.random() < self.cooperation_probability else Action.D

class Strategy_COLLECTIVE_14(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Dynamically adjusts cooperation based on observable evidence of collective commitment.
    Cooperates in round 1, then adapts based on recent cooperation rates and threshold viability.
    Includes end-game adjustments and threshold detection mechanisms.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_ever_met = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        cooperators_last_round = int(sum(history.opponent_actions[round_num - 1, :]))
        total_cooperators_last_round = cooperators_last_round + (1 if history.my_actions[round_num - 1] else 0)
        recent_cooperation_rate = total_cooperators_last_round / self.n_players
        threshold_rate = self.m / self.n_players
        for past_round in range(round_num):
            past_cooperators = int(sum(history.opponent_actions[past_round, :]))
            past_total = past_cooperators + (1 if history.my_actions[past_round] else 0)
            if past_total >= self.m:
                self.threshold_ever_met = True
                break
        if recent_cooperation_rate >= 0.9 * threshold_rate:
            base_action_prob = 1.0
        elif recent_cooperation_rate >= 0.5 * threshold_rate:
            base_action_prob = recent_cooperation_rate
        elif self.threshold_ever_met:
            base_action_prob = 0.6
        else:
            base_action_prob = 0.0
        if round_num > self.n_rounds * 0.8:
            cumulative_payoff = float(np.sum(history.my_payoffs[:round_num]))
            expected_median = (1 + self.k) / 2 * round_num
            if cumulative_payoff >= expected_median:
                base_action_prob = min(1.0, base_action_prob + 0.15)
            else:
                base_action_prob = max(0.0, base_action_prob - 0.15)
        if round_num == self.n_rounds - 1:
            if self.threshold_ever_met:
                return Action.C
            else:
                cumulative_payoff = float(np.sum(history.my_payoffs[:round_num]))
                expected_median = (1 + self.k) / 2 * round_num
                if cumulative_payoff < expected_median * 0.8:
                    return Action.D
                else:
                    return Action.C
        if random.random() < base_action_prob:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_15(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances collective welfare maximization through threshold achievement with
    robust individual protection against exploitation. Uses adaptive thresholds,
    trend-sensitive forgiveness, and conditional reciprocity to achieve cooperative
    equilibrium while remaining robust against various opponent types.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        coop_count_prev = int(np.sum(history.opponent_actions[round_num - 1, :]))
        coop_rate_prev = coop_count_prev / self.n
        decay_factor = (self.r - round_num) / self.r
        base_threshold = self.m / self.n
        adjustment = max(0.05, min(0.25, self.k / (2 * self.n)))
        threshold = base_threshold + decay_factor * adjustment
        if round_num == self.r - 1:
            final_threshold = self.m / self.n * 0.85
            return Action.C if coop_rate_prev >= final_threshold else Action.D
        if round_num >= 2:
            coop_count_two_rounds_ago = int(np.sum(history.opponent_actions[round_num - 2, :]))
            coop_rate_two_rounds_ago = coop_count_two_rounds_ago / self.n
            if coop_rate_prev < threshold and coop_rate_prev > coop_rate_two_rounds_ago:
                if random.random() < 0.7:
                    return Action.C
        rounds_remaining = self.r - round_num
        if rounds_remaining <= 3 and coop_rate_prev >= base_threshold:
            return Action.C
        threshold_margin = 0.1
        if abs(coop_rate_prev - threshold) <= threshold_margin:
            prob = max(0.0, 1.0 - (threshold - coop_rate_prev) / (2 * threshold_margin))
            return Action.C if random.random() < prob else Action.D
        if coop_rate_prev >= threshold:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_16(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Recognizes that cooperation becomes individually rational once sufficient others
    cooperate. Uses three phases: Establishment (test cooperation viability),
    Commitment (build sustainable cooperation), and Finalization (maximize final payoff
    given equilibrium). Adapts to observed cooperation rates without assuming shared norms.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.phase1_end = math.ceil(self.n_rounds / 3)
        self.phase2_end = math.floor(2 * self.n_rounds / 3)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if self.n_players < self.m + 1:
            return Action.C
        if current_round == 0:
            return Action.C
        if current_round <= self.phase1_end:
            return self._phase1_decision(current_round, history)
        elif current_round <= self.phase2_end:
            return self._phase2_decision(current_round, history)
        else:
            return self._phase3_decision(current_round, history)

    def _phase1_decision(self, current_round: int, history: PlayerHistory) -> Action:
        """Phase 1: ESTABLISHMENT - Test whether sufficient cooperation is achievable."""
        cooperators_prev = int(np.sum(history.opponent_actions[current_round - 1, :]))
        cooperation_rate = cooperators_prev / (self.n_players - 1)
        threshold_rate = self.m / self.n_players * 0.8
        if cooperation_rate >= threshold_rate:
            return Action.C
        mid_threshold = self.m / self.n_players * 0.5
        if cooperation_rate >= mid_threshold:
            if random.random() < cooperation_rate:
                return Action.C
            return Action.D
        return Action.D

    def _phase2_decision(self, current_round: int, history: PlayerHistory) -> Action:
        """Phase 2: COMMITMENT - Build sustainable cooperation around threshold."""
        history_window = min(5, current_round)
        recent_rounds_indices = list(range(current_round - history_window, current_round))
        cooperation_counts = [int(np.sum(history.opponent_actions[idx, :])) for idx in recent_rounds_indices]
        average_cooperation = np.mean(cooperation_counts)
        if len(cooperation_counts) > 1:
            cooperation_trend = (cooperation_counts[-1] - cooperation_counts[0]) / (len(cooperation_counts) - 1)
        else:
            cooperation_trend = 0.0
        target = self.m - 1
        if average_cooperation >= target:
            return Action.C
        if average_cooperation >= target * 0.75 and cooperation_trend >= 0:
            return Action.C
        if average_cooperation < target * 0.5:
            return Action.D
        prob = average_cooperation / self.m if self.m > 0 else 0.5
        if random.random() < prob:
            return Action.C
        return Action.D

    def _phase3_decision(self, current_round: int, history: PlayerHistory) -> Action:
        """Phase 3: FINALIZATION - Maximize final payoff given current equilibrium."""
        rounds_left = self.n_rounds - current_round
        history_window = min(3, current_round)
        recent_rounds_indices = list(range(current_round - history_window, current_round))
        cooperation_counts = [int(np.sum(history.opponent_actions[idx, :])) for idx in recent_rounds_indices]
        if not cooperation_counts:
            return Action.D
        min_coop = min(cooperation_counts)
        max_coop = max(cooperation_counts)
        avg_coop = np.mean(cooperation_counts)
        if min_coop >= self.m:
            return Action.C
        if max_coop >= self.m and rounds_left <= 2:
            return Action.C
        if avg_coop >= (self.m - 1) * 0.6:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_17(BaseStrategy):
    """
    Adaptive Threshold Orchestration strategy for Collective Risk Dilemma.
    
    Balances self-protection against free-riders with threshold achievement
    through adaptive responsiveness to observed cooperation levels.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        coop_rate = self._calculate_cooperation_rate(history, round_num)
        if round_num == self.n_rounds - 1:
            threshold_high = (self.m - 1) / self.n_players
            if coop_rate >= threshold_high:
                return Action.C
            else:
                return Action.D
        return self._decide_middle_round(coop_rate)

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate cooperation rate from all players across all previous rounds.
        Returns: (total cooperators in history) / (n_players Ã— round_num)
        """
        if round_num == 0:
            return 0.0
        my_cooperations = np.sum(history.my_actions[:round_num])
        opponent_cooperations = np.sum(history.opponent_actions[:round_num, :])
        total_cooperations = my_cooperations + opponent_cooperations
        total_possible = self.n_players * round_num
        if total_possible == 0:
            return 0.0
        return total_cooperations / total_possible

    def _decide_middle_round(self, coop_rate: float) -> Action:
        """
        Adaptive decision logic for rounds 1 to r-2.
        """
        if self.m == self.n_players:
            if coop_rate >= 1.0:
                return Action.C
            else:
                return Action.D
        if self.m == 2:
            return Action.C
        threshold_high = (self.m - 1) / self.n_players
        threshold_moderate = (self.m - 2) / self.n_players
        if coop_rate >= threshold_high:
            return Action.C
        if coop_rate >= threshold_moderate:
            if self.k > 2.0:
                p_adapt = 0.5 + 0.5 * (1 - coop_rate)
            else:
                p_adapt = 1 - coop_rate
            if random.random() < p_adapt:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_18(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS)
    
    Treats the collective risk dilemma as a trust-building problem with calculated risk management.
    Cooperates in round 1 to gather information, then makes decisions based on:
    - Current cooperation rate (proportion of cooperators in previous round)
    - Historical success rate (proportion of rounds where threshold m was met)
    Defects in the final round (no future reputation to protect).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.history_cooperators = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.r - 1:
            return Action.D
        previous_round_cooperators = int(history.my_actions[round_number - 1]) + int(np.sum(history.opponent_actions[round_number - 1, :]))
        self.history_cooperators.append(previous_round_cooperators)
        current_cooperation_rate = previous_round_cooperators / self.n
        successful_rounds = sum((1 for coop_count in self.history_cooperators if coop_count >= self.m))
        total_past_rounds = len(self.history_cooperators)
        success_rate = successful_rounds / total_past_rounds if total_past_rounds > 0 else 0.0
        threshold_cooperation_rate = self.m / self.n
        threshold_minus_one_rate = (self.m - 1) / self.n
        if current_cooperation_rate >= threshold_cooperation_rate and success_rate >= 0.5:
            return Action.C
        elif current_cooperation_rate >= threshold_minus_one_rate and success_rate >= 0.7:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_19(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances individual payoff maximization with collective welfare by:
    1. Cooperating when cooperation is likely to succeed (threshold will be met)
    2. Defecting strategically when cooperation is unlikely
    3. Adapting to observed group behavior across rounds
    4. Weighting later rounds more heavily to maximize final payoff
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            return self._final_round_decision(history)
        return self._midgame_decision(history, current_round)

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """
        Final round decision: cooperate only if historical evidence is strong.
        """
        threshold_rate = self._calculate_threshold_achievement_rate(history)
        if threshold_rate > 0.9:
            return Action.C
        else:
            return Action.D

    def _midgame_decision(self, history: PlayerHistory, current_round: int) -> Action:
        """
        Mid-game rounds: Use deficit-based decision rule with probabilistic free-riding.
        """
        prev_round_idx = current_round - 1
        prev_cooperators = int(sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            prev_cooperators += 1
        deficit = self.m - prev_cooperators
        if deficit <= 0:
            cooperation_prob = (self.k - 1.0) / self.k
            if random.random() < cooperation_prob:
                return Action.C
            else:
                return Action.D
        elif deficit > 0 and deficit <= (self.n - self.m) / 2.0:
            return Action.C
        else:
            return Action.D

    def _calculate_threshold_achievement_rate(self, history: PlayerHistory) -> float:
        """
        Calculate the proportion of past rounds where threshold m was met.
        Counts both own and opponents' actions.
        """
        n_past_rounds = history.my_actions.shape[0]
        if n_past_rounds == 0:
            return 0.0
        threshold_count = 0
        for round_idx in range(n_past_rounds):
            opponent_cooperators = int(sum(history.opponent_actions[round_idx, :]))
            total_cooperators = opponent_cooperators
            if history.my_actions[round_idx]:
                total_cooperators += 1
            if total_cooperators >= self.m:
                threshold_count += 1
        return threshold_count / n_past_rounds

class Strategy_COLLECTIVE_20(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS)
    
    Balances aggressive early cooperation with responsive adjustment to demonstrated
    group behavior, tracking threshold momentum and pivoting defensively when cooperation
    signals are weak. Prioritizes achieving the m-cooperator threshold through trust-building
    and avoiding unraveling in final rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        cooperators_prev = int(np.sum(history.opponent_actions[current_round - 1, :]))
        cooperation_ratio = cooperators_prev / self.n
        cooperation_streak = self._calculate_cooperation_streak(history, current_round)
        if cooperation_ratio >= self.m / self.n * 1.2 and cooperation_streak >= 1:
            return Action.C
        early_phase_threshold = math.ceil(self.r / 3)
        if current_round <= early_phase_threshold and cooperators_prev >= self.m - 1:
            return Action.C
        bootstrap_threshold = math.ceil(self.r / 2)
        if current_round <= bootstrap_threshold and cooperators_prev >= self.m:
            return Action.C
        endgame_threshold = math.ceil(2 * self.r / 3)
        if current_round > endgame_threshold and cooperation_streak >= 2:
            return Action.C
        fair_share_min = self.m / self.n * 0.95
        fair_share_max = self.m / self.n * 1.5
        if cooperation_ratio >= fair_share_min and cooperation_ratio <= fair_share_max:
            return Action.C
        return Action.D

    def _calculate_cooperation_streak(self, history: PlayerHistory, current_round: int) -> int:
        """
        Count consecutive rounds (ending at current_round - 1) where m or more players cooperated.
        Returns the length of the streak, or 0 if the most recent round had fewer than m cooperators.
        """
        streak = 0
        for round_idx in range(current_round - 1, -1, -1):
            cooperators_in_round = int(np.sum(history.opponent_actions[round_idx, :]))
            if cooperators_in_round >= self.m:
                streak += 1
            else:
                break
        return streak

class Strategy_COLLECTIVE_21(BaseStrategy):
    """
    Adaptive Threshold Commitment Strategy (ATCS) for Collective Risk Dilemma.
    
    Balances collective benefit maximization with robust defection against free-riders
    through conditional cooperation with adaptive thresholds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.early_end = math.floor(self.r / 3)
        self.middle_end = math.floor(2 * self.r / 3)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_idx = round_num - 1
        cooperators_prev = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        cooperation_rate = cooperators_prev / self.n
        if round_num == self.r - 1:
            threshold_rate = self.m / self.n
            if cooperation_rate >= threshold_rate:
                return Action.C
            elif cooperation_rate >= threshold_rate * 0.8:
                return Action.C
            else:
                return Action.D
        if self.m == 2:
            if round_num <= 1:
                return Action.C
            elif cooperators_prev < 2:
                return Action.D
            else:
                return Action.C
        if self.m == self.n:
            if round_num <= 1:
                return Action.C
            elif cooperators_prev < self.n - 1:
                return Action.D
            else:
                return Action.C
        threshold_rate = self.m / self.n
        if self.k > 3:
            tolerance_high = 0.85
            tolerance_mid = 0.6
            tolerance_low = 0.45
        elif self.k <= 1.5:
            tolerance_high = 1.05
            tolerance_mid = 0.55
            tolerance_low = 0.35
        else:
            tolerance_high = 0.75
            tolerance_mid = 0.5
            tolerance_low = 0.5
        if cooperation_rate >= threshold_rate:
            return Action.C
        elif cooperation_rate >= threshold_rate * tolerance_high:
            return Action.C
        elif cooperation_rate >= threshold_rate * tolerance_mid and round_num <= self.middle_end:
            return Action.C
        elif cooperation_rate < threshold_rate * tolerance_low and round_num > self.middle_end:
            return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_22(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual security with collective benefit by dynamically adjusting
    cooperation based on collective health, temporal position, and risk assessment.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        c_prev = int(sum(history.opponent_actions[round_number - 1, :]))
        deficit = self.m - c_prev
        if round_number == self.r - 1:
            if c_prev >= self.m:
                return Action.D
            else:
                p_cooperate = deficit / self.m if self.m > 0 else 0
                return Action.C if random.random() < p_cooperate else Action.D
        else:
            if c_prev >= self.m:
                p_cooperate = 1.0 / self.k
            else:
                threshold_third = (self.n - 1) / 3.0
                if deficit <= threshold_third:
                    p_cooperate = 1.0 - deficit / (self.n - 1) if self.n > 1 else 1.0
                else:
                    p_cooperate = max(1.0 / self.k, deficit / (self.n - 1)) if self.n > 1 else 1.0 / self.k
            return Action.C if random.random() < p_cooperate else Action.D

class Strategy_COLLECTIVE_23(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances collective benefit-seeking with individual payoff protection by:
    1. Tracking observed cooperation rates across rounds
    2. Estimating probability of threshold success
    3. Cooperating when threshold achievement is sufficiently probable
    4. Adapting behavior based on game phase (early, middle, final rounds)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_confidence = (self.m - 1) / (self.n - 1) if self.n > 1 else 0
        self.near_threshold_buffer = 1 / (self.n - 1) if self.n > 1 else 0
        self.final_threshold = self.m / self.n
        self.smoothed_coop_rate = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            if self.m == self.n:
                return Action.C
            else:
                return Action.D
        prev_round_idx = round_num - 1
        cooperators_prev = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        total_cooperators_prev = cooperators_prev
        coop_rate = total_cooperators_prev / self.n
        if self.smoothed_coop_rate is None:
            self.smoothed_coop_rate = coop_rate
        else:
            self.smoothed_coop_rate = 0.7 * coop_rate + 0.3 * self.smoothed_coop_rate
        if round_num <= 2 and cooperators_prev == 0:
            return Action.D
        if self.n == 2 and self.m == 2:
            return Action.C if history.opponent_actions[prev_round_idx, 0] else Action.D
        if round_num == self.r - 1:
            if self.smoothed_coop_rate >= self.final_threshold:
                return Action.C
            else:
                return Action.D
        if self.smoothed_coop_rate >= self.threshold_confidence:
            return Action.C
        elif self.smoothed_coop_rate >= self.threshold_confidence - self.near_threshold_buffer:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_24(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual incentives with collective goals by:
    - Always cooperating in round 1 to signal willingness
    - Maintaining cooperation once threshold m is met
    - Adapting strategically to observed cooperation rates
    - Testing opponent commitment through selective defection
    - Defecting in final round unless threshold was already met
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        t = state.round_number
        if t == 0:
            return Action.C
        my_action_last = history.my_actions[t - 1]
        opponent_actions_last = history.opponent_actions[t - 1, :]
        cooperators_last_round = int(my_action_last) + int(np.sum(opponent_actions_last))
        if cooperators_last_round >= m:
            return Action.C
        if t == r - 1:
            return Action.D
        cooperation_deficit = m - cooperators_last_round
        rounds_remaining = r - t
        opponent_cooperators_last = int(np.sum(opponent_actions_last))
        cooperation_rate = opponent_cooperators_last / (n - 1) if n > 1 else 0.0
        expected_cooperators_next = cooperation_rate * (n - 1)
        if expected_cooperators_next + 1.0 >= m:
            return Action.C
        if expected_cooperators_next < m - 1:
            return Action.D
        if rounds_remaining > 0:
            threshold_probability = expected_cooperators_next / m if m > 0 else 0.0
            threshold_ratio = (rounds_remaining - 1) / rounds_remaining if rounds_remaining > 0 else 0.0
            if threshold_probability > threshold_ratio:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_25(BaseStrategy):
    """
    Adaptive Threshold Matching (ATM) Strategy for Collective Risk Dilemma.
    
    Balances individual security with collective benefit by:
    1. Cooperating in round 1 to bootstrap cooperation
    2. In middle rounds, adapting threshold based on observed cooperation rate
    3. In final round, defecting unless group is near-unanimous and I'm critical
    
    The core decision: cooperate if expected cooperators (excluding me) >= m-1
    AND recent cooperation rate exceeds an adaptive threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.r - 1:
            coop_rate = self._calculate_cooperation_rate(history, round_number)
            if coop_rate >= 0.7 and self._am_i_critical(history, round_number):
                return Action.C
            return Action.D
        coop_rate = self._calculate_cooperation_rate(history, round_number)
        adaptive_threshold = self._get_adaptive_threshold(round_number, coop_rate)
        expected_cooperators_excluding_me = self._estimate_others_cooperation(coop_rate)
        if expected_cooperators_excluding_me >= self.m - 1:
            if coop_rate >= adaptive_threshold:
                return Action.C
        return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_number: int) -> float:
        """
        Calculate cooperation rate over a sliding window of recent rounds.
        Window size is min(5, number of completed rounds).
        """
        num_completed_rounds = round_number
        if num_completed_rounds == 0:
            return 0.0
        window_size = min(5, num_completed_rounds)
        start_idx = num_completed_rounds - window_size
        my_cooperations = np.sum(history.my_actions[start_idx:num_completed_rounds])
        opponent_cooperations = np.sum(history.opponent_actions[start_idx:num_completed_rounds, :])
        total_actions = window_size * self.n
        total_cooperations = my_cooperations + opponent_cooperations
        if total_actions == 0:
            return 0.0
        return float(total_cooperations) / float(total_actions)

    def _get_adaptive_threshold(self, round_number: int, coop_rate: float) -> float:
        """
        Determine adaptive threshold based on round number and cooperation rate.
        """
        if round_number <= 2:
            return 0.4
        if coop_rate >= 0.6:
            return 0.5
        elif coop_rate >= 0.3:
            return 0.4
        else:
            return 0.2

    def _estimate_others_cooperation(self, coop_rate: float) -> int:
        """
        Estimate number of cooperators among other players (excluding me).
        Uses cooperation rate scaled to n-1 players.
        """
        expected = coop_rate * (self.n - 1)
        return int(round(expected))

    def _am_i_critical(self, history: PlayerHistory, round_number: int) -> bool:
        """
        Determine if I'm a critical player for achieving threshold.
        This is a simplified heuristic: check if in the last round,
        the number of cooperators was exactly m-1 (meaning my defection breaks it).
        """
        if round_number == 0:
            return False
        last_round_idx = round_number - 1
        my_last_action = history.my_actions[last_round_idx]
        opponent_last_actions = history.opponent_actions[last_round_idx, :]
        opponent_cooperators = int(np.sum(opponent_last_actions))
        my_contribution = 1 if my_last_action else 0
        total_cooperators = opponent_cooperators + my_contribution
        return total_cooperators >= self.m and total_cooperators - my_contribution < self.m

class Strategy_COLLECTIVE_26(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS)
    
    Dynamically estimates the probability that cooperation will succeed by observing
    cooperation rates in previous rounds. Cooperates when observed cooperation meets
    or exceeds the success threshold (m/n), defects otherwise. Special handling for
    first and last rounds based on threshold analysis and end-game incentives.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.success_threshold = self.m / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            if self.success_threshold <= 0.5:
                return Action.C
            else:
                return Action.D
        if round_number == self.n_rounds - 1:
            cooperation_count_prev = int(np.sum(history.opponent_actions[round_number - 1, :]))
            cooperation_count_prev += int(history.my_actions[round_number - 1])
            if cooperation_count_prev >= self.m:
                return Action.C
            else:
                return Action.D
        cooperation_count_prev = int(np.sum(history.opponent_actions[round_number - 1, :]))
        cooperation_count_prev += int(history.my_actions[round_number - 1])
        cpe = cooperation_count_prev / self.n_players
        if cpe >= self.success_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_27(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Cooperating in round 1 to establish trust
    2. Dynamically responding to cooperation rates in middle rounds
    3. Defecting in final round if threshold met, cooperating if not
    
    Uses escalation threshold mechanism to identify critical moments when
    cooperation is mathematically necessary and feasible.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.escalation_threshold = (self.m - 0.5) / self.n_players
        self.threshold_rate = self.m / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            threshold_met_previously = self._check_threshold_met(history, current_round)
            if threshold_met_previously:
                return Action.D
            else:
                return Action.C
        cooperation_rate = self._calculate_cooperation_rate(history, current_round)
        if cooperation_rate >= self.threshold_rate:
            return Action.D
        min_viable_rate = (self.m - 1) / self.n_players
        if cooperation_rate < min_viable_rate:
            return Action.D
        previous_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        cooperation_gap = self.m - previous_cooperators - 1
        rounds_remaining = self.n_rounds - current_round
        if cooperation_gap <= rounds_remaining and cooperation_rate >= self.escalation_threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the cooperation rate from opponents in the most recent round.
        Returns proportion of opponents who cooperated in round (current_round - 1).
        """
        if current_round <= 0:
            return 0.0
        recent_round = current_round - 1
        cooperators = int(np.sum(history.opponent_actions[recent_round, :]))
        if self.n_players == 0:
            return 0.0
        return cooperators / self.n_players

    def _check_threshold_met(self, history: PlayerHistory, current_round: int) -> bool:
        """
        Check if the threshold (m cooperators) has been met in any previous round.
        Counts total cooperators including self and opponents.
        """
        if current_round <= 0:
            return False
        for round_idx in range(current_round):
            my_contribution = 1 if history.my_actions[round_idx] else 0
            opponent_cooperation = int(np.sum(history.opponent_actions[round_idx, :]))
            total_cooperators = my_contribution + opponent_cooperation
            if total_cooperators >= self.m:
                return True
        return False

class Strategy_COLLECTIVE_28(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances individual security with collective benefit by dynamically adjusting
    cooperation based on observed cooperation rates, round position, and historical
    reliability of threshold achievement.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        last_round_cooperators = int(np.sum(history.opponent_actions[round_num - 1, :]))
        observed_coop_rate = last_round_cooperators / (self.n - 1) if self.n > 1 else 0.5
        expected_cooperators = observed_coop_rate * self.n
        threshold_likely = expected_cooperators >= self.m
        rounds_remaining = self.r - round_num
        if rounds_remaining <= 1:
            urgency_factor = 1.0
        else:
            urgency_factor = 0.5
        base_threshold = self.m / self.n
        if threshold_likely:
            required_confidence = base_threshold * 0.85
        else:
            required_confidence = base_threshold * 1.15
        my_last_action = history.my_actions[round_num - 1]
        stability_signal = 0.7 if my_last_action else 0.3
        effective_rate = observed_coop_rate * (1 - urgency_factor) + stability_signal * urgency_factor
        if effective_rate >= required_confidence:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_29(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances collective benefit maximization with individual protection by:
    - Cooperating unconditionally in early rounds to build reputation
    - Using empirical cooperation rates with optimism bias in mid-game
    - Cooperating in penultimate round to preserve reputation
    - Defecting in final round (backward induction)
    - Adapting thresholds based on observed cooperation trends
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.optimism_bias = 0.4

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == self.n_rounds - 1:
            return Action.D
        if current_round == self.n_rounds - 2:
            return Action.C
        if current_round <= 1:
            return Action.C
        cooperation_rate = self._calculate_cooperation_rate(history, current_round)
        expected_cooperators = self._predict_cooperation(cooperation_rate, current_round)
        threshold = self._get_adaptive_threshold(history, current_round)
        if expected_cooperators >= self.m:
            return Action.D
        elif expected_cooperators >= threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate empirical cooperation rate from opponent actions in previous rounds.
        Returns rate in [0, 1].
        """
        if current_round == 0:
            return 0.5
        total_cooperations = np.sum(history.opponent_actions[:current_round, :])
        total_possible = (self.n_players - 1) * current_round
        if total_possible == 0:
            return 0.5
        return float(total_cooperations) / float(total_possible)

    def _predict_cooperation(self, cooperation_rate: float, current_round: int) -> float:
        """
        Predict number of cooperators this round using cooperation rate and optimism bias.
        """
        expected_from_rate = (self.n_players - 1) * cooperation_rate
        optimism_adjustment = self.optimism_bias * (1.0 - cooperation_rate)
        adjusted_estimate = expected_from_rate + optimism_adjustment
        return adjusted_estimate

    def _get_adaptive_threshold(self, history: PlayerHistory, current_round: int) -> float:
        """
        Detect cooperation trends and return adaptive threshold.
        Base threshold is (m - 0.7) but increases if defection trend detected.
        """
        base_threshold = self.m - 0.7
        if current_round >= 4:
            recent_coop = self._get_cooperation_rate_window(history, current_round, 3)
            earlier_coop = self._get_cooperation_rate_window(history, current_round, 4, 6)
            if recent_coop < earlier_coop - 0.1:
                return float(self.m)
        if current_round >= 3:
            recent_coop = self._get_cooperation_rate_window(history, current_round, 3)
            if recent_coop > 0.7:
                return self.m - 1.5
        return base_threshold

    def _get_cooperation_rate_window(self, history: PlayerHistory, current_round: int, window_size: int, start_offset: int=None) -> float:
        """
        Calculate cooperation rate over a specific window of recent rounds.
        window_size: number of recent rounds to consider
        start_offset: if provided, look back from (current_round - start_offset)
        """
        if start_offset is None:
            start_offset = window_size
        start_idx = max(0, current_round - start_offset)
        end_idx = max(1, current_round - (start_offset - window_size))
        if start_idx >= end_idx or end_idx > current_round:
            return 0.5
        window_cooperations = np.sum(history.opponent_actions[start_idx:end_idx, :])
        window_possible = (self.n_players - 1) * (end_idx - start_idx)
        if window_possible == 0:
            return 0.5
        return float(window_cooperations) / float(window_possible)

class Strategy_COLLECTIVE_30(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances collective benefit maximization, individual protection, and robust adaptation
    by dynamically estimating opponent cooperation likelihood and adjusting cooperation probability.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            coop_rate = self._calculate_cooperation_rate(history, 0, current_round - 1)
            if coop_rate >= 0.7:
                return Action.C
            else:
                return Action.D
        cle = self._calculate_cle(history, current_round)
        cooperation_prob = self._calculate_cooperation_probability(cle, history, current_round)
        cooperation_prob = self._apply_free_rider_check(cooperation_prob, history, current_round)
        if random.random() < cooperation_prob:
            return Action.C
        else:
            return Action.D

    def _calculate_cle(self, history: PlayerHistory, current_round: int) -> float:
        """Calculate Cooperation Likelihood Estimate based on history."""
        if current_round == 0:
            return 0.5
        total_cooperators = 0
        for round_idx in range(current_round):
            round_cooperators = sum(history.opponent_actions[round_idx, :])
            total_cooperators += round_cooperators
        total_slots = current_round * self.n
        if total_slots == 0:
            return 0.5
        cle = total_cooperators / total_slots
        return cle

    def _calculate_cooperation_probability(self, cle: float, history: PlayerHistory, current_round: int) -> float:
        """Determine cooperation probability based on CLE and decision rules."""
        threshold_ratio = self.m / self.n
        lower_threshold_ratio = (self.m - 1) / self.n
        if cle >= threshold_ratio:
            return 1.0
        elif cle >= lower_threshold_ratio:
            numerator = cle * self.n - (self.m - 2)
            cooperation_prob = numerator / 2.0
            return max(0.0, min(1.0, cooperation_prob))
        else:
            cooperation_prob = max(0.0, cle - 1.0 / self.n)
            return cooperation_prob

    def _apply_free_rider_check(self, cooperation_prob: float, history: PlayerHistory, current_round: int) -> float:
        """Apply guilt-weighted adjustment for free-riding in previous round."""
        if current_round < 1:
            return cooperation_prob
        prev_round = current_round - 1
        cooperators_last_round = sum(history.opponent_actions[prev_round, :])
        my_action_last_round = history.my_actions[prev_round]
        if cooperators_last_round == self.m and (not my_action_last_round):
            cooperation_prob = min(0.7, cooperation_prob + 0.3)
        return cooperation_prob

    def _calculate_cooperation_rate(self, history: PlayerHistory, start_round: int, end_round: int) -> float:
        """Calculate the average cooperation rate across rounds for all players."""
        if start_round > end_round or end_round < 0:
            return 0.5
        total_cooperators = 0
        total_slots = 0
        for round_idx in range(start_round, end_round + 1):
            round_cooperators = sum(history.opponent_actions[round_idx, :])
            total_cooperators += round_cooperators
            total_slots += self.n
        if total_slots == 0:
            return 0.5
        return total_cooperators / total_slots

class Strategy_COLLECTIVE_31(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances individual security with collective benefit by dynamically adjusting
    cooperation based on observed cooperation rates, game parameters, and remaining rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.recovery_locked = False
        self.recovery_start_round = -1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return self._bootstrap_decision()
        rounds_remaining = self.r - round_num
        cooperation_count = np.sum(history.opponent_actions, axis=1)
        cooperation_rates = cooperation_count / self.n
        current_rate = cooperation_rates[-1]
        if self.recovery_locked:
            return Action.D
        if rounds_remaining > 2 and current_rate < self.m / self.n:
            if self.recovery_start_round < 0:
                self.recovery_start_round = round_num
            recovery_window = min(3, rounds_remaining)
            if round_num - self.recovery_start_round >= recovery_window:
                avg_rate_in_window = np.mean(cooperation_rates[max(0, round_num - recovery_window):round_num])
                if avg_rate_in_window < self.m / self.n:
                    self.recovery_locked = True
                    return Action.D
        historical_avg = np.mean(cooperation_rates)
        smoothed_rate = 0.7 * current_rate + 0.3 * historical_avg
        if round_num == self.r - 1:
            expected_cooperators = historical_avg * self.n
            if expected_cooperators >= self.m:
                return Action.C
            return Action.D
        if smoothed_rate < 0.05:
            return Action.D
        baseline_threshold = self.m / self.n
        risk_adjustment = 1.0 / self.k * 0.1
        time_adjustment = 0.05 * (round_num / self.r)
        adjusted_threshold = baseline_threshold + risk_adjustment + time_adjustment
        if smoothed_rate >= adjusted_threshold:
            return Action.C
        return Action.D

    def _bootstrap_decision(self) -> Action:
        """
        Determine whether to cooperate in the first round.
        
        Logic:
        - If k > 1.5: COOPERATE (high reward incentive)
        - Else if m <= n/2: COOPERATE (low threshold, likely success)
        - Else: DEFECT (risky to lead with high threshold and modest reward)
        """
        if self.k > 1.5:
            return Action.C
        if self.m <= self.n / 2.0:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_32(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances cooperation for collective reward against exploitation risk through:
    - Round 1: Cooperate to gather information
    - Rounds 2 to r-1: Adaptive probabilistic decisions based on observed cooperation rate
    - Round r: Context-dependent final round behavior
    - Exploitation detection and free-rider response
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.exploitation_signal_count = 0
        self.consecutive_cooperation_rounds = 0
        self.last_action_was_defect = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        observed_coop_rate = self._calculate_observed_cooperation_rate(history, current_round)
        if self._check_unanimous_defection(history, current_round):
            self.last_action_was_defect = True
            return Action.D
        if self._check_perfect_cooperation(history, current_round):
            self.last_action_was_defect = False
            return Action.C
        if current_round == self.n_rounds - 1:
            return self._decide_final_round(history, observed_coop_rate, current_round)
        return self._decide_adaptive_round(history, observed_coop_rate, current_round)

    def _calculate_observed_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """Calculate the observed cooperation rate from all previous rounds."""
        if current_round == 0:
            return 0.5
        total_cooperations = np.sum(history.opponent_actions[:current_round, :])
        total_possible = self.n_players * current_round
        if total_possible == 0:
            return 0.5
        return total_cooperations / total_possible

    def _check_unanimous_defection(self, history: PlayerHistory, current_round: int) -> bool:
        """Check if all other players defected in the previous round."""
        if current_round == 0:
            return False
        previous_round_defections = np.sum(history.opponent_actions[current_round - 1, :] == False)
        return previous_round_defections == self.n_players

    def _check_perfect_cooperation(self, history: PlayerHistory, current_round: int) -> bool:
        """Check if all players cooperated in the previous round."""
        if current_round == 0:
            return False
        if history.my_actions[current_round - 1] == False:
            return False
        previous_round_cooperations = np.sum(history.opponent_actions[current_round - 1, :])
        return previous_round_cooperations == self.n_players

    def _update_exploitation_tracking(self, history: PlayerHistory, current_round: int) -> None:
        """Update exploitation signal count based on recent history."""
        if current_round < 1:
            return
        start_round = max(0, current_round - 3)
        for round_idx in range(start_round, current_round):
            if history.my_actions[round_idx]:
                cooperator_count = np.sum(history.opponent_actions[round_idx, :]) + 1
                if cooperator_count < self.m:
                    self.exploitation_signal_count += 1
        if self.exploitation_signal_count > 6:
            self.exploitation_signal_count = 6

    def _decide_adaptive_round(self, history: PlayerHistory, observed_coop_rate: float, current_round: int) -> Action:
        """Decide action for rounds 2 to r-1."""
        self._update_exploitation_tracking(history, current_round)
        threshold_confidence = observed_coop_rate * self.n_players
        if threshold_confidence >= self.m:
            likelihood_success = 'MODERATE_TO_HIGH'
        elif threshold_confidence >= self.m - 1:
            likelihood_success = 'UNCERTAIN'
        else:
            likelihood_success = 'LOW'
        if likelihood_success == 'MODERATE_TO_HIGH':
            self.last_action_was_defect = False
            self.consecutive_cooperation_rounds += 1
            return Action.C
        elif likelihood_success == 'UNCERTAIN':
            p_uncertain = threshold_confidence / self.m
            if self.exploitation_signal_count >= 2:
                p_uncertain = max(0.1, p_uncertain - 0.15)
            if random.random() < p_uncertain:
                self.last_action_was_defect = False
                self.consecutive_cooperation_rounds += 1
                return Action.C
            else:
                self.last_action_was_defect = True
                self.consecutive_cooperation_rounds = 0
                return Action.D
        else:
            threshold_ratio = self.m / self.n_players
            if threshold_ratio <= 0.34:
                if random.random() < 0.4:
                    self.last_action_was_defect = False
                    self.consecutive_cooperation_rounds += 1
                    return Action.C
            self.last_action_was_defect = True
            self.consecutive_cooperation_rounds = 0
            return Action.D

    def _decide_final_round(self, history: PlayerHistory, observed_coop_rate: float, current_round: int) -> Action:
        """Decide action for the final round."""
        threshold_for_success = (self.m - 1) / self.n_players
        if observed_coop_rate >= threshold_for_success and self.consecutive_cooperation_rounds >= 2:
            self.last_action_was_defect = False
            return Action.C
        elif observed_coop_rate < threshold_for_success and (not self.last_action_was_defect):
            self.last_action_was_defect = True
            return Action.D
        else:
            threshold_confidence = observed_coop_rate * self.n_players
            p_uncertain = threshold_confidence / self.m if self.m > 0 else 0.5
            p_uncertain = max(0.1, min(0.9, p_uncertain))
            if random.random() < p_uncertain:
                self.last_action_was_defect = False
                return Action.C
            else:
                self.last_action_was_defect = True
                return Action.D

class Strategy_COLLECTIVE_33(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances collective survival (reaching threshold m) with individual rationality.
    - Round 1: Cooperate to establish intent and gather information
    - Rounds 2 to r-1: Cooperate if threshold is achievable (cooperators >= m-1), else defect
    - Round r: Final push - cooperate if threshold still achievable, else defect
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if state.round_number == 0:
            return Action.C
        cooperators_last_round = int(sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            cooperators_last_round += 1
        if state.round_number < r - 1:
            if cooperators_last_round >= m - 1:
                return Action.C
            else:
                return Action.D
        elif cooperators_last_round >= m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_34(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances individual risk management with collective benefit maximization by:
    - Starting with defection to gather information (round 1)
    - Adaptively estimating cooperation propensity from history
    - Cooperating when expected cooperators meet threshold with sufficient confidence
    - Defecting in final round (backward induction)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        return self._adaptive_decision(current_round, history)

    def _adaptive_decision(self, current_round: int, history: PlayerHistory) -> Action:
        """
        Implements the adaptive confidence-based cooperation logic.
        """
        total_prior_rounds = current_round
        total_cooperators = int(np.sum(history.opponent_actions[:current_round, :]))
        if total_prior_rounds == 0:
            return Action.D
        coop_rate = total_cooperators / (self.n * total_prior_rounds)
        expected_cooperators = round(self.n * coop_rate)
        if expected_cooperators < self.m:
            return Action.D
        confidence = (expected_cooperators - self.m) / self.n if self.n > 0 else 0
        prior_round_idx = current_round - 1
        prior_round_cooperators = int(np.sum(history.opponent_actions[prior_round_idx, :]))
        if prior_round_cooperators >= self.m:
            confidence += 0.15
        else:
            confidence -= 0.25
        confidence = max(0.0, min(1.0, confidence))
        threshold_value = (1.0 - 1.0 / self.k) * 0.5
        if self.k > 2.0:
            threshold_value += 0.2
        elif self.k < 1.2:
            threshold_value -= 0.15
        threshold_value = max(0.0, min(1.0, threshold_value))
        if confidence >= threshold_value:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_35(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances collective welfare with individual rationality by:
    1. Cooperating in round 1 to establish trust
    2. Defecting in final round (no future consequences)
    3. Dynamically adjusting cooperation threshold based on game phase
    4. Early rounds: Optimistic (target m-1 cooperators)
    5. Late rounds: Conservative (target m cooperators)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.n_rounds - 1:
            return Action.D
        previous_round_idx = round_number - 1
        opponent_cooperators = int(np.sum(history.opponent_actions[previous_round_idx, :]))
        self_cooperated = int(history.my_actions[previous_round_idx])
        total_cooperators = opponent_cooperators + self_cooperated
        if self.n_rounds <= 2:
            progress_ratio = 0.5
        else:
            progress_ratio = (round_number - 1) / (self.n_rounds - 2)
        dynamic_threshold = self.m - (1.0 - progress_ratio) * 0.9
        threshold_to_meet = math.ceil(dynamic_threshold)
        if total_cooperators >= threshold_to_meet:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_36(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Cooperating in round 1 to signal willingness
    2. Adapting to empirical cooperation rates in intermediate rounds
    3. Defecting in final round unless collective success is assured
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if state.round_number == 0:
            return Action.C
        if state.round_number == r - 1:
            cooperators_prev = int(np.sum(history.opponent_actions[state.round_number - 1, :]))
            cooperation_rate_prev = cooperators_prev / n
            threshold_rate = m / n
            if cooperation_rate_prev >= threshold_rate:
                if cooperators_prev >= m:
                    return Action.C
            return Action.D
        cooperators_last = int(np.sum(history.opponent_actions[state.round_number - 1, :]))
        cooperation_rate = cooperators_last / n
        threshold_rate = m / n
        if cooperation_rate >= threshold_rate:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_37(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Dynamically adjusts contribution based on estimated cooperation tendency,
    tracking deficit relative to threshold m, and exploiting free-rider
    opportunities only when threshold is secure.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        last_round_actions = history.opponent_actions[round_num - 1, :]
        last_round_cooperation_count = int(np.sum(last_round_actions))
        my_last_action = history.my_actions[round_num - 1]
        if my_last_action:
            last_round_cooperation_count += 1
        cooperation_rate = last_round_cooperation_count / self.n_players
        deficit = self.m - last_round_cooperation_count
        rounds_remaining = self.n_rounds - round_num
        if round_num == self.n_rounds - 1:
            if last_round_cooperation_count >= self.m:
                return Action.D
            else:
                return Action.C
        if last_round_cooperation_count >= self.m:
            if deficit <= 1 and rounds_remaining >= 2:
                if random.random() < 0.3:
                    return Action.D
                else:
                    return Action.C
            else:
                return Action.C
        if last_round_cooperation_count == self.m - 1:
            return Action.C
        if cooperation_rate <= 0.25:
            return Action.D
        non_cooperators = self.n_players - last_round_cooperation_count
        if non_cooperators > 0:
            required_switch_rate = deficit / non_cooperators
        else:
            required_switch_rate = 0.0
        if required_switch_rate <= 0.5 and rounds_remaining >= 2:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_38(BaseStrategy):
    """
    Adaptive Threshold Matching (ATM) for Collective Risk Dilemma.
    
    Balances cooperative resilience, defect-resistance, adaptive learning,
    and collective accountability. Coordinates toward the m-cooperator threshold
    while avoiding exploitation by pure defectors.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        previous_round_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if current_round == r - 1:
            if previous_round_cooperators >= m - 1:
                return Action.C
            else:
                return Action.D
        if previous_round_cooperators >= m:
            return Action.C
        elif previous_round_cooperators == m - 1:
            return Action.C
        elif previous_round_cooperators >= math.ceil(m / 2):
            return Action.C
        elif current_round < r - 2:
            return Action.D
        elif previous_round_cooperators >= m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_39(BaseStrategy):
    """
    Adaptive Threshold Sentinel (ATS) Strategy for Collective Risk Dilemma.
    
    This strategy treats the game as a coordination problem, aiming to:
    1. Achieve threshold cooperation when possible (collective benefit)
    2. Minimize exploitation when others defect
    3. Signal cooperativeness while remaining robust to free-riders
    
    Uses adaptive decision-making based on observed cooperation rates and
    confidence in achieving the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_rate = self.m / self.n
        self.safety_buffer = 0.5 / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        cooperation_count = int(np.sum(history.opponent_actions[current_round - 1, :]))
        cooperation_rate = cooperation_count / self.n
        own_cooperated_last = bool(history.my_actions[current_round - 1])
        recent_trend_positive = False
        if current_round >= 2:
            prev_cooperation = int(np.sum(history.opponent_actions[current_round - 2, :])) / self.n
            curr_cooperation = cooperation_rate
            recent_trend_positive = curr_cooperation > prev_cooperation or (curr_cooperation >= self.threshold_rate and prev_cooperation >= self.threshold_rate)
        elif current_round == 1:
            recent_trend_positive = cooperation_rate > 0
        if current_round == self.r - 1:
            if cooperation_count >= self.m - 1:
                return Action.C
            if cooperation_count >= self.m:
                return Action.C
            return Action.D
        threshold_margin = cooperation_rate - self.threshold_rate
        if cooperation_rate >= self.threshold_rate + self.safety_buffer:
            return Action.C
        elif cooperation_rate >= self.threshold_rate - self.safety_buffer:
            if cooperation_rate >= (self.m - 1) / self.n:
                if random.random() < 0.7:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.C
        elif cooperation_count > 0:
            rounds_remaining = self.r - current_round
            if rounds_remaining >= 1 and recent_trend_positive:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_40(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Dynamically adjusts cooperation based on observed cooperation rates and remaining rounds.
    Initiates cooperation, monitors threshold achievability, and adapts when cooperation
    appears unachievable while prioritizing collective success when possible.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        prev_round_idx = round_number - 1
        opponent_cooperators_prev = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        total_cooperators_prev = opponent_cooperators_prev + (1 if history.my_actions[prev_round_idx] else 0)
        observed_coop_rate = total_cooperators_prev / self.n_players
        threshold_ratio = self.m / self.n_players
        near_threshold_ratio = (self.m - 1) / self.n_players
        far_below_ratio = (self.m - 2) / self.n_players
        rounds_remaining_after = self.n_rounds - round_number - 1
        is_penultimate = round_number == self.n_rounds - 2
        is_final = round_number == self.n_rounds - 1
        if is_penultimate:
            if observed_coop_rate >= near_threshold_ratio:
                return Action.C
            else:
                return Action.D
        if is_final:
            if observed_coop_rate >= near_threshold_ratio:
                return Action.C
            else:
                return Action.D
        if observed_coop_rate >= threshold_ratio:
            return Action.C
        if observed_coop_rate >= near_threshold_ratio:
            return Action.C
        if observed_coop_rate >= far_below_ratio and rounds_remaining_after >= 3:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_41(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual payoff maximization with collective risk mitigation through:
    - Initial cooperation to signal willingness and test environment
    - Adaptive mid-game decisions based on cooperation rates relative to threshold
    - Final round defection (backward induction)
    - Early collapse detection to minimize losses
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.collapse_detected = False
        self.collapse_round = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        rounds_remaining = r - current_round
        cooperators_prev = int(sum(history.opponent_actions[current_round - 1, :]))
        cooperation_rate_prev = cooperators_prev / n if n > 0 else 0
        threshold_rate = m / n if n > 0 else 0
        if cooperation_rate_prev < 0.1 * threshold_rate:
            if self.collapse_round is None:
                self.collapse_round = current_round
            elif current_round - self.collapse_round >= 1:
                self.collapse_detected = True
        else:
            self.collapse_round = None
        if self.collapse_detected:
            return Action.D
        if current_round == r - 1:
            return Action.D
        if cooperation_rate_prev >= threshold_rate:
            return Action.D
        elif cooperation_rate_prev >= 0.75 * threshold_rate:
            return Action.C
        elif cooperation_rate_prev >= 0.5 * threshold_rate:
            if rounds_remaining >= 3:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_42(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATC) for Collective Risk Dilemma.
    
    Dynamically adjusts cooperation based on observed cooperation rates and payoff trends,
    balancing individual security with collective benefit by targeting the threshold m.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        my_actions = history.my_actions[:current_round]
        opponent_actions = history.opponent_actions[:current_round, :]
        recent_window = min(5, current_round)
        recent_actions = opponent_actions[current_round - recent_window:current_round, :]
        recent_cooperators_opponents = np.sum(recent_actions)
        recent_cooperators_self = np.sum(my_actions[current_round - recent_window:current_round])
        total_recent_cooperators = recent_cooperators_opponents + recent_cooperators_self
        if recent_window * self.n > 0:
            observed_coop_rate = total_recent_cooperators / (recent_window * self.n)
        else:
            observed_coop_rate = 0.0
        expected_cooperators = round(self.n * observed_coop_rate)
        if current_round == self.r - 1:
            total_cooperators_so_far = np.sum(my_actions) + np.sum(opponent_actions)
            my_cooperation_count = np.sum(my_actions)
            if total_cooperators_so_far >= self.m * (self.r - 1):
                return Action.C
            elif my_cooperation_count >= 1 and observed_coop_rate >= 0.3:
                return Action.C
            else:
                return Action.D
        if expected_cooperators >= self.m:
            return Action.C
        elif expected_cooperators == self.m - 1:
            momentum = self._calculate_momentum(opponent_actions, my_actions, current_round)
            if momentum == 'increasing' or momentum == 'stable':
                return Action.C
            else:
                return Action.D
        elif expected_cooperators < self.m - 1:
            if self.m == self.n:
                if np.sum(opponent_actions) == current_round * self.n:
                    return Action.C
                else:
                    return Action.D
            if current_round >= 3:
                recent_three = opponent_actions[current_round - 3:current_round, :]
                if np.sum(recent_three) == 0 and np.sum(my_actions[current_round - 3:current_round]) == 0:
                    return Action.D
            return Action.D
        return Action.D

    def _calculate_momentum(self, opponent_actions: NDArray[np.bool_], my_actions: NDArray[np.bool_], current_round: int) -> str:
        """
        Calculate cooperation momentum (increasing, stable, or decreasing).
        """
        if current_round < 2:
            return 'stable'
        mid = max(1, current_round // 2)
        first_half_coops = np.sum(opponent_actions[:mid, :]) + np.sum(my_actions[:mid])
        first_half_rate = first_half_coops / (mid * self.n) if mid * self.n > 0 else 0.0
        second_half_coops = np.sum(opponent_actions[mid:current_round, :]) + np.sum(my_actions[mid:current_round])
        second_half_rounds = current_round - mid
        second_half_rate = second_half_coops / (second_half_rounds * self.n) if second_half_rounds * self.n > 0 else 0.0
        threshold = 0.05
        if second_half_rate > first_half_rate + threshold:
            return 'increasing'
        elif second_half_rate < first_half_rate - threshold:
            return 'decreasing'
        else:
            return 'stable'

class Strategy_COLLECTIVE_43(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual security with collective efficiency by adapting decisions
    based on observed cooperation rates and game phase (early/middle/late).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.early_threshold = math.ceil(self.r / 3)
        self.late_threshold = math.ceil(2 * self.r / 3)
        threshold_ratio = self.m / self.n
        if threshold_ratio > 0.75:
            self.close_enough_factor = 0.5
        elif threshold_ratio < 0.33:
            self.close_enough_factor = 0.75
        else:
            self.close_enough_factor = 0.6

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        prev_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if history.my_actions[current_round - 1]:
            prev_cooperators += 1
        prev_coop_rate = prev_cooperators / self.n if self.n > 0 else 0.0
        deficit = self.m - prev_cooperators
        rounds_remaining = self.r - current_round
        if current_round > self.late_threshold:
            if rounds_remaining <= 2:
                return Action.D
        if current_round <= self.early_threshold:
            if prev_coop_rate == 0.0:
                return Action.C
            if prev_coop_rate >= self.m / self.n:
                return Action.C
            if prev_coop_rate >= self.close_enough_factor * (self.m / self.n):
                return Action.C
            return Action.D
        if prev_coop_rate >= self.m / self.n:
            return Action.C
        if deficit <= 2 and prev_coop_rate >= 0.5 * (self.m / self.n):
            return Action.C
        if deficit > 2 and prev_coop_rate < 0.4 * (self.m / self.n):
            return Action.D
        return Action.C

class Strategy_COLLECTIVE_44(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Dynamically estimates cooperation probability based on observed history
    and cooperates when the threshold is likely to be met. Uses reciprocal
    adaptation with special handling for first and last rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.cooperation_history = []
        self.collapse_detector = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            threshold_ratio = self.m / self.n
            if threshold_ratio >= 0.5:
                return Action.C
            else:
                return Action.D
        last_cooperators = int(np.sum(history.opponent_actions[round_num - 1, :]))
        self.cooperation_history.append(last_cooperators)
        collapse_threshold = (self.m - 1) / self.n
        if len(self.cooperation_history) >= 2:
            recent_rate = np.mean(self.cooperation_history[-2:]) / self.n
            if recent_rate < collapse_threshold:
                self.collapse_detector.append(True)
            else:
                self.collapse_detector.append(False)
            if len(self.collapse_detector) >= 2 and all(self.collapse_detector[-2:]):
                return Action.D
        if round_num == self.r - 1:
            if last_cooperators >= self.m:
                return Action.D
            elif last_cooperators + 1 >= self.m:
                return Action.C
            else:
                return Action.D
        if len(self.cooperation_history) == 0:
            avg_cooperation_rate = self.m / self.n
        else:
            avg_cooperation_rate = np.mean(self.cooperation_history) / self.n
        weighted_cooperation_rate = last_cooperators / self.n * 0.6 + avg_cooperation_rate * 0.4
        expected_cooperators = self.n * weighted_cooperation_rate
        expected_total_if_cooperate = expected_cooperators + 1
        expected_total_if_defect = expected_cooperators
        if last_cooperators == self.n:
            rand_val = random.random()
            if rand_val < 0.95:
                return Action.C
            else:
                return Action.D
        if expected_total_if_cooperate >= self.m:
            denom = self.n - self.m
            if denom > 0:
                confidence = (expected_total_if_cooperate - self.m) / denom
            else:
                confidence = 1.0
            confidence = min(confidence, 1.0)
            confidence = max(confidence, 0.0)
            if confidence >= 0.3:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_45(BaseStrategy):
    """
    Adaptive Threshold Cooperation with Decay strategy for Collective Risk Dilemma.
    
    Balances securing collective benefit with protection against exploitation.
    - Round 1: Cooperate (goodwill)
    - Rounds 2 to r-1: Adapt based on recent cooperation rate vs dynamic threshold
    - Final round: Defect unless overall cooperation pattern is strong
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_counter = 0
        self.in_punishment = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if state.round_number == 0:
            return Action.C
        if state.round_number == 1:
            cooperators_r0 = int(np.sum(history.opponent_actions[0, :]))
            if cooperators_r0 > 0:
                return Action.C
            else:
                return Action.D
        if self.in_punishment:
            self.punishment_counter -= 1
            if self.punishment_counter <= 0:
                self.in_punishment = False
            else:
                return Action.D
        if state.round_number == r - 1:
            total_cooperations = int(np.sum(history.opponent_actions[:state.round_number, :]))
            total_possible = state.round_number * n
            overall_coop_rate = total_cooperations / total_possible if total_possible > 0 else 0
            threshold_final = m / n + 0.15
            if overall_coop_rate > threshold_final:
                return Action.C
            else:
                return Action.D
        t = state.round_number
        window_size = min(5, t)
        if m >= n / 2 + n / 4:
            window_size = min(7, t)
        start_idx = max(0, t - window_size)
        recent_actions = history.opponent_actions[start_idx:t, :]
        recent_cooperations = int(np.sum(recent_actions))
        recent_possible = (t - start_idx) * n
        recent_coop_rate = recent_cooperations / recent_possible if recent_possible > 0 else 0
        if recent_coop_rate < 0.2 and t > 1:
            if not self.in_punishment:
                self.in_punishment = True
                self.punishment_counter = 2
            return Action.D
        base_threshold = m / n
        adjustment_factor = -0.05 * (t / r)
        dynamic_threshold = base_threshold + adjustment_factor
        if m == n:
            dynamic_threshold = 0.95
        if recent_coop_rate >= dynamic_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_46(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual security with collective benefit by dynamically adjusting
    cooperation based on collective progress toward the threshold, historical reliability,
    and temporal urgency.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_low_coop_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == r - 1:
            return Action.D
        last_round_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        coop_rate = last_round_cooperators / n
        if coop_rate >= m / n:
            if coop_rate >= m * 0.8 / n:
                return Action.C
            elif r - current_round < 2:
                return Action.D
            else:
                return Action.C
        deficit = m - last_round_cooperators
        rounds_remaining = r - current_round
        if deficit <= 2 and rounds_remaining > 1:
            self.consecutive_low_coop_rounds = 0
            return Action.C
        if last_round_cooperators >= m - 1:
            self.consecutive_low_coop_rounds = 0
            return Action.C
        if coop_rate <= m * 0.3 / n:
            self.consecutive_low_coop_rounds += 1
            if self.consecutive_low_coop_rounds >= 2:
                return Action.D
            return Action.D
        expected_value_cooperate = m / n * k
        if coop_rate > 0:
            expected_value_defect = 1.0 + coop_rate / (m / n) * k
        else:
            expected_value_defect = 1.0
        self.consecutive_low_coop_rounds = 0
        if expected_value_cooperate > expected_value_defect:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_47(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Dynamically adapts cooperation based on observed group behavior and remaining rounds.
    Balances individual security with collective benefit by:
    - Starting cooperatively (round 1) to signal willingness
    - Reciprocating threshold success in middle rounds with probabilistic defection near endgame
    - Free-riding in final round if threshold previously failed
    - Attempting recovery when near-collapse but recovery is plausible
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        cooperators_prev = int(sum(history.opponent_actions[round_num - 1, :]))
        if round_num == self.n_rounds - 1:
            if cooperators_prev >= self.m:
                return Action.C
            else:
                return Action.D
        rounds_remaining = self.n_rounds - round_num
        if cooperators_prev >= self.m:
            defection_prob = 0.05 * rounds_remaining
            defection_prob = min(0.95, defection_prob)
            if random.random() < defection_prob:
                return Action.D
            else:
                return Action.C
        elif cooperators_prev == self.m - 1:
            my_prev_action = history.my_actions[round_num - 1]
            if my_prev_action:
                return Action.C
            else:
                return Action.D
        else:
            deficit = self.m - cooperators_prev
            half_m = math.ceil(self.m * 0.5)
            if rounds_remaining > deficit and cooperators_prev >= half_m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_48(BaseStrategy):
    """
    Adaptive Threshold Sentinel: A collective risk dilemma strategy that balances
    cooperation with individual security by adapting to observed cooperation levels
    across three distinct phases (exploration, middle game, endgame).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        c_prev = int(sum(history.opponent_actions[round_num - 1, :]))
        exploration_end = math.ceil(self.n_rounds / 3)
        endgame_start = math.floor(2 * self.n_rounds / 3) + 1
        if round_num <= exploration_end:
            if c_prev >= self.m - 1:
                return Action.C
            else:
                return Action.D
        if round_num >= endgame_start:
            if round_num == self.n_rounds - 1 and c_prev >= self.m:
                return Action.C
            success_count = self._count_successful_rounds(history, round_num)
            success_threshold = self.n_rounds / 2
            if success_count >= success_threshold:
                if c_prev >= self.m - 2:
                    return Action.C
            if success_count < success_threshold and c_prev < self.m:
                return Action.D
        if self.m - 2 <= c_prev < self.m:
            return Action.C
        if c_prev >= self.m:
            return Action.C
        if round_num >= 2:
            c_prev2 = int(sum(history.opponent_actions[round_num - 2, :]))
            if c_prev >= self.m and c_prev2 >= self.m:
                return Action.C
        if round_num >= 2:
            c_prev2 = int(sum(history.opponent_actions[round_num - 2, :]))
            if c_prev < self.m - 2 and c_prev2 < self.m - 2:
                return Action.D
        if c_prev >= self.m - 1:
            return Action.C
        else:
            return Action.D

    def _count_successful_rounds(self, history: PlayerHistory, current_round: int) -> int:
        """
        Count the number of rounds (up to current_round, exclusive) where
        the threshold m was met.
        """
        count = 0
        for round_idx in range(current_round):
            cooperators = int(sum(history.opponent_actions[round_idx, :]))
            if cooperators >= self.m:
                count += 1
        return count

class Strategy_COLLECTIVE_49(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) for Collective Risk Dilemma.
    
    Balances individual security with collective benefit by:
    1. Starting with cooperation to signal good faith
    2. Tracking recent cooperation rates against threshold m/n
    3. Adapting decisions based on whether threshold is likely to be met
    4. Exploiting when threshold is met (except final round attempts)
    5. Gracefully degrading if cooperation collapses
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold_estimate = self.m / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            cooperators_prev = int(sum(history.opponent_actions[current_round - 1, :]))
            if cooperators_prev >= self.m:
                return Action.D
            else:
                return Action.C
        start_idx = max(0, current_round - 3)
        recent_rounds = history.opponent_actions[start_idx:current_round, :]
        if recent_rounds.size == 0:
            return Action.C
        recent_cooperators = np.sum(recent_rounds, axis=1)
        avg_cooperation_rate = float(np.mean(recent_cooperators)) / self.n
        if avg_cooperation_rate >= self.threshold_estimate:
            return Action.C
        if avg_cooperation_rate < self.threshold_estimate / 2:
            return Action.D
        cooperators_last = int(sum(history.opponent_actions[current_round - 1, :]))
        if cooperators_last >= self.m:
            return Action.D
        elif cooperators_last >= self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_50(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances individual rational security with collective welfare through adaptive
    risk assessment. Cooperates conditionally based on whether the cooperation
    threshold (m cooperators) is achievable and has been met in previous rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.critical_threshold = (self.m - 1) / self.n
        self.closing_gap_threshold = math.ceil((self.m - 1) / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        last_round_idx = current_round - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[last_round_idx, :]))
        if history.my_actions[last_round_idx]:
            cooperators_last_round += 1
        cooperation_rate_last_round = cooperators_last_round / self.n
        threshold_rate = self.m / self.n
        if cooperators_last_round == 0:
            if current_round <= self.r / 2:
                return Action.C
            else:
                return Action.D
        if current_round >= 3:
            recent_coop_sum = 0
            recent_rounds_count = min(3, current_round)
            for i in range(current_round - recent_rounds_count, current_round):
                round_coop = int(np.sum(history.opponent_actions[i, :]))
                if history.my_actions[i]:
                    round_coop += 1
                recent_coop_sum += round_coop
            avg_cooperation_rate = recent_coop_sum / (recent_rounds_count * self.n)
            if avg_cooperation_rate < threshold_rate * 0.5:
                return Action.D
        if current_round == self.r - 1:
            if cooperation_rate_last_round >= threshold_rate:
                return Action.C
            elif cooperation_rate_last_round >= self.critical_threshold:
                return Action.C
            else:
                return Action.D
        if cooperation_rate_last_round >= threshold_rate:
            return Action.C
        elif cooperation_rate_last_round >= self.critical_threshold:
            gap = self.m - cooperators_last_round
            if gap <= self.closing_gap_threshold:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_51(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances collective welfare, individual resilience, and adaptive learning by:
    1. Always cooperating in round 1 to signal intent
    2. Conditioning cooperation on observed cooperation rates relative to threshold m/n
    3. Adjusting defection thresholds based on cooperation trends in rounds 2+
    4. Using graceful degradation: only defect when collective success is implausible
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_rate = self.m / self.n_players
        self.defection_threshold_adjustment = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        prev_round_idx = round_number - 1
        prev_opponent_actions = history.opponent_actions[prev_round_idx, :]
        my_prev_action = history.my_actions[prev_round_idx]
        opponent_cooperators = int(np.sum(prev_opponent_actions))
        total_cooperators = opponent_cooperators + int(my_prev_action)
        cooperation_rate = total_cooperators / self.n_players
        if round_number >= 2:
            prev_prev_round_idx = round_number - 2
            prev_prev_opponent_actions = history.opponent_actions[prev_prev_round_idx, :]
            my_prev_prev_action = history.my_actions[prev_prev_round_idx]
            prev_prev_opponent_cooperators = int(np.sum(prev_prev_opponent_actions))
            prev_prev_total_cooperators = prev_prev_opponent_cooperators + int(my_prev_prev_action)
            prev_cooperation_rate = prev_prev_total_cooperators / self.n_players
            cooperation_trend = cooperation_rate - prev_cooperation_rate
            if cooperation_trend < -0.15:
                self.defection_threshold_adjustment += 0.1
            elif cooperation_trend > 0.15:
                self.defection_threshold_adjustment -= 0.05
        adjusted_threshold_rate = self.threshold_rate + self.defection_threshold_adjustment
        if cooperation_rate >= self.threshold_rate:
            return Action.C
        elif cooperation_rate >= self.threshold_rate * 0.75:
            return Action.C
        elif cooperation_rate >= self.threshold_rate * 0.5:
            return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_52(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual security with collective welfare by dynamically adjusting
    cooperation based on observed group behavior and remaining rounds. Cooperates
    in round 1, adapts based on cooperation rate in middle rounds, and defects
    in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if self.n_players < self.m:
            return Action.D
        if round_number == 0:
            return Action.C
        if round_number == self.n_rounds - 1:
            return Action.D
        prev_round_idx = round_number - 1
        opponent_cooperators = np.sum(history.opponent_actions[prev_round_idx, :])
        my_cooperation = 1 if history.my_actions[prev_round_idx] else 0
        total_cooperators = opponent_cooperators + my_cooperation
        cooperation_rate = total_cooperators / self.n_players
        threshold_rate = self.m / self.n_players
        if cooperation_rate >= threshold_rate:
            return Action.C
        if cooperation_rate > 0:
            defection_threshold = 0.5
            if threshold_rate > 0.8:
                defection_threshold = 0.4
            if cooperation_rate >= defection_threshold:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_53(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances collective success, rational self-interest, and robustness by using
    probabilistic cooperation that adapts across three game phases:
    - Early: Signal cooperation at (m+1)/n probability
    - Mid: Calibrate based on observed cooperation rates
    - End: Optimize based on threshold achievement frequency
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.early_phase_end = math.ceil(self.r / 3)
        self.mid_phase_end = math.ceil(2 * self.r / 3)
        self.p0 = (self.m + 1) / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        round_num = state.round_number
        if round_num <= self.early_phase_end:
            phase = 'early'
        elif round_num <= self.mid_phase_end:
            phase = 'mid'
        else:
            phase = 'end'
        past_cooperators = np.sum(history.opponent_actions, axis=1)
        observed_coop_count = np.sum(past_cooperators)
        observed_coop_rate = observed_coop_count / (round_num * self.n) if round_num > 0 else 0
        threshold_achieved = np.sum(past_cooperators >= self.m)
        threshold_achievement_rate = threshold_achieved / round_num if round_num > 0 else 0
        if phase == 'early':
            p_coop = self.p0
        elif phase == 'mid':
            if observed_coop_rate >= self.m / self.n:
                p_coop = 0.9
            elif observed_coop_rate >= (self.m - 1) / self.n:
                p_coop = (self.m + 2) / self.n
            else:
                p_coop = max(0.1, (self.m - 1) / self.n)
        elif round_num == self.r - 1:
            if round_num > 0 and past_cooperators[-1] >= self.m:
                p_coop = 0.9
            else:
                p_coop = 0.0
        elif threshold_achievement_rate >= 0.5:
            p_coop = 0.85
        elif threshold_achieved == 0:
            p_coop = 0.15
        else:
            p_coop = self.p0
        p_coop = max(0.05, min(0.95, p_coop))
        if random.random() < p_coop:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_54(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances collective welfare, individual rationality, and robustness by:
    1. Cooperating in round 1 to test feasibility
    2. Adapting cooperation based on observed cooperation rates vs. adaptive threshold
    3. Using stricter decision rule in final round
    4. Permanently defecting if threshold never reached early
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.permanently_defect = False
        self.has_checked_permanent_defect = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        if not self.has_checked_permanent_defect:
            trigger_round = min(3, max(1, r // 2))
            if current_round > trigger_round:
                self.has_checked_permanent_defect = True
                max_coop_rate = self._get_max_cooperation_rate(history)
                epsilon = self._calculate_epsilon(m, n)
                threshold = m / n + epsilon
                if max_coop_rate < threshold:
                    self.permanently_defect = True
        if self.permanently_defect:
            return Action.D
        if current_round == r - 1:
            prev_cooperators = self._count_cooperators_in_round(history, current_round - 1)
            if prev_cooperators >= m:
                return Action.C
            else:
                return Action.D
        epsilon = self._calculate_epsilon(m, n)
        threshold = m / n + epsilon
        if current_round >= 2:
            if current_round >= 3:
                coop_rate_prev2 = self._get_cooperation_rate(history, current_round - 2)
                coop_rate_prev1 = self._get_cooperation_rate(history, current_round - 1)
                coop_rate = (coop_rate_prev2 + coop_rate_prev1) / 2.0
            else:
                coop_rate = self._get_cooperation_rate(history, current_round - 1)
            if coop_rate >= threshold:
                return Action.C
            else:
                return Action.D
        return Action.D

    def _calculate_epsilon(self, m: int, n: int) -> float:
        """Calculate tolerance buffer for threshold."""
        if m == n:
            epsilon = (n - 1) / n + min(0.15, (m - 1) / (2 * n))
            return epsilon - (n - 1) / n
        else:
            return min(0.15, (m - 1) / (2 * n))

    def _count_cooperators_in_round(self, history: PlayerHistory, round_idx: int) -> int:
        """Count total cooperators (including self) in a given round."""
        my_action = history.my_actions[round_idx]
        opponent_cooperators = np.sum(history.opponent_actions[round_idx, :])
        return int(my_action) + int(opponent_cooperators)

    def _get_cooperation_rate(self, history: PlayerHistory, round_idx: int) -> float:
        """Get cooperation rate in a given round (includes self)."""
        n = self.game_description.n_players
        cooperators = self._count_cooperators_in_round(history, round_idx)
        return cooperators / n

    def _get_max_cooperation_rate(self, history: PlayerHistory) -> float:
        """Get maximum cooperation rate across all previous rounds."""
        if history is None or len(history.my_actions) == 0:
            return 0.0
        max_rate = 0.0
        for round_idx in range(len(history.my_actions)):
            rate = self._get_cooperation_rate(history, round_idx)
            max_rate = max(max_rate, rate)
        return max_rate

class Strategy_COLLECTIVE_55(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual security with collective welfare by:
    1. Cooperating when observed cooperation suggests threshold achievement is likely
    2. Defecting when cooperation seems futile
    3. Using adaptive thresholds based on game parameters
    4. Maintaining incentive compatibility (never worse than universal defection)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold_rate = self.m / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            if self.m <= self.n / 2:
                return Action.C
            else:
                return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[-1, :]))
        cooperation_rate = cooperators_last_round / self.n
        recent_rounds = min(3, state.round_number)
        recent_cooperators = np.sum(history.opponent_actions[-recent_rounds:, :])
        recent_cooperation_rate = recent_cooperators / (recent_rounds * self.n)
        threshold_confidence = recent_cooperation_rate / self.threshold_rate if self.threshold_rate > 0 else 0
        if threshold_confidence >= 0.9:
            return Action.C
        elif threshold_confidence >= 0.7:
            if random.random() < 0.7:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_56(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances collective welfare maximization with robust defection against free-riders.
    Uses adaptive rules based on recent cooperation rates, threshold-maker pivoting,
    and end-game cooperation evaluation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.p_rejoin = 0.75
        self.defect_dominant_mode = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            return self._decide_last_round(history)
        return self._decide_middle_rounds(history, round_num)

    def _decide_last_round(self, history: PlayerHistory) -> Action:
        """
        Final round: Cooperate if recent cooperation â‰¥ threshold, else defect.
        """
        evaluation_depth = min(3, len(history.my_actions))
        if evaluation_depth == 0:
            return Action.C
        recent_coop_counts = 0
        for i in range(evaluation_depth):
            round_idx = len(history.my_actions) - evaluation_depth + i
            round_cooperators = sum(history.opponent_actions[round_idx, :])
            recent_coop_counts += round_cooperators
        avg_recent_coop = recent_coop_counts / (evaluation_depth * self.n)
        threshold_ratio = self.m / self.n
        if avg_recent_coop >= threshold_ratio:
            return Action.C
        else:
            return Action.D

    def _decide_middle_rounds(self, history: PlayerHistory, round_num: int) -> Action:
        """
        Middle rounds: Apply adaptive threshold rule with edge case handling.
        """
        if round_num >= 4:
            moving_avg = self._get_moving_average_cooperation(history, 4)
            threshold_ratio = self.m / self.n
            if moving_avg >= threshold_ratio:
                return Action.C
            else:
                return Action.D
        if round_num >= 3:
            early_coop_rates = []
            for i in range(1, min(3, round_num)):
                coop_count = sum(history.opponent_actions[i, :])
                early_coop_rates.append(coop_count / self.n)
            if early_coop_rates and all((rate < self.m / self.n for rate in early_coop_rates)):
                self.defect_dominant_mode = True
            if self.defect_dominant_mode:
                recent_coop = sum(history.opponent_actions[round_num - 1, :]) / self.n
                if round_num >= 2:
                    prev_coop = sum(history.opponent_actions[round_num - 2, :]) / self.n
                    if recent_coop >= self.m / self.n and prev_coop >= self.m / self.n:
                        self.defect_dominant_mode = False
                if self.defect_dominant_mode:
                    return Action.D
        recent_coop_count = int(sum(history.opponent_actions[round_num - 1, :]))
        coop_rate = recent_coop_count / self.n
        my_last_action = history.my_actions[round_num - 1]
        threshold_ratio = self.m / self.n
        if recent_coop_count == 0:
            rounds_remaining = self.r - round_num
            if rounds_remaining <= 2:
                if recent_coop_count + 1 >= self.m:
                    return Action.C
            return Action.D
        if self.n == self.m:
            if my_last_action:
                return Action.C
            else:
                return Action.D
        if self.n == self.m + 1:
            if recent_coop_count == 0:
                return Action.D
            if coop_rate >= threshold_ratio:
                return Action.C
        if coop_rate >= threshold_ratio:
            if my_last_action:
                return Action.C
            elif random.random() < self.p_rejoin:
                return Action.C
            else:
                return Action.D
        elif recent_coop_count + 1 >= self.m:
            return Action.C
        else:
            return Action.D

    def _get_moving_average_cooperation(self, history: PlayerHistory, window: int) -> float:
        """
        Calculate moving average cooperation rate over last `window` rounds.
        """
        history_len = len(history.my_actions)
        if history_len == 0:
            return 0.0
        start_idx = max(0, history_len - window)
        total_cooperators = 0
        rounds_counted = 0
        for i in range(start_idx, history_len):
            round_cooperators = sum(history.opponent_actions[i, :])
            total_cooperators += round_cooperators
            rounds_counted += 1
        if rounds_counted == 0:
            return 0.0
        return total_cooperators / (rounds_counted * self.n)

class Strategy_COLLECTIVE_57(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by cooperating when
    evidence suggests the threshold will be met, with graduated recovery mechanisms
    and endgame rationality adjustments.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.epsilon = 0.15
        self.restart_probability = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            if self.m / self.n <= 0.5:
                return Action.C
            else:
                return Action.D
        prev_round_opponent_actions = history.opponent_actions[round_number - 1, :]
        prev_round_my_action = history.my_actions[round_number - 1]
        opponent_coop_count = int(np.sum(prev_round_opponent_actions))
        total_coop_count = opponent_coop_count + (1 if prev_round_my_action else 0)
        coop_rate = total_coop_count / self.n
        threshold_rate = self.m / self.n
        rounds_remaining = self.r - round_number
        if rounds_remaining <= 1:
            if coop_rate >= 0.8 * threshold_rate:
                return Action.C
            else:
                return Action.D
        if total_coop_count == self.n:
            return Action.C
        if total_coop_count == 0:
            if round_number < self.r / 2 and self.r > 3:
                if random.random() < self.restart_probability:
                    return Action.C
            return Action.D
        if coop_rate >= threshold_rate * (1 - self.epsilon):
            return Action.C
        elif coop_rate >= threshold_rate * (1 - 2 * self.epsilon):
            p_recovery = 0.5 + 0.5 * (coop_rate / threshold_rate) if threshold_rate > 0 else 0.5
            if random.random() < p_recovery:
                return Action.C
            else:
                return Action.D
        else:
            if round_number < self.r / 2 and self.r > 3 and (coop_rate > 0):
                if random.random() < self.restart_probability:
                    return Action.C
            return Action.D

class Strategy_COLLECTIVE_58(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances cooperation for collective value with rational defection to avoid exploitation.
    Uses adaptive threshold adjustment based on empirical cooperation rates to maximize
    long-term payoff while remaining responsive to opponent behavior.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            prev_round_idx = current_round - 1
            cooperators_prev = int(sum(history.opponent_actions[prev_round_idx, :]))
            my_action_prev = history.my_actions[prev_round_idx]
            total_cooperators_prev = cooperators_prev + (1 if my_action_prev else 0)
            if total_cooperators_prev >= self.m:
                return Action.C
            else:
                return Action.D
        prev_round_idx = current_round - 1
        cooperators_prev = int(sum(history.opponent_actions[prev_round_idx, :]))
        my_action_prev = history.my_actions[prev_round_idx]
        total_cooperators_prev = cooperators_prev + (1 if my_action_prev else 0)
        rho = total_cooperators_prev / self.n_players
        threshold_ratio = self.m / self.n_players
        if rho >= threshold_ratio:
            coop_prob = min(1.0, 0.5 + rho)
        elif abs(rho - threshold_ratio) <= 1.0 / self.n_players:
            coop_prob = 0.9
        else:
            coop_prob = max(0.2, 2.0 * rho)
        if current_round == 1:
            if rho < 0.1:
                coop_prob = 0.3
            else:
                coop_prob = 0.8
        if current_round >= self.n_rounds - 2:
            if total_cooperators_prev < self.m:
                coop_prob *= 0.7
        if self.m >= self.n_players:
            return Action.D
        if self.k > 5.0:
            coop_prob = min(1.0, coop_prob + 0.2)
        if self.k <= 1.2:
            coop_prob = max(0.0, coop_prob - 0.2)
        if random.random() < coop_prob:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_59(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATC) for Collective Risk Dilemma.
    
    Dynamically adjusts cooperation based on observed cooperation rates and round position.
    - Round 1: Always cooperate to establish cooperative signal
    - Last round: Always defect to maximize individual payoff
    - Middle rounds: Cooperate if observed cooperation rate meets declining threshold
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if history.my_actions[current_round - 1]:
            cooperators_last_round += 1
        observed_coop_rate = cooperators_last_round / self.n_players
        flexibility_factor = 0.9 - current_round / (2 * self.n_rounds)
        flexibility_factor = max(0.1, min(0.9, flexibility_factor))
        coop_threshold = math.ceil(self.m * flexibility_factor)
        required_rate = coop_threshold / self.n_players
        if observed_coop_rate >= required_rate:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_60(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual security with collective benefit by maintaining a cooperation
    baseline proportional to the threshold requirement and adapting dynamically based
    on observed cooperation rates. Exploits predictable defectors while rewarding
    reliable cooperators, protecting against free-riding without cascade defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.r - 1:
            return Action.D
        if round_number == self.r - 2:
            cooperation_rate = self._get_cooperation_rate(history, round_number - 1)
            cooperation_threshold = self.m / self.n
            if cooperation_rate >= cooperation_threshold * 0.9:
                return Action.C
            else:
                return Action.D
        cooperation_rate = self._get_cooperation_rate(history, round_number - 1)
        cooperation_threshold = self.m / self.n
        rounds_remaining = self.r - round_number - 1
        if cooperation_rate >= cooperation_threshold:
            return Action.C
        expected_cooperators = cooperation_rate * (self.n - 1)
        cooperators_needed = self.m - expected_cooperators
        if cooperators_needed <= 0:
            return Action.C
        if cooperators_needed >= self.n * 0.4:
            return Action.D
        if rounds_remaining >= 4:
            return Action.C
        deficit_ratio = cooperators_needed / self.m if self.m > 0 else 0
        if deficit_ratio <= 0.5:
            return Action.C
        else:
            return Action.D

    def _get_cooperation_rate(self, history: PlayerHistory, round_idx: int) -> float:
        """
        Calculate the cooperation rate in a given round.
        
        Args:
            history: PlayerHistory object containing opponent actions
            round_idx: Index of the round to analyze (0-indexed)
        
        Returns:
            Proportion of players (including self) that cooperated in that round
        """
        if round_idx < 0 or round_idx >= len(history.opponent_actions):
            return 0.0
        opponent_cooperators = np.sum(history.opponent_actions[round_idx, :])
        self_cooperator = 1 if history.my_actions[round_idx] else 0
        total_cooperators = opponent_cooperators + self_cooperator
        cooperation_rate = total_cooperators / self.n
        return cooperation_rate

class Strategy_COLLECTIVE_61(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) for Collective Risk Dilemma.
    
    Balances individual security with collective benefit by dynamically adjusting
    cooperation based on observed group behavior. Cooperates in round 1 to initiate
    reciprocity, monitors cooperation rate via thresholds, and adapts decisions
    across middle and final rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.last_coop_rate = None
        self.consecutive_stable_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round_idx = state.round_number - 1
        self_cooperated = history.my_actions[prev_round_idx]
        opponent_cooperators = np.sum(history.opponent_actions[prev_round_idx, :])
        total_cooperators = (1 if self_cooperated else 0) + opponent_cooperators
        coop_rate = total_cooperators / self.n_players
        if self.last_coop_rate is not None and abs(coop_rate - self.last_coop_rate) < 1e-09:
            self.consecutive_stable_rounds += 1
        else:
            self.consecutive_stable_rounds = 0
        self.last_coop_rate = coop_rate
        theta = self.m / self.n_players
        epsilon = max(0.3, (self.m - 1) / self.n_players)
        if state.round_number == self.n_rounds - 1:
            if coop_rate >= theta:
                return Action.C
            else:
                return Action.D
        if coop_rate >= theta:
            return Action.C
        elif coop_rate >= epsilon:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_62(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances aggressive early cooperation to establish thresholds, adaptive
    adjustment based on population trends, and endgame exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.phase_1_end = self.r // 3
        self.phase_2_end = 2 * self.r // 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round <= self.phase_1_end:
            return Action.C
        if current_round == self.r - 1:
            if self.m == self.n:
                return Action.C
            return Action.D
        if current_round <= self.phase_2_end:
            return self._adaptive_adjustment(current_round, history)
        return self._endgame_decision(current_round, history)

    def _adaptive_adjustment(self, current_round: int, history: PlayerHistory) -> Action:
        """
        Phase 2 decision: observe recent cooperation trend and adapt.
        Uses rolling 3-round window to assess cooperation rate.
        """
        lookback_rounds = min(3, current_round)
        recent_cooperators = 0
        for i in range(current_round - lookback_rounds, current_round):
            if i >= 0:
                recent_cooperators += sum(history.opponent_actions[i, :])
        total_possible = lookback_rounds * self.n
        if total_possible == 0:
            return Action.C
        cooperation_rate = recent_cooperators / total_possible
        threshold_rate = self.m / self.n
        high_threshold = threshold_rate * 0.9
        mid_threshold = threshold_rate * 0.5
        if cooperation_rate >= high_threshold:
            return Action.C
        elif cooperation_rate >= mid_threshold:
            prob_cooperate = cooperation_rate / threshold_rate if threshold_rate > 0 else 0
            prob_cooperate = min(1.0, max(0.0, prob_cooperate))
            return Action.C if random.random() < prob_cooperate else Action.D
        else:
            return Action.D

    def _endgame_decision(self, current_round: int, history: PlayerHistory) -> Action:
        """
        Phase 3 decision: extract maximum payoff.
        Defect unless universal cooperation is required.
        """
        if self.m == self.n:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_63(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) for Collective Risk Dilemma.
    
    Cooperates when collective viability is demonstrated by prior round cooperation rates.
    Uses probabilistic commitment in uncertain zones to create a ratchet effect toward
    cooperation when the collective is approaching the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round_idx = state.round_number - 1
        self_cooperated_prev = history.my_actions[prev_round_idx]
        opponent_cooperators_prev = np.sum(history.opponent_actions[prev_round_idx, :])
        cooperators_prev = int(self_cooperated_prev) + int(opponent_cooperators_prev)
        cooperation_rate = cooperators_prev / self.n
        threshold_rate = self.m / self.n
        upper_threshold = 0.8 * threshold_rate
        lower_threshold = 0.5 * threshold_rate
        if cooperation_rate >= upper_threshold:
            return Action.C
        elif cooperation_rate < lower_threshold:
            return Action.D
        else:
            gray_zone_width = 0.3 * threshold_rate
            if gray_zone_width == 0:
                return Action.C
            probability = (cooperation_rate - lower_threshold) / gray_zone_width
            probability = max(0.0, min(1.0, probability))
            if random.random() < probability:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_64(BaseStrategy):
    """
    Adaptive Threshold Response (ATR) strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare through:
    1. Reciprocal cooperation - matching collective behavior
    2. Adaptive threshold tracking - learning sustainable cooperation levels
    3. Graceful degradation - shifting to defection only when collective success is unlikely
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.hysteresis_threshold = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return self._adaptive_decision(state, history)

    def _adaptive_decision(self, state: GameState, history: PlayerHistory) -> Action:
        """
        Calculate cooperation metrics and make adaptive decision.
        """
        m = self.game_description.m
        n = self.game_description.n_players
        window_size = min(3, state.round_number)
        start_idx = max(0, state.round_number - window_size)
        recent_opponent_actions = history.opponent_actions[start_idx:state.round_number, :]
        recent_coop_count = np.sum(recent_opponent_actions, axis=1)
        my_recent_actions = history.my_actions[start_idx:state.round_number]
        total_coop_per_round = recent_coop_count + my_recent_actions.astype(int)
        if len(total_coop_per_round) > 0:
            avg_coop_rate = np.mean(total_coop_per_round) / n
        else:
            avg_coop_rate = 0.0
        last_round_total_coops = total_coop_per_round[-1] if len(total_coop_per_round) > 0 else 0
        recent_threshold_met = last_round_total_coops >= m
        if self.hysteresis_threshold is None:
            self.hysteresis_threshold = m / n * 0.9
        if recent_threshold_met:
            self.hysteresis_threshold = m / n * 0.9
            return Action.C
        if avg_coop_rate >= m / n:
            self.hysteresis_threshold = m / n * 0.9
            return Action.C
        if avg_coop_rate >= m / n * 0.75:
            self.hysteresis_threshold = m / n * 0.9
            return Action.C
        if avg_coop_rate < self.hysteresis_threshold:
            self.hysteresis_threshold = m / n * 0.75
            return Action.D
        return Action.C

class Strategy_COLLECTIVE_65(BaseStrategy):
    """
    Adaptive Threshold Coalescence strategy for Collective Risk Dilemma.
    
    Prioritizes collective welfare by cooperating when it meaningfully advances
    the probability of meeting the threshold m, and defecting only when cooperation
    becomes individually dominated (threshold already guaranteed or unreachable).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number + 1
        if round_t == 1:
            return Action.C
        cooperators_prev = int(np.sum(history.opponent_actions[-1, :]))
        deficit = self.m - cooperators_prev
        rounds_remaining = self.r - round_t
        if deficit <= 0:
            return Action.D
        if deficit > rounds_remaining:
            return Action.D
        early_game_threshold = math.ceil(self.n / self.m)
        if round_t <= early_game_threshold and deficit > 0 and (deficit <= rounds_remaining):
            return Action.C
        if round_t >= self.r - 1:
            if cooperators_prev >= self.m:
                return Action.D
            elif cooperators_prev >= self.m - 1:
                return Action.C
            else:
                return Action.D
        return Action.C

class Strategy_COLLECTIVE_66(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances collective welfare with individual resilience by:
    1. Cooperating unconditionally in round 1 to signal willingness
    2. Tracking cooperation deficit relative to threshold m
    3. Defecting when threshold is met or impossible to reach
    4. Using probabilistic cooperation scaled by urgency when deficit is recoverable
    5. Always defecting in the final round (no future consequences)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.n_rounds - 1:
            return Action.D
        prev_round_opponent_actions = history.opponent_actions[round_number - 1, :]
        prev_round_cooperators = int(np.sum(prev_round_opponent_actions))
        if history.my_actions[round_number - 1]:
            prev_round_cooperators += 1
        deficit = max(0, self.m - prev_round_cooperators)
        remaining_rounds = self.n_rounds - round_number
        if deficit == 0:
            return Action.D
        if deficit > remaining_rounds:
            return Action.D
        if prev_round_cooperators >= self.m - 1:
            return Action.C
        cooperation_probability = deficit / (remaining_rounds + 1)
        if random.random() < cooperation_probability:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_67(BaseStrategy):
    """
    Reciprocal Threshold Adjustment (RTA) Strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare through:
    1. Initial cooperation to signal reliability
    2. Adaptive middle-game response based on observed cooperation rates
    3. Strategic endgame behavior accounting for remaining rounds
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.phase1_end = max(3, math.ceil(self.n_rounds / 3))
        self.phase2_end = math.floor(2 * self.n_rounds / 3)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num < self.phase1_end:
            return self._phase1_decision(history, round_num)
        if round_num >= self.n_rounds - 2:
            return self._phase3_decision(history, round_num)
        return self._phase2_decision(history, round_num)

    def _phase1_decision(self, history: PlayerHistory, round_num: int) -> Action:
        """Phase 1: Rounds 1 to phase1_end. Establish baseline cooperation."""
        if round_num == 1:
            round_0_cooperators = sum(history.opponent_actions[0, :])
            cooperation_rate = (round_0_cooperators + 1) / self.n_players
            target_rate = (self.m - 1) / (self.n_players - 1)
            if cooperation_rate >= target_rate:
                return Action.C
            else:
                return Action.D
        cooperation_count = np.sum(history.opponent_actions[:round_num, :])
        my_cooperations = np.sum(history.my_actions[:round_num])
        total_cooperations = cooperation_count + my_cooperations
        total_actions = round_num * self.n_players
        cooperation_rate = total_cooperations / total_actions if total_actions > 0 else 0
        target_rate = (self.m - 1) / (self.n_players - 1)
        if cooperation_rate >= target_rate:
            return Action.C
        else:
            return Action.D

    def _phase2_decision(self, history: PlayerHistory, round_num: int) -> Action:
        """Phase 2: Middle rounds. Adaptive response with probabilistic defection."""
        start_idx = max(0, round_num - 3)
        recent_rounds = history.opponent_actions[start_idx:round_num, :]
        recent_my_actions = history.my_actions[start_idx:round_num]
        opponent_cooperators = np.sum(recent_rounds)
        my_recent_cooperations = np.sum(recent_my_actions)
        total_recent = opponent_cooperators + my_recent_cooperations
        window_size = (round_num - start_idx) * self.n_players
        cooperation_rate = total_recent / window_size if window_size > 0 else 0
        target_rate = (self.m - 1) / (self.n_players - 1)
        if cooperation_rate >= target_rate * 0.85:
            return Action.C
        elif cooperation_rate >= target_rate * 0.5:
            probability = cooperation_rate / target_rate if target_rate > 0 else 0
            probability = min(probability, 1.0)
            if random.random() < probability:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _phase3_decision(self, history: PlayerHistory, round_num: int) -> Action:
        """Phase 3: Last 2 rounds. Strategic endgame behavior."""
        last_round = self.n_rounds - 1
        if round_num == last_round:
            start_idx = max(0, round_num - 5)
            recent_rounds = history.opponent_actions[start_idx:round_num, :]
            recent_my_actions = history.my_actions[start_idx:round_num]
            opponent_cooperators = np.sum(recent_rounds)
            my_recent_cooperations = np.sum(recent_my_actions)
            total_recent = opponent_cooperators + my_recent_cooperations
            window_size = (round_num - start_idx) * self.n_players
            cooperation_rate = total_recent / window_size if window_size > 0 else 0
            target_rate = (self.m - 1) / (self.n_players - 1)
            if cooperation_rate >= target_rate:
                return Action.C
            else:
                return Action.D
        else:
            start_idx = max(0, round_num - 4)
            recent_rounds = history.opponent_actions[start_idx:round_num, :]
            recent_my_actions = history.my_actions[start_idx:round_num]
            opponent_cooperators = np.sum(recent_rounds)
            my_recent_cooperations = np.sum(recent_my_actions)
            total_recent = opponent_cooperators + my_recent_cooperations
            window_size = (round_num - start_idx) * self.n_players
            cooperation_rate = total_recent / window_size if window_size > 0 else 0
            target_rate = (self.m - 1) / (self.n_players - 1)
            all_rounds = history.opponent_actions[:round_num, :]
            all_my_actions = history.my_actions[:round_num]
            all_opponent_cooperators = np.sum(all_rounds)
            all_my_cooperations = np.sum(all_my_actions)
            all_total = all_opponent_cooperators + all_my_cooperations
            all_window_size = round_num * self.n_players
            all_cooperation_rate = all_total / all_window_size if all_window_size > 0 else 0
            cooperative_round_count = 0
            for r in range(round_num):
                round_cooperators = np.sum(history.opponent_actions[r, :]) + (1 if history.my_actions[r] else 0)
                if round_cooperators >= self.m:
                    cooperative_round_count += 1
            if cooperation_rate >= target_rate * 0.9 and cooperative_round_count >= 2:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_68(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) for Collective Risk Dilemma.
    
    Balances collective success, individual rationality, and robustness by:
    1. Starting with cooperation to signal good faith (Round 1)
    2. Assessing threshold achievability based on observed cooperation rates
    3. Adapting play based on population behavior
    4. Defecting only when threshold is mathematically unattainable or exploitation is evident
    5. Optimizing final round based on previous cooperation rates
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == 1:
            self_coop_r0 = 1 if history.my_actions[0] else 0
            opponent_coop_r0 = np.sum(history.opponent_actions[0, :])
            total_coop_r0 = self_coop_r0 + opponent_coop_r0
            if total_coop_r0 >= self.m:
                return Action.C
            else:
                return Action.D
        if round_num == self.n_rounds - 1:
            total_cooperations = np.sum(history.my_actions[:-1]) + np.sum(history.opponent_actions[:-1, :])
            total_slots = round_num * self.n_players
            if total_slots > 0:
                prev_coop_rate = total_cooperations / total_slots
            else:
                prev_coop_rate = 0.0
            if prev_coop_rate >= self.m / self.n_players:
                return Action.C
            else:
                return Action.D
        total_cooperations = np.sum(history.my_actions[:round_num]) + np.sum(history.opponent_actions[:round_num, :])
        total_slots = round_num * self.n_players
        if total_slots > 0:
            coop_rate = total_cooperations / total_slots
        else:
            coop_rate = 0.0
        expected_cooperators = coop_rate * self.n_players
        threshold_achievable = expected_cooperators >= self.m - 1
        exploitation_threshold = self.m / (self.n_players + 1)
        if coop_rate < exploitation_threshold:
            return Action.D
        if threshold_achievable:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_69(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual security with collective welfare by monitoring group cooperation
    trends and adapting participation based on historical success rates and current
    cooperation levels relative to the threshold m.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        cooperators_prev_round = int(sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            cooperators_prev_round += 1
        cooperation_rate = cooperators_prev_round / self.n
        rounds_where_threshold_met = 0
        for round_idx in range(current_round):
            round_cooperators = int(sum(history.opponent_actions[round_idx, :]))
            if history.my_actions[round_idx]:
                round_cooperators += 1
            if round_cooperators >= self.m:
                rounds_where_threshold_met += 1
        success_rate = rounds_where_threshold_met / current_round if current_round > 0 else 0.0
        if current_round == self.r - 1:
            if success_rate > 0.6 and cooperators_prev_round >= self.m:
                return Action.C
            elif cooperators_prev_round >= self.m:
                return Action.C
            else:
                return Action.D
        else:
            m_ratio = self.m / self.n
            m_minus_1_ratio = (self.m - 1) / self.n
            if cooperation_rate >= m_ratio:
                if success_rate > 0.5:
                    return Action.C
                else:
                    return Action.C
            elif cooperation_rate < m_minus_1_ratio:
                return Action.D
            elif cooperation_rate >= 0.5 * m_ratio:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_70(BaseStrategy):
    """
    Adaptive Collective Threshold Strategy (ACTS)
    
    Balances individual risk minimization with collective welfare by dynamically
    adjusting cooperation based on observed cooperation rates and remaining rounds.
    Cooperates when threshold probability is high; defects strategically when low,
    but maintains minimum cooperation commitment to preserve collective viability.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        previous_round_idx = round_num - 1
        previous_opponent_actions = history.opponent_actions[previous_round_idx, :]
        previous_cooperators = int(sum(previous_opponent_actions))
        if history.my_actions[previous_round_idx]:
            previous_cooperators += 1
        coop_rate = previous_cooperators / self.n
        threshold_rate = self.m / self.n
        if round_num == self.r - 1:
            if previous_cooperators >= self.m:
                return Action.C
            deficit = self.m - previous_cooperators
            if deficit <= 1:
                return Action.C
            else:
                return Action.D
        if coop_rate >= threshold_rate:
            return Action.C
        expected_other_cooperators = coop_rate * (self.n - 1)
        if expected_other_cooperators + 1 >= self.m:
            return Action.C
        my_coop_count = int(sum(history.my_actions[:round_num]))
        my_coop_rate = my_coop_count / round_num
        quota = self.m / self.n
        if my_coop_rate < quota:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_71(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances collective welfare with individual rationality by maintaining a running
    estimate of group cooperation rate and adjusting behavior based on the likelihood
    of reaching the threshold m and securing reward k.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        coop_rate = self._calculate_cooperation_rate(history, current_round)
        epsilon = 0.1 if self.n <= 3 else 0.05
        threshold_ratio = self.m / self.n
        if coop_rate >= threshold_ratio - epsilon:
            return Action.C
        rounds_remaining = self.r - current_round
        if rounds_remaining <= 2:
            return Action.D
        p_cooperate = self._calculate_adaptive_probability(coop_rate, threshold_ratio)
        if random.random() < p_cooperate:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the proportion of cooperations observed across all players
        in all previous rounds.
        """
        if current_round == 0:
            return 0.0
        total_coop_count = 0
        total_coop_count += np.sum(history.my_actions[:current_round])
        total_coop_count += np.sum(history.opponent_actions[:current_round, :])
        total_possible = current_round * self.n
        if total_possible == 0:
            return 0.0
        return float(total_coop_count) / float(total_possible)

    def _calculate_adaptive_probability(self, coop_rate: float, threshold_ratio: float) -> float:
        """
        Calculate the probability of cooperation when group is below threshold.
        Scales with observed cooperation rate but has a minimum floor.
        """
        if threshold_ratio > 0:
            base_prob = coop_rate / threshold_ratio
        else:
            base_prob = 0.0
        floor_prob = 0.4 if self.k > 2.0 else 0.3
        return max(base_prob, floor_prob)

class Strategy_COLLECTIVE_72(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    This strategy coordinates on reaching the cooperation threshold m by:
    1. Cooperating unconditionally in round 1 to signal trustworthiness
    2. Observing cooperation rates and adapting based on proximity to threshold
    3. Withdrawing cooperation only when the population drops below critical mass
    4. Using probabilistic cooperation in the intermediate zone to support momentum
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round_index = state.round_number - 1
        opponent_cooperators_prev = np.sum(history.opponent_actions[previous_round_index, :])
        self_cooperated_prev = history.my_actions[previous_round_index]
        total_cooperators_prev = opponent_cooperators_prev + (1 if self_cooperated_prev else 0)
        coop_rate = total_cooperators_prev / self.n
        threshold_ratio = self.m / self.n
        if coop_rate >= threshold_ratio:
            return Action.C
        if coop_rate >= threshold_ratio - 0.2:
            return Action.C
        if coop_rate < threshold_ratio * 0.5:
            return Action.D
        lower_bound = threshold_ratio * 0.5
        upper_bound = threshold_ratio
        denominator = upper_bound - lower_bound
        if denominator <= 0:
            return Action.D
        prob_cooperate = (coop_rate - lower_bound) / denominator
        prob_cooperate = max(0.0, min(1.0, prob_cooperate))
        if random.random() < prob_cooperate:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_73(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Maximizes collective welfare by cooperating when the threshold m appears achievable,
    while protecting against exploitation through graduated defection when cooperation
    seems insufficient. Uses previous round cooperation counts as signals of collective capacity.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        c_prev = int(sum(history.opponent_actions[current_round - 1, :]))
        if history.my_actions[current_round - 1]:
            c_prev += 1
        if c_prev >= self.m:
            return Action.C
        elif c_prev >= self.m - 1:
            return Action.C
        elif c_prev >= math.ceil(self.m / 2):
            return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_74(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances collective welfare (reaching cooperation threshold) with individual security
    (avoiding exploitation). Uses adaptive probabilistic cooperation based on historical
    success rates and current cooperation signals.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_idx = round_num - 1
        prev_cooperators = int(sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            prev_cooperators += 1
        cooperation_rate = prev_cooperators / self.n_players
        threshold_ratio = self.m / self.n_players
        if round_num == self.n_rounds - 1:
            if cooperation_rate >= threshold_ratio:
                return Action.C
            else:
                return Action.D
        threshold_achievement_rate = self._calculate_threshold_achievement_rate(history, round_num)
        if cooperation_rate >= threshold_ratio * 0.9:
            return Action.C
        elif cooperation_rate >= threshold_ratio * 0.5:
            if random.random() < threshold_achievement_rate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _calculate_threshold_achievement_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the fraction of past rounds where m or more players cooperated.
        
        Args:
            history: Player history up to current round
            current_round: Current round number (0-indexed)
        
        Returns:
            Fraction of successful rounds (0.0 to 1.0)
        """
        if current_round <= 1:
            return 0.5
        successful_rounds = 0
        for past_round_idx in range(current_round):
            round_cooperators = int(sum(history.opponent_actions[past_round_idx, :]))
            if history.my_actions[past_round_idx]:
                round_cooperators += 1
            if round_cooperators >= self.m:
                successful_rounds += 1
        total_past_rounds = current_round
        if total_past_rounds == 0:
            return 0.5
        return successful_rounds / total_past_rounds

class Strategy_COLLECTIVE_75(BaseStrategy):
    """
    Conditional Threshold Assurance strategy for Collective Risk Dilemma.
    
    Prioritizes collective welfare through conditional commitment by:
    1. Cooperating in round 1 to signal willingness
    2. Tracking empirical cooperation rates in intermediate rounds
    3. Making probabilistic decisions based on threshold likelihood
    4. Defecting in the final round (vulnerability of finite games)
    
    The strategy treats cooperation as an investment in group success,
    conditioning play on the probability of reaching the cooperation threshold m.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        empirical_rate = self._calculate_empirical_rate(history, round_num)
        if round_num == self.r - 1:
            expected_cooperators = empirical_rate * self.n
            if expected_cooperators >= self.m:
                return Action.D
            else:
                return Action.D
        return self._decide_intermediate_round(empirical_rate, round_num)

    def _calculate_empirical_rate(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate observed cooperation rate across all players in rounds 0 to round_num-1.
        
        Returns fraction of cooperations observed.
        Handles edge case of division by zero.
        """
        if round_num == 0:
            return 0.0
        total_opponent_cooperations = float(np.sum(history.opponent_actions[:round_num, :]))
        total_possible = round_num * self.n
        if total_possible == 0:
            return 0.0
        return total_opponent_cooperations / total_possible

    def _decide_intermediate_round(self, empirical_rate: float, round_num: int) -> Action:
        """
        Make probabilistic cooperation decision for intermediate rounds (1 to r-2).
        
        Uses empirical cooperation tracking with confidence thresholds.
        """
        expected_cooperators = empirical_rate * self.n
        threshold_met = expected_cooperators >= self.m
        high_confidence_threshold = self.m * 0.85
        medium_confidence_threshold = self.m * 0.5
        if expected_cooperators >= high_confidence_threshold:
            return Action.C
        if expected_cooperators >= medium_confidence_threshold:
            p_cooperate = self._calculate_cooperation_probability(empirical_rate, round_num)
            if random.random() < p_cooperate:
                return Action.C
            else:
                return Action.D
        return Action.D

    def _calculate_cooperation_probability(self, empirical_rate: float, round_num: int) -> float:
        """
        Calculate probabilistic cooperation for medium-confidence scenarios.
        
        Accounts for:
        - Distance from threshold (soft transition zone)
        - Reward multiplier k
        - Remaining rounds
        """
        lower_bound = self.m / self.n - 0.15
        transition_width = 0.3
        if transition_width == 0:
            transition_factor = 0.5
        else:
            transition_factor = (empirical_rate - lower_bound) / transition_width
        transition_factor = max(0.0, min(1.0, transition_factor))
        k_factor = 1.0 + math.log(max(1.0, self.k))
        remaining_rounds = self.r - round_num
        rounds_factor = remaining_rounds / max(1, self.r)
        p_cooperate = transition_factor * k_factor * rounds_factor
        return max(0.0, min(1.0, p_cooperate))

class Strategy_COLLECTIVE_76(BaseStrategy):
    """
    Adaptive Threshold Reciprocity Strategy for Collective Risk Dilemma.
    
    Balances individual security with collective benefit by:
    1. Monitoring historical cooperation rates
    2. Estimating expected cooperators for the current round
    3. Cooperating when cooperation can help achieve the threshold m
    4. Defecting when threshold is unachievable or already assured without us
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            if self.m <= math.floor(self.n_players / 2):
                return Action.C
            else:
                return Action.D
        rounds_elapsed = round_t
        total_opponent_cooperators = 0
        for prev_round in range(rounds_elapsed):
            cooperators_in_round = sum(history.opponent_actions[prev_round, :])
            total_opponent_cooperators += cooperators_in_round
        total_all_cooperators = total_opponent_cooperators + sum(history.my_actions[:rounds_elapsed])
        total_participant_rounds = rounds_elapsed * self.n_players
        if total_participant_rounds == 0:
            historical_coop_rate = 0.0
        else:
            historical_coop_rate = total_all_cooperators / total_participant_rounds
        expected_coop = round(self.n_players * historical_coop_rate)
        if expected_coop + 1 >= self.m:
            return Action.C
        elif expected_coop >= self.m:
            return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_77(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATC)
    
    Dynamically adjusts cooperation based on observed cooperation rates and game phase.
    Cooperates when the observed cooperation rate meets or exceeds the threshold (m/n),
    defects otherwise. Maintains consistent behavior even in the final round to signal
    trustworthiness and support collective resilience.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.m / self.n
        self.high_threshold_mode = self.m / self.n > 0.75

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        prev_round_cooperators = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        obs_coop_rate = prev_round_cooperators / self.n
        effective_threshold = self._compute_effective_threshold(current_round, obs_coop_rate)
        if obs_coop_rate >= effective_threshold:
            return Action.C
        else:
            return Action.D

    def _compute_effective_threshold(self, current_round: int, obs_coop_rate: float) -> float:
        """
        Compute the effective cooperation threshold for this round.
        
        For high-threshold games (m/n > 0.75), use aggressive early-game cooperation
        and relaxed late-game thresholds. For other games, use the standard threshold.
        """
        if not self.high_threshold_mode:
            return self.threshold
        early_game_boundary = self.r * 0.4
        if current_round < early_game_boundary:
            return self.threshold
        else:
            relaxed_threshold = (self.m - 1) / self.n if self.m > 1 else self.threshold
            return max(relaxed_threshold, 0.0)

class Strategy_COLLECTIVE_78(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances collective welfare with individual rationality by:
    1. Pursuing collective success through conditional cooperation
    2. Protecting against exploitation via defection when irrational
    3. Adapting to observable patterns to maximize group outcomes
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.opponent_defection_counts = np.zeros(self.n - 1)
        self.opponent_cooperation_counts = np.zeros(self.n - 1)

    def _estimate_cooperators(self, history: PlayerHistory, current_round: int) -> float:
        """
        Estimate expected cooperators for next round based on observed trends.
        """
        if current_round == 0:
            return self.m
        last_round_cooperators = np.sum(history.opponent_actions[current_round - 1, :])
        if current_round == 1:
            return float(last_round_cooperators)
        prev_round_cooperators = np.sum(history.opponent_actions[current_round - 2, :])
        if last_round_cooperators > prev_round_cooperators:
            estimate = last_round_cooperators * 1.2
        elif last_round_cooperators < prev_round_cooperators:
            estimate = last_round_cooperators * 0.8
        else:
            estimate = float(last_round_cooperators)
        return np.clip(estimate, 0, self.n - 1)

    def _estimate_defectors(self, history: PlayerHistory, current_round: int) -> float:
        """
        Estimate expected defectors based on individual consistency patterns.
        """
        if current_round == 0:
            return 0.0
        consistent_defectors = 0.0
        for opp_idx in range(self.n - 1):
            defection_count = np.sum(~history.opponent_actions[:current_round, opp_idx])
            cooperation_count = np.sum(history.opponent_actions[:current_round, opp_idx])
            if cooperation_count > 0 and defection_count / (defection_count + cooperation_count) > 0.8:
                consistent_defectors += 1.0
            elif cooperation_count == 0 and current_round > 0:
                consistent_defectors += 1.0
        return consistent_defectors

    def _get_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate cooperation rate in the most recent round.
        """
        if current_round == 0:
            return 0.0
        recent_cooperators = np.sum(history.opponent_actions[current_round - 1, :])
        return recent_cooperators / (self.n - 1)

    def _get_phase_factor(self, current_round: int) -> str:
        """
        Determine game phase based on round number.
        """
        if current_round == 0:
            return 'first'
        elif current_round < 3:
            return 'commitment'
        elif current_round < self.r * 0.75:
            return 'midgame'
        else:
            return 'endgame'

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        last_round_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        threshold_met_last_round = last_round_cooperators >= self.m
        cooperation_rate_last_round = self._get_cooperation_rate(history, current_round)
        min_coop_rate_needed = self.m / self.n
        phase = self._get_phase_factor(current_round)
        if current_round == self.r - 1:
            if threshold_met_last_round:
                return Action.C
            estimated_coop = self._estimate_cooperators(history, current_round)
            if estimated_coop >= self.m:
                return Action.C
            return Action.D
        if threshold_met_last_round:
            estimated_defectors = self._estimate_defectors(history, current_round)
            expected_cooperators = self.n - 1 - estimated_defectors
            if expected_cooperators >= self.m:
                return Action.C
            else:
                return Action.D
        estimated_cooperators = self._estimate_cooperators(history, current_round)
        if estimated_cooperators >= self.m:
            return Action.C
        if phase == 'commitment':
            tolerance_threshold = min_coop_rate_needed * 0.5
            if cooperation_rate_last_round >= tolerance_threshold:
                return Action.C
            return Action.D
        elif phase == 'midgame':
            if cooperation_rate_last_round >= min_coop_rate_needed:
                return Action.C
            return Action.D
        elif phase == 'endgame':
            pessimism_threshold = min_coop_rate_needed * 0.6
            if cooperation_rate_last_round >= pessimism_threshold:
                return Action.C
            return Action.D
        return Action.D

class Strategy_COLLECTIVE_79(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances collective welfare with individual rationality by:
    - Cooperating in round 1 to bootstrap cooperation
    - Defecting in the final round (endgame logic)
    - Tracking aggregate cooperation rate and responding adaptively in middle rounds
    - Using dynamic tolerance buffers that tighten in late rounds
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.n_rounds - 1:
            return Action.D
        total_coop_acts = 0
        total_possible_acts = 0
        for r in range(round_number):
            for opponent_idx in range(self.n_players - 1):
                if history.opponent_actions[r, opponent_idx]:
                    total_coop_acts += 1
            if history.my_actions[r]:
                total_coop_acts += 1
            total_possible_acts += self.n_players
        if total_possible_acts == 0:
            cooperation_rate = 0.0
        else:
            cooperation_rate = total_coop_acts / total_possible_acts
        if round_number <= 3:
            tolerance = 0.2
        elif round_number >= self.n_rounds - 3:
            tolerance = 0.1
        else:
            tolerance = 0.15
        critical_ratio = self.m / self.n_players
        upper_bound = critical_ratio * (1.0 + tolerance)
        lower_bound = critical_ratio * (1.0 - tolerance)
        if cooperation_rate >= upper_bound:
            return Action.C
        elif cooperation_rate >= lower_bound:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_80(BaseStrategy):
    """
    Adaptive Threshold Dynamics strategy for Collective Risk Dilemma.
    
    Balances collective welfare with rational self-protection by:
    - Opening with cooperation to establish good faith
    - Defecting in final round (no future punishment possible)
    - Adapting middle-round decisions based on observed cooperation levels
    - Using three cooperation bands: high (â‰¥66%), threshold (m to 66%), collapse (<m)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.r - 1:
            return Action.D
        previous_round_idx = round_number - 1
        observed_cooperators = int(sum(history.opponent_actions[previous_round_idx, :]))
        rounds_remaining = self.r - round_number
        if observed_cooperators >= math.ceil(0.66 * self.n):
            return Action.C
        if observed_cooperators >= self.m:
            if rounds_remaining > 1:
                return Action.C
            else:
                return Action.D
        if observed_cooperators >= math.ceil(0.5 * self.n):
            return Action.C
        elif observed_cooperators >= 1 and rounds_remaining > 2:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_81(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances collective optimization (achieving cooperation threshold) with individual
    resilience (protecting against exploitation). Uses dynamic decision rules based on
    observed cooperation levels and remaining rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        c_prev = int(sum(history.opponent_actions[round_num - 1, :]))
        rounds_remaining = self.r - round_num - 1
        if round_num == self.r - 1:
            return self._final_round_decision(c_prev)
        return self._middle_round_decision(c_prev, rounds_remaining)

    def _final_round_decision(self, c_prev: int) -> Action:
        """Decision rule for final round."""
        m_half = math.ceil(self.m / 2.0)
        if c_prev >= self.m - 1:
            return Action.C
        elif c_prev >= m_half:
            return Action.C
        else:
            return Action.D

    def _middle_round_decision(self, c_prev: int, rounds_remaining: int) -> Action:
        """Decision rule for middle rounds (2 to r-1)."""
        m_60 = math.ceil(self.m * 0.6)
        m_30 = math.floor(self.m * 0.3)
        if c_prev >= self.m:
            return Action.C
        if c_prev >= self.m - 1:
            return Action.C
        if c_prev >= m_60:
            return Action.C
        if c_prev <= m_30 and rounds_remaining <= 2:
            return Action.D
        return self._probabilistic_decision(c_prev, rounds_remaining)

    def _probabilistic_decision(self, c_prev: int, rounds_remaining: int) -> Action:
        """Probabilistic decision rule for uncertain middle rounds."""
        if self.m == self.n:
            p_cooperate = (c_prev / self.n) ** 2 * (rounds_remaining / self.r)
        elif self.r <= 3:
            m_50 = math.ceil(self.m * 0.5)
            if c_prev >= m_50:
                return Action.C
            p_cooperate = c_prev / self.m * (rounds_remaining / self.r)
        elif self.n >= 50 and self.m <= self.n / 5:
            p_cooperate = c_prev / self.m * (rounds_remaining / self.r) * 0.8
        else:
            p_cooperate = c_prev / self.m * (rounds_remaining / self.r)
        p_cooperate = max(0.0, min(1.0, p_cooperate))
        if random.random() < p_cooperate:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_82(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances collective welfare (achieving threshold) with individual rationality.
    Cooperates when group momentum is strong, defects when cooperation collapses,
    and adapts based on remaining rounds and historical success rates.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.last_nonzero_coop_round = -1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            return self._final_round_decision(history)
        return self._middle_round_decision(round_num, history)

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """
        Final round: cooperate if threshold was achieved in â‰¥50% of previous rounds,
        otherwise defect.
        """
        rounds_with_threshold = 0
        for round_idx in range(len(history.my_actions) - 1):
            coop_count = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                coop_count += 1
            if coop_count >= self.m:
                rounds_with_threshold += 1
        threshold_success_rate = rounds_with_threshold / (self.r - 1) if self.r > 1 else 0
        if threshold_success_rate >= 0.5:
            return Action.C
        return Action.D

    def _middle_round_decision(self, round_num: int, history: PlayerHistory) -> Action:
        """
        Middle rounds: compute cooperation rates and apply decision logic.
        """
        recent_coop_count = sum(history.opponent_actions[round_num - 1, :])
        if history.my_actions[round_num - 1]:
            recent_coop_count += 1
        recent_coop_rate = recent_coop_count / self.n
        total_coop_count = np.sum(history.opponent_actions[:round_num, :]) + np.sum(history.my_actions[:round_num])
        total_possible = self.n * round_num
        global_coop_rate = total_coop_count / total_possible if total_possible > 0 else 0
        threshold_proximity = self.m / self.n
        defection_band = 0.15
        if self.m > self.n * 0.7:
            defection_band = 0.25
        if recent_coop_rate == 0:
            if round_num - self.last_nonzero_coop_round >= 2:
                return Action.D
        else:
            self.last_nonzero_coop_round = round_num
        buffer = 1.2 if self.m > 2 else 1.1
        if global_coop_rate >= buffer * threshold_proximity:
            return Action.C
        if recent_coop_rate >= threshold_proximity and global_coop_rate >= 0.9 * threshold_proximity:
            return Action.C
        if recent_coop_rate < threshold_proximity - defection_band and global_coop_rate < threshold_proximity:
            return Action.D
        remaining_rounds = self.r - round_num
        if remaining_rounds >= 3:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_83(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATC) for Collective Risk Dilemma.
    
    Balances individual security with collective benefit by dynamically adjusting
    cooperation based on observed cooperation rates and proximity to critical thresholds.
    Core insight: defection is only rational if cooperation will fail anyway;
    cooperation becomes rational when others are likely to cooperate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        round_num = state.round_number
        coop_rate = self._calculate_cooperation_rate(history)
        threshold_rate = self.m / self.n
        if self.m == self.n:
            if coop_rate < 1.0:
                return Action.D
            return Action.C
        if coop_rate >= threshold_rate:
            return Action.C
        if round_num >= 3:
            recent_avg = self._calculate_recent_cooperation_rate(history, window=3)
            if recent_avg > coop_rate:
                return Action.C
        if round_num == self.r - 1:
            current_round_coops = self._count_current_round_cooperators(history)
            if current_round_coops >= self.m - 1:
                return Action.C
        return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        """
        Calculate the historical cooperation rate of all opponents.
        Returns the fraction of opponent actions that were cooperation across all past rounds.
        """
        if history.opponent_actions.shape[0] == 0:
            return 0.0
        total_cooperations = float(np.sum(history.opponent_actions))
        total_actions = float(history.opponent_actions.shape[0] * history.opponent_actions.shape[1])
        if total_actions == 0:
            return 0.0
        return total_cooperations / total_actions

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory, window: int) -> float:
        """
        Calculate cooperation rate in the most recent 'window' rounds.
        """
        if history.opponent_actions.shape[0] == 0:
            return 0.0
        start_idx = max(0, history.opponent_actions.shape[0] - window)
        recent_actions = history.opponent_actions[start_idx:, :]
        if recent_actions.size == 0:
            return 0.0
        total_cooperations = float(np.sum(recent_actions))
        total_actions = float(recent_actions.shape[0] * recent_actions.shape[1])
        if total_actions == 0:
            return 0.0
        return total_cooperations / total_actions

    def _count_current_round_cooperators(self, history: PlayerHistory) -> int:
        """
        Count the number of opponents who cooperated in the most recent round.
        """
        if history.opponent_actions.shape[0] == 0:
            return 0
        current_round = history.opponent_actions[-1, :]
        return int(np.sum(current_round))

class Strategy_COLLECTIVE_84(BaseStrategy):
    """
    Adaptive Threshold Matching strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by monitoring progress
    toward the cooperation threshold dynamically and adapting behavior based on
    observed cooperation rates, remaining rounds, and historical patterns.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.unanimous_defection_detected = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if self.unanimous_defection_detected:
            return Action.D
        cooperators_prev = int(sum(history.opponent_actions[round_num - 1, :]))
        if cooperators_prev == 0 and round_num > 0:
            self.unanimous_defection_detected = True
            return Action.D
        if round_num == self.n_rounds - 1:
            if cooperators_prev >= self.m:
                return Action.C
            else:
                return Action.D
        threshold_needed = self.m - 1
        if self.m > self.n_players - 2:
            threshold_needed = self.m - 2
        if cooperators_prev >= threshold_needed:
            return Action.C
        start_idx = max(0, round_num - 3)
        end_idx = round_num
        rounds_to_check = history.opponent_actions[start_idx:end_idx, :]
        if rounds_to_check.size > 0:
            total_cooperations = np.sum(rounds_to_check)
            total_slots = rounds_to_check.shape[0] * rounds_to_check.shape[1]
            coop_rate = total_cooperations / total_slots if total_slots > 0 else 0.0
            threshold_rate = self.m / self.n_players * 1.2
            if coop_rate >= threshold_rate:
                return Action.C
        if round_num <= 2:
            early_history = history.opponent_actions[0:round_num, :]
            if early_history.size > 0:
                defection_count = np.sum(~early_history)
                total_slots = early_history.shape[0] * early_history.shape[1]
                defection_rate = defection_count / total_slots if total_slots > 0 else 0.0
                if defection_rate <= 0.5:
                    return Action.C
        if cooperators_prev < self.m and self.n_rounds - round_num >= 2:
            probability = (self.n_rounds - round_num) / self.n_rounds
            if random.random() < probability:
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_85(BaseStrategy):
    """
    Adaptive Threshold Matching (ATM) Strategy for Collective Risk Dilemma.
    
    Balances optimistic cooperation with rational defection based on empirical
    cooperation rates. Leads with cooperation in round 1, defects in final round,
    and adaptively matches observed cooperation levels in between using threshold
    multipliers (0.9x, 0.6x, 1.0x) to filter noise while rewarding genuine signals.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        if round_t == self.n_rounds - 1:
            return Action.D
        prev_cooperators = int(np.sum(history.opponent_actions[round_t - 1, :]))
        cooperation_rate = prev_cooperators / self.n_players
        cooperation_threshold = self.m / self.n_players
        consecutive_defections = 0
        for t in range(round_t - 1, max(-1, round_t - 3), -1):
            if t < 0:
                break
            round_cooperators = int(np.sum(history.opponent_actions[t, :]))
            round_cooperation_rate = round_cooperators / self.n_players
            if round_cooperation_rate < cooperation_threshold:
                consecutive_defections += 1
            else:
                break
        if cooperation_rate >= cooperation_threshold * 0.9:
            return Action.C
        elif cooperation_rate >= cooperation_threshold * 0.6:
            return Action.C
        elif cooperation_rate >= cooperation_threshold:
            if consecutive_defections <= 1:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_86(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances collective welfare with individual security by tracking cooperation rates,
    maintaining a safety margin above the threshold, and responding to trends in opponent behavior.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.total_cooperators = 0
        self.total_rounds_elapsed = 0
        self.threshold_met_last_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        cooperation_rate = self.total_cooperators / (self.total_rounds_elapsed * n) if self.total_rounds_elapsed > 0 else 0.0
        threshold_min = m / n * 0.8
        threshold_max = m / n * 1.2
        threshold_ideal = m / n
        if cooperation_rate >= threshold_max:
            action = Action.C
        elif cooperation_rate < threshold_min:
            action = Action.D
        else:
            action = self._decide_in_critical_zone(state, history, cooperation_rate, threshold_ideal, m, n)
        cooperators_this_round = int(np.sum(history.opponent_actions[state.round_number - 1, :]))
        cooperators_this_round += int(action == Action.C)
        self.total_cooperators += cooperators_this_round
        self.total_rounds_elapsed += 1
        self.threshold_met_last_round = cooperators_this_round >= m
        return action

    def _decide_in_critical_zone(self, state: GameState, history: PlayerHistory, cooperation_rate: float, threshold_ideal: float, m: int, n: int) -> Action:
        """Decide action when cooperation rate is in the critical zone."""
        current_round = state.round_number
        if self.threshold_met_last_round and cooperation_rate >= threshold_ideal:
            return Action.C
        if current_round >= 2:
            cooperators_prev_round = int(np.sum(history.opponent_actions[current_round - 1, :]))
            cooperators_two_rounds_ago = int(np.sum(history.opponent_actions[current_round - 2, :]))
            if cooperators_prev_round < m and cooperators_two_rounds_ago < m:
                if cooperation_rate < threshold_ideal * 1.1:
                    return Action.D
        recent_cooperators = self._get_recent_cooperation_rate(history, current_round, n)
        earlier_rounds = current_round - 1
        if earlier_rounds > 0:
            earlier_cooperators = (self.total_cooperators - int(np.sum(history.opponent_actions[current_round - 1, :]))) / (earlier_rounds * n) if earlier_rounds > 0 else 0.0
        else:
            earlier_cooperators = 0.0
        recent_trend = recent_cooperators - earlier_cooperators
        if recent_trend >= 0.0:
            return Action.C
        else:
            return Action.D

    def _get_recent_cooperation_rate(self, history: PlayerHistory, current_round: int, n: int) -> float:
        """Calculate cooperation rate in the last 3 rounds (or fewer if not enough history)."""
        start_round = max(0, current_round - 4)
        end_round = current_round - 1
        if start_round > end_round:
            return 0.0
        recent_cooperators = 0
        for round_idx in range(start_round, end_round + 1):
            if round_idx < len(history.opponent_actions):
                recent_cooperators += int(np.sum(history.opponent_actions[round_idx, :]))
        rounds_examined = end_round - start_round + 1
        if rounds_examined <= 0:
            return 0.0
        return recent_cooperators / (rounds_examined * n)

class Strategy_COLLECTIVE_87(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Cooperating in round 1 to establish baseline trust
    2. Defecting in the final round (no future consequences)
    3. Adapting in middle rounds based on observed cooperation rates and recent success
    4. Using thresholds (1.2Ã— and 0.8Ã— of m/n) to detect cooperation trends
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.n_rounds - 1:
            return Action.D
        prev_round_idx = round_number - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            cooperators_last_round += 1
        cooperation_rate = cooperators_last_round / self.n_players
        recent_success = cooperators_last_round >= self.m
        threshold_min = self.m / self.n_players
        threshold_high = threshold_min * 1.2
        threshold_low = threshold_min * 0.8
        if cooperation_rate >= threshold_high:
            return Action.C
        elif cooperation_rate >= threshold_min and recent_success:
            return Action.C
        elif cooperation_rate < threshold_low:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_88(BaseStrategy):
    """
    Adaptive Threshold Sentinel Strategy for Collective Risk Dilemma.
    
    Balances individual security vs. collective welfare through conditional cooperation.
    Uses expected cooperator estimation, contagion sensitivity, optimism gradient,
    and majority response mechanisms to adapt to evolving cooperation dynamics.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.base_threshold = (self.m + 0.5) / self.n
        self.current_threshold = self.base_threshold
        self.threshold_reduction = 0.0
        self.consecutive_increase_count = 0
        self.last_coop_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        all_actions = history.opponent_actions
        observed_last = int(np.sum(all_actions[round_t - 1, :]))
        expected_cooperators = self._calculate_expected_cooperators(all_actions, round_t, observed_last)
        in_recovery = self._check_contagion(all_actions, round_t)
        if in_recovery:
            return Action.D
        self._update_optimism_gradient(all_actions, round_t)
        threshold = self.base_threshold - self.threshold_reduction
        threshold_cooperators = threshold * self.m
        if expected_cooperators >= threshold_cooperators:
            confidence = expected_cooperators / self.m if self.m > 0 else 0.0
            if confidence >= threshold:
                decision = Action.C
            else:
                decision = Action.D
        else:
            decision = Action.D
        decision = self._apply_majority_response(decision, all_actions, round_t)
        self.last_coop_count = observed_last
        return decision

    def _calculate_expected_cooperators(self, all_actions: NDArray, round_t: int, observed_last: int) -> float:
        """
        Calculate expected cooperators using recent behavior, historical patterns,
        and volatility discount.
        """
        if round_t <= 1:
            return float(observed_last)
        if round_t <= 2:
            historical_coop = float(observed_last)
        else:
            historical_coop_counts = np.sum(all_actions[0:round_t - 1, :], axis=1)
            historical_coop = float(np.mean(historical_coop_counts))
        if round_t <= 2:
            volatility = 0.0
        else:
            start_idx = max(0, round_t - 4)
            recent_counts = np.sum(all_actions[start_idx:round_t - 1, :], axis=1)
            volatility = float(np.std(recent_counts)) if len(recent_counts) > 0 else 0.0
        uncertainty_discount = min(volatility / self.n, 0.5) if self.n > 0 else 0.0
        expected = 0.6 * observed_last + 0.3 * historical_coop - 0.1 * uncertainty_discount * self.n
        return expected

    def _check_contagion(self, all_actions: NDArray, round_t: int) -> bool:
        """
        Check if cooperation has dropped below m-1 for 2 consecutive rounds.
        If so, enter recovery mode (defect).
        """
        if round_t < 2:
            return False
        current_coop = int(np.sum(all_actions[round_t - 1, :]))
        previous_coop = int(np.sum(all_actions[round_t - 2, :]))
        if current_coop < self.m - 1 and previous_coop < self.m - 1:
            return True
        return False

    def _update_optimism_gradient(self, all_actions: NDArray, round_t: int) -> None:
        """
        If cooperation has increased for 2+ consecutive rounds, decrease threshold.
        Reset if cooperation falls.
        """
        if round_t < 2:
            return
        current_coop = int(np.sum(all_actions[round_t - 1, :]))
        previous_coop = int(np.sum(all_actions[round_t - 2, :]))
        if current_coop > previous_coop:
            self.consecutive_increase_count += 1
            if self.consecutive_increase_count >= 2:
                self.threshold_reduction = min(self.threshold_reduction + 0.05, 0.15)
        else:
            self.consecutive_increase_count = 0
            self.threshold_reduction = 0.0

    def _apply_majority_response(self, decision: Action, all_actions: NDArray, round_t: int) -> Action:
        """
        If strict majority defected last round and we decided to cooperate, defect instead.
        If strict majority cooperated last round and we defected, cooperate instead.
        """
        if round_t < 1:
            return decision
        coop_last = int(np.sum(all_actions[round_t - 1, :]))
        majority_threshold = self.n / 2.0
        if decision == Action.C and coop_last < majority_threshold:
            return Action.D
        elif decision == Action.D and coop_last > majority_threshold:
            return Action.C
        return decision

class Strategy_COLLECTIVE_89(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC): A two-round information gathering strategy
    followed by adaptive cooperation based on empirical cooperation rates.
    
    Balances self-protection against exploitation with collective optimization by:
    1. Testing cooperation intent in rounds 1-2
    2. Computing empirical cooperation rate from observations
    3. Adapting decisions based on whether threshold success appears plausible
    4. Protecting endowment in final round if threshold unlikely
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0 or round_num == 1:
            return Action.C
        coop_rate = self._calculate_cooperation_rate(history, rounds_to_check=2)
        threshold_rate = self.m / self.n
        if round_num == self.r - 1:
            if coop_rate >= threshold_rate * 0.9:
                return Action.C
            else:
                return Action.D
        if coop_rate >= threshold_rate * 1.2:
            return Action.C
        elif coop_rate >= threshold_rate * 0.8:
            rounds_remaining = self.r - round_num
            if rounds_remaining > 1:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, rounds_to_check: int) -> float:
        """
        Calculate the empirical cooperation rate based on opponent actions
        in the first `rounds_to_check` rounds.
        
        Returns a value in [0, 1] representing the fraction of cooperators.
        """
        if history is None or len(history.opponent_actions) == 0:
            return 0.0
        available_rounds = min(rounds_to_check, len(history.opponent_actions))
        if available_rounds == 0:
            return 0.0
        total_cooperations = 0
        for round_idx in range(available_rounds):
            cooperators_in_round = np.sum(history.opponent_actions[round_idx, :])
            total_cooperations += cooperators_in_round
        avg_cooperators = total_cooperations / available_rounds
        coop_rate = avg_cooperators / self.n
        return coop_rate

class Strategy_COLLECTIVE_90(BaseStrategy):
    """
    Adaptive Threshold Reciprocity strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare through:
    - Initial cooperation to test reciprocity
    - Threshold-based reciprocation in middle rounds
    - Strategic defection in final round based on recent success
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        last_round_idx = state.round_number - 1
        my_last_action = history.my_actions[last_round_idx]
        opponent_last_actions = history.opponent_actions[last_round_idx, :]
        cooperators_last_round = int(my_last_action) + int(np.sum(opponent_last_actions))
        threshold_met_last = cooperators_last_round >= m
        if state.round_number == r - 1:
            if threshold_met_last:
                return Action.C
            else:
                return Action.D
        if threshold_met_last:
            return Action.C
        else:
            defector_count = n - cooperators_last_round
            if defector_count > n - m:
                return Action.D
            else:
                return Action.C

class Strategy_COLLECTIVE_91(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Dynamically adjusts cooperation based on observed cooperation rates and remaining time,
    balancing individual rational self-interest with collective welfare through:
    - Optimistic cooperation in round 1
    - Adaptive threshold response in middle rounds
    - Conditional defection in final round (with reciprocity exception)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.tolerance = 0.15
        self._adjust_tolerance()

    def _adjust_tolerance(self) -> None:
        """Adjust tolerance based on game parameters."""
        threshold_ratio = self.m / self.n_players
        if self.m == self.n_players - 1:
            self.tolerance = 0.2
        elif self.m == 2 and self.n_players > 4:
            self.tolerance = 0.1
        elif threshold_ratio <= 0.2:
            self.tolerance = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        """
        Determine action based on game state and history.
        """
        if state.round_number == 0:
            return Action.C
        prev_round_idx = state.round_number - 1
        prev_cooperators = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        prev_coop_rate = prev_cooperators / self.n_players
        if state.round_number == self.n_rounds - 1:
            if self.n_rounds <= 3:
                return Action.D
            avg_coop_rate = np.mean(np.sum(history.opponent_actions, axis=1)) / self.n_players
            threshold_ratio = self.m / self.n_players
            if avg_coop_rate >= threshold_ratio:
                return Action.C
            return Action.D
        return self._adaptive_response(prev_coop_rate)

    def _adaptive_response(self, coop_rate: float) -> Action:
        """
        Determine action based on cooperation rate in previous round.
        """
        threshold_ratio = self.m / self.n_players
        if coop_rate >= threshold_ratio:
            if coop_rate >= 1.0 - 1e-10:
                if random.random() < 0.95:
                    return Action.C
                return Action.D
            return Action.C
        if coop_rate < threshold_ratio - self.tolerance:
            return Action.D
        surplus = coop_rate - threshold_ratio + self.tolerance
        prob_coop = surplus / self.tolerance
        prob_coop = max(0.0, min(1.0, prob_coop))
        if random.random() < prob_coop:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_92(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Cooperating in round 1 to establish baseline cooperation
    2. Dynamically adapting based on observed cooperation rates in rounds 2 to r-1
    3. Defecting in the final round (with exception for very short games)
    4. Using probabilistic cooperation when cooperation is near the threshold
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        c_prev = int(sum(history.opponent_actions[round_num - 1, :]))
        if round_num == self.r - 1:
            if self.r <= 5 and c_prev >= self.m:
                return Action.C
            else:
                return Action.D
        if c_prev >= self.m:
            return Action.C
        elif c_prev >= self.m - 1:
            return Action.C
        elif c_prev >= math.ceil(self.m / 2):
            probability = c_prev / self.m
            if random.random() < probability:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_93(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATC)
    
    Dynamically calibrates cooperation based on observed cooperation rates and round context.
    Balances collective welfare maximization with self-protection against exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_rate = self.m / self.n_players
        self.marginal_impact = 1.0 / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        total_rounds = self.n_rounds
        if round_number == 0:
            return Action.C
        last_round_opponent_actions = history.opponent_actions[round_number - 1, :]
        cooperators_last_round = int(np.sum(last_round_opponent_actions))
        if history.my_actions[round_number - 1]:
            cooperators_last_round += 1
        cooperation_rate = cooperators_last_round / self.n_players
        if round_number == total_rounds - 1:
            if cooperation_rate >= self.threshold_rate:
                return Action.C
            else:
                return Action.D
        deficit = self.threshold_rate - cooperation_rate
        remaining_rounds = total_rounds - round_number
        if cooperation_rate >= self.threshold_rate:
            return Action.C
        if deficit <= self.marginal_impact:
            return Action.C
        if deficit > remaining_rounds * self.marginal_impact:
            return Action.D
        return Action.C

class Strategy_COLLECTIVE_94(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances proactive cooperation with adaptive defection by:
    1. Leading with cooperation in early rounds to establish intent
    2. Maintaining a dynamic cooperation threshold with safety margin
    3. Punishing free-riding through proportional defection
    4. Recovering from transient failures while avoiding spiral collapse
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_counter = 0
        self.threshold_never_achieved = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if round_num == 0:
            return Action.C
        if round_num <= 2:
            return Action.C
        last_round_idx = round_num - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[last_round_idx, :]))
        if history.my_actions[last_round_idx]:
            cooperators_last_round += 1
        recent_start = max(0, round_num - 3)
        recent_rounds = round_num - recent_start
        recent_cooperators = int(np.sum(history.opponent_actions[recent_start:round_num, :]))
        recent_my_cooperations = int(np.sum(history.my_actions[recent_start:round_num]))
        total_recent = recent_cooperators + recent_my_cooperations
        if recent_rounds > 0:
            recent_coop_rate = total_recent / (recent_rounds * n)
        else:
            recent_coop_rate = 0.0
        if round_num >= 2:
            prev_prev_idx = round_num - 2
            prev_idx = round_num - 1
            prev_prev_coop = int(np.sum(history.opponent_actions[prev_prev_idx, :]))
            if history.my_actions[prev_prev_idx]:
                prev_prev_coop += 1
            prev_coop = cooperators_last_round
            if prev_prev_coop < m and prev_coop < m:
                if self.punishment_counter == 0:
                    self.punishment_counter = 2
        if self.punishment_counter > 0:
            self.punishment_counter -= 1
            return Action.D
        base_threshold = math.ceil(m + 0.5)
        if round_num <= r // 3:
            adaptation_term = 1
        elif round_num >= 2 * r // 3:
            adaptation_term = -1
        else:
            adaptation_term = 0
        if recent_coop_rate < m / n * 0.8 and recent_coop_rate > 0:
            adaptation_term -= 1
        cooperation_threshold = max(m, base_threshold + adaptation_term)
        if cooperators_last_round < m:
            self.threshold_never_achieved = True
        if 3 < round_num < 2 * r // 3:
            if cooperators_last_round >= cooperation_threshold and cooperators_last_round > m - 2:
                return Action.C
            else:
                return Action.D
        if 2 * r // 3 <= round_num < r - 1:
            if cooperators_last_round >= m:
                return Action.C
            else:
                return Action.D
        if round_num == r - 1:
            if cooperators_last_round >= m:
                return Action.C
            else:
                return Action.D
        if self.threshold_never_achieved and round_num > 3:
            return Action.D
        return Action.C

class Strategy_COLLECTIVE_95(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Seeking equilibrium cooperation when m or more players cooperate
    2. Protecting against exploitation through adaptive defection
    3. Recovering from breakdown through controlled re-engagement
    4. Maximizing group payoff while remaining robust to free-riders
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.consecutive_failure_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        last_cooperators = int(sum(history.opponent_actions[round_num - 1, :]))
        trend = 0.0
        if round_num > 1:
            prev_cooperators = int(sum(history.opponent_actions[round_num - 2, :]))
            trend = (last_cooperators - prev_cooperators) / self.n
        if last_cooperators >= self.m:
            self.consecutive_failure_count = 0
            if trend >= -0.2:
                return Action.C
            else:
                return Action.D
        elif last_cooperators == self.m - 1:
            self.consecutive_failure_count = 0
            return Action.C
        else:
            self.consecutive_failure_count += 1
            if self.consecutive_failure_count >= 2 and round_num >= self.r - 2:
                return Action.C
            elif self.consecutive_failure_count == 1:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_96(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances robustness, adaptability, and collective orientation by:
    1. Estimating expected cooperators based on observed trends
    2. Cooperating if threshold is likely reachable
    3. Exploring early, adapting later
    4. Avoiding premature surrender via salvage mode
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.salvage_counter = 0
        self.consecutive_below_threshold = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        previous_round_actions = history.opponent_actions[round_number - 1, :]
        past_cooperators = int(np.sum(previous_round_actions))
        if history.my_actions[round_number - 1]:
            past_cooperators += 1
        stability_bonus = 1 if past_cooperators > self.m else 0
        defection_drift = max(1, math.floor(self.n * 0.1))
        estimated_cooperators = past_cooperators + stability_bonus - defection_drift
        estimated_cooperators = max(0, estimated_cooperators)
        if round_number >= 2:
            prev_round_idx = round_number - 1
            if prev_round_idx >= 1:
                prev_prev_cooperators = int(np.sum(history.opponent_actions[prev_round_idx - 1, :]))
                if history.my_actions[prev_round_idx - 1]:
                    prev_prev_cooperators += 1
                current_round_cooperators = past_cooperators
                if current_round_cooperators < self.m and prev_prev_cooperators < self.m:
                    self.consecutive_below_threshold += 1
                    if self.consecutive_below_threshold == 2 and self.salvage_counter < 1:
                        self.salvage_counter += 1
                        return Action.C
                    elif self.consecutive_below_threshold >= 2 and self.salvage_counter >= 1:
                        return Action.D
                else:
                    self.consecutive_below_threshold = 0
        cooperation_needed = self.m - estimated_cooperators
        deficit_tolerance = math.ceil((self.n - self.m) / 2.0)
        early_phase_threshold = math.ceil(self.r * 0.3)
        early_phase = round_number <= early_phase_threshold
        if estimated_cooperators >= self.m:
            return Action.C
        elif cooperation_needed <= deficit_tolerance:
            return Action.C
        elif early_phase:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_97(BaseStrategy):
    """
    Adaptive Collective Risk Strategy (ACR)
    
    Balances individual rationality with collective welfare through conditional cooperation.
    Cooperates when threshold achievement seems likely, defects when it's mathematically
    impossible or when others are systematically free-riding. Includes recovery mechanism
    to break defection spirals and special handling for early/late game phases.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = 0.75
        self.recovery_threshold = 2
        self.predicted_returners = 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        """Decide whether to cooperate or defect in current round."""
        if state.round_number == 0:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        coop_rate = self._calculate_cooperation_rate(history)
        last_round_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        threshold_met_last = last_round_cooperators >= m
        estimated_cooperators = self._estimate_cooperators(history, current_round, n, m)
        if current_round == r - 1:
            return self._late_game_decision(coop_rate, history, current_round, n, m)
        if coop_rate >= m / n * self.cooperation_threshold:
            return Action.C
        if estimated_cooperators >= m:
            return Action.C
        if self._should_recover(history, current_round, n, m):
            return Action.C
        return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate historical cooperation rate across all rounds and players."""
        if history.opponent_actions.shape[0] == 0:
            return 0.0
        total_rounds = history.opponent_actions.shape[0]
        total_players = history.opponent_actions.shape[1]
        if total_rounds == 0 or total_players == 0:
            return 0.0
        total_cooperations = np.sum(history.opponent_actions)
        total_decisions = total_rounds * total_players
        return float(total_cooperations / total_decisions) if total_decisions > 0 else 0.0

    def _estimate_cooperators(self, history: PlayerHistory, current_round: int, n: int, m: int) -> int:
        """
        Estimate how many players will cooperate this round.
        
        Based on Rule 2 logic.
        """
        if current_round == 0:
            return n // 2
        observed_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if observed_cooperators >= m:
            return observed_cooperators + 1
        if observed_cooperators == m - 1:
            return m
        deficit = m - observed_cooperators
        if deficit <= self.recovery_threshold and deficit > 0:
            predicted_return = min(self.predicted_returners, deficit)
            return observed_cooperators + predicted_return
        return observed_cooperators

    def _should_recover(self, history: PlayerHistory, current_round: int, n: int, m: int) -> bool:
        """
        Check recovery mechanism: break defection spirals.
        
        If last 2 rounds both failed (< m cooperators):
        - If I cooperated in those rounds, defect to signal unprofitability
        - If I defected in those rounds, cooperate to test recovery
        """
        if current_round < 2:
            return False
        last_two_rounds = history.opponent_actions[current_round - 2:current_round, :]
        round_1_coop = int(np.sum(last_two_rounds[0, :]))
        round_2_coop = int(np.sum(last_two_rounds[1, :]))
        both_failed = round_1_coop < m and round_2_coop < m
        if not both_failed:
            return False
        my_last_two = history.my_actions[current_round - 2:current_round]
        if np.sum(my_last_two) == 2:
            return False
        if np.sum(my_last_two) == 0:
            return True
        return False

    def _late_game_decision(self, coop_rate: float, history: PlayerHistory, current_round: int, n: int, m: int) -> Action:
        """
        Special handling for final round.
        
        If threshold has been met in â‰¥50% of previous rounds, cooperate.
        Otherwise, defect to maximize immediate payoff.
        """
        if current_round == 0:
            return Action.C
        rounds_met_threshold = 0
        for round_idx in range(current_round):
            cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
            if cooperators >= m:
                rounds_met_threshold += 1
        success_rate = rounds_met_threshold / current_round if current_round > 0 else 0.0
        if success_rate >= 0.5:
            return Action.C
        if coop_rate < m / n:
            return Action.D
        estimated_cooperators = self._estimate_cooperators(history, current_round, n, m)
        if estimated_cooperators >= m:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_98(BaseStrategy):
    """
    Adaptive Threshold Consensus strategy for Collective Risk Dilemma.
    
    This strategy coordinates collective threshold achievement through adaptive
    reciprocity, cooperating when the threshold is reachable and defecting when
    it becomes impossible, with special leniency in early rounds and responsiveness
    to improving cooperation trends.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
        if history.my_actions[current_round - 1]:
            cooperators_last_round += 1
        if cooperators_last_round >= self.m:
            return Action.C
        if cooperators_last_round == self.m - 1:
            return Action.C
        if cooperators_last_round < self.m - 1:
            if current_round == 1 and cooperators_last_round >= self.m - 2:
                return Action.C
            if current_round > 1:
                cooperators_two_rounds_ago = int(sum(history.opponent_actions[current_round - 2, :]))
                if history.my_actions[current_round - 2]:
                    cooperators_two_rounds_ago += 1
                if cooperators_last_round > cooperators_two_rounds_ago:
                    return Action.C
            return Action.D
        return Action.D

class Strategy_COLLECTIVE_99(BaseStrategy):
    """
    Adaptive Threshold Sentinel: A collective strategy for the Collective Risk Dilemma.
    
    Core philosophy: Treat the game as a collective survival problem. The strategy:
    1. Initiates cooperation to catalyze collective success
    2. Sustains cooperation to maintain threshold achievements
    3. Closes gaps when the threshold is one cooperator away
    4. Exits gracefully when collective success becomes impossible
    5. Adapts dynamically based on observed cooperator counts
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        last_round_index = current_round - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[last_round_index, :]))
        if history.my_actions[last_round_index]:
            cooperators_last_round += 1
        if cooperators_last_round >= self.m:
            return Action.C
        if cooperators_last_round == self.m - 1:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_100(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Dynamically estimates cooperation rates and responds with calibrated contributions
    that balance collective welfare with individual resilience. Uses probabilistic
    cooperation near threshold to encourage coordination, and strategic defection
    when threshold appears unattainable.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_rate = self.m / self.n
        self.smoothed_rate = 0.0
        self.last_rate = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        cooperators_last_round = sum(history.opponent_actions[round_num - 1, :])
        observed_rate = cooperators_last_round / self.n
        self.smoothed_rate = 0.7 * observed_rate + 0.3 * self.last_rate
        self.last_rate = observed_rate
        is_final_round = round_num == self.r - 1
        if self.m == 1:
            return Action.C
        if self.m == self.n:
            if self.smoothed_rate >= 0.99:
                return Action.C
            else:
                return Action.D
        if round_num == 2 and len(history.opponent_actions) > 1:
            round_1_coop = sum(history.opponent_actions[0, :]) / self.n
            if round_1_coop >= 0.9 and observed_rate < 0.5:
                return Action.C
        if is_final_round:
            if self.smoothed_rate >= self.threshold_rate:
                return Action.C
            elif self.smoothed_rate >= self.threshold_rate * 0.5:
                return Action.D
            else:
                return Action.D
        if self.smoothed_rate >= self.threshold_rate:
            return Action.C
        elif self.smoothed_rate >= self.threshold_rate * 0.75:
            prob = self.smoothed_rate / self.threshold_rate * 0.8
            if random.random() < prob:
                return Action.C
            else:
                return Action.D
        elif self.smoothed_rate >= self.threshold_rate * 0.4:
            return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_101(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    - Cooperating in round 1 to establish cooperative baseline
    - Continuing cooperation when others reciprocate sufficiently
    - Punishing systematic defection to prevent race-to-bottom
    - Lowering expectations near game end to salvage mutual benefit
    - Scaling thresholds based on game parameters
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.punishment_mode = False
        self.punishment_rounds_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        last_round_idx = current_round - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[last_round_idx, :]))
        if history.my_actions[last_round_idx]:
            cooperators_last_round += 1
        cooperation_rate = cooperators_last_round / self.n
        if self.punishment_mode:
            self.punishment_rounds_remaining -= 1
            if self.punishment_rounds_remaining <= 0:
                self.punishment_mode = False
            else:
                return Action.D
        min_viable_rate = self.m / self.n
        if cooperation_rate < 0.5 * min_viable_rate:
            self.punishment_mode = True
            self.punishment_rounds_remaining = 1
            return Action.D
        threshold = self._calculate_threshold(current_round)
        if current_round == self.r - 1:
            threshold = max(threshold - 0.2, min_viable_rate - 0.1)
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_threshold(self, current_round: int) -> float:
        """
        Calculate adaptive threshold for cooperation decision.
        
        threshold = m/n + decay_factor * (1 - t/r)
        
        Adjusted for low m/n and high m/n scenarios.
        """
        min_viable_rate = self.m / self.n
        decay_factor = 0.3
        progress_term = 1.0 - current_round / self.r
        threshold = min_viable_rate + decay_factor * progress_term
        if min_viable_rate < 0.4:
            threshold = min_viable_rate + 0.15 + decay_factor * progress_term
        elif min_viable_rate > 0.6:
            threshold = min_viable_rate - 0.1 + decay_factor * progress_term
        threshold = max(0.0, min(1.0, threshold))
        return threshold

class Strategy_COLLECTIVE_102(BaseStrategy):
    """
    Adaptive Collective Threshold Strategy (ACTS)
    
    Implements conditional cooperation based on probabilistic threshold assessment.
    Cooperates when P(â‰¥m cooperators) > 1/(1+k) + safety_margin, otherwise defects.
    Uses weighted recent history with drift detection and edge case handling.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.safety_margin = 0.05
        self.drift_threshold = 1.0 / (1.0 + self.k)
        self.recent_window = 3
        self.drift_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        coop_rate = self._calculate_cooperation_rate(history, state.round_number)
        coop_rate_threshold = self.drift_threshold
        if coop_rate < coop_rate_threshold:
            self.drift_counter += 1
        else:
            self.drift_counter = 0
        if self.drift_counter >= 2:
            return Action.D
        threshold_prob = self._calculate_threshold_probability(coop_rate)
        breakeven = self.drift_threshold + self.safety_margin
        if threshold_prob > breakeven:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_number: int) -> float:
        """
        Calculate recent cooperation rate with weighted recency bias.
        Uses last 3 rounds (or all available if fewer), weighted 2x for recent rounds.
        """
        if round_number <= 0:
            return 0.5
        start_idx = max(0, round_number - self.recent_window)
        end_idx = round_number
        total_cooperators = 0.0
        total_weight = 0.0
        for round_idx in range(start_idx, end_idx):
            if round_idx == end_idx - 1:
                weight = 2.0
            else:
                weight = 1.0
            cooperators_this_round = float(np.sum(history.opponent_actions[round_idx, :]))
            total_cooperators += cooperators_this_round * weight
            total_weight += weight * self.n
        if total_weight == 0:
            return 0.5
        coop_rate = total_cooperators / total_weight
        return coop_rate

    def _calculate_threshold_probability(self, coop_rate: float) -> float:
        """
        Estimate P(â‰¥m cooperators this round) using binomial approximation.
        Uses 1 - CDF(m-1) to get P(X â‰¥ m).
        """
        if coop_rate <= 0:
            return 0.0
        if coop_rate >= 1.0:
            return 1.0
        cdf_value = self._binomial_cdf(self.m - 1, self.n, coop_rate)
        threshold_prob = 1.0 - cdf_value
        return threshold_prob

    def _binomial_cdf(self, k: int, n: int, p: float) -> float:
        """
        Compute binomial CDF: P(X â‰¤ k) where X ~ Binomial(n, p).
        Uses cumulative sum of binomial PMF.
        """
        if k < 0:
            return 0.0
        if k >= n:
            return 1.0
        cdf = 0.0
        for i in range(k + 1):
            cdf += self._binomial_pmf(i, n, p)
        return cdf

    def _binomial_pmf(self, k: int, n: int, p: float) -> float:
        """
        Compute binomial PMF: P(X = k) where X ~ Binomial(n, p).
        Uses logarithms to avoid overflow.
        """
        if k < 0 or k > n or p < 0 or (p > 1):
            return 0.0
        if p == 0:
            return 1.0 if k == 0 else 0.0
        if p == 1:
            return 1.0 if k == n else 0.0
        log_binom_coeff = self._log_factorial(n) - self._log_factorial(k) - self._log_factorial(n - k)
        log_pmf = log_binom_coeff + k * math.log(p) + (n - k) * math.log(1 - p)
        return math.exp(log_pmf)

    def _log_factorial(self, n: int) -> float:
        """
        Compute log(n!) using Stirling's approximation or sum.
        """
        if n <= 0:
            return 0.0
        if n <= 1:
            return 0.0
        if n <= 20:
            result = 0.0
            for i in range(1, n + 1):
                result += math.log(float(i))
            return result
        else:
            return n * math.log(n) - n + 0.5 * math.log(2 * math.pi * n)

class Strategy_COLLECTIVE_103(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATC)
    
    Balances individual risk management with collective payoff optimization using dynamic
    cooperation thresholds that adapt to observed behavior patterns. Cooperates in round 1
    to establish a baseline, then makes threshold-dependent decisions in subsequent rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        round_idx = state.round_number - 1
        cooperators_last_round = int(sum(history.opponent_actions[round_idx, :]))
        obs_rate = cooperators_last_round / self.n
        threshold = self.m / self.n
        margin = 1.0 / self.n
        if obs_rate >= threshold:
            return Action.C
        elif math.fabs(obs_rate - (threshold - margin)) < 1e-09:
            p_marginal = (self.k - 1.0) / self.k
            if random.random() < p_marginal:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_104(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual risk management with collective welfare by:
    1. Cooperating in round 1 to signal willingness
    2. Adapting cooperation based on observed cooperation rates (rounds 2 to r-1)
    3. Making final decision based on previous round's success (round r)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == r - 1:
            cooperators_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
            if history.my_actions[current_round - 1]:
                cooperators_last_round += 1
            if cooperators_last_round >= m:
                return Action.C
            else:
                return Action.D
        total_cooperators = 0
        total_cooperators += int(sum(history.my_actions[:current_round]))
        total_cooperators += int(np.sum(history.opponent_actions[:current_round, :]))
        total_instances = current_round * n
        if total_instances == 0:
            return Action.C
        cooperation_rate = total_cooperators / total_instances
        required_cooperation_rate = m / n
        if cooperation_rate >= 0.85 * required_cooperation_rate:
            return Action.C
        if cooperation_rate >= 0.5 * required_cooperation_rate:
            probability = cooperation_rate / required_cooperation_rate if required_cooperation_rate > 0 else 0
            if random.random() < probability:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_105(BaseStrategy):
    """
    Adaptive Threshold Matching Strategy for Collective Risk Dilemma.
    
    Balances conditional cooperation, adaptive risk assessment, and robust defection recovery.
    Cooperates in round 1, then monitors cooperation rate against threshold (m/n).
    Maintains cooperation if threshold is met or nearly met (deficit â‰¤ 25% of n),
    otherwise defects to preserve endowment.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.threshold_rate = self.m / self.n_players
        self.tolerance = math.ceil(0.25 * self.n_players)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round_idx = state.round_number - 1
        opponent_cooperators = np.sum(history.opponent_actions[prev_round_idx, :])
        my_prev_action = history.my_actions[prev_round_idx]
        my_prev_cooperation = 1 if my_prev_action else 0
        total_cooperators = opponent_cooperators + my_prev_cooperation
        cooperation_rate = total_cooperators / self.n_players
        if cooperation_rate >= self.threshold_rate:
            return Action.C
        deficit = self.m - total_cooperators
        if deficit <= self.tolerance:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_106(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances conditional cooperation with pragmatic defection by tracking
    cooperation rates and adapting decisions based on estimated likelihood
    of reaching the threshold m. Uses critical thresholds and stochastic
    defection in uncertain regimes.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.defection_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == self.r - 1:
            return Action.D
        if round_num == 0:
            return Action.C
        if self.n == self.m:
            return Action.C
        if self.n == self.m + 1:
            if round_num > 0:
                other_cooperators = sum(history.opponent_actions[-1, :])
                if other_cooperators == 0:
                    return Action.D
            return Action.C
        previous_cooperators = sum(history.opponent_actions[-1, :])
        cooperation_rate = previous_cooperators / (self.n - 1)
        critical_threshold = self.m / self.n * 1.15
        low_threshold = max(0.0, (self.m - 2) / self.n)
        if cooperation_rate < low_threshold:
            self.defection_streak += 1
            if self.defection_streak >= 2:
                return Action.D
        else:
            self.defection_streak = 0
        if round_num > 1:
            prev_round_cooperators = sum(history.opponent_actions[-2, :])
            prev_cooperation_rate = prev_round_cooperators / (self.n - 1)
            surge = cooperation_rate - prev_cooperation_rate
            if surge > 0.4:
                critical_threshold = critical_threshold * 1.1
        if cooperation_rate >= critical_threshold:
            return Action.C
        if cooperation_rate <= low_threshold:
            return Action.D
        if critical_threshold <= low_threshold:
            stochastic_prob = 0.5
        else:
            stochastic_prob = (cooperation_rate - low_threshold) / (critical_threshold - low_threshold)
        if random.random() < stochastic_prob:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_107(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Cooperates conditionally based on whether the collective is likely to meet
    the cooperation threshold (m players). Uses observed cooperation rates to
    signal collective willingness, with special handling for first and final rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            m_relative = self.m / self.n
            if m_relative <= 0.5:
                return Action.C
            else:
                return Action.D
        elif round_number == self.r - 1:
            last_round_cooperators = int(np.sum(self.game_description.n_players - 1 - np.sum(~history.opponent_actions[round_number - 1, :])))
            last_round_cooperators = int(np.sum(history.opponent_actions[round_number - 1, :]))
            if history.my_actions[round_number - 1]:
                last_round_cooperators += 1
            if last_round_cooperators >= self.m:
                return Action.C
            else:
                return Action.D
        else:
            opponent_cooperators = int(np.sum(history.opponent_actions[round_number - 1, :]))
            if history.my_actions[round_number - 1]:
                total_cooperators = opponent_cooperators + 1
            else:
                total_cooperators = opponent_cooperators
            cooperation_rate = total_cooperators / self.n
            threshold_rate = (self.m - 0.5) / self.n
            if cooperation_rate >= threshold_rate:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_108(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances individual security with collective benefit by:
    1. Cooperating in round 1 to test the environment
    2. Adapting middle-game decisions based on observed cooperation rates
    3. Defecting in final round unless prior cooperation succeeded
    4. Using threshold-based reciprocity rather than tit-for-tat
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.n_rounds - 1:
            cooperators_prev = self._count_cooperators(history, round_number - 1)
            if cooperators_prev >= self.m:
                return Action.C
            else:
                return Action.D
        cooperators_prev = self._count_cooperators(history, round_number - 1)
        if cooperators_prev >= self.m:
            return Action.C
        likely_new_cooperators = cooperators_prev + math.floor(cooperators_prev * 0.5)
        if likely_new_cooperators >= self.m:
            return Action.C
        else:
            return Action.D

    def _count_cooperators(self, history: PlayerHistory, round_index: int) -> int:
        """
        Count how many opponents cooperated in the given round.
        Round indices are 0-based.
        True/1 represents cooperation (Action.C).
        """
        if round_index < 0 or round_index >= len(history.opponent_actions):
            return 0
        cooperators = int(np.sum(history.opponent_actions[round_index, :]))
        return cooperators

class Strategy_COLLECTIVE_109(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Cooperating in round 1 to bootstrap collective action
    2. Cooperating when threshold is met (k > 1 makes it rational)
    3. Adapting probabilistically based on observed cooperation levels
    4. Defecting strategically when time/cooperation levels make it unjustified
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        prev_cooperators_opponents = sum(history.opponent_actions[prev_round_idx, :])
        prev_cooperators_total = prev_cooperators_opponents + (1 if history.my_actions[prev_round_idx] else 0)
        rounds_remaining = self.n_rounds - current_round
        gap_to_threshold = self.m - prev_cooperators_total
        if prev_cooperators_total >= self.m:
            return Action.C
        if gap_to_threshold <= 2 and rounds_remaining >= 3:
            return Action.C
        if prev_cooperators_total >= self.m - 1 and rounds_remaining == 2:
            return Action.C
        if prev_cooperators_total < self.m - 1 and rounds_remaining >= 3:
            coop_probability = min(0.6, 0.3 + 0.1 * prev_cooperators_opponents)
            return Action.C if random.random() < coop_probability else Action.D
        if prev_cooperators_total < self.m - 1 and rounds_remaining <= 2:
            return Action.D
        if current_round == self.n_rounds - 1:
            if prev_cooperators_total >= self.m:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_110(BaseStrategy):
    """
    Adaptive Threshold Confidence (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by adapting cooperation
    decisions based on historical cooperation rates, round position, and threshold proximity.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        m = self.game_description.m
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if history is not None and len(history.opponent_actions) > 0:
            previous_round_idx = current_round - 1
            cooperators_previous = np.sum(history.opponent_actions[previous_round_idx, :])
            observed_cooperation_rate = cooperators_previous / n
        else:
            observed_cooperation_rate = 0.0
        threshold_ratio = m / n
        rounds_remaining = r - current_round
        if current_round == r - 1:
            if observed_cooperation_rate >= threshold_ratio - 0.05:
                return Action.C
            else:
                return Action.D
        elif observed_cooperation_rate >= threshold_ratio - 0.1:
            return Action.C
        elif observed_cooperation_rate >= threshold_ratio * 0.5:
            if rounds_remaining >= 3:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_111(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Dynamically adjusts cooperation based on observed cooperation rates, game phase,
    threshold proximity, and defection trends. Treats cooperation as a conditional
    public good, cooperating when expected payoff from reaching threshold m exceeds
    the cost of cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return self._bootstrap_decision()
        if round_num < self.r - 1:
            return self._adaptive_decision(round_num, history)
        return self._final_round_decision(round_num, history)

    def _bootstrap_decision(self) -> Action:
        """Round 1 decision: Based on group size and threshold ratio."""
        if self.n <= 4:
            return Action.C
        threshold_ratio = self.m / self.n
        if threshold_ratio <= 0.4:
            return Action.C
        return Action.D

    def _adaptive_decision(self, round_num: int, history: PlayerHistory) -> Action:
        """Rounds 2 to r-1: Adaptive decision based on history analysis."""
        phase = self._get_phase(round_num)
        cooperation_rate = self._calculate_cooperation_rate(history, round_num)
        defection_trend = self._calculate_defection_trend(history, round_num)
        threshold_feasibility = self._assess_threshold_feasibility(cooperation_rate)
        if round_num == 1 and cooperation_rate < 0.2:
            return Action.D
        if round_num > 1 and self._was_cooperation_low_earlier(history, round_num) and (cooperation_rate > 0.6):
            return Action.C
        if self.m / self.n < 0.3:
            return Action.C
        if threshold_feasibility == 'VIABLE':
            return Action.C
        elif threshold_feasibility == 'RISKY':
            if defection_trend == 'declining':
                return Action.C
            elif cooperation_rate > 0.5:
                return Action.C
            else:
                return Action.D
        elif phase == 'EARLY' and cooperation_rate > 0.6:
            return Action.C
        else:
            return Action.D

    def _final_round_decision(self, round_num: int, history: PlayerHistory) -> Action:
        """Final round: Secure reward if threshold has been achieved."""
        if self._was_threshold_met(history, round_num):
            return Action.C
        current_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        if current_cooperators == self.m - 1:
            return Action.C
        return Action.D

    def _get_phase(self, round_num: int) -> str:
        """Identify game phase: EARLY, MIDDLE, or LATE."""
        early_end = math.floor(self.r / 3)
        middle_end = math.floor(2 * self.r / 3)
        if round_num < early_end:
            return 'EARLY'
        elif round_num < middle_end:
            return 'MIDDLE'
        else:
            return 'LATE'

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """Calculate observed cooperation rate across all players in previous rounds."""
        if round_num <= 0:
            return 0.0
        cooperators_past = int(np.sum(history.opponent_actions[:round_num, :]))
        total_actions = self.n * round_num
        if total_actions == 0:
            return 0.0
        return cooperators_past / total_actions

    def _calculate_defection_trend(self, history: PlayerHistory, round_num: int) -> str:
        """Determine defection trend: accelerating, stable, or declining."""
        if round_num < 2:
            return 'stable'
        lookback = min(3, round_num)
        recent_rounds = history.opponent_actions[max(0, round_num - lookback):round_num, :]
        defection_counts = []
        for i in range(recent_rounds.shape[0]):
            defections = self.n - int(np.sum(recent_rounds[i, :]))
            defection_counts.append(defections)
        if len(defection_counts) < 2:
            return 'stable'
        if defection_counts[-1] > defection_counts[0]:
            return 'accelerating'
        elif defection_counts[-1] < defection_counts[0]:
            return 'declining'
        else:
            return 'stable'

    def _assess_threshold_feasibility(self, cooperation_rate: float) -> str:
        """Assess whether threshold m is VIABLE, RISKY, or UNLIKELY."""
        expected_cooperators = cooperation_rate * self.n
        if expected_cooperators >= self.m - 1:
            return 'VIABLE'
        elif expected_cooperators >= math.ceil(self.m / 2):
            return 'RISKY'
        else:
            return 'UNLIKELY'

    def _was_threshold_met(self, history: PlayerHistory, round_num: int) -> bool:
        """Check if threshold m was met in any previous round."""
        for past_round in range(round_num):
            cooperators = int(np.sum(history.opponent_actions[past_round, :]))
            if cooperators >= self.m:
                return True
        return False

    def _was_cooperation_low_earlier(self, history: PlayerHistory, round_num: int) -> bool:
        """Check if cooperation was low in earlier rounds."""
        if round_num < 2:
            return False
        early_rounds = history.opponent_actions[:max(1, round_num - 2), :]
        early_cooperation = np.mean(early_rounds)
        return early_cooperation < 0.3

class Strategy_COLLECTIVE_112(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Seeking collective success through threshold achievement
    2. Protecting against exploitation when others defect
    3. Adapting to observed behavior to coordinate with genuine cooperators
    4. Maintaining credible commitment to collective goals
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_idx = round_num - 1
        opponent_actions_prev = history.opponent_actions[prev_round_idx, :]
        cooperators_prev = int(np.sum(opponent_actions_prev))
        c_rate = cooperators_prev / (self.n - 1) if self.n > 1 else 0.0
        tv = (self.m - 1) / (self.n - 1) if self.n > 1 else 0.0
        er_intensity = self._calculate_exploitation_risk(history, round_num)
        if round_num == self.r - 1:
            return self._decide_final_round(c_rate, tv, er_intensity)
        return self._decide_adaptive_phase(c_rate, tv, er_intensity, round_num)

    def _calculate_exploitation_risk(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate exploitation risk intensity.
        ER_intensity = (count of defectors who gained k) / n
        """
        if current_round == 0:
            return 0.0
        prev_round_idx = current_round - 1
        opponent_actions_prev = history.opponent_actions[prev_round_idx, :]
        cooperators_prev = int(np.sum(opponent_actions_prev))
        threshold_met = cooperators_prev >= self.m
        if not threshold_met:
            return 0.0
        defectors_with_k = 0
        for i in range(self.n - 1):
            if not opponent_actions_prev[i]:
                defectors_with_k += 1
        er_intensity = defectors_with_k / self.n if self.n > 0 else 0.0
        return er_intensity

    def _decide_adaptive_phase(self, c_rate: float, tv: float, er_intensity: float, round_num: int) -> Action:
        """
        Decision logic for rounds 1 to r-2.
        """
        if c_rate >= tv + 0.15:
            return Action.C
        if c_rate >= tv and er_intensity < 0.3:
            return Action.C
        if c_rate >= tv and er_intensity >= 0.3:
            return Action.D
        if c_rate < tv and round_num <= self.r / 2:
            return Action.C
        if c_rate < tv and round_num > self.r / 2:
            return Action.D
        return Action.C

    def _decide_final_round(self, c_rate: float, tv: float, er_intensity: float) -> Action:
        """
        Decision logic for the final round r-1.
        Slightly relaxed thresholds since no future rounds.
        """
        if c_rate >= tv + 0.1:
            return Action.C
        if c_rate < tv:
            return Action.D
        if er_intensity >= 0.4:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_113(BaseStrategy):
    """
    Graduated Reciprocal Escalation with Collective Threshold (GRECT)
    
    Adaptive strategy for Collective Risk Dilemma that:
    1. Gathers information in estimation phase
    2. Escalates cooperation toward threshold in middle game
    3. Commits to threshold achievement in endgame
    4. Optimizes final round based on threshold viability
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.estimation_end = max(1, math.ceil(self.r / 3))
        self.amplification_end = max(self.estimation_end + 1, math.ceil(2 * self.r / 3))
        self.commitment_end = max(self.amplification_end + 1, self.r - 1)

    def _determine_phase(self, round_number: int) -> str:
        """Determine which phase we're in based on round number (0-indexed)."""
        if round_number < self.estimation_end:
            return 'ESTIMATION'
        elif round_number < self.amplification_end:
            return 'AMPLIFICATION'
        elif round_number < self.commitment_end:
            return 'COMMITMENT'
        else:
            return 'FINAL'

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_number: int) -> float:
        """Calculate mean cooperation rate of opponents up to current round."""
        if round_number == 0:
            return 0.0
        total_coops = np.sum(history.opponent_actions[:round_number, :])
        total_observations = round_number * (self.n - 1)
        if total_observations == 0:
            return 0.0
        return total_coops / total_observations

    def _count_cooperators_last_round(self, history: PlayerHistory) -> int:
        """Count how many opponents cooperated in the most recent round."""
        if history is None or len(history.opponent_actions) == 0:
            return 0
        return int(np.sum(history.opponent_actions[-1, :]))

    def _decide_estimation_phase(self, coop_rate: float) -> Action:
        """Decision logic for estimation phase (rounds 1 to âŒˆr/3âŒ‰)."""
        threshold = (self.m - 1) / (self.n - 1) - 0.15
        if coop_rate >= threshold:
            return Action.C
        return Action.D

    def _decide_amplification_phase(self, last_round_coops: int, coop_rate: float) -> Action:
        """Decision logic for threshold amplification phase."""
        if last_round_coops >= self.m:
            return Action.C
        if last_round_coops >= self.m - 2:
            return Action.C
        threshold = (self.m - 1) / (self.n - 1) - 0.1
        if coop_rate >= threshold:
            return Action.C
        return Action.D

    def _decide_commitment_phase(self, last_round_coops: int, coop_rate: float) -> Action:
        """Decision logic for commitment phase."""
        if last_round_coops >= self.m - 1:
            return Action.C
        threshold = self.m / self.n - 0.1
        if coop_rate >= threshold:
            return Action.C
        return Action.D

    def _decide_final_phase(self, last_round_coops: int) -> Action:
        """Decision logic for final round."""
        if last_round_coops >= self.m - 1:
            return Action.C
        return Action.D

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        last_round_coops = self._count_cooperators_last_round(history)
        coop_rate = self._calculate_cooperation_rate(history, round_number)
        phase = self._determine_phase(round_number)
        if phase == 'ESTIMATION':
            return self._decide_estimation_phase(coop_rate)
        elif phase == 'AMPLIFICATION':
            return self._decide_amplification_phase(last_round_coops, coop_rate)
        elif phase == 'COMMITMENT':
            return self._decide_commitment_phase(last_round_coops, coop_rate)
        else:
            return self._decide_final_phase(last_round_coops)

class Strategy_COLLECTIVE_114(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances individual risk management with collective welfare through dynamic
    conditional cooperation. Cooperates when observed cooperation likelihood meets
    or exceeds a safety margin (threshold + 15% buffer, minimum 50%), otherwise defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.buffer = 0.15
        self.min_threshold = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round_idx = state.round_number - 1
        cooperators_prev_round = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        cooperation_likelihood = cooperators_prev_round / self.n_players
        threshold_probability = self.m / self.n_players
        safety_margin = max(threshold_probability + self.buffer, self.min_threshold)
        if cooperation_likelihood >= safety_margin:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_115(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual security with collective welfare by dynamically adjusting
    cooperation based on threshold feasibility, observable cooperation trends, and
    temporal dynamics across rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        cooperators_prev = int(np.sum(history.opponent_actions[round_num - 1, :]))
        coop_likelihood = cooperators_prev / (self.n - 1) if self.n > 1 else 0.0
        if round_num == self.r - 1:
            if cooperators_prev >= self.m - 1:
                return Action.C
            else:
                return Action.D
        threshold_prob = self.m / self.n
        threshold_for_success = (self.m - 1) / (self.n - 1) if self.n > 1 else 0.0
        if coop_likelihood >= threshold_for_success:
            return Action.C
        if coop_likelihood >= threshold_prob * 0.75:
            return Action.C
        if coop_likelihood < threshold_prob * 0.5:
            return Action.D
        rounds_remaining = self.r - round_num
        if rounds_remaining > 1:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_116(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Dynamically adjusts cooperation based on:
    1. Collective progress toward the threshold
    2. Historical reliability and success rates
    3. Temporal dynamics and remaining rounds
    
    Core insight: Defection is rational only when collective failure is certain.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.early_phase_end = max(1, math.floor(self.r / 3))
        self.mid_phase_end = max(2, math.floor(2 * self.r / 3))
        self.last_defection_wave_round = -10

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_cooperators = int(np.sum(history.opponent_actions[round_num - 1, :]))
        if history.my_actions[round_num - 1]:
            prev_cooperators += 1
        if round_num >= 2:
            prev_prev_cooperators = int(np.sum(history.opponent_actions[round_num - 2, :]))
            if history.my_actions[round_num - 2]:
                prev_prev_cooperators += 1
            if prev_prev_cooperators > 0:
                coop_drop = prev_prev_cooperators - prev_cooperators
                if coop_drop > 0.3 * self.n:
                    self.last_defection_wave_round = round_num - 1
        if round_num - self.last_defection_wave_round <= 2:
            return Action.D
        if round_num <= self.early_phase_end:
            return self._early_game_decision(round_num, prev_cooperators, history)
        elif round_num <= self.mid_phase_end:
            return self._mid_game_decision(round_num, prev_cooperators, history)
        else:
            return self._end_game_decision(round_num, prev_cooperators, history)

    def _early_game_decision(self, round_num: int, prev_cooperators: int, history: PlayerHistory) -> Action:
        """Phase 1: Early game (rounds 1 to r/3)"""
        coop_rate = prev_cooperators / self.n
        threshold_ratio = self.m / self.n
        if coop_rate >= threshold_ratio * 0.8:
            return Action.C
        if coop_rate < threshold_ratio * 0.5:
            return Action.D
        gap = self.m - prev_cooperators
        if gap <= 2 and gap > 0:
            return Action.C
        elif gap <= 0:
            return Action.C
        else:
            return Action.D

    def _mid_game_decision(self, round_num: int, prev_cooperators: int, history: PlayerHistory) -> Action:
        """Phase 2: Mid game (rounds r/3+1 to 2r/3)"""
        success_count = 0
        for r_idx in range(round_num):
            round_cooperators = int(np.sum(history.opponent_actions[r_idx, :]))
            if history.my_actions[r_idx]:
                round_cooperators += 1
            if round_cooperators >= self.m:
                success_count += 1
        success_rate = success_count / round_num if round_num > 0 else 0.0
        if success_rate >= 0.6:
            return Action.C
        if success_rate <= 0.2:
            return Action.D
        remaining_rounds = self.r - round_num
        if remaining_rounds > self.r / 3:
            gap = self.m - prev_cooperators
            if gap <= 1 and gap > 0:
                return Action.C
            elif gap <= 0:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _end_game_decision(self, round_num: int, prev_cooperators: int, history: PlayerHistory) -> Action:
        """Phase 3: End game (rounds 2r/3+1 to r)"""
        if round_num == self.r - 1:
            if prev_cooperators >= self.m:
                return Action.C
            else:
                return Action.D
        success_count = 0
        for r_idx in range(round_num):
            round_cooperators = int(np.sum(history.opponent_actions[r_idx, :]))
            if history.my_actions[r_idx]:
                round_cooperators += 1
            if round_cooperators >= self.m:
                success_count += 1
        success_rate = success_count / round_num if round_num > 0 else 0.0
        if success_rate >= 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_117(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Cooperating in round 1 to establish norms
    2. Conditionally cooperating based on observed cooperation levels
    3. Adapting decisions based on remaining rounds and threshold proximity
    4. Defecting only when threshold appears unreachable or in final round with unmet threshold
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        if t == 0:
            return Action.C
        prev_cooperators = int(sum(history.opponent_actions[t - 1, :]))
        if history.my_actions[t - 1]:
            prev_cooperators += 1
        rounds_remaining = self.r - t - 1
        if prev_cooperators >= self.m:
            return Action.C
        if rounds_remaining == 0:
            return Action.D
        threshold_gap = self.m - prev_cooperators
        if prev_cooperators == self.m - 1:
            return Action.C
        critical_ratio = prev_cooperators / self.m if self.m > 0 else 0
        decay_factor = rounds_remaining / self.r if self.r > 0 else 0
        if critical_ratio >= 0.5 and decay_factor > 0.3:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_118(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATC) for Collective Risk Dilemma.
    
    Dynamically adjusts cooperation based on observable defection rates and round position,
    balancing individual rationality with collective welfare by targeting the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.consecutive_exploitation_rounds = 0
        self.pure_defection_mode = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            coop_benefit = (self.k - 1) * (self.m / self.n)
            if coop_benefit > 1:
                return Action.C
            else:
                return Action.D
        rounds_completed = round_num
        total_coop_observed = int(np.sum(history.opponent_actions[:round_num, :]))
        observed_coop_rate = total_coop_observed / (self.n * rounds_completed) if rounds_completed > 0 else 0
        target_rate = self.m / self.n
        defection_rate = 1.0 - observed_coop_rate
        exploitation_threshold = (self.n - self.m) / self.n + 0.15
        if defection_rate > 1.0 - self.m / self.n + 0.2:
            self.pure_defection_mode = True
        if self.pure_defection_mode:
            return Action.D
        if round_num >= 2:
            exploitation_detected = self._check_exploitation(history, round_num)
            if exploitation_detected:
                self.consecutive_exploitation_rounds += 1
                if self.consecutive_exploitation_rounds >= 3:
                    return Action.D
            else:
                self.consecutive_exploitation_rounds = 0
        if defection_rate > exploitation_threshold:
            return Action.D
        if round_num == self.r - 1:
            others_coop_last_round = int(np.sum(history.opponent_actions[round_num - 1, :]))
            if others_coop_last_round >= self.m - 1:
                return Action.C
            else:
                return Action.D
        halfway = math.ceil(self.r / 2)
        if round_num < halfway:
            return Action.C
        others_coop_last_round = int(np.sum(history.opponent_actions[round_num - 1, :]))
        if others_coop_last_round >= self.m - 1:
            return Action.C
        if observed_coop_rate < target_rate:
            return Action.C
        return Action.D

    def _check_exploitation(self, history: PlayerHistory, round_num: int) -> bool:
        """
        Check if this player cooperated but fewer than (m-1) others cooperated
        in the most recent round.
        """
        if round_num < 1:
            return False
        my_last_action = history.my_actions[round_num - 1]
        others_coop_last_round = int(np.sum(history.opponent_actions[round_num - 1, :]))
        if my_last_action and others_coop_last_round < self.m - 1:
            return True
        return False

class Strategy_COLLECTIVE_119(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    This strategy dynamically adjusts cooperation likelihood based on empirical evidence
    of collective commitment. It recognizes that individual payoff maximization is achievable
    only when the threshold is met, and adapts cooperation probability based on observed
    cooperation rates in previous rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            total_cooperators = prev_round_cooperators + 1
        else:
            total_cooperators = prev_round_cooperators
        observed_rate = total_cooperators / self.n
        threshold_rate = self.m / self.n
        if observed_rate >= threshold_rate:
            return Action.C
        elif observed_rate >= threshold_rate - 1.0 / self.n:
            safe_observed_rate = max(observed_rate, 1.0 / self.n)
            prob = threshold_rate / safe_observed_rate
            prob = min(prob, 1.0)
            if random.random() < prob:
                return Action.C
            else:
                return Action.D
        else:
            prob = threshold_rate / self.n
            prob = min(prob, 1.0)
            if random.random() < prob:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_120(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances collective welfare, robustness, and adaptability by:
    - Cooperating in round 1 to signal intent and gather information
    - In middle rounds, cooperating if historical cooperation rate suggests threshold m is likely
    - In final round, cooperating if threshold is achievable, defecting only when impossible
    - Detecting defection spirals and withdrawing cooperation to minimize losses
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.n_rounds - 1:
            cooperators_last_round = int(sum(history.opponent_actions[-1, :]))
            if cooperators_last_round >= self.m - 1:
                return Action.C
            else:
                return Action.D
        return self._decide_middle_round(round_number, history)

    def _decide_middle_round(self, round_number: int, history: PlayerHistory) -> Action:
        """
        Decide action in middle rounds based on historical cooperation rate.
        """
        total_cooperators = 0
        total_decisions = 0
        for i in range(round_number):
            total_cooperators += int(sum(history.opponent_actions[i, :]))
            total_cooperators += int(history.my_actions[i])
            total_decisions += self.n_players
        if total_decisions == 0:
            hcr = 0.0
        else:
            hcr = total_cooperators / total_decisions
        epsilon = min(0.15, (self.k - 1) / (2 * self.n_players))
        threshold_target = self.m / self.n_players + epsilon
        if self.m > 0.8 * self.n_players:
            threshold_target += 0.1
        if round_number >= 2:
            prev_total_cooperators = 0
            prev_total_decisions = 0
            for i in range(round_number - 1):
                prev_total_cooperators += int(sum(history.opponent_actions[i, :]))
                prev_total_cooperators += int(history.my_actions[i])
                prev_total_decisions += self.n_players
            if prev_total_decisions > 0:
                prev_hcr = prev_total_cooperators / prev_total_decisions
            else:
                prev_hcr = 0.0
            if hcr < 0.3 and prev_hcr > 0 and (hcr < prev_hcr - 0.25):
                return Action.D
        if self.m == 2 and self.n_players > 2:
            if round_number >= 2 and hcr < 0.3:
                return Action.D
        if hcr >= threshold_target:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_121(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances collective welfare, self-protection, and robust exploration by:
    1. Cooperating in round 1 to signal willingness
    2. Adapting cooperation based on whether threshold m is met or near
    3. Using probability-weighted cooperation when near-threshold
    4. Defecting in final round (or with reduced probability for long games)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        my_prev_action = history.my_actions[prev_round_idx]
        opponent_prev_actions = history.opponent_actions[prev_round_idx, :]
        c_prev = int(my_prev_action) + int(np.sum(opponent_prev_actions))
        cooperation_rate = c_prev / self.n
        threshold_rate = self.m / self.n
        if current_round == self.r - 1:
            if self.r > 20:
                if random.random() < 0.7:
                    return Action.D
                else:
                    return Action.C
            else:
                return Action.D
        if cooperation_rate >= threshold_rate:
            return Action.C
        if cooperation_rate >= threshold_rate - 1.0 / self.n:
            probability = (self.r - current_round) / self.r
            if random.random() < probability:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_122(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual security with collective benefit through:
    1. Probing cooperation feasibility in early rounds
    2. Adapting to observed cooperation levels
    3. Maintaining collective benefit when achievable
    4. Protecting against exploitation without punishing honest uncertainty
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            return Action.D
        coop_rate = self._get_cooperation_rate(history, current_round)
        threshold_target = self.m / self.n
        exploration_threshold = self._get_exploration_threshold(threshold_target)
        if current_round <= 2:
            if coop_rate >= exploration_threshold:
                return Action.C
            else:
                return Action.D
        if self._is_unanimous_defection(history, current_round):
            return Action.D
        if current_round < self.r - 1:
            if coop_rate >= threshold_target - 0.05:
                return Action.C
            elif coop_rate >= threshold_target * 0.6:
                remaining = self.r - current_round
                if remaining >= 3:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D
        if coop_rate >= threshold_target - 0.05:
            return Action.C
        else:
            return Action.D

    def _get_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """Calculate cooperation rate from the last round."""
        if current_round == 0:
            return 0.0
        last_round_idx = current_round - 1
        cooperators = int(np.sum(history.opponent_actions[last_round_idx, :]))
        if history.my_actions[last_round_idx]:
            cooperators += 1
        return cooperators / self.n

    def _get_exploration_threshold(self, threshold_target: float) -> float:
        """Adjust exploration threshold based on game parameters."""
        if self.n == self.m:
            return threshold_target * 0.85
        elif self.k > 2:
            return max(0.0, threshold_target - 0.05)
        else:
            return threshold_target * 0.9

    def _is_unanimous_defection(self, history: PlayerHistory, current_round: int) -> bool:
        """Check if all other players defected in the last round."""
        if current_round == 0:
            return False
        last_round_idx = current_round - 1
        return not np.any(history.opponent_actions[last_round_idx, :])

class Strategy_COLLECTIVE_123(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATC)
    
    Balances individual rationality with collective welfare by learning the cooperation
    landscape and dynamically adjusting based on observed cooperation rates. Cooperates
    in round 1 as a costly signal, then adapts based on whether the m-threshold appears
    achievable through observed cooperation rates and personal credibility streaks.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            self.cooperation_streak = 1
            return Action.C
        prev_round_idx = current_round - 1
        cooperators_prev_round = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        coop_rate = cooperators_prev_round / n
        baseline_threshold = m / n
        adjusted_threshold = max(baseline_threshold, 0.5)
        if current_round <= 2:
            min_others_needed = m - 1
            if cooperators_prev_round < min_others_needed:
                self.cooperation_streak = 0
                return Action.D
        if current_round == r - 1:
            if coop_rate >= adjusted_threshold:
                self.cooperation_streak += 1
                return Action.C
            else:
                self.cooperation_streak = 0
                return Action.D
        if coop_rate >= adjusted_threshold:
            self.cooperation_streak += 1
            return Action.C
        if cooperators_prev_round + 1 >= m:
            remaining_rounds = r - current_round
            if remaining_rounds <= 3 or self.cooperation_streak >= 2:
                self.cooperation_streak += 1
                return Action.C
        if m <= 2 and coop_rate >= 0.2:
            self.cooperation_streak += 1
            return Action.C
        if m == n:
            if cooperators_prev_round == n - 1:
                self.cooperation_streak += 1
                return Action.C
            else:
                self.cooperation_streak = 0
                return Action.D
        self.cooperation_streak = 0
        return Action.D

class Strategy_COLLECTIVE_124(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATC) for Collective Risk Dilemma.
    
    Balances individual rationality with collective benefit by dynamically adjusting
    cooperation based on observable success patterns. Recognizes that reaching the
    critical mass (m cooperators) is essential and structures decisions to maximize
    the probability of hitting this threshold while protecting against systematic defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_ratio = self.m / self.n_players
        self.consecutive_zero_coop_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.n_rounds - 1:
            return self._last_round_decision(history)
        return self._adaptive_phase_decision(history, round_number)

    def _last_round_decision(self, history: PlayerHistory) -> Action:
        """
        Last round logic: COOPERATE if threshold was met in previous round,
        else DEFECT (no future rounds to benefit from reciprocation).
        """
        prev_round_idx = len(history.my_actions) - 1
        self_coop = history.my_actions[prev_round_idx]
        opponent_coop = sum(history.opponent_actions[prev_round_idx, :])
        total_cooperators = (1 if self_coop else 0) + opponent_coop
        if total_cooperators >= self.m:
            return Action.C
        else:
            return Action.D

    def _adaptive_phase_decision(self, history: PlayerHistory, round_number: int) -> Action:
        """
        Rounds 1 to r-2: Apply adaptive decision rules based on observed cooperation rate.
        """
        prev_round_idx = len(history.my_actions) - 1
        opponent_coop_prev = sum(history.opponent_actions[prev_round_idx, :])
        self_coop_prev = history.my_actions[prev_round_idx]
        total_coop_prev = (1 if self_coop_prev else 0) + opponent_coop_prev
        coop_rate = total_coop_prev / self.n_players
        if coop_rate == 0:
            self.consecutive_zero_coop_rounds += 1
        else:
            self.consecutive_zero_coop_rounds = 0
        if self.consecutive_zero_coop_rounds >= 2:
            return Action.D
        if coop_rate >= self.threshold_ratio:
            return Action.C
        if coop_rate < self.threshold_ratio and self.threshold_ratio <= 0.5:
            return Action.C
        if round_number == 1:
            return Action.C
        if coop_rate < self.threshold_ratio and self.threshold_ratio > 0.5:
            return Action.D
        return Action.D

class Strategy_COLLECTIVE_125(BaseStrategy):
    """
    Adaptive Threshold Reciprocity (ATR) strategy for Collective Risk Dilemma.
    
    Balances individual risk management with collective benefit maximization by:
    1. Cooperating unconditionally in round 1 to establish cooperation baseline
    2. Adapting decisions in middle rounds based on observed cooperation rates and threshold proximity
    3. Cooperating unconditionally in final round to signal collective values
    4. Using probabilistic cooperation when near the threshold to maximize coordination chances
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        n = self.n_players
        m = self.m
        r = self.n_rounds
        if round_num == 0:
            return Action.C
        if round_num == r - 1:
            return Action.C
        prev_round_cooperators = int(np.sum(history.opponent_actions[round_num - 1, :]))
        if history.my_actions[round_num - 1]:
            prev_round_cooperators += 1
        cooperation_rate = prev_round_cooperators / n
        expected_cooperators = cooperation_rate * (n - 1)
        threshold_gap = expected_cooperators - (m - 1)
        if threshold_gap >= 0:
            return Action.C
        if threshold_gap >= -0.5:
            return Action.C
        if threshold_gap >= -1.5:
            probability = 0.5 + (threshold_gap + 1.5) / 3.0
            return Action.C if random.random() < probability else Action.D
        if threshold_gap >= -2.5:
            probability = (threshold_gap + 2.5) / 1.5
            return Action.C if random.random() < probability else Action.D
        return Action.D

class Strategy_COLLECTIVE_126(BaseStrategy):
    """
    Adaptive Threshold Reciprocity (ATR) Strategy for Collective Risk Dilemma.
    
    Operates in three phases:
    - Phase 1 (Early): Diagnostic cooperation with threshold-based calibration
    - Phase 2 (Middle): Informed reciprocity based on defector tracking
    - Phase 3 (Endgame): Exploit learned information, secure final outcome
    
    Core principle: Conditional cooperation calibrated to collective survival threshold,
    with adaptive sensitivity to free-riding patterns.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.early_phase_end = max(1, math.ceil(self.n_rounds / 3))
        self.middle_phase_end = max(self.early_phase_end + 1, math.floor(2 * self.n_rounds / 3))
        self.early_round_defectors = set()
        self.high_trust_players = set()
        self.player_cooperation_count = {}
        self.player_total_rounds = {}

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return self._round_one_decision()
        if current_round <= self.early_phase_end:
            return self._early_phase_decision(current_round, history)
        if current_round <= self.middle_phase_end:
            return self._middle_phase_decision(current_round, history)
        return self._endgame_phase_decision(current_round, history)

    def _round_one_decision(self) -> Action:
        """
        Round 1 decision rule based on threshold reasonableness.
        """
        m = self.m
        n = self.n_players
        if m == n:
            return Action.D
        if m <= math.ceil(n * 2 / 3):
            return Action.C
        if n - m >= 2:
            return Action.C
        return Action.C

    def _early_phase_decision(self, current_round: int, history: PlayerHistory) -> Action:
        """
        Early phase (rounds 1 to ceil(r/3)): diagnostic cooperation with observation.
        """
        total_opponent_cooperations = np.sum(history.opponent_actions[:current_round, :])
        total_possible = current_round * (self.n_players - 1)
        if total_possible == 0:
            cooperation_rate = 0.0
        else:
            cooperation_rate = total_opponent_cooperations / total_possible
        threshold_rate = self.m / self.n_players
        if current_round == self.early_phase_end:
            self._update_early_phase_memory(history, current_round)
        if cooperation_rate >= threshold_rate * 1.2:
            return Action.C
        elif cooperation_rate < threshold_rate * 0.8:
            return Action.D
        else:
            return Action.C

    def _update_early_phase_memory(self, history: PlayerHistory, current_round: int) -> None:
        """
        Update memory of repeat defectors and high-trust players at end of early phase.
        """
        for player_idx in range(self.n_players - 1):
            opponent_cooperations = np.sum(history.opponent_actions[:current_round, player_idx])
            opponent_defections = current_round - opponent_cooperations
            defection_rate = opponent_defections / current_round if current_round > 0 else 0.0
            cooperation_rate = opponent_cooperations / current_round if current_round > 0 else 0.0
            if defection_rate >= 0.5:
                self.early_round_defectors.add(player_idx)
            if cooperation_rate >= 0.8:
                self.high_trust_players.add(player_idx)

    def _middle_phase_decision(self, current_round: int, history: PlayerHistory) -> Action:
        """
        Middle phase: informed reciprocity with defector tracking.
        """
        repeat_defector_count = len(self.early_round_defectors)
        defector_threshold = math.ceil((self.n_players - 1) * 0.5)
        total_opponent_cooperations = np.sum(history.opponent_actions[:current_round, :])
        total_possible = current_round * (self.n_players - 1)
        cooperation_rate = total_opponent_cooperations / total_possible if total_possible > 0 else 0.0
        threshold_rate = self.m / self.n_players
        if repeat_defector_count >= defector_threshold:
            return Action.D
        if cooperation_rate >= threshold_rate:
            my_cooperations = np.sum(history.my_actions[:current_round])
            if my_cooperations >= math.ceil(self.m * 0.6):
                return Action.D
            else:
                return Action.C
        return Action.C

    def _endgame_phase_decision(self, current_round: int, history: PlayerHistory) -> Action:
        """
        Endgame phase: exploit information, secure outcome.
        """
        rounds_remaining = self.n_rounds - current_round
        if rounds_remaining <= 2:
            total_cooperations_so_far = np.sum(history.opponent_actions[:current_round, :]) + np.sum(history.my_actions[:current_round])
            rounds_so_far = current_round
            cumulative_cooperators = total_cooperations_so_far / (rounds_so_far * self.n_players) if rounds_so_far > 0 else 0.0
            if rounds_remaining == 1:
                if cumulative_cooperators >= self.m / self.n_players:
                    return Action.C
                else:
                    return Action.D
            elif cumulative_cooperators >= self.m / self.n_players:
                return Action.D
            else:
                return Action.C
        high_trust_count = len(self.high_trust_players)
        if high_trust_count >= self.m - 1:
            return Action.D
        my_cooperations = np.sum(history.my_actions[:current_round])
        required_cooperation = math.ceil(self.m * 0.6)
        if my_cooperations >= required_cooperation:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_127(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances individual risk management with collective benefit maximization by:
    - Testing cooperation viability early in small groups
    - Seeking evidence that threshold m is achievable
    - Building momentum when success is demonstrated
    - Transparently defecting only when mathematically futile
    - Unconditionally defecting in final round
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            if self.n <= 6:
                return Action.C
            elif self.n <= 10 and self.m / self.n <= 0.5:
                return Action.C
            else:
                return Action.D
        recent_coop_rate = self._get_recent_coop_rate(history)
        historical_coop_rate = self._get_historical_coop_rate(history)
        max_coop_last_3 = self._get_max_coop_last_3(history)
        bootstrap_phase_threshold = math.ceil(self.n / 2)
        late_game_threshold = math.ceil(0.75 * self.r)
        if round_t == self.r - 1:
            return Action.D
        if round_t <= bootstrap_phase_threshold:
            if recent_coop_rate >= self.m / self.n - 0.1:
                return Action.C
            else:
                return Action.D
        if round_t < late_game_threshold:
            if max_coop_last_3 >= self.m and self.r - round_t >= 2:
                return Action.C
            else:
                return Action.D
        if round_t < self.r - 1:
            if historical_coop_rate >= self.m / self.n:
                return Action.C
            elif recent_coop_rate >= (self.m - 1) / self.n:
                return Action.C
            else:
                return Action.D
        return Action.D

    def _get_recent_coop_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate in the most recent round."""
        if history.opponent_actions.shape[0] == 0:
            return 0.0
        recent_round_coop = int(sum(history.opponent_actions[-1, :]))
        return recent_round_coop / self.n

    def _get_historical_coop_rate(self, history: PlayerHistory) -> float:
        """Calculate average cooperation rate across all prior rounds."""
        if history.opponent_actions.shape[0] == 0:
            return 0.0
        total_coop = int(np.sum(history.opponent_actions))
        total_possible = history.opponent_actions.shape[0] * self.n
        if total_possible == 0:
            return 0.0
        return total_coop / total_possible

    def _get_max_coop_last_3(self, history: PlayerHistory) -> int:
        """Get maximum number of cooperators in any of the last 3 rounds."""
        if history.opponent_actions.shape[0] == 0:
            return 0
        start_idx = max(0, history.opponent_actions.shape[0] - 3)
        last_3_rounds = history.opponent_actions[start_idx:, :]
        max_coop = int(np.max(np.sum(last_3_rounds, axis=1)))
        return max_coop

class Strategy_COLLECTIVE_128(BaseStrategy):
    """
    Adaptive Threshold Monitoring strategy for Collective Risk Dilemma.
    
    Balances individual security with collective welfare through:
    - Monitoring whether threshold m is being met
    - Graduated commitment based on cooperation deficit
    - Exploitation resistance against consistent defectors
    - Temporal awareness adjusting behavior based on remaining rounds
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        cooperators_last = int(np.sum(history.opponent_actions[round_num - 1, :]))
        defectors_last = self.n - 1 - cooperators_last
        if history.my_actions[round_num - 1]:
            total_cooperators_last = cooperators_last + 1
        else:
            total_cooperators_last = cooperators_last
        defection_rate = defectors_last / (self.n - 1) if self.n > 1 else 0.0
        cooperation_deficit = max(0, self.m - total_cooperators_last)
        rounds_remaining = self.r - round_num
        if cooperation_deficit == 0:
            return Action.D
        if cooperation_deficit >= self.m or rounds_remaining == 1:
            return Action.C
        if cooperation_deficit > 0 and defection_rate > 0.5:
            return Action.C
        if rounds_remaining <= 3 and cooperation_deficit > 0:
            if defection_rate < 0.4:
                return Action.C
        if defection_rate > 0.99:
            return Action.D
        return Action.D

class Strategy_COLLECTIVE_129(BaseStrategy):
    """
    Adaptive Threshold Commitment Strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Starting cooperative to signal intent
    2. Maintaining cooperation when threshold is met
    3. Escalating commitment based on deficit urgency
    4. Selectively punishing free-riding while remaining exploitable
    5. Using reciprocity checks to support emerging cooperation trends
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        prev_round = current_round - 1
        cooperators_prev = int(np.sum(history.opponent_actions[prev_round, :]))
        if history.my_actions[prev_round]:
            cooperators_prev += 1
        rounds_remaining = self.n_rounds - current_round
        if cooperators_prev >= self.m:
            return Action.C
        else:
            deficit = self.m - cooperators_prev
            if rounds_remaining <= 0:
                urgency = 1.0
            else:
                urgency = deficit / rounds_remaining
            if urgency > 0.5:
                return Action.C
            elif urgency <= 0.5:
                my_prev_action = history.my_actions[prev_round]
                if my_prev_action and cooperators_prev <= self.m - 2:
                    return Action.D
                else:
                    return Action.C
            else:
                total_rounds_so_far = current_round
                cooperators_by_round = np.sum(history.opponent_actions[:total_rounds_so_far, :], axis=1)
                cooperators_by_round = cooperators_by_round + history.my_actions[:total_rounds_so_far].astype(int)
                avg_cooperation_count = np.mean(cooperators_by_round)
                avg_cooperation_rate = avg_cooperation_count / self.n_players
                if avg_cooperation_rate >= self.m / self.n_players:
                    return Action.C
                else:
                    return Action.D

class Strategy_COLLECTIVE_130(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances collective survival (ensuring threshold m is met) with individual robustness
    (protecting against free-riders). Uses adaptive cooperation based on observed cooperation
    rates in previous rounds, with special handling for early rounds, edge cases, and
    mathematical impossibility conditions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        last_round_opponent_actions = history.opponent_actions[round_number - 1, :]
        last_round_cooperators = np.sum(last_round_opponent_actions)
        if history.my_actions[round_number - 1]:
            total_cooperators_last_round = last_round_cooperators + 1
        else:
            total_cooperators_last_round = last_round_cooperators
        last_round_cooperation_rate = total_cooperators_last_round / self.n
        required_rate = self.m / self.n
        escape_valve_rate = (self.m - 1) / self.n
        if round_number <= 2 and last_round_cooperation_rate < required_rate:
            return Action.C
        if last_round_cooperators < self.m - 1:
            return Action.D
        if self.m == self.n and last_round_cooperation_rate < 1.0:
            return Action.D
        if self.m == 2 and self.n > 4:
            if last_round_cooperation_rate >= escape_valve_rate:
                return Action.C
        if last_round_cooperation_rate >= required_rate:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_131(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) for Collective Risk Dilemma.
    
    This strategy dynamically adjusts its cooperation threshold based on observed
    cooperation rates, environmental volatility, and temporal dynamics. It balances
    individual rationality with collective welfare through probabilistic contingent
    cooperation and graceful degradation when collective thresholds fail.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.base_threshold = game_description.m / game_description.n_players
        self.defections_observed = 0
        self.total_actions_observed = 0
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        m = self.game_description.m
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        cooperators_last_round = np.sum(history.opponent_actions[current_round - 1, :])
        observed_coop_rate = cooperators_last_round / n
        self.total_actions_observed += n
        defections_last_round = n - cooperators_last_round
        self.defections_observed += defections_last_round
        self.cooperation_history.append(observed_coop_rate)
        recent_rounds_count = min(3, current_round)
        recent_coop_rate = np.mean(self.cooperation_history[-recent_rounds_count:])
        if len(self.cooperation_history) >= 2:
            recent_volatility = np.std(self.cooperation_history[-min(3, len(self.cooperation_history)):]) / 2.0
        else:
            recent_volatility = 0.0
        risk_adjustment = min(0.15, self.defections_observed / max(1, self.total_actions_observed))
        adaptive_threshold = self.base_threshold + risk_adjustment + recent_volatility
        expected_coop_rate = 0.6 * observed_coop_rate + 0.4 * recent_coop_rate
        if current_round == r - 1:
            if recent_coop_rate >= 0.75 * self.base_threshold:
                return Action.C
            else:
                return Action.D
        if current_round == r - 2:
            if expected_coop_rate >= adaptive_threshold:
                return Action.C
            else:
                return Action.D
        if observed_coop_rate == 0.0:
            return Action.D
        elif expected_coop_rate >= adaptive_threshold:
            return Action.C
        elif random.random() < observed_coop_rate:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_132(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATC)
    
    Balances collective welfare, protection against exploitation, and robustness
    through conditional cooperation with adaptive thresholds based on observed
    cooperation rates and game progress.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold_ever_met = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if state.round_number == 0:
            return Action.C
        prev_round_idx = state.round_number - 1
        my_prev_action = history.my_actions[prev_round_idx]
        opponent_prev_cooperators = sum(history.opponent_actions[prev_round_idx, :])
        coop_prev = int(my_prev_action) + opponent_prev_cooperators
        if coop_prev >= m:
            self.threshold_ever_met = True
        if state.round_number == r - 1:
            if coop_prev == 0 and (not self.threshold_ever_met):
                return Action.D
        if coop_prev >= m:
            if coop_prev >= n - 1:
                return Action.C
            else:
                prob_cooperate = coop_prev / m
                return Action.C if random.random() < prob_cooperate else Action.D
        elif coop_prev == 0:
            return Action.D
        elif coop_prev >= m / 2:
            prob_cooperate = coop_prev / m
            return Action.C if random.random() < prob_cooperate else Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_133(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual security with collective welfare by:
    1. Measuring collective health through cooperation rates
    2. Adapting contribution levels based on observed risk
    3. Protecting against free-riding while rewarding genuine cooperation
    4. Escalating commitment as the game progresses
    
    Uses dynamic threshold that starts optimistic and becomes more cautious near the end.
    Includes probabilistic escalation to signal commitment during collective failures.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.p_escalate = 0.85
        self.p_test = 0.65

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_idx = round_num - 1
        opponent_cooperators = np.sum(history.opponent_actions[prev_round_idx, :])
        my_prev_action = history.my_actions[prev_round_idx]
        total_cooperators = opponent_cooperators + (1 if my_prev_action else 0)
        cooperation_rate = total_cooperators / n
        rounds_remaining = r - round_num
        threshold = m / n + rounds_remaining / (4 * r)
        if cooperation_rate >= threshold:
            return Action.C
        elif rounds_remaining <= 1:
            return Action.D
        elif my_prev_action:
            return Action.C if random.random() < self.p_escalate else Action.D
        else:
            return Action.C if random.random() < self.p_test else Action.D

class Strategy_COLLECTIVE_134(BaseStrategy):
    """
    Adaptive Threshold Commitment Strategy (ATCS) for Collective Risk Dilemma.
    
    Balances collective success with self-protection through three phases:
    - Exploration: Build trust and test cooperation rates
    - Commitment: Stabilize coordination around threshold
    - Exploitation: Leverage successful coordination or minimize losses
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold_ratio = self.m / self.n

    def _classify_phase(self, round_num: int) -> str:
        """Classify which phase we're in (0-indexed rounds)."""
        exploration_end = math.ceil(self.r / 3) - 1
        commitment_end = math.floor(2 * self.r / 3) - 1
        if round_num <= exploration_end:
            return 'exploration'
        elif round_num <= commitment_end:
            return 'commitment'
        else:
            return 'exploitation'

    def _count_cooperators_in_round(self, history: PlayerHistory, round_idx: int) -> int:
        """Count total cooperators (including self) in a given round."""
        my_action = 1 if history.my_actions[round_idx] else 0
        opponent_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
        return my_action + opponent_cooperators

    def _get_cooperation_rate(self, history: PlayerHistory, round_idx: int) -> float:
        """Get cooperation rate (fraction of all players) in a given round."""
        if self.n == 0:
            return 0.0
        return self._count_cooperators_in_round(history, round_idx) / self.n

    def _compute_recent_success_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Compute success rate over last 3 rounds (or fewer if not enough history).
        Success = round had >= m cooperators.
        """
        start_round = max(0, current_round - 3)
        recent_rounds = range(start_round, current_round)
        if len(list(recent_rounds)) == 0:
            return 0.0
        success_count = sum((1 for r in recent_rounds if self._count_cooperators_in_round(history, r) >= self.m))
        return success_count / len(list(recent_rounds))

    def _compute_recent_cooperation_avg(self, history: PlayerHistory, current_round: int) -> float:
        """
        Compute average cooperation rate over last 2 rounds (or fewer if not enough history).
        """
        start_round = max(0, current_round - 2)
        recent_rounds = list(range(start_round, current_round))
        if len(recent_rounds) == 0:
            return 0.0
        total_coop_rate = sum((self._get_cooperation_rate(history, r) for r in recent_rounds))
        return total_coop_rate / len(recent_rounds)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            cooperators_prev = self._count_cooperators_in_round(history, round_num - 1)
            cooperation_rate_prev = cooperators_prev / self.n if self.n > 0 else 0.0
            if cooperation_rate_prev > 0.9:
                return Action.C
            else:
                return Action.D
        phase = self._classify_phase(round_num)
        if phase == 'exploration':
            cooperators_prev = self._count_cooperators_in_round(history, round_num - 1)
            coop_rate_prev = cooperators_prev / self.n if self.n > 0 else 0.0
            if self.m > 2 * self.n / 3:
                threshold = self.threshold_ratio * 0.95
            else:
                threshold = self.threshold_ratio * 0.9
            if coop_rate_prev >= threshold:
                return Action.C
            else:
                return Action.D
        elif phase == 'commitment':
            recent_success_rate = self._compute_recent_success_rate(history, round_num)
            recent_coop_avg = self._compute_recent_cooperation_avg(history, round_num)
            if self.m > 2 * self.n / 3:
                coop_threshold = self.threshold_ratio * 0.95
            else:
                coop_threshold = self.threshold_ratio * 0.85
            if recent_success_rate >= 0.67 and recent_coop_avg >= coop_threshold:
                return Action.C
            elif recent_success_rate <= 0.33:
                return Action.D
            else:
                return Action.C
        else:
            cooperators_prev = self._count_cooperators_in_round(history, round_num - 1)
            if cooperators_prev >= self.m:
                if cooperators_prev == self.n:
                    return Action.D
                else:
                    return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_135(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances individual security with collective welfare by dynamically adjusting
    cooperation based on observed cooperation rates and remaining rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.trend_threshold = 0.15
        self.required_confidence = 0.6
        self.round2_threshold = 0.33

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_cooperators = int(sum(history.opponent_actions[round_num - 1, :]))
        cooperation_rate = prev_cooperators / self.n
        estimated_next_cooperators = round(cooperation_rate * self.n)
        if round_num == self.r - 1:
            if estimated_next_cooperators >= self.m:
                return Action.C
            else:
                return Action.D
        if round_num == 1:
            if cooperation_rate >= self.round2_threshold:
                return Action.C
            else:
                return Action.D
        threshold_likelihood = self._estimate_threshold_likelihood(estimated_next_cooperators)
        recent_rate = self._calculate_recent_cooperation_rate(history, round_num)
        trend = self._detect_trend(recent_rate, cooperation_rate)
        if threshold_likelihood >= self.required_confidence:
            return Action.C
        elif trend == 'INCREASING':
            return Action.C
        elif trend == 'STABLE_HIGH' and cooperation_rate >= self.m / self.n - 0.1:
            return Action.C
        else:
            return Action.D

    def _estimate_threshold_likelihood(self, estimated_cooperators: int) -> float:
        """
        Estimate probability that threshold will be met.
        Apply smoothing near boundary (m-1 or m).
        """
        if estimated_cooperators >= self.m:
            return 1.0
        elif estimated_cooperators == self.m - 1:
            return 0.5
        else:
            return 0.0

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate moving average of cooperation rate over last Ï„ rounds.
        Ï„ = min(3, current_round)
        """
        tau = min(3, round_num)
        if tau == 0:
            return 0.0
        start_round = max(0, round_num - tau)
        recent_rates = []
        for r in range(start_round, round_num):
            cooperators = int(sum(history.opponent_actions[r, :]))
            rate = cooperators / self.n
            recent_rates.append(rate)
        if not recent_rates:
            return 0.0
        return sum(recent_rates) / len(recent_rates)

    def _detect_trend(self, recent_rate: float, previous_rate: float) -> str:
        """
        Detect cooperation trend by comparing recent average to previous round.
        Returns: "INCREASING", "DECREASING", or "STABLE"
        Also considers stability level when returning "STABLE".
        """
        if recent_rate > previous_rate + self.trend_threshold:
            return 'INCREASING'
        elif recent_rate < previous_rate - self.trend_threshold:
            return 'DECREASING'
        elif previous_rate >= self.m / self.n:
            return 'STABLE_HIGH'
        else:
            return 'STABLE'

class Strategy_COLLECTIVE_136(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATC) for Collective Risk Dilemma.
    
    Balances individual security with collective benefit by maintaining an adaptive
    cooperation threshold that adjusts based on observed cooperation rates. Uses
    defection streak tracking to identify when collective coordination has failed
    and transitions to individual security (defection).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.observed_coop_rate = 0.5
        self.defection_streak = 0
        self.threshold = game_description.m / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        self._update_state(history, round_number)
        action = self._decide_action(round_number)
        return action

    def _update_state(self, history: PlayerHistory, round_number: int) -> None:
        """Update observed cooperation rate and defection streak based on history."""
        prev_round_idx = round_number - 1
        opponent_cooperators = np.sum(history.opponent_actions[prev_round_idx, :])
        my_action = history.my_actions[prev_round_idx]
        total_cooperators = opponent_cooperators + (1 if my_action else 0)
        coop_count = total_cooperators
        if round_number == 1:
            self.observed_coop_rate = coop_count / self.game_description.n_players
        else:
            self.observed_coop_rate = (self.observed_coop_rate * (round_number - 1) + coop_count / self.game_description.n_players) / round_number
        if coop_count >= self.game_description.m:
            self.defection_streak = 0
        else:
            self.defection_streak += 1

    def _decide_action(self, round_number: int) -> Action:
        """Determine action based on defection streak and cooperation history."""
        n_rounds = self.game_description.n_rounds
        if self.defection_streak >= 2:
            return Action.D
        if round_number == n_rounds - 1:
            if self.observed_coop_rate >= self.threshold * 1.2:
                return Action.C
            else:
                return Action.D
        if self.defection_streak == 1:
            if self.observed_coop_rate >= self.threshold * 0.9:
                return Action.C
            else:
                return Action.D
        if self.observed_coop_rate >= self.threshold * 1.1:
            return Action.C
        elif self.observed_coop_rate >= self.threshold:
            rounds_remaining = n_rounds - round_number
            if rounds_remaining >= 3:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_137(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances collective welfare with individual rationality by:
    1. Promoting cooperation when threshold achievement is likely
    2. Protecting against exploitation when cooperation is unlikely
    3. Adapting dynamically based on observed cooperation rates
    4. Maximizing collective payoff while remaining individually rational
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        total_opponent_cooperators = int(np.sum(history.opponent_actions[:round_t, :]))
        total_possible_cooperations = round_t * self.n_players
        if total_possible_cooperations == 0:
            coop_rate = 0.0
        else:
            coop_rate = total_opponent_cooperators / total_possible_cooperations
        if round_t == self.n_rounds - 1:
            expected_cooperators = round(coop_rate * self.n_players)
            if expected_cooperators >= self.m:
                return Action.C
            else:
                return Action.D
        recent_rounds_count = min(3, round_t)
        recent_start_idx = max(0, round_t - 3)
        recent_cooperators = int(np.sum(history.opponent_actions[recent_start_idx:round_t, :]))
        recent_possible = recent_rounds_count * self.n_players
        if recent_possible == 0:
            recent_coop_rate = 0.0
        else:
            recent_coop_rate = recent_cooperators / recent_possible
        blended_rate = 0.6 * recent_coop_rate + 0.4 * coop_rate
        expected_cooperators = blended_rate * self.n_players
        cooperation_margin = expected_cooperators - self.m
        if cooperation_margin >= 1.5:
            return Action.C
        elif cooperation_margin >= 0.5:
            return Action.C
        elif cooperation_margin >= -0.5:
            rounds_remaining = self.n_rounds - round_t
            threshold_distance = self.n_rounds / 3.0
            if rounds_remaining > threshold_distance:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_138(BaseStrategy):
    """
    Collective Risk Adaptive Strategy (CRAS)
    
    Prioritizes collective welfare while maintaining individual security.
    Cooperates when the threshold for collective success (m cooperators) is expected,
    adapts based on observed cooperation rates, and enters an exploitation phase
    to penalize sustained defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.in_exploitation_phase = False
        self.exploitation_timer = 0
        self.rounds_below_threshold = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        recent_cooperators = int(np.sum(history.opponent_actions[round_num - 1, :]))
        my_prev_action = history.my_actions[round_num - 1]
        recent_cooperators_with_me = recent_cooperators + (1 if my_prev_action else 0)
        if self.in_exploitation_phase:
            if self.exploitation_timer > 0:
                self.exploitation_timer -= 1
                return Action.D
            else:
                self.in_exploitation_phase = False
                self.rounds_below_threshold = 0
        cooperation_rate = recent_cooperators / (self.n - 1) if self.n > 1 else 0
        threshold_safe = (self.m - 1) / (self.n - 1) if self.n > 1 else 0
        threshold_caution = (self.m + 1) / (self.n - 1) if self.n > 1 else 1
        if cooperation_rate >= threshold_safe:
            expected_cooperators = recent_cooperators
        elif cooperation_rate >= threshold_caution:
            expected_cooperators = math.floor(0.9 * recent_cooperators)
        else:
            expected_cooperators = max(1, recent_cooperators - 1)
        if recent_cooperators_with_me < self.m:
            self.rounds_below_threshold += 1
            if self.rounds_below_threshold >= 2:
                self.in_exploitation_phase = True
                self.exploitation_timer = math.ceil(self.r / 4) + 1
                self.rounds_below_threshold = 0
                return Action.D
        else:
            self.rounds_below_threshold = 0
        if round_num == self.r - 1:
            if recent_cooperators_with_me >= self.m:
                return Action.C
            elif recent_cooperators_with_me >= self.m - 1:
                return Action.C
            else:
                return Action.D
        if expected_cooperators >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_139(BaseStrategy):
    """
    Adaptive Threshold Steward: A strategy for Collective Risk Dilemma that balances
    collective welfare with rational self-interest by monitoring cooperation rates
    and adapting participation based on likelihood of reaching the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.tolerance_buffer_adaptive = 0.15
        self.tolerance_buffer_final = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        coop_rate = self._calculate_cooperation_rate(history, n, current_round)
        threshold_ratio = m / n
        if current_round == r - 1:
            if coop_rate >= threshold_ratio - self.tolerance_buffer_final:
                return Action.C
            else:
                return Action.D
        else:
            remaining_rounds = r - current_round
            if coop_rate >= threshold_ratio - self.tolerance_buffer_adaptive:
                return Action.C
            elif remaining_rounds > 1:
                return Action.D
            else:
                return Action.C

    def _calculate_cooperation_rate(self, history: PlayerHistory, n: int, current_round: int) -> float:
        """
        Calculate the cooperation rate as the ratio of total cooperators
        across all previous rounds to total possible actions.
        """
        if current_round == 0:
            return 0.0
        total_cooperators = 0
        own_cooperations = int(np.sum(history.my_actions[:current_round]))
        total_cooperators += own_cooperations
        opponent_cooperations = int(np.sum(history.opponent_actions[:current_round, :]))
        total_cooperators += opponent_cooperations
        total_actions = n * current_round
        if total_actions == 0:
            return 0.0
        return total_cooperators / total_actions

class Strategy_COLLECTIVE_140(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances individual security with collective welfare by:
    1. Calculating a Cooperation Index based on historical cooperation rates
    2. Using risk stratification (Tier 1/2/3) to decide action
    3. Adapting to observed cooperation patterns
    4. Handling edge cases: first round, final round, and persistent low cooperation
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.pessimistic_mode = False
        self.low_cooperation_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return self._first_round_decision()
        coop_rate = self._calculate_cooperation_rate(history, current_round)
        expected_cooperators = self.m + (coop_rate - 0.5) * self.n_players
        self._update_pessimistic_mode(history, current_round)
        if current_round == self.n_rounds - 1:
            return self._final_round_decision(expected_cooperators, history, current_round)
        return self._non_final_round_decision(expected_cooperators)

    def _first_round_decision(self) -> Action:
        """
        First round logic: use neutral assumption based on m/n ratio.
        If threshold requires more than half, be conservative (defect).
        Otherwise, be optimistic (cooperate).
        """
        baseline_assumption = self.m / self.n_players
        if baseline_assumption >= 0.5:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate historical cooperation rate across all completed rounds.
        Handles edge case of division by zero.
        """
        if current_round == 0:
            return self.m / self.n_players
        total_cooperators = np.sum(history.opponent_actions[:current_round, :])
        total_slots = self.n_players * current_round
        if total_slots == 0:
            return self.m / self.n_players
        return total_cooperators / total_slots

    def _update_pessimistic_mode(self, history: PlayerHistory, current_round: int) -> None:
        """
        Check for consecutive low cooperation rounds (3+ rounds below m/n threshold).
        Enter pessimistic mode if detected; exit if cooperation spikes.
        """
        if current_round < 3:
            return
        recent_cooperators = np.sum(history.opponent_actions[max(0, current_round - 3):current_round, :])
        recent_slots = self.n_players * min(3, current_round)
        if recent_slots > 0:
            recent_coop_rate = recent_cooperators / recent_slots
            if recent_coop_rate < self.m / self.n_players:
                self.low_cooperation_count += 1
                if self.low_cooperation_count >= 3:
                    self.pessimistic_mode = True
            else:
                self.low_cooperation_count = 0
                self.pessimistic_mode = False

    def _non_final_round_decision(self, expected_cooperators: float) -> Action:
        """
        Non-final round decision using risk stratification tiers.
        
        Tier 1 (High confidence, CI >= m + 1): Cooperate unconditionally
        Tier 2 (Medium confidence, m - 0.5 <= CI < m + 1): Probabilistic cooperation
        Tier 3 (Low confidence, CI < m - 0.5): Defect (unless in pessimistic mode review)
        """
        if self.pessimistic_mode:
            return Action.D
        if expected_cooperators >= self.m + 1:
            return Action.C
        if self.m - 0.5 <= expected_cooperators < self.m + 1:
            coop_probability = (expected_cooperators - (self.m - 1)) / 2
            coop_probability = max(0.0, min(1.0, coop_probability))
            return Action.C if random.random() < coop_probability else Action.D
        return Action.D

    def _final_round_decision(self, expected_cooperators: float, history: PlayerHistory, current_round: int) -> Action:
        """
        Final round special handling with no future to hedge for.
        
        - If CI >= m: Cooperate (enjoy final payoff, signal commitment)
        - Else if CI < m and private payoff > 1: Defect (exploit collective failure)
        - Else: Cooperate (collective welfare default)
        """
        if expected_cooperators >= self.m:
            return Action.C
        endowment_private = 1
        if endowment_private > 1:
            return Action.D
        return Action.C

class Strategy_COLLECTIVE_141(BaseStrategy):
    """
    Adaptive Threshold Cooperation with Reciprocal Adjustment
    
    This strategy balances individual rationality with collective welfare by:
    1. Estimating peer cooperation rates from observed history
    2. Cooperating only when the threshold is likely to be met
    3. Using reciprocal adjustment to reward cooperation and punish defection
    4. Special handling for the final round
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        window_size = min(3, current_round)
        total_cooperators_in_window = 0
        for round_idx in range(current_round - window_size, current_round):
            round_cooperators = int(sum(history.opponent_actions[round_idx, :]))
            total_cooperators_in_window += round_cooperators
        total_observations = window_size * (self.n_players - 1)
        if total_observations > 0:
            peer_cooperation_rate = total_cooperators_in_window / total_observations
        else:
            peer_cooperation_rate = 0.0
        expected_peer_cooperators = peer_cooperation_rate * (self.n_players - 1)
        expected_total_cooperators = expected_peer_cooperators + 1
        if current_round == self.n_rounds - 1:
            prev_round_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
            if prev_round_cooperators >= self.m:
                return Action.C
            else:
                return Action.D
        if expected_total_cooperators >= self.m - 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_142(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances collective welfare, individual resilience, and adaptive robustness by:
    - Cooperating unconditionally in round 1 to signal willingness
    - Making cooperation conditional on observed cooperation rates in intermediate rounds
    - Context-dependent defection in the last round based on threshold likelihood
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.safety_margin = 1.1
        self.strong_coop_threshold = 0.8
        self.weak_coop_threshold = 0.5
        self.max_prob_cooperation = 0.9

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round_opponent_actions = history.opponent_actions[state.round_number - 1, :]
        cooperators_prev = np.sum(prev_round_opponent_actions)
        my_prev_action = history.my_actions[state.round_number - 1]
        total_cooperators_prev = cooperators_prev + (1 if my_prev_action else 0)
        cooperation_rate_prev = total_cooperators_prev / self.game_description.n_players
        threshold_rate = self.game_description.m / self.game_description.n_players
        if state.round_number == self.game_description.n_rounds - 1:
            if cooperation_rate_prev >= threshold_rate * self.safety_margin:
                return Action.C
            else:
                return Action.D
        if cooperation_rate_prev >= threshold_rate * self.strong_coop_threshold:
            return Action.C
        elif cooperation_rate_prev >= threshold_rate * self.weak_coop_threshold:
            prob_cooperate = min(self.max_prob_cooperation, cooperation_rate_prev / threshold_rate)
            if random.random() < prob_cooperate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_143(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances collective welfare with individual rationality by:
    1. Cooperating initially to signal intent
    2. Adapting to observed cooperation rates relative to threshold m/n
    3. Defecting when defection trends are severe or in final round
    4. Making marginal contributions when close to threshold
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.deficit_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        previous_cooperators = int(sum(history.opponent_actions[round_num - 1, :]))
        coop_rate = previous_cooperators / self.n
        threshold_rate = self.m / self.n
        deficit = self.m - previous_cooperators
        delta = 1.0 / self.n
        if round_num == self.r - 1:
            if coop_rate >= threshold_rate and deficit <= 2:
                return Action.C
            else:
                return Action.D
        if coop_rate >= threshold_rate:
            self.deficit_rounds = 0
            return Action.C
        if coop_rate > threshold_rate - delta:
            self.deficit_rounds = 0
            return Action.C
        if deficit <= self.n / 3.0:
            self.deficit_rounds = 0
            return Action.C
        if round_num >= 2:
            prev_prev_cooperators = int(sum(history.opponent_actions[round_num - 2, :]))
            prev_prev_deficit = self.m - prev_prev_cooperators
            if prev_prev_deficit > self.n / 3.0:
                self.deficit_rounds += 1
            else:
                self.deficit_rounds = 0
            if self.deficit_rounds >= 1:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_144(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by cooperating when
    the probability of reaching the threshold m is sufficiently high. Adapts
    cooperation thresholds based on game parameters and observed cooperation rates.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_ratio = self.m / self.n_players
        self.conservative_margin = 0.25 - (self.k - 1) * 0.05
        self.conservative_margin = max(0.1, min(0.4, self.conservative_margin))
        self.consecutive_zero_coop_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round_actions = history.opponent_actions[state.round_number - 1, :]
        cooperators_last_round = np.sum(previous_round_actions)
        coop_rate = cooperators_last_round / self.n_players
        if self.m == self.n_players:
            if coop_rate < 1.0:
                self.consecutive_zero_coop_rounds += 1
                if self.consecutive_zero_coop_rounds >= 1:
                    return Action.D
            else:
                self.consecutive_zero_coop_rounds = 0
                return Action.C
            return Action.D
        if coop_rate == 0:
            self.consecutive_zero_coop_rounds += 1
            if self.consecutive_zero_coop_rounds >= 2:
                return Action.D
        else:
            self.consecutive_zero_coop_rounds = 0
        if coop_rate >= self.threshold_ratio:
            return Action.C
        elif coop_rate >= self.threshold_ratio - self.conservative_margin:
            prob_cooperate = coop_rate / self.threshold_ratio if self.threshold_ratio > 0 else 0
            if random.random() < prob_cooperate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_145(BaseStrategy):
    """
    Conditional Cooperation with Adaptive Decay (CCAD) Strategy
    
    Balances individual security with collective welfare by dynamically adjusting
    cooperation based on observed cooperation rates. Uses a resilience buffer (Îµ=0.15)
    to tolerate temporary cooperation drops and adaptive dampening to prevent
    defection cascades.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.epsilon = 0.15
        self.cooperation_threshold = game_description.m / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        threshold = self.cooperation_threshold
        epsilon = self.epsilon
        prev_round_idx = current_round - 1
        prev_cooperators = float(np.sum(history.opponent_actions[prev_round_idx, :]))
        coop_rate = prev_cooperators / n
        if current_round == r - 1:
            if coop_rate >= threshold - epsilon:
                return Action.C
            else:
                return Action.D
        if coop_rate >= threshold - epsilon:
            return Action.C
        elif coop_rate >= threshold - 2 * epsilon:
            if threshold > 0:
                p_dampen = coop_rate / threshold
            else:
                p_dampen = 0.0
            if random.random() < p_dampen:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_146(BaseStrategy):
    """
    Adaptive Threshold Pursuit strategy for Collective Risk Dilemma.
    
    Balances collective welfare with individual security by:
    1. Bootstrapping cooperation in round 1
    2. Maintaining cooperation when threshold is met
    3. Defecting when threshold is unreachable
    4. Attempting recovery when threshold is achievable within remaining rounds
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators_last_round = int(sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            cooperators_last_round += 1
        if cooperators_last_round >= self.m:
            return Action.C
        if cooperators_last_round == 0:
            return Action.D
        cooperators_needed = self.m - cooperators_last_round
        current_round = state.round_number
        rounds_remaining = self.n_rounds - current_round
        if rounds_remaining <= 0:
            return Action.D
        recovery_threshold = rounds_remaining * 0.6
        if cooperators_needed <= recovery_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_147(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by conditioning
    cooperation on observed success rates, with special handling for critical
    moments when individual contribution determines collective success.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        recent_window_size = min(5, current_round)
        recent_start = max(0, current_round - recent_window_size)
        recent_successes = 0
        overall_successes = 0
        for round_idx in range(current_round):
            cooperators_in_round = int(history.my_actions[round_idx]) + sum(history.opponent_actions[round_idx, :])
            if cooperators_in_round >= self.m:
                overall_successes += 1
                if round_idx >= recent_start:
                    recent_successes += 1
        recent_success_rate = recent_successes / recent_window_size if recent_window_size > 0 else 0.0
        overall_success_rate = overall_successes / current_round if current_round > 0 else 0.0
        last_cooperators = int(sum(history.opponent_actions[-1, :]))
        rounds_remaining = self.r - current_round
        if rounds_remaining <= 2:
            return Action.C if recent_success_rate > 0.5 else Action.D
        if last_cooperators == self.m - 1:
            return Action.C
        if last_cooperators >= self.m:
            return Action.D if recent_success_rate > 0.7 else Action.C
        if last_cooperators < self.m - 1:
            return Action.D
        expected_cooperators = last_cooperators + 0.5
        if expected_cooperators >= self.m:
            return Action.C
        if recent_success_rate >= 0.6:
            return Action.C
        elif recent_success_rate < 0.3 and overall_success_rate < 0.4:
            return Action.D
        else:
            return Action.C if overall_success_rate >= 0.4 else Action.D

class Strategy_COLLECTIVE_148(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances collective welfare with individual resilience by:
    1. Cooperating in round 1 to establish baseline
    2. In middle rounds, conditionally cooperating based on historical cooperation rate
    3. In final round, defecting if cooperation has fallen below threshold
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.buffer = 0.05
        self.threshold_ratio = game_description.m / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperation_rate = self._calculate_cooperation_rate(history, state.round_number)
        if state.round_number == self.game_description.n_rounds - 1:
            if cooperation_rate >= self.threshold_ratio - self.buffer:
                return Action.C
            else:
                return Action.D
        rounds_remaining = self.game_description.n_rounds - state.round_number - 1
        if cooperation_rate >= self.threshold_ratio - self.buffer:
            return Action.C
        elif cooperation_rate < self.threshold_ratio - self.buffer and rounds_remaining >= 2:
            return Action.D
        else:
            return Action.C

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the observed cooperation rate from all previous rounds.
        
        cooperation_rate = (total cooperators across all past rounds) / (n Ã— rounds_completed)
        """
        if current_round == 0:
            return 0.0
        my_cooperations = np.sum(history.my_actions[:current_round])
        opponent_cooperations = np.sum(history.opponent_actions[:current_round, :])
        total_cooperations = my_cooperations + opponent_cooperations
        total_actions = self.game_description.n_players * current_round
        if total_actions == 0:
            return 0.0
        cooperation_rate = total_cooperations / total_actions
        return cooperation_rate

class Strategy_COLLECTIVE_149(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC): A conditional collective strategy that cooperates
    to enable collective success, but adapts pragmatically based on observed cooperation rates.
    Cooperates when threshold achievement is plausible, defects when it becomes unlikely.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.epsilon = 0.05

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        n_players = self.game_description.n_players
        n_rounds = self.game_description.n_rounds
        m = self.game_description.m
        k = self.game_description.k
        current_round = state.round_number
        if current_round == 0:
            observed_coop_rate = 0.0
        else:
            total_opponent_cooperations = np.sum(history.opponent_actions[:current_round, :])
            total_opponent_actions = (n_players - 1) * current_round
            if total_opponent_actions == 0:
                observed_coop_rate = 0.0
            else:
                observed_coop_rate = total_opponent_cooperations / total_opponent_actions
        if current_round == n_rounds - 1:
            threshold_coop_rate = (m - 1) / (n_players - 1) - self.epsilon
            if observed_coop_rate >= threshold_coop_rate:
                return Action.C
            else:
                return Action.D
        expected_cooperators = round(observed_coop_rate * n_players)
        rounds_remaining = n_rounds - current_round
        if expected_cooperators + 1 >= m:
            if rounds_remaining >= 2:
                return Action.C
            else:
                threshold_value = k
                defect_value = 1.0
                if threshold_value > defect_value:
                    return Action.C
                else:
                    return Action.D
        elif expected_cooperators + 1 == m - 1:
            rounds_remaining_benefit = max(0, rounds_remaining - 1)
            cumulative_benefit = rounds_remaining_benefit * k
            defect_cost = 1.0 * rounds_remaining
            if cumulative_benefit > defect_cost:
                return Action.C
            else:
                return Action.D
        else:
            min_required_coop_rate = m / n_players
            if observed_coop_rate < min_required_coop_rate:
                return Action.D
            else:
                return Action.D

class Strategy_COLLECTIVE_150(BaseStrategy):
    """
    Adaptive Threshold Cooperation for Collective Risk Dilemma.
    
    Balances collective benefit (achieving threshold) with rational self-interest
    by cooperating probabilistically based on observed cooperation rates and
    remaining opportunities. Includes special handling for edge cases and final rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.prev_cooperation_rate = 1.0
        self.prev_prev_cooperation_rate = 1.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        m = self.game_description.m
        k = self.game_description.k
        t = state.round_number + 1
        prev_round_idx = state.round_number - 1
        cooperators_last_round = float(np.sum(history.opponent_actions[prev_round_idx, :]))
        prev_cooperation_rate = cooperators_last_round / n
        if t == r:
            threshold_fraction = m / n
            if prev_cooperation_rate >= threshold_fraction:
                return Action.C
            else:
                deficit = m - prev_cooperation_rate * n
                if deficit <= 2 and prev_cooperation_rate >= 0.6:
                    return Action.C if random.random() < 0.7 else Action.D
                else:
                    return Action.D
        threshold_feasibility = m / n
        deficit = threshold_feasibility - prev_cooperation_rate
        rounds_remaining = r - t
        if prev_cooperation_rate >= threshold_feasibility:
            p_coop = 0.95
        elif deficit <= 0:
            p_coop = 0.9
        elif rounds_remaining < 2:
            if threshold_feasibility > 0:
                p_coop = min(0.5, prev_cooperation_rate / threshold_feasibility)
            else:
                p_coop = 0.5
        elif threshold_feasibility > 0:
            p_coop = min(1.0, prev_cooperation_rate / threshold_feasibility * 0.85 + 0.15)
        else:
            p_coop = 0.85
        if prev_cooperation_rate < self.prev_prev_cooperation_rate:
            p_coop *= 0.85
        if prev_cooperation_rate == 0:
            p_coop = 0.3
        if m >= n - 1:
            p_coop *= 1.2
            p_coop = min(p_coop, 1.0)
        if m == 2:
            p_coop = 0.9
        self.prev_prev_cooperation_rate = self.prev_cooperation_rate
        self.prev_cooperation_rate = prev_cooperation_rate
        return Action.C if random.random() < p_coop else Action.D

class Strategy_COLLECTIVE_151(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances collective welfare through cooperation with protection against exploitation.
    - Round 1: Cooperate (costly signal of good faith)
    - Last round: Defect (no future reciprocation possible)
    - Middle rounds: Adaptive threshold based on observed cooperation rates
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            return Action.D
        avg_cooperation = self._calculate_avg_cooperation(history, current_round)
        time_decay_factor = (self.r - current_round) / self.r
        expected_cooperators_excluding_me = (self.n - 1) * avg_cooperation
        effective_threshold = self.m - 1 - 0.5 * time_decay_factor
        if expected_cooperators_excluding_me >= effective_threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_avg_cooperation(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the average cooperation rate of other players across all previous rounds.
        
        Returns a value in [0, 1] representing the proportion of cooperate actions.
        Handles edge case of division by zero.
        """
        if current_round == 0:
            return 0.0
        total_opponent_cooperations = 0
        for round_idx in range(current_round):
            cooperators_in_round = np.sum(history.opponent_actions[round_idx, :])
            total_opponent_cooperations += cooperators_in_round
        total_possible = (self.n - 1) * current_round
        if total_possible == 0:
            return 0.0
        avg_cooperation_rate = total_opponent_cooperations / total_possible
        return float(avg_cooperation_rate)

class Strategy_COLLECTIVE_152(BaseStrategy):
    """
    Adaptive Threshold Commitment strategy for Collective Risk Dilemma.
    
    Balances conditional cooperation with strategic defection signaling.
    - Phase 1 (Rounds 0-2): Explore and establish cooperative norms
    - Phase 2 (Middle rounds): Strategic positioning based on cooperation rates
    - Phase 3 (Final rounds): Endgame with reduced patience for coordination
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defections_in_phase = 0
        self.last_phase = 0
        self.threshold_achieved_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round <= 2:
            return Action.C
        cooperators_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
        cooperators_last_round += int(history.my_actions[current_round - 1])
        total_cooperators = 0
        for round_idx in range(current_round):
            total_cooperators += int(sum(history.opponent_actions[round_idx, :]))
            total_cooperators += int(history.my_actions[round_idx])
        coop_rate_overall = total_cooperators / (n * current_round) if current_round > 0 else 0
        if cooperators_last_round >= m:
            self.threshold_achieved_count += 1
        rounds_remaining = r - current_round
        is_endgame = rounds_remaining <= 2
        if is_endgame:
            if current_round == r - 1:
                if self.threshold_achieved_count > 0:
                    return Action.C
                else:
                    return Action.C
            elif cooperators_last_round >= m:
                return Action.C
            else:
                return Action.D
        if self.last_phase != 1:
            self.defections_in_phase = 0
            self.last_phase = 1
        if cooperators_last_round >= m:
            return Action.C
        if coop_rate_overall > m / n:
            return Action.C
        if cooperators_last_round == m - 1:
            return Action.C
        if self.defections_in_phase < 1:
            self.defections_in_phase += 1
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_153(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Core philosophy: Cooperate when collective success is achievable, defect when it's not.
    Uses an adaptive threshold based on the minimum cooperators needed (m) and adjusts
    based on observed cooperation trends.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        if self.n > 1:
            self.baseline_threshold = (self.m - 1) / (self.n - 1)
        else:
            self.baseline_threshold = 0.0
        self.adjustment_factor = 0.05
        self.previous_cooperation_rate = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            return Action.C
        previous_round_idx = round_num - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[previous_round_idx, :]))
        if history.my_actions[previous_round_idx]:
            cooperators_last_round += 1
        cooperation_rate = cooperators_last_round / self.n
        current_threshold = self.baseline_threshold + self.adjustment_factor
        if self.previous_cooperation_rate is not None:
            if cooperation_rate < self.previous_cooperation_rate:
                self.adjustment_factor += 0.02
            elif cooperation_rate > self.previous_cooperation_rate:
                self.adjustment_factor -= 0.01
            self.adjustment_factor = max(0.03, min(0.15, self.adjustment_factor))
        self.previous_cooperation_rate = cooperation_rate
        if cooperation_rate >= current_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_154(BaseStrategy):
    """
    Adaptive Threshold Enforcement Strategy for Collective Risk Dilemma.
    
    This strategy balances pragmatic threshold-seeking, defection deterrence,
    adaptive learning, and temporal awareness to promote collective success
    while protecting against exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        c_prev = int(sum(history.opponent_actions[round_num - 1, :]))
        if history.my_actions[round_num - 1]:
            c_prev += 1
        rounds_remaining = self.r - round_num - 1
        if round_num == self.r - 1:
            if c_prev >= self.m - 1:
                return Action.C
            else:
                return Action.D
        if c_prev >= self.m:
            if history.my_actions[round_num - 1]:
                return Action.C
            else:
                shame_probability = self.m / self.n
                if random.random() < shame_probability:
                    return Action.C
                else:
                    return Action.D
        elif c_prev >= self.m - 1:
            return Action.C
        elif rounds_remaining > 2:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_155(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances collective benefit maximization with self-protection against exploitation.
    Cooperates when cooperation is likely to meet the threshold m, defects when threshold
    is unlikely to be reached. Includes adaptive thresholds, round-specific logic, and
    edge case handling for robust performance.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        buffer = max(1, math.ceil(0.15 * self.n))
        self.critical_threshold = (self.m + buffer) / self.n
        self.perfect_defection_detected = False
        self.perfect_cooperation_detected = False
        self.cooperation_values = []
        self.declining_trend_count = 0

    def _count_cooperators_in_round(self, history: PlayerHistory, round_idx: int) -> int:
        """Count total cooperators (including self) in a given round."""
        my_action = history.my_actions[round_idx]
        opponent_coop = np.sum(history.opponent_actions[round_idx, :])
        return int(my_action) + int(opponent_coop)

    def _get_cooperation_rate(self, history: PlayerHistory, up_to_round: int) -> float:
        """Get average cooperation rate across rounds up to (inclusive) up_to_round."""
        if up_to_round < 0:
            return 0.0
        total_coop = 0
        for i in range(up_to_round + 1):
            total_coop += self._count_cooperators_in_round(history, i)
        total_players_across_rounds = (up_to_round + 1) * self.n
        if total_players_across_rounds == 0:
            return 0.0
        return total_coop / total_players_across_rounds

    def _get_recent_cooperation_rate(self, history: PlayerHistory, round_idx: int) -> float:
        """Get cooperation rate in the most recent previous round."""
        if round_idx <= 0:
            return 0.0
        cooperators = self._count_cooperators_in_round(history, round_idx - 1)
        return cooperators / self.n

    def _check_edge_cases(self, history: PlayerHistory, current_round: int) -> tuple[bool, bool]:
        """
        Check for edge cases:
        - Perfect defection (all defect in early rounds)
        - Perfect cooperation (all cooperate)
        Returns (perfect_defection, perfect_cooperation)
        """
        if current_round < 2:
            return (False, False)
        for i in range(min(2, current_round)):
            coop_count = self._count_cooperators_in_round(history, i)
            if coop_count < 1:
                return (True, False)
        for i in range(current_round):
            coop_count = self._count_cooperators_in_round(history, i)
            if coop_count == self.n:
                return (False, True)
        return (False, False)

    def _check_chaotic_behavior(self, history: PlayerHistory, current_round: int) -> bool:
        """
        Check if cooperation behavior is chaotic (high variance).
        Returns True if should increase defection propensity.
        """
        if current_round < 2:
            return False
        recent_rates = []
        for i in range(max(0, current_round - 3), current_round):
            rate = self._get_cooperation_rate(history, i)
            recent_rates.append(rate)
        if len(recent_rates) < 2:
            return False
        mean_rate = np.mean(recent_rates)
        if mean_rate == 0:
            return False
        std_dev = np.std(recent_rates)
        if std_dev > 0.35 * mean_rate:
            return True
        return False

    def _check_declining_trend(self, history: PlayerHistory, current_round: int) -> bool:
        """
        Check if cooperation rate is declining over 3+ consecutive rounds.
        """
        if current_round < 4:
            return False
        rates = []
        for i in range(max(0, current_round - 3), current_round):
            rate = self._get_recent_cooperation_rate(history, i)
            rates.append(rate)
        if len(rates) < 3:
            return False
        return rates[0] > rates[1] > rates[2]

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        perfect_defection, perfect_cooperation = self._check_edge_cases(history, current_round)
        if perfect_cooperation:
            return Action.C
        if perfect_defection:
            return Action.D
        chaotic = self._check_chaotic_behavior(history, current_round)
        if chaotic:
            recent_coop_count = self._count_cooperators_in_round(history, current_round - 1)
            return Action.C if recent_coop_count >= self.m else Action.D
        if self.n == 2:
            opponent_last = history.opponent_actions[current_round - 1, 0]
            return Action.C if opponent_last else Action.D
        if self.n == 3:
            recent_coop_count = self._count_cooperators_in_round(history, current_round - 1)
            return Action.C if recent_coop_count >= 2 else Action.D
        threshold = self.critical_threshold
        if self._check_declining_trend(history, current_round):
            threshold = min(1.0, threshold * 1.05)
        if current_round == self.r - 1:
            historical_coop = self._get_cooperation_rate(history, current_round - 1)
            return Action.C if historical_coop > 0.6 else Action.D
        if current_round == self.r - 1:
            avg_coop = self._get_cooperation_rate(history, current_round - 1)
            return Action.C if avg_coop >= threshold else Action.D
        recent_coop_rate = self._get_recent_cooperation_rate(history, current_round)
        recent_coop_count = self._count_cooperators_in_round(history, current_round - 1)
        if recent_coop_count == self.m - 1:
            return Action.D
        return Action.C if recent_coop_rate >= threshold else Action.D

class Strategy_COLLECTIVE_156(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Treats the game as a collective survival problem, balancing trust, accountability,
    and collective welfare through adaptive cooperation based on threshold viability.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == 1:
            cooperators_prev = int(sum(history.opponent_actions[0, :]))
            return Action.C
        if round_num == self.r - 1:
            total_cooperations = int(sum(history.my_actions[:-1]))
            historical_coop_rate = total_cooperations / (self.r - 1) if self.r > 1 else 0.0
            if historical_coop_rate >= 0.6:
                return Action.C
            else:
                return Action.D
        cooperators_last = int(sum(history.opponent_actions[round_num - 1, :]))
        defection_rate = 1.0 - cooperators_last / self.n
        rounds_remaining = self.r - round_num
        threshold_tolerance = (self.n - self.m) / (self.n - 1) if self.n > 1 else 0.0
        if self.k > 10:
            threshold_tolerance = 2.0 * threshold_tolerance
        elif self.k <= 2:
            threshold_tolerance = 0.5 * threshold_tolerance
        if cooperators_last >= self.m:
            if defection_rate <= threshold_tolerance:
                return Action.C
            else:
                return Action.D
        elif defection_rate > 0.5:
            return Action.D
        elif rounds_remaining >= 2:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_157(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual security with collective welfare by:
    1. Starting with cooperation to signal commitment
    2. Adapting to observed cooperation rates across three phases
    3. Protecting against exploitation while maintaining willingness to cooperate
    4. Handling edge cases (m=n, mâ‰¤2, etc.) with special logic
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.phase1_end = max(1, math.floor(self.r / 3))
        self.phase2_end = max(self.phase1_end + 1, math.floor(2 * self.r / 3))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if self.m == self.n:
            return self._handle_unanimous_threshold(history, round_num)
        if self.m <= 2:
            return Action.C
        if self._has_collective_collapse(history, round_num):
            return Action.D
        if round_num <= self.phase1_end:
            return self._phase1_decision(history, round_num)
        elif round_num <= self.phase2_end:
            return self._phase2_decision(history, round_num)
        else:
            return self._phase3_decision(history, round_num)

    def _get_recent_coop_rate(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate the average cooperation rate over the last 3 rounds,
        or all available rounds if fewer than 3 exist.
        """
        if round_num == 0:
            return 0.0
        start_idx = max(0, round_num - 3)
        end_idx = round_num
        cooperator_counts = []
        for idx in range(start_idx, end_idx):
            cooperators_in_round = np.sum(history.opponent_actions[idx, :])
            cooperator_counts.append(cooperators_in_round)
        if not cooperator_counts:
            return 0.0
        avg_cooperators = np.mean(cooperator_counts)
        return avg_cooperators / self.n

    def _get_last_round_coop_rate(self, history: PlayerHistory, round_num: int) -> float:
        """
        Get the cooperation rate from the immediately previous round.
        """
        if round_num <= 0:
            return 0.0
        cooperators = np.sum(history.opponent_actions[round_num - 1, :])
        return cooperators / self.n

    def _has_collective_collapse(self, history: PlayerHistory, round_num: int) -> bool:
        """
        Check if there was a round with 0 cooperators among opponents.
        If so, strategy switches to permanent defection.
        """
        if round_num == 0:
            return False
        for idx in range(round_num):
            cooperators = np.sum(history.opponent_actions[idx, :])
            if cooperators == 0:
                return True
        return False

    def _handle_unanimous_threshold(self, history: PlayerHistory, round_num: int) -> Action:
        """
        Special handling when m = n (everyone must cooperate).
        Test commitment in first few rounds, then switch to defect if anyone defects.
        """
        if round_num <= 1:
            return Action.C
        for idx in range(round_num):
            cooperators = np.sum(history.opponent_actions[idx, :])
            if cooperators < self.n - 1:
                return Action.D
            if not history.my_actions[idx]:
                return Action.D
        return Action.C

    def _phase1_decision(self, history: PlayerHistory, round_num: int) -> Action:
        """
        Phase 1: Opening rounds (1 to floor(r/3))
        Track cooperation rate; cooperate if rate >= m/n, else defect.
        """
        coop_rate = self._get_last_round_coop_rate(history, round_num)
        threshold = self.m / self.n
        if coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _phase2_decision(self, history: PlayerHistory, round_num: int) -> Action:
        """
        Phase 2: Middle rounds (floor(r/3)+1 to floor(2r/3))
        Use probabilistic cooperation based on recent cooperation momentum.
        """
        recent_coop_rate = self._get_recent_coop_rate(history, round_num)
        threshold = self.m / self.n
        if recent_coop_rate >= 0.9 * threshold:
            return Action.C
        elif recent_coop_rate >= 0.7 * threshold:
            prob = recent_coop_rate / threshold if threshold > 0 else 0.0
            if random.random() < prob:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _phase3_decision(self, history: PlayerHistory, round_num: int) -> Action:
        """
        Phase 3: Closing rounds (floor(2r/3)+1 to r)
        Stricter decision: cooperate only if recent coop rate >= 0.85 * (m/n).
        """
        recent_coop_rate = self._get_recent_coop_rate(history, round_num)
        threshold = self.m / self.n
        if recent_coop_rate >= 0.85 * threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_158(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances collective success with individual security by:
    1. Cooperating in round 1 to establish cooperative baseline
    2. Monitoring cooperation rates and defection patterns
    3. Dynamically adjusting based on threshold feasibility and exploitation detection
    4. Defecting in final round (individually rational)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number + 1
        if t == 1:
            return Action.C
        if t == self.r:
            return Action.D
        cooperators_by_round = np.sum(history.opponent_actions, axis=1)
        cooperators_by_round = np.concatenate([history.my_actions[:t - 1].astype(np.int64) + cooperators_by_round])
        total_cooperations = np.sum(cooperators_by_round[:t - 1])
        historical_coop_rate = total_cooperations / (self.n * (t - 1)) if t > 1 else 0.0
        cooperators_last_round = int(np.sum(history.opponent_actions[t - 2, :])) + int(history.my_actions[t - 2])
        defectors_last_round = self.n - cooperators_last_round
        current_defection_rate = defectors_last_round / self.n if self.n > 0 else 0.0
        cooperators_needed = self.m - cooperators_last_round
        rounds_remaining = self.r - t
        momentum_threshold = 0.8 * (self.m / self.n)
        if historical_coop_rate >= momentum_threshold:
            return Action.C
        if cooperators_needed <= rounds_remaining and historical_coop_rate >= 0.5:
            return Action.C
        expected_defection_ceiling = (self.n - self.m) / self.n if self.n > self.m else 0.0
        exploitation_threshold = 1.5 * expected_defection_ceiling
        if current_defection_rate > exploitation_threshold:
            return Action.D
        return Action.C

class Strategy_COLLECTIVE_159(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances collective welfare maximization with protection against exploitation.
    Core insight: cooperation becomes individually rational once m-1 others cooperate.
    Strategy seeks to break into cooperation cycles through adaptive signaling.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.n_rounds - 1:
            return Action.D
        coop_prev = self._calculate_cooperation_rate(history, round_num - 1)
        threshold_rate = (self.m - 1) / self.n_players
        if coop_prev >= threshold_rate:
            return Action.C
        if coop_prev >= threshold_rate - 0.15:
            p_cooperate = threshold_rate + 0.1
            return Action.C if random.random() < p_cooperate else Action.D
        trend = self._calculate_trend(history, round_num)
        if trend > 0:
            return Action.C
        return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_idx: int) -> float:
        """Calculate the proportion of opponents who cooperated in a given round."""
        if round_idx < 0 or round_idx >= len(history.opponent_actions):
            return 0.0
        cooperators = sum(history.opponent_actions[round_idx, :])
        return cooperators / self.n_players if self.n_players > 0 else 0.0

    def _calculate_trend(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate trend of cooperation rates over past 3 rounds.
        Returns positive if trending upward, negative if trending downward.
        """
        coop_rates = []
        for i in range(max(0, current_round - 3), current_round):
            if i >= 0 and i < len(history.opponent_actions):
                coop_rates.append(self._calculate_cooperation_rate(history, i))
        if len(coop_rates) < 2:
            return 0.0
        if len(coop_rates) == 2:
            return coop_rates[1] - coop_rates[0]
        slopes = [coop_rates[i + 1] - coop_rates[i] for i in range(len(coop_rates) - 1)]
        avg_slope = sum(slopes) / len(slopes) if slopes else 0.0
        return avg_slope

class Strategy_COLLECTIVE_160(BaseStrategy):
    """
    Adaptive Threshold Monitoring Strategy (ATMS)
    
    Balances individual security with collective benefit through dynamic risk assessment.
    Monitors whether cooperation reaches the threshold and adjusts participation accordingly.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            threshold_ratio = self.m / self.n
            if threshold_ratio <= 0.5:
                return Action.C
            else:
                return Action.D
        if current_round == self.r - 1:
            cooperators_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
            if cooperators_last_round >= self.m:
                return Action.C
            else:
                return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
        if cooperators_last_round >= self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_161(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances individual security with collective value creation by:
    1. Cooperating at a baseline probability based on game parameters in round 1
    2. Adapting cooperation probability based on observed cooperation rates
    3. Detecting and penalizing systematic exploiters
    4. Handling edge cases (unanimous cooperation/defection)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.opponent_defection_count = [0] * (self.n - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            baseline_prob = self.m / self.n * (self.k / (self.k + 1))
            return Action.C if random.random() < baseline_prob else Action.D
        total_cooperations = np.sum(history.opponent_actions)
        total_actions = self.n * state.round_number
        total_possible_cooperations = (self.n - 1) * state.round_number
        if total_possible_cooperations == 0:
            observed_coop_rate = 0.0
        else:
            observed_coop_rate = total_cooperations / total_possible_cooperations
        if observed_coop_rate == 0:
            return Action.D
        if observed_coop_rate == 1.0:
            return Action.C
        if state.round_number > 0:
            most_recent_opponent_cooperations = np.sum(history.opponent_actions[state.round_number - 1, :])
            threshold_met = most_recent_opponent_cooperations >= self.m - 1
            if threshold_met:
                for opponent_idx in range(self.n - 1):
                    if not history.opponent_actions[state.round_number - 1, opponent_idx]:
                        self.opponent_defection_count[opponent_idx] += 1
        exploitation_penalty = 0.0
        exploitation_threshold = self.r / 3
        for defect_count in self.opponent_defection_count:
            if defect_count > exploitation_threshold:
                exploitation_penalty += 0.1
        threshold_ratio = self.m / self.n
        if observed_coop_rate >= threshold_ratio:
            coop_prob = min(observed_coop_rate * 1.1, 1.0)
        else:
            coop_prob = threshold_ratio * (self.k / (self.k + 1))
        coop_prob = coop_prob - exploitation_penalty
        coop_prob = max(0.0, min(1.0, coop_prob))
        return Action.C if random.random() < coop_prob else Action.D

class Strategy_COLLECTIVE_162(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Dynamically adjusts cooperation based on observed cooperation rates and game phase.
    Balances individual security with collective benefit through three distinct periods:
    - Early Game: Probe collective willingness with strategic second chances
    - Middle Game: Establish stable cooperation or exploitation-resistant defection
    - End Game: Maximize personal payoff based on threshold achievability
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.early_phase_end = math.ceil(self.r / 3)
        self.middle_phase_end = math.ceil(2 * self.r / 3)
        if self.k < 1.5:
            self.threshold_multiplier = 0.6
        else:
            self.threshold_multiplier = 0.75

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if self.r == 1:
            threshold_rate = self.m / self.n
            if threshold_rate <= 0.5:
                return Action.C
            else:
                return Action.D
        prev_round_cooperators = int(np.sum(history.opponent_actions[round_num - 1, :]))
        cooperation_rate = prev_round_cooperators / self.n
        threshold_rate = self.m / self.n
        if round_num <= self.early_phase_end:
            return self._early_game_decision(round_num, cooperation_rate, threshold_rate)
        elif round_num <= self.middle_phase_end:
            return self._middle_game_decision(cooperation_rate, threshold_rate)
        else:
            return self._end_game_decision(cooperation_rate, threshold_rate)

    def _early_game_decision(self, round_num: int, cooperation_rate: float, threshold_rate: float) -> Action:
        """
        Early Game (rounds 1 to âŒˆr/3âŒ‰): Probe collective willingness.
        Give a second chance if cooperation is zero.
        """
        if round_num == 1 and cooperation_rate == 0:
            return Action.C
        if cooperation_rate >= threshold_rate:
            return Action.C
        elif cooperation_rate > 0:
            return Action.D
        else:
            return Action.D

    def _middle_game_decision(self, cooperation_rate: float, threshold_rate: float) -> Action:
        """
        Middle Game (rounds âŒˆr/3âŒ‰ + 1 to âŒˆ2r/3âŒ‰): Establish stable cooperation or exit.
        Make final push toward cooperation if close to threshold.
        """
        if cooperation_rate >= threshold_rate:
            return Action.C
        elif cooperation_rate >= threshold_rate * self.threshold_multiplier:
            return Action.C
        else:
            return Action.D

    def _end_game_decision(self, cooperation_rate: float, threshold_rate: float) -> Action:
        """
        End Game (rounds âŒˆ2r/3âŒ‰ + 1 to r): Maximize personal payoff.
        Only cooperate if threshold will be met based on previous round.
        """
        if cooperation_rate >= threshold_rate:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_163(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Cooperating unconditionally in round 1 to initiate momentum
    2. Maintaining cooperation in round 2 if previously cooperated
    3. Using a declining adaptive threshold in subsequent rounds
    4. Defecting when observed cooperation falls below the threshold
    
    The adaptive threshold decreases as the game progresses, allowing the strategy
    to salvage collective gains in later rounds while maintaining discipline early on.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == 1:
            if history.my_actions[0]:
                return Action.C
            else:
                return Action.D
        prev_round_idx = round_number - 1
        cooperators_prev = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            cooperators_prev += 1
        progress_ratio = round_number / self.n_rounds
        decline_factor = (1.0 - progress_ratio) * (self.m - 1)
        theta_t = max(1, self.m - math.floor(decline_factor))
        if cooperators_prev >= theta_t:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_164(BaseStrategy):
    """
    Adaptive Threshold Sentinel Strategy for Collective Risk Dilemma.
    
    Balances proactive contribution with defensive monitoring, adapting based on
    empirical evidence of other players' commitment to reach the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.cooperation_history = []
        self.threshold_met_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            if len(self.threshold_met_history) > 0 and self.threshold_met_history[-1]:
                return Action.C
            else:
                return Action.D
        prev_round_cooperators = int(np.sum(history.opponent_actions[round_num - 1, :]))
        if history.my_actions[round_num - 1]:
            prev_round_cooperators += 1
        c_rate = prev_round_cooperators / self.n
        expected_coop = c_rate * self.n
        threshold_met = prev_round_cooperators >= self.m
        self.threshold_met_history.append(threshold_met)
        self.cooperation_history.append(prev_round_cooperators)
        buffer = self._compute_buffer(round_num)
        if expected_coop >= self.m:
            return Action.C
        deficit = self.m - expected_coop
        if deficit <= buffer:
            return Action.C
        if round_num >= 2 and len(self.cooperation_history) >= 2:
            if self.cooperation_history[-1] == 0 and self.cooperation_history[-2] == 0:
                return Action.D
        return Action.D

    def _compute_buffer(self, round_num: int) -> float:
        """Compute the cooperation buffer based on edge cases and adaptive learning."""
        if self.n == 2:
            base_buffer = 0.5 * self.n
        elif self.m == self.n:
            base_buffer = 0.1 * self.n
        elif self.m <= 2:
            base_buffer = 0.4 * self.n
        else:
            base_buffer = 0.25 * self.n
        if round_num >= 4 and len(self.cooperation_history) >= 3:
            avg_last_2 = np.mean(self.cooperation_history[-2:])
            avg_last_3 = np.mean(self.cooperation_history[-3:])
            if avg_last_2 < self.m:
                base_buffer = max(0.15 * self.n, base_buffer * 0.6)
            elif avg_last_3 >= self.m:
                base_buffer = min(0.35 * self.n, base_buffer * 1.4)
        return base_buffer

class Strategy_COLLECTIVE_165(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances collective welfare with individual security by:
    1. Cooperating initially to establish cooperative intent
    2. Dynamically tracking cooperation feasibility via threshold analysis
    3. Shifting to defection when cooperation becomes unachievable
    4. Maintaining reciprocal discipline while avoiding exploitation
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number + 1
        if round_t == 1:
            return Action.C
        if round_t == self.r:
            cooperators_last_round = int(sum(history.opponent_actions[-1, :]))
            if cooperators_last_round >= self.m - 1:
                return Action.C
            else:
                return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[-1, :]))
        coop_rate = cooperators_last_round / self.n
        efficiency_factor = min(1.2, (self.r - round_t) / self.r + 0.1)
        threshold = self.m / self.n * efficiency_factor
        if coop_rate >= threshold:
            return Action.C
        elif coop_rate >= self.m / self.n * 0.5:
            trend = self._analyze_trend(history, round_t)
            return Action.C if trend == 'improving' else Action.D
        else:
            return Action.D

    def _analyze_trend(self, history: PlayerHistory, round_t: int) -> str:
        """
        Analyze cooperation trend from recent rounds.
        
        Returns 'improving' if recent cooperation rate >= previous average,
        otherwise returns 'declining'.
        """
        rounds_available = round_t - 1
        if rounds_available < 3:
            return 'improving'
        rates = []
        for i in range(-3, 0):
            cooperators = int(sum(history.opponent_actions[i, :]))
            rate = cooperators / self.n
            rates.append(rate)
        recent = rates[-1]
        previous_avg = (rates[0] + rates[1]) / 2.0
        return 'improving' if recent >= previous_avg else 'declining'

class Strategy_COLLECTIVE_166(BaseStrategy):
    """
    Adaptive Threshold Commitment (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare through three phases:
    1. Early Exploration: Signal willingness and test others' commitment
    2. Commitment Deepening: Build toward threshold with reciprocity
    3. Endgame: Defect when threshold secure, cooperate when at risk
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        phase1_end = math.ceil(self.r / 3)
        phase2_end = math.floor(2 * self.r / 3)
        if current_round <= phase1_end:
            return self._phase1_decision(current_round, history)
        elif current_round <= phase2_end:
            return self._phase2_decision(current_round, history)
        else:
            return self._phase3_decision(current_round, history)

    def _phase1_decision(self, current_round: int, history: PlayerHistory) -> Action:
        """Early exploration phase: test cooperation commitment."""
        total_cooperators = np.sum(history.opponent_actions)
        total_possible = current_round * self.n
        if total_possible == 0:
            return Action.C
        observed_cooperation_rate = total_cooperators / total_possible
        threshold_commitment = self.m / self.n
        if observed_cooperation_rate >= threshold_commitment * 1.2:
            return Action.C
        elif observed_cooperation_rate >= threshold_commitment * 0.8:
            match_probability = observed_cooperation_rate / threshold_commitment
            return Action.C if random.random() < match_probability else Action.D
        else:
            return Action.D

    def _phase2_decision(self, current_round: int, history: PlayerHistory) -> Action:
        """Commitment deepening phase: build toward threshold."""
        rounds_remaining = self.r - current_round
        recent_window = min(3, current_round)
        recent_cooperators = np.sum(history.opponent_actions[-recent_window:, :])
        cooperation_deficit = self.m - recent_cooperators
        if cooperation_deficit <= 0:
            return Action.C
        if cooperation_deficit > 0:
            any_cooperated = np.any(history.opponent_actions, axis=0)
            active_cooperative_players = np.sum(any_cooperated)
            if active_cooperative_players == 0:
                return Action.D
            if cooperation_deficit <= rounds_remaining * active_cooperative_players:
                return Action.C
            else:
                return Action.D
        return Action.D

    def _phase3_decision(self, current_round: int, history: PlayerHistory) -> Action:
        """Endgame phase: maximize individual payoff while respecting threshold."""
        rounds_remaining = self.r - current_round
        if current_round == self.r - 1:
            recent_cooperators = np.sum(history.opponent_actions[-1, :])
            if recent_cooperators >= self.m:
                return Action.D
            elif recent_cooperators >= self.m - 1:
                return Action.C
            else:
                return Action.D
        else:
            recent_cooperators = np.sum(history.opponent_actions[-1, :]) if current_round > 0 else 0
            cooperators_needed = self.m - recent_cooperators
            if cooperators_needed <= 0:
                return Action.C
            if cooperators_needed <= rounds_remaining:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_167(BaseStrategy):
    """
    Adaptive Threshold Commitment strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by adapting cooperation
    probability based on historical cooperation rates and round position, aiming to
    achieve and maintain the threshold m while avoiding exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            target = max(self.m / self.n, min(self.m / self.n * 1.2, 1.0))
            coop_prob = target
            return Action.C if random.random() < coop_prob else Action.D
        hcr = self._calculate_historical_cooperation_rate(history, round_t)
        threshold_ratio = self.m / self.n
        target_cooperation = max(threshold_ratio, min(threshold_ratio * 1.2, 1.0))
        base_probability = target_cooperation
        if hcr >= target_cooperation:
            adjusted_prob = base_probability * 1.1
        elif hcr >= target_cooperation * 0.8:
            adjusted_prob = base_probability
        else:
            adjusted_prob = min(base_probability * 1.3, 0.95)
        if hcr < 0.3 * target_cooperation:
            adjusted_prob = 0.85
        elif hcr > 1.1 * target_cooperation:
            adjusted_prob = 0.7
        if round_t == self.r - 1:
            adjusted_prob = max(adjusted_prob - 0.15, 0)
        final_prob = max(0, min(adjusted_prob, 0.95))
        return Action.C if random.random() < final_prob else Action.D

    def _calculate_historical_cooperation_rate(self, history: PlayerHistory, round_t: int) -> float:
        """
        Calculate the historical cooperation rate of other players.
        
        HCR = (total cooperations by other players in past rounds) / 
              ((t) * (n-1))
        
        Returns a value in [0, 1].
        """
        if round_t <= 0:
            return 0.5
        total_cooperations = np.sum(history.opponent_actions[:round_t, :])
        total_possible = round_t * (self.n - 1)
        if total_possible == 0:
            return 0.5
        hcr = total_cooperations / total_possible
        return hcr

class Strategy_COLLECTIVE_168(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances individual security with collective welfare by dynamically adjusting
    cooperation based on historical cooperation rates, threshold likelihood,
    temporal urgency, and collective pressure.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.cooperation_rate_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            cooperation_rate = 0.5
            threshold_target = (self.m - 1) / (self.n_players - 1)
            if self.m <= self.n_players / 2:
                return Action.C
            else:
                return Action.D
        cooperation_rate = self._calculate_cooperation_rate(history, current_round)
        self.cooperation_rate_history.append(cooperation_rate)
        rounds_remaining = self.n_rounds - current_round
        threshold_target = (self.m - 1) / (self.n_players - 1)
        if rounds_remaining == 1:
            return Action.D
        if cooperation_rate >= threshold_target:
            return Action.C
        else:
            coop_probability = max(0, 2 * (cooperation_rate - 0.33))
            coop_probability = min(coop_probability, 0.6)
            if random.random() <= coop_probability:
                return Action.C
            else:
                return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the historical cooperation rate of other players.
        
        cooperation_rate = (observed cooperations) / (total possible cooperations)
        """
        if current_round <= 0:
            return 0.5
        cooperators_observed = 0
        total_observations = 0
        for round_idx in range(current_round):
            cooperators_in_round = int(np.sum(history.opponent_actions[round_idx, :]))
            cooperators_observed += cooperators_in_round
            total_observations += self.n_players - 1
        if total_observations == 0:
            return 0.5
        cooperation_rate = cooperators_observed / total_observations
        return cooperation_rate

class Strategy_COLLECTIVE_169(BaseStrategy):
    """
    Adaptive Threshold Reciprocity Strategy (ATRS) for Collective Risk Dilemma.
    
    Maximizes collective welfare through:
    1. Initial cooperation to signal trustworthiness
    2. Responsive adaptation to demonstrated cooperation patterns
    3. Protection against exploitation while remaining open to mutual benefit
    4. Dynamic threshold adjustment based on observed behavior
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defection_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        previous_round_idx = current_round - 1
        opponent_cooperators = int(sum(history.opponent_actions[previous_round_idx, :]))
        my_previous_action = history.my_actions[previous_round_idx]
        total_cooperators = opponent_cooperators + (1 if my_previous_action else 0)
        if current_round == r - 1:
            if total_cooperators >= m:
                return Action.C
            else:
                return Action.D
        coop_ratio = total_cooperators / n
        threshold_ratio = m / n
        if total_cooperators < m:
            self.defection_streak += 1
        else:
            self.defection_streak = 0
        required_threshold = m
        if self.defection_streak >= 2:
            required_threshold = m + 1
        if total_cooperators >= required_threshold:
            return Action.C
        elif total_cooperators >= math.ceil(threshold_ratio * n * 0.5):
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_170(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS) for Collective Risk Dilemma.
    
    Dynamically adjusts cooperation based on observed cooperation rates, the critical
    threshold (m cooperators needed), and round position. Leads with cooperation in
    round 1, applies adaptive logic in middle rounds, and defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            return Action.D
        previous_round_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        previous_round_cooperators += int(history.my_actions[current_round - 1])
        cooperation_rate = previous_round_cooperators / self.n
        threshold_ratio = self.m / self.n
        if cooperation_rate >= threshold_ratio:
            return Action.C
        rounds_remaining = self.r - current_round
        if rounds_remaining <= 2:
            return Action.D
        if cooperation_rate >= threshold_ratio * 0.5:
            probability = cooperation_rate / threshold_ratio
            if random.random() < probability:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_171(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS) for Collective Risk Dilemma.
    
    Treats the game as a progressive trust-building problem with adaptive risk management.
    Cooperates in round 1, then uses threshold-responsive rules based on observed cooperation
    in previous rounds. Near the end, switches to defection-only mode if threshold seems unattainable.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        previous_round_idx = round_num - 1
        previous_cooperators = int(np.sum(history.opponent_actions[previous_round_idx, :]))
        if round_num == self.r - 1:
            if previous_cooperators >= self.m:
                return Action.C
            elif previous_cooperators >= math.ceil(self.m / self.n * self.n) - 1:
                return Action.C
            else:
                return Action.D
        else:
            if previous_cooperators >= self.m:
                return Action.C
            threshold_ceiling = math.ceil(self.m / self.n * self.n) - 1
            if previous_cooperators >= threshold_ceiling:
                return Action.C
            half_threshold = math.ceil(0.5 * self.m)
            if previous_cooperators >= half_threshold:
                probability = previous_cooperators / self.m
                if random.random() < probability:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D

class Strategy_COLLECTIVE_172(BaseStrategy):
    """
    Adaptive Threshold Monitoring strategy for Collective Risk Dilemma.
    
    Balances collective welfare with individual security by:
    1. Unconditionally cooperating in round 1 to establish good faith
    2. Unconditionally defecting in the final round (no future punishment)
    3. Dynamically adjusting cooperation in middle rounds based on observed cooperation rates
    4. Using probabilistic cooperation when cooperation is borderline
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        prev_round_idx = state.round_number - 1
        cooperators_prev_round = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        n = self.game_description.n_players
        m = self.game_description.m
        if n == 0:
            return Action.D
        cooperation_rate = cooperators_prev_round / n
        threshold_rate = m / n
        if cooperation_rate >= threshold_rate:
            return Action.C
        elif cooperation_rate >= threshold_rate * 0.6:
            p_increase = min(0.8, 1.0 - cooperation_rate)
            if random.random() < p_increase:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_173(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual safety with collective success by:
    1. Promoting group welfare when cooperation levels support it
    2. Protecting against exploitation through conditional defection
    3. Adapting dynamically to observed cooperation rates
    4. Implementing a recovery protocol after cooperation failures
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_failure_round = -10

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        m = self.game_description.m
        if state.round_number == 0:
            threshold_ratio = (m - 1) / n
            if threshold_ratio < 0.5:
                return Action.C
            else:
                return Action.D
        if state.round_number == r - 1:
            prev_cooperators = int(sum(history.opponent_actions[-1, :]))
            if prev_cooperators >= m - 1:
                return Action.C
            else:
                return Action.D
        prev_cooperators = int(sum(history.opponent_actions[-1, :]))
        cooperation_rate = prev_cooperators / n
        epsilon = (r - state.round_number) / (2 * r)
        threshold = (m - 1 + epsilon) / n
        if self._should_explore_recovery(state.round_number):
            recovery_probability = state.round_number / r
            if random.random() < recovery_probability:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= threshold:
            return Action.C
        else:
            self.last_failure_round = state.round_number
            return Action.D

    def _should_explore_recovery(self, current_round: int) -> bool:
        """
        Determine if we should attempt recovery after a cooperation failure.
        
        Recovery is attempted for 1-2 rounds after failure, but only if:
        - Failure occurred in a recent round
        - We're not in the final 2 rounds
        - Not too much time has passed since failure
        """
        if self.last_failure_round < 0:
            return False
        rounds_since_failure = current_round - self.last_failure_round
        rounds_until_end = self.game_description.n_rounds - current_round
        if rounds_since_failure <= 2 and rounds_until_end > 2:
            return True
        return False

class Strategy_COLLECTIVE_174(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual security with collective welfare through:
    1. Reciprocal conditional cooperation - matching community participation
    2. Dynamic threshold adjustment - learning sustainable participation rates
    3. Credible commitment - building reputation through consistent behavior
    4. Graceful degradation - maintaining cooperation until clear defection patterns emerge
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.confidence = 2
        self.last_cooperation_rate = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        prev_round_idx = state.round_number - 1
        opponent_cooperators = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        self_cooperated = 1 if history.my_actions[prev_round_idx] else 0
        total_cooperators = opponent_cooperators + self_cooperated
        cooperation_rate = total_cooperators / n
        threshold_rate = m / n
        if n == 0:
            return Action.D
        if m == n:
            if cooperation_rate >= threshold_rate:
                self.confidence = min(3, self.confidence + 1)
                return Action.C
            else:
                self.confidence = 0
                return Action.D
        if m == 2 and n > 2:
            self.confidence = 3
        if cooperation_rate >= threshold_rate:
            self.confidence = min(3, self.confidence + 1)
            self.last_cooperation_rate = cooperation_rate
            return Action.C
        elif cooperation_rate >= threshold_rate * 0.75:
            if self.confidence > 0:
                self.confidence -= 1
                self.last_cooperation_rate = cooperation_rate
                return Action.C
            else:
                self.last_cooperation_rate = cooperation_rate
                return Action.D
        elif cooperation_rate >= threshold_rate * 0.5:
            self.confidence = 0
            self.last_cooperation_rate = cooperation_rate
            return Action.D
        else:
            self.confidence = 0
            self.last_cooperation_rate = cooperation_rate
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            threshold_rate = m / n
            if self.last_cooperation_rate < threshold_rate:
                if self.confidence > 1:
                    return Action.C
                else:
                    return Action.D
        return Action.C

class Strategy_COLLECTIVE_175(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Cooperates in round 1 to probe for collective viability.
    In rounds 2 to r-1, cooperates if observed cooperators in previous round >= m-1.
    Defects in the final round (round r-1 in 0-indexed).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.n_rounds - 1:
            return Action.D
        previous_round_index = round_number - 1
        cooperators_last_round = int(sum(history.opponent_actions[previous_round_index, :]))
        if cooperators_last_round >= self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_176(BaseStrategy):
    """
    Adaptive Threshold Cooperation for Collective Risk Dilemma.
    
    Balances collective welfare and individual rationality by:
    1. Probing cooperation in round 1
    2. Adapting mid-game based on observed cooperation levels relative to threshold
    3. Making end-game decisions based on proximity to threshold
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        c_prev = int(sum(history.opponent_actions[round_num - 1, :]))
        remaining_rounds = self.n_rounds - round_num
        if round_num == self.n_rounds - 1:
            if c_prev >= self.m - 1:
                return Action.C
            else:
                return Action.D
        if c_prev >= self.m:
            return Action.C
        if c_prev == self.m - 1:
            return Action.C
        half_threshold = math.ceil(self.m / 2.0)
        if c_prev >= half_threshold and remaining_rounds >= 2:
            return Action.C
        if c_prev < half_threshold and c_prev > 0:
            return Action.D
        if c_prev == 0:
            return Action.D
        return Action.D

class Strategy_COLLECTIVE_177(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual security with collective welfare by monitoring cooperation rates,
    adapting contribution based on observed trends, and maintaining the minimum viable
    cooperation level while gracefully degrading when cooperation becomes unsustainable.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        cooperators_last_round = int(np.sum(history.opponent_actions[round_number - 1, :]))
        if history.my_actions[round_number - 1]:
            cooperators_last_round += 1
        deficit = self.m - cooperators_last_round
        if cooperators_last_round < self.m:
            threshold_bridgeable = deficit <= math.ceil(self.n * 0.15)
            if threshold_bridgeable:
                return Action.C
            else:
                return Action.D
        if cooperators_last_round >= self.m:
            cooperation_declining = False
            if round_number >= 2:
                cooperators_t_minus_2 = int(np.sum(history.opponent_actions[round_number - 2, :]))
                if history.my_actions[round_number - 2]:
                    cooperators_t_minus_2 += 1
                cooperation_declining = cooperators_last_round < cooperators_t_minus_2
            if round_number > self.r - 2:
                if cooperators_last_round >= self.m + 1:
                    return Action.C
                elif cooperators_last_round == self.m:
                    return Action.C
                else:
                    return Action.D
            if cooperation_declining and cooperators_last_round <= self.m + 1:
                return Action.D
            else:
                return Action.C
        return Action.C

class Strategy_COLLECTIVE_178(BaseStrategy):
    """
    Adaptive Threshold Monitoring strategy for Collective Risk Dilemma.
    
    Balances individual security with collective welfare by cooperating when
    the probability of reaching the cooperation threshold (m) is sufficiently high.
    Uses historical cooperation rates to make adaptive decisions across rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        num_rounds_completed = round_num
        cooperators_per_round = np.sum(history.opponent_actions, axis=1) + history.my_actions
        avg_cooperators = np.mean(cooperators_per_round[:round_num])
        cooperation_rate = avg_cooperators / self.n
        threshold_met_count = np.sum(cooperators_per_round[:round_num] >= self.m)
        threshold_reliability = threshold_met_count / max(1, round_num)
        if round_num == self.r - 1:
            if avg_cooperators >= self.m - 1:
                return Action.C
            elif avg_cooperators >= self.m - 1.5:
                return Action.C
            else:
                return Action.D
        threshold_required_high = (self.m - 1) / self.n
        threshold_required_medium = (self.m - 2) / self.n
        threshold_required_medium_high = (self.m - 1.5) / self.n
        threshold_required_low = (self.m - 0.5) / self.n
        if cooperation_rate >= threshold_required_high:
            return Action.C
        elif cooperation_rate >= threshold_required_medium and threshold_reliability >= 0.5:
            return Action.C
        elif round_num <= self.r / 2:
            if cooperation_rate >= threshold_required_medium_high:
                return Action.C
            else:
                return Action.D
        elif cooperation_rate >= threshold_required_low:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_179(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Dynamically adjusts cooperation based on observed collective behavior and game progress.
    Cooperates when the threshold appears achievable, defects when it's demonstrably unattainable,
    and applies special endgame logic in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = []
        self.threshold_breaches = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        m = self.game_description.m
        if state.round_number == 0:
            return Action.C
        prev_round_idx = state.round_number - 1
        cooperators_prev = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        cooperation_rate = cooperators_prev / (n - 1) if n > 1 else 0.0
        threshold_rate = (m - 1) / (n - 1) if n > 1 else 0.0
        total_cooperators_prev = cooperators_prev + int(history.my_actions[prev_round_idx])
        if total_cooperators_prev >= m:
            self.threshold_breaches += 1
        rounds_remaining = r - state.round_number
        if state.round_number == r - 1:
            breach_ratio = self.threshold_breaches / (r - 1) if r > 1 else 0.0
            if breach_ratio >= 0.5:
                return Action.C
            if cooperation_rate >= threshold_rate:
                return Action.C
            return Action.D
        trend = 0.0
        if state.round_number >= 2:
            prev_prev_idx = state.round_number - 2
            cooperators_prev_prev = int(np.sum(history.opponent_actions[prev_prev_idx, :]))
            cooperation_rate_prev_prev = cooperators_prev_prev / (n - 1) if n > 1 else 0.0
            trend = cooperation_rate - cooperation_rate_prev_prev
        if cooperators_prev == 0 and state.round_number >= 2:
            return Action.D
        if cooperation_rate >= threshold_rate:
            return Action.C
        if cooperation_rate >= threshold_rate - 0.15 and trend >= 0:
            return Action.C
        if cooperation_rate < threshold_rate - 0.3 and rounds_remaining >= 3:
            return Action.D
        return Action.C

class Strategy_COLLECTIVE_180(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Recognizes that cooperation only yields collective benefit when participation
    reaches a critical threshold m/n. The strategy adapts to observed cooperation
    rates and distinguishes between failure modes to calibrate contribution likelihood.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold_ratio = self.m / self.n
        self.threshold_tolerance = (self.m - 1) / self.n
        self.p_base = min(1.0, self.threshold_ratio + 0.15)
        self.p_high = min(1.0, self.threshold_ratio + 0.35)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            coop_prob = self.threshold_ratio
            return Action.C if random.random() <= coop_prob else Action.D
        prev_round_idx = current_round - 1
        my_prev_action = history.my_actions[prev_round_idx]
        opponent_prev_actions = history.opponent_actions[prev_round_idx, :]
        cooperators_prev = int(my_prev_action) + np.sum(opponent_prev_actions)
        coop_rate_prev = cooperators_prev / self.n
        if current_round < self.r - 1:
            if coop_rate_prev >= self.threshold_ratio:
                return Action.C
            elif coop_rate_prev >= self.threshold_tolerance:
                coop_prob = self.p_high
            else:
                coop_prob = self.p_base
            return Action.C if random.random() <= coop_prob else Action.D
        if current_round == self.r - 1:
            if coop_rate_prev >= self.threshold_ratio:
                return Action.C
            else:
                coop_prob = min(0.9, self.threshold_ratio + 0.4)
                return Action.C if random.random() <= coop_prob else Action.D
        return Action.D

class Strategy_COLLECTIVE_181(BaseStrategy):
    """
    Adaptive Threshold Reciprocity strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Starting with cooperation to signal trustworthiness
    2. Conditionally cooperating based on whether the threshold was met
    3. Using adaptive probability-matching when close to threshold
    4. Defecting only when cooperation has completely collapsed
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round_idx = state.round_number - 1
        cooperators_prev = int(sum(history.opponent_actions[prev_round_idx, :]))
        is_final_round = state.round_number == self.r - 1
        if cooperators_prev >= self.m:
            return Action.C
        elif cooperators_prev == 0:
            return Action.D
        else:
            if is_final_round:
                p_cooperate = 0.8
            else:
                p_adjust = 1.0 - (self.m - cooperators_prev) / self.m
                if self.m == self.n:
                    p_adjust = min(p_adjust * 1.3, 1.0)
                elif self.m == 2 and cooperators_prev == 1:
                    p_adjust = 0.9
                p_cooperate = min(p_adjust, 1.0)
            if random.random() < p_cooperate:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_182(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Cooperating in round 1 to signal good faith
    2. Adapting based on observed cooperation rate vs. threshold
    3. Using a 0.75 buffer zone for near-miss scenarios (90% cooperation probability)
    4. Defecting decisively if threshold is far from met
    5. Preserving success in the final round if threshold was met previously
    6. Defaulting to defection in final round if cooperation already failed
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_rate = self.m / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        prev_round_idx = round_t - 1
        cooperators_prev_round = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        coop_rate = cooperators_prev_round / self.n_players
        if round_t == self.n_rounds - 1:
            if coop_rate >= self.threshold_rate:
                return Action.C
            else:
                return Action.D
        if coop_rate >= self.threshold_rate:
            return Action.C
        elif coop_rate >= self.threshold_rate * 0.75:
            if random.random() < 0.9:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_183(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    This strategy recognizes that cooperation is only valuable if the threshold m is met.
    It estimates the likelihood that other players will cooperate based on observed history,
    and cooperates if the expected number of cooperators (including itself) reaches the threshold.
    
    Core decision rule: Cooperate if expected_cooperators >= m + buffer
    where expected_cooperators = observed_cooperation_rate * (n - 1) + 1
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            if self.m <= (self.n_players + 1) / 2:
                return Action.C
            else:
                return Action.D
        total_cooperations = np.sum(history.opponent_actions[:round_number, :])
        total_cooperations += np.sum(history.my_actions[:round_number])
        total_observations = self.n_players * round_number
        if total_observations == 0:
            observed_cooperation_rate = 0.5
        else:
            observed_cooperation_rate = total_cooperations / total_observations
        expected_other_cooperators = observed_cooperation_rate * (self.n_players - 1)
        expected_total_cooperators = expected_other_cooperators + 1
        rate_deviation = observed_cooperation_rate - 0.5
        buffer = 1 - rate_deviation ** 2
        threshold_adjusted = self.m + buffer
        if expected_total_cooperators >= threshold_adjusted:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_184(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Dynamically adjusts cooperation based on observed cooperation rates and expected
    cooperators in the next round. Balances collective welfare with individual security
    through conditional contribution decisions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        cooperation_rate = self._calculate_cooperation_rate(history, round_num)
        expected_cooperators = cooperation_rate * self.n_players
        if round_num == self.n_rounds - 1:
            return self._final_round_decision(cooperation_rate, expected_cooperators)
        return self._main_phase_decision(expected_cooperators, cooperation_rate)

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """Calculate smoothed cooperation rate from previous rounds."""
        if round_num == 0:
            return 0.0
        past_rounds = round_num
        if past_rounds == 0:
            return 0.0
        total_cooperations = float(np.sum(history.opponent_actions[:past_rounds, :]))
        total_possible = float(self.n_players * past_rounds)
        if total_possible == 0:
            return 0.0
        cooperation_rate = total_cooperations / total_possible
        if past_rounds >= 3:
            cooperation_rate = self._smooth_cooperation_rate(history, past_rounds)
        return cooperation_rate

    def _smooth_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """Apply smoothing over last 3 rounds to reduce volatility."""
        look_back = min(3, round_num)
        start_idx = max(0, round_num - look_back)
        recent_cooperations = float(np.sum(history.opponent_actions[start_idx:round_num, :]))
        recent_possible = float(self.n_players * look_back)
        if recent_possible == 0:
            return 0.0
        return recent_cooperations / recent_possible

    def _main_phase_decision(self, expected_cooperators: float, cooperation_rate: float) -> Action:
        """Decision logic for rounds 1 to r-2 (main phase)."""
        if self.m == self.n_players:
            if cooperation_rate >= 0.8:
                return Action.C
            else:
                return Action.D
        if cooperation_rate < 0.1 and cooperation_rate > 0.0:
            return Action.D
        if cooperation_rate >= 0.99:
            return Action.C
        if expected_cooperators >= self.m:
            return Action.C
        if expected_cooperators >= self.m - 1:
            pivot_probability = expected_cooperators - (self.m - 1)
            if random.random() < pivot_probability:
                return Action.C
            else:
                return Action.D
        return Action.D

    def _final_round_decision(self, cooperation_rate: float, expected_cooperators: float) -> Action:
        """Decision logic for the final round (more cautious)."""
        if self.m == self.n_players:
            if cooperation_rate >= 0.9:
                return Action.C
            else:
                return Action.D
        if cooperation_rate > 0.5 and expected_cooperators >= self.m:
            return Action.C
        if cooperation_rate > 0.3 and expected_cooperators >= self.m - 1:
            if random.random() < 0.4:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_185(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) for Collective Risk Dilemma.
    
    Balances collective welfare maximization, individual rationality, and adaptive robustness
    by using conditional cooperation based on observed cooperation rates and pivotal contribution analysis.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        last_round_actions = history.opponent_actions[current_round - 1, :]
        last_round_cooperators = int(np.sum(last_round_actions))
        observed_cooperation_rate = last_round_cooperators / self.n
        expected_others_cooperating = observed_cooperation_rate * (self.n - 1)
        cooperation_gap = self.m - 1 - expected_others_cooperating
        if current_round == self.r - 1:
            if observed_cooperation_rate >= self.m / self.n:
                return Action.C
            else:
                return Action.D
        if cooperation_gap <= 0:
            return Action.C
        threshold_pivot = math.ceil(self.n / 3)
        if 0 < cooperation_gap <= threshold_pivot:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_186(BaseStrategy):
    """
    Adaptive Threshold Commitment (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual rational self-interest with collective benefit by committing
    to cooperation when threshold probability is high, while defecting when cooperation
    becomes futile or in the final round. Treats the game as trust-building where
    cooperation signals confidence in others' rationality.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            return Action.D
        prev_round_idx = round_num - 1
        prev_actions = history.opponent_actions[prev_round_idx, :]
        cooperators_prev = int(np.sum(prev_actions))
        coop_rate = cooperators_prev / self.n
        def_rate = 1.0 - coop_rate
        remaining_rounds = self.r - round_num
        threshold_ratio = self.m / self.n
        if coop_rate >= threshold_ratio:
            return Action.C
        if cooperators_prev == self.m - 1:
            denominator = self.n - self.m + 1
            if denominator > 0:
                p_threshold = 1.0 / denominator
                if random.random() < p_threshold:
                    return Action.C
            return Action.D
        threshold_deficit = self.m - cooperators_prev
        if threshold_deficit > remaining_rounds:
            return Action.D
        if remaining_rounds <= 2:
            return Action.D
        if def_rate > 0:
            exponent = threshold_deficit - 1
            if exponent > 0:
                p_recovery = 1.0 - math.pow(def_rate, exponent)
            else:
                p_recovery = 1.0
        else:
            p_recovery = 1.0
        if random.random() < p_recovery:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_187(BaseStrategy):
    """
    Adaptive Collective Threshold Strategy (ACTS)
    
    Balances collective welfare with individual resilience by:
    1. Cooperating unconditionally in round 1 to signal good faith
    2. Using graduated thresholds in middle rounds to tolerate temporary low cooperation
    3. Making final round decision based on historical cooperation rate
    
    This maximizes threshold achievement while minimizing exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            threshold_for_final = self.m / self.n_players * 0.75
            total_cooperation_rate = self._calculate_historical_cooperation_rate(history)
            if total_cooperation_rate >= threshold_for_final:
                return Action.C
            else:
                return Action.D
        prev_round_cooperators = self._count_cooperators_in_round(history, current_round - 1)
        if prev_round_cooperators >= self.m:
            return Action.C
        elif prev_round_cooperators >= self.m - 1:
            return Action.C
        elif prev_round_cooperators >= math.ceil(self.m / 2.0):
            return Action.C
        else:
            return Action.D

    def _count_cooperators_in_round(self, history: PlayerHistory, round_idx: int) -> int:
        """
        Count the number of cooperators (including self) in a given round.
        
        Args:
            history: PlayerHistory object containing actions from all rounds
            round_idx: The round index (0-indexed)
        
        Returns:
            Total count of cooperators in that round
        """
        my_action = history.my_actions[round_idx]
        opponent_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
        return int(my_action) + opponent_cooperators

    def _calculate_historical_cooperation_rate(self, history: PlayerHistory) -> float:
        """
        Calculate the overall cooperation rate across all completed rounds.
        
        Args:
            history: PlayerHistory object
        
        Returns:
            Fraction of all player-round combinations where cooperation occurred
        """
        n_completed_rounds = len(history.my_actions)
        if n_completed_rounds == 0:
            return 0.0
        my_cooperations = int(np.sum(history.my_actions))
        opponent_cooperations = int(np.sum(history.opponent_actions))
        total_cooperations = my_cooperations + opponent_cooperations
        total_possible = self.n_players * n_completed_rounds
        return total_cooperations / total_possible if total_possible > 0 else 0.0

class Strategy_COLLECTIVE_188(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances robustness, adaptivity, and collective benefit by:
    - Cooperating in round 1 to establish norms
    - Tracking cooperation rates and adapting based on deficit vs. rounds remaining
    - Strongly favoring cooperation in the final round
    - Using probabilistic exploration when uncertain
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_coop_count = int(sum(history.opponent_actions[current_round - 1, :]))
        prev_coop_rate = prev_coop_count / self.n_players
        threshold_rate = self.m / self.n_players
        if prev_coop_rate >= threshold_rate:
            return Action.C
        deficit = self.m - prev_coop_count
        rounds_remaining = self.n_rounds - current_round
        if current_round == self.n_rounds - 1:
            if prev_coop_count >= self.m - 1:
                return Action.C
            else:
                return Action.D
        if deficit <= 2 and rounds_remaining >= 2:
            return Action.C
        if deficit > 2 and deficit >= self.n_players / 2:
            return Action.D
        if random.random() < threshold_rate:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_189(BaseStrategy):
    """
    Adaptive Threshold Coordinator for Collective Risk Dilemma.
    
    Operates in three phases (Diagnostic, Coordination, Endgame) to assess
    population cooperativeness and adapt decisions to match group coordination
    patterns while protecting against exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = []
        self.success_rounds = 0
        self.phase_1_end = math.ceil(game_description.n_rounds / 3)
        self.phase_2_end = math.floor(2 * game_description.n_rounds / 3)
        self.threshold_boost = 0.05 if game_description.n_players < 5 else 0.0
        self.high_threshold_ratio = game_description.m / game_description.n_players
        self.threshold_tighten = 0.1 if self.high_threshold_ratio > 0.75 else 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        self._update_cooperation_history(history, current_round)
        if current_round < self.phase_1_end:
            return Action.C
        elif current_round < self.phase_2_end:
            return self._phase_2_decision(history, current_round)
        else:
            return self._phase_3_decision(history, current_round)

    def _update_cooperation_history(self, history: PlayerHistory, current_round: int) -> None:
        """Track cooperation rate from all completed rounds."""
        if current_round == 0:
            return
        total_cooperators = 0
        for round_idx in range(current_round):
            if history.my_actions[round_idx]:
                total_cooperators += 1
            total_cooperators += sum(history.opponent_actions[round_idx, :])
        total_possible = current_round * self.game_description.n_players
        if total_possible > 0:
            self.cooperation_history.append(total_cooperators / total_possible)
        if current_round > 0:
            cooperators_last_round = int(history.my_actions[current_round - 1])
            cooperators_last_round += sum(history.opponent_actions[current_round - 1, :])
            if cooperators_last_round >= self.game_description.m:
                self.success_rounds += 1

    def _get_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """Calculate average cooperation rate across all previous rounds."""
        if current_round == 0:
            return 0.5
        total_cooperators = 0
        for round_idx in range(current_round):
            if history.my_actions[round_idx]:
                total_cooperators += 1
            total_cooperators += sum(history.opponent_actions[round_idx, :])
        total_possible = current_round * self.game_description.n_players
        return total_cooperators / total_possible if total_possible > 0 else 0.5

    def _get_observed_cooperators_last_round(self, history: PlayerHistory, current_round: int) -> int:
        """Count cooperators in the immediately preceding round."""
        if current_round == 0:
            return 0
        cooperators = int(history.my_actions[current_round - 1])
        cooperators += sum(history.opponent_actions[current_round - 1, :])
        return cooperators

    def _phase_2_decision(self, history: PlayerHistory, current_round: int) -> Action:
        """Coordination Phase decision logic with adaptive thresholds."""
        coop_rate = self._get_cooperation_rate(history, current_round)
        observed_cooperators = self._get_observed_cooperators_last_round(history, current_round)
        threshold_ratio = self.game_description.m / self.game_description.n_players
        high_threshold = threshold_ratio * 1.2 + self.threshold_boost - self.threshold_tighten
        mid_threshold = threshold_ratio * 0.8 + self.threshold_boost
        low_threshold = threshold_ratio * 0.5 + self.threshold_boost
        if coop_rate >= high_threshold:
            return Action.C
        elif coop_rate >= mid_threshold:
            if observed_cooperators >= self.game_description.m - 1:
                return Action.C
            else:
                return Action.D
        elif coop_rate >= low_threshold:
            if observed_cooperators >= self.game_description.m:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _phase_3_decision(self, history: PlayerHistory, current_round: int) -> Action:
        """Endgame Phase decision logic with tightened thresholds."""
        rounds_remaining = self.game_description.n_rounds - current_round
        coop_rate = self._get_cooperation_rate(history, current_round)
        observed_cooperators = self._get_observed_cooperators_last_round(history, current_round)
        if rounds_remaining <= 2:
            threshold_ratio = self.game_description.m / self.game_description.n_players
            tight_threshold = threshold_ratio * 0.9 + self.threshold_boost
            if coop_rate >= tight_threshold:
                return Action.C
            else:
                return Action.D
        else:
            threshold_ratio = self.game_description.m / self.game_description.n_players
            high_threshold = threshold_ratio * 1.2 * 1.1 + self.threshold_boost - self.threshold_tighten
            mid_threshold = threshold_ratio * 0.8 * 1.1 + self.threshold_boost
            low_threshold = threshold_ratio * 0.5 * 1.1 + self.threshold_boost
            if coop_rate >= high_threshold:
                return Action.C
            elif coop_rate >= mid_threshold:
                if observed_cooperators >= self.game_description.m - 1:
                    return Action.C
                else:
                    return Action.D
            elif coop_rate >= low_threshold:
                if observed_cooperators >= self.game_description.m:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D

class Strategy_COLLECTIVE_190(BaseStrategy):
    """
    Adaptive Threshold Monitoring strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by treating cooperation
    as a contingent investment in group success. Cooperates when conditions suggest
    the threshold is achievable, defects when threshold seems unattainable.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_idx = round_num - 1
        prev_cooperators = int(sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            prev_cooperators += 1
        total_players = self.n
        coop_rate = prev_cooperators / total_players
        threshold_met_last = prev_cooperators >= self.m
        if round_num < self.r - 1:
            return self._early_game_decision(coop_rate, threshold_met_last, round_num)
        else:
            return self._final_round_decision(history, coop_rate, threshold_met_last)

    def _early_game_decision(self, coop_rate: float, threshold_met_last: bool, round_num: int) -> Action:
        """Decision logic for early game (rounds 1 through r-2)."""
        m_ratio = self.m / self.n
        if threshold_met_last:
            return Action.C
        if coop_rate >= m_ratio:
            return Action.C
        if coop_rate >= 0.4:
            prob = min(0.75, m_ratio / coop_rate)
            if random.random() < prob:
                return Action.C
            else:
                return Action.D
        return Action.D

    def _final_round_decision(self, history: PlayerHistory, coop_rate: float, threshold_met_last: bool) -> Action:
        """Decision logic for final round."""
        m_ratio = self.m / self.n
        successful_rounds = 0
        for round_idx in range(self.r - 1):
            round_cooperators = int(sum(history.opponent_actions[round_idx, :]))
            if history.my_actions[round_idx]:
                round_cooperators += 1
            if round_cooperators >= self.m:
                successful_rounds += 1
        if self.r > 1:
            success_rate = successful_rounds / (self.r - 1)
        else:
            success_rate = 0.0
        if success_rate >= 0.6 and coop_rate >= m_ratio:
            return Action.C
        if coop_rate >= m_ratio * 1.2:
            return Action.C
        if coop_rate >= m_ratio and self.k > 1.5:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_191(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy for Collective Risk Dilemma.
    
    Balances individual security with collective welfare through conditional cooperation,
    escalating sanctions, and phase-based decision-making. Cooperates early to establish
    norms, adapts to group behavior in mid-game, and makes final-round decisions based
    on overall cooperation history.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        mid_game_start = math.floor(self.r / 2) + 1
        rounds_remaining = self.r - round_num
        cooperate_count_last_round = int(np.sum(history.opponent_actions[round_num - 1, :]))
        cooperate_rate_last = cooperate_count_last_round / self.n
        all_opponent_actions = history.opponent_actions[:round_num, :]
        cooperate_rate_overall = np.mean(all_opponent_actions) if round_num > 0 else 0.0
        if self.m == self.n:
            if round_num == self.r - 1:
                return Action.C if cooperate_rate_overall >= 1.0 else Action.D
            else:
                return Action.C
        if self.r == 2:
            if round_num == 1:
                return Action.C if cooperate_rate_last >= self.m / self.n else Action.D
        if round_num <= math.floor(self.r / 2):
            threshold_rate = self.m / self.n
            recovery_threshold = threshold_rate - 0.2
            if cooperate_rate_last >= threshold_rate:
                return Action.C
            elif cooperate_rate_last >= recovery_threshold and rounds_remaining >= 3:
                return Action.C
            else:
                return Action.D
        elif round_num < self.r - 1:
            threshold_rate = self.m / self.n
            near_threshold_rate = (self.m - 1) / self.n if self.m > 1 else 0.0
            defection_severity = 1.0 - cooperate_rate_overall
            if self.k > 2.0:
                recovery_threshold = threshold_rate - 0.3
                if cooperate_rate_overall >= near_threshold_rate:
                    return Action.C
                elif cooperate_rate_overall >= recovery_threshold and rounds_remaining >= 2:
                    return Action.C
            elif cooperate_rate_overall >= threshold_rate:
                return Action.C
            elif cooperate_rate_overall >= near_threshold_rate and rounds_remaining >= 2:
                return Action.C
            if self.m == 2:
                if cooperate_rate_overall < 0.3:
                    return Action.D
            if defection_severity >= 0.5:
                return Action.D
            return Action.C if random.random() < cooperate_rate_overall else Action.D
        else:
            threshold_rate = self.m / self.n
            near_threshold_rate = (self.m - 1) / self.n if self.m > 1 else 0.0
            if cooperate_rate_overall >= threshold_rate:
                return Action.C
            elif cooperate_rate_overall >= near_threshold_rate:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_192(BaseStrategy):
    """
    Conditional Threshold Follower with Adaptive Defection.
    
    Balances threshold insurance, defection resistance, and adaptive learning.
    Cooperates in round 1 to probe, adapts based on observed cooperation rates,
    and defects in the final round (backward induction).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            return Action.D
        if history is None:
            return Action.C
        prev_round_idx = round_num - 1
        prev_opponent_cooperators = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        my_prev_action_coop = int(history.my_actions[prev_round_idx])
        total_cooperators_prev = prev_opponent_cooperators + my_prev_action_coop
        if total_cooperators_prev >= self.m:
            return Action.C
        observed_coop_rate = total_cooperators_prev / self.n
        required_others_coop_rate = (self.m - 1) / self.n
        if observed_coop_rate >= required_others_coop_rate:
            if round_num >= 2:
                prev_prev_round_idx = round_num - 2
                prev_prev_opponent_cooperators = int(np.sum(history.opponent_actions[prev_prev_round_idx, :]))
                my_prev_prev_action_coop = int(history.my_actions[prev_prev_round_idx])
                total_cooperators_prev_prev = prev_prev_opponent_cooperators + my_prev_prev_action_coop
                if total_cooperators_prev >= total_cooperators_prev_prev:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_193(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances collective welfare with protection against exploitation by using
    historical cooperation rates to estimate threshold achievement probability.
    Cooperates by default, adapts based on observed cooperation trends, and
    defects strategically only when cooperation has demonstrably failed or
    in the final round after sustained low cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        coop_rate = self._calculate_coop_rate(history, state.round_number)
        defection_rate = 1.0 - coop_rate
        trend = self._calculate_trend(history, state.round_number)
        if state.round_number == self.n_rounds - 1:
            if coop_rate < 0.4:
                return Action.D
            else:
                return Action.C
        threshold_likely = coop_rate >= (self.m - 1) / self.n_players or trend > 0.1
        if threshold_likely and defection_rate < 0.3:
            return Action.C
        if coop_rate >= (self.m - 1) / self.n_players * 0.7 and state.round_number < self.n_rounds - 2:
            return Action.C
        if defection_rate > 0.6:
            return Action.D
        return Action.C

    def _calculate_coop_rate(self, history: PlayerHistory, round_number: int) -> float:
        """
        Calculate the historical cooperation rate across all players and past rounds.
        
        Args:
            history: PlayerHistory object containing opponent actions
            round_number: Current round number (0-indexed)
        
        Returns:
            Cooperation rate as a float in [0, 1]
        """
        if round_number == 0:
            return self.m / self.n_players
        total_cooperators = np.sum(history.opponent_actions[:round_number, :])
        total_slots = self.n_players * round_number
        if total_slots == 0:
            return self.m / self.n_players
        return total_cooperators / total_slots

    def _calculate_trend(self, history: PlayerHistory, round_number: int) -> float:
        """
        Calculate cooperation trend: is cooperation improving or declining?
        
        Args:
            history: PlayerHistory object containing opponent actions
            round_number: Current round number (0-indexed)
        
        Returns:
            Trend value (positive = improving, negative = declining)
        """
        if round_number < 2:
            return 0.0
        start_idx = max(0, round_number - 3)
        recent_rounds = history.opponent_actions[start_idx:round_number, :]
        recent_coop = np.mean(recent_rounds) if recent_rounds.size > 0 else 0.0
        overall_coop = np.mean(history.opponent_actions[:round_number, :])
        trend = recent_coop - overall_coop
        return trend

class Strategy_COLLECTIVE_194(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS)
    
    Balances individual security with collective benefit through:
    - Phase 1 (Opening): Conditional cooperation based on threshold achievement
    - Phase 2 (Middle): Adaptive threshold chasing with 3-round moving average
    - Phase 3 (Endgame): Salvage and secure with higher cooperation bar
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        opening_end = math.ceil(self.n_rounds / 3)
        if round_num < opening_end:
            return self._phase1_opening(round_num, history)
        endgame_start = math.floor(2 * self.n_rounds / 3)
        if round_num >= endgame_start:
            return self._phase3_endgame(round_num, history)
        return self._phase2_middle(round_num, history)

    def _phase1_opening(self, round_num: int, history: None | PlayerHistory) -> Action:
        """
        Opening phase: Conditional cooperation with verification.
        Start with cooperation, then cooperate only if threshold was met last round.
        """
        if round_num == 0:
            return Action.C
        cooperators_last_round = int(np.sum(history.opponent_actions[-1, :]))
        if cooperators_last_round >= self.m:
            return Action.C
        else:
            return Action.D

    def _phase2_middle(self, round_num: int, history: PlayerHistory) -> Action:
        """
        Middle phase: Adaptive threshold chasing with 3-round moving average.
        """
        lookback = min(3, round_num)
        total_cooperators = 0
        for i in range(round_num - lookback, round_num):
            total_cooperators += int(np.sum(history.opponent_actions[i, :]))
        observed_cooperation_rate = total_cooperators / (lookback * self.n_players)
        threshold_rate = self.m / self.n_players
        if observed_cooperation_rate >= threshold_rate * 1.1:
            return Action.C
        if observed_cooperation_rate >= threshold_rate * 0.9:
            if round_num % 2 == 0:
                return Action.C
            else:
                return Action.D
        return Action.D

    def _phase3_endgame(self, round_num: int, history: PlayerHistory) -> Action:
        """
        Endgame phase: Salvage and secure.
        Higher bar for cooperation; terminal rounds always defect.
        """
        rounds_remaining = self.n_rounds - round_num
        if rounds_remaining <= 2:
            return Action.D
        lookback = min(3, round_num)
        total_cooperators = 0
        for i in range(round_num - lookback, round_num):
            total_cooperators += int(np.sum(history.opponent_actions[i, :]))
        observed_cooperation_rate = total_cooperators / (lookback * self.n_players)
        threshold_rate = self.m / self.n_players
        if observed_cooperation_rate >= threshold_rate * 1.15:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_195(BaseStrategy):
    """
    Adaptive Threshold Cascade strategy for Collective Risk Dilemma.
    
    Balances collective welfare maximization with individual resilience by:
    1. Estimating probability that threshold will be met given cooperation
    2. Cooperating when probability exceeds break-even threshold
    3. Adapting based on observed cooperation rates
    4. Using stricter thresholds in final rounds to avoid exploitation
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        baseline_cooperation_rate = self._estimate_cooperation_rate(history, round_number)
        threshold_met_probability = self._estimate_threshold_probability(baseline_cooperation_rate)
        breakeven_threshold = 1.0 - 1.0 / self.k
        if round_number >= self.n_rounds - 2:
            breakeven_threshold = breakeven_threshold * 1.2
        if threshold_met_probability >= breakeven_threshold:
            return Action.C
        else:
            return Action.D

    def _estimate_cooperation_rate(self, history: PlayerHistory, round_number: int) -> float:
        """
        Estimate baseline cooperation rate from recent rounds.
        
        Uses last min(3, round_number) rounds with decay weighting.
        Most recent round weighted 2x, previous rounds weighted 1x each.
        """
        if round_number <= 0:
            return 0.0
        observation_window = min(3, round_number)
        start_idx = round_number - observation_window
        recent_actions = history.opponent_actions[start_idx:round_number, :]
        total_cooperators = 0.0
        total_weight = 0.0
        for i, round_idx in enumerate(range(start_idx, round_number)):
            weight = 2.0 if round_idx == round_number - 1 else 1.0
            cooperators_in_round = np.sum(recent_actions[i, :])
            total_cooperators += cooperators_in_round * weight
            total_weight += weight * (self.n_players - 1)
        if total_weight == 0:
            return 0.0
        baseline_rate = total_cooperators / total_weight
        baseline_rate = max(0.0, min(1.0, baseline_rate))
        return baseline_rate

    def _estimate_threshold_probability(self, baseline_cooperation_rate: float) -> float:
        """
        Estimate probability that m-1 other players will cooperate.
        
        Assumes other players' cooperation is independent with rate = baseline_cooperation_rate.
        P(threshold met | I cooperate) = baseline_rate^(m-1)
        """
        if self.m <= 1:
            return 1.0
        threshold_probability = baseline_cooperation_rate ** (self.m - 1)
        threshold_probability = max(0.0, min(1.0, threshold_probability))
        return threshold_probability

class Strategy_COLLECTIVE_196(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances cooperation and defection based on observed cooperation rates,
    adjusting thresholds dynamically for extreme game parameters. Cooperates
    in early rounds to establish norms, punishes systematic defection in the
    main phase, and defects in the final round (endgame consideration).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def _adjust_threshold_multiplier(self) -> float:
        """Adjust threshold_multiplier based on k and game parameters."""
        if self.k < 1.5:
            return 1.5
        if self.m >= self.n - 1:
            return 1.0
        return 1.2

    def _adjust_tolerance_parameter(self) -> float:
        """Adjust tolerance_parameter based on k."""
        if self.k > 3:
            return 0.25
        return 0.15

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if self.n == 2 and self.m == 1:
            return Action.C
        if current_round == self.r - 1:
            if self.r <= 3:
                return Action.D
            return Action.D
        prev_round_idx = current_round - 1
        cooperators_prev = sum(history.opponent_actions[prev_round_idx, :])
        if history.my_actions[prev_round_idx]:
            cooperators_prev += 1
        cooperation_rate = cooperators_prev / self.n
        min_threshold = self.m / self.n
        threshold_multiplier = self._adjust_threshold_multiplier()
        tolerance_parameter = self._adjust_tolerance_parameter()
        cooperation_target = min_threshold * threshold_multiplier
        if cooperation_rate >= cooperation_target:
            return Action.C
        else:
            cooperation_deficit = min_threshold - cooperation_rate
            if cooperation_deficit > tolerance_parameter:
                return Action.D
            else:
                return Action.C

class Strategy_COLLECTIVE_197(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances collective welfare with individual rationality by:
    1. Opening with cooperation to establish norms
    2. Maintaining cooperation when threshold is plausibly achievable
    3. Exiting strategically when collective success becomes impossible
    4. Locking in cooperation once threshold is reached
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        previous_round_idx = round_t - 1
        cooperators_prev = int(sum(history.opponent_actions[previous_round_idx, :]))
        if history.my_actions[previous_round_idx]:
            cooperators_prev += 1
        if round_t == self.r - 1:
            if cooperators_prev >= self.m:
                return Action.C
            else:
                return Action.D
        remaining_rounds = self.r - round_t
        contingency_margin = max(1, math.ceil(self.m / 3))
        if cooperators_prev >= self.m:
            return Action.C
        if cooperators_prev + contingency_margin >= self.m:
            return Action.C
        if remaining_rounds <= 2:
            return Action.D
        return Action.D

class Strategy_COLLECTIVE_198(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual security with collective welfare by:
    1. Cooperating in round 1 to establish reciprocity
    2. Tracking historical cooperation rates across all previous rounds
    3. Using an adaptive threshold that decreases over time
    4. Protecting against exploitation via defection safeguards
    5. Responding dynamically to observed cooperation levels
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        total_cooperators = int(np.sum(history.opponent_actions[:round_number, :]))
        cooperation_rate = total_cooperators / (self.n_players * round_number)
        threshold = 0.5 + 0.4 * (self.n_rounds - round_number) / self.n_rounds
        if round_number > 1:
            recent_start = max(0, round_number - 2)
            recent_cooperators = int(np.sum(history.opponent_actions[recent_start:round_number, :]))
            recent_rounds_count = round_number - recent_start
            recent_coop_rate = recent_cooperators / (self.n_players * recent_rounds_count)
            if recent_coop_rate < 0.05:
                return Action.D
        if cooperation_rate >= 0.95:
            return Action.C
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_199(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual security with collective welfare through:
    1. Early cooperation to test and signal good faith
    2. Adaptive mid-game decisions based on observed cooperation rates
    3. End-game defection to avoid exploitation
    
    Monitors whether the cooperation threshold m is achievable and adjusts
    cooperation probability accordingly.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.phase1_end = math.ceil(self.n_rounds / 3)
        self.phase2_end = math.floor(2 * self.n_rounds / 3)
        self.total_cooperators_observed = 0
        self.consecutive_defection_rounds = 0
        self.consecutive_threshold_success = 0
        self.confidence_threshold_offset = -0.15

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num < self.phase1_end:
            self._update_tracking(history, round_num)
            return Action.C
        self._update_tracking(history, round_num)
        rounds_remaining = self.n_rounds - round_num
        if round_num == self.n_rounds - 1:
            return Action.D
        if rounds_remaining <= 2:
            return Action.D
        coop_rate = self._calculate_cooperation_rate(round_num)
        threshold_benchmark = self.m / self.n_players + self.confidence_threshold_offset
        if coop_rate >= threshold_benchmark:
            return Action.C
        elif coop_rate >= 0.5:
            return Action.C if random.random() < coop_rate else Action.D
        else:
            return Action.D

    def _update_tracking(self, history: PlayerHistory, round_num: int) -> None:
        """Update tracking state based on observed opponent actions."""
        if round_num == 0:
            return
        cooperators_in_last_round = int(sum(history.opponent_actions[round_num - 1, :]))
        self.total_cooperators_observed += cooperators_in_last_round
        if cooperators_in_last_round == 0:
            self.consecutive_defection_rounds += 1
        else:
            self.consecutive_defection_rounds = 0
        if cooperators_in_last_round >= self.m:
            self.consecutive_threshold_success += 1
            if self.consecutive_threshold_success >= 3:
                self.confidence_threshold_offset = -0.2
        else:
            self.consecutive_threshold_success = 0
        if cooperators_in_last_round <= self.m - 1:
            if round_num >= 4:
                self.confidence_threshold_offset = -0.05

    def _calculate_cooperation_rate(self, round_num: int) -> float:
        """
        Calculate the observed cooperation rate from opponents.
        
        coop_rate = total_cooperators_observed / ((n-1) * rounds_elapsed)
        """
        if round_num == 0:
            return 0.0
        rounds_elapsed = round_num
        max_possible_cooperations = (self.n_players - 1) * rounds_elapsed
        if max_possible_cooperations == 0:
            return 0.0
        coop_rate = self.total_cooperators_observed / max_possible_cooperations
        return coop_rate

class Strategy_COLLECTIVE_200(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances individual risk mitigation with collective benefit maximization by:
    1. Cooperating in round 1 to signal willingness
    2. Defecting in the final round to avoid last-round exploitation
    3. Conditionally cooperating in middle rounds based on prior cooperation count:
       - If threshold m is met: cooperate (secure collective gain)
       - If exactly m-1 cooperators: cooperate with probability (k-1)/k (marginal decision)
       - If fewer than m-1: defect (threshold unachievable)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        if history is not None:
            previous_round_index = current_round - 1
            opponent_cooperations_prev = sum(history.opponent_actions[previous_round_index, :])
            my_action_prev = history.my_actions[previous_round_index]
            total_cooperators_prev = opponent_cooperations_prev + (1 if my_action_prev else 0)
            if total_cooperators_prev >= self.m:
                return Action.C
            elif total_cooperators_prev == self.m - 1:
                p_marginal = (self.k - 1.0) / self.k
                if random.random() < p_marginal:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_201(BaseStrategy):
    """
    Adaptive Threshold Convergence strategy for Collective Risk Dilemma.
    
    Balances collective welfare with individual rationality by:
    - Cooperating in round 1 to establish cooperative baseline
    - In intermediate rounds: defecting when threshold is secure or impossible,
      cooperating when exactly one more cooperator is needed (deficit=1) or
      at the threshold boundary
    - In final round: cooperating if threshold is achievable, defecting if impossible
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        previous_round_idx = current_round - 1
        opponent_cooperators = np.sum(history.opponent_actions[previous_round_idx, :])
        my_previous_action = history.my_actions[previous_round_idx]
        c_count = opponent_cooperators + (1 if my_previous_action else 0)
        deficit = self.m - c_count
        safety_margin = c_count - self.m
        if current_round == self.n_rounds - 1:
            if deficit >= 2:
                return Action.D
            else:
                return Action.C
        if safety_margin >= 1:
            return Action.D
        if deficit >= 2:
            return Action.D
        if deficit <= 1:
            return Action.C
        return Action.C

class Strategy_COLLECTIVE_202(BaseStrategy):
    """
    Adaptive Threshold Reciprocity for Collective Risk Dilemma.
    
    Balances securing collective benefit with protection against free-riders.
    Adapts cooperation probability based on observed group behavior and remaining rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C if random.random() < 0.65 else Action.D
        total_cooperators = int(np.sum(history.opponent_actions[:round_number, :]))
        total_rounds_played = round_number
        total_slots = self.n * total_rounds_played
        if total_slots == 0:
            observed_rate = 0.5
        else:
            observed_rate = total_cooperators / total_slots
        buffer = math.ceil(self.n * (1.0 - observed_rate) * 0.3)
        target_cooperators = self.m + buffer
        cooperation_probability = min(target_cooperators / self.n, 0.95)
        rounds_remaining = self.r - round_number - 1
        if rounds_remaining <= 1:
            cooperation_probability *= 0.5
        elif rounds_remaining <= 2:
            cooperation_probability *= 0.7
        threshold_ratio = (self.m - 1) / self.n
        if observed_rate < threshold_ratio:
            return Action.D
        if round_number > 0:
            prev_cooperators = int(np.sum(history.opponent_actions[round_number - 1, :]))
            if prev_cooperators >= self.m:
                cooperation_probability = 0.75
        if round_number >= 2:
            last_two_rounds_cooperators = int(np.sum(history.opponent_actions[round_number - 1, :])) + int(np.sum(history.opponent_actions[round_number - 2, :]))
            if last_two_rounds_cooperators == 0:
                return Action.D
        return Action.C if random.random() < cooperation_probability else Action.D

class Strategy_COLLECTIVE_203(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Recognizing mutual vulnerability through threshold-seeking behavior
    2. Escalating cooperation as evidence of collective capability emerges
    3. Gracefully responding to defection without mutual destruction
    4. Bootstrapping in round 1 with probability m/n to self-fulfill threshold
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.previous_coop_rate = None
        self.stagnation_rounds = 0
        self.escalation_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            threshold_prob = self.m / self.n
            if random.random() < threshold_prob:
                return Action.C
            return Action.D
        lookback = min(3, current_round)
        start_idx = current_round - lookback
        recent_cooperations = 0
        for round_idx in range(start_idx, current_round):
            recent_cooperations += np.sum(history.opponent_actions[round_idx, :])
        recent_coop_rate = recent_cooperations / (self.n * lookback)
        stagnation_detected = False
        if self.previous_coop_rate is not None:
            if abs(recent_coop_rate - self.previous_coop_rate) < 0.01:
                self.stagnation_rounds += 1
                if self.stagnation_rounds >= 2:
                    stagnation_detected = True
            else:
                self.stagnation_rounds = 0
        self.previous_coop_rate = recent_coop_rate
        threshold_margin = self.m / self.n - 0.1
        if current_round == self.r - 1 and recent_coop_rate >= threshold_margin:
            return Action.C
        if stagnation_detected and self.escalation_count < 3:
            base_prob = min(0.95, recent_coop_rate + 0.25)
            self.escalation_count += 1
        else:
            base_prob = self._calculate_standard_probability(recent_coop_rate)
        if random.random() < base_prob:
            return Action.C
        return Action.D

    def _calculate_standard_probability(self, coop_rate: float) -> float:
        """
        Calculate standard cooperation probability based on recent cooperation rate.
        """
        threshold_margin = self.m / self.n - 0.1
        threshold_half = self.m / self.n * 0.5
        if coop_rate >= threshold_margin:
            return min(0.95, coop_rate + 0.15)
        elif coop_rate >= threshold_half:
            return self.m / self.n
        else:
            return max(0.1, coop_rate * 0.5)

class Strategy_COLLECTIVE_204(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances collective welfare with individual security by:
    1. Actively pursuing collective success (m+ cooperators) when conditions favor it
    2. Protecting against exploitation by defecting when cooperation seems unlikely
    3. Dynamically adapting to observed cooperation patterns
    
    Core decision logic:
    - Round 1: Always cooperate (bootstrap cooperation)
    - Middle rounds: Cooperate if recent cooperation rate suggests threshold is achievable
    - Final round: Cooperate if conditions still favor collective success, else defect
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.buffer = 0.15
        self.recent_window_size = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        round_num = state.round_number
        all_rounds_elapsed = round_num
        recent_window = min(self.recent_window_size, all_rounds_elapsed)
        recent_cooperators = 0
        for i in range(all_rounds_elapsed - recent_window, all_rounds_elapsed):
            if i >= 0:
                recent_cooperators += int(np.sum(history.opponent_actions[i, :]))
        recent_coop_rate = recent_cooperators / max(1, n * recent_window) if recent_window > 0 else 0.0
        overall_cooperators = int(np.sum(history.opponent_actions))
        overall_coop_rate = overall_cooperators / max(1, n * all_rounds_elapsed) if all_rounds_elapsed > 0 else 0.0
        threshold_met_count = 0
        for i in range(all_rounds_elapsed):
            cooperators_in_round = int(np.sum(history.opponent_actions[i, :]))
            if cooperators_in_round >= m:
                threshold_met_count += 1
        threshold_met_freq = threshold_met_count / max(1, all_rounds_elapsed) if all_rounds_elapsed > 0 else 0.0
        critical_threshold = m / n
        if round_num == r - 1:
            if recent_coop_rate >= critical_threshold:
                return Action.C
            else:
                return Action.D
        if recent_coop_rate >= critical_threshold:
            return Action.C
        elif recent_coop_rate < critical_threshold - self.buffer:
            return Action.D
        elif threshold_met_freq > 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_205(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATC)
    
    Balances individual risk management with collective welfare by monitoring
    cooperation thresholds and adapting behavior based on observed group success.
    
    Decision rules:
    - Round 1: Cooperate (test cooperation)
    - Rounds 2 to r-1: Cooperate if threshold met OR if cost of collective failure
      exceeds cost of contribution
    - Final round: Defect (no future rounds to sustain)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        prev_round_idx = current_round - 1
        cooperators_prev_round = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            cooperators_prev_round += 1
        coop_rate = cooperators_prev_round / self.n_players
        threshold_rate = self.m / self.n_players
        if coop_rate >= threshold_rate:
            return Action.C
        defection_cost = self.k - 1
        rounds_left = self.n_rounds - current_round
        if defection_cost * rounds_left > 1:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_206(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATC) for Collective Risk Dilemma.
    
    Recognizes tension between individual payoff maximization and collective welfare.
    Builds self-enforcing equilibrium by rewarding cooperation, punishing defection,
    and adapting to opponent patterns dynamically.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_fraction = self.m / self.n_players
        self.deficit_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        cooperators_last_round = int(np.sum(history.opponent_actions[round_num - 1, :]))
        cr = cooperators_last_round / self.n_players
        if round_num == self.n_rounds - 1:
            return self._final_round_decision(history, round_num, cr)
        return self._adaptive_round_decision(history, round_num, cr, cooperators_last_round)

    def _adaptive_round_decision(self, history: PlayerHistory, round_num: int, cr: float, cooperators_last_round: int) -> Action:
        """Decision logic for rounds 2 to r-1."""
        if cr >= self.threshold_fraction:
            return Action.C
        if cr == 0:
            return Action.D
        if cr > 0 and cr < self.threshold_fraction:
            deficit = self.m - cooperators_last_round
            self.deficit_history.append(deficit)
            if len(self.deficit_history) > 3:
                self.deficit_history.pop(0)
            if len(self.deficit_history) >= 2:
                if all((d > self.n_players / 3 for d in self.deficit_history[-2:])):
                    return Action.D
            if round_num >= 2:
                recent_crs = []
                for r in range(max(0, round_num - 2), round_num):
                    coop_count = int(np.sum(history.opponent_actions[r, :]))
                    recent_crs.append(coop_count / self.n_players)
                if len(recent_crs) >= 2:
                    volatility = float(np.std(recent_crs))
                    if volatility > 0.4:
                        return Action.D
            if deficit >= self.n_players / 2:
                return Action.D
            return Action.C
        return Action.D

    def _final_round_decision(self, history: PlayerHistory, round_num: int, cr: float) -> Action:
        """Decision logic for final round."""
        if cr >= self.threshold_fraction:
            return Action.C
        cumulative_coop = 0
        for r in range(round_num):
            cumulative_coop += int(np.sum(history.opponent_actions[r, :]))
        avg_coop_needed = self.m * (self.n_rounds - 1) / 2
        if cumulative_coop > avg_coop_needed:
            return Action.C
        if cr >= 0.8 and cr < self.threshold_fraction:
            return Action.D
        return Action.D

class Strategy_COLLECTIVE_207(BaseStrategy):
    """
    Adaptive Threshold Reciprocity strategy for Collective Risk Dilemma.
    
    Balances collective welfare with individual resilience by:
    1. Promoting cooperation when it serves group interests
    2. Protecting against exploitation through conditional defection
    3. Adapting to empirical group behavior rather than assuming fixed cooperation levels
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.empirical_threshold = self.m / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        cooperation_count = int(np.sum(history.opponent_actions[round_num - 1, :]))
        cooperation_rate = cooperation_count / (self.n - 1) if self.n > 1 else 0.0
        if round_num == self.r - 1:
            if cooperation_rate >= 0.9 * self.empirical_threshold:
                return Action.C
            else:
                return Action.D
        threshold_lower_bound = self.empirical_threshold * 0.5
        threshold_lower_mid = self.empirical_threshold * 0.8
        threshold_upper_mid = self.empirical_threshold * 1.1
        if cooperation_rate >= threshold_upper_mid:
            return Action.C
        elif cooperation_rate >= threshold_lower_mid:
            if random.random() < cooperation_rate:
                return Action.C
            else:
                return Action.D
        elif cooperation_rate < threshold_lower_bound:
            return Action.D
        else:
            rounds_remaining = self.r - round_num
            halfway_point = self.r / 2.0
            if rounds_remaining > halfway_point:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_208(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Dynamically estimates cooperation rates and cooperates when estimated cooperators
    plus self would meet the threshold. Includes special handling for edge cases,
    cascade detection, and endgame logic.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.previous_estimate = 0.5
        self.previous_rate = 0.5
        self.cooperative_rounds_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if self.m > self.n:
            return Action.D
        if self.m == 1:
            return Action.C
        if current_round == 0:
            return self._decide_round_0()
        if current_round < self.r - 1:
            return self._decide_middle_rounds(current_round, history)
        return self._decide_final_round(history)

    def _decide_round_0(self) -> Action:
        """Decide for round 0 using baseline optimism."""
        if 0.5 * (self.n - 1) + 1 >= self.m:
            return Action.C
        return Action.D

    def _decide_middle_rounds(self, current_round: int, history: PlayerHistory) -> Action:
        """Decide for rounds 1 to r-2."""
        total_cooperators = int(np.sum(history.opponent_actions[:current_round, :]))
        total_actions = current_round * self.n
        if total_actions == 0:
            observed_rate = 0.5
        else:
            observed_rate = total_cooperators / total_actions
        adjusted_rate = 0.7 * observed_rate + 0.3 * self.previous_estimate
        rate_change = abs(adjusted_rate - self.previous_rate)
        if rate_change > 0.4:
            adjusted_rate = min(adjusted_rate, 0.8 * (self.m / self.n))
        estimated_cooperators = adjusted_rate * (self.n - 1)
        threshold_for_cooperation = self.m
        if self.r > 20 and current_round > self.r - 10:
            threshold_for_cooperation = self.m + 1
        self.previous_estimate = adjusted_rate
        self.previous_rate = observed_rate
        if estimated_cooperators + 1 >= threshold_for_cooperation:
            return Action.C
        return Action.D

    def _decide_final_round(self, history: PlayerHistory) -> Action:
        """Decide for the final round."""
        current_round = self.r - 1
        if current_round >= 1:
            last_round_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
            last_2_rounds_cooperators = int(np.sum(history.opponent_actions[max(0, current_round - 2):current_round, :]))
            rounds_with_threshold = 0
            for round_idx in range(max(0, current_round - 1), current_round):
                round_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
                if round_cooperators >= self.m:
                    rounds_with_threshold += 1
            if current_round >= 1:
                threshold_met_last_2 = rounds_with_threshold >= 2 or (current_round == 1 and last_round_cooperators >= self.m)
                if threshold_met_last_2:
                    return Action.C
        threshold_ever_met = False
        for round_idx in range(current_round):
            round_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
            if round_cooperators >= self.m:
                threshold_ever_met = True
                break
        if not threshold_ever_met:
            return Action.D
        return Action.D

class Strategy_COLLECTIVE_209(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances robust collective value creation with protection against exploitation
    by adapting cooperation decisions based on observed cooperation rates across rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_idx = round_num - 1
        prev_cooperators = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        cooperation_rate = prev_cooperators / self.n
        if round_num == self.r - 1:
            threshold = self.m / self.n * 0.25
            if cooperation_rate >= threshold:
                return Action.C
            else:
                return Action.D
        if round_num <= 2:
            threshold = (self.m - 1) / self.n
        elif round_num == self.r - 2:
            threshold = self.m / self.n
        else:
            threshold = (self.m - 0.5) / self.n
        if round_num >= 2:
            prev_prev_round_idx = round_num - 2
            prev_prev_cooperators = int(np.sum(history.opponent_actions[prev_prev_round_idx, :]))
            prev_prev_cooperation_rate = prev_prev_cooperators / self.n
            low_threshold = self.m / (2 * self.n)
            if cooperation_rate < low_threshold and prev_prev_cooperation_rate < low_threshold:
                return Action.D
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_210(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances collective welfare maximization with individual security by adaptively
    estimating group trustworthiness based on historical cooperation rates and
    calibrating contributions accordingly with round-dependent adjustments.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        coop_rate = self._calculate_cooperation_rate(history, state.round_number)
        base_threshold = (self.m - 1) / self.n_players
        adjusted_threshold = self._get_adjusted_threshold(state.round_number, base_threshold)
        if 0.3 <= coop_rate <= 0.7:
            prob_cooperate = (coop_rate - 0.3) / 0.4
            if random.random() < prob_cooperate:
                return Action.C
            else:
                return Action.D
        elif coop_rate >= adjusted_threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the empirical cooperation rate across all players in all past rounds.
        
        Returns the fraction of cooperate actions observed historically.
        """
        if current_round == 0:
            return 0.5
        total_opponent_cooperations = np.sum(history.opponent_actions)
        total_my_cooperations = np.sum(history.my_actions)
        total_actions = self.n_players * current_round
        total_cooperations = total_opponent_cooperations + total_my_cooperations
        if total_actions == 0:
            return 0.5
        coop_rate = total_cooperations / total_actions
        return coop_rate

    def _get_adjusted_threshold(self, current_round: int, base_threshold: float) -> float:
        """
        Apply round-dependent adjustments to the cooperation threshold.
        
        Early rounds: more permissive (0.9x threshold) - cautious exploration
        Middle rounds: standard threshold - full information
        Final rounds: more permissive (0.85x threshold) - collective commitment
        """
        one_third = self.n_rounds / 3.0
        two_thirds = 2.0 * self.n_rounds / 3.0
        if current_round <= one_third:
            return 0.9 * base_threshold
        elif current_round >= two_thirds:
            return 0.85 * base_threshold
        else:
            return base_threshold

class Strategy_COLLECTIVE_211(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances collective success, self-protection, and opportunistic rationality by:
    1. Cooperating in round 1 to probe others' intentions
    2. Adaptively adjusting based on observed cooperation counts relative to threshold m
    3. Defecting in the final round (dominant strategy in terminal round)
    
    Core logic: Cooperate when threshold is met or nearly met, defect when threshold
    is unreachable or in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.n_rounds - 1:
            return Action.D
        previous_round_idx = round_number - 1
        c_count = int(np.sum(history.opponent_actions[previous_round_idx, :]))
        if history.my_actions[previous_round_idx]:
            c_count += 1
        if c_count >= self.m:
            return Action.C
        if c_count == self.m - 1:
            return Action.C
        halfway_point = math.ceil(self.m / 2.0)
        if c_count >= halfway_point:
            cooperation_probability = min(c_count / self.m, 0.85)
            if random.random() < cooperation_probability:
                return Action.C
            return Action.D
        return Action.D

class Strategy_COLLECTIVE_212(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances conditional cooperation with threshold sensitivity and collective resilience.
    Uses a dynamic cooperation threshold that adapts based on observed cooperation rates,
    combined with an information-gathering phase to test opponent intentions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        observed_coop_rate = self._calculate_observed_coop_rate(history, current_round)
        if current_round <= 2:
            threshold = (self.m - 1) / self.n_players
            if observed_coop_rate >= threshold:
                return Action.C
            else:
                return Action.D
        if current_round == self.n_rounds - 1:
            threshold = self.m / self.n_players * 0.85
            if observed_coop_rate >= threshold:
                return Action.C
            else:
                return Action.D
        rounds_until_end = self.n_rounds - current_round
        discount_factor = 1.0 - 0.15 * rounds_until_end / self.n_rounds
        threshold_adjusted = self.m / self.n_players * discount_factor
        if observed_coop_rate >= threshold_adjusted:
            return Action.C
        else:
            return Action.D

    def _calculate_observed_coop_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the average cooperation rate across all previous rounds.
        Returns a value between 0 and 1 representing the proportion of cooperators.
        """
        if current_round == 0:
            return 0.0
        total_cooperators = 0
        total_observations = 0
        for round_idx in range(current_round):
            cooperators_in_round = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += cooperators_in_round
            total_observations += self.n_players
        if total_observations == 0:
            return 0.0
        observed_coop_rate = total_cooperators / total_observations
        return observed_coop_rate

class Strategy_COLLECTIVE_213(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC): A collectively-minded strategy for the 
    Collective Risk Dilemma that balances individual incentives to free-ride with 
    collective incentives to meet the cooperation threshold.
    
    The strategy operates in three phases:
    - Phase 1 (early rounds): Unconditional cooperation to signal commitment
    - Phase 2 (mid-game): Adaptive cooperation based on observed cooperation rates
    - Phase 3 (final round): Limited opportunism when threshold is already secure
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        phase1_end = math.ceil(self.n_rounds / 3)
        if current_round < phase1_end:
            return Action.C
        phase2_end = math.floor(2 * self.n_rounds / 3)
        if current_round < phase2_end:
            return self._phase2_decision(current_round, history)
        return self._phase3_decision(current_round, history)

    def _phase2_decision(self, current_round: int, history: PlayerHistory) -> Action:
        """
        Mid-game adaptation based on cooperation in the previous round and 
        historical cooperation rate.
        """
        cooperators_last_round = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if cooperators_last_round >= self.m:
            return Action.C
        if cooperators_last_round >= self.m - 1:
            return Action.C
        if cooperators_last_round < self.m - 1:
            avg_cooperation_rate = self._calculate_average_cooperation(history, current_round)
            cooperation_threshold = self.m / self.n_players - 0.1
            if avg_cooperation_rate >= cooperation_threshold:
                return Action.C
            else:
                return Action.D
        return Action.C

    def _phase3_decision(self, current_round: int, history: PlayerHistory) -> Action:
        """
        Final round decision: limited opportunism when threshold is already secure,
        but still cooperate if marginal effort can save the round.
        """
        if current_round == 0:
            return Action.C
        cooperators_last_round = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if cooperators_last_round >= self.m:
            return Action.D
        if cooperators_last_round >= self.m - 1:
            return Action.C
        return Action.D

    def _calculate_average_cooperation(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the average cooperation rate of opponents, excluding the first round.
        Handles edge cases where there are insufficient rounds or zero history.
        """
        if current_round <= 1:
            start_index = 0
        else:
            start_index = 1
        relevant_history = history.opponent_actions[start_index:current_round, :]
        if relevant_history.size == 0:
            return self.m / self.n_players
        total_cooperators = np.sum(relevant_history)
        total_slots = relevant_history.size
        if total_slots == 0:
            return self.m / self.n_players
        cooperation_rate = total_cooperators / total_slots
        return cooperation_rate

class Strategy_COLLECTIVE_214(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATC) for Collective Risk Dilemma.
    
    Balances conditional cooperation based on observable cooperation rates with
    strategic defection in final rounds and under low cooperation scenarios.
    Adapts threshold sensitivity based on game parameters (m, n, k, r).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            return Action.D
        return self._decide_middle_round(history, round_num)

    def _decide_middle_round(self, history: PlayerHistory, round_num: int) -> Action:
        """
        Decide action in middle rounds based on recent cooperation rate.
        """
        cooperators_last_round = int(np.sum(history.opponent_actions[round_num - 1, :]))
        cooperation_rate = cooperators_last_round / (self.n - 1) if self.n > 1 else 0.0
        epsilon = self._calculate_epsilon()
        threshold = self.m / self.n - epsilon
        if cooperation_rate >= threshold:
            return Action.C
        elif cooperation_rate >= 0.5:
            return Action.C
        else:
            return Action.D

    def _calculate_epsilon(self) -> float:
        """
        Adjust epsilon (threshold buffer) based on game parameters.
        """
        if self.m == self.n:
            return 0.0
        if self.m <= 2:
            return 0.1
        if self.k > 5:
            return 0.15
        return 0.15

    def _should_cooperate_high_k(self, cooperation_rate: float) -> bool:
        """
        Special handling for very large k values.
        More aggressive cooperation is justified.
        """
        if self.k > 5 and cooperation_rate >= 0.3:
            return True
        return False

class Strategy_COLLECTIVE_215(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Promoting threshold achievement
    2. Punishing free-riding after systemic failures
    3. Recovering from temporary coordination failures
    4. Exploiting scenarios where cooperation is futile
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        defect_streak = self._count_consecutive_failures(history, self.m)
        time_remaining = self.n_rounds - current_round
        coop_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
        if history.my_actions[current_round - 1]:
            coop_last_round += 1
        if current_round == self.n_rounds - 1:
            defect_streak = 0
        if defect_streak >= 2:
            return Action.D
        if coop_last_round >= self.m:
            return Action.C
        if coop_last_round == self.m - 1:
            return Action.C
        if coop_last_round < self.m - 1 and time_remaining == 1:
            return Action.D
        if coop_last_round == 0:
            return Action.D
        if coop_last_round < self.m - 1 and time_remaining > 1:
            return Action.C
        return Action.C

    def _count_consecutive_failures(self, history: PlayerHistory, m: int) -> int:
        """
        Count consecutive rounds where cooperation threshold was not met,
        looking backward from the most recent round.
        """
        streak = 0
        current_round = len(history.my_actions)
        for round_idx in range(current_round - 1, -1, -1):
            opponent_cooperators = int(sum(history.opponent_actions[round_idx, :]))
            my_contribution = 1 if history.my_actions[round_idx] else 0
            total_cooperators = opponent_cooperators + my_contribution
            if total_cooperators < m:
                streak += 1
            else:
                break
        return streak

class Strategy_COLLECTIVE_216(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATC) for Collective Risk Dilemma.
    
    Balances exploitation resistance, threshold achievement, sustainability, and robustness
    by dynamically adjusting cooperation based on observed cooperation rates and proximity
    to the minimum threshold m.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        total_cooperators = 0
        for round_idx in range(current_round):
            my_cooperation = 1 if history.my_actions[round_idx] else 0
            opponent_cooperations = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += my_cooperation + opponent_cooperations
        total_possible = current_round * n
        if total_possible == 0:
            cooperation_rate = 0.0
        else:
            cooperation_rate = total_cooperators / total_possible
        expected_cooperators = cooperation_rate * n
        if current_round == r - 1:
            if expected_cooperators >= m:
                return Action.C
            else:
                return Action.D
        if expected_cooperators >= m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_217(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective orientation by:
    1. Starting with cooperation to establish good faith
    2. Adapting to recent cooperation rates with a 3-round rolling window
    3. Using Â±15% hysteresis buffer to avoid oscillation
    4. Employing mixed strategy in transition zones
    5. Making final-round decisions conditional on previous success
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        window_size = min(3, round_number)
        recent_rounds = history.opponent_actions[-window_size:, :]
        cooperators_in_window = np.sum(recent_rounds)
        recent_coop_rate = cooperators_in_window / (window_size * self.n_players)
        threshold_rate = self.m / self.n_players
        if round_number == self.n_rounds - 1:
            last_round_cooperators = np.sum(history.opponent_actions[-1, :])
            if last_round_cooperators >= self.m:
                return Action.C
            else:
                return Action.D
        if recent_coop_rate >= threshold_rate + 0.15:
            return Action.C
        elif recent_coop_rate >= threshold_rate:
            return Action.C
        elif recent_coop_rate >= threshold_rate - 0.15:
            defection_probability = (threshold_rate - recent_coop_rate) / 0.15
            if random.random() < defection_probability:
                return Action.D
            else:
                return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_218(BaseStrategy):
    """
    Threshold Sentinel Strategy for Collective Risk Dilemma.
    
    Cooperates strategically to achieve and maintain the cooperation threshold m,
    while defecting when the threshold is mathematically unreachable to minimize losses.
    
    Core logic:
    - Round 1: Always cooperate (establish cooperative foundation)
    - Rounds 2-r: Follow threshold-based decision rules:
      * If threshold met in previous round: cooperate
      * If within 1 of threshold: cooperate (be the swing vote)
      * If meaningful cooperation (â‰¥50%) and rounds remain: cooperate (signal commitment)
      * Otherwise: defect (minimize losses)
    - Final round: Special handling to push over threshold if close
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        rounds_remaining = self.n_rounds - current_round
        cooperators_prev_round = int(sum(history.opponent_actions[current_round - 1, :]))
        my_prev_action = history.my_actions[current_round - 1]
        total_cooperators_prev_round = cooperators_prev_round + (1 if my_prev_action else 0)
        if current_round == self.n_rounds - 1:
            if total_cooperators_prev_round >= self.m - 1:
                return Action.C
            elif total_cooperators_prev_round >= self.m:
                return Action.C
            elif total_cooperators_prev_round >= math.ceil(self.m / 2) * 1.5:
                return Action.C
            else:
                return Action.D
        if total_cooperators_prev_round >= self.m:
            return Action.C
        elif total_cooperators_prev_round >= self.m - 1:
            return Action.C
        elif total_cooperators_prev_round >= math.ceil(self.m / 2) and rounds_remaining > 2:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_219(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances collective benefit maximization, individual robustness, and adaptive learning
    by making cooperation contingent on observed cooperation rates meeting a threshold.
    Adjusts safety margins across three game phases: early (conservative), middle (balanced),
    and late (committed).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        all_opponent_cooperations = history.opponent_actions[:round_num, :]
        my_cooperations = history.my_actions[:round_num]
        total_cooperators = np.sum(all_opponent_cooperations) + np.sum(my_cooperations)
        total_slots = round_num * self.n_players
        if total_slots == 0:
            observed_cooperation_rate = 0.0
        else:
            observed_cooperation_rate = total_cooperators / total_slots
        expected_cooperators = math.floor(observed_cooperation_rate * self.n_players)
        cooperators_needed = self.m
        risk_of_failure = cooperators_needed - expected_cooperators
        early_phase_end = math.ceil(self.n_rounds / 3)
        late_phase_start = math.floor(2 * self.n_rounds / 3) + 1
        if round_num <= early_phase_end:
            threshold_safety_margin = 1.0
        elif round_num >= late_phase_start:
            threshold_safety_margin = 0.0
        else:
            threshold_safety_margin = 0.5
        if round_num == self.n_rounds - 1:
            if observed_cooperation_rate >= self.m / self.n_players:
                return Action.C
            else:
                return Action.D
        if risk_of_failure > threshold_safety_margin:
            return Action.D
        elif expected_cooperators >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_220(BaseStrategy):
    """
    Collective Risk Adaptive Strategy (CRAS)
    
    Dynamically adjusts cooperation based on observed cooperation rates and remaining rounds.
    Exploits the threshold structure while protecting against exploitation through:
    - First round cooperation (bootstrap phase)
    - Adaptive middle rounds based on cooperation rate tiers
    - Last round defection (no future consequences)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.r - 1:
            return Action.D
        previous_round_index = round_number - 1
        cooperators_previous = int(np.sum(history.opponent_actions[previous_round_index, :]))
        if history.my_actions[previous_round_index]:
            cooperators_previous += 1
        cooperation_rate = cooperators_previous / self.n
        threshold_ratio = self.m / self.n
        rounds_remaining = self.r - round_number
        if cooperation_rate >= threshold_ratio:
            if rounds_remaining >= 2:
                return Action.C
            else:
                return Action.D
        elif cooperation_rate >= threshold_ratio * 0.6:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_221(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by dynamically adjusting
    cooperation based on: (1) probability of reaching threshold m, (2) remaining rounds,
    and (3) historical cooperation rate in the group.
    
    Core logic:
    - Round 1: COOPERATE (information gathering)
    - Final round: DEFECT (no future payoff)
    - Rounds 2 to r-1: COOPERATE if observed cooperation rate >= adaptive threshold, else DEFECT
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        m = self.game_description.m
        k = self.game_description.k
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == r - 1:
            return Action.D
        previous_round_idx = current_round - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[previous_round_idx, :]))
        if history.my_actions[previous_round_idx]:
            cooperators_last_round += 1
        cooperation_rate = cooperators_last_round / n if n > 0 else 0.0
        base_threshold = m / n
        remaining_rounds = r - current_round
        time_adjustment = -0.05 * (remaining_rounds / n) if n > 0 else 0.0
        payoff_adjustment = -0.1 * (k - 1.0)
        threshold = base_threshold + time_adjustment + payoff_adjustment
        if current_round > r - 3:
            threshold += 0.15
        threshold = max(base_threshold, min(threshold, 1.0))
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_222(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances individual security with collective benefit through:
    1. Reciprocal cooperation based on demonstrated reliability
    2. Dynamic threshold adjustment to changing cooperation rates
    3. Protective defection when collective success becomes unlikely
    4. Opportunistic defection minimization through reputation tracking
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if self.n == 2:
            return self._handle_two_players(history, round_num)
        if self.m == self.n:
            return self._handle_unanimity_required(history, round_num)
        if round_num < self.r - 1:
            return self._adaptive_decision(history, round_num)
        return self._final_round_decision(history, round_num)

    def _handle_two_players(self, history: PlayerHistory, round_num: int) -> Action:
        """Special handling for n=2 case."""
        if round_num < 2:
            return Action.C
        opponent_last_two = history.opponent_actions[-2:, 0]
        if not opponent_last_two[0] and (not opponent_last_two[1]):
            return Action.D
        return Action.C

    def _handle_unanimity_required(self, history: PlayerHistory, round_num: int) -> Action:
        """Special handling for m=n case (unanimity required)."""
        coop_rate = self._calculate_cooperation_rate(history, round_num)
        if coop_rate >= 0.95:
            return Action.C
        return Action.D

    def _adaptive_decision(self, history: PlayerHistory, round_num: int) -> Action:
        """Adaptive phase for rounds 1 to r-2."""
        coop_rate = self._calculate_cooperation_rate(history, round_num)
        expected_coop = self._estimate_expected_cooperators(coop_rate)
        safety_buffer = expected_coop - self.m
        if safety_buffer >= 1:
            return Action.C
        if safety_buffer >= 0:
            recent_coop_rate = self._calculate_recent_cooperation_rate(history, round_num)
            if recent_coop_rate >= coop_rate:
                return Action.C
            return Action.D
        return Action.D

    def _final_round_decision(self, history: PlayerHistory, round_num: int) -> Action:
        """Decision logic for the final round."""
        coop_rate = self._calculate_cooperation_rate(history, round_num)
        expected_coop = self._estimate_expected_cooperators(coop_rate)
        if expected_coop >= self.m:
            return Action.C
        return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate historical cooperation rate across all players and all past rounds.
        
        coop_rate = (total cooperators across all rounds) / (n Ã— round_num)
        """
        if round_num == 0:
            return 0.0
        my_coop_count = np.sum(history.my_actions[:round_num])
        opponent_coop_count = np.sum(history.opponent_actions[:round_num, :])
        total_coop = my_coop_count + opponent_coop_count
        total_possible = self.n * round_num
        if total_possible == 0:
            return 0.0
        return total_coop / total_possible

    def _estimate_expected_cooperators(self, coop_rate: float) -> float:
        """
        Estimate expected cooperators in next round, assuming self-cooperation.
        
        expected_coop = coop_rate Ã— (n - 1) + 1
        """
        return coop_rate * (self.n - 1) + 1

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate cooperation rate over the last 2 rounds.
        
        recent_coop_rate = (cooperators in last 2 rounds) / (2 Ã— n)
        """
        if round_num < 2:
            return 0.0
        last_two_rounds = history.opponent_actions[round_num - 2:round_num, :]
        recent_opponent_coop = np.sum(last_two_rounds)
        my_last_two = np.sum(history.my_actions[round_num - 2:round_num])
        total_recent_coop = recent_opponent_coop + my_last_two
        total_possible = 2 * self.n
        if total_possible == 0:
            return 0.0
        return total_recent_coop / total_possible

class Strategy_COLLECTIVE_223(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances collective welfare maximization with individual resilience by:
    1. Cooperating in round 1 to signal intent
    2. Adaptively cooperating based on threshold progress and free-rider detection
    3. Defecting in final round (backward induction)
    4. Protecting against systematic exploitation (>33% free-riders)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.r - 1:
            return Action.D
        prev_round_idx = state.round_number - 1
        coop_count_prev = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            coop_count_prev += 1
        coop_rate = coop_count_prev / self.n
        threshold_met = coop_count_prev >= self.m
        if threshold_met:
            free_riders = 0
            for opponent_idx in range(self.n - 1):
                if not history.opponent_actions[prev_round_idx, opponent_idx]:
                    free_riders += 1
            exploitation_ratio = free_riders / self.n if self.n > 0 else 0
            if exploitation_ratio > 0.33:
                return Action.D
            else:
                return Action.C
        elif coop_count_prev >= self.m - 1:
            if history.my_actions[prev_round_idx] and coop_count_prev < self.m:
                if coop_rate > 0.5:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.C
        elif coop_count_prev >= math.ceil(self.m / 2):
            if coop_rate >= 0.4:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_224(BaseStrategy):
    """
    Adaptive Threshold Sentinel strategy for Collective Risk Dilemma.
    
    Balances conditional cooperation, defection detection, and dynamic adaptation
    to maximize both individual and collective payoffs across repeated rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        if t == 0:
            return Action.C
        cooperators_last_round = int(sum(history.opponent_actions[t - 1, :]))
        if history.my_actions[t - 1]:
            cooperators_last_round += 1
        cascade_failure = True
        for round_idx in range(t):
            round_cooperators = int(sum(history.opponent_actions[round_idx, :]))
            if history.my_actions[round_idx]:
                round_cooperators += 1
            if round_cooperators >= self.m:
                cascade_failure = False
                break
        if cascade_failure and t > 1:
            return Action.D
        if t == self.r - 1:
            if cooperators_last_round >= self.m - 1:
                return Action.C
            else:
                return Action.D
        gap = self.m - 1 - cooperators_last_round
        if cooperators_last_round >= self.m - 1:
            return Action.C
        if gap > 0:
            rounds_remaining = self.r - t
            critical_threshold = max(1, self.r * 0.25)
            critical_phase_ratio = min(1.0, rounds_remaining / critical_threshold)
            denominator = max(1, self.n - self.m + 1)
            gap_prob = min(1.0, gap / denominator)
            cooperation_probability = gap_prob * critical_phase_ratio
            if random.random() < cooperation_probability:
                return Action.C
            else:
                return Action.D
        return Action.C

class Strategy_COLLECTIVE_225(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances individual and collective rationality by making cooperation contingent
    on observable cooperation rates from previous rounds, with adaptive thresholds
    that lower over time and include robustness against persistent defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.decay_factor = 0.2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        round_t = state.round_number + 1
        if round_t == 1:
            threshold_initial = (m - 1) / n
            if threshold_initial <= 0.5:
                return Action.C
            else:
                return Action.D
        prev_round_idx = round_t - 2
        prev_cooperators = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        coop_rate = prev_cooperators / n
        if round_t > 2:
            two_rounds_back_idx = round_t - 3
            coop_rate_two_back = int(np.sum(history.opponent_actions[two_rounds_back_idx, :])) / n
            if coop_rate < 0.3 and coop_rate_two_back < 0.3:
                return Action.D
        if round_t == r:
            threshold = 0.5
        else:
            threshold = max(0.5, (m - 1) / n + self.decay_factor * (r - round_t) / r)
        if coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_226(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Starting with cooperation to signal good intent
    2. Calibrating responses to observed cooperation rate vs. threshold
    3. Using probabilistic interpolation near the threshold
    4. Committing to cooperation in penultimate round
    5. Playing strict threshold response in final round
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 2:
            return Action.C
        if current_round == self.r - 1:
            previous_cooperators = np.sum(history.opponent_actions[current_round - 1, :])
            previous_coop_rate = previous_cooperators / self.n
            threshold_ratio = self.m / self.n
            if previous_coop_rate >= threshold_ratio:
                return Action.C
            else:
                return Action.D
        previous_cooperators = np.sum(history.opponent_actions[current_round - 1, :])
        coop_rate = previous_cooperators / self.n
        threshold_ratio = self.m / self.n
        if coop_rate >= threshold_ratio:
            return Action.C
        lower_bound = (self.m - 2) / self.n
        if coop_rate >= lower_bound:
            prob = (coop_rate - lower_bound) / (2.0 / self.n)
            prob = max(0.0, min(1.0, prob))
            if random.random() < prob:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_227(BaseStrategy):
    """
    Adaptive Threshold Sentinel strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare through:
    - Monitoring cooperation rates against the success threshold (m/n)
    - Reciprocal contribution with adaptive tolerance
    - Risk calibration based on game progress
    - Last-round integrity preservation
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.epsilon = 0.15
        self.threshold_decay = 0.6
        self.cooperation_counts = []
        self.oscillation_count = 0
        self.last_cooperation_rate = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        m = self.game_description.m
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        prev_round_idx = current_round - 1
        my_prev_action = history.my_actions[prev_round_idx]
        opponent_prev_actions = history.opponent_actions[prev_round_idx, :]
        cooperators_prev_round = int(my_prev_action) + int(np.sum(opponent_prev_actions))
        cooperation_rate = cooperators_prev_round / n if n > 0 else 0.0
        required_rate = m / n if n > 0 else 0.0
        self.cooperation_counts.append(cooperators_prev_round)
        self._detect_oscillation(required_rate)
        if cooperation_rate >= required_rate - self.epsilon:
            return Action.C
        elif cooperation_rate >= required_rate * self.threshold_decay:
            p_adaptive = (r - current_round) / r * 0.8 + 0.2 if r > 0 else 0.5
            if random.random() < p_adaptive:
                return Action.C
            else:
                return Action.D
        else:
            if current_round == r - 1:
                if len(self.cooperation_counts) > 0:
                    historical_coop_rate = np.mean(self.cooperation_counts) / n if n > 0 else 0.0
                else:
                    historical_coop_rate = 0.0
                if historical_coop_rate >= required_rate - self.epsilon:
                    return Action.C
            return Action.D

    def _detect_oscillation(self, required_rate: float) -> None:
        """
        Detect oscillation pattern: if cooperation oscillates above/below threshold
        for 3+ consecutive rounds, increase defection likelihood.
        """
        if len(self.cooperation_counts) < 3:
            return
        n = self.game_description.n_players
        threshold_cooperators = self.game_description.m
        last_three = self.cooperation_counts[-3:]
        is_above = [count >= threshold_cooperators for count in last_three]
        if is_above[0] != is_above[1] and is_above[1] != is_above[2]:
            self.oscillation_count += 1
            if self.oscillation_count >= 3:
                self.threshold_decay = 0.5

class Strategy_COLLECTIVE_228(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by monitoring cooperation levels,
    adjusting commitment based on proximity to the critical m-threshold, and maintaining
    consistent behavior throughout the game. Uses graduated commitment: defect when cooperation
    is insufficient, cooperate when threshold is likely met, and recognize pivotal moments
    when individual contribution tips collective success.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defection_inertia_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        if state.round_number == 0:
            return Action.D
        previous_round_idx = state.round_number - 1
        previous_round_opponent_actions = history.opponent_actions[previous_round_idx, :]
        cooperators_last_round = int(np.sum(previous_round_opponent_actions))
        my_previous_action = history.my_actions[previous_round_idx]
        total_cooperators_last_round = cooperators_last_round + int(my_previous_action)
        cooperation_rate = total_cooperators_last_round / n
        expected_cooperators_next = cooperation_rate * n
        if expected_cooperators_next >= m:
            decision = Action.C
        elif expected_cooperators_next < m - 1:
            decision = Action.D
        else:
            decision = Action.C
        if self.defection_inertia_counter > 0:
            decision = Action.D
            self.defection_inertia_counter -= 1
        elif cooperation_rate < 0.3 and decision == Action.C:
            decision = Action.D
            self.defection_inertia_counter = 1
        if cooperation_rate >= 0.5:
            self.defection_inertia_counter = 0
        return decision

class Strategy_COLLECTIVE_229(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances individual security with collective welfare by dynamically adjusting
    cooperation based on observed cooperation patterns and round phase. Makes decisions
    relative to the threshold m rather than absolute cooperation levels.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        last_round_cooperators = self._count_last_round_cooperators(history)
        recent_cooperation_rate = self._calculate_recent_cooperation_rate(history)
        if round_num == self.r - 1:
            deficit = self.m - last_round_cooperators
            if last_round_cooperators >= self.m:
                return Action.C
            elif deficit <= 2:
                return Action.C
            else:
                return Action.D
        deficit = self.m - last_round_cooperators
        if deficit == 0:
            base_prob = 0.6
            momentum_factor = recent_cooperation_rate * 0.4
            cooperation_prob = base_prob + momentum_factor
            return Action.C if random.random() < cooperation_prob else Action.D
        elif deficit > 0 and deficit <= self.n / 4:
            return Action.C
        elif deficit > self.n / 4:
            if recent_cooperation_rate >= self.m / self.n:
                return Action.C
            else:
                return Action.D
        return Action.C

    def _count_last_round_cooperators(self, history: PlayerHistory) -> int:
        """Count cooperators (including self) in the most recent round."""
        last_round_opponent_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        my_last_action = int(history.my_actions[-1])
        return last_round_opponent_cooperators + my_last_action

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory) -> float:
        """
        Calculate average cooperation rate over recent rounds (up to 5 rounds back).
        Includes both self and opponents.
        """
        lookback = min(5, len(history.my_actions))
        if lookback == 0:
            return 0.0
        recent_actions = history.opponent_actions[-lookback:, :]
        recent_my_actions = history.my_actions[-lookback:]
        total_cooperators = np.sum(recent_actions) + np.sum(recent_my_actions)
        total_slots = lookback * (self.n + 1)
        if total_slots == 0:
            return 0.0
        return float(total_cooperators) / float(total_slots)

class Strategy_COLLECTIVE_230(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by adapting cooperation
    decisions based on historical cooperation rates, round position, and risk assessment.
    Core principle: Cooperate to sustain the collective threshold, but only as much as needed.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        early_end = math.ceil(self.r / 3)
        mid_end = math.floor(2 * self.r / 3)
        total_rounds_played = round_num
        all_actions = history.opponent_actions[:round_num, :]
        my_actions = history.my_actions[:round_num]
        total_opponent_coop = np.sum(all_actions)
        total_coop_rate = total_opponent_coop / (total_rounds_played * self.n)
        recent_rounds = min(3, round_num)
        recent_actions = all_actions[max(0, round_num - recent_rounds):round_num, :]
        recent_coop_count = np.sum(recent_actions)
        recent_coop_rate = recent_coop_count / (recent_rounds * self.n) if recent_rounds > 0 else 0.0
        threshold_rate = self.m / self.n
        if round_num <= early_end:
            if total_coop_rate >= threshold_rate:
                return Action.C
            if self._can_enable_threshold(all_actions, round_num):
                return Action.C
            if self._has_defection_pattern(all_actions, round_num):
                return Action.D
            return Action.C
        elif round_num <= mid_end:
            epsilon = 0.05
            if recent_coop_rate >= threshold_rate - epsilon:
                return Action.C
            if self._would_defection_break_threshold(all_actions, round_num):
                return Action.C
            return Action.D
        elif round_num == self.r - 1:
            if total_coop_rate >= threshold_rate - 0.1:
                return Action.D
            else:
                return Action.C
        elif round_num == self.r:
            if total_coop_rate >= threshold_rate:
                return Action.D
            else:
                return Action.C
        return Action.C

    def _can_enable_threshold(self, all_actions: NDArray, current_round: int) -> bool:
        """
        Check if this player's cooperation would enable reaching the threshold.
        Returns True if the group is currently at m-1 cooperators (opponent perspective).
        """
        if current_round == 0:
            return False
        recent_coop = int(np.sum(all_actions[current_round - 1, :]))
        if recent_coop >= self.m - 1:
            return True
        return False

    def _would_defection_break_threshold(self, all_actions: NDArray, current_round: int) -> bool:
        """
        Check if our defection would cause the threshold to be broken.
        This happens when opponent cooperation is barely at or just above m.
        """
        if current_round == 0:
            return False
        recent_rounds = min(3, current_round)
        recent_actions = all_actions[max(0, current_round - recent_rounds):current_round, :]
        for i in range(recent_actions.shape[0]):
            coop_count = int(np.sum(recent_actions[i, :]))
            if coop_count <= self.m + 1 and coop_count >= self.m:
                return True
        return False

    def _has_defection_pattern(self, all_actions: NDArray, current_round: int) -> bool:
        """
        Detect if defections are concentrated and persistent.
        Returns True if multiple consecutive rounds show cooperation < m.
        """
        if current_round < 3:
            return False
        recent_actions = all_actions[max(0, current_round - 3):current_round, :]
        failure_count = 0
        for i in range(recent_actions.shape[0]):
            coop_count = int(np.sum(recent_actions[i, :]))
            if coop_count < self.m:
                failure_count += 1
        return failure_count >= 2

class Strategy_COLLECTIVE_231(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances collective welfare, individual rationality, and robustness by treating
    the cooperation threshold as the primary strategic object. Uses adaptive threshold
    tracking and information-responsive cooperation to maximize probability of reaching
    the threshold while avoiding exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        total_rounds = self.n_rounds
        m = self.m
        n = self.n_players
        if round_number == 0:
            if m / n <= 0.5:
                return Action.C
            else:
                return Action.D
        prev_cooperators = int(sum(history.opponent_actions[round_number - 1, :]))
        if history.my_actions[round_number - 1]:
            prev_cooperators += 1
        if round_number == total_rounds - 1:
            if prev_cooperators >= m:
                return Action.C
            elif prev_cooperators >= math.ceil(m / 2.0):
                return Action.C
            else:
                return Action.D
        cooperators_needed = m - prev_cooperators
        rounds_remaining = total_rounds - round_number
        if cooperators_needed <= 0:
            cooperation_probability_needed = 0.0
        else:
            cooperation_probability_needed = cooperators_needed / float(n)
        safe_margin = rounds_remaining / 2.0
        if cooperation_probability_needed <= 0.5:
            return Action.C
        elif cooperation_probability_needed > 0.5 and rounds_remaining > safe_margin:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_232(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances cooperation with defection by:
    1. Starting with cooperation to signal trustworthiness
    2. Adapting to observed cooperation rates in middle rounds
    3. Making final-round decisions based on threshold achievement likelihood
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            return self._decide_final_round(history)
        return self._decide_middle_round(current_round, history)

    def _decide_final_round(self, history: PlayerHistory) -> Action:
        """
        Final round decision: cooperate if threshold was met last round,
        otherwise defect to maximize payoff.
        """
        penultimate_round_idx = self.r - 2
        cooperators = sum(history.opponent_actions[penultimate_round_idx, :])
        if history.my_actions[penultimate_round_idx]:
            cooperators += 1
        cooperation_rate = cooperators / self.n
        threshold_rate = self.m / self.n
        if cooperation_rate >= threshold_rate:
            return Action.C
        else:
            return Action.D

    def _decide_middle_round(self, current_round: int, history: PlayerHistory) -> Action:
        """
        Middle rounds decision: adapt based on observed cooperation rate
        and rounds remaining.
        """
        prev_round_idx = current_round - 1
        cooperators = sum(history.opponent_actions[prev_round_idx, :])
        if history.my_actions[prev_round_idx]:
            cooperators += 1
        cooperation_rate = cooperators / self.n
        rounds_remaining = self.r - current_round
        threshold_rate = self.m / self.n
        near_threshold_rate = (self.m - 1) / self.n if self.m > 1 else 0
        if cooperation_rate >= threshold_rate:
            return Action.C
        if rounds_remaining > 2:
            return Action.D
        if cooperation_rate >= near_threshold_rate:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_233(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy
    
    Balances individual security with collective benefit by monitoring group health,
    adapting cooperation based on observed cooperation rates, and withdrawing when
    the group systematically fails to meet the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_failures = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        last_round_idx = state.round_number - 1
        opponent_actions_last_round = history.opponent_actions[last_round_idx, :]
        cooperators_last_round = int(np.sum(opponent_actions_last_round)) + int(history.my_actions[last_round_idx])
        threshold_met_last = cooperators_last_round >= m
        if not threshold_met_last:
            self.consecutive_failures += 1
        else:
            self.consecutive_failures = 0
        failure_threshold = math.ceil((n - m) / 2) + 1
        target_rate = (m + 1) / n
        min_rate = (m - 1) / n
        observed_cooperators = int(np.sum(opponent_actions_last_round))
        observed_rate = observed_cooperators / n if n > 0 else 0.0
        if self.consecutive_failures >= failure_threshold:
            return Action.D
        if observed_rate >= target_rate:
            return Action.C
        if observed_rate >= min_rate:
            if target_rate > min_rate:
                escalate_prob = min(0.7, (observed_rate - min_rate) / (target_rate - min_rate))
            else:
                escalate_prob = 0.7
            if random.random() < escalate_prob:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_234(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Cooperating initially to test group coordination
    2. Adaptively responding to cooperation deficits in middle rounds
    3. Making endgame decisions based on threshold achievement
    
    The strategy recognizes that cooperation is rational when k > 1,
    adapts to group behavior without explicit coordination, and stabilizes
    cooperation near the threshold m for mutual benefit.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        prev_round_cooperators = int(sum(history.opponent_actions[prev_round_idx, :]))
        if current_round == self.n_rounds - 1:
            if prev_round_cooperators >= self.m:
                return Action.C
            else:
                return Action.D
        cooperation_deficit = self.m - prev_round_cooperators
        if cooperation_deficit > 0:
            small_gap_threshold = math.ceil(self.n_players / 4)
            if cooperation_deficit <= small_gap_threshold:
                return Action.C
            else:
                return Action.D
        elif cooperation_deficit == 0:
            return Action.C
        elif prev_round_cooperators <= self.m + 1:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_235(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances collective welfare (maximizing threshold achievement) with individual
    resilience (avoiding unilateral cooperation losses). Uses observation-based
    cooperation rates to make graduated decisions, with recovery signals and
    defection penalties for robustness.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_round_active = False
        self.last_defection_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        k = self.game_description.k
        if round_num == 0:
            return Action.C
        total_coop_actions = np.sum(history.opponent_actions[:round_num, :])
        total_actions_observed = round_num * (n - 1)
        if total_actions_observed == 0:
            coop_rate = 0.0
        else:
            coop_rate = float(total_coop_actions) / float(total_actions_observed)
        recent_rounds_count = min(2, round_num)
        earlier_rounds_count = max(0, round_num - recent_rounds_count - 2)
        if recent_rounds_count > 0:
            recent_coop_sum = np.sum(history.opponent_actions[max(0, round_num - recent_rounds_count):round_num, :])
            recent_coop_rate = float(recent_coop_sum) / float(recent_rounds_count * (n - 1))
        else:
            recent_coop_rate = 0.0
        if earlier_rounds_count > 0:
            earlier_coop_sum = np.sum(history.opponent_actions[:max(0, round_num - recent_rounds_count - 2), :])
            earlier_coop_rate = float(earlier_coop_sum) / float(earlier_rounds_count * (n - 1))
        else:
            earlier_coop_rate = 0.0
        improvement = recent_coop_rate - earlier_coop_rate
        threshold_base = float(m) / float(n)
        if round_num == r - 1:
            if coop_rate >= threshold_base * 0.75:
                return Action.C
            else:
                return Action.D
        last_two_coop_rate = 0.0
        if round_num >= 2:
            last_two_sum = np.sum(history.opponent_actions[max(0, round_num - 2):round_num, :])
            last_two_coop_rate = float(last_two_sum) / float(2 * (n - 1)) if n - 1 > 0 else 0.0
        if last_two_coop_rate < 0.2:
            if not self.punishment_round_active:
                self.punishment_round_active = True
                self.last_defection_rounds = 1
                return Action.D
            else:
                self.last_defection_rounds += 1
                if self.last_defection_rounds > 1:
                    self.punishment_round_active = False
                    self.last_defection_rounds = 0
                else:
                    return Action.D
        else:
            self.punishment_round_active = False
            self.last_defection_rounds = 0
        if improvement > 0.15:
            threshold_base *= 0.9
        if coop_rate >= threshold_base * 1.1:
            return Action.C
        elif coop_rate >= threshold_base * 0.9:
            return Action.C
        elif coop_rate >= threshold_base * 0.6:
            cooperation_prob = coop_rate / threshold_base if threshold_base > 0 else 0.0
            cooperation_prob = min(1.0, max(0.0, cooperation_prob))
            if random.random() < cooperation_prob:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_236(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by adaptively adjusting
    cooperation based on observed group behavior and remaining rounds. The strategy
    uses phase-based decision rules: probing in early rounds, sustaining in middle rounds,
    and optimizing in final rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        phase1_end = math.ceil(self.n_rounds / 3)
        phase2_end = math.floor(2 * self.n_rounds / 3)
        total_rounds_so_far = round_num
        total_cooperators_all = int(np.sum(history.opponent_actions[:round_num, :]))
        total_cooperators_all += int(np.sum(history.my_actions[:round_num]))
        total_possible = self.n_players * total_rounds_so_far
        observed_cooperation_rate = total_cooperators_all / total_possible if total_possible > 0 else 0
        cooperation_threshold = (self.m - 0.5) / self.n_players
        if self.m / self.n_players > 0.85:
            cooperation_threshold += 0.1
        elif self.m / self.n_players < 0.4:
            cooperation_threshold = (self.m - 1.5) / self.n_players
        if round_num <= phase1_end:
            if observed_cooperation_rate >= cooperation_threshold:
                return Action.C
            else:
                return Action.D
        elif round_num <= phase2_end:
            recent_rounds = min(5, round_num)
            recent_cooperators = int(np.sum(history.opponent_actions[round_num - recent_rounds:round_num, :]))
            recent_cooperators += int(np.sum(history.my_actions[round_num - recent_rounds:round_num]))
            recent_cooperation_rate = recent_cooperators / (self.n_players * recent_rounds) if recent_rounds > 0 else 0
            threshold_probability = recent_cooperation_rate >= cooperation_threshold
            if threshold_probability:
                return Action.C
            else:
                rounds_remaining = self.n_rounds - round_num
                if rounds_remaining > self.n_rounds / 3:
                    return Action.D
                else:
                    return Action.C
        else:
            rounds_remaining = self.n_rounds - round_num
            if rounds_remaining == 1:
                recent_rounds = min(5, round_num)
                if recent_rounds > 0:
                    recent_cooperators = int(np.sum(history.opponent_actions[round_num - recent_rounds:round_num, :]))
                    recent_cooperators += int(np.sum(history.my_actions[round_num - recent_rounds:round_num]))
                    recent_cooperation_rate = recent_cooperators / (self.n_players * recent_rounds)
                else:
                    recent_cooperation_rate = 0
                if recent_cooperation_rate >= cooperation_threshold:
                    return Action.C
                else:
                    return Action.D
            else:
                recent_rounds = min(5, round_num)
                if recent_rounds > 0:
                    recent_cooperators = int(np.sum(history.opponent_actions[round_num - recent_rounds:round_num, :]))
                    recent_cooperators += int(np.sum(history.my_actions[round_num - recent_rounds:round_num]))
                    recent_cooperation_rate = recent_cooperators / (self.n_players * recent_rounds)
                else:
                    recent_cooperation_rate = 0
                success_likelihood = recent_cooperation_rate >= cooperation_threshold
                if success_likelihood and rounds_remaining <= 3:
                    return Action.C
                elif not success_likelihood:
                    return Action.D
                elif random.random() < success_likelihood:
                    return Action.C
                else:
                    return Action.D

class Strategy_COLLECTIVE_237(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) for Collective Risk Dilemma.
    
    Cooperates adaptively based on observed cooperation rates and dynamically
    calculated thresholds that balance collective success probability with
    individual rationality. Thresholds account for remaining rounds, payoff
    structure, and accumulated cooperation history.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_rates = []
        self.buffer = 0.15
        self.decay_factor = 0.1
        self.momentum_multiplier = 0.05

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round_idx = state.round_number - 1
        opponent_cooperators = np.sum(history.opponent_actions[prev_round_idx, :])
        my_prev_action = history.my_actions[prev_round_idx]
        total_cooperators = opponent_cooperators + (1 if my_prev_action else 0)
        observed_cooperation_rate = total_cooperators / self.game_description.n_players
        self.cooperation_rates.append(observed_cooperation_rate)
        remaining_rounds = self.game_description.n_rounds - state.round_number
        if remaining_rounds == 1:
            breakeven_point = self.game_description.m / self.game_description.n_players
            if observed_cooperation_rate >= breakeven_point:
                return Action.C
            else:
                return Action.D
        threshold = self._calculate_threshold(state.round_number, observed_cooperation_rate)
        if observed_cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_threshold(self, current_round: int, observed_cooperation_rate: float) -> float:
        """
        Dynamically calculate cooperation threshold based on game state,
        remaining rounds, and cooperative momentum.
        """
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        remaining_rounds = r - current_round
        breakeven_point = m / n
        success_probability = observed_cooperation_rate * n / m
        success_probability = max(0.0, min(1.0, success_probability))
        if remaining_rounds == 1:
            threshold = max(0.0, breakeven_point - 0.05)
        else:
            decay = self.decay_factor * (current_round / r)
            base_threshold = breakeven_point + self.buffer
            adjusted_threshold = success_probability - decay
            threshold = max(base_threshold, adjusted_threshold)
        if len(self.cooperation_rates) > 0:
            prev_success = self.cooperation_rates[-1] >= m / n
            if prev_success:
                threshold = max(breakeven_point, threshold - self.momentum_multiplier)
            else:
                threshold = min(1.0, threshold + 2 * self.momentum_multiplier)
        if current_round <= r // 2:
            if observed_cooperation_rate >= 0.5:
                threshold = max(breakeven_point, threshold - 0.05)
        threshold = max(0.0, min(1.0, threshold))
        return threshold

class Strategy_COLLECTIVE_238(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Actively seeking to meet the cooperation threshold m
    2. Dynamically adjusting cooperation based on observable progress
    3. Punishing defection without escalating mutual destruction
    4. Protecting against exploitation while rewarding cooperation
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        cooperators_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
        my_last_action = history.my_actions[current_round - 1]
        my_last_payoff = history.my_payoffs[current_round - 1]
        opponent_payoffs_last = history.opponent_payoffs[current_round - 1, :]
        avg_opponent_payoff = float(np.mean(opponent_payoffs_last)) if len(opponent_payoffs_last) > 0 else 0.0
        if cooperators_last_round >= self.m:
            if not my_last_action and my_last_payoff - avg_opponent_payoff > 0.5:
                return Action.D
            else:
                return Action.C
        elif cooperators_last_round == self.m - 1:
            return Action.C
        elif cooperators_last_round >= math.ceil(self.m / 2.0):
            if current_round <= self.r * 0.5:
                return Action.C
            else:
                return Action.D
        else:
            if self.m > 0:
                cooperate_probability = cooperators_last_round / float(self.m) * 0.6 + 0.2
            else:
                cooperate_probability = 0.2
            if random.random() < cooperate_probability:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_239(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual rational self-interest with collective welfare by dynamically
    adjusting cooperation based on observable cooperation rates and round progression.
    Cooperates when conditions permit collective success; defects when collective breaks down.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        required_rate = self.m / self.n
        prev_round_idx = round_num - 1
        cooperators_last_round = int(sum(history.opponent_actions[prev_round_idx, :]))
        coop_rate = cooperators_last_round / self.n
        if round_num == self.r - 1:
            total_cooperations = 0
            for past_round in range(round_num):
                total_cooperations += int(sum(history.opponent_actions[past_round, :]))
            avg_historical_coop_rate = total_cooperations / (round_num * self.n)
            if avg_historical_coop_rate >= required_rate:
                return Action.C
            else:
                return Action.D
        if coop_rate >= required_rate:
            return Action.C
        elif coop_rate >= required_rate * 0.5:
            p_adjust = min(0.5, coop_rate / required_rate * 0.7)
            if random.random() < p_adjust:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_240(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances cooperation efficiency, defection deterrence, and robustness by:
    - Always cooperating in round 1 to establish cooperation baseline
    - Using strict threshold check in final round
    - Adapting cooperation dynamically in intermediate rounds based on observed cooperation rates
    - Including recovery mechanism when threshold is mathematically achievable
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        if t == 0:
            return Action.C
        prev_round_idx = t - 1
        prev_cooperators = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        cooperation_rate = prev_cooperators / self.n_players
        if t == self.n_rounds - 1:
            if prev_cooperators >= self.m:
                return Action.C
            else:
                return Action.D
        threshold_rate = self.m / self.n_players
        if cooperation_rate >= 1.1 * threshold_rate:
            return Action.C
        elif cooperation_rate >= 0.9 * threshold_rate:
            prob_cooperate = threshold_rate / cooperation_rate
            if random.random() < prob_cooperate:
                return Action.C
            else:
                return Action.D
        else:
            rounds_remaining = self.n_rounds - t
            deficit = self.m - prev_cooperators
            if deficit <= rounds_remaining and cooperation_rate >= 0.25:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_241(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS): Balances conditional cooperation with robust 
    self-preservation by monitoring observed cooperation rates and adapting decisions 
    based on proximity to the success threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_cooperators = int(sum(history.opponent_actions[round_num - 1, :]))
        cooperation_rate = prev_round_cooperators / self.n
        threshold_rate = self.m / self.n
        rounds_remaining = self.r - round_num
        if prev_round_cooperators >= self.m:
            return Action.C
        if prev_round_cooperators == 0:
            return Action.D
        if round_num == self.r - 1:
            if prev_round_cooperators >= self.m:
                return Action.C
            else:
                return Action.D
        if cooperation_rate > threshold_rate / 2:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_242(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances collective benefit, individual security, and adaptive resilience by:
    1. Starting optimistically proportional to threshold achievability
    2. Conditionally cooperating based on recent success rates
    3. Defecting in final round unless group shows exceptional commitment
    4. Handling edge cases (trivial/demanding thresholds, oscillating history)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return self._optimistic_opening()
        if round_num == self.r - 1:
            return self._final_round_decision(history)
        return self._conditional_cooperation(round_num, history)

    def _optimistic_opening(self) -> Action:
        """
        Round 1 decision: Optimism proportional to threshold achievability.
        """
        threshold_ratio = self.m / self.n
        if self.m <= 2:
            return Action.C
        if threshold_ratio > 0.75:
            return Action.D
        if threshold_ratio <= 0.5:
            return Action.C
        elif threshold_ratio <= 0.75:
            if random.random() < 0.7:
                return Action.C
            else:
                return Action.D
        return Action.D

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """
        Final round strategy: Only cooperate if group showed exceptional commitment
        or if threshold was met last round.
        """
        prev_round_idx = self.r - 2
        prev_cooperators = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            prev_cooperators += 1
        if prev_cooperators >= self.m:
            return Action.D
        cooperation_rate_prev = prev_cooperators / self.n
        if cooperation_rate_prev >= 0.8:
            return Action.C
        if self.m <= 2:
            return Action.C
        return Action.D

    def _conditional_cooperation(self, round_num: int, history: PlayerHistory) -> Action:
        """
        Main strategy for rounds 2 to r-1:
        Cooperate based on recent success rate relative to threshold ratio.
        """
        if self.m <= 2:
            return Action.C
        threshold_ratio = self.m / self.n
        if threshold_ratio > 0.75:
            max_cooperation_rate = np.mean([int(np.sum(history.opponent_actions[i, :])) for i in range(round_num)]) / self.n
            if max_cooperation_rate < 0.7:
                return Action.D
        w = min(3, round_num)
        recent_rounds = history.opponent_actions[round_num - w:round_num, :]
        threshold_met_count = 0
        for i in range(w):
            round_idx = round_num - w + i
            cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators >= self.m:
                threshold_met_count += 1
        recent_success_rate = threshold_met_count / w if w > 0 else 0.0
        cooperation_rates = []
        for i in range(round_num - w, round_num):
            if i >= 0:
                cooperators = int(np.sum(history.opponent_actions[i, :]))
                if history.my_actions[i]:
                    cooperators += 1
                cooperation_rates.append(cooperators / self.n)
        oscillating = False
        if len(cooperation_rates) >= 2:
            variance = np.var(cooperation_rates) if cooperation_rates else 0.0
            if variance > 0.25:
                oscillating = True
                w_reduced = min(2, round_num)
                threshold_met_count = 0
                for i in range(round_num - w_reduced, round_num):
                    if i >= 0:
                        cooperators = int(np.sum(history.opponent_actions[i, :]))
                        if history.my_actions[i]:
                            cooperators += 1
                        if cooperators >= self.m:
                            threshold_met_count += 1
                recent_success_rate = threshold_met_count / w_reduced if w_reduced > 0 else 0.0
        threshold_ratio = self.m / self.n
        high_threshold = threshold_ratio - 0.15
        medium_threshold = threshold_ratio - 0.3
        if oscillating:
            medium_threshold -= 0.1
        if recent_success_rate >= high_threshold:
            return Action.C
        elif recent_success_rate >= medium_threshold:
            if random.random() < 0.5:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_243(BaseStrategy):
    """
    Adaptive Threshold Reciprocity (ATR) Strategy for Collective Risk Dilemma.
    
    Balances collective welfare maximization with rational self-protection by:
    1. Starting cooperatively to signal willingness and test cooperation
    2. Adaptively maintaining cooperation if empirical cooperation rate suggests threshold m is achievable
    3. Defecting in final round (no future reputation consequences)
    4. Switching to defection if cooperation rate drops too low to reach threshold
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.n_rounds - 1:
            return Action.D
        total_cooperations_by_others = 0
        total_opportunities = (self.n_players - 1) * round_number
        for round_idx in range(round_number):
            cooperators_in_round = int(np.sum(history.opponent_actions[round_idx, :]))
            total_cooperations_by_others += cooperators_in_round
        if total_opportunities == 0:
            observed_cooperation_rate = 0.0
        else:
            observed_cooperation_rate = total_cooperations_by_others / total_opportunities
        expected_cooperators_next_round = (self.n_players - 1) * observed_cooperation_rate
        if expected_cooperators_next_round + 1 >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_244(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual security with collective success by cooperating when the
    probability of reaching the cooperation threshold is sufficiently high, and
    defecting when the threshold appears unreachable.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.base_threshold = self.m / self.n + 0.15
        if self.n <= 3 or self.m > self.n / 2:
            self.base_threshold = self.m / self.n + 0.25
        if self.r > 10:
            self.base_threshold += 0.05 * ((self.r - 5) // 5)
        self.base_threshold = min(self.base_threshold, 1.0)
        self.permanently_defect = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.permanently_defect:
            return Action.D
        coop_rate = self._calculate_coop_rate(history, state.round_number)
        if coop_rate < (self.m - 1) / self.n:
            self.permanently_defect = True
            return Action.D
        if state.round_number == self.r - 1:
            if coop_rate >= self.m / self.n:
                return Action.C
            else:
                return Action.D
        current_threshold = self._adjust_threshold_for_volatility(history, state.round_number)
        if coop_rate >= current_threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_coop_rate(self, history: PlayerHistory, round_number: int) -> float:
        """
        Calculate the cooperation rate from all previous rounds.
        
        Returns the proportion of cooperations observed across all players
        in all previous rounds (rounds 0 to round_number-1).
        """
        if round_number == 0:
            return 0.0
        total_cooperators = np.sum(history.opponent_actions[:round_number, :])
        total_slots = self.n * round_number
        if total_slots == 0:
            return 0.0
        return float(total_cooperators) / float(total_slots)

    def _adjust_threshold_for_volatility(self, history: PlayerHistory, round_number: int) -> float:
        """
        Adjust cooperation threshold based on observed volatility in cooperation rates.
        
        If cooperation fluctuates wildly, raise threshold to account for unreliability.
        """
        if round_number < 2:
            return self.base_threshold
        recent_coop = np.sum(history.opponent_actions[round_number - 1, :]) / self.n
        prev_coop = np.sum(history.opponent_actions[round_number - 2, :]) / self.n
        volatility = abs(recent_coop - prev_coop)
        if volatility > 0.2:
            return min(self.base_threshold + 0.05, 1.0)
        return self.base_threshold

class Strategy_COLLECTIVE_245(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective success by:
    1. Starting with cooperation to establish trust
    2. Detecting exploitation via payoff asymmetry
    3. Punishing free-riders while allowing redemption
    4. Using empirical cooperation rates for final round decisions
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.monitor_mode = False
        self.monitor_duration_remaining = 0
        self.cooperation_threshold = 0.55

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        round_num = state.round_number
        total_rounds = self.game_description.n_rounds
        m = self.game_description.m
        k = self.game_description.k
        if self.monitor_duration_remaining > 0:
            self.monitor_duration_remaining -= 1
        last_cooperators = int(np.sum(history.opponent_actions[round_num - 1, :]))
        my_last_action = history.my_actions[round_num - 1]
        if round_num == total_rounds - 1:
            total_cooperations = np.sum(history.my_actions) + np.sum(history.opponent_actions)
            total_possible = self.game_description.n_players * round_num
            if total_possible > 0:
                cooperation_rate = total_cooperations / total_possible
            else:
                cooperation_rate = 0.0
            if cooperation_rate > self.cooperation_threshold:
                return Action.C
            else:
                return Action.D
        if last_cooperators >= m:
            if my_last_action:
                my_payoff_last = history.my_payoffs[round_num - 1]
                expected_cooperative_payoff = k
                if my_payoff_last == k:
                    self.monitor_mode = True
                    self.monitor_duration_remaining = min(3, total_rounds - round_num - 1)
                    return Action.C
            return Action.C
        elif self.monitor_mode and self.monitor_duration_remaining > 0:
            return Action.D
        else:
            if self.monitor_duration_remaining <= 0:
                self.monitor_mode = False
            return Action.C

class Strategy_COLLECTIVE_246(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances individual security with collective benefit by conditioning cooperation
    on observed cooperation rates relative to an adaptive threshold. The threshold
    adjusts based on game phase (early forgiveness, mid moderation, late strictness)
    to enable trust-building while preventing exploitation in endgame scenarios.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            if self.m / self.n <= 0.5:
                return Action.C
            else:
                return Action.D
        recent_rounds_count = min(5, current_round)
        recent_start = current_round - recent_rounds_count
        recent_opponent_actions = history.opponent_actions[recent_start:current_round, :]
        cooperators_in_recent = np.sum(recent_opponent_actions)
        total_recent_observations = recent_rounds_count * (self.n - 1)
        if total_recent_observations == 0:
            cooperation_rate = 0.0
        else:
            cooperation_rate = cooperators_in_recent / total_recent_observations
        if current_round <= self.r / 3:
            forgiveness = 0.15
        elif current_round <= 2 * self.r / 3:
            forgiveness = 0.05
        else:
            forgiveness = -0.1
        threshold = (self.m - 1) / self.n + forgiveness
        remaining_rounds = self.r - current_round
        max_cooperators_possible = remaining_rounds * (self.n - 1) + cooperators_in_recent
        if self.m - max_cooperators_possible > remaining_rounds:
            return Action.D
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_247(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Dynamically adjusts cooperation based on collective need (proximity to threshold m),
    historical reliability of other players, and temporal urgency (rounds remaining).
    Balances individual rationality with collective welfare maximization.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.defection_recovery_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        last_round_cooperators = int(np.sum(history.opponent_actions[round_num - 1, :]))
        cooperation_rate_last_round = last_round_cooperators / self.n
        expected_cooperators = cooperation_rate_last_round * self.n
        if round_num >= 2:
            prev_round_cooperators = int(np.sum(history.opponent_actions[round_num - 2, :]))
            prev_cooperation_rate = prev_round_cooperators / self.n
            if prev_cooperation_rate - cooperation_rate_last_round > 0.3:
                self.defection_recovery_rounds = 2
        if self.defection_recovery_rounds > 0:
            self.defection_recovery_rounds -= 1
            return Action.C
        if round_num == self.r - 1:
            if cooperation_rate_last_round >= self.m / self.n:
                return Action.C
            else:
                return Action.D
        if self.n <= 3:
            if expected_cooperators >= self.m - 2:
                return Action.C
            else:
                return Action.D
        if self.m > self.n - 2:
            if cooperation_rate_last_round > 0.8:
                return Action.C
            else:
                return Action.D
        if self.m <= 2:
            return Action.C
        if self.r > 20 and round_num >= 3:
            recent_rounds = min(3, round_num)
            recent_coop_rates = []
            for i in range(round_num - recent_rounds, round_num):
                recent_cooperators = int(np.sum(history.opponent_actions[i, :]))
                recent_coop_rates.append(recent_cooperators / self.n)
            cooperation_rate_last_round = np.mean(recent_coop_rates)
            expected_cooperators = cooperation_rate_last_round * self.n
        if expected_cooperators >= self.m:
            return Action.C
        elif expected_cooperators >= self.m - 1:
            return Action.C
        elif expected_cooperators >= math.floor(self.m / 2):
            threshold_low = math.floor(self.m / 2)
            threshold_high = self.m
            cooperation_probability = (expected_cooperators - threshold_low) / (threshold_high - threshold_low)
            if random.random() < cooperation_probability:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_248(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances collective welfare with rational self-protection by:
    1. Investing in cooperation when collective can succeed
    2. Withdrawing strategically when cooperation appears unsustainable
    3. Punishing persistent defectors
    4. Recovering gracefully when conditions improve
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defection_penalty_score = 0
        self.consecutive_collapse_rounds = 0
        self.last_collapse_round = -1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        window_size = min(3, state.round_number)
        window_start = state.round_number - window_size
        cooperation_count = 0
        for round_idx in range(window_start, state.round_number):
            cooperators_in_round = np.sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators_in_round += 1
            cooperation_count += cooperators_in_round
        total_player_rounds = self.game_description.n_players * window_size
        recent_coop_rate = cooperation_count / total_player_rounds if total_player_rounds > 0 else 0
        cooperation_threshold = self.game_description.m / self.game_description.n_players * 1.25
        defection_rate_last_round = (self.game_description.n_players - np.sum(history.opponent_actions[state.round_number - 1, :]) - (1 if history.my_actions[state.round_number - 1] else 0)) / self.game_description.n_players
        if defection_rate_last_round >= 0.5:
            self.defection_penalty_score -= 1
        else:
            self.defection_penalty_score += 1
        if recent_coop_rate < 0.3:
            self.consecutive_collapse_rounds += 1
            if self.consecutive_collapse_rounds == 1:
                self.last_collapse_round = state.round_number - 1
        else:
            self.consecutive_collapse_rounds = 0
        if recent_coop_rate < 0.3 and self.consecutive_collapse_rounds >= 2:
            if state.round_number == self.last_collapse_round + 2:
                return Action.C
            elif recent_coop_rate > 0.4:
                return Action.C
            else:
                return Action.D
        if recent_coop_rate >= cooperation_threshold and self.defection_penalty_score >= 0:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_249(BaseStrategy):
    """
    Adaptive Threshold Rescue: A collectively-minded strategy for the Collective Risk Dilemma.
    
    Core philosophy: Break the defection cycle through observable commitment and intelligent adaptation.
    The strategy recognizes that individual payoff maximization requires collective success.
    
    Decision logic:
    - Round 1: Cooperate if threshold is modest (m/n â‰¤ 0.5), else defect
    - Middle rounds: Cooperate if threshold was met last round, or if close to threshold with any cooperation
    - Last round: Cooperate only if threshold was met last round
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.consecutive_collapse_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            threshold_ratio = self.m / self.n_players
            if threshold_ratio <= 0.5:
                return Action.C
            else:
                return Action.D
        last_round_idx = round_number - 1
        opponent_actions_last_round = history.opponent_actions[last_round_idx, :]
        cooperators_last_round = int(np.sum(opponent_actions_last_round))
        my_last_action = history.my_actions[last_round_idx]
        total_cooperators_last_round = cooperators_last_round + (1 if my_last_action else 0)
        cooperation_rate = total_cooperators_last_round / self.n_players
        if cooperation_rate == 0:
            self.consecutive_collapse_rounds += 1
        else:
            self.consecutive_collapse_rounds = 0
        if round_number == self.n_rounds - 1:
            if cooperation_rate >= self.m / self.n_players:
                return Action.C
            else:
                return Action.D
        threshold_ratio = self.m / self.n_players
        rescue_ratio = (self.m - 1) / self.n_players
        if cooperation_rate >= threshold_ratio:
            return Action.C
        if cooperation_rate >= rescue_ratio and cooperation_rate > 0:
            return Action.C
        if cooperation_rate == 0 and self.consecutive_collapse_rounds >= 2:
            return Action.D
        return Action.D

class Strategy_COLLECTIVE_250(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective benefit by:
    1. Cooperating unconditionally in round 1
    2. Adapting cooperation probabilistically in middle rounds based on observed cooperation rates
    3. Strategically defecting in final round if threshold was ever achieved
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold_ever_met = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if state.round_number == 0:
            return Action.C
        if history is not None:
            for round_idx in range(state.round_number):
                cooperators_that_round = int(np.sum(history.opponent_actions[round_idx, :])) + int(history.my_actions[round_idx])
                if cooperators_that_round >= m:
                    self.threshold_ever_met = True
                    break
        if state.round_number == r - 1:
            if self.threshold_ever_met:
                return Action.D
            else:
                return Action.C
        prev_round_idx = state.round_number - 1
        cooperators_prev = int(np.sum(history.opponent_actions[prev_round_idx, :])) + int(history.my_actions[prev_round_idx])
        p_coop = self._compute_cooperation_probability(cooperators_prev, n, m)
        if random.random() < p_coop:
            return Action.C
        else:
            return Action.D

    def _compute_cooperation_probability(self, c_prev: int, n: int, m: int) -> float:
        """
        Compute probability of cooperation based on previous round's cooperation count.
        """
        if c_prev >= m:
            denominator = n - m
            if denominator <= 0:
                p_coop = 0.9
            else:
                p_coop = 1.0 - (c_prev - m) / denominator
            if m == n:
                p_coop = min(1.0, p_coop + 0.1)
        elif m <= 0:
            p_coop = 0.7
        else:
            deficit_ratio = c_prev / m
            p_coop = max(0.3, 1.0 - deficit_ratio * 0.3)
        p_coop = max(0.0, min(1.0, p_coop))
        return p_coop

class Strategy_COLLECTIVE_251(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Navigates the tension between individual rationality and collective welfare by:
    1. Recognizing the threshold m as the critical pivot point
    2. Cooperating in early rounds to establish cooperation baseline
    3. Using adaptive reciprocity in middle rounds with threshold sensitivity
    4. Focusing on threshold achievement in final rounds
    5. Applying measured defection pressure when cooperation is too sparse
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if self.m == 1:
            return Action.C
        if self.m == self.n:
            if round_num == 0:
                return Action.C
            if np.all(history.opponent_actions[0, :]):
                return Action.C
            else:
                return Action.D
        total_coop_count = np.sum(history.opponent_actions[:round_num, :])
        total_possible = round_num * (self.n - 1)
        overall_coop_rate = total_coop_count / total_possible if total_possible > 0 else 0.0
        threshold_rate = (self.m - 1) / (self.n - 1)
        if round_num < math.floor(self.r / 2):
            if overall_coop_rate >= threshold_rate:
                return Action.C
            elif overall_coop_rate >= threshold_rate - 0.1:
                return Action.C
            else:
                return Action.D
        elif round_num == self.r - 1:
            total_coop_all_rounds = np.sum(history.opponent_actions[:round_num, :])
            if total_coop_all_rounds > self.m * round_num:
                return Action.C
            player_has_cooperated = np.any(history.opponent_actions[:round_num, :], axis=0)
            if np.sum(player_has_cooperated) == self.n - 1:
                return Action.C
            return Action.D
        elif round_num == self.r - 1:
            if round_num > 0:
                prev_round_coop = np.sum(history.opponent_actions[round_num - 1, :])
                if prev_round_coop >= self.m - 1:
                    return Action.C
            return Action.D
        else:
            recent_window = min(5, round_num)
            recent_start = round_num - recent_window
            recent_coop_count = np.sum(history.opponent_actions[recent_start:round_num, :])
            recent_coop_rate = recent_coop_count / (recent_window * (self.n - 1)) if recent_window > 0 else 0.0
            threshold_achievable = recent_coop_rate >= threshold_rate * 0.85
            recent_payoff_window = min(3, round_num)
            recent_payoff_start = round_num - recent_payoff_window
            if recent_payoff_start < round_num:
                recent_payoffs = history.my_payoffs[recent_payoff_start:round_num]
                recent_personal_payoff = np.mean(recent_payoffs) if len(recent_payoffs) > 0 else 0.0
            else:
                recent_personal_payoff = 0.0
            universal_cooperation_payoff = self.k
            if threshold_achievable:
                if recent_personal_payoff >= 0.8 * universal_cooperation_payoff:
                    return Action.C
                else:
                    return Action.C if random.random() < 0.7 else Action.D
            elif recent_coop_rate > 0.5 * threshold_rate:
                return Action.C if random.random() < 0.5 else Action.D
            else:
                return Action.D

class Strategy_COLLECTIVE_252(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances optimistic cooperation with pragmatic defection based on whether
    the critical mass (m cooperators) has been achieved in the previous round.
    
    Core logic:
    - Round 1: Always cooperate (optimistic start)
    - Subsequent rounds: Cooperate if observed cooperators >= m-1, else defect
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round_idx = state.round_number - 1
        opponent_cooperators_last_round = int(sum(history.opponent_actions[previous_round_idx, :]))
        own_action_last_round = int(history.my_actions[previous_round_idx])
        total_cooperators_last_round = opponent_cooperators_last_round + own_action_last_round
        if total_cooperators_last_round >= self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_253(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances collective efficiency with individual security by cooperating when
    confidence is high that the cooperation threshold (m) will be met, while
    protecting against free-riders through adaptive decision thresholds that
    relax over time to encourage recovery from defection cascades.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number + 1
        cooperators_last_round = int(sum(history.opponent_actions[state.round_number - 1, :]))
        if history.my_actions[state.round_number - 1]:
            cooperators_last_round += 1
        cooperation_rate = cooperators_last_round / self.n
        primary_threshold = (self.m - 1) / self.n
        adjustment_factor = min(0.15, (self.m - 1) / (2 * self.n))
        recovery_threshold = primary_threshold - current_round / self.r * adjustment_factor
        if current_round == self.r:
            if cooperation_rate >= primary_threshold:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= recovery_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_254(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual security with collective welfare by probing the environment,
    reciprocating based on observed cooperation, safeguarding against exploitation,
    and escalating pressure when the group approaches failure.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            threshold_rate = self.m / self.n
            if threshold_rate <= 0.5:
                return Action.C
            else:
                return Action.D
        if current_round == self.r - 1:
            return Action.D
        prev_round_idx = current_round - 1
        prev_cooperators = int(sum(history.opponent_actions[prev_round_idx, :]))
        coop_rate = prev_cooperators / self.n
        threshold_rate = self.m / self.n
        if self.n <= 4:
            lenient_threshold = 0.75
        else:
            lenient_threshold = 0.5
        if self.n > 8:
            near_miss_threshold = threshold_rate - 2.0 / self.n
        else:
            near_miss_threshold = threshold_rate - 1.0 / self.n
        if coop_rate >= threshold_rate:
            p_adapt = 0.9 + 0.1 * (coop_rate - threshold_rate) / max(1.0 - threshold_rate, 1e-10)
            if random.random() < p_adapt:
                return Action.C
            else:
                return Action.D
        if coop_rate >= near_miss_threshold:
            return Action.D
        rounds_remaining = self.r - current_round
        if rounds_remaining <= 3:
            return Action.D
        if coop_rate <= threshold_rate * 0.5:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_255(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) for Collective Risk Dilemma.
    
    Conditionally cooperates based on threshold achievability, reciprocity potential,
    and collective success likelihood. Defects in final round, when threshold is
    impossible, or when being exploited systematically.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        rounds_left = self.r - round_number
        if rounds_left == 0:
            return Action.D
        if round_number == 0:
            if self.m > (self.n + 1) / 2:
                return Action.D
            else:
                return Action.C
        last_round_idx = round_number - 1
        others_cooperated = int(np.sum(history.opponent_actions[last_round_idx, :]))
        min_others_needed = self.m - 1
        if others_cooperated < min_others_needed:
            return Action.D
        window_size = min(3, round_number)
        recent_rounds = history.opponent_actions[max(0, round_number - window_size):round_number, :]
        avg_others_cooperated = np.mean(np.sum(recent_rounds, axis=1))
        recent_cooperation_rate = avg_others_cooperated / (self.n - 1)
        defection_threshold = self.n / 2
        defection_count = 0
        if round_number >= 2:
            for i in range(max(0, round_number - 2), round_number):
                others_defected = self.n - 1 - int(np.sum(history.opponent_actions[i, :]))
                if others_defected > defection_threshold:
                    defection_count += 1
            if defection_count >= 2:
                return Action.D
        if others_cooperated == min_others_needed:
            threshold_ratio = self.m / self.n
            risk_threshold = threshold_ratio * 0.8
            if recent_cooperation_rate < risk_threshold:
                return Action.C
            else:
                return Action.D
        if others_cooperated >= self.m:
            return Action.D
        return Action.C

class Strategy_COLLECTIVE_256(BaseStrategy):
    """
    Adaptive Threshold Sentinel for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Cooperating in round 1 to signal good faith
    2. Adaptively tracking cooperation rates from history
    3. Cooperating when threshold success seems likely
    4. Attempting recovery from defection streaks
    5. Maintaining consistent strategy throughout all rounds
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defection_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round_idx = state.round_number - 1
        previous_cooperators = int(np.sum(history.opponent_actions[previous_round_idx, :]))
        cooperation_rate = previous_cooperators / self.game_description.n_players
        expected_cooperators = cooperation_rate * self.game_description.n_players + 1
        success_likely = expected_cooperators >= self.game_description.m
        if success_likely:
            self.defection_streak = 0
            return Action.C
        elif self.defection_streak >= 2:
            self.defection_streak = 0
            return Action.C
        else:
            self.defection_streak += 1
            return Action.D

class Strategy_COLLECTIVE_257(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    This strategy recognizes that cooperation is rational only when a threshold can be met.
    It cooperates in round 1 (Schelling point), then adaptively responds to the participation
    rate observed in previous rounds, cooperating when the threshold appears achievable and
    defecting only when it demonstrably cannot be reached.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round_idx = state.round_number - 1
        opponent_actions_prev_round = history.opponent_actions[prev_round_idx, :]
        opponent_cooperators = np.sum(opponent_actions_prev_round)
        my_action_prev = history.my_actions[prev_round_idx]
        total_cooperators_prev = opponent_cooperators + (1 if my_action_prev else 0)
        participation_rate = total_cooperators_prev / self.n_players
        near_threshold_rate = (self.m - 1) / self.n_players
        weak_threshold_rate = self.m / (2 * self.n_players)
        if participation_rate >= near_threshold_rate:
            return Action.C
        elif participation_rate >= weak_threshold_rate:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_258(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Dynamically adjusts cooperation based on observed cooperation rates and remaining rounds.
    Cooperates in first round, then reciprocates success when threshold is met, otherwise defects.
    Always defects in final round(s) due to lack of future consequences.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        rounds_remaining = r - current_round - 1
        previous_round_idx = current_round - 1
        opponent_cooperators_prev = int(sum(history.opponent_actions[previous_round_idx, :]))
        my_cooperation_prev = int(history.my_actions[previous_round_idx])
        total_cooperators_prev = opponent_cooperators_prev + my_cooperation_prev
        coop_rate_prev = total_cooperators_prev / n
        threshold_rate = m / n
        if coop_rate_prev >= threshold_rate:
            return Action.C
        elif rounds_remaining > 0:
            return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_259(BaseStrategy):
    """
    Threshold Sentinel: An adaptive collective risk strategy that balances prudent risk-taking
    with strategic caution. Cooperates initially and in adaptive rounds based on threshold
    likelihood, then defects in the endgame unless cooperation has proven stable.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.n_rounds - 1:
            return self._endgame_decision(history)
        return self._adaptive_decision(round_number, history)

    def _endgame_decision(self, history: PlayerHistory) -> Action:
        """
        Final round decision: Defect by default, but cooperate if cooperation
        has been stable and achieved the threshold consistently.
        """
        if self.n_rounds < 4:
            return Action.D
        recent_rounds_start = max(0, self.n_rounds - 4)
        recent_actions = history.opponent_actions[recent_rounds_start:-1, :]
        if recent_actions.size == 0:
            return Action.D
        cooperation_rates = []
        for round_idx in range(recent_actions.shape[0]):
            coop_count = int(np.sum(recent_actions[round_idx, :]))
            coop_rate = coop_count / self.n_players
            cooperation_rates.append(coop_rate)
        threshold_ratio = self.m / self.n_players
        if cooperation_rates and all((rate >= threshold_ratio for rate in cooperation_rates)):
            return Action.C
        return Action.D

    def _adaptive_decision(self, round_number: int, history: PlayerHistory) -> Action:
        """
        Rounds 1 to r-2: Adapt based on cooperation rate in the previous round.
        """
        prev_round_idx = round_number - 1
        if prev_round_idx < 0:
            return Action.C
        cooperators_last_round = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        defectors_last_round = self.n_players - cooperators_last_round
        cooperation_rate = cooperators_last_round / self.n_players
        threshold_ratio = self.m / self.n_players
        marginal_ratio = (self.m - 1) / self.n_players
        rounds_remaining = self.n_rounds - round_number
        if cooperation_rate >= threshold_ratio:
            return Action.C
        elif cooperation_rate >= marginal_ratio:
            if rounds_remaining >= 2:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_260(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances individual incentive to defect against collective need for threshold achievement.
    Uses a two-phase approach: Assessment (rounds 1-2) followed by Adaptive Response (rounds 3+).
    Branches into Reciprocal Mode (high cooperation detected) or Opportunistic Mode (low cooperation detected).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.c_1 = None
        self.mode = None
        self.threshold_achieved_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == 1 and history is not None:
            self.c_1 = int(np.sum(history.opponent_actions[0, :]))
            self.mode = 'reciprocal' if self.c_1 >= self.m else 'opportunistic'
            cooperators_r0 = self.c_1 + int(history.my_actions[0])
            self.threshold_achieved_history.append(cooperators_r0 >= self.m)
        if round_num > 1 and history is not None:
            cooperators_last = int(np.sum(history.opponent_actions[round_num - 1, :])) + int(history.my_actions[round_num - 1])
            self.threshold_achieved_history.append(cooperators_last >= self.m)
        if self.n_rounds == 2:
            if round_num == 1:
                return Action.C if self.c_1 >= self.m else Action.D
        if round_num == self.n_rounds - 2:
            if len(self.threshold_achieved_history) > 0 and any(self.threshold_achieved_history):
                return Action.C
            return Action.D
        if round_num == self.n_rounds - 1:
            if len(self.threshold_achieved_history) > 0 and any(self.threshold_achieved_history):
                return Action.C
            return Action.D
        if history is None:
            return Action.C
        cooperators_last_round = int(np.sum(history.opponent_actions[round_num - 1, :]))
        if self.mode == 'reciprocal':
            if cooperators_last_round >= self.m:
                return Action.C
            elif cooperators_last_round < self.m and self.n_rounds - round_num > 2:
                return Action.D
            else:
                return Action.C
        else:
            threshold_estimate = (self.n_players - 1) * (self.c_1 / self.n_players)
            deficit = self.m - threshold_estimate
            if deficit <= 1:
                return Action.C
            elif self.n_rounds - round_num > 3:
                return Action.D
            else:
                return Action.C

class Strategy_COLLECTIVE_261(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    A history-dependent, threshold-centric strategy that:
    - Cooperates in round 1 to signal good faith
    - Tracks recent cooperation rates to assess threshold achievability
    - Cooperates when threshold is likely to be met
    - Defects strategically when collective success is unlikely
    - Uses probabilistic cooperation to prevent defection cascades
    - Optimizes final round payoff based on observed cooperation patterns
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        recent_coop_rate = self._calculate_recent_cooperation_rate(history, current_round)
        threshold_rate = (self.m - 1) / self.n_players
        if current_round == self.n_rounds - 1:
            if recent_coop_rate >= threshold_rate:
                return Action.C
            else:
                return Action.D
        if recent_coop_rate >= threshold_rate:
            return Action.C
        lower_threshold = (self.m - 2) / self.n_players if self.m >= 2 else 0
        is_early_to_mid = current_round <= self.n_rounds / 2
        if recent_coop_rate >= lower_threshold and is_early_to_mid:
            return Action.C
        mid_threshold = self.m / (2 * self.n_players)
        if mid_threshold < recent_coop_rate < threshold_rate:
            cooperation_probability = min(0.6, recent_coop_rate * 2)
            if random.random() < cooperation_probability:
                return Action.C
            else:
                return Action.D
        return Action.D

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the cooperation rate in recent rounds.
        Uses the last min(3, current_round) rounds of history.
        """
        if current_round <= 0:
            return 0.0
        lookback_window = min(3, current_round)
        start_index = current_round - lookback_window
        recent_actions = history.opponent_actions[start_index:current_round, :]
        total_cooperators = np.sum(recent_actions)
        total_opportunities = recent_actions.shape[0] * recent_actions.shape[1]
        if total_opportunities == 0:
            return 0.0
        cooperation_rate = total_cooperators / total_opportunities
        return cooperation_rate

class Strategy_COLLECTIVE_262(BaseStrategy):
    """
    Adaptive Threshold Stewardship: A collective-minded strategy for the Collective Risk Dilemma.
    
    Employs three phases:
    1. Growth Phase (rounds 1 to r/2): Build cooperation momentum toward threshold
    2. Stabilization Phase (rounds r/2+1 to r-1): Protect collective wins, minimize losses
    3. Final Round: Reinforce successful patterns or minimize regret
    
    Core mechanism: Conditional cooperation with selective defection to signal costs of free-riding,
    while gracefully handling scenarios where collective coordination fails.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        cooperators_prev = int(sum(history.opponent_actions[round_t - 1, :]))
        threshold_met_prev = cooperators_prev >= self.m
        times_threshold_met = 0
        for r in range(round_t):
            cooperators_in_round = int(sum(history.opponent_actions[r, :]))
            if cooperators_in_round >= self.m:
                times_threshold_met += 1
        growth_phase_end = math.floor(self.n_rounds / 2)
        early_phase_end = math.floor(self.n_rounds / 3)
        is_final_round = round_t == self.n_rounds - 1
        if round_t <= growth_phase_end:
            if threshold_met_prev:
                return Action.C
            if cooperators_prev >= self.m - 1:
                return Action.C
            if round_t <= early_phase_end:
                return Action.C
            consecutive_fails = self._count_consecutive_threshold_failures(history, round_t)
            if consecutive_fails >= 2:
                return Action.D
            else:
                return Action.C
        elif not is_final_round:
            if times_threshold_met >= 1:
                return Action.C
            if cooperators_prev >= self.m - 2:
                return Action.C
            return Action.D
        else:
            if threshold_met_prev:
                return Action.C
            if cooperators_prev >= self.m - 1:
                return Action.C
            return Action.D

    def _count_consecutive_threshold_failures(self, history: PlayerHistory, current_round: int) -> int:
        """
        Count how many consecutive rounds ending at current_round-1 have failed to meet threshold.
        Returns the count of consecutive failures (0 if the most recent round met threshold).
        """
        count = 0
        for r in range(current_round - 1, -1, -1):
            cooperators_in_round = int(sum(history.opponent_actions[r, :]))
            if cooperators_in_round < self.m:
                count += 1
            else:
                break
        return count

class Strategy_COLLECTIVE_263(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) for Collective Risk Dilemma.
    
    Balances collective success with individual rationality by:
    1. Cooperating in round 1 to signal willingness
    2. In rounds 2 to r-1: cooperating if threshold m was met in previous round
    3. Defecting in final round (no future reciprocity possible)
    
    This creates a self-reinforcing attractor toward the m-cooperator state.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == r - 1:
            return Action.D
        previous_round_index = current_round - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[previous_round_index, :]))
        if history.my_actions[previous_round_index]:
            cooperators_last_round += 1
        cooperation_rate = cooperators_last_round / n
        threshold_rate = m / n
        if cooperation_rate >= threshold_rate:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_264(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances collective success (achieving m-threshold cooperation) with individual rationality.
    - Round 1: Cooperate (explore and signal intent)
    - Middle rounds: Conditional cooperation based on observed cooperation rate
    - Final round: Defect (subgame perfect equilibrium)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == self.n_rounds - 1:
            return Action.D
        if current_round == 0:
            return Action.C
        return self._conditional_cooperate(history, current_round)

    def _conditional_cooperate(self, history: PlayerHistory, current_round: int) -> Action:
        """
        Estimate cooperation rate from history and decide based on threshold achievability.
        """
        cooperators_observed = np.sum(history.opponent_actions[:current_round, :])
        total_observations = current_round * (self.n_players - 1)
        if total_observations == 0:
            return Action.C
        coop_rate = cooperators_observed / total_observations
        estimated_next_cooperators = round(coop_rate * (self.n_players - 1))
        if self.m == 1:
            return Action.C
        if self.m == self.n_players - 1:
            if coop_rate > 0.9:
                return Action.C
            else:
                return Action.D
        if coop_rate < self.m / (self.n_players - 1):
            return Action.D
        if estimated_next_cooperators >= self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_265(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances collective welfare and individual rationality by:
    1. Cooperating in round 1 to signal willingness
    2. Adapting cooperation in middle rounds based on observed cooperation rates
    3. Defecting in the final round (backward induction)
    
    Core decision logic: Cooperate if observed cooperation rate suggests the
    threshold m will be met AND if the expected value justifies the cost.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.n_rounds - 1:
            return Action.D
        avg_cooperation_rate = self._calculate_cooperation_rate(history, round_num)
        trigger_rate = (self.m - 1) / (self.n_players - 1)
        confidence_needed = (self.k - 1) / self.k
        if avg_cooperation_rate >= trigger_rate and avg_cooperation_rate >= confidence_needed:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate the average cooperation rate of opponents in previous rounds.
        
        Handles edge cases:
        - Division by zero protection
        - Perfect cooperation (coop_rate = 1.0)
        - Perfect defection (coop_rate = 0.0)
        
        Args:
            history: PlayerHistory containing opponent actions
            round_num: Current round (0-indexed)
        
        Returns:
            Cooperation rate as a float in [0, 1]
        """
        if round_num == 0:
            return 0.0
        total_cooperations = 0
        total_possible_actions = round_num * (self.n_players - 1)
        for past_round in range(round_num):
            cooperators_in_round = np.sum(history.opponent_actions[past_round, :])
            total_cooperations += cooperators_in_round
        if total_possible_actions == 0:
            return 0.0
        avg_cooperation_rate = total_cooperations / total_possible_actions
        return float(avg_cooperation_rate)

class Strategy_COLLECTIVE_266(BaseStrategy):
    """
    Cascading Confidence (CC) Strategy for Collective Risk Dilemma.
    
    A history-dependent, threshold-aware strategy that bootstraps cooperation
    in the first round, maintains cooperation when observable trends suggest
    the collective can reach the threshold, and switches to defection when
    the collective goal becomes unreachable.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == r - 1:
            total_coop_history = int(np.sum(history.opponent_actions))
            avg_coop_rate = total_coop_history / (current_round * n)
            if avg_coop_rate >= (m - 1) / n:
                return Action.C
            else:
                return Action.D
        recent_window_size = min(3, current_round)
        recent_rounds_start = max(0, current_round - recent_window_size)
        recent_opponent_actions = history.opponent_actions[recent_rounds_start:current_round, :]
        recent_coop_count = int(np.sum(recent_opponent_actions))
        recent_total_slots = recent_window_size * n
        if recent_total_slots == 0:
            return Action.C
        recent_rate = recent_coop_count / recent_total_slots
        required_rate = m / n
        confidence_threshold = 0.75 * required_rate
        if recent_rate >= confidence_threshold:
            return Action.C
        elif recent_rate >= 0.5 * required_rate:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_267(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) for Collective Risk Dilemma.
    
    Balances individual security with collective welfare by:
    1. Cooperating when cooperation likelihood exceeds a dynamic threshold
    2. Learning from observed cooperation rates
    3. Protecting against exploitation while maintaining willingness to cooperate
    4. Using probabilistic cooperation in the grey zone between m/n and threshold
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        buffer = self._calculate_buffer()
        threshold = self.m / self.n + buffer
        min_threshold = self.m / self.n
        ocr = self._calculate_ocr(history, round_num)
        if round_num == self.r - 1:
            return self._final_round_decision(ocr, threshold, history)
        if ocr >= threshold:
            return Action.C
        elif ocr >= min_threshold:
            p_mercy = ocr / min_threshold
            if random.random() < p_mercy:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _calculate_buffer(self) -> float:
        """Calculate buffer based on edge cases and m/n ratio."""
        min_threshold = self.m / self.n
        if self.m == self.n:
            return 0.05
        if self.m <= 2:
            return 0.0
        return min(0.15, 0.5 * min_threshold)

    def _calculate_ocr(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate Observed Cooperation Rate from all previous rounds.
        
        OCR = (total cooperators across all past rounds) / (number of past rounds Ã— n)
        """
        if round_num == 0:
            return 0.0
        total_cooperators = 0
        total_cooperators += np.sum(history.my_actions[:round_num])
        total_cooperators += np.sum(history.opponent_actions[:round_num, :])
        total_slots = round_num * self.n
        if total_slots == 0:
            return 0.0
        ocr = total_cooperators / total_slots
        return ocr

    def _final_round_decision(self, ocr: float, threshold: float, history: PlayerHistory) -> Action:
        """
        Final round decision logic.
        
        Cooperate if and only if:
        - OCR >= threshold AND
        - At least m cooperators in the previous round
        """
        prev_round_idx = self.r - 2
        my_prev_action = history.my_actions[prev_round_idx]
        opponent_prev_cooperators = np.sum(history.opponent_actions[prev_round_idx, :])
        prev_cooperators = (1 if my_prev_action else 0) + opponent_prev_cooperators
        if ocr >= threshold and prev_cooperators >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_268(BaseStrategy):
    """
    Adaptive Threshold Reciprocity strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Initiating cooperation in round 1 to break defection equilibrium
    2. Learning from observed cooperation levels and threshold progress
    3. Sustaining cooperation once threshold is met
    4. Protecting against exploitation in final rounds
    5. Adapting exploration vs. caution based on remaining rounds
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.cooperation_threshold = self.m - 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        cooperators_prev_round = int(np.sum(history.opponent_actions[round_number - 1, :]))
        my_action_prev = history.my_actions[round_number - 1]
        if my_action_prev:
            cooperators_prev_round += 1
        threshold_met = cooperators_prev_round >= self.m
        if round_number == self.n_rounds - 1:
            if threshold_met:
                return Action.C
            else:
                return Action.D
        if threshold_met:
            return Action.C
        if cooperators_prev_round >= self.cooperation_threshold:
            return Action.C
        rounds_remaining = self.n_rounds - round_number
        if rounds_remaining >= 2:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_269(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual security with collective welfare through:
    1. Probing cooperation in round 1
    2. Adapting based on observed cooperation rates
    3. Protecting against exploitation
    4. Escalating pressure on defectors via conditional cooperation
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold_high = 0.6
        self.threshold_low = 0.4
        self.p_mid = 0.75

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if state.round_number == 0:
            return Action.C
        if state.round_number == r - 1:
            return Action.D
        prev_round_idx = state.round_number - 1
        cooperators_prev = np.sum(history.opponent_actions[prev_round_idx, :])
        if history.my_actions[prev_round_idx]:
            cooperators_prev += 1
        coop_rate = cooperators_prev / n
        threshold_critical = math.ceil(m / n)
        if coop_rate >= self.threshold_high:
            return Action.C
        elif coop_rate >= self.threshold_low:
            return Action.C if random.random() < self.p_mid else Action.D
        elif coop_rate >= threshold_critical:
            return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_270(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances securing collective reward by reaching threshold m with protecting
    against free-riders. Cooperates conditionally based on historical threshold
    achievement and observable cooperation rates.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.consecutive_defect_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        previous_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        previous_cooperators += int(history.my_actions[current_round - 1])
        threshold_met_last_round = previous_cooperators >= self.m
        if threshold_met_last_round:
            self.consecutive_defect_rounds = 0
        else:
            self.consecutive_defect_rounds += 1
        if self.m == 1:
            return Action.C
        if self.consecutive_defect_rounds >= 3:
            return Action.D
        if threshold_met_last_round:
            if current_round == self.r - 1:
                return Action.C
            return Action.C
        cooperation_rate = previous_cooperators / self.n
        cooperation_threshold = self.m / self.n
        if cooperation_rate >= cooperation_threshold:
            return Action.C
        if cooperation_rate >= cooperation_threshold - 1.0 / self.n:
            boost_probability = (self.m - previous_cooperators) / self.n
            boost_probability = max(0.0, min(1.0, boost_probability))
            if random.random() < boost_probability:
                return Action.C
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        return Action.D

class Strategy_COLLECTIVE_271(BaseStrategy):
    """
    Adaptive Threshold Cooperation for Collective Risk Dilemma.
    
    Cooperates to build collective safety when conditions support it, but robustly 
    defects when the collective good becomes unattainable. Uses threshold awareness,
    adaptive reciprocity, and graceful degradation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_low_coop_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        round_num = state.round_number
        if round_num == 0:
            if m <= n / 2 + 1:
                return Action.C
            else:
                return Action.D
        if round_num == r - 1:
            last_cooperators = int(sum(history.opponent_actions[-1, :]))
            if last_cooperators >= m:
                return Action.C
            else:
                return Action.D
        last_cooperators = int(sum(history.opponent_actions[-1, :]))
        cooperation_rate = last_cooperators / n
        target_rate = m / n
        if target_rate == 0:
            return Action.D
        if cooperation_rate < 0.1:
            self.consecutive_low_coop_rounds += 1
            if self.consecutive_low_coop_rounds >= 3:
                return Action.D
        else:
            self.consecutive_low_coop_rounds = 0
        if cooperation_rate >= target_rate:
            return Action.C
        if cooperation_rate >= target_rate * 0.75:
            cooperate_prob = cooperation_rate / target_rate
            if random.random() < cooperate_prob:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_272(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare through:
    - Conditional cooperation based on empirical cooperation rates
    - Dynamic thresholds that adapt to game phase and opponent behavior
    - Protection against free-riders through defection detection
    - Special handling for edge cases (near-perfect cooperation/defection, oscillation, extreme m values)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return self._decide_round_1()
        return self._decide_adaptive(round_num, history)

    def _decide_round_1(self) -> Action:
        """Initial round decision based on threshold achievability."""
        threshold_ratio = self.m / self.n
        if threshold_ratio <= 0.5:
            return Action.C
        else:
            return Action.D

    def _get_cooperation_rate(self, history: PlayerHistory, num_rounds_back: int=3) -> float:
        """Calculate recent cooperation rate from opponent actions."""
        if len(history.opponent_actions) == 0:
            return 0.0
        start_idx = max(0, len(history.opponent_actions) - num_rounds_back)
        recent_actions = history.opponent_actions[start_idx:, :]
        if recent_actions.shape[0] == 0:
            return 0.0
        total_actions = recent_actions.shape[0] * recent_actions.shape[1]
        if total_actions == 0:
            return 0.0
        cooperation_count = np.sum(recent_actions)
        return float(cooperation_count) / float(total_actions)

    def _count_defection_failures(self, history: PlayerHistory) -> int:
        """Count rounds where fewer than m players cooperated."""
        if len(history.opponent_actions) == 0:
            return 0
        defection_count = 0
        for round_idx in range(len(history.opponent_actions)):
            cooperators_in_round = np.sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators_in_round += 1
            if cooperators_in_round < self.m:
                defection_count += 1
        return defection_count

    def _check_oscillation(self, history: PlayerHistory) -> bool:
        """Detect if cooperation rate oscillates significantly."""
        if len(history.opponent_actions) < 2:
            return False
        cooperation_counts = []
        for round_idx in range(len(history.opponent_actions)):
            cooperators = np.sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            cooperation_counts.append(cooperators / self.n)
        if len(cooperation_counts) < 2:
            return False
        for i in range(len(cooperation_counts) - 1):
            if abs(cooperation_counts[i] - cooperation_counts[i + 1]) > 0.3:
                return True
        return False

    def _decide_adaptive(self, round_num: int, history: PlayerHistory) -> Action:
        """Adaptive decision logic for rounds 1+."""
        recent_coop_rate = self._get_cooperation_rate(history, num_rounds_back=3)
        defection_failure_count = self._count_defection_failures(history)
        rounds_remaining = self.r - round_num - 1
        threshold_ratio = self.m / self.n
        if recent_coop_rate >= 0.9:
            return Action.C
        if recent_coop_rate <= 0.2 and round_num >= 2:
            return Action.D
        if self._check_oscillation(history):
            if round_num <= 3:
                return Action.C
            elif round_num > self.r / 2:
                return Action.D
            else:
                return Action.C
        if self.m <= 3 and self.n >= 6:
            if defection_failure_count >= 2:
                return Action.D
            else:
                return Action.C
        if self.m >= self.n - 1:
            if round_num <= 1:
                return Action.D
            else:
                if len(history.opponent_actions) > 0:
                    prev_cooperators = np.sum(history.opponent_actions[-1, :])
                    if history.my_actions[-1]:
                        prev_cooperators += 1
                    if prev_cooperators >= self.m - 1:
                        return Action.C
                return Action.D
        if self.r <= 3:
            threshold_margin = threshold_ratio - 0.05
            strict_margin = threshold_ratio - 0.1
        elif self.r >= 10:
            threshold_margin = threshold_ratio - 0.2
            strict_margin = threshold_ratio - 0.35
        else:
            threshold_margin = threshold_ratio - 0.1
            strict_margin = threshold_ratio - 0.25
        if round_num == self.r - 1:
            if recent_coop_rate >= threshold_ratio - 0.15:
                return Action.C
            else:
                return Action.D
        if recent_coop_rate >= threshold_margin:
            return Action.C
        if recent_coop_rate >= strict_margin:
            if rounds_remaining > self.r / 2:
                return Action.C
            else:
                return Action.D
        if defection_failure_count <= 1 and rounds_remaining > 3:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_273(BaseStrategy):
    """
    Adaptive Threshold Coalition strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Cooperating in round 1 to establish cooperation baseline
    2. Adapting in rounds 2 to r-1 based on observed cooperation rates
    3. Making final-round decision based on whether cooperation norms were established
    
    Uses Recent Cooperation Rate (RCR) to determine when cooperation threshold
    is likely to be met, and defects when collective success is improbable.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        rcr = self._calculate_rcr(history, current_round)
        threshold_rate = self.m / self.n_players
        if current_round == self.n_rounds - 1:
            if rcr >= threshold_rate:
                return Action.C
            else:
                return Action.D
        if rcr >= threshold_rate + 0.15:
            return Action.C
        elif rcr >= threshold_rate - 0.1:
            estimated_cooperators = self._estimate_cooperators(history, current_round)
            if estimated_cooperators >= self.m - 1:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _calculate_rcr(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate Recent Cooperation Rate (RCR).
        RCR = (number of rounds where â‰¥m players cooperated) / (current_round)
        """
        if current_round == 0:
            return 0.0
        cooperative_rounds = 0
        for round_idx in range(current_round):
            self_cooperated = history.my_actions[round_idx]
            opponent_cooperators = int(sum(history.opponent_actions[round_idx, :]))
            total_cooperators = int(self_cooperated) + opponent_cooperators
            if total_cooperators >= self.m:
                cooperative_rounds += 1
        rcr = cooperative_rounds / current_round
        return rcr

    def _estimate_cooperators(self, history: PlayerHistory, current_round: int) -> int:
        """
        Estimate expected cooperators in the next round using:
        - 60% weight on last round's cooperator count
        - 40% weight on average cooperators across all previous rounds
        """
        if current_round == 0:
            return 0
        last_round_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        last_round_cooperators += int(history.my_actions[current_round - 1])
        total_cooperators_all_rounds = 0
        for round_idx in range(current_round):
            self_cooperated = history.my_actions[round_idx]
            opponent_cooperators = int(sum(history.opponent_actions[round_idx, :]))
            total_cooperators_all_rounds += int(self_cooperated) + opponent_cooperators
        average_cooperators = total_cooperators_all_rounds / current_round
        estimated = math.floor(last_round_cooperators * 0.6 + average_cooperators * 0.4)
        return estimated

class Strategy_COLLECTIVE_274(BaseStrategy):
    """
    Collective Risk Adaptive Strategy (CRAS): Balances individual rationality with collective welfare
    through threshold-based cooperation, adaptive responsiveness, and defection-tolerant learning.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.coop_history = []
        self.last_round_cooperators = 0
        self.threshold_multiplier = 1.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        observed_coop = int(np.sum(history.opponent_actions[current_round - 1, :]))
        self.coop_history.append(observed_coop)
        total_cooperators_observed = sum(self.coop_history)
        avg_rate = total_cooperators_observed / (n * current_round) if current_round > 0 else 0.0
        temporal_adjustment = 0.1 * (1.0 - current_round / r)
        threshold = m / n + temporal_adjustment * self.threshold_multiplier
        if observed_coop >= m - 1:
            self.last_round_cooperators = observed_coop
            return Action.C
        if avg_rate >= threshold:
            self.last_round_cooperators = observed_coop
            return Action.C
        if current_round == r - 1 and avg_rate >= m / n:
            self.last_round_cooperators = observed_coop
            return Action.C
        if self.last_round_cooperators > 0 and observed_coop < self.last_round_cooperators - 1:
            self.threshold_multiplier *= 1.1
        if current_round >= 4 and len(self.coop_history) >= 3:
            recent_coop = self.coop_history[-3:]
            if all((c >= m for c in recent_coop)):
                self.last_round_cooperators = observed_coop
                return Action.C
        self.last_round_cooperators = observed_coop
        return Action.D

class Strategy_COLLECTIVE_275(BaseStrategy):
    """
    Adaptive Threshold Seeking strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Always cooperating in round 1 to signal good faith
    2. In middle rounds, adapting based on recent cooperation rates relative to threshold m/n
    3. In final round, cooperating if overall cooperation suggests success is achievable
    
    Uses probabilistic cooperation when near the threshold to gracefully degrade and avoid
    wasting contributions when collective success is unlikely.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.threshold_ratio = self.m / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            total_cooperations = np.sum(history.my_actions) + np.sum(history.opponent_actions)
            total_slots = current_round * self.n
            if total_slots > 0:
                overall_cooperation_rate = total_cooperations / total_slots
            else:
                overall_cooperation_rate = 0
            if overall_cooperation_rate >= self.threshold_ratio:
                return Action.C
            else:
                return Action.D
        recent_rounds_start = max(0, current_round - 2)
        recent_rounds_end = current_round
        my_recent_cooperations = np.sum(history.my_actions[recent_rounds_start:recent_rounds_end])
        opponent_recent_cooperations = np.sum(history.opponent_actions[recent_rounds_start:recent_rounds_end, :])
        total_recent_cooperations = my_recent_cooperations + opponent_recent_cooperations
        recent_slots = (recent_rounds_end - recent_rounds_start) * self.n
        if recent_slots > 0:
            recent_cooperation_rate = total_recent_cooperations / recent_slots
        else:
            recent_cooperation_rate = 0
        if recent_cooperation_rate >= self.threshold_ratio * 1.2:
            return Action.C
        elif recent_cooperation_rate >= self.threshold_ratio:
            return Action.C
        elif recent_cooperation_rate >= self.threshold_ratio * 0.7:
            gap_size = self.threshold_ratio * 0.3
            if gap_size > 0:
                cooperate_probability = (recent_cooperation_rate - 0.7 * self.threshold_ratio) / gap_size
            else:
                cooperate_probability = 0
            if random.random() < cooperate_probability:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_276(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Opening with cooperation to establish credible intent
    2. Tracking cooperation rates against the threshold m/n
    3. Adapting behavior based on whether threshold is met
    4. Avoiding exploitation while supporting collective success
    5. Demonstrating consistency through final rounds
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_below_threshold = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if state.round_number == 0:
            return Action.C
        prev_round_idx = state.round_number - 1
        my_prev_action = history.my_actions[prev_round_idx]
        opponent_prev_actions = history.opponent_actions[prev_round_idx, :]
        cooperation_count = int(my_prev_action) + int(np.sum(opponent_prev_actions))
        cooperation_rate = cooperation_count / n
        threshold_rate = m / n
        if state.round_number == r - 1:
            if cooperation_rate >= threshold_rate:
                return Action.C
            else:
                return Action.C
        if cooperation_rate >= threshold_rate:
            self.consecutive_below_threshold = 0
            return Action.C
        if cooperation_rate == 0:
            self.consecutive_below_threshold += 1
            return Action.D
        if cooperation_rate > 0:
            self.consecutive_below_threshold += 1
            if self.consecutive_below_threshold >= 2:
                return Action.D
            else:
                return Action.C
        return Action.C

class Strategy_COLLECTIVE_277(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare through:
    - Phase-based decision rules (early/middle/late game)
    - Adaptive cooperation based on observable cooperation rates
    - Escalating commitment as game progresses
    - Robustness against diverse opponent strategies
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def _classify_phase(self, current_round: int) -> str:
        """Classify which phase of the game we're in (0-indexed rounds)."""
        early_end = max(0, math.floor(self.r / 3) - 1)
        middle_end = max(0, math.floor(2 * self.r / 3) - 1)
        if current_round <= early_end:
            return 'early'
        elif current_round <= middle_end:
            return 'middle'
        else:
            return 'late'

    def _count_cooperators_in_round(self, history: PlayerHistory, round_idx: int) -> int:
        """Count total cooperators in a specific round (including self)."""
        if round_idx < 0 or round_idx >= len(history.my_actions):
            return 0
        my_coop = 1 if history.my_actions[round_idx] else 0
        opponent_coop = int(np.sum(history.opponent_actions[round_idx, :]))
        return my_coop + opponent_coop

    def _get_recent_coop_rate(self, history: PlayerHistory, num_rounds: int=3) -> float:
        """Calculate cooperation rate over recent rounds."""
        current_round = len(history.my_actions)
        start_round = max(0, current_round - num_rounds)
        if start_round >= current_round:
            return 0.0
        total_possible = (current_round - start_round) * self.n
        if total_possible == 0:
            return 0.0
        my_coop = int(np.sum(history.my_actions[start_round:current_round]))
        opponent_coop = int(np.sum(history.opponent_actions[start_round:current_round, :]))
        total_coop = my_coop + opponent_coop
        return total_coop / total_possible

    def _get_overall_coop_rate(self, history: PlayerHistory) -> float:
        """Calculate overall cooperation rate across all previous rounds."""
        current_round = len(history.my_actions)
        if current_round == 0:
            return 0.0
        total_possible = current_round * self.n
        my_coop = int(np.sum(history.my_actions[:current_round]))
        opponent_coop = int(np.sum(history.opponent_actions[:current_round, :]))
        total_coop = my_coop + opponent_coop
        return total_coop / total_possible

    def _get_historical_success_rate(self, history: PlayerHistory) -> float:
        """Calculate rate of rounds where threshold was met."""
        current_round = len(history.my_actions)
        if current_round == 0:
            return 0.0
        success_count = 0
        for round_idx in range(current_round):
            coop_count = self._count_cooperators_in_round(history, round_idx)
            if coop_count >= self.m:
                success_count += 1
        return success_count / current_round

    def _early_phase_decision(self, current_round: int, history: PlayerHistory) -> Action:
        """Decision logic for early phase (exploration)."""
        if current_round == 0:
            return Action.C
        recent_coop_rate = self._get_recent_coop_rate(history, 3)
        threshold_rate = self.m / self.n
        if recent_coop_rate >= threshold_rate:
            return Action.C
        elif recent_coop_rate < threshold_rate * 0.5:
            return Action.D
        else:
            prob = recent_coop_rate / threshold_rate if threshold_rate > 0 else 0.5
            return Action.C if random.random() < prob else Action.D

    def _middle_phase_decision(self, current_round: int, history: PlayerHistory) -> Action:
        """Decision logic for middle phase (stabilization)."""
        observed_coop_rate = self._get_overall_coop_rate(history)
        threshold_rate = self.m / self.n
        if observed_coop_rate >= threshold_rate:
            return Action.C
        else:
            deficit = threshold_rate - observed_coop_rate
            rounds_remaining = self.r - current_round
            if rounds_remaining <= 0:
                return Action.D
            required_escalation = deficit * (self.n / rounds_remaining)
            if required_escalation <= 0.3:
                return Action.C
            elif required_escalation <= 0.7:
                return Action.C if random.random() < 0.7 else Action.D
            else:
                return Action.D

    def _late_phase_decision(self, current_round: int, history: PlayerHistory) -> Action:
        """Decision logic for late phase (commitment)."""
        is_final_round = current_round == self.r - 1
        if is_final_round:
            historical_success = self._get_historical_success_rate(history)
            return Action.C if historical_success >= 0.6 else Action.D
        else:
            recent_coop_3 = self._get_recent_coop_rate(history, 3)
            threshold_rate = self.m / self.n
            if recent_coop_3 >= threshold_rate:
                return Action.C
            else:
                return Action.C if random.random() < 0.85 else Action.D

    def _adjust_for_extreme_parameters(self, base_action: Action) -> Action:
        """Adjust decision for extreme parameter values."""
        if self.m == self.n:
            return Action.C
        if self.k > 5 and base_action == Action.D:
            if random.random() < 0.1:
                return Action.C
        return base_action

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        phase = self._classify_phase(current_round)
        if phase == 'early':
            action = self._early_phase_decision(current_round, history)
        elif phase == 'middle':
            action = self._middle_phase_decision(current_round, history)
        else:
            action = self._late_phase_decision(current_round, history)
        action = self._adjust_for_extreme_parameters(action)
        return action

class Strategy_COLLECTIVE_278(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances collective welfare with self-protection through adaptive thresholds:
    - Round 1: Unconditional cooperation (bootstrap)
    - Grace period: Cooperate if majority cooperated or still in grace period
    - Main phase: Cooperate if observed cooperation meets rationality threshold
    - Final round: Unconditional defection (endgame logic)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.grace_period = max(2, math.ceil(self.r / 4))
        self.threshold = (self.m - 0.5) / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            return Action.D
        cooperators_prev = sum(history.opponent_actions[round_num - 1, :])
        coop_rate_prev = cooperators_prev / (self.n - 1) if self.n > 1 else 0.0
        if round_num <= self.grace_period:
            if coop_rate_prev >= 0.5:
                return Action.C
            else:
                return Action.D
        if coop_rate_prev >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_279(BaseStrategy):
    """
    Conditional Reciprocal Threshold (CRT) Strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by adapting cooperation
    based on observed success rates across three phases: early (probe), middle (adapt),
    and final (maximize collective outcome).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = []
        self.success_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self._update_history(history)
        round_num = state.round_number
        n_rounds = self.game_description.n_rounds
        m = self.game_description.m
        n_players = self.game_description.n_players
        recent_success = self._calculate_recent_success(n_rounds)
        overall_success = self._calculate_overall_success()
        recent_cooperators = self._calculate_recent_cooperators(n_players)
        avg_cooperators = self._calculate_avg_cooperators(n_players)
        early_phase_end = math.ceil(n_rounds / 3)
        if round_num <= early_phase_end:
            return self._early_phase(round_num, recent_success, m, n_players)
        middle_phase_end = math.floor(2 * n_rounds / 3)
        if round_num <= middle_phase_end:
            return self._middle_phase(round_num, recent_success, avg_cooperators, overall_success, m, n_players)
        return self._final_phase(round_num, overall_success, recent_success, recent_cooperators, m, n_rounds, n_players)

    def _update_history(self, history: PlayerHistory) -> None:
        """Extract and store cooperation and success information from history."""
        if not history.my_actions.size:
            return
        for round_idx in range(len(history.my_actions)):
            opponent_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
            my_action = int(history.my_actions[round_idx])
            total_cooperators = opponent_cooperators + my_action
            cooperation_rate = total_cooperators / self.game_description.n_players
            success = total_cooperators >= self.game_description.m
            if round_idx >= len(self.cooperation_history):
                self.cooperation_history.append(cooperation_rate)
                self.success_history.append(success)

    def _calculate_recent_success(self, n_rounds: int) -> float:
        """Calculate success rate in the last 3 rounds."""
        if not self.success_history:
            return 0.0
        recent_count = min(3, len(self.success_history))
        recent_successes = sum(self.success_history[-recent_count:])
        return recent_successes / recent_count if recent_count > 0 else 0.0

    def _calculate_overall_success(self) -> float:
        """Calculate overall success rate across all played rounds."""
        if not self.success_history:
            return 0.0
        return sum(self.success_history) / len(self.success_history)

    def _calculate_recent_cooperators(self, n_players: int) -> float:
        """Calculate average cooperator count in last 3 rounds."""
        if not self.cooperation_history:
            return 0.0
        recent_count = min(3, len(self.cooperation_history))
        recent_avg = np.mean(self.cooperation_history[-recent_count:])
        return recent_avg * n_players

    def _calculate_avg_cooperators(self, n_players: int) -> float:
        """Calculate average cooperator rate across all rounds."""
        if not self.cooperation_history:
            return 0.0
        return np.mean(self.cooperation_history)

    def _early_phase(self, round_num: int, recent_success: float, m: int, n_players: int) -> Action:
        """Phase 1: Early rounds - probe and establish baseline cooperation."""
        epsilon = 0.1
        threshold = m / n_players - epsilon
        if round_num <= 2:
            return Action.C
        if recent_success >= threshold:
            return Action.C
        return Action.D

    def _middle_phase(self, round_num: int, recent_success: float, avg_cooperators: float, overall_success: float, m: int, n_players: int) -> Action:
        """Phase 2: Middle rounds - adapt to observed patterns."""
        threshold_proportion = m / n_players
        if recent_success > 0.6:
            return Action.C
        if avg_cooperators >= threshold_proportion - 0.05:
            return Action.C
        if overall_success > 0.5:
            return Action.C
        if round_num <= 5:
            return Action.C
        return Action.D

    def _final_phase(self, round_num: int, overall_success: float, recent_success: float, recent_cooperators: float, m: int, n_rounds: int, n_players: int) -> Action:
        """Phase 3: Final rounds - maximize collective outcome."""
        rounds_remaining = n_rounds - round_num
        trajectory = 0.0
        if overall_success > 0.0:
            trajectory = recent_success - (overall_success - 0.5)
        if overall_success >= 0.5:
            return Action.C
        if trajectory > 0.15:
            return Action.C
        if recent_cooperators >= 0.85 * m:
            return Action.C
        if rounds_remaining <= 2:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_280(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances individual rationality with collective benefit by maintaining a dynamic
    cooperation threshold that responds to observed cooperation rates. Cooperates in
    round 1, uses adaptive threshold in middle rounds, and makes final-round decisions
    based on demonstrated success.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        last_round_actions = history.opponent_actions[round_number - 1, :]
        cooperators_last_round = int(np.sum(last_round_actions))
        observed_coop_rate = cooperators_last_round / self.n_players
        if round_number == self.n_rounds - 1:
            threshold_final = self.m / self.n_players
            if observed_coop_rate >= threshold_final:
                return Action.C
            else:
                return Action.D
        epsilon = 0.15 * (1.0 - round_number / (self.n_rounds - 1))
        threshold = self.m / self.n_players + epsilon
        if observed_coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_281(BaseStrategy):
    """
    Adaptive Threshold Cooperation for Collective Risk Dilemma.
    
    Strategy balances individual rationality with collective welfare by:
    1. Cooperating in round 1 to signal trustworthiness
    2. In rounds 2 to r-1: Cooperating if cooperation rate â‰¥ m/n, else defecting
    3. Defecting in final round (backward induction)
    
    This creates a coordination equilibrium when multiple players adopt it,
    securing collective rewards while avoiding exploitation spirals.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        if round_t == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = sum(history.opponent_actions[round_t - 1, :])
        if history.my_actions[round_t - 1]:
            cooperators_last_round += 1
        cooperation_rate = cooperators_last_round / self.n_players
        threshold_rate = self.m / self.n_players
        if cooperation_rate >= threshold_rate:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_282(BaseStrategy):
    """
    Adaptive Threshold Sentinel: A collective risk dilemma strategy that balances
    individual rationality with collective welfare by monitoring cooperation rates,
    adapting decisions based on progress toward the threshold, and defending against
    free-riding while rewarding genuine cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_ratio = self.m / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return self._evaluate_endgame(history)
        return self._adaptive_cooperation(history)

    def _evaluate_endgame(self, history: PlayerHistory) -> Action:
        """
        Final round decision: cooperate only if threshold was met in previous round.
        """
        prev_cooperators = int(sum(history.opponent_actions[-1, :]))
        cooperation_rate = prev_cooperators / self.n_players
        if cooperation_rate >= self.threshold_ratio:
            return Action.C
        else:
            return Action.D

    def _adaptive_cooperation(self, history: PlayerHistory) -> Action:
        """
        Main adaptive strategy for rounds 2 to r-1.
        Decision based on observed cooperation rate from previous round.
        """
        prev_cooperators = int(sum(history.opponent_actions[-1, :]))
        cooperation_rate = prev_cooperators / self.n_players
        if cooperation_rate >= self.threshold_ratio:
            return Action.C
        elif cooperation_rate >= 0.75 * self.threshold_ratio:
            return Action.C if random.random() < 0.7 else Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_283(BaseStrategy):
    """
    Adaptive Threshold Assurance strategy for Collective Risk Dilemma.
    
    Balances individual risk exposure with collective success through adaptive
    cooperation that responds to historical cooperation rates and remaining time pressure.
    Uses three phases: early (intelligence gathering), middle (threshold stabilization),
    and late (payoff maximization with graceful degradation).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        phase = self._determine_phase(current_round)
        hist_coop_rate = self._calculate_historical_cooperation_rate(history)
        last_coop_count = int(np.sum(history.opponent_actions[-1, :]))
        rounds_remaining = self.r - current_round
        if phase == 'early':
            return self._phase_early(current_round, hist_coop_rate)
        elif phase == 'middle':
            return self._phase_middle(hist_coop_rate, last_coop_count)
        else:
            return self._phase_late(rounds_remaining, last_coop_count, hist_coop_rate)

    def _determine_phase(self, current_round: int) -> str:
        """Determine game phase based on current round."""
        early_threshold = max(1, math.floor(self.r / 3))
        middle_threshold = max(2, math.floor(2 * self.r / 3))
        if current_round <= early_threshold:
            return 'early'
        elif current_round <= middle_threshold:
            return 'middle'
        else:
            return 'late'

    def _calculate_historical_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate average cooperation rate of opponents in past rounds."""
        if history.opponent_actions.shape[0] == 0:
            return 0.0
        total_opponent_actions = np.sum(history.opponent_actions)
        total_possible = history.opponent_actions.shape[0] * history.opponent_actions.shape[1]
        if total_possible == 0:
            return 0.0
        return float(total_opponent_actions) / float(total_possible)

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory, window: int=5) -> float:
        """Calculate cooperation rate in recent rounds (sliding window)."""
        if history.opponent_actions.shape[0] == 0:
            return 0.0
        window_size = min(window, history.opponent_actions.shape[0])
        recent_actions = history.opponent_actions[-window_size:, :]
        total_recent = np.sum(recent_actions)
        total_possible = recent_actions.shape[0] * recent_actions.shape[1]
        if total_possible == 0:
            return 0.0
        return float(total_recent) / float(total_possible)

    def _phase_early(self, current_round: int, hist_coop_rate: float) -> Action:
        """
        Phase 1 (Early Rounds): Gather intelligence on opponent cooperation propensity.
        """
        if current_round == 1:
            return Action.C
        threshold = self.m / self.n * 1.2
        if hist_coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _phase_middle(self, hist_coop_rate: float, last_coop_count: int) -> Action:
        """
        Phase 2 (Middle Rounds): Stabilize cooperative equilibrium if threshold achievable.
        """
        cooperation_deficit = self.m - last_coop_count
        if cooperation_deficit >= 1:
            if cooperation_deficit <= 2 and hist_coop_rate >= (self.m - 1) / self.n:
                return Action.C
            else:
                return Action.D
        elif cooperation_deficit < 0:
            if hist_coop_rate >= self.m / self.n * 1.1:
                return Action.C
            else:
                return Action.D
        else:
            return Action.C

    def _phase_late(self, rounds_remaining: int, last_coop_count: int, hist_coop_rate: float) -> Action:
        """
        Phase 3 (Late Rounds): Maximize final-round payoffs while preserving group welfare.
        """
        if rounds_remaining == 1:
            if last_coop_count >= self.m:
                return Action.C
            else:
                return Action.D
        elif rounds_remaining <= 3:
            if hist_coop_rate >= self.m / self.n * 1.15 or last_coop_count >= self.m:
                return Action.C
            else:
                return Action.D
        else:
            return self._phase_middle(hist_coop_rate, last_coop_count)

class Strategy_COLLECTIVE_284(BaseStrategy):
    """
    Progressive Assurance Strategy for Collective Risk Dilemma.
    
    A history-responsive strategy that balances collective welfare with individual risk management.
    Cooperates in round 1 to signal commitment, then adapts based on observed cooperation rates,
    using threshold achievement as the primary goal while defending against systematic free-riding.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        if self.n == 2 and self.m == 2:
            return self._handle_minimal_case(round_t, history)
        if self.r == 2:
            return Action.D if round_t == 1 else Action.C
        cooperation_rate = self._calculate_cooperation_rate(history, round_t)
        required_rate = self.m / self.n
        if round_t == self.r - 1:
            if cooperation_rate >= required_rate:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= required_rate:
            return Action.C
        if round_t <= self.r / 2:
            return Action.C
        cooperators_last_round = int(sum(history.opponent_actions[round_t - 1, :]))
        cooperation_needed = self.m - cooperators_last_round
        remaining_players = self.n - 1
        if cooperation_needed <= remaining_players / 3:
            return Action.C
        if cooperation_needed > remaining_players / 2:
            return Action.D
        if self.k > 1.5:
            return Action.C
        else:
            return Action.D

    def _handle_minimal_case(self, round_t: int, history: PlayerHistory) -> Action:
        """Special handling for n=2, m=2 case (Tit-for-Tat variant)."""
        if round_t == self.r - 1:
            return Action.D
        opponent_last_action = history.opponent_actions[round_t - 1, 0]
        return Action.C if opponent_last_action else Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_t: int) -> float:
        """
        Calculate the average cooperation rate across all players (including self) 
        across all completed rounds so far.
        """
        if round_t == 0:
            return 0.0
        total_cooperations = 0
        total_cooperations += int(sum(history.my_actions[:round_t]))
        total_cooperations += int(np.sum(history.opponent_actions[:round_t, :]))
        total_possible = self.n * round_t
        if total_possible == 0:
            return 0.0
        return total_cooperations / total_possible

class Strategy_COLLECTIVE_285(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances collective welfare with individual security by:
    1. Cooperating proactively when collective success is achievable
    2. Defecting defensively only when cooperation appears insufficient
    3. Dynamically adapting based on observed cooperation rates
    4. Maintaining long-term orientation for repeated mutual benefit
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        cooperation_rate = self._calculate_cooperation_rate(history, current_round)
        expected_cooperators = math.floor(cooperation_rate * (self.n_players - 1)) + 1
        if current_round < self.n_rounds - 1:
            if expected_cooperators >= self.m:
                return Action.C
            else:
                return Action.D
        elif expected_cooperators >= self.m - 1:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the observed cooperation rate from previous rounds.
        Returns a value between 0 and 1.
        """
        if current_round == 0:
            return 0.5
        previous_rounds = current_round
        total_opponent_slots = previous_rounds * (self.n_players - 1)
        if total_opponent_slots == 0:
            return 0.5
        total_cooperations = np.sum(history.opponent_actions[:current_round, :])
        cooperation_rate = total_cooperations / total_opponent_slots
        return cooperation_rate

class Strategy_COLLECTIVE_286(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATC)
    
    Balances self-protection with collective benefit by:
    - Estimating expected cooperators based on game parameters and history
    - Cooperating conditionally when threshold appears achievable
    - Always cooperating in final round if threshold looks viable
    - Detecting defection spirals and switching to pure defection
    - Handling edge cases where threshold is impossible or trivial
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.defection_spiral_mode = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return self._decide_round_zero()
        return self._decide_subsequent_round(round_num, history)

    def _decide_round_zero(self) -> Action:
        """Decide action for round 0 based on game parameters."""
        if self.m == self.n_players:
            return Action.D
        if self.m == 2 and self.n_players > 2:
            return Action.C
        threshold_estimate = math.ceil(self.n_players * 0.6)
        if self.m > threshold_estimate:
            return Action.D
        if self.m <= math.ceil(self.n_players * 0.3):
            return Action.C
        if threshold_estimate >= self.m:
            return Action.C
        return Action.D

    def _decide_subsequent_round(self, round_num: int, history: PlayerHistory) -> Action:
        """Decide action for rounds 1 to r-1."""
        if self.defection_spiral_mode:
            return Action.D
        observed_cooperators_prev = self._count_cooperators_previous_round(history)
        if round_num >= 2:
            if self._detect_defection_spiral(history):
                self.defection_spiral_mode = True
                return Action.D
        if round_num == self.n_rounds - 1:
            return self._decide_final_round(observed_cooperators_prev)
        if observed_cooperators_prev == self.m - 1:
            return Action.C
        estimated_coop = observed_cooperators_prev
        if estimated_coop >= self.m:
            return Action.C
        return Action.D

    def _count_cooperators_previous_round(self, history: PlayerHistory) -> int:
        """Count total cooperators (including self) in previous round."""
        round_idx = len(history.my_actions) - 1
        my_action = history.my_actions[round_idx]
        opponent_coop_count = int(sum(history.opponent_actions[round_idx, :]))
        return int(my_action) + opponent_coop_count

    def _detect_defection_spiral(self, history: PlayerHistory) -> bool:
        """
        Detect if defection spiral is happening:
        Two consecutive rounds with very low cooperation.
        """
        if len(history.my_actions) < 2:
            return False
        round_idx_prev1 = len(history.my_actions) - 1
        round_idx_prev2 = len(history.my_actions) - 2
        coop_count_prev1 = self._count_cooperators_round(history, round_idx_prev1)
        coop_count_prev2 = self._count_cooperators_round(history, round_idx_prev2)
        threshold_low = max(1, math.ceil(self.m * 0.4))
        return coop_count_prev1 < threshold_low and coop_count_prev2 < threshold_low

    def _count_cooperators_round(self, history: PlayerHistory, round_idx: int) -> int:
        """Count total cooperators in a specific round."""
        my_action = history.my_actions[round_idx]
        opponent_coop_count = int(sum(history.opponent_actions[round_idx, :]))
        return int(my_action) + opponent_coop_count

    def _decide_final_round(self, observed_cooperators_prev: int) -> Action:
        """
        Final round: collective pledge.
        Cooperate if threshold appears achievable.
        """
        if observed_cooperators_prev >= self.m - 1:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_287(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Core philosophy: Cooperate when evidence suggests the threshold will likely be met,
    using Bayesian reasoning about observed cooperation rates. Defect unconditionally
    in the final round due to lack of future reciprocity.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.n_rounds - 1:
            return Action.D
        return self._adaptive_decision(state, history)

    def _adaptive_decision(self, state: GameState, history: PlayerHistory) -> Action:
        """
        Adaptive decision rule for rounds 2 through r-1.
        
        Calculates empirical cooperation rate from history and estimates
        probability of threshold being met in future rounds.
        """
        current_round = state.round_number
        rounds_completed = current_round
        total_cooperators = 0
        total_slots = 0
        for round_idx in range(rounds_completed):
            round_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
            total_cooperators += round_cooperators
            total_slots += self.n_players - 1
        if total_slots == 0:
            observed_cooperation_rate = 0.0
        else:
            observed_cooperation_rate = total_cooperators / total_slots
        if current_round >= 2:
            recent_rounds = min(3, current_round)
            recent_defection_rates = []
            for i in range(1, recent_rounds + 1):
                round_idx = current_round - i
                if round_idx >= 0:
                    round_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
                    round_defection_rate = 1.0 - round_cooperators / (self.n_players - 1)
                    recent_defection_rates.append(round_defection_rate)
            if len(recent_defection_rates) >= 2:
                if recent_defection_rates[0] > recent_defection_rates[1] + 0.2:
                    return Action.D
        prob_threshold_met = self._calculate_threshold_probability(observed_cooperation_rate)
        rounds_remaining = self.n_rounds - current_round
        required_confidence = 0.5 + rounds_remaining / self.n_rounds * 0.3
        required_confidence = self._adjust_for_edge_cases(required_confidence, observed_cooperation_rate)
        if prob_threshold_met >= required_confidence:
            return Action.C
        else:
            return Action.D

    def _calculate_threshold_probability(self, observed_cooperation_rate: float) -> float:
        """
        Estimate probability that threshold m will be met in next round.
        
        Assumes that other n-1 players will cooperate with observed_cooperation_rate.
        We consider both scenarios: if we cooperate and if we defect.
        
        Returns probability that at least m players cooperate (including ourselves if we cooperate).
        """
        other_players = self.n_players - 1
        if other_players == 0:
            return 1.0
        p = observed_cooperation_rate
        prob = self._binomial_tail_probability(other_players, p, self.m - 1)
        return prob

    def _binomial_tail_probability(self, n: int, p: float, k: int) -> float:
        """
        Calculate P(X >= k) where X ~ Binomial(n, p).
        
        Uses a simplified approach: normal approximation for large n,
        or direct calculation for small n.
        """
        if n == 0:
            return 1.0 if k <= 0 else 0.0
        if p < 0.0 or p > 1.0:
            p = max(0.0, min(1.0, p))
        if n <= 20:
            return self._binomial_tail_exact(n, p, k)
        mean = n * p
        variance = n * p * (1.0 - p)
        if variance < 1e-10:
            return 1.0 if mean >= k else 0.0
        stddev = math.sqrt(variance)
        z = (k - 0.5 - mean) / stddev
        return self._normal_tail(z)

    def _binomial_tail_exact(self, n: int, p: float, k: int) -> float:
        """
        Exact calculation of P(X >= k) for X ~ Binomial(n, p).
        """
        if k < 0:
            return 1.0
        if k > n:
            return 0.0
        prob_sum = 0.0
        for i in range(k, n + 1):
            prob_sum += self._binomial_pmf(n, p, i)
        return prob_sum

    def _binomial_pmf(self, n: int, p: float, k: int) -> float:
        """
        Calculate P(X = k) for X ~ Binomial(n, p).
        """
        if k < 0 or k > n:
            return 0.0
        binom_coeff = 1.0
        for i in range(min(k, n - k)):
            binom_coeff = binom_coeff * (n - i) / (i + 1.0)
        if p == 0.0:
            return 1.0 if k == 0 else 0.0
        if p == 1.0:
            return 1.0 if k == n else 0.0
        log_prob = math.log(binom_coeff) + k * math.log(p) + (n - k) * math.log(1.0 - p)
        return math.exp(log_prob)

    def _normal_tail(self, z: float) -> float:
        """
        Approximate P(Z > z) for standard normal Z using error function.
        """
        return 0.5 * math.erfc(z / math.sqrt(2.0))

    def _adjust_for_edge_cases(self, required_confidence: float, observed_cooperation_rate: float) -> float:
        """
        Adjust required confidence based on game parameters and observed behavior.
        """
        if self.m == self.n_players:
            return min(0.95, required_confidence + 0.2)
        if self.m <= 2 and self.n_players > 4:
            return max(0.55, required_confidence + 0.15)
        if observed_cooperation_rate > self.m / self.n_players + 0.2:
            return max(0.45, required_confidence - 0.05)
        return required_confidence

class Strategy_COLLECTIVE_288(BaseStrategy):
    """
    Adaptive Threshold Coordination strategy for Collective Risk Dilemma.
    
    Dynamically estimates collective cooperation likelihood and adjusts contribution
    decisions to seek threshold m. Uses momentum factors and critical margin logic
    to balance exploration with commitment to viable cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        prev_round_idx = current_round - 1
        prev_cooperators = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        prev_cooperation_rate = prev_cooperators / self.n
        threshold_to_join = max(0.4, (self.m - 1) / (self.n - 1))
        rounds_remaining = self.r - current_round
        momentum_factor = min(0.7, 1.0 - rounds_remaining / self.r)
        estimated_next_cooperators = prev_cooperation_rate * self.n
        if abs(estimated_next_cooperators + 1.0 - self.m) < 1e-09:
            return Action.C
        if estimated_next_cooperators >= self.m - 1e-09:
            if prev_cooperation_rate >= threshold_to_join - 1e-09:
                return Action.C
            elif random.random() < momentum_factor:
                return Action.C
            else:
                return Action.D
        else:
            if current_round == self.r - 1:
                if prev_cooperation_rate < threshold_to_join:
                    return Action.D
                if history.my_actions[prev_round_idx]:
                    return Action.C
                return Action.D
            if current_round == 1 and prev_cooperators >= self.m - 1:
                return Action.C
            return Action.D

class Strategy_COLLECTIVE_289(BaseStrategy):
    """
    Threshold Sentinel: Adaptive Collective Risk Strategy
    
    Balances individual security with collective success by maintaining a dynamic threshold model
    that adjusts cooperation based on observed cooperation rates and proximity to the critical threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        previous_round_idx = current_round - 1
        opponent_actions_prev = history.opponent_actions[previous_round_idx, :]
        observed_cooperators = int(np.sum(opponent_actions_prev))
        if history.my_actions[previous_round_idx]:
            observed_cooperators += 1
        rounds_remaining = self.n_rounds - current_round
        if observed_cooperators >= self.m:
            return Action.C
        if observed_cooperators == self.m - 1:
            return Action.C
        if observed_cooperators == self.m - 2:
            if rounds_remaining >= 2:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_290(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances individual security with collective benefit by:
    1. Cooperating in round 1 to signal willingness
    2. Maintaining cooperation when threshold m is met or nearly met
    3. Defecting only when threshold is mathematically unreachable
    4. Using consistent logic throughout all rounds including the final round
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n_players = game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators_prev = int(np.sum(history.opponent_actions[state.round_number - 1, :]))
        if history.my_actions[state.round_number - 1]:
            cooperators_prev += 1
        if cooperators_prev >= self.m:
            return Action.C
        elif cooperators_prev == self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_291(BaseStrategy):
    """
    Adaptive Threshold Sentinel: A collective risk dilemma strategy that balances
    individual security with collective welfare through threshold monitoring,
    adaptive commitment, and reciprocal enforcement.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.n_rounds - 1:
            return Action.D
        prev_cooperators = int(sum(history.opponent_actions[round_num - 1, :]))
        deficit = self.m - prev_cooperators
        total_past_rounds = round_num
        total_cooperators = int(sum(history.opponent_actions[:round_num, :].flatten()))
        hcr = total_cooperators / (total_past_rounds * self.n_players) if total_past_rounds > 0 else 0.0
        if hcr < 0.3 and round_num >= 2:
            return Action.D
        if hcr >= 0.6 and deficit <= 2:
            return Action.C
        if deficit <= 0:
            prob = min(0.95, hcr + 0.1)
            return Action.C if random.random() < prob else Action.D
        if deficit == 1:
            return Action.C
        if deficit <= self.n_players // 3:
            return Action.C if random.random() < 0.8 else Action.D
        if deficit <= self.n_players // 2:
            return Action.C if random.random() < 0.5 else Action.D
        return Action.D

class Strategy_COLLECTIVE_292(BaseStrategy):
    """
    Adaptive Threshold Cooperation for Collective Risk Dilemma.
    
    Balances collective welfare with individual rationality by:
    1. Cooperating unconditionally in round 1 to signal commitment
    2. Adapting to observed cooperation rates in intermediate rounds
    3. Making rational defection choices in the final round
    4. Probabilistically filling cooperation gaps when thresholds are at risk
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        cooperators_last_round += int(history.my_actions[prev_round_idx])
        cooperation_rate = cooperators_last_round / self.n_players
        target_cooperation_rate = self.m / self.n_players
        if current_round == self.n_rounds - 1:
            if cooperators_last_round >= self.m:
                return Action.C
            else:
                return Action.D
        if cooperation_rate == 0:
            return Action.D
        if cooperation_rate >= target_cooperation_rate:
            if random.random() < 0.95:
                return Action.C
            else:
                return Action.D
        expected_cooperators_next = cooperation_rate * self.n_players
        deficit = self.m - expected_cooperators_next
        if deficit > 0:
            fill_probability = deficit / self.n_players
            if random.random() < fill_probability:
                return Action.C
            else:
                return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_293(BaseStrategy):
    """
    Adaptive Threshold Commitment Strategy (ATCS)
    
    Balances individual security with collective welfare through progressive commitment
    with conditional defection. Cooperates when historical evidence suggests the threshold
    will be met, and strategically defects only when threshold is genuinely at risk.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.buffer = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        observed_cooperators = int(np.sum(history.opponent_actions[:current_round, :]))
        total_opponent_actions = current_round * (self.n - 1)
        if total_opponent_actions == 0:
            observed_coop_rate = 0.0
        else:
            observed_coop_rate = observed_cooperators / total_opponent_actions
        threshold_rate = self.m / self.n
        if observed_coop_rate > threshold_rate + self.buffer:
            return Action.C
        elif observed_coop_rate >= threshold_rate:
            return Action.C
        else:
            estimated_others_cooperating = observed_coop_rate * (self.n - 1)
            if estimated_others_cooperating + 1 >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_294(BaseStrategy):
    """
    Adaptive Threshold Monitoring strategy for Collective Risk Dilemma.
    
    Balances individual incentive compatibility with collective risk mitigation by:
    - Cooperating in round 1 to establish baseline
    - Defecting only when threshold is already guaranteed (â‰¥ m cooperators)
    - Cooperating when pivotal (m-1 cooperators) or close to threshold (m-2 cooperators)
    - Defecting when threshold is far away (< m-2 cooperators)
    
    This creates a "last-mile buffer" that amplifies cooperation cascades while
    rationally free-riding only when collective success is assured.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round_idx = state.round_number - 1
        my_previous_action = history.my_actions[previous_round_idx]
        my_cooperated = int(my_previous_action)
        opponents_cooperated = int(np.sum(history.opponent_actions[previous_round_idx, :]))
        observed_cooperators = my_cooperated + opponents_cooperated
        if observed_cooperators >= self.m:
            return Action.D
        elif observed_cooperators == self.m - 1:
            return Action.C
        elif observed_cooperators >= self.m - 2:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_295(BaseStrategy):
    """
    Progressive Assurance: Adaptive Threshold Coordination for Collective Risk Dilemma
    
    Balances collective welfare with individual security by proactively building toward
    the threshold while monitoring collective momentum and dynamically adjusting cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round >= self.r - 2:
            return Action.D
        if current_round == 0:
            return Action.C
        lookback_window = min(3, current_round)
        recent_actions = history.opponent_actions[max(0, current_round - lookback_window):current_round, :]
        if recent_actions.size == 0:
            return Action.C
        cooperators_recent = np.sum(recent_actions)
        total_slots = recent_actions.shape[0] * recent_actions.shape[1]
        if total_slots == 0:
            avg_cooperation_rate = 0.0
        else:
            avg_cooperation_rate = cooperators_recent / total_slots
        threshold_rate = self.m / self.n
        near_threshold_rate = (self.m - 1) / self.n if self.m > 1 else 0.0
        if avg_cooperation_rate >= threshold_rate:
            return Action.C
        elif avg_cooperation_rate >= near_threshold_rate:
            cooperation_threshold = 0.7
            if random.random() < cooperation_threshold:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_296(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATC) for Collective Risk Dilemma.
    
    Balances individual security with collective benefit by conditionally cooperating
    based on observable cooperation rates, with adaptive thresholds, punishment phases,
    and rebuild mechanisms.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.punishment_rounds_remaining = 0
        self.rebuild_rounds_remaining = 0
        self.last_coop_rate = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        coop_rate = self._calculate_coop_rate(history, current_round)
        self.last_coop_rate = coop_rate
        if self.punishment_rounds_remaining > 0:
            self.punishment_rounds_remaining -= 1
            if self.punishment_rounds_remaining == 0:
                self.rebuild_rounds_remaining = math.ceil(self.n_rounds / 5)
            return Action.D
        if self.rebuild_rounds_remaining > 0:
            self.rebuild_rounds_remaining -= 1
            return Action.C
        if current_round == self.n_rounds - 1:
            if coop_rate >= self.m / self.n_players:
                return Action.C
            else:
                return Action.D
        if current_round == self.n_rounds - 2:
            if coop_rate >= self.m / self.n_players + 0.1:
                return Action.C
            else:
                return Action.D
        required_threshold = self._calculate_threshold(current_round)
        if coop_rate >= required_threshold:
            return Action.C
        elif coop_rate > 0:
            self.punishment_rounds_remaining = max(2, math.ceil(self.n_rounds / 10))
            return Action.D
        else:
            return Action.D

    def _calculate_coop_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the historical cooperation rate across all players in previous rounds.
        
        coop_rate = (total cooperators in rounds 0 to current_round-1) / (n Ã— current_round)
        """
        if current_round == 0:
            return 0.0
        opponent_cooperators = np.sum(history.opponent_actions[:current_round, :])
        my_cooperators = np.sum(history.my_actions[:current_round])
        total_cooperators = opponent_cooperators + my_cooperators
        total_slots = self.n_players * current_round
        if total_slots == 0:
            return 0.0
        return total_cooperators / total_slots

    def _calculate_threshold(self, current_round: int) -> float:
        """
        Calculate the adaptive threshold for the current round.
        
        adaptive_threshold(t) = (m / n) + adjustment(t)
        
        Adjustment logic:
        - Early rounds (t â‰¤ r/3): adjustment = +0.15
        - Mid rounds (r/3 < t < 2r/3): adjustment = +0.05
        - Late rounds (t â‰¥ 2r/3): adjustment = 0
        """
        base_threshold = self.m / self.n_players
        third_point_1 = self.n_rounds / 3
        third_point_2 = 2 * self.n_rounds / 3
        if current_round <= third_point_1:
            adjustment = 0.15
        elif current_round < third_point_2:
            adjustment = 0.05
        else:
            adjustment = 0.0
        return min(1.0, base_threshold + adjustment)

class Strategy_COLLECTIVE_297(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances collective welfare maximization through threshold achievement with
    robustness against free-riders. Operates in three phases: exploration, 
    commitment, and endgame, adapting decisions based on observed cooperation rates.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        phase1_end = math.ceil(self.r / 3)
        phase2_end = math.ceil(2 * self.r / 3)
        if current_round == 0:
            return Action.C if random.random() < 0.5 else Action.D
        if current_round < phase1_end:
            return self._phase1_decision(history, current_round)
        elif current_round < phase2_end:
            return self._phase2_decision(history, current_round)
        else:
            return self._phase3_decision(history, current_round)

    def _phase1_decision(self, history: PlayerHistory, current_round: int) -> Action:
        """Early exploration phase: assess opponent cooperation propensity."""
        cooperation_rate = self._calculate_cooperation_rate(history, current_round)
        threshold_fraction = self.m / self.n
        if self.n == self.m:
            init_threshold = threshold_fraction * 0.8
            high_threshold = threshold_fraction * 0.8
        else:
            init_threshold = threshold_fraction * 0.8
            high_threshold = threshold_fraction * 0.8
        low_threshold = threshold_fraction * 0.4
        if cooperation_rate >= high_threshold:
            return Action.C
        elif cooperation_rate < low_threshold:
            return Action.D
        else:
            prob = cooperation_rate / threshold_fraction if threshold_fraction > 0 else 0.5
            prob = min(prob, 1.0)
            return Action.C if random.random() < prob else Action.D

    def _phase2_decision(self, history: PlayerHistory, current_round: int) -> Action:
        """Commitment period: drive toward threshold achievement."""
        recent_coop = self._calculate_recent_cooperation_rate(history, current_round, window=3)
        threshold_fraction = self.m / self.n
        if recent_coop >= threshold_fraction * 0.9:
            return Action.C
        elif recent_coop >= threshold_fraction * 0.6:
            return Action.C if random.random() < 0.8 else Action.D
        elif recent_coop >= threshold_fraction * 0.35:
            return Action.C if random.random() < 0.6 else Action.D
        else:
            return Action.D

    def _phase3_decision(self, history: PlayerHistory, current_round: int) -> Action:
        """Endgame: secure threshold success or maximize individual payoff."""
        cumulative_coop = self._calculate_cooperation_rate(history, current_round)
        threshold_fraction = self.m / self.n
        rounds_remaining = self.r - current_round
        if cumulative_coop >= threshold_fraction * 0.85:
            return Action.C
        if rounds_remaining <= 3:
            last_round_achieved = self._last_round_achieved_threshold(history)
            if last_round_achieved:
                return Action.C
            cooperators_needed = self._count_cooperators_needed(history, current_round)
            if cooperators_needed <= 2:
                return Action.C if random.random() < 0.7 else Action.D
            return Action.D
        if cumulative_coop >= threshold_fraction * 0.5:
            return Action.C if random.random() < 0.7 else Action.D
        return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """Calculate average cooperation rate of opponents up to current round."""
        if current_round == 0:
            return 0.0
        total_cooperators = np.sum(history.opponent_actions[:current_round, :])
        total_opportunities = (self.n - 1) * current_round
        if total_opportunities == 0:
            return 0.0
        return float(total_cooperators) / float(total_opportunities)

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory, current_round: int, window: int=3) -> float:
        """Calculate cooperation rate over the last 'window' rounds."""
        if current_round == 0:
            return 0.0
        start_round = max(0, current_round - window)
        end_round = current_round
        total_cooperators = np.sum(history.opponent_actions[start_round:end_round, :])
        total_opportunities = (self.n - 1) * (end_round - start_round)
        if total_opportunities == 0:
            return 0.0
        return float(total_cooperators) / float(total_opportunities)

    def _last_round_achieved_threshold(self, history: PlayerHistory) -> bool:
        """Check if the last completed round achieved the cooperation threshold."""
        if history.opponent_actions.shape[0] == 0:
            return False
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        my_last_action = history.my_actions[-1]
        total_cooperators = last_round_cooperators + (1 if my_last_action else 0)
        return total_cooperators >= self.m

    def _count_cooperators_needed(self, history: PlayerHistory, current_round: int) -> int:
        """Count how many more cooperators are needed to reach threshold in current round."""
        current_cooperators = np.sum(history.opponent_actions[current_round, :]) if current_round < history.opponent_actions.shape[0] else 0
        cooperators_needed = max(0, self.m - current_cooperators - 1)
        return cooperators_needed

class Strategy_COLLECTIVE_298(BaseStrategy):
    """
    Adaptive Threshold Monitoring strategy for Collective Risk Dilemma.
    
    Balances collective welfare with individual rationality by:
    1. Cooperating in round 1 to signal willingness
    2. Tracking cooperation counts to assess threshold achievement
    3. Defecting when collective action is failing to avoid exploitation
    4. Maintaining cooperation when threshold is met to reinforce equilibrium
    5. Supporting recovery trends in middle rounds
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        cooperators_last_round = int(sum(history.opponent_actions[round_number - 1, :]))
        rounds_remaining = self.r - round_number - 1
        if round_number == self.r - 1:
            if cooperators_last_round >= self.m - 1:
                return Action.C
            else:
                return Action.D
        if cooperators_last_round >= self.m:
            return Action.C
        elif cooperators_last_round >= self.m - 1:
            defectors_last_round = self.n - cooperators_last_round
            if defectors_last_round == 1:
                return Action.C
            else:
                return Action.D
        elif rounds_remaining >= 2 and self._is_cooperation_improving(history, round_number):
            return Action.C
        else:
            return Action.D

    def _is_cooperation_improving(self, history: PlayerHistory, round_number: int) -> bool:
        """
        Check if cooperation is improving by comparing cooperation counts
        in the last two rounds.
        """
        if round_number < 2:
            return False
        cooperators_two_rounds_ago = int(sum(history.opponent_actions[round_number - 2, :]))
        cooperators_last_round = int(sum(history.opponent_actions[round_number - 1, :]))
        return cooperators_last_round > cooperators_two_rounds_ago

class Strategy_COLLECTIVE_299(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by making cooperation
    contingent on evidence that the group can achieve the threshold. Cooperates in
    round 1 unconditionally, then conditionally based on recent cooperation trends
    and round position.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        prev_round_idx = current_round - 1
        cooperators_last_round = int(sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            cooperators_last_round += 1
        threshold_signal = cooperators_last_round >= math.ceil(self.m / 2)
        if not threshold_signal:
            return Action.D
        if current_round < self.n_rounds - 1:
            return Action.C
        other_cooperators_prev = cooperators_last_round
        if history.my_actions[prev_round_idx]:
            other_cooperators_prev -= 1
        if other_cooperators_prev >= self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_300(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATC) for Collective Risk Dilemma.
    
    Balances collective welfare (achieving the cooperation threshold) with individual
    protection against exploitation. Uses three phases:
    1. Exploration (rounds 1 to âŒˆr/3âŒ‰): Cooperate to gather information
    2. Adaptive Response (rounds âŒˆr/3âŒ‰+1 to r-1): Adjust based on observed cooperation rate
    3. Endgame (last round): Defect to avoid last-round exploitation
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.epsilon = 0.15
        self.exploration_end = math.ceil(self.r / 3)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num < self.exploration_end:
            return Action.C
        if round_num == self.r - 1:
            return Action.D
        return self._adaptive_response(history)

    def _adaptive_response(self, history: PlayerHistory) -> Action:
        """
        Calculate cooperation rate and decide based on threshold comparison.
        """
        rounds_completed = len(history.my_actions)
        if rounds_completed == 0:
            return Action.C
        total_cooperators = np.sum(history.opponent_actions)
        total_observations = (self.n - 1) * rounds_completed
        if total_observations == 0:
            return Action.C
        cooperation_rate = total_cooperators / total_observations
        threshold_rate = self.m / self.n
        if cooperation_rate >= threshold_rate + self.epsilon:
            return Action.C
        elif cooperation_rate >= threshold_rate - self.epsilon:
            cooperators_last_round = np.sum(history.opponent_actions[-1, :])
            if cooperators_last_round >= self.m - 1:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_301(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances individual security with collective benefit by dynamically adjusting
    cooperation based on collective health, personal vulnerability, game phase,
    and historical trends.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.defect_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_cooperators = int(np.sum(history.opponent_actions[round_num - 1, :]))
        if self.defect_counter > 0:
            self.defect_counter -= 1
            if self.defect_counter == 0:
                return Action.C
            return Action.D
        if round_num >= 2:
            total_opponent_cooperations = np.sum(history.opponent_actions[:round_num, :])
            total_opponent_actions = round_num * (self.n - 1)
            if total_opponent_actions > 0:
                defection_rate = 1.0 - total_opponent_cooperations / total_opponent_actions
                if defection_rate > 0.9:
                    self.defect_counter = 2
                    return Action.D
        if self.n - 1 > 0:
            cooperation_rate = prev_cooperators / (self.n - 1)
        else:
            cooperation_rate = 0.0
        if round_num == self.r - 1:
            if prev_cooperators >= self.m:
                return Action.C
            elif prev_cooperators == self.m - 1:
                return Action.C if random.random() < 0.6 else Action.D
            else:
                return Action.D
        threshold_prob = 0.0
        if prev_cooperators >= self.m:
            threshold_prob = min(1.0, 0.95 + 0.05 * cooperation_rate)
        elif prev_cooperators >= self.m - 1:
            threshold_prob = min(1.0, 0.7 + 0.25 * cooperation_rate)
        elif prev_cooperators >= math.ceil(self.m / 2.0):
            threshold_prob = max(0.3, 0.5 * cooperation_rate)
        else:
            threshold_prob = 0.0
        if self.k > 2.0:
            threshold_prob = min(1.0, threshold_prob + 0.15)
        return Action.C if random.random() < threshold_prob else Action.D

class Strategy_COLLECTIVE_302(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by dynamically adjusting
    cooperation based on observed cooperators, risk proximity to threshold m, and
    remaining rounds. Cooperates when threshold is met or nearly met, defects when
    collective action has failed.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.consecutive_zero_cooperation_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        observed_cooperators = int(sum(history.opponent_actions[round_number - 1, :]))
        if observed_cooperators == 0:
            self.consecutive_zero_cooperation_rounds += 1
        else:
            self.consecutive_zero_cooperation_rounds = 0
        rounds_remaining = self.n_rounds - round_number
        if observed_cooperators >= self.m:
            return Action.C
        if observed_cooperators == self.m - 1:
            assist_probability = (self.n_players - observed_cooperators) / (self.n_players - 1)
            if rounds_remaining <= 2:
                assist_probability *= 0.9
            if random.random() < assist_probability:
                return Action.C
            return Action.D
        if rounds_remaining == 1:
            if observed_cooperators >= self.m - 1:
                return Action.C
            return Action.D
        if observed_cooperators < self.m - 1:
            return Action.D
        return Action.D

class Strategy_COLLECTIVE_303(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances collective welfare, self-protection, and robustness by:
    - Round 1: Cooperate (trust but verify)
    - Middle rounds: Cooperate if expected cooperators â‰¥ required_others - 0.5
    - Final round: Cooperate if cooperation rate suggests threshold will be met
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        completed_rounds = current_round
        n_opponents = self.n_players - 1
        if completed_rounds == 0 or n_opponents == 0:
            return Action.C
        total_cooperations = np.sum(history.opponent_actions[:completed_rounds, :])
        total_opponent_decisions = completed_rounds * n_opponents
        cooperation_rate = total_cooperations / total_opponent_decisions if total_opponent_decisions > 0 else 0.0
        expected_cooperators = n_opponents * cooperation_rate
        required_others = self.m - 1
        if current_round == self.n_rounds - 1:
            if expected_cooperators >= required_others:
                return Action.C
            else:
                return Action.D
        else:
            delta = 0.5
            if expected_cooperators >= required_others - delta:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_304(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual security with collective benefit through conditional cooperation.
    - Phase 1 (Rounds 0-1): Exploration and threshold viability testing
    - Phase 2 (Rounds 2 to r-2): Adaptive reciprocity with punishment cycles
    - Phase 3 (Rounds r-1): Endgame cooperation aligned with threshold
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_punishment_round = -999
        self.threshold_momentum = game_description.m / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if round_num == 0:
            return Action.C
        if round_num == 1:
            cooperators_round_0 = int(np.sum(history.opponent_actions[0, :]))
            if history.my_actions[0]:
                cooperators_round_0 += 1
            if cooperators_round_0 >= m:
                return Action.C
            else:
                self.last_punishment_round = round_num
                return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[round_num - 1, :]))
        if history.my_actions[round_num - 1]:
            cooperators_last_round += 1
        momentum = cooperators_last_round / n
        min_momentum = self.threshold_momentum
        if momentum >= min_momentum:
            return Action.C
        elif cooperators_last_round == 0:
            if round_num - self.last_punishment_round <= 2:
                return Action.D
            else:
                self.last_punishment_round = -999
                return Action.C
        elif round_num - self.last_punishment_round > 2:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_305(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy for Collective Risk Dilemma.
    
    Balances collective threshold achievement with protection against free-riders.
    Cooperates when confidence in reaching threshold is high, defects when cooperation
    rates fall below sustainable levels. Uses terminal round defection to avoid exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = []
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.n_rounds - 1:
            observed_coops_prev = int(sum(history.opponent_actions[-1, :]))
            if observed_coops_prev >= self.m - 1:
                return Action.D
            else:
                return Action.C
        recent_coop_rate = self._compute_recent_cooperation_rate(history, round_num)
        threshold = (self.m - 1) / self.n_players
        rounds_left = self.n_rounds - round_num
        if recent_coop_rate >= threshold:
            return Action.C
        elif rounds_left > self.n_players and recent_coop_rate < 0.3:
            return Action.D
        elif recent_coop_rate > 0.3:
            return Action.C
        else:
            return Action.D

    def _compute_recent_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Compute cooperation rate from last 3 rounds (or fewer if not enough history).
        Returns optimistic baseline (0.5) if insufficient history.
        """
        if current_round < 1:
            return 0.5
        start_idx = max(0, current_round - 3)
        end_idx = current_round
        if start_idx >= end_idx:
            return 0.5
        recent_actions = history.opponent_actions[start_idx:end_idx, :]
        if recent_actions.size == 0:
            return 0.5
        total_cooperations = int(np.sum(recent_actions))
        total_possible = recent_actions.shape[0] * recent_actions.shape[1]
        if total_possible == 0:
            return 0.5
        return total_cooperations / total_possible

class Strategy_COLLECTIVE_306(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual and collective rationality by cooperating when cooperation
    is needed and likely to be reciprocated, while defecting when the collective
    goal is already secured or mathematically unachievable.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_round = self.r * (self.m - 1) / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        if round_t == self.r - 1:
            return Action.D
        previous_cooperators = int(np.sum(history.opponent_actions[round_t - 1, :]))
        self_contribution = 1
        estimated_total = previous_cooperators + self_contribution
        if round_t <= self.threshold_round and estimated_total < self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_307(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances individual security with collective welfare by dynamically adjusting
    cooperation based on demonstrated collective capacity and remaining opportunity.
    Uses threshold-focused decision rules with special handling for early, mid, and end games.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.defection_cooldown = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            prev_round_cooperators = np.sum(history.opponent_actions[round_num - 1, :])
            if prev_round_cooperators >= self.m - 1:
                return Action.C
            else:
                return Action.D
        if self.defection_cooldown > 0:
            self.defection_cooldown -= 1
            return Action.D
        lookback = min(round_num, 3)
        if self.n <= 3:
            lookback = min(round_num, 5)
        start_idx = max(0, round_num - lookback)
        recent_opponent_cooperators = np.sum(history.opponent_actions[start_idx:round_num, :])
        recent_my_cooperators = np.sum(history.my_actions[start_idx:round_num])
        total_recent_cooperators = recent_opponent_cooperators + recent_my_cooperators
        total_recent_slots = lookback * self.n
        if total_recent_slots > 0:
            recent_avg = total_recent_cooperators / total_recent_slots
        else:
            recent_avg = 0.0
        threshold_ratio = self.m / self.n
        if recent_avg < threshold_ratio * 0.3 and round_num > 1:
            self.defection_cooldown = 2
            return Action.D
        if recent_avg >= threshold_ratio * 0.95:
            return Action.C
        elif recent_avg >= threshold_ratio * 0.75:
            if round_num % 2 == 1:
                return Action.C
            else:
                return Action.D
        elif recent_avg >= threshold_ratio * 0.5:
            return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_308(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances individual rationality with collective benefit by conditioning
    cooperation on observable evidence of reciprocation. Uses a time-dependent
    adaptive threshold that decreases over time to track cooperation rates and
    adjust decisions accordingly.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        total_cooperations = 0
        total_cooperations += int(np.sum(history.opponent_actions[:current_round, :]))
        total_cooperations += int(np.sum(history.my_actions[:current_round]))
        total_actions = self.n_players * current_round
        if total_actions == 0:
            coop_rate = 0.0
        else:
            coop_rate = total_cooperations / total_actions
        baseline_threshold = self.m / self.n_players
        if current_round == self.n_rounds - 1:
            threshold = baseline_threshold - 0.05
        else:
            rounds_remaining = self.n_rounds - current_round
            threshold = baseline_threshold + 0.15 * rounds_remaining / self.n_rounds
        if coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_309(BaseStrategy):
    """
    Adaptive Threshold Reciprocity Strategy for Collective Risk Dilemma.
    
    Balances collective success (reaching threshold m) with individual protection
    by adaptively responding to observed cooperation rates. Cooperates initially,
    selectively defects when threshold is secure and cooperation is stable,
    re-cooperates to stabilize declining cooperation, and makes final attempts
    to reach threshold in the last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        cooperators_last_round = int(np.sum(history.opponent_actions[round_num - 1, :]))
        cooperation_rate = cooperators_last_round / (self.n - 1) if self.n > 1 else 0.0
        threshold_ratio = self.m / self.n
        if round_num == self.r - 1:
            if cooperators_last_round >= self.m:
                return Action.D
            else:
                return Action.C
        if cooperators_last_round >= self.m:
            if cooperation_rate >= threshold_ratio:
                return Action.D
            else:
                return Action.C
        else:
            crisis_deficit = self.m - cooperators_last_round
            if cooperation_rate >= threshold_ratio * 0.9:
                return Action.C
            min_cooperation_needed = crisis_deficit / (self.n - 1) if self.n > 1 else 0.0
            if cooperation_rate >= min_cooperation_needed:
                return Action.C
            return Action.D

class Strategy_COLLECTIVE_310(BaseStrategy):
    """
    Adaptive Threshold Monitoring strategy for Collective Risk Dilemma.
    
    Balances individual security with collective benefit by:
    1. Monitoring whether the cooperation threshold is being met
    2. Adapting to empirical cooperation levels from previous rounds
    3. Maintaining incentive compatibility when threshold is achievable
    4. Avoiding exploitation when cooperation is insufficient
    
    Decision rule:
    - Round 1: Cooperate if threshold â‰¤ 50% of players, else defect
    - Later rounds: Cooperate if previous round had â‰¥ m cooperators, else defect
    - Special cases: Pivotal player rule, unanimous defection avoidance
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.oscillation_counter = 0
        self.last_cooperator_count = None
        self.defection_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            if self.m <= self.n_players / 2:
                return Action.C
            else:
                return Action.D
        previous_round_idx = round_num - 1
        opponent_coop_count = int(np.sum(history.opponent_actions[previous_round_idx, :]))
        my_prev_action = history.my_actions[previous_round_idx]
        total_cooperators = opponent_coop_count + (1 if my_prev_action else 0)
        if total_cooperators == 0:
            self.defection_streak += 1
            return Action.D
        else:
            self.defection_streak = 0
        if total_cooperators == self.m - 1:
            return Action.C
        if total_cooperators >= self.m:
            self.oscillation_counter = 0
            return Action.C
        else:
            if self.last_cooperator_count is not None:
                if (self.last_cooperator_count >= self.m) != (total_cooperators >= self.m):
                    self.oscillation_counter += 1
                else:
                    self.oscillation_counter = 0
            self.last_cooperator_count = total_cooperators
            return Action.D

class Strategy_COLLECTIVE_311(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances collective welfare with individual security by dynamically adjusting
    cooperation based on observed cooperation rates. Seeks to establish and maintain
    sustainable cooperation equilibrium while protecting against exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        safety_margin = min(1, math.ceil(0.2 * (self.n - self.m)))
        threshold_target = (self.m + safety_margin) / self.n
        minimum_threshold = self.m / self.n
        buffer = 1.0 / self.n
        last_round_idx = round_number - 1
        my_last_action = history.my_actions[last_round_idx]
        opponent_last_actions = history.opponent_actions[last_round_idx, :]
        last_round_cooperators = int(my_last_action) + int(np.sum(opponent_last_actions))
        last_cooperation_rate = last_round_cooperators / self.n
        all_cooperation_rates = []
        for round_idx in range(round_number):
            my_action = history.my_actions[round_idx]
            opponent_actions = history.opponent_actions[round_idx, :]
            round_cooperators = int(my_action) + int(np.sum(opponent_actions))
            all_cooperation_rates.append(round_cooperators / self.n)
        avg_cooperation = np.mean(all_cooperation_rates) if all_cooperation_rates else 0.0
        if last_cooperation_rate >= threshold_target:
            return Action.C
        if last_cooperation_rate >= minimum_threshold - buffer:
            if avg_cooperation >= minimum_threshold - buffer:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_312(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances collective value creation, individual security, and adaptive robustness
    by cooperating when the threshold is reasonably expected to be met, while
    defecting when cooperation is unlikely to succeed or in exploitative situations.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            if self.m <= (self.n + 1) / 2:
                return Action.C
            else:
                return Action.D
        if current_round < self.r - 1:
            return self._adaptive_round_decision(current_round, history)
        else:
            return self._final_round_decision(current_round, history)

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """Calculate historical cooperation rate across all players and rounds."""
        if current_round == 0:
            return 0.0
        my_cooperations = np.sum(history.my_actions[:current_round])
        opponent_cooperations = np.sum(history.opponent_actions[:current_round, :])
        total_cooperations = my_cooperations + opponent_cooperations
        total_actions = self.n * current_round
        if total_actions == 0:
            return 0.0
        return total_cooperations / total_actions

    def _calculate_expected_cooperators(self, cooperation_rate: float) -> float:
        """
        Estimate expected cooperators in the current round.
        Assumes we cooperate (1) and others cooperate at historical rate.
        """
        expected_others = cooperation_rate * (self.n - 1)
        return expected_others + 1

    def _adaptive_round_decision(self, current_round: int, history: PlayerHistory) -> Action:
        """Decision logic for rounds 1 through r-2."""
        cooperation_rate = self._calculate_cooperation_rate(history, current_round)
        expected_cooperators = self._calculate_expected_cooperators(cooperation_rate)
        if expected_cooperators >= self.m and current_round < self.r - 2:
            return Action.C
        if current_round == self.r - 2:
            if cooperation_rate > 1 - 1 / self.n:
                return Action.C
        if cooperation_rate >= 0.5 and expected_cooperators >= self.m - 1:
            return Action.C
        return Action.D

    def _final_round_decision(self, current_round: int, history: PlayerHistory) -> Action:
        """Decision logic for the final round (r-1)."""
        cooperation_rate = self._calculate_cooperation_rate(history, current_round)
        expected_cooperators = self._calculate_expected_cooperators(cooperation_rate)
        threshold_confidence = self.m / self.n + 0.15
        if cooperation_rate >= threshold_confidence and expected_cooperators >= self.m:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_313(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by adapting to observed
    cooperation rates and prioritizing threshold achievement. Uses threshold-focused
    decision rules with special handling for edge cases and trend analysis.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        if self.n <= 3:
            self.threshold_tolerance = 0.05
        else:
            self.threshold_tolerance = 0.1
        self.high_m_threshold = self.m > 2 * self.n / 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        rounds_remaining = self.r - round_num
        if round_num == self.r - 1:
            return self._final_round_decision(history)
        return self._middle_round_decision(history, rounds_remaining)

    def _middle_round_decision(self, history: PlayerHistory, rounds_remaining: int) -> Action:
        """Decision logic for rounds 2 through r-1."""
        prev_round_idx = len(history.opponent_actions) - 1
        cooperators_prev = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        cooperation_rate = cooperators_prev / self.n
        target_rate = self.m / self.n - self.threshold_tolerance
        if (round_num := (len(history.opponent_actions) == 1)):
            if cooperators_prev == 0:
                self._persistent_defection = True
            else:
                self._persistent_defection = False
        if hasattr(self, '_persistent_defection') and self._persistent_defection:
            if cooperators_prev > 0:
                self._persistent_defection = False
            else:
                return Action.D
        if cooperation_rate >= target_rate:
            return Action.C
        if rounds_remaining <= 2:
            return Action.D
        if self._has_improving_trend(history):
            return Action.C if random.random() < 0.7 else Action.D
        if self.high_m_threshold and rounds_remaining > 2:
            return Action.C if random.random() < 0.4 else Action.D
        return Action.D

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """Decision logic for final round."""
        all_cooperators = np.sum(history.opponent_actions, axis=1)
        cooperators_mean = float(np.mean(all_cooperators))
        projected_cooperators = int(round(cooperators_mean))
        if projected_cooperators + 1 >= self.m:
            return Action.C
        if projected_cooperators < self.m - 1:
            return Action.D
        if projected_cooperators == self.m - 1:
            return Action.C if random.random() < 0.5 else Action.D
        return Action.D

    def _has_improving_trend(self, history: PlayerHistory) -> bool:
        """Check if cooperation trend is improving using 3-round moving average."""
        all_cooperators = np.sum(history.opponent_actions, axis=1)
        num_rounds = len(all_cooperators)
        if num_rounds < 2:
            return False
        if num_rounds >= 3:
            recent_avg = float(np.mean(all_cooperators[-3:]))
            earlier_avg = float(np.mean(all_cooperators[-4:-1])) if num_rounds >= 4 else float(all_cooperators[-3])
            return recent_avg > earlier_avg
        else:
            return all_cooperators[-1] > all_cooperators[-2]

class Strategy_COLLECTIVE_314(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by adapting cooperation
    probability based on observed cooperation rates and round dynamics. Uses stochastic
    cooperation to avoid mutual defection traps while remaining individually rational.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.cooperation_prob = max(self.m / self.n, 0.5)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            p = max(self.m / self.n, 0.5)
            return Action.C if random.random() < p else Action.D
        round_idx = state.round_number - 1
        prev_opponent_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
        my_prev_cooperation = int(history.my_actions[round_idx])
        cooperators_prev = prev_opponent_cooperators + my_prev_cooperation
        rho_prev = cooperators_prev / self.n
        success_prev = cooperators_prev >= self.m
        p = self.cooperation_prob
        if success_prev:
            p = rho_prev + 0.05
        else:
            threshold_rate = self.m / self.n
            if rho_prev <= threshold_rate - 0.05:
                p = min(p + 0.1, 1.0)
        rounds_remaining = self.r - state.round_number
        if rounds_remaining <= 2:
            p = p + 0.15
        min_prob = self.m / self.n - 0.1
        p = max(min(p, 1.0), min_prob)
        self.cooperation_prob = p
        return Action.C if random.random() < p else Action.D

class Strategy_COLLECTIVE_315(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances individual security with collective benefit through dynamic contribution
    based on observed cooperation rates. Uses exponential smoothing to estimate future
    cooperation and adjusts decision thresholds based on game phase and confidence levels.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.alpha = 0.5
        self.coop_history = []
        self.historical_avg = None
        self.phi = 0.65

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return self._decide_first_round()
        prev_round_idx = round_num - 1
        opponent_actions_prev = history.opponent_actions[prev_round_idx, :]
        cooperators_prev = int(np.sum(opponent_actions_prev))
        observed_coop_rate = cooperators_prev / self.n_players
        if self.historical_avg is None:
            self.historical_avg = observed_coop_rate
        else:
            self.historical_avg = self.alpha * observed_coop_rate + (1 - self.alpha) * self.historical_avg
        self.coop_history.append(observed_coop_rate)
        if round_num == 1:
            if cooperators_prev >= self.m:
                self.phi = 0.55
            else:
                self.phi = 0.75
        rounds_remaining = self.n_rounds - round_num
        if rounds_remaining == 1:
            return self._decide_final_round(history, round_num)
        elif rounds_remaining <= 3:
            return self._decide_endgame(history, round_num)
        return self._decide_standard(observed_coop_rate)

    def _decide_first_round(self) -> Action:
        """
        First round: optimistic initialization.
        Cooperate if threshold is reasonable relative to group size.
        """
        if self.m > 2 * self.n_players / 3:
            return Action.D
        if self.m <= self.n_players / 2:
            return Action.C
        return Action.C

    def _decide_standard(self, observed_coop_rate: float) -> Action:
        """
        Standard decision rule for middle rounds.
        Uses expected cooperators and confidence threshold.
        """
        expected_cooperators = observed_coop_rate * (self.n_players - 1) + 1
        if expected_cooperators < self.m:
            return Action.D
        threshold_success_prob = min(1.0, expected_cooperators / self.m)
        error_margin = math.sqrt(self.n_players * observed_coop_rate * (1 - observed_coop_rate)) / self.n_players
        adjusted_prob = max(0.0, threshold_success_prob - 0.1 * error_margin)
        if adjusted_prob > self.phi:
            return Action.C
        return Action.D

    def _decide_endgame(self, history: PlayerHistory, round_num: int) -> Action:
        """
        Decision logic for last 2-3 rounds.
        Checks consistency of cooperation across previous rounds.
        """
        if len(self.coop_history) < 1:
            return Action.D
        avg_coop = np.mean(self.coop_history)
        if avg_coop >= 0.8:
            return Action.C
        elif avg_coop < self.m / (self.n_players - 1):
            return Action.D
        else:
            current_coop = self.coop_history[-1] if self.coop_history else 0.5
            adjusted_phi = min(0.8, self.phi + 0.1)
            phi_backup = self.phi
            self.phi = adjusted_phi
            result = self._decide_standard(current_coop)
            self.phi = phi_backup
            return result

    def _decide_final_round(self, history: PlayerHistory, round_num: int) -> Action:
        """
        Final round decision logic.
        Requires stronger evidence before cooperating to avoid exploitation.
        """
        if len(self.coop_history) < 1:
            return Action.D
        avg_coop = np.mean(self.coop_history)
        if avg_coop >= 0.8:
            return Action.C
        if avg_coop < 0.5:
            return Action.D
        current_coop = self.coop_history[-1] if self.coop_history else 0.5
        expected_cooperators = current_coop * (self.n_players - 1) + 1
        phi_final = min(0.9, self.phi + 0.15)
        threshold_success_prob = min(1.0, expected_cooperators / self.m)
        if threshold_success_prob > phi_final:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_316(BaseStrategy):
    """
    Adaptive Threshold Enforcement strategy for Collective Risk Dilemma.
    
    Balances exploitation resistance, adaptive calibration, and collective welfare
    maximization by adjusting cooperation based on observed group behavior relative
    to the cooperation threshold m.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        if t == 0:
            return Action.C
        cooperation_last_round = int(np.sum(history.opponent_actions[t - 1, :]))
        coop_rate = cooperation_last_round / self.n
        threshold_rate = self.m / self.n
        deficit = threshold_rate - coop_rate
        if coop_rate >= threshold_rate:
            if coop_rate >= 0.9 * threshold_rate:
                return Action.C
            elif deficit < 0.15:
                return Action.C
            elif random.random() < deficit / 2:
                return Action.D
            else:
                return Action.C
        else:
            trend = 0.0
            if t >= 2:
                cooperation_prev_round = int(np.sum(history.opponent_actions[t - 2, :]))
                coop_rate_prev = cooperation_prev_round / self.n
                trend = coop_rate - coop_rate_prev
            if trend < -0.1:
                return Action.D
            elif coop_rate > 0.5 * threshold_rate:
                urgency = (coop_rate / threshold_rate) ** 2
                if random.random() < urgency:
                    return Action.C
                else:
                    return Action.D
            elif t <= self.r / 2:
                return Action.D
            elif random.random() < 0.3:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_317(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Cooperates conditionally based on estimated likelihood of reaching the cooperation
    threshold m. Adapts an internal parameter Î± based on observed cooperation trends
    to balance optimism about collective success with protection against exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.alpha = 0.7
        self.cooperation_history = []
        self.trend_direction = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        prev_round_idx = current_round - 1
        opponent_actions_prev = history.opponent_actions[prev_round_idx, :]
        cooperators_prev = int(np.sum(opponent_actions_prev))
        my_action_prev = history.my_actions[prev_round_idx]
        total_cooperators_prev = cooperators_prev + int(my_action_prev)
        coop_rate_prev = total_cooperators_prev / n
        self.cooperation_history.append(coop_rate_prev)
        if len(self.cooperation_history) >= 2:
            if self.cooperation_history[-1] < self.cooperation_history[-2] - 0.05:
                self.trend_direction = -1
                self.alpha = max(0.6, self.alpha - 0.05)
            elif self.cooperation_history[-1] > self.cooperation_history[-2] + 0.05:
                self.trend_direction = 1
                self.alpha = min(0.8, self.alpha + 0.05)
            else:
                self.trend_direction = 0
        if current_round == r - 1:
            if total_cooperators_prev >= m:
                return Action.C
            if coop_rate_prev >= m / n - 1 / n:
                return Action.C
            if coop_rate_prev < m / n * 0.5:
                return Action.D
            return Action.C
        threshold_fraction = m / n
        if total_cooperators_prev >= m:
            return Action.C
        threshold_margin = m - total_cooperators_prev
        if coop_rate_prev >= threshold_fraction - 1 / n and threshold_margin <= 1:
            return Action.C
        if coop_rate_prev >= threshold_fraction * self.alpha:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_318(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    This strategy balances collective welfare with individual rationality by:
    1. Always cooperating in round 1 to signal good faith
    2. Adapting cooperation based on observed cooperation rates relative to threshold m/n
    3. Using tiered thresholds (100%, 75%, 50% of m/n) for decision-making
    4. Applying special logic for early rounds (more patient) and endgame (more defensive)
    5. Using 3-round rolling average to smooth noise in opponent patterns
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold_rate = self.m / self.n

    def _get_cooperation_rate(self, history: PlayerHistory, round_idx: int) -> float:
        """
        Calculate cooperation rate in a specific round.
        round_idx is 0-indexed (0 = first round).
        Returns fraction of opponents who cooperated.
        """
        if round_idx < 0 or round_idx >= history.opponent_actions.shape[0]:
            return 0.0
        cooperators = sum(history.opponent_actions[round_idx, :])
        return cooperators / self.n

    def _get_rolling_average_cooperation_rate(self, history: PlayerHistory, round_idx: int, window: int=3) -> float:
        """
        Calculate rolling average cooperation rate over last `window` rounds.
        Uses available rounds if fewer than `window` rounds exist.
        """
        if round_idx < 0:
            return 0.0
        start_idx = max(0, round_idx - window + 1)
        end_idx = round_idx + 1
        total_cooperators = 0
        count = 0
        for i in range(start_idx, end_idx):
            if i >= 0 and i < history.opponent_actions.shape[0]:
                total_cooperators += sum(history.opponent_actions[i, :])
                count += 1
        if count == 0:
            return 0.0
        return total_cooperators / (count * self.n)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round_idx = state.round_number
        prev_round_idx = current_round_idx - 1
        prev_cooperation_rate = self._get_cooperation_rate(history, prev_round_idx)
        if current_round_idx == self.r - 1:
            if prev_cooperation_rate >= self.threshold_rate:
                return Action.C
            else:
                return Action.D
        if current_round_idx >= 2:
            cooperation_rate = self._get_rolling_average_cooperation_rate(history, prev_round_idx, window=3)
        else:
            cooperation_rate = prev_cooperation_rate
        if cooperation_rate >= self.threshold_rate:
            return Action.C
        if cooperation_rate >= 0.75 * self.threshold_rate:
            return Action.C
        if cooperation_rate >= 0.5 * self.threshold_rate:
            if current_round_idx <= 3:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_319(BaseStrategy):
    """
    Adaptive Threshold Escalation (ATE) Strategy for Collective Risk Dilemma.
    
    Balances individual security with collective benefit by monitoring cooperation rates,
    escalating commitment gradually, punishing defection intelligently, and protecting
    against exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.target_threshold = self.m / self.n
        self.window_size = min(3, self.r - 1) if self.r > 1 else 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return self._round_zero_decision()
        return self._adaptive_decision(round_num, history)

    def _round_zero_decision(self) -> Action:
        """Edge case logic for round 1 (no history available)."""
        ratio = self.target_threshold
        if ratio <= 0.5:
            return Action.C
        elif ratio <= 0.67:
            return Action.C
        else:
            return Action.D

    def _adaptive_decision(self, round_num: int, history: PlayerHistory) -> Action:
        """Main adaptive decision logic for rounds 1+."""
        cooperation_rate = self._calculate_cooperation_rate(history)
        if round_num > self.r * 0.75:
            return self._endgame_decision(round_num, cooperation_rate)
        if self._detect_unanimous_defection_trap(history):
            return self._handle_unanimous_defection_trap(round_num, history)
        if self._detect_oscillation(history):
            return Action.D
        if cooperation_rate >= self.target_threshold * 1.2:
            return Action.C
        elif cooperation_rate >= self.target_threshold * 0.9:
            return Action.C
        elif cooperation_rate < self.target_threshold * 0.5:
            return Action.D
        else:
            return self._secondary_rule_decision(history)

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate over the recent window."""
        if len(history.my_actions) == 0:
            return 0.0
        start_idx = max(0, len(history.my_actions) - self.window_size)
        recent_actions = history.opponent_actions[start_idx:, :]
        if recent_actions.size == 0:
            return 0.0
        total_possible = recent_actions.shape[0] * recent_actions.shape[1]
        cooperators = int(np.sum(recent_actions))
        if total_possible == 0:
            return 0.0
        return cooperators / total_possible

    def _secondary_rule_decision(self, history: PlayerHistory) -> Action:
        """Secondary rule: Reciprocal escalation in gray zone."""
        my_actions = history.my_actions
        opponent_actions = history.opponent_actions
        if len(my_actions) == 0:
            return Action.C
        my_cooperations = int(np.sum(my_actions))
        rounds_played = len(my_actions)
        personal_ratio = my_cooperations / rounds_played if rounds_played > 0 else 0.0
        successful_rounds = 0
        for round_idx in range(len(opponent_actions)):
            round_cooperators = int(np.sum(opponent_actions[round_idx, :]))
            if round_cooperators >= self.m:
                successful_rounds += 1
        group_ratio = successful_rounds / rounds_played if rounds_played > 0 else 0.0
        if personal_ratio < group_ratio - 0.15:
            return Action.C
        elif personal_ratio > group_ratio + 0.15:
            return Action.D
        else:
            return Action.C

    def _endgame_decision(self, round_num: int, cooperation_rate: float) -> Action:
        """Tertiary rule: End-game behavior in final quarter."""
        if cooperation_rate >= self.target_threshold * 1.1:
            return Action.C
        elif round_num == self.r - 1:
            return Action.D
        else:
            return Action.C

    def _detect_unanimous_defection_trap(self, history: PlayerHistory) -> bool:
        """Detect if we're in unanimous defection for 2+ consecutive rounds."""
        if len(history.opponent_actions) < 2:
            return False
        last_two = history.opponent_actions[-2:, :]
        for round_actions in last_two:
            if int(np.sum(round_actions)) > 0:
                return False
        return True

    def _handle_unanimous_defection_trap(self, round_num: int, history: PlayerHistory) -> Action:
        """Handle unanimous defection by testing cooperation once."""
        consecutive_defections = 0
        for round_idx in range(len(history.opponent_actions) - 1, -1, -1):
            if int(np.sum(history.opponent_actions[round_idx, :])) == 0:
                consecutive_defections += 1
            else:
                break
        if consecutive_defections >= 2:
            return Action.C
        else:
            return Action.D

    def _detect_oscillation(self, history: PlayerHistory) -> bool:
        """Detect oscillation pattern [C,D,C,D] or [D,C,D,C]."""
        if len(history.my_actions) < 4:
            return False
        last_four = history.my_actions[-4:]
        pattern1 = [True, False, True, False]
        pattern2 = [False, True, False, True]
        last_four_list = [bool(x) for x in last_four]
        if last_four_list == pattern1 or last_four_list == pattern2:
            return True
        return False

class Strategy_COLLECTIVE_320(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances collective welfare with individual security by:
    1. Cooperating in round 1 to test collective possibility
    2. Adaptively responding to observed cooperation rates in rounds 2 to r-1
    3. Defecting in the final round (subgame perfect equilibrium)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            return Action.D
        total_cooperations = np.sum(history.opponent_actions[:current_round, :])
        total_cooperations += np.sum(history.my_actions[:current_round])
        total_actions = self.n * current_round
        if total_actions == 0:
            obs_coop_rate = 0.0
        else:
            obs_coop_rate = total_cooperations / total_actions
        last_round_cooperators = np.sum(history.opponent_actions[current_round - 1, :])
        if last_round_cooperators >= self.m - 1:
            return Action.C
        if last_round_cooperators >= (self.m - 1) * 0.75:
            if obs_coop_rate >= self.m / self.n:
                return Action.C
            else:
                return Action.D
        if obs_coop_rate >= self.m / self.n:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_321(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Recognizing the coordination challenge imposed by threshold m
    2. Building robust cooperation based on observed cooperation rates
    3. Protecting against exploitation through adaptive defection
    
    Core decision rule: Cooperate if observed cooperation rate suggests
    threshold will be met; otherwise defect. Includes recovery protocol
    and round-specific handling.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.recovery_counter = 0
        self.threshold_T = (game_description.m - 0.5) / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        round_num = state.round_number
        if round_num == 0:
            if n <= 4:
                return Action.C
            elif m / n > 0.5:
                return Action.C
            else:
                return Action.D
        prev_round_idx = round_num - 1
        prev_cooperators = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            prev_cooperators += 1
        cooperation_rate = prev_cooperators / n
        if round_num == r - 1:
            if cooperation_rate >= self.threshold_T:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= self.threshold_T:
            self.recovery_counter = 0
            return Action.C
        if self.recovery_counter == 0:
            self.recovery_counter = 1
            return Action.C
        elif self.recovery_counter == 1:
            self.recovery_counter = 2
            return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_322(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    A 3-phase strategy that:
    1. Cooperates in round 1 to signal willingness and probe population
    2. Conditionally cooperates in middle rounds if cooperation rate meets threshold
    3. Defects in final round (subgame perfection)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        previous_round_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        cooperation_rate = previous_round_cooperators / self.n_players
        success_threshold = self.m / self.n_players
        if cooperation_rate >= success_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_323(BaseStrategy):
    """
    Adaptive Threshold Sentinel: A collective risk dilemma strategy that adaptively
    cooperates based on historical cooperation rates, progress toward the threshold,
    round position, and safety margins to balance individual advantage with group welfare.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        my_actions = history.my_actions[:round_number]
        opponent_actions = history.opponent_actions[:round_number, :]
        cooperation_history = np.sum(opponent_actions, axis=1)
        avg_cooperation_rate = np.mean(cooperation_history) / (self.n_players - 1)
        cooperators_last_round = cooperation_history[-1]
        rounds_remaining = self.n_rounds - round_number
        expected_cooperators = avg_cooperation_rate * (self.n_players - 1)
        probability_threshold_met = self._estimate_threshold_probability(expected_cooperators, self.m, self.n_players - 1)
        if round_number == self.n_rounds - 1:
            return Action.D
        if probability_threshold_met >= 0.75:
            return Action.D
        elif probability_threshold_met >= 0.5:
            if cooperators_last_round >= self.m:
                return Action.D
            else:
                return Action.C
        elif probability_threshold_met >= 0.3:
            return Action.C
        elif rounds_remaining > 2:
            return Action.C
        else:
            return Action.D

    def _estimate_threshold_probability(self, expected_cooperators: float, threshold: int, max_players: int) -> float:
        """
        Estimate the probability that the threshold will be met given expected cooperators.
        Uses normal approximation to binomial distribution for computational efficiency.
        """
        if max_players <= 0:
            return 0.0
        expected_cooperators = max(0.0, min(float(max_players), expected_cooperators))
        p = expected_cooperators / max_players
        mean = expected_cooperators
        variance = max_players * p * (1.0 - p)
        if variance < 1e-10:
            return 1.0 if mean >= threshold else 0.0
        std_dev = math.sqrt(variance)
        z_score = (threshold - 0.5 - mean) / std_dev
        prob = 0.5 * (1.0 + math.erf(-z_score / math.sqrt(2.0)))
        return max(0.0, min(1.0, prob))

class Strategy_COLLECTIVE_324(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS) for Collective Risk Dilemma.
    
    Balances individual security with collective welfare through conditional cooperation,
    defection pattern tracking, and rational exploitation of failed thresholds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.THRESHOLD = self.m / self.n + 0.15
        self.MIN_VIABLE = (self.m - 1) / (self.n - 1) if self.n > 1 else 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            cooperators_last_round = int(sum(history.opponent_actions[-1, :]))
            if cooperators_last_round >= self.m:
                return Action.C
            else:
                return Action.D
        cooperation_rate = self._calculate_cooperation_rate(history, round_num)
        rounds_since_success = self._count_rounds_since_success(history, round_num)
        if rounds_since_success >= 2 and cooperation_rate < self.THRESHOLD * 0.9:
            return Action.D
        if cooperation_rate >= self.THRESHOLD:
            return Action.C
        if cooperation_rate >= self.MIN_VIABLE:
            cooperators_last_round = int(sum(history.opponent_actions[-1, :]))
            if cooperators_last_round >= self.m:
                return Action.C
        return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate the cooperation rate of opponents across all observed rounds.
        Returns a value between 0.0 and 1.0.
        """
        if round_num == 0:
            return 0.0
        total_cooperators = 0
        total_observations = (self.n - 1) * round_num
        if total_observations == 0:
            return 0.0
        for r in range(round_num):
            total_cooperators += int(sum(history.opponent_actions[r, :]))
        cooperation_rate = total_cooperators / total_observations
        return cooperation_rate

    def _count_rounds_since_success(self, history: PlayerHistory, round_num: int) -> int:
        """
        Count consecutive rounds where cooperators < m, going backwards from current round.
        """
        rounds_since = 0
        for r in range(round_num - 1, -1, -1):
            cooperators_in_round = int(sum(history.opponent_actions[r, :]))
            if cooperators_in_round < self.m:
                rounds_since += 1
            else:
                break
        return rounds_since

class Strategy_COLLECTIVE_325(BaseStrategy):
    """
    Adaptive Threshold Stewardship: A threshold-dependent cooperation strategy
    that balances individual security with collective success in the Collective Risk Dilemma.
    
    The strategy observes cooperation rates and makes decisions based on whether the
    threshold m is likely to be reached, with special endgame logic for the final rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        prev_opponent_cooperators = sum(history.opponent_actions[prev_round_idx, :])
        prev_self_action = history.my_actions[prev_round_idx]
        prev_total_cooperators = prev_opponent_cooperators + (1 if prev_self_action else 0)
        expected_cooperators = float(prev_total_cooperators)
        is_final_round = current_round == self.n_rounds - 1
        endgame_threshold = math.ceil(self.n_rounds / 3)
        is_endgame = current_round >= self.n_rounds - endgame_threshold
        if is_final_round:
            if expected_cooperators >= self.m:
                return Action.C
            else:
                return Action.D
        elif is_endgame:
            threshold_trigger = 0.8 * self.m
            if expected_cooperators >= threshold_trigger:
                return Action.C
            else:
                return Action.D
        elif expected_cooperators >= self.m:
            return Action.C
        elif expected_cooperators >= 0.6 * self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_326(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual security with collective welfare by monitoring cooperation rates,
    reciprocating proportionally, leading early, protecting against free-riders, and
    maximizing collective gain when threshold success is likely.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        prev_round_idx = current_round - 1
        opponent_cooperators_prev = int(sum(history.opponent_actions[prev_round_idx, :]))
        my_action_prev = history.my_actions[prev_round_idx]
        total_cooperators_prev = opponent_cooperators_prev + (1 if my_action_prev else 0)
        observed_cooperation_rate = total_cooperators_prev / n
        if current_round == r - 1:
            return Action.D
        if total_cooperators_prev >= m:
            return Action.C
        if observed_cooperation_rate == 0:
            return Action.D
        threshold_rate = m / n
        near_threshold_rate = (m - 1) / n
        if observed_cooperation_rate >= near_threshold_rate and observed_cooperation_rate < threshold_rate:
            return Action.C
        if opponent_cooperators_prev >= m - 1:
            return Action.C
        if observed_cooperation_rate >= (m + 1) / n:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_327(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by dynamically assessing
    cooperation viability based on historical cooperation rates. Cooperates in round 1
    to gather signals, adapts in mid-game based on observed cooperation rates, and
    defects in the final round due to subgame perfection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.safety_margin = 1.1
        self.low_cooperation_threshold = 0.3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if round_number == 0:
            return Action.C
        if round_number == r - 1:
            return Action.D
        if history is None:
            return Action.C
        total_opponent_choices = history.opponent_actions[:round_number].size
        if total_opponent_choices == 0:
            return Action.C
        total_cooperations = np.sum(history.opponent_actions[:round_number])
        cooperation_rate = total_cooperations / total_opponent_choices
        cooperators_needed = m - 1
        required_rate = cooperators_needed / (n - 1)
        high_confidence_threshold = required_rate * self.safety_margin
        if cooperation_rate >= high_confidence_threshold:
            return Action.C
        if cooperation_rate < required_rate * self.low_cooperation_threshold:
            return Action.D
        rounds_remaining = r - round_number
        time_discount = rounds_remaining / r
        random_threshold = cooperation_rate * time_discount
        if random.random() < random_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_328(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Recognizes that collective success requires m cooperators. Proactively cooperates
    early, adaptively calibrates based on observed cooperation rates, protects the
    collective threshold by increasing contribution when cooperation falls short, and
    minimizes exploitation by defecting when collective success is sufficiently likely
    without the player's contribution.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        round_number = state.round_number
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        prev_round_idx = round_number - 1
        cooperators_prev = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        coop_rate = cooperators_prev / n if n > 0 else 0.0
        threshold_rate = m / n if n > 0 else 0.0
        deficit = threshold_rate - coop_rate
        if deficit > 0.15:
            return Action.C
        if deficit < 0.0:
            if round_number == r - 1 and cooperators_prev == n:
                return Action.D
            return Action.D
        expected_cooperators = math.floor(coop_rate * n) + 1
        if expected_cooperators >= m:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_329(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances collective welfare with individual security by:
    1. Proactive cooperation when mutual benefit is achievable
    2. Defensive defection when cooperation appears exploited
    3. Recovery mechanisms to rebuild cooperation after defection spirals
    4. Collective signaling through consistent behavior patterns
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            cooperators_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
            if history.my_actions[current_round - 1]:
                cooperators_last_round += 1
            if cooperators_last_round >= self.m:
                return Action.C
            else:
                return Action.D
        total_cooperators = 0
        for round_idx in range(current_round):
            round_cooperators = int(sum(history.opponent_actions[round_idx, :]))
            if history.my_actions[round_idx]:
                round_cooperators += 1
            total_cooperators += round_cooperators
        cooperation_rate = total_cooperators / (current_round * self.n)
        threshold_met_count = 0
        for round_idx in range(current_round):
            round_cooperators = int(sum(history.opponent_actions[round_idx, :]))
            if history.my_actions[round_idx]:
                round_cooperators += 1
            if round_cooperators >= self.m:
                threshold_met_count += 1
        threshold_met_rate = threshold_met_count / current_round if current_round > 0 else 0
        recent_rounds = min(3, current_round)
        recent_cooperators = 0
        for round_idx in range(current_round - recent_rounds, current_round):
            round_cooperators = int(sum(history.opponent_actions[round_idx, :]))
            if history.my_actions[round_idx]:
                round_cooperators += 1
            recent_cooperators += round_cooperators
        recent_cooperators = recent_cooperators / recent_rounds if recent_rounds > 0 else 0
        if recent_cooperators >= self.m and threshold_met_rate >= 0.6:
            return Action.C
        if recent_cooperators >= self.m and cooperation_rate >= self.m / self.n * 1.5:
            return Action.C
        if cooperation_rate < self.m / self.n * 0.8:
            return Action.D
        rounds_since_success = current_round
        for round_idx in range(current_round - 1, -1, -1):
            round_cooperators = int(sum(history.opponent_actions[round_idx, :]))
            if history.my_actions[round_idx]:
                round_cooperators += 1
            if round_cooperators >= self.m:
                rounds_since_success = current_round - round_idx - 1
                break
        if rounds_since_success <= 2:
            return Action.C
        if recent_cooperators >= self.m - 1:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_330(BaseStrategy):
    """
    Adaptive Threshold Guardian: A conditional cooperation strategy that monitors
    collective progress toward the cooperation threshold and adapts contribution
    rates based on observed cooperation levels, while protecting against exploitation
    and maximizing group payoff when cooperation becomes self-reinforcing.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            slack_threshold = self.n - self.m
            if slack_threshold <= 2:
                return Action.D
            else:
                return Action.C
        if round_t == self.r - 1:
            return Action.D
        recent_coop_rate = self._get_recent_cooperation_rate(history, round_t)
        threshold_rate = self.m / self.n
        if recent_coop_rate >= threshold_rate:
            return Action.D
        cooperators_needed = self.m - 1
        others_count = self.n - 1
        if others_count <= 0:
            return Action.D
        required_rate_from_others = cooperators_needed / others_count
        if recent_coop_rate >= required_rate_from_others * 0.9:
            return Action.C
        if recent_coop_rate >= required_rate_from_others * 0.5:
            return Action.C
        return Action.D

    def _get_recent_cooperation_rate(self, history: PlayerHistory, round_t: int) -> float:
        """
        Calculate the average cooperation rate over the last 2 rounds
        (or fewer if fewer than 2 rounds have been completed).
        """
        if round_t == 0:
            return 0.0
        start_round = max(0, round_t - 2)
        end_round = round_t
        total_cooperators = 0
        round_count = 0
        for r in range(start_round, end_round):
            if r < len(history.opponent_actions):
                cooperators_in_round = np.sum(history.opponent_actions[r, :])
                total_cooperators += cooperators_in_round
                round_count += 1
        if round_count == 0:
            return 0.0
        avg_cooperators_per_round = total_cooperators / round_count
        cooperation_rate = avg_cooperators_per_round / self.n
        return cooperation_rate

class Strategy_COLLECTIVE_331(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Dynamically adjusts cooperation based on historical group success rate
    and recent cooperation levels. Balances individual rationality with
    collective benefit by tracking whether the group can reliably achieve
    the cooperation threshold m.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round_index = state.round_number
        success_rate = self.cooperation_rounds / current_round_index
        prev_round_index = current_round_index - 1
        prev_cooperators = int(np.sum(history.opponent_actions[prev_round_index, :]))
        if history.my_actions[prev_round_index]:
            prev_cooperators += 1
        if success_rate >= 0.7:
            return Action.C
        elif success_rate >= 0.3:
            if prev_cooperators >= self.game_description.m - 1:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round_index = state.round_number
        rounds_with_threshold = 0
        for past_round in range(current_round_index):
            cooperators_in_round = int(np.sum(history.opponent_actions[past_round, :]))
            if history.my_actions[past_round]:
                cooperators_in_round += 1
            if cooperators_in_round >= self.game_description.m:
                rounds_with_threshold += 1
        success_rate = rounds_with_threshold / current_round_index
        prev_round_index = current_round_index - 1
        prev_cooperators = int(np.sum(history.opponent_actions[prev_round_index, :]))
        if history.my_actions[prev_round_index]:
            prev_cooperators += 1
        if success_rate >= 0.7:
            return Action.C
        elif success_rate >= 0.3:
            if prev_cooperators >= self.game_description.m - 1:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_332(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATC)
    
    Balances individual rational self-interest with collective benefit by:
    1. Seeding cooperation in round 1
    2. Adapting dynamically based on observed cooperation rates
    3. Using probabilistic commitment near the threshold
    4. Defecting in the final round (subgame perfect equilibrium)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            return Action.D
        total_cooperators = int(np.sum(history.opponent_actions[:round_num, :]))
        total_slots = self.n * round_num
        if total_slots == 0:
            cooperation_rate = 0.0
        else:
            cooperation_rate = total_cooperators / total_slots
        recent_cooperators = int(np.sum(history.opponent_actions[round_num - 1, :]))
        recent_coop = recent_cooperators / self.n
        threshold_ratio = self.m / self.n
        if threshold_ratio == 0:
            return Action.C
        achievability = recent_coop / threshold_ratio
        if round_num >= 2:
            prev_cooperators = int(np.sum(history.opponent_actions[round_num - 2, :]))
            if recent_cooperators == 0 and prev_cooperators == 0:
                return Action.D
        if round_num >= 3:
            coop_streak = 0
            for i in range(round_num - 1, max(round_num - 4, -1), -1):
                if int(np.sum(history.opponent_actions[i, :])) == self.n:
                    coop_streak += 1
                else:
                    break
            if coop_streak >= 3:
                return Action.C
        if achievability >= 1.0:
            return Action.C
        elif achievability >= 0.5:
            if threshold_ratio > 0.7:
                prob = min(2.0 * achievability, 1.0)
            elif threshold_ratio < 0.3:
                prob = achievability ** 1.5
            else:
                prob = achievability
            if random.random() < prob:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_333(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Cooperating in round 1 to establish cooperative signal
    2. Adaptively tracking threshold risk in middle rounds
    3. Making final round decisions based on whether threshold was met
    
    Key insight: Cooperation becomes individually optimal once threshold is met,
    and threshold protection requires monitoring cooperator count relative to minimum needed.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        cooperators_last_round = int(np.sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            cooperators_last_round += 1
        if current_round == self.n_rounds - 1:
            if cooperators_last_round >= self.m:
                return Action.C
            else:
                return Action.D
        coop_rate = cooperators_last_round / self.n_players
        threshold_rate = self.m / self.n_players
        if coop_rate >= threshold_rate:
            return Action.C
        if coop_rate < threshold_rate * 0.5:
            return Action.D
        if cooperators_last_round == self.m - 1:
            return Action.C
        if cooperators_last_round >= self.m:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_334(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATC)
    
    Balances individual risk management with collective benefit maximization through
    adaptive, history-informed decision-making. Cooperation decisions are contingent on
    observable collective progress toward the threshold m, not on trust in others' intentions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.required_threshold = self.m / self.n
        self.safety_margin = 0.15
        self.effective_threshold = self.required_threshold + self.safety_margin

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            if random.random() < self.required_threshold:
                return Action.C
            return Action.D
        cooperation_rate = self._calculate_cooperation_rate(history, round_num)
        if cooperation_rate < 0.01:
            if random.random() < 0.05:
                return Action.C
            return Action.D
        cooperators_prev_round = np.sum(history.opponent_actions[round_num - 1, :])
        if cooperators_prev_round >= self.m:
            return self._repeat_previous_action(history, round_num)
        tipping_point_boost = 0.0
        if self.m - 1 <= cooperators_prev_round <= self.m + 1:
            tipping_point_boost = 0.1
        if round_num <= 3:
            defection_rate_early = self._calculate_early_defection_rate(history, round_num)
            if defection_rate_early > 0.7:
                if random.random() < 0.05:
                    return Action.C
                return Action.D
        if round_num == self.r - 1:
            if cooperation_rate >= self.required_threshold:
                return Action.C
            return Action.D
        rounds_remaining = self.r - round_num
        if cooperation_rate >= self.effective_threshold:
            return Action.C
        elif cooperation_rate >= self.required_threshold:
            prob = (cooperation_rate - self.required_threshold) / self.safety_margin
            prob = min(prob, 1.0)
            prob += tipping_point_boost
            if random.random() < prob:
                return Action.C
            return Action.D
        elif rounds_remaining > 2:
            return Action.D
        else:
            if cooperation_rate >= self.required_threshold * 0.8:
                if random.random() < 0.3:
                    return Action.C
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """Calculate the proportion of cooperators observed across all history."""
        if round_num == 0:
            return 0.0
        total_cooperators = 0
        for r in range(round_num):
            cooperators_in_round = np.sum(history.opponent_actions[r, :])
            total_cooperators += cooperators_in_round
        total_observations = self.n * round_num
        if total_observations == 0:
            return 0.0
        return total_cooperators / total_observations

    def _calculate_early_defection_rate(self, history: PlayerHistory, round_num: int) -> float:
        """Calculate defection rate in early rounds (1-3)."""
        rounds_to_check = min(3, round_num)
        if rounds_to_check == 0:
            return 0.0
        total_defectors = 0
        for r in range(rounds_to_check):
            defectors_in_round = self.n - np.sum(history.opponent_actions[r, :])
            total_defectors += defectors_in_round
        total_observations = self.n * rounds_to_check
        if total_observations == 0:
            return 0.0
        return total_defectors / total_observations

    def _repeat_previous_action(self, history: PlayerHistory, round_num: int) -> Action:
        """Maintain previous action choice to avoid disrupting equilibrium."""
        if history.my_actions[round_num - 1]:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_335(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Cooperates when the group needs us (pivotal player), defects when threshold
    is already met or unlikely to be reached. Dynamically estimates future
    cooperation based on observed trends.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        recent_rounds = min(3, current_round)
        recent_history = history.opponent_actions[-recent_rounds:, :]
        total_recent_cooperators = np.sum(recent_history)
        total_recent_slots = recent_rounds * self.n_players
        recent_cooperation_rate = total_recent_cooperators / total_recent_slots if total_recent_slots > 0 else 0.0
        projected_cooperators = self._estimate_future_cooperation(recent_cooperation_rate, current_round)
        if current_round == self.n_rounds - 1:
            if recent_cooperation_rate > 0.5:
                return Action.C
            else:
                return Action.D
        prev_round_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        if prev_round_cooperators >= self.m:
            return Action.D
        if prev_round_cooperators == self.m - 1:
            return Action.C
        if prev_round_cooperators < self.m - 1:
            remaining_rounds = self.n_rounds - current_round
            if remaining_rounds <= 2:
                return Action.C
            else:
                return Action.D
        if projected_cooperators >= self.m:
            return Action.D
        elif projected_cooperators >= self.m - 1:
            return Action.C
        else:
            remaining_rounds = self.n_rounds - current_round
            if remaining_rounds <= 2:
                return Action.C
            else:
                return Action.D

    def _estimate_future_cooperation(self, recent_rate: float, current_round: int) -> float:
        """
        Estimate the number of future cooperators based on observed cooperation rate
        and remaining rounds.
        """
        if recent_rate >= 0.75:
            expected_rate = recent_rate * 0.95
        elif recent_rate >= 0.5:
            expected_rate = recent_rate * 0.98
        elif recent_rate >= self.m / self.n_players:
            expected_rate = self.m / self.n_players + 0.1
        else:
            expected_rate = recent_rate * 0.85
        remaining_rounds = self.n_rounds - current_round
        if remaining_rounds <= 2:
            expected_rate = min(1.0, expected_rate * 1.15)
        projected_cooperators = expected_rate * self.n_players
        return projected_cooperators

class Strategy_COLLECTIVE_337(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by conditionally cooperating
    based on whether the cooperation threshold is being met. Uses three regimes:
    1. Healthy (cooperation_rate >= m/n): COOPERATE
    2. Fragile (m/(2n) <= cooperation_rate < m/n): COOPERATE with probability
    3. Collapse (cooperation_rate < m/(2n)): DEFECT
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round_idx = state.round_number - 1
        prev_cooperators_opponents = sum(history.opponent_actions[prev_round_idx, :])
        prev_cooperators_self = int(history.my_actions[prev_round_idx])
        prev_cooperation_count = prev_cooperators_opponents + prev_cooperators_self
        cooperation_rate = prev_cooperation_count / self.n
        threshold_rate = self.m / self.n
        collapse_threshold_rate = threshold_rate * 0.5
        if cooperation_rate >= threshold_rate:
            return Action.C
        elif cooperation_rate >= collapse_threshold_rate:
            probability = 2 * cooperation_rate / threshold_rate
            if random.random() < probability:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_338(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Starting with cooperation to establish mutual benefit
    2. Monitoring cooperation rates against the threshold m/n
    3. Punishing free-riding when cooperation is insufficient
    4. Recovering cooperation when threat levels decrease
    5. Strategic defection in final round or crisis scenarios
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        round_num = state.round_number
        cooperators_last_round = int(sum(history.opponent_actions[round_num - 1, :]))
        threshold_met_last_round = cooperators_last_round >= self.m
        cooperation_rate = self._calculate_cooperation_rate(history, round_num)
        threat_level = self._determine_threat_level(cooperation_rate)
        if round_num == self.r - 1:
            if threat_level in ['HIGH', 'CRITICAL'] or cooperation_rate < self.m / self.n:
                return Action.D
            else:
                return Action.C
        early_game_threshold = max(3, math.ceil(self.r / 3))
        if round_num < early_game_threshold and threat_level == 'CRITICAL':
            return Action.C
        if threat_level == 'CRITICAL':
            return Action.D
        elif threat_level == 'HIGH':
            return Action.D
        elif threat_level == 'MODERATE':
            return Action.C
        else:
            return Action.C

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate the average cooperation rate over recent rounds.
        Uses a sliding window of last 5 rounds or all available rounds if fewer.
        """
        recent_rounds = min(5, round_num)
        if recent_rounds == 0:
            return 0.0
        total_cooperators = 0
        for i in range(round_num - recent_rounds, round_num):
            opponent_cooperators = int(sum(history.opponent_actions[i, :]))
            my_cooperation = 1 if history.my_actions[i] else 0
            total_cooperators += opponent_cooperators + my_cooperation
        total_players_across_rounds = recent_rounds * self.n
        cooperation_rate = total_cooperators / total_players_across_rounds if total_players_across_rounds > 0 else 0.0
        return cooperation_rate

    def _determine_threat_level(self, cooperation_rate: float) -> str:
        """
        Classify threat level based on cooperation rate.
        Thresholds are relative to m/n (the success threshold).
        """
        threshold = self.m / self.n
        if cooperation_rate < threshold * 0.5:
            return 'CRITICAL'
        elif cooperation_rate < threshold:
            return 'HIGH'
        elif cooperation_rate < threshold * 1.5:
            return 'MODERATE'
        else:
            return 'LOW'

class Strategy_COLLECTIVE_339(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    This strategy balances collective cooperation with rational self-protection,
    using graduated reciprocity and threshold monitoring to achieve coordination
    while remaining robust to defection and free-riding.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        last_round_actions = history.opponent_actions[-1, :]
        last_round_cooperators = int(np.sum(last_round_actions))
        last_cooperation_rate = last_round_cooperators / self.n
        all_cooperation_rates = np.mean(history.opponent_actions, axis=1)
        avg_cooperation_all = float(np.mean(all_cooperation_rates))
        threshold_stability = (self.m + 1) / self.n
        if self.m == self.n - 1:
            drift_tolerance = 0.2
        elif self.m == 2:
            drift_tolerance = 0.3
        else:
            drift_tolerance = 0.15
        min_cooperation_threshold = max(0.0, self.m / self.n - drift_tolerance)
        if current_round == self.r - 1:
            if avg_cooperation_all >= threshold_stability:
                return Action.C
            else:
                return Action.D
        if last_cooperation_rate >= threshold_stability:
            return Action.C
        elif last_cooperation_rate >= min_cooperation_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_340(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances individual risk management with collective benefit maximization by:
    1. Cooperating optimistically in round 1 to signal goodwill
    2. Adapting a dynamic confidence threshold based on observed cooperation rates
    3. Making context-aware decisions in the final round
    4. Gracefully withdrawing cooperation only when the group fails to sustain collaboration
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            cooperators_last_round = int(sum(history.opponent_actions[-1, :]))
            if cooperators_last_round >= self.m:
                return Action.C
            else:
                return Action.D
        total_cooperators = 0
        for round_idx in range(current_round):
            total_cooperators += sum(history.opponent_actions[round_idx, :])
        if current_round > 0:
            observed_cooperation_rate = total_cooperators / (current_round * self.n_players)
        else:
            observed_cooperation_rate = 0.0
        rounds_remaining = self.n_rounds - current_round
        threshold_base = self.m / self.n_players
        threshold_adjustment = (1.0 - threshold_base) * (rounds_remaining / self.n_rounds)
        required_confidence = threshold_base + threshold_adjustment
        cooperators_last_round = int(sum(history.opponent_actions[-1, :]))
        if observed_cooperation_rate >= required_confidence:
            if cooperators_last_round >= self.m - 1:
                return Action.C
            else:
                return Action.D
        elif cooperators_last_round >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_341(BaseStrategy):
    """
    Adaptive Threshold Insurance strategy for Collective Risk Dilemma.
    
    Balances individual security against collective benefit by:
    1. Using reward-to-risk ratio for initial decision
    2. Tracking cooperation history to estimate threshold achievement likelihood
    3. Adapting decisions based on observed cooperation rates
    4. Protecting against cascading defection
    5. Making realistic final-round decisions based on observed data
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if self.m == 1:
            return Action.C
        if self.m == self.n:
            return Action.D
        if round_num == 0:
            if (self.k - 1) / self.k > (self.n - self.m) / self.n:
                return Action.C
            else:
                return Action.D
        cooperation_rate = self._calculate_cooperation_rate(history, round_num)
        expected_cooperators = cooperation_rate * self.n
        rounds_remaining = self.r - round_num - 1
        if round_num > 1:
            prev_cooperation_rate = self._calculate_cooperation_rate(history, round_num - 1)
            if prev_cooperation_rate > 0 and cooperation_rate < 0.5 * prev_cooperation_rate:
                return Action.D
        if round_num == self.r - 1:
            if cooperation_rate >= self.m / self.n:
                return Action.C
            else:
                return Action.D
        if expected_cooperators >= self.m:
            return Action.C
        elif expected_cooperators >= self.m - 1:
            if rounds_remaining > 1:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the cooperation rate from history up to (but not including) current_round.
        
        Args:
            history: PlayerHistory object containing opponent actions
            current_round: The current round number (0-indexed)
        
        Returns:
            Cooperation rate as a float between 0 and 1, or 0 if no history
        """
        if current_round <= 0:
            return 0.0
        total_cooperations = 0
        for round_idx in range(current_round):
            total_cooperations += np.sum(history.opponent_actions[round_idx, :])
        total_possible = self.n * current_round
        if total_possible == 0:
            return 0.0
        return total_cooperations / total_possible

class Strategy_COLLECTIVE_342(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances collective survival (ensuring threshold m is met) with individual rationality
    (avoiding exploitation by free-riders). Uses adaptive decision rules based on observed
    cooperation rates in previous rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        opponent_coops_prev = sum(history.opponent_actions[prev_round_idx, :])
        my_action_prev = history.my_actions[prev_round_idx]
        total_coops_prev = opponent_coops_prev + (1 if my_action_prev else 0)
        coop_rate_last = total_coops_prev / self.n
        threshold_met = self.m / self.n
        threshold_adapt = (self.m - 1) / self.n
        is_final_round = current_round == self.r - 1
        if is_final_round:
            if coop_rate_last >= threshold_met:
                return Action.C
            elif coop_rate_last >= threshold_adapt:
                return Action.C
            else:
                return Action.D
        elif coop_rate_last >= threshold_met:
            return Action.C
        elif coop_rate_last > 0 and coop_rate_last < threshold_met:
            if coop_rate_last >= threshold_adapt:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_343(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATC) for Collective Risk Dilemma.
    
    Balances efficiency (reaching threshold m), robustness (protecting against free-riders),
    and adaptive learning by adjusting cooperation probability based on observed cooperation rates.
    Cooperates in round 1, uses adaptive mixed strategies in rounds 2 to r-1, and defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.consecutive_low_coop_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.n_rounds - 1:
            return Action.D
        last_round_cooperators = int(sum(history.opponent_actions[round_number - 1, :]))
        last_round_cooperators += int(history.my_actions[round_number - 1])
        observed_coop_rate = last_round_cooperators / self.n_players
        threshold_ratio = self.m / self.n_players
        marginal_ratio = (self.m - 1) / self.n_players
        if observed_coop_rate >= threshold_ratio:
            cooperation_prob = 0.9
            self.consecutive_low_coop_rounds = 0
        elif observed_coop_rate >= marginal_ratio:
            cooperation_prob = 0.7
            self.consecutive_low_coop_rounds = 0
        elif observed_coop_rate >= 0.4:
            cooperation_prob = 0.4
            self.consecutive_low_coop_rounds = 0
        else:
            cooperation_prob = 0.15
            self.consecutive_low_coop_rounds += 1
        if self.consecutive_low_coop_rounds >= 2 and observed_coop_rate < 0.2:
            cooperation_prob = 0.1
        if random.random() < cooperation_prob:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_344(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Maximizes collective welfare while maintaining individual incentive compatibility
    through adaptive reciprocity. Cooperates when threshold is reachable, defects when
    it's not, with probabilistic support near the threshold boundary.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_idx = round_num - 1
        prev_cooperators = int(sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            prev_cooperators += 1
        coop_rate = prev_cooperators / self.n
        threshold_rate = self.m / self.n
        gap = self.m - prev_cooperators
        if round_num == self.r - 1:
            if coop_rate >= threshold_rate:
                return Action.C
            else:
                return Action.D
        if prev_cooperators == 0 and round_num > 1:
            punishment_round = round_num - 1
            last_all_defect = None
            for i in range(prev_round_idx, -1, -1):
                if int(sum(history.opponent_actions[i, :])) == 0 and (not history.my_actions[i]):
                    last_all_defect = i
                    break
            if last_all_defect is not None and round_num - last_all_defect <= 2:
                return Action.D
        if gap <= 1:
            if random.random() < 0.95:
                return Action.C
            else:
                return Action.D
        elif gap <= 2:
            if random.random() < 0.9:
                return Action.C
            else:
                return Action.D
        elif gap > self.n / 2:
            return Action.D
        if coop_rate >= threshold_rate:
            return Action.C
        elif coop_rate >= threshold_rate - 1 / self.n:
            if random.random() < 0.75:
                return Action.C
            else:
                return Action.D
        else:
            if round_num >= 3:
                recent_cooperators = []
                for i in range(max(0, round_num - 3), round_num):
                    recent_coop = int(sum(history.opponent_actions[i, :]))
                    if history.my_actions[i]:
                        recent_coop += 1
                    recent_cooperators.append(recent_coop)
                if len(recent_cooperators) >= 2:
                    trend_improving = recent_cooperators[-1] > recent_cooperators[-2]
                    if trend_improving:
                        if random.random() < 0.8:
                            return Action.C
            return Action.D

class Strategy_COLLECTIVE_345(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Employs a collective-first approach with intelligent defection safeguards:
    - Round 1: Always cooperate to establish cooperative norm
    - Middle rounds: Adapt based on recent cooperation levels and recovery potential
    - Final round: Defect if group cooperation is insufficient, otherwise cooperate
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.n_rounds - 1:
            return self._final_round_decision(history)
        return self._middle_round_decision(round_num, history)

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """
        Final round: cooperate if historical cooperation rate >= m/n threshold.
        """
        total_rounds_completed = len(history.my_actions)
        if total_rounds_completed == 0:
            return Action.C
        total_opponent_cooperations = np.sum(history.opponent_actions)
        total_possible_cooperations = self.n_players * total_rounds_completed
        if total_possible_cooperations == 0:
            return Action.C
        overall_coop_rate = total_opponent_cooperations / total_possible_cooperations
        threshold_for_final = self.m / self.n_players
        if overall_coop_rate >= threshold_for_final:
            return Action.C
        else:
            return Action.D

    def _middle_round_decision(self, round_num: int, history: PlayerHistory) -> Action:
        """
        Middle rounds: adaptive cooperation based on recent behavior.
        """
        last_round_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        if last_round_cooperators >= self.m:
            return Action.C
        if last_round_cooperators == self.m - 1:
            return Action.C
        defection_rate = (self.n_players - last_round_cooperators) / self.n_players
        rounds_remaining = self.n_rounds - round_num - 1
        if defection_rate > 0.5 and rounds_remaining <= 2:
            return Action.D
        return Action.C

class Strategy_COLLECTIVE_346(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Cooperates when the observed cooperation rate in the previous round suggests
    the threshold m is achievable. Defects otherwise to avoid exploitation.
    In round 1, cooperates if m <= n/2, defects if m > n/2.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        if state.round_number == 0:
            if m <= n / 2:
                return Action.C
            else:
                return Action.D
        most_recent_round_idx = state.round_number - 1
        opponent_cooperators_last_round = sum(history.opponent_actions[most_recent_round_idx, :])
        self_cooperated_last_round = history.my_actions[most_recent_round_idx]
        total_cooperators_last_round = opponent_cooperators_last_round
        if self_cooperated_last_round:
            total_cooperators_last_round += 1
        observed_coop_rate = total_cooperators_last_round / n
        threshold = (m - 1) / n
        if observed_coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_347(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual security with collective welfare by dynamically adjusting
    cooperation based on group reliability, time pressure, and recent momentum.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        n = self.n_players
        m = self.m
        r = self.n_rounds
        rounds_remaining = r - round_number
        if rounds_remaining <= 2:
            return Action.C
        if round_number == 0:
            return Action.C
        if m == 1:
            return Action.C
        my_actions = history.my_actions
        opponent_actions = history.opponent_actions
        successes = 0
        for past_round in range(round_number):
            cooperators_in_round = int(my_actions[past_round])
            cooperators_in_round += sum(opponent_actions[past_round, :])
            if cooperators_in_round >= m:
                successes += 1
        rounds_completed = round_number
        if rounds_completed > 0:
            reliability_threshold = rounds_completed / 2.0
            if successes >= reliability_threshold:
                return Action.C
        last_round_opponent_cooperators = sum(opponent_actions[round_number - 1, :])
        last_round_my_action = my_actions[round_number - 1]
        last_round_total_cooperators = last_round_opponent_cooperators + int(last_round_my_action)
        if last_round_total_cooperators >= m:
            return Action.C
        defection_streak = 0
        for i in range(round_number - 1, -1, -1):
            if not my_actions[i]:
                defection_streak += 1
            else:
                break
        if defection_streak >= 2:
            return Action.C
        if last_round_opponent_cooperators == m - 1:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_348(BaseStrategy):
    """
    Adaptive Threshold Cooperation for Collective Risk Dilemma.
    
    Balances collective welfare, robustness, and adaptability by cooperating
    when observed cooperation rates approach the threshold m, with time-sensitive
    escalation and recovery capacity assessment.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.threshold_met_historically = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        r = self.n_rounds
        if t == 0:
            return Action.C
        opponent_coop_count = int(sum(history.opponent_actions[t - 1, :]))
        observed_cooperation_rate = opponent_coop_count / (self.n_players - 1) if self.n_players > 1 else 0.0
        if opponent_coop_count + int(history.my_actions[t - 1]) >= self.m:
            self.threshold_met_historically = True
        rounds_remaining = r - t
        if t <= r / 2:
            threshold = (self.m - 1) / self.n_players if self.n_players > 0 else 0.0
        elif t <= 3 * r / 4:
            threshold = 0.9 * self.m / self.n_players if self.n_players > 0 else 0.0
        else:
            threshold = self.m / self.n_players if self.n_players > 0 else 0.0
        if observed_cooperation_rate >= threshold:
            return Action.C
        if rounds_remaining >= 2:
            cooperation_deficit = self.m - opponent_coop_count
            catch_up_capacity = (self.m - 1) * (rounds_remaining - 1)
            if cooperation_deficit <= catch_up_capacity:
                return Action.C
        if rounds_remaining == 1:
            if self.threshold_met_historically:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_349(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Core principle: Cooperate strategically based on observed cooperation rates,
    with unconditional cooperation in round 1, unconditional defection in the final round,
    and adaptive threshold-based decisions in middle rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        if round_t == self.n_rounds - 1:
            return Action.D
        prev_round_idx = round_t - 1
        cooperators_prev = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            cooperators_prev += 1
        cooperation_rate = cooperators_prev / self.n_players
        threshold = self.m / self.n_players + (self.n_rounds - round_t) / (2.0 * self.n_rounds)
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_350(BaseStrategy):
    """
    Adaptive Threshold Guardianship: A collective-oriented strategy that dynamically
    adjusts cooperation based on the group's capacity to reach the cooperation threshold.
    
    Cooperates in bootstrap phase, reinforces success, escalates near-misses, 
    defects when recovery is implausible, and pushes hard in final rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_collapse_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if state.round_number == 0:
            return Action.C
        c_prev = int(np.sum(history.opponent_actions[-1, :]))
        gap = m - c_prev
        if c_prev <= 1:
            self.consecutive_collapse_rounds += 1
            if self.consecutive_collapse_rounds >= 2:
                return Action.D
        else:
            self.consecutive_collapse_rounds = 0
        if gap <= 0:
            return Action.C
        threshold_distance = m - math.ceil(n / 4)
        if gap > 0 and c_prev >= threshold_distance:
            return Action.C
        if r - state.round_number <= 2:
            return Action.C
        defector_tolerance = n - m
        if defector_tolerance > 0 and gap > defector_tolerance * 0.5:
            return Action.D
        return Action.C

class Strategy_COLLECTIVE_351(BaseStrategy):
    """
    Adaptive Threshold Matching Strategy (ATMS) for Collective Risk Dilemma.
    
    Balances individual rationality with collective benefit by dynamically matching
    cooperation to observed group behavior. Cooperates in round 1 to gather information,
    then reciprocates based on whether the group met the cooperation threshold in the
    previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round_actions = history.opponent_actions[state.round_number - 1, :]
        cooperators_count = int(np.sum(previous_round_actions))
        my_previous_action = history.my_actions[state.round_number - 1]
        total_cooperators = cooperators_count + (1 if my_previous_action else 0)
        cooperation_rate = total_cooperators / self.n_players
        threshold_rate = self.m / self.n_players
        if cooperation_rate >= threshold_rate:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_352(BaseStrategy):
    """
    Adaptive Threshold Matching strategy for Collective Risk Dilemma.
    
    Pursues conditional cooperation with adaptive risk assessment by:
    1. Maintaining a recent cooperation rate from a sliding window
    2. Adjusting cooperation threshold based on game phase (early/mid/late)
    3. Detecting cooperation collapse and defecting preemptively
    4. Handling final round with special logic to balance exploitation and reciprocity
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        if t == 0:
            if self.m <= self.n / 2:
                return Action.C
            else:
                return Action.D
        window_size = max(3, math.ceil(self.r / 4))
        start_idx = max(0, t - window_size)
        recent_rounds = history.opponent_actions[start_idx:t, :]
        if recent_rounds.shape[0] > 0:
            cooperators_per_round = np.sum(recent_rounds, axis=1)
            recent_coop_rate = np.mean(cooperators_per_round) / self.n
        else:
            recent_coop_rate = 0.0
        if t <= self.r / 3:
            threshold = 0.3
        elif t <= 2 * self.r / 3:
            threshold = self.m / self.n + 0.1
        else:
            threshold = self.m / self.n + 0.2
        collapse_threshold = self.m / self.n - 0.15
        if recent_coop_rate < collapse_threshold:
            return Action.D
        if t == self.r - 1:
            if recent_coop_rate < self.m / self.n + 0.1:
                if self.k > 1.5:
                    return Action.D
                else:
                    return Action.C
            elif random.random() < recent_coop_rate:
                return Action.C
            else:
                return Action.D
        if recent_coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_353(BaseStrategy):
    """
    Adaptive Collective Risk Strategy (ACRS)
    
    Implements threshold-based cooperation monitoring with optimistic opening,
    adaptive mid-game adjustment, and strategic final-round defection.
    
    Core logic:
    - Round 0: Cooperate (optimistic opening)
    - Rounds 1 to r-2: Cooperate if cooperation_rate >= m/n, else defect
    - Round r-1: Defect (final round free-riding)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.cooperation_threshold = self.m / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.n_rounds - 1:
            return Action.D
        previous_round_idx = round_number - 1
        opponent_cooperators = sum(history.opponent_actions[previous_round_idx, :])
        my_cooperation = history.my_actions[previous_round_idx]
        total_cooperators = opponent_cooperators + (1 if my_cooperation else 0)
        cooperation_rate = total_cooperators / self.n_players
        if cooperation_rate >= self.cooperation_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_354(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Dynamically adjusts cooperation based on observed cooperation rates in the population,
    remaining rounds, and risk exposure. Cooperates in round 1, defects in final round,
    and uses probabilistic response to marginal cooperation rates in between.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        prev_round_idx = current_round - 1
        opponent_cooperators = np.sum(history.opponent_actions[prev_round_idx, :])
        self_cooperated = history.my_actions[prev_round_idx]
        total_cooperators = opponent_cooperators + (1 if self_cooperated else 0)
        cooperation_rate = total_cooperators / self.n_players
        threshold_rate = self.m / self.n_players
        if cooperation_rate >= threshold_rate * 1.2:
            return Action.C
        if cooperation_rate < threshold_rate * 0.8:
            return Action.D
        if threshold_rate > 0:
            cooperation_probability = cooperation_rate / threshold_rate
            cooperation_probability = max(0.0, min(1.0, cooperation_probability))
        else:
            cooperation_probability = 1.0
        if math.isclose(cooperation_rate, threshold_rate):
            return Action.C
        if random.random() < cooperation_probability:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_355(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances collective welfare pursuit with exploitation protection by adapting
    cooperation decisions based on observed cooperation rates relative to the
    threshold needed for success.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.required_rate = self.m / self.n_players
        self.prev_ccm = 1.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        last_round_cooperators = int(np.sum(history.opponent_actions[round_number - 1, :]))
        if self.m == 0:
            ccm = 1.0
        else:
            ccm = last_round_cooperators / self.m
        in_final_rounds = round_number >= self.n_rounds - 2
        if ccm >= 0.9:
            return Action.C
        elif ccm >= 0.6:
            trend_direction = ccm - self.prev_ccm
            if trend_direction >= 0:
                coop_probability = ccm / 1.5
                if random.random() < coop_probability:
                    self.prev_ccm = ccm
                    return Action.C
                else:
                    self.prev_ccm = ccm
                    return Action.D
            else:
                self.prev_ccm = ccm
                return Action.D
        elif in_final_rounds:
            self.prev_ccm = ccm
            return Action.D
        else:
            self.prev_ccm = ccm
            return Action.D

class Strategy_COLLECTIVE_356(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances collective welfare, individual security, and adaptive resilience by:
    1. Cooperating in round 1 to signal willingness
    2. Conditionally cooperating in middle rounds based on others' cooperation rate
    3. Defecting in final round unless threshold was met in previous round
    
    Uses probabilistic defection in near-threshold zones to avoid exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            cooperators_prev = int(sum(history.opponent_actions[round_num - 1, :]))
            if history.my_actions[round_num - 1]:
                cooperators_prev += 1
            if cooperators_prev >= self.m and cooperators_prev <= self.n // 2:
                return Action.C
            return Action.D
        opponents_cooperators = int(sum(history.opponent_actions[round_num - 1, :]))
        if history.my_actions[round_num - 1]:
            others_coop_count = opponents_cooperators
        else:
            others_coop_count = opponents_cooperators
        cooperation_rate = others_coop_count / (self.n - 1) if self.n > 1 else 0.0
        threshold_rate = (self.m - 1) / (self.n - 1) if self.n > 1 else 0.0
        tau = 1.0 / (2.0 * (self.n - 1)) if self.n > 1 else 0.0
        if cooperation_rate >= threshold_rate:
            return Action.C
        elif cooperation_rate >= threshold_rate - tau:
            if threshold_rate > 0:
                p_cooperate = cooperation_rate / threshold_rate
            else:
                p_cooperate = 1.0
            p_cooperate = max(0.0, min(1.0, p_cooperate))
            if random.random() < p_cooperate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_357(BaseStrategy):
    """
    Adaptive Threshold Assurance strategy for Collective Risk Dilemma.
    
    Balances individual security with collective welfare by:
    1. Cooperating in round 1 to establish cooperative intent
    2. Adapting to observable cooperation rates in middle rounds
    3. Defecting in the final round (with exception for critical threshold)
    
    Core decision logic responds to:
    - Whether threshold (m) was met in previous round
    - Cooperation rate relative to 50% threshold
    - Rounds remaining (endgame protection)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        cooperators_previous = int(sum(history.opponent_actions[-1, :]))
        if current_round == self.n_rounds - 1:
            if cooperators_previous == self.m - 1:
                return Action.C
            return Action.D
        cooperation_rate = cooperators_previous / self.n_players if self.n_players > 0 else 0.0
        rounds_remaining = self.n_rounds - current_round
        if cooperators_previous >= self.m:
            return Action.C
        if cooperators_previous == self.m - 1:
            return Action.C
        if cooperation_rate >= 0.5:
            return Action.C
        if rounds_remaining <= 2:
            return Action.D
        return Action.D

class Strategy_COLLECTIVE_358(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Monitoring cooperation levels across rounds
    2. Contributing proportionally to collective risk
    3. Reciprocating collective success
    4. Defecting when threshold is unreachable
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_coop_count = int(np.sum(history.opponent_actions[current_round - 1, :]))
        coop_rate = prev_coop_count / self.n_players
        threshold_rate = self.m / self.n_players
        if current_round < self.n_rounds - 1:
            if coop_rate >= threshold_rate:
                return Action.C
            if prev_coop_count >= self.m - 1:
                return Action.C
            elif prev_coop_count >= self.m - 2:
                buffer = self.m - 1 if self.n_players <= 4 else self.m - 2
                if prev_coop_count >= buffer:
                    rounds_remaining = self.n_rounds - current_round
                    if rounds_remaining > 3:
                        return Action.C
                    else:
                        return Action.D
                return Action.D
            else:
                return Action.D
        else:
            prev_coop_count = int(np.sum(history.opponent_actions[current_round - 1, :]))
            coop_rate = prev_coop_count / self.n_players
            threshold_rate = self.m / self.n_players
            if coop_rate >= threshold_rate:
                return Action.C
            my_coop_count = int(np.sum(history.my_actions[:current_round]))
            my_coop_ratio = my_coop_count / current_round if current_round > 0 else 0
            cooperation_threshold = 0.7
            if my_coop_ratio >= cooperation_threshold:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_359(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances collective success (reaching cooperation threshold m) with individual
    protection against exploitation. Cooperates initially, adapts based on observed
    group behavior, and employs terminal altruism in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.C
        previous_round_idx = current_round - 1
        opponent_actions_previous = history.opponent_actions[previous_round_idx, :]
        c_observed = int(np.sum(opponent_actions_previous))
        c_needed = self.m - 1
        rounds_remaining = self.n_rounds - current_round
        if self.n_players == 2 and self.m == 2:
            if c_observed >= 1:
                return Action.C
            else:
                return Action.D
        if c_observed >= c_needed:
            return Action.C
        elif c_observed == c_needed - 1:
            return Action.C
        elif rounds_remaining > 2:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_360(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by conditionally cooperating
    based on observed cooperation rates and remaining rounds. Cooperates generously early,
    reciprocates faithfully mid-game, and defects only when collective is substantially failing.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_idx = round_num - 1
        cooperators_prev = int(sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            cooperators_prev += 1
        cooperation_rate = cooperators_prev / self.n
        threshold_rate = self.m / self.n
        rounds_remaining = self.r - round_num
        if cooperators_prev >= self.m:
            return Action.C
        if rounds_remaining == 0:
            return Action.D
        if round_num <= 2:
            if cooperation_rate >= 0.2:
                return Action.C
            else:
                return Action.D
        if rounds_remaining == 1:
            if round_num >= 2:
                prev_prev_idx = round_num - 2
                cooperators_prev_prev = int(sum(history.opponent_actions[prev_prev_idx, :]))
                if history.my_actions[prev_prev_idx]:
                    cooperators_prev_prev += 1
                cooperation_rate_prev_prev = cooperators_prev_prev / self.n
                threshold_rate_check = 0.6 * threshold_rate
                if cooperation_rate_prev_prev >= threshold_rate_check:
                    return Action.C
            return Action.D
        if threshold_rate > 0:
            deficit = cooperation_rate - threshold_rate
            deficit_ratio = deficit / threshold_rate
        else:
            deficit_ratio = -1.0
        if round_num <= 3:
            required_deficit_ratio = -0.3
        elif round_num <= self.r - 2:
            required_deficit_ratio = -0.15
        else:
            required_deficit_ratio = -0.1
        if deficit_ratio >= required_deficit_ratio:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_361(BaseStrategy):
    """
    Adaptive Threshold Reciprocity (ATR) Strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective benefit maximization by:
    1. Recognizing universal defection yields payoff 1, universal cooperation yields k > 1
    2. Exploiting asymmetry where defectors benefit when others cooperate
    3. Using dynamic threshold adjustment to maintain cooperative coalitions
    
    Core decision rules:
    - Round 1: Cooperate if k > 2, or if k == 2 and m <= n/2
    - Final round: Cooperate only if previous round achieved threshold
    - Other rounds: Adapt based on cooperation rate relative to threshold bounds
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_lower = (self.m - 1) / self.n_players
        self.threshold_upper = (self.m - 0.5) / self.n_players
        self.coop_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return self._round_1_decision()
        if current_round == self.n_rounds - 1:
            return self._final_round_decision(history)
        return self._adaptive_decision(history, current_round)

    def _round_1_decision(self) -> Action:
        """
        Round 1 initialization:
        - Cooperate if k > 2 (strong reward justifies risk)
        - Cooperate if k == 2 and m <= n/2 (moderate reward with achievable threshold)
        - Otherwise defect
        """
        if self.k > 2:
            return Action.C
        elif self.k == 2 and self.m <= self.n_players / 2:
            return Action.C
        else:
            return Action.D

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """
        Final round logic:
        - Cooperate if previous round achieved m or more cooperators
        - Defect otherwise (end-game defection, no future punishment)
        """
        if history is None:
            return Action.D
        prev_round_idx = self.n_rounds - 2
        cooperators_prev = sum(history.opponent_actions[prev_round_idx, :])
        my_prev_action = history.my_actions[prev_round_idx]
        if my_prev_action:
            cooperators_prev += 1
        if cooperators_prev >= self.m:
            return Action.C
        else:
            return Action.D

    def _adaptive_decision(self, history: PlayerHistory, current_round: int) -> Action:
        """
        Intermediate rounds: Adapt based on cooperation rate in previous round.
        
        - If coop_rate >= threshold_upper: Cooperate
        - If coop_rate < threshold_lower: Defect (or reset signal)
        - Otherwise: Probabilistic bridging
        """
        if history is None:
            return Action.D
        prev_round_idx = current_round - 1
        cooperators_prev = sum(history.opponent_actions[prev_round_idx, :])
        my_prev_action = history.my_actions[prev_round_idx]
        if my_prev_action:
            cooperators_prev += 1
        coop_rate = cooperators_prev / self.n_players
        self._update_coop_history(coop_rate)
        if self.m > self.n_players / 2:
            return Action.D
        if self.m <= 2:
            return Action.C
        if self._oscillation_detected():
            defection_count = self._count_recent_defection_rounds(history, current_round)
            if defection_count >= 2:
                return Action.D
        if coop_rate >= self.threshold_upper:
            return Action.C
        elif coop_rate < self.threshold_lower:
            return Action.D
        else:
            probability = (coop_rate - self.threshold_lower) / (0.5 / self.n_players)
            probability = min(probability, 1.0)
            probability = max(probability, 0.0)
            if random.random() < probability:
                return Action.C
            else:
                return Action.D

    def _update_coop_history(self, coop_rate: float) -> None:
        """Track cooperation rates for oscillation detection."""
        self.coop_history.append(coop_rate)
        if len(self.coop_history) > 3:
            self.coop_history.pop(0)

    def _oscillation_detected(self) -> bool:
        """
        Detect oscillation: large swings in cooperation rate between recent rounds.
        Returns True if abs difference between last two rates > 0.4.
        """
        if len(self.coop_history) < 2:
            return False
        recent_oscillation = abs(self.coop_history[-1] - self.coop_history[-2]) > 0.4
        return recent_oscillation

    def _count_recent_defection_rounds(self, history: PlayerHistory, current_round: int) -> int:
        """
        Count rounds in last 3 rounds where fewer than m players cooperated.
        """
        defection_count = 0
        start_round = max(0, current_round - 3)
        for round_idx in range(start_round, current_round):
            cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators < self.m:
                defection_count += 1
        return defection_count

class Strategy_COLLECTIVE_362(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective benefit by:
    1. Recognizing the mutual gain threshold (m cooperators)
    2. Minimizing free-riding vulnerability through conditional cooperation
    3. Graceful degradation with recovery attempts when cooperation fails
    
    Uses empirical cooperation rates to estimate expected cooperators and decide
    whether to cooperate based on likelihood of reaching the threshold m.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_count = 0
        self.last_round_had_success = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            threshold_estimate = m / n
            if m <= n / 2:
                return Action.C
            else:
                return Action.D
        total_rounds_observed = current_round
        if total_rounds_observed > 0:
            observed_cooperation_rate = self.cooperation_count / (n * total_rounds_observed)
        else:
            observed_cooperation_rate = m / n
        expected_cooperators = round(n * observed_cooperation_rate)
        if expected_cooperators >= m:
            action = Action.C
        elif expected_cooperators == m - 1 and observed_cooperation_rate > 0 and self.last_round_had_success:
            action = Action.C
        else:
            action = Action.D
        round_idx = current_round - 1
        if round_idx >= 0 and round_idx < len(history.opponent_actions):
            cooperators_this_round = int(np.sum(history.opponent_actions[round_idx, :]))
            self.cooperation_count += cooperators_this_round
            self.last_round_had_success = cooperators_this_round >= m
        return action

class Strategy_COLLECTIVE_363(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by dynamically adapting
    cooperation decisions based on observed historical cooperation rates. Cooperates
    when the threshold m is expected to be met, defects otherwise.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            if self.n >= 2 * self.m - 1:
                return Action.C
            else:
                return Action.D
        cooperation_rate = self._calculate_cooperation_rate(history, current_round)
        expected_others = cooperation_rate * (self.n - 1)
        if current_round >= self.r - 2:
            expected_others = expected_others * 0.7
        if cooperation_rate > 0 and cooperation_rate < 1.0 / self.m:
            return Action.D
        if expected_others + 1 >= self.m:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the empirical cooperation rate from previous rounds.
        
        cooperation_rate = (total cooperators in rounds 0 to current_round-1) / (n * current_round)
        """
        if current_round <= 0:
            return 0.5
        total_coop_actions = 0
        for round_idx in range(current_round):
            total_coop_actions += np.sum(history.opponent_actions[round_idx, :])
        for round_idx in range(current_round):
            if history.my_actions[round_idx]:
                total_coop_actions += 1
        total_possible = self.n * current_round
        if total_possible == 0:
            return 0.5
        cooperation_rate = total_coop_actions / total_possible
        return cooperation_rate

class Strategy_COLLECTIVE_364(BaseStrategy):
    """
    Adaptive Threshold Convergence strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare through three phases:
    1. Exploration: Probe cooperation landscape, start cooperatively
    2. Adaptation: Track patterns, adapt to sustainability of cooperation
    3. Finalization: Minimize regret based on established trajectory
    
    Includes special handling for perfect cooperation, mutual defection traps,
    high variance, and extreme threshold values.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_ratio = self.m / self.n_players
        self.cooperation_history = []
        self.own_action_history = []
        self.perfect_coop_count = 0
        self.mutual_defect_count = 0
        self.rounds_since_defect_reset = 0

    def _get_cooperation_rate(self, round_idx: int) -> float:
        """Calculate cooperation rate in a given round (0-indexed)."""
        if round_idx < 0 or round_idx >= len(self.cooperation_history):
            return 0.0
        return self.cooperation_history[round_idx]

    def _get_recent_cooperation_avg(self, history: PlayerHistory, lookback: int) -> float:
        """Calculate mean cooperation rate over last lookback rounds."""
        if len(self.cooperation_history) == 0:
            return 0.0
        start_idx = max(0, len(self.cooperation_history) - lookback)
        recent = self.cooperation_history[start_idx:]
        if not recent:
            return 0.0
        return float(np.mean(recent))

    def _get_cooperation_std(self, lookback: int) -> float:
        """Calculate standard deviation of cooperation rate over last lookback rounds."""
        if len(self.cooperation_history) < lookback:
            return 0.0
        recent = self.cooperation_history[-lookback:]
        if len(recent) < 2:
            return 0.0
        return float(np.std(recent))

    def _get_historical_cooperation_avg(self) -> float:
        """Calculate mean cooperation rate over entire game so far."""
        if len(self.cooperation_history) == 0:
            return 0.0
        return float(np.mean(self.cooperation_history))

    def _update_cooperation_history(self, history: PlayerHistory) -> None:
        """Update cooperation history based on opponent actions in latest round."""
        if history is None or len(history.opponent_actions) == 0:
            return
        latest_round_actions = history.opponent_actions[-1, :]
        cooperators = int(np.sum(latest_round_actions))
        cooperation_rate = cooperators / self.n_players
        self.cooperation_history.append(cooperation_rate)

    def _handle_perfect_cooperation(self) -> bool:
        """Check for perfect cooperation emerging (2 consecutive rounds of 100% cooperation)."""
        if len(self.cooperation_history) < 2:
            return False
        if self.cooperation_history[-1] >= 1.0 and self.cooperation_history[-2] >= 1.0:
            self.perfect_coop_count += 1
            return self.perfect_coop_count >= 2
        self.perfect_coop_count = 0
        return False

    def _handle_mutual_defection(self) -> bool:
        """Check for mutual defection trap (2 consecutive rounds of 0% cooperation)."""
        if len(self.cooperation_history) < 2:
            return False
        if self.cooperation_history[-1] <= 0.0 and self.cooperation_history[-2] <= 0.0:
            self.mutual_defect_count += 1
            self.rounds_since_defect_reset += 1
            return True
        self.mutual_defect_count = 0
        self.rounds_since_defect_reset = 0
        return False

    def _handle_high_variance(self) -> bool:
        """Check for high variance (oscillating cooperation > 0.25 std dev)."""
        if len(self.cooperation_history) < 3:
            return False
        std = self._get_cooperation_std(3)
        return std > 0.25

    def _get_adjusted_threshold(self) -> float:
        """Get adjusted success threshold based on m value."""
        if self.m / self.n_players > 0.67:
            return self.threshold_ratio + 0.25
        elif self.m / self.n_players <= 0.3:
            return self.threshold_ratio
        else:
            return self.threshold_ratio

    def _phase_1_exploration(self, state: GameState, history: PlayerHistory) -> Action:
        """Phase 1: Exploration (rounds 0 to ceil(r/3) - 1)."""
        if state.round_number == 0:
            return Action.C
        cooperation_rate = self._get_cooperation_rate(state.round_number - 1)
        threshold_ratio = self.threshold_ratio
        if cooperation_rate >= threshold_ratio:
            return Action.C
        elif cooperation_rate >= threshold_ratio * 0.75:
            return Action.C if random.random() < 0.8 else Action.D
        else:
            return Action.D

    def _phase_2_adaptation(self, state: GameState, history: PlayerHistory) -> Action:
        """Phase 2: Adaptation (rounds ceil(r/3) to floor(2r/3) - 1)."""
        recent_cooperation_rate = self._get_recent_cooperation_avg(history, 3)
        threshold_ratio = self.threshold_ratio
        success_threshold = threshold_ratio + 0.15
        if recent_cooperation_rate >= success_threshold:
            return Action.C
        elif recent_cooperation_rate >= threshold_ratio:
            if len(self.own_action_history) > 0 and self.own_action_history[-1] and (self._get_cooperation_rate(state.round_number - 1) >= threshold_ratio):
                return Action.C
            elif state.round_number > 0 and len(self.cooperation_history) > 0:
                cooperators_last = int(self._get_cooperation_rate(state.round_number - 1) * self.n_players)
                if cooperators_last == self.m:
                    return Action.C
            return Action.D
        elif recent_cooperation_rate >= threshold_ratio * 0.5:
            return Action.D
        else:
            return Action.D

    def _phase_3_finalization(self, state: GameState, history: PlayerHistory) -> Action:
        """Phase 3: Finalization (rounds floor(2r/3) to r - 1)."""
        remaining_rounds = self.n_rounds - state.round_number
        threshold_ratio = self.threshold_ratio
        if remaining_rounds <= 2:
            historical_cooperation_rate = self._get_historical_cooperation_avg()
            if historical_cooperation_rate >= threshold_ratio:
                return Action.C
            else:
                return Action.D
        else:
            recent_cooperation_rate = self._get_recent_cooperation_avg(history, 4)
            success_threshold = threshold_ratio + 0.2
            if recent_cooperation_rate >= success_threshold:
                return Action.C
            else:
                return Action.D

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            self._update_cooperation_history(history)
        if self._handle_perfect_cooperation():
            return Action.C
        if self._handle_mutual_defection():
            if self.rounds_since_defect_reset <= 3:
                return Action.C if random.random() < 0.15 else Action.D
            else:
                self.mutual_defect_count = 0
                self.rounds_since_defect_reset = 0
        if self._handle_high_variance():
            return Action.D if random.random() > 0.2 else Action.C
        exploration_cutoff = math.ceil(self.n_rounds / 3)
        finalization_cutoff = math.floor(2 * self.n_rounds / 3)
        if state.round_number < exploration_cutoff:
            action = self._phase_1_exploration(state, history)
        elif state.round_number < finalization_cutoff:
            action = self._phase_2_adaptation(state, history)
        else:
            action = self._phase_3_finalization(state, history)
        self.own_action_history.append(action == Action.C)
        return action

class Strategy_COLLECTIVE_365(BaseStrategy):
    """
    Adaptive Threshold Trust strategy for Collective Risk Dilemma.
    
    Maximizes collective welfare while maintaining individual resilience against exploitation.
    Operates on conditional cooperation with adaptive risk assessment:
    - Round 1: Cooperate (information gathering)
    - Rounds 2 to r-1: Cooperate if threshold was met last round, else defect
    - Round r: Defect (no future consequences)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        m = self.game_description.m
        if state.round_number == 0:
            return Action.C
        if state.round_number == r - 1:
            return Action.D
        prev_round_index = state.round_number - 1
        opponent_cooperators = np.sum(history.opponent_actions[prev_round_index, :])
        own_prev_action = history.my_actions[prev_round_index]
        total_cooperators = opponent_cooperators + (1 if own_prev_action else 0)
        cooperation_rate = total_cooperators / n
        threshold_rate = m / n
        if cooperation_rate >= threshold_rate:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_366(BaseStrategy):
    """
    Adaptive Threshold Commitment strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by monitoring progress
    toward the cooperation threshold, adapting contributions based on defection patterns,
    and protecting against exploitation while maintaining cooperation potential.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_proportion = self.m / self.n
        self.defection_tolerance = 0.6
        self.persistence_window = min(5, self.r - 1)
        if self.n <= 3:
            self.defection_tolerance = 0.7
            self.margin_threshold = self.threshold_proportion - 0.15
        else:
            self.margin_threshold = (self.m - 1) / self.n
        if self.m > self.n / 2:
            self.cooperation_threshold_final = 0.6
        else:
            self.cooperation_threshold_final = self.threshold_proportion
        if self.k > 3:
            self.defection_tolerance = 0.7
        elif self.k <= 1.5:
            self.defection_tolerance = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        if t == 0:
            return Action.C
        prev_round_idx = t - 1
        prev_cooperators = int(sum(history.opponent_actions[prev_round_idx, :]))
        prev_cooperation_rate = prev_cooperators / self.n
        if t == self.r - 1:
            if prev_cooperation_rate >= self.cooperation_threshold_final:
                return Action.C
            elif prev_cooperation_rate >= self.margin_threshold:
                return Action.C
            else:
                return Action.D
        rounds_threshold_met = 0
        observed_defections = 0
        for round_idx in range(t):
            round_cooperators = int(sum(history.opponent_actions[round_idx, :]))
            if round_cooperators >= self.m:
                rounds_threshold_met += 1
            observed_defections += self.n - round_cooperators
        success_rate = rounds_threshold_met / t if t > 0 else 0.0
        if prev_cooperation_rate >= self.threshold_proportion:
            return Action.C
        elif success_rate >= 0.5:
            return Action.C
        else:
            defection_window = min(self.persistence_window, t)
            defectors_recent = 0
            for round_idx in range(t - defection_window, t):
                round_cooperators = int(sum(history.opponent_actions[round_idx, :]))
                defectors_recent += self.n - round_cooperators
            defection_concentration = defectors_recent / (defection_window * self.n) if defection_window > 0 else 0.0
            if defection_concentration > self.defection_tolerance and observed_defections > self.n * 0.4:
                return Action.D
            elif prev_cooperation_rate >= self.margin_threshold:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_367(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy for Collective Risk Dilemma.
    
    Core approach: Bootstrap cooperation in round 1, then adaptively cooperate based on
    observed cooperation rates relative to an adjusted threshold (m/n + risk premium).
    Defect in late game if threshold not met, defect immediately if round 1 sees zero cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.risk_premium = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        cooperators_previous = int(sum(history.opponent_actions[round_number - 1, :]))
        cooperation_rate = cooperators_previous / self.n_players
        threshold = self.m / self.n_players + self.risk_premium
        if round_number == self.n_rounds - 1:
            if cooperation_rate >= self.m / self.n_players:
                return Action.C
            else:
                return Action.D
        if round_number == 1:
            if cooperators_previous == 0:
                return Action.D
            else:
                return Action.C
        mid_game_threshold = 2 * self.n_rounds / 3
        if cooperation_rate >= threshold:
            return Action.C
        if round_number > mid_game_threshold:
            return Action.D
        if cooperation_rate > self.m / self.n_players:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_368(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATC) for Collective Risk Dilemma.
    
    Balances individual security with collective benefit by:
    1. Cooperating in round 1 to establish baseline and gather information
    2. Defecting in final round (no future reciprocation)
    3. In middle rounds, adapting based on cooperation rates:
       - Cooperate if threshold is achievable or momentum is strong
       - Defect if cooperation is futile
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        last_round_actions = history.opponent_actions[-1, :]
        cooperators_last = int(np.sum(last_round_actions))
        n = self.game_description.n_players
        m = self.game_description.m
        if cooperators_last >= m:
            return Action.C
        if cooperators_last == m - 1:
            return Action.C
        min_rate = m / n
        coop_rate = cooperators_last / n
        if coop_rate >= min_rate * 1.5:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_369(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Cooperating initially to establish cooperation baseline
    2. Adapting middle-game decisions based on observed cooperation rates
    3. Using probabilistic hedging near the threshold to avoid exploitation
    4. Making final-round decisions based on historical cooperation rates
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        observed_rate = self._calculate_observed_cooperation_rate(history, round_num)
        estimated_others_cooperating = self._estimate_others_cooperating(observed_rate)
        if round_num == self.r - 1:
            return self._decide_final_round(observed_rate)
        return self._decide_middle_game(estimated_others_cooperating)

    def _calculate_observed_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate the historical cooperation rate across all players in all previous rounds.
        Returns: cooperation_rate in [0, 1]
        """
        my_cooperations = np.sum(history.my_actions[:round_num])
        opponent_cooperations = np.sum(history.opponent_actions[:round_num, :])
        total_cooperations = my_cooperations + opponent_cooperations
        total_decisions = round_num * self.n
        if total_decisions == 0:
            return 0.0
        return float(total_cooperations) / float(total_decisions)

    def _estimate_others_cooperating(self, observed_rate: float) -> int:
        """
        Estimate how many of the other (n-1) players will cooperate this round
        based on observed historical cooperation rate.
        Returns: estimated number of other players cooperating
        """
        estimated = round(observed_rate * (self.n - 1))
        return max(0, min(estimated, self.n - 1))

    def _decide_middle_game(self, estimated_others: int) -> Action:
        """
        Make decision in middle rounds (rounds 1 to r-2) based on estimated
        cooperation from other players.
        """
        my_contribution_would_reach_m = estimated_others + 1 >= self.m
        others_would_reach_m = estimated_others >= self.m
        near_threshold_from_above = estimated_others == self.m - 1
        if my_contribution_would_reach_m:
            return Action.C
        elif others_would_reach_m:
            return Action.C if random.random() < 0.9 else Action.D
        elif near_threshold_from_above:
            return Action.C if random.random() < 0.7 else Action.D
        else:
            return Action.D

    def _decide_final_round(self, observed_rate: float) -> Action:
        """
        Make decision in final round (round r-1) based on historical cooperation rate.
        If the observed cooperation rate suggests threshold is achievable, cooperate.
        Otherwise, defect to preserve final endowment.
        """
        threshold_rate = float(self.m) / float(self.n)
        if observed_rate >= threshold_rate:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_370(BaseStrategy):
    """
    Adaptive Threshold Insurance strategy for Collective Risk Dilemma.
    
    Balances three imperatives:
    1. Enable collective success when cooperation is achievable
    2. Protect against exploitation by free-riders
    3. Minimize wasted contributions to impossible thresholds
    
    Uses adaptive trend-detection and threshold tolerance to decide whether
    to contribute toward closing gaps in cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_tolerance = math.ceil(self.n_players / 4)
        self.adaptive_factor = 1.2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        cooperators_last_round = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if current_round == self.n_rounds - 1:
            if cooperators_last_round >= self.m:
                return Action.C
            else:
                return Action.D
        cooperation_rate = cooperators_last_round / self.n_players
        if cooperators_last_round >= self.m:
            return Action.C
        deficit = self.m - cooperators_last_round
        if deficit > 0 and deficit <= self.threshold_tolerance:
            min_threshold_rate = self.m / self.n_players * self.adaptive_factor
            if cooperation_rate >= min_threshold_rate:
                return Action.C
            else:
                return Action.D
        if deficit > self.threshold_tolerance:
            return Action.D
        return Action.D

class Strategy_COLLECTIVE_371(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Dynamically adjusts cooperation based on historical cooperation rates and
    conditional reciprocity, balancing individual security with collective welfare.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.n_rounds - 1:
            return self._final_round_decision(history)
        return self._adaptive_round_decision(history)

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """
        Final round logic: cooperate only if demonstrated cooperation exceeds threshold.
        """
        coop_rate = self._calculate_cooperation_rate(history)
        threshold = self.m / self.n_players + 0.1
        if coop_rate >= threshold:
            return Action.C
        return Action.D

    def _adaptive_round_decision(self, history: PlayerHistory) -> Action:
        """
        Rounds 2 to r-1: Adaptive cooperation based on expected cooperators.
        """
        round_num = len(history.my_actions)
        coop_rate = self._calculate_cooperation_rate(history)
        if round_num == 1:
            observed_coop = np.sum(history.opponent_actions[0, :])
            if history.my_actions[0]:
                observed_coop += 1
            expected_coop_count = float(observed_coop)
        else:
            expected_coop_count = coop_rate * self.n_players
        return self._threshold_decision(expected_coop_count)

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        """
        Calculate the historical cooperation rate across all previous rounds.
        Returns the fraction of cooperation observed.
        """
        n_completed_rounds = len(history.my_actions)
        if n_completed_rounds == 0:
            return 0.0
        total_actions = n_completed_rounds * self.n_players
        if total_actions == 0:
            return 0.0
        total_cooperators = np.sum(history.my_actions) + np.sum(history.opponent_actions)
        coop_rate = total_cooperators / total_actions
        return coop_rate

    def _threshold_decision(self, expected_coop_count: float) -> Action:
        """
        Make cooperation decision based on expected cooperator count.
        
        Uses tiered thresholds:
        - Cooperate if expected >= m - 0.5
        - Probabilistic if m - 1.5 <= expected < m - 0.5
        - Defect otherwise
        """
        upper_threshold = self.m - 0.5
        lower_threshold = self.m - 1.5
        if expected_coop_count >= upper_threshold:
            return Action.C
        elif expected_coop_count >= lower_threshold:
            transition_value = expected_coop_count - (self.m - 2)
            probability = max(0.0, min(1.0, transition_value))
            if random.random() < probability:
                return Action.C
            return Action.D
        else:
            if self._check_coordination_failure(expected_coop_count):
                return Action.D
            return Action.D

    def _check_coordination_failure(self, expected_coop_count: float) -> bool:
        """
        Detect if coordination has failed (cannot reliably meet threshold).
        Returns True if cooperation is unviably low.
        """
        return expected_coop_count < self.m - 1

class Strategy_COLLECTIVE_372(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances collective welfare, self-protection, and robustness by:
    1. Defecting in round 1 to gather information
    2. During calibration (rounds 2-3), cooperating if observed cooperation rate suggests threshold is achievable
    3. In execution phase, adaptively cooperating when the deficit (m - current_cooperators) is small relative to remaining rounds
    4. Free-riding when threshold is already met
    5. In final round, cooperating only if we can be the tiebreaker
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[round_number - 1, :]))
        rounds_remaining = self.n_rounds - round_number
        if round_number > 0:
            total_cooperations = int(np.sum(history.opponent_actions[0:round_number, :]))
            total_observations = round_number * (self.n_players - 1)
            observed_cooperation_rate = total_cooperations / max(1, total_observations)
        else:
            observed_cooperation_rate = 0.0
        if round_number <= 2 and round_number < self.n_rounds - 1:
            threshold_rate = (self.m - 1) / self.n_players
            if observed_cooperation_rate > threshold_rate:
                return Action.C
            else:
                return Action.D
        if round_number == self.n_rounds - 1:
            if cooperators_last_round >= self.m - 1:
                return Action.C
            else:
                return Action.D
        if cooperators_last_round >= self.m:
            return Action.D
        deficit = self.m - cooperators_last_round
        if deficit <= rounds_remaining - 1:
            if observed_cooperation_rate > 0.3:
                return Action.C
            else:
                return Action.D
        elif deficit <= 2:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_373(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Seeding cooperation in round 1
    2. Cooperating when observed cooperation rate meets/exceeds threshold m/n
    3. Defecting when threshold is not met to avoid wasting endowment
    4. Maintaining consistency through end-game to support collective resilience
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_rate = self.m / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        previous_round_idx = current_round - 1
        previous_round_opponent_actions = history.opponent_actions[previous_round_idx, :]
        previous_round_my_action = history.my_actions[previous_round_idx]
        opponent_cooperators = np.sum(previous_round_opponent_actions)
        my_previous_action = int(previous_round_my_action)
        total_previous_cooperators = opponent_cooperators + my_previous_action
        cooperation_rate = total_previous_cooperators / self.n_players
        if cooperation_rate >= self.threshold_rate:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_374(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances individual rationality with collective value creation by:
    1. Signaling cooperative intent in round 1
    2. Dynamically adjusting based on empirical cooperation rates
    3. Protecting against free-riding when threshold fails
    4. Applying endgame logic in final round
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if self.n == self.m:
            return Action.C
        cooperation_rate = self._calculate_cooperation_rate(history, round_num)
        other_cooperators_last_round = int(sum(history.opponent_actions[-1, :]))
        my_past_cooperations = int(sum(history.my_actions[:round_num]))
        if round_num == self.r - 1:
            return self._final_round_decision(cooperation_rate, other_cooperators_last_round)
        return self._adaptive_round_decision(cooperation_rate, other_cooperators_last_round, my_past_cooperations, round_num)

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """Calculate proportion of rounds where threshold was met."""
        if round_num == 0:
            return 0.0
        threshold_met_count = 0
        for r in range(round_num):
            cooperators_in_round = int(sum(history.opponent_actions[r, :])) + int(history.my_actions[r])
            if cooperators_in_round >= self.m:
                threshold_met_count += 1
        return threshold_met_count / round_num

    def _final_round_decision(self, cooperation_rate: float, other_cooperators_last_round: int) -> Action:
        """Logic for final round (round r)."""
        if other_cooperators_last_round >= self.m - 1:
            return Action.C
        if cooperation_rate >= 0.6:
            return Action.C
        return Action.D

    def _adaptive_round_decision(self, cooperation_rate: float, other_cooperators_last_round: int, my_past_cooperations: int, round_num: int) -> Action:
        """Logic for rounds 2 to r-1."""
        target_rate = self.m / self.n * 0.8
        if cooperation_rate >= target_rate:
            cooperation_threshold = self.m - 1
            if other_cooperators_last_round >= cooperation_threshold:
                return Action.C
            return Action.D
        target_rate_medium = self.m / self.n * 0.5
        if cooperation_rate >= target_rate_medium:
            deficit = self.m - other_cooperators_last_round
            if deficit <= 1:
                return Action.C
            if deficit > 1 and my_past_cooperations > self.r / 3:
                return Action.C
            return Action.D
        total_expected_cooperators = cooperation_rate * self.n
        if total_expected_cooperators < self.m - 1:
            return Action.D
        rounds_remaining = self.r - round_num
        total_rounds = self.r
        if random.random() < rounds_remaining / total_rounds:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_375(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATC)
    
    Balances individual rationality with collective welfare by cooperating when
    the expected benefit from collective success (trust-weighted) outweighs the
    individual cost. Uses a dynamic trust score based on observed cooperation rates.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.cooperation_threshold = 1.0 / self.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            initial_trust = (self.m - 1) / (self.n - 1)
            if initial_trust >= self.cooperation_threshold:
                return Action.C
            else:
                return Action.D
        total_cooperators = 0
        for round_idx in range(round_num):
            round_cooperators = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += round_cooperators
        own_cooperators = np.sum(history.my_actions[:round_num])
        total_cooperators += own_cooperators
        total_actions = self.n * round_num
        if total_actions == 0:
            trust_score = 0.0
        else:
            trust_score = total_cooperators / total_actions
        if trust_score >= self.cooperation_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_376(BaseStrategy):
    """
    Adaptive Threshold Sentinel: A collective risk dilemma strategy that balances
    collective welfare maximization, self-protection, and robustness through dynamic
    adaptation to opponent behavior patterns.
    
    Key mechanics:
    - Round 1: Cooperate (bootstrap/signal good faith)
    - Rounds 2 to r-1: Adapt based on threshold achievement, marginal recovery potential,
      and historical cooperation trends
    - Final round: Defect unless perfect cooperation achieved (credible end-game)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        cooperators_last_round = int(sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            cooperators_last_round += 1
        rounds_played = current_round
        total_cooperators = int(np.sum(history.opponent_actions[:current_round, :]))
        if history.my_actions[current_round - 1]:
            total_cooperators += 1
        total_player_rounds = self.n_players * rounds_played
        avg_cooperation_rate = total_cooperators / total_player_rounds if total_player_rounds > 0 else 0.0
        if current_round == self.n_rounds - 1:
            if avg_cooperation_rate >= 1.0:
                return Action.C
            else:
                return Action.D
        if cooperators_last_round >= self.m:
            return Action.C
        if cooperators_last_round < self.m:
            coop_needed = self.m - cooperators_last_round
            recovery_threshold = math.ceil(self.n_players * 0.4)
            if coop_needed <= recovery_threshold:
                return Action.C
            else:
                return Action.D
        threshold_rate = self.m / self.n_players
        if avg_cooperation_rate >= threshold_rate:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_377(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances collective survival (ensuring threshold m is met) with individual prudence
    (avoiding unilateral sacrifice). Uses optimistic early cooperation followed by
    evidence-based momentum detection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.adaptive_threshold_round = math.ceil(game_description.n_rounds * (game_description.m / game_description.n_players))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None:
            return Action.C
        cooperators_last_round = int(np.sum(history.opponent_actions[-1, :]))
        if state.round_number <= self.adaptive_threshold_round:
            return Action.C
        if cooperators_last_round >= self.game_description.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_378(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective benefit by:
    1. Starting with cooperation to signal good intent
    2. Reciprocating cooperation when threshold is met or nearly met
    3. Defecting only when cooperation seems futile
    4. Maintaining successful coalitions even in final round
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.epsilon = 1.0 / (2.0 * self.n)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        prev_cooperators = int(sum(history.opponent_actions[prev_round_idx, :]))
        cooperation_rate = prev_cooperators / self.n
        threshold_rate = self.m / self.n
        if current_round == self.r - 1:
            return self._final_round_decision(history, cooperation_rate, threshold_rate)
        return self._midgame_decision(cooperation_rate, threshold_rate)

    def _midgame_decision(self, cooperation_rate: float, threshold_rate: float) -> Action:
        """Decision logic for rounds 2 through r-1"""
        threshold_adjustment = 0.1 if self.m == 2 else 0.0
        adjusted_threshold = max(0.0, threshold_rate - threshold_adjustment)
        cooperation_boost = 0.05 if self.k > 3.0 else 0.0
        if cooperation_rate >= threshold_rate - self.epsilon:
            return Action.C
        if cooperation_rate >= 0.5:
            return Action.C
        if cooperation_rate >= threshold_rate - 2.0 * self.epsilon:
            return Action.C
        return Action.D

    def _final_round_decision(self, history: PlayerHistory, cooperation_rate: float, threshold_rate: float) -> Action:
        """Decision logic for final round"""
        if cooperation_rate >= threshold_rate:
            return Action.C
        accumulated_threshold_rounds = 0
        for round_idx in range(self.r - 1):
            round_cooperators = int(sum(history.opponent_actions[round_idx, :]))
            if round_cooperators >= self.m:
                accumulated_threshold_rounds += 1
        if accumulated_threshold_rounds >= 1:
            return Action.C
        if self.m == 2 and self.n <= 4:
            return Action.C
        if self.m == self.n:
            for round_idx in range(self.r - 1):
                round_cooperators = int(sum(history.opponent_actions[round_idx, :]))
                if round_cooperators < self.n - 1:
                    return Action.D
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_379(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances collective welfare, personal security, and adaptive robustness by:
    - Cooperating in round 1 to establish good faith
    - Defecting in the last round (backward induction)
    - Using binomial probability to estimate likelihood of reaching threshold
    - Maintaining an "earned defection budget" for strategic defections when cooperation rates drop
    - Prioritizing threshold success over individual payoff maximization
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.max_defections_available = min(self.n_rounds / 4.0, 2.0)

    def _binomial_probability_threshold_met(self, p_coop: float, trials: int, successes_needed: int) -> float:
        """
        Calculate probability that at least successes_needed cooperators occur
        in trials independent trials with probability p_coop per trial.
        Uses normal approximation for efficiency.
        """
        if trials <= 0 or successes_needed <= 0:
            return 0.0
        mean = trials * p_coop
        variance = trials * p_coop * (1.0 - p_coop)
        if variance < 1e-10:
            return 1.0 if mean >= successes_needed else 0.0
        std_dev = math.sqrt(variance)
        z_score = (successes_needed - 0.5 - mean) / std_dev
        cdf_value = 0.5 * (1.0 + math.erf(z_score / math.sqrt(2.0)))
        return max(0.0, min(1.0, 1.0 - cdf_value))

    def _calculate_observed_cooperation_rate(self, history: PlayerHistory) -> float:
        """
        Calculate the observed cooperation rate from all players in all past rounds.
        """
        round_number = history.my_actions.shape[0]
        if round_number == 0:
            return 0.0
        my_cooperations = int(np.sum(history.my_actions))
        opponent_cooperations = int(np.sum(history.opponent_actions))
        total_cooperations = my_cooperations + opponent_cooperations
        total_actions = self.n_players * round_number
        if total_actions == 0:
            return 0.0
        return total_cooperations / total_actions

    def _count_own_defections(self, history: PlayerHistory) -> int:
        """Count how many times this player has defected so far."""
        return int(np.sum(~history.my_actions))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        observed_coop_rate = self._calculate_observed_cooperation_rate(history)
        assume_cooperation_rate = observed_coop_rate
        cooperators_needed = max(self.m - 1, 0)
        prob_threshold_met = self._binomial_probability_threshold_met(assume_cooperation_rate, self.n_players - 1, cooperators_needed)
        defections_used = self._count_own_defections(history)
        defections_available = self.max_defections_available
        if prob_threshold_met < 0.4:
            return Action.D
        threshold_rate = self.m / self.n_players
        if observed_coop_rate < threshold_rate - 0.15:
            if defections_used < defections_available:
                return Action.D
            else:
                return Action.C
        if observed_coop_rate >= threshold_rate:
            return Action.C
        return Action.C

class Strategy_COLLECTIVE_380(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances individual security with collective benefit by learning the cooperation
    landscape and dynamically adjusting participation based on demonstrated collective
    capacity. Cooperates in round 1, adapts in middle rounds based on historical
    cooperation rates, and defects in final round (unless perfect cooperation history).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            cooperation_rate = self._calculate_cooperation_rate(history)
            if cooperation_rate == 1.0:
                return Action.C
            else:
                return Action.D
        return self._adaptive_decision(history, current_round)

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate historical cooperation rate across all players and rounds."""
        if history is None or len(history.my_actions) == 0:
            return 0.0
        rounds_completed = len(history.my_actions)
        my_cooperations = np.sum(history.my_actions)
        opponent_cooperations = np.sum(history.opponent_actions)
        total_cooperators = my_cooperations + opponent_cooperations
        total_actions = rounds_completed * self.n_players
        if total_actions == 0:
            return 0.0
        return total_cooperators / total_actions

    def _get_smoothed_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """Apply 2-round moving average to smooth oscillations."""
        if history is None or len(history.my_actions) < 2:
            return self._calculate_cooperation_rate(history)
        last_round_cooperators = np.sum(history.opponent_actions[-1, :]) + int(history.my_actions[-1])
        last_round_rate = last_round_cooperators / self.n_players
        if len(history.my_actions) >= 2:
            second_last_cooperators = np.sum(history.opponent_actions[-2, :]) + int(history.my_actions[-2])
            second_last_rate = second_last_cooperators / self.n_players
            smoothed_rate = (last_round_rate + second_last_rate) / 2.0
        else:
            smoothed_rate = last_round_rate
        return smoothed_rate

    def _adaptive_decision(self, history: PlayerHistory, current_round: int) -> Action:
        """Make adaptive decision based on cooperation history."""
        coop_rate = self._calculate_cooperation_rate(history)
        smoothed_coop_rate = self._get_smoothed_cooperation_rate(history, current_round)
        midpoint = self.n_rounds // 2
        if current_round >= midpoint and smoothed_coop_rate < 0.5:
            return Action.D
        if current_round >= 2 and coop_rate < self.m / self.n_players:
            recovery_threshold = self.m / self.n_players + 0.1
            if coop_rate < recovery_threshold:
                return Action.D
        expected_cooperators = smoothed_coop_rate * (self.n_players - 1) + 1
        if expected_cooperators >= self.m:
            payoff_if_cooperate = self.k
        else:
            payoff_if_cooperate = 0.0
        payoff_if_defect = 1.0 + payoff_if_cooperate
        payoff_gap = payoff_if_defect - payoff_if_cooperate
        if payoff_gap <= 0:
            return Action.C
        if smoothed_coop_rate <= self.m / self.n_players:
            return Action.D
        if abs(expected_cooperators - self.m) < 0.01:
            cooperation_probability = 0.7
        else:
            cooperation_probability = max(0.0, 1.0 - payoff_gap / self.k)
        if random.random() < cooperation_probability:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_381(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual payoff maximization with collective welfare by maintaining
    cooperative equilibrium when achievable, while protecting against exploitation
    through dynamic defection thresholds and trust-based decision making.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.cooperation_count_history = []
        self.cooperators_last_round = 0
        self.rounds_threshold_met = 0
        self.consecutive_defection_rounds = 0
        self.my_last_action = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            self.my_last_action = Action.C
            return Action.C
        self._update_history(history, current_round)
        action = self._decide_action(current_round, history)
        self.my_last_action = action
        return action

    def _update_history(self, history: PlayerHistory, current_round: int) -> None:
        """Update internal state tracking based on previous round outcomes."""
        prev_round = current_round - 1
        cooperators_prev = int(np.sum(history.opponent_actions[prev_round, :]))
        self.cooperators_last_round = cooperators_prev
        self.cooperation_count_history.append(cooperators_prev)
        if cooperators_prev >= self.m:
            self.rounds_threshold_met += 1
            self.consecutive_defection_rounds = 0
        else:
            self.consecutive_defection_rounds += 1
        self.consecutive_defection_rounds = min(self.consecutive_defection_rounds, 3)

    def _calculate_trust_score(self, current_round: int) -> float:
        """
        Calculate trust score from 0 to 1.
        trust_score = (rounds_threshold_met / total_rounds_played) Ã— 
                      (cooperators_last_round / n) Ã—
                      (1 - defection_momentum)
        """
        if current_round < 2:
            return 0.5
        total_rounds_played = current_round
        rounds_ratio = self.rounds_threshold_met / max(total_rounds_played, 1)
        cooperators_ratio = self.cooperators_last_round / max(self.n, 1)
        defection_momentum = min(self.consecutive_defection_rounds / 3.0, 1.0)
        trust_score = rounds_ratio * cooperators_ratio * (1.0 - defection_momentum)
        return max(0.0, min(trust_score, 1.0))

    def _calculate_cooperation_rate(self, current_round: int) -> float:
        """Calculate average cooperation rate up to current round."""
        if current_round < 2:
            return 0.5
        total_cooperators = sum(self.cooperation_count_history)
        total_rounds = len(self.cooperation_count_history)
        if total_rounds == 0:
            return 0.5
        return total_cooperators / (total_rounds * self.n)

    def _check_exploitation_detected(self, current_round: int) -> bool:
        """
        Check if exploitation is detected:
        - cooperators_last_round < m AND
        - cooperation_count_(t-1) < m AND
        - cooperation_count_(t-2) < m (minimum 2 rounds of failure)
        """
        if current_round < 3:
            return False
        if self.cooperators_last_round >= self.m:
            return False
        recent_counts = self.cooperation_count_history[-2:]
        if len(recent_counts) < 2:
            return False
        return all((count < self.m for count in recent_counts))

    def _check_defection_cascade(self) -> bool:
        """
        Check if defection cascade detected:
        - cooperators_last_round < (m - 1) AND
        - cooperation_rate < (m / n) Ã— 0.6
        """
        if self.cooperators_last_round >= self.m - 1:
            return False
        cooperation_rate = self._calculate_cooperation_rate(len(self.cooperation_count_history) + 1)
        threshold = self.m / self.n * 0.6
        return cooperation_rate < threshold

    def _decide_action(self, current_round: int, history: PlayerHistory) -> Action:
        """Determine the action for the current round based on decision rules."""
        if current_round == self.r - 1:
            trust_score = self._calculate_trust_score(current_round)
            if trust_score < 0.5:
                return Action.D
            else:
                return Action.C
        trust_score = self._calculate_trust_score(current_round)
        cooperation_rate = self._calculate_cooperation_rate(current_round)
        if self.m == self.n:
            if self.cooperators_last_round >= self.m and cooperation_rate > 0.9 and (trust_score > 0.35):
                return Action.C
            elif self.cooperators_last_round < self.m:
                return Action.D
            else:
                return Action.C if trust_score > 0.35 else Action.D
        if self.m == 2:
            if self._check_exploitation_detected(current_round):
                return Action.D
            if self.consecutive_defection_rounds >= 3:
                return Action.D
            if self.cooperators_last_round >= self.m and trust_score > 0.2:
                return Action.C
            return Action.C if cooperation_rate > self.m / self.n else Action.D
        if self._check_exploitation_detected(current_round):
            return Action.D
        if self._check_defection_cascade():
            return Action.D
        if current_round == self.r - 2:
            if self.cooperators_last_round == self.m and trust_score < 0.4:
                return Action.D
        if self.cooperators_last_round >= self.m and trust_score > 0.35:
            return Action.C
        if current_round >= 2:
            recovery_threshold = self.m / self.n * 0.8
            if cooperation_rate > recovery_threshold and self.cooperators_last_round >= self.m:
                return Action.C
        if self.cooperators_last_round >= self.m and self.consecutive_defection_rounds < 2:
            return Action.C
        if current_round <= 3:
            if cooperation_rate > self.m / self.n * 0.7:
                return Action.C
        if cooperation_rate > self.m / self.n and (not self._check_defection_cascade()):
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_382(BaseStrategy):
    """
    Adaptive Threshold Stewardship: A collective risk strategy that dynamically adjusts
    cooperation based on empirical cooperation rates relative to the threshold, with
    stagnation detection and end-game logic.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold_rate = self.m / self.n
        self.danger_zone_lower = self.threshold_rate * 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            accumulated_payoff = float(np.sum(history.my_payoffs))
            expected_threshold_payoff = (self.r - 1) * self.k
            if accumulated_payoff < expected_threshold_payoff * 0.75:
                return Action.D
            else:
                return Action.C
        coop_count_last_round = int(np.sum(history.opponent_actions[current_round - 1, :]))
        recent_coop_rate = coop_count_last_round / self.n
        stagnation_count = 0
        if current_round > 3:
            for round_idx in range(current_round - 3, current_round):
                round_coop_count = int(np.sum(history.opponent_actions[round_idx, :]))
                round_coop_rate = round_coop_count / self.n
                if round_coop_rate < self.danger_zone_lower:
                    stagnation_count += 1
            if stagnation_count >= 3:
                return Action.D
        if recent_coop_rate >= self.threshold_rate:
            return Action.C
        elif recent_coop_rate >= self.danger_zone_lower:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_383(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare through:
    - Reciprocal cooperation matching population cooperation rate
    - Threshold-sensitive adjustment based on proximity to m
    - Risk-aware defection only when collective likely succeeds without you
    - History-weighted adaptation to predict future cooperation
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.all_defect_rounds = 0
        self.all_coop_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            if self.m / self.n <= 0.5:
                return Action.C
            else:
                return Action.D
        total_cooperations = int(np.sum(history.opponent_actions[:round_number, :]))
        total_cooperations += int(np.sum(history.my_actions[:round_number]))
        total_rounds_played = round_number * self.n
        if total_rounds_played == 0:
            cooperation_rate = 0.0
        else:
            cooperation_rate = total_cooperations / total_rounds_played
        expected_cooperators = cooperation_rate * (self.n - 1)
        gap_to_threshold = self.m - expected_cooperators
        if gap_to_threshold >= 1:
            return Action.C
        if cooperation_rate >= self.m / self.n:
            return Action.C
        if cooperation_rate < self.m / self.n and expected_cooperators >= self.m + 1:
            if cooperation_rate == 0.0:
                self.all_defect_rounds += 1
                if self.all_defect_rounds >= 2:
                    if random.random() < 0.3:
                        self.all_defect_rounds = 0
                        return Action.C
                    else:
                        return Action.D
            else:
                self.all_defect_rounds = 0
            return Action.D
        return Action.C

class Strategy_COLLECTIVE_384(BaseStrategy):
    """
    Adaptive Threshold Sentinel strategy for Collective Risk Dilemma.
    
    Core philosophy: Protect the collective threshold through coordinated contribution.
    Cooperate when threshold is met or when endgame conditions allow. Otherwise, defect
    to avoid subsidizing free-riders.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_rate = self.m / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        cooperators_prev_round = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        cooperation_rate_prev = cooperators_prev_round / self.n_players
        rounds_remaining = self.n_rounds - current_round - 1
        threshold_met_prev = cooperators_prev_round >= self.m
        if threshold_met_prev:
            return Action.C
        if not threshold_met_prev and rounds_remaining <= 2:
            return Action.C
        if not threshold_met_prev and rounds_remaining > 2:
            return Action.D
        return Action.D

class Strategy_COLLECTIVE_385(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATC) for Collective Risk Dilemma.
    
    Dynamically balances risk mitigation with rational self-interest by:
    1. Cooperating unconditionally in round 1
    2. Tracking cooperation rates and adapting threshold-sensitive decisions
    3. Using parameter-dependent probability adjustments based on reward magnitude (k)
    4. Special handling for final round to maximize individual payoff
    5. Defecting only when threshold is unattainable or in final exploitation opportunity
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        cooperation_rate = self._calculate_cooperation_rate(history, round_num)
        min_required = self.m / self.n
        safety_buffer = self._determine_buffer()
        adaptive_prob = self._get_adaptive_probability()
        if round_num == self.r - 1:
            cumulative_rate = self._calculate_cumulative_cooperation_rate(history, round_num)
            if cumulative_rate > 0.65:
                return Action.D
            else:
                return Action.C
        if cooperation_rate >= min_required + safety_buffer:
            return Action.C
        elif cooperation_rate >= min_required:
            if random.random() < adaptive_prob:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate cooperation rate from recent rounds (last 4 rounds or available).
        Returns fraction of opponent cooperators in recent history.
        """
        if round_num <= 0:
            return 0.5
        lookback = min(4, round_num)
        recent_rounds = history.opponent_actions[round_num - lookback:round_num]
        if recent_rounds.size == 0:
            return 0.5
        total_cooperations = np.sum(recent_rounds)
        total_possible = recent_rounds.size
        if total_possible == 0:
            return 0.5
        return float(total_cooperations) / float(total_possible)

    def _calculate_cumulative_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate average cooperation rate over all previous rounds.
        """
        if round_num <= 0:
            return 0.5
        all_rounds = history.opponent_actions[:round_num]
        if all_rounds.size == 0:
            return 0.5
        total_cooperations = np.sum(all_rounds)
        total_possible = all_rounds.size
        if total_possible == 0:
            return 0.5
        return float(total_cooperations) / float(total_possible)

    def _determine_buffer(self) -> float:
        """
        Determine safety buffer based on reward magnitude (k).
        Higher rewards lead to more optimistic buffers.
        """
        if self.k > 2.0:
            return 0.15
        elif self.k > 1.5:
            return 0.1
        else:
            return 0.05

    def _get_adaptive_probability(self) -> float:
        """
        Get probability of cooperating when cooperation rate is near threshold.
        Higher rewards lead to higher cooperation probability.
        """
        if self.k > 2.0:
            return 0.8
        elif self.k > 1.5:
            return 0.6
        else:
            return 0.4

class Strategy_COLLECTIVE_386(BaseStrategy):
    """
    Adaptive Threshold Reciprocity (ATR) Strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Cooperating in round 1 to bootstrap cooperation
    2. Adapting based on observed cooperation rate in rounds 2 to r-1
    3. Defecting in the final round to avoid exploitation
    
    Decision logic:
    - Round 1: COOPERATE (signal that cooperation is possible)
    - Rounds 2 to r-1: COOPERATE if observed cooperation_rate >= m/n, else DEFECT
    - Round r: DEFECT (endgame logic, no future punishment)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_ratio = self.m / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        previous_round_index = current_round - 1
        opponent_actions_previous = history.opponent_actions[previous_round_index, :]
        cooperators_previous = np.sum(opponent_actions_previous)
        my_action_previous = history.my_actions[previous_round_index]
        total_cooperators_previous = cooperators_previous + (1 if my_action_previous else 0)
        cooperation_rate = total_cooperators_previous / self.n_players
        if cooperation_rate >= self.threshold_ratio:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_387(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances individual temptation to defect with collective vulnerability by
    cooperating conditionally based on observed cooperation density across three phases:
    - Early phase: Test cooperation with conservative threshold
    - Middle phase: Stabilize cooperation near critical threshold
    - Final phase: Harvest established cooperation
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        early_phase_end = math.ceil(self.n_rounds / 3)
        late_phase_start = math.floor(2 * self.n_rounds / 3) + 1
        prev_cooperators = int(sum(history.opponent_actions[round_number - 1, :]))
        if round_number <= early_phase_end:
            threshold = math.ceil(self.m / 2)
            if prev_cooperators >= threshold:
                return Action.C
            else:
                return Action.D
        if round_number >= late_phase_start:
            if prev_cooperators >= self.m:
                return Action.C
            else:
                return Action.D
        if prev_cooperators >= self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_388(BaseStrategy):
    """
    Adaptive Threshold Cooperation: A dynamic strategy for the Collective Risk Dilemma
    that balances commitment to collective success with rational self-protection.
    
    The strategy adapts across three phases:
    - Early game: Signal willingness and test population cooperation tendency
    - Middle game: Use trend analysis to decide continued cooperation
    - Endgame: Sustain momentum or protect individual payoff
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        last_round_cooperators = int(sum(history.opponent_actions[-1, :]))
        my_last_action = history.my_actions[-1]
        total_cooperators_last_round = last_round_cooperators + (1 if my_last_action else 0)
        if total_cooperators_last_round == 0:
            return Action.D
        early_game_end = max(1, math.floor(self.n_rounds / 3))
        middle_game_end = math.floor(2 * self.n_rounds / 3)
        threshold_cooperation_rate = self.m / self.n_players
        if current_round <= early_game_end:
            observed_rate = total_cooperators_last_round / self.n_players
            if observed_rate >= threshold_cooperation_rate * 0.75:
                return Action.C
            else:
                return Action.D
        if current_round <= middle_game_end:
            lookback = min(3, current_round)
            cooperation_history = []
            for i in range(lookback):
                round_idx = current_round - 1 - i
                cooperators_in_round = int(sum(history.opponent_actions[round_idx, :]))
                cooperators_in_round += 1 if history.my_actions[round_idx] else 0
                cooperation_history.append(cooperators_in_round / self.n_players)
            recent_trend = np.mean(cooperation_history)
            if recent_trend >= threshold_cooperation_rate:
                return Action.C
            deficit = self.m - total_cooperators_last_round
            rounds_remaining = self.n_rounds - current_round
            if deficit <= rounds_remaining / 2:
                return Action.C
            else:
                return Action.D
        if total_cooperators_last_round >= self.m:
            return Action.C
        total_deficiency_rounds = 0
        for round_idx in range(current_round):
            cooperators_in_round = int(sum(history.opponent_actions[round_idx, :]))
            cooperators_in_round += 1 if history.my_actions[round_idx] else 0
            if cooperators_in_round < self.m:
                total_deficiency_rounds += 1
        deficit_severity = total_deficiency_rounds / current_round if current_round > 0 else 0
        rounds_remaining = self.n_rounds - current_round
        if deficit_severity < 0.3 and rounds_remaining <= 2:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_389(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by dynamically adjusting
    cooperation based on observed cooperation rates and remaining rounds. Cooperates
    optimistically in round 1, adapts based on threshold achievement in middle rounds,
    and uses conditional defection in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if state.round_number == 0:
            return Action.C
        prev_round_idx = state.round_number - 1
        prev_opponent_actions = history.opponent_actions[prev_round_idx, :]
        prev_cooperators_opponents = np.sum(prev_opponent_actions)
        prev_self_action = history.my_actions[prev_round_idx]
        total_prev_cooperators = prev_cooperators_opponents + (1 if prev_self_action else 0)
        cooperation_rate = total_prev_cooperators / n
        threshold_rate = m / n
        rounds_remaining = r - state.round_number
        if state.round_number == r - 1:
            if cooperation_rate >= threshold_rate:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= threshold_rate:
            return Action.C
        elif cooperation_rate >= threshold_rate * 0.5:
            if rounds_remaining >= 2:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_390(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS)
    
    Balances collective welfare with individual robustness by:
    1. Cooperating in round 1 to signal willingness
    2. In middle rounds, cooperating if observed cooperation rate >= threshold rate
    3. Defecting in the final round (terminal round dominance)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if state.round_number == 0:
            return Action.C
        if state.round_number == r - 1:
            return Action.D
        prev_round_cooperators = int(sum(history.opponent_actions[state.round_number - 1, :]))
        if history.my_actions[state.round_number - 1]:
            prev_round_cooperators += 1
        observed_coop_rate = prev_round_cooperators / n
        threshold_rate = m / n
        if observed_coop_rate >= threshold_rate:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_391(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Bootstraps collective action through conditional cooperation with adaptive momentum tracking.
    Cooperates in round 1 to signal willingness, then conditionally cooperates based on whether
    the threshold for collective success was met in the previous round. Uses momentum-based
    probabilistic cooperation for resilience against coordination failures.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold = self.m / self.n_players
        self.rounds_threshold_met = 0
        self.consecutive_failures = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        my_prev_action = history.my_actions[prev_round_idx]
        opponent_prev_actions = history.opponent_actions[prev_round_idx, :]
        cooperators_prev_round = int(my_prev_action) + int(np.sum(opponent_prev_actions))
        threshold_met_prev = cooperators_prev_round >= self.m
        if threshold_met_prev:
            self.rounds_threshold_met += 1
            self.consecutive_failures = 0
        else:
            self.consecutive_failures += 1
        rounds_remaining = self.n_rounds - current_round
        if rounds_remaining == 0:
            if threshold_met_prev:
                return Action.C
            else:
                return Action.D
        if threshold_met_prev:
            return Action.C
        if self.consecutive_failures >= 3:
            return Action.D
        rounds_played = current_round
        if rounds_played == 0:
            momentum = 0.0
        else:
            momentum = self.rounds_threshold_met / rounds_played
        if momentum > 0.6:
            return Action.C if random.random() < momentum else Action.D
        elif momentum == 0.0:
            return Action.D
        else:
            coop_prob = max(0.3, momentum)
            return Action.C if random.random() < coop_prob else Action.D

class Strategy_COLLECTIVE_392(BaseStrategy):
    """
    Adaptive Threshold Cooperator: A history-dependent strategy for the Collective Risk Dilemma.
    
    Seeds cooperation in round 1, then adapts based on observed cooperation rates:
    - Cooperates when the threshold is within reach
    - Reciprocates early cooperation to build momentum
    - Protects against exploitation when cooperation is too sparse
    - Makes final round decision based on whether threshold has been achieved
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        total_decisions = current_round * n
        my_cooperators = np.sum(history.my_actions)
        opponent_cooperators = np.sum(history.opponent_actions)
        total_cooperators = my_cooperators + opponent_cooperators
        if total_decisions == 0:
            coop_rate = 0.0
        else:
            coop_rate = total_cooperators / total_decisions
        if current_round == r - 1:
            if coop_rate >= m / n:
                return Action.C
            else:
                return Action.D
        expected_cooperators = coop_rate * n + 1.0
        if expected_cooperators >= m:
            return Action.C
        elif coop_rate > 0 and current_round < r / 2:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_393(BaseStrategy):
    """
    Adaptive Threshold Sentinel: A strategy that balances individual rationality
    with collective welfare by monitoring the cooperation threshold, adapting to
    observed behavior, and protecting against exploitation.
    
    Core logic:
    - Round 1: Cooperate (bootstrap/signal trustworthiness)
    - Middle rounds: Cooperate if threshold met or close to met (within uncertainty buffer)
    - Final round: Cooperate if threshold met or close to met, else defect
    - Uncertainty buffer: ceil(n * 0.15) to handle variance in cooperation levels
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.uncertainty_buffer = math.ceil(self.n_players * 0.15)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        cooperators_prev_round = int(sum(history.opponent_actions[-1, :]))
        self_cooperated_prev = history.my_actions[-1]
        total_cooperators_prev = cooperators_prev_round + (1 if self_cooperated_prev else 0)
        deficit = self.m - total_cooperators_prev
        if round_number == self.n_rounds - 1:
            if total_cooperators_prev >= self.m or deficit <= self.uncertainty_buffer:
                return Action.C
            else:
                return Action.D
        if total_cooperators_prev >= self.m:
            return Action.C
        elif deficit <= self.uncertainty_buffer:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_394(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS)
    
    Balances individual risk management with collective benefit realization by:
    1. Seeding cooperation in round 1
    2. Matching cooperation to the minimum threshold with adaptive buffers
    3. Using stochastic decisions in uncertain zones
    4. Resisting free-riding through defection when cooperation fails
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.alpha = 0.9
        self.beta = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        if self.m == 1:
            return Action.C
        if self.m == self.n:
            cooperators_last = int(sum(history.opponent_actions[-1, :]))
            if cooperators_last == self.n - 1:
                return Action.C
            return Action.D
        cooperators_last = int(sum(history.opponent_actions[-1, :]))
        cooperation_rate = cooperators_last / self.n
        threshold_ratio = self.m / self.n
        threshold_upper = threshold_ratio * self.alpha
        threshold_lower = threshold_ratio * self.beta
        if cooperation_rate >= threshold_upper:
            return Action.C
        if cooperation_rate < threshold_lower:
            return Action.D
        cooperation_deficit = threshold_upper - cooperation_rate
        zone_width = threshold_upper - threshold_lower
        if zone_width <= 0:
            success_prob = 0.5
        else:
            success_prob = 1.0 - cooperation_deficit / zone_width
        success_prob = max(0.0, min(1.0, success_prob))
        if random.random() < success_prob:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_395(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATC) for Collective Risk Dilemma.
    
    Balances individual security with collective benefit by conditioning cooperation
    on empirical evidence that the threshold m will be reached. Uses parameter-aware
    logic (m, n, k, r) to make decisions robust to exploitation while enabling
    cooperation amplification in cooperative populations.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_actions = history.opponent_actions[round_num - 1, :]
        prev_cooperators = int(np.sum(prev_round_actions))
        coop_rate = prev_cooperators / self.n
        threshold_rate = self.m / self.n
        if round_num == self.r - 1:
            if coop_rate >= threshold_rate - 0.1:
                return Action.C
            else:
                return Action.D
        if round_num == self.r - 2:
            if coop_rate >= threshold_rate:
                return Action.C
            else:
                return Action.D
        success_prob = self._estimate_success_probability(coop_rate)
        eps = self.k / (2 * self.n)
        expected_payoff_coop = 0 + self.k * success_prob
        expected_payoff_defect = 1 + self.k * success_prob
        if expected_payoff_coop >= expected_payoff_defect - eps:
            return Action.C
        else:
            return Action.D

    def _estimate_success_probability(self, observed_coop_rate: float) -> float:
        """
        Estimate P(X >= m) where X ~ Binomial(n, observed_coop_rate).
        Uses cumulative binomial distribution.
        """
        if observed_coop_rate <= 0:
            return 0.0
        if observed_coop_rate >= 1.0:
            return 1.0
        prob_less_than_m = 0.0
        for k in range(self.m):
            prob_less_than_m += self._binomial_pmf(k, self.n, observed_coop_rate)
        return 1.0 - prob_less_than_m

    def _binomial_pmf(self, k: int, n: int, p: float) -> float:
        """
        Calculate binomial probability mass function: P(X = k) where X ~ Binomial(n, p).
        """
        if k < 0 or k > n:
            return 0.0
        log_binom_coeff = math.lgamma(n + 1) - math.lgamma(k + 1) - math.lgamma(n - k + 1)
        log_prob = log_binom_coeff + k * math.log(p + 1e-10) + (n - k) * math.log(1 - p + 1e-10)
        return math.exp(log_prob)

class Strategy_COLLECTIVE_396(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Cooperating in round 1 to bootstrap trust
    2. Maintaining cooperation when threshold is met
    3. Conditionally cooperating based on prior behavior when near threshold
    4. Defecting when cooperation clearly collapses
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_rate = self.m / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round_idx = state.round_number - 1
        prev_round_actions = history.opponent_actions[current_round_idx, :]
        my_prev_action = history.my_actions[current_round_idx]
        opponent_cooperators = np.sum(prev_round_actions)
        total_cooperators = opponent_cooperators + (1 if my_prev_action else 0)
        cooperation_rate = total_cooperators / self.n_players
        if cooperation_rate >= self.threshold_rate:
            return Action.C
        elif cooperation_rate >= self.threshold_rate - 1.0 / self.n_players:
            return Action.C if my_prev_action else Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_397(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Dynamically adjusts cooperation based on progress toward the cooperation threshold,
    round position, and historical reciprocity. Cooperates early to establish trust,
    adapts to observed cooperation rates in the middle game, and defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            return Action.D
        prev_cooperators = int(sum(history.opponent_actions[round_num - 1, :]))
        cooperation_rate = prev_cooperators / self.n
        threshold_met = self.m / self.n
        threshold_close = (self.m - 1) / self.n
        threshold_invest = (self.m - 2) / self.n
        early_middle_boundary = 0.75 * self.r
        if cooperation_rate >= threshold_met:
            return Action.C
        elif cooperation_rate >= threshold_close:
            return Action.C
        elif cooperation_rate >= threshold_invest and round_num < early_middle_boundary:
            return Action.C
        elif cooperation_rate < threshold_invest:
            return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_398(BaseStrategy):
    """
    Collective Resilience Strategy (CRS): Adapts cooperation across three phases
    (exploration, stabilization, enforcement) based on observed population cooperation rates,
    balancing individual security with collective threshold achievement.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        m = self.game_description.m
        k = self.game_description.k
        phase1_end = math.ceil(r / 3)
        phase2_end = math.ceil(2 * r / 3)
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        for round_idx in range(current_round):
            cooperators_in_round = int(np.sum(history.opponent_actions[round_idx, :]))
            if history.my_actions[round_idx]:
                cooperators_in_round += 1
            self.cooperation_history.append(cooperators_in_round)
        avg_cooperators = np.mean(self.cooperation_history) if self.cooperation_history else 0.5 * n
        cooperation_rate = avg_cooperators / n if n > 0 else 0.5
        cooperators_last_round = int(np.sum(history.opponent_actions[current_round - 1, :]))
        threshold_met_last_round = cooperators_last_round >= m - 1
        expected_others_cooperating = (n - 1) * cooperation_rate
        if current_round <= phase1_end:
            return Action.C
        elif current_round <= phase2_end:
            if expected_others_cooperating + 1 >= m:
                return Action.C
            elif expected_others_cooperating >= m - 1:
                if random.random() < cooperation_rate:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D
        else:
            cooperators_needed = m - expected_others_cooperating
            if cooperators_needed <= 1:
                return Action.C
            elif cooperators_needed <= 0.2 * n:
                return Action.C
            elif threshold_met_last_round:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_399(BaseStrategy):
    """
    Adaptive Threshold Sentinel Strategy for Collective Risk Dilemma.
    
    Cooperates when the observed cooperation rate meets or exceeds the threshold ratio (m/n).
    Defects when cooperation falls below threshold. Bootstraps with cooperation in round 1.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round_index = state.round_number - 1
        my_previous_action = history.my_actions[previous_round_index]
        opponent_previous_actions = history.opponent_actions[previous_round_index, :]
        total_cooperators = int(my_previous_action) + int(np.sum(opponent_previous_actions))
        cooperation_rate = total_cooperators / self.n
        required_rate = self.m / self.n
        if cooperation_rate >= required_rate:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_400(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances individual rational self-interest with collective welfare by using
    adaptive thresholds that respond to observed cooperation levels and remaining
    game duration. Cooperates when cooperation is likely sufficient to meet the
    threshold, defects when the collective is clearly failing.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        observed_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        rounds_remaining = self.n_rounds - current_round
        base_high = 0.9
        base_medium_high = 0.7
        base_medium = 0.5
        base_low = 0.2
        if self.m <= self.n_players / 3:
            base_high += 0.2
            base_medium_high += 0.2
            base_medium += 0.2
            base_low += 0.2
        elif self.m > 2 * self.n_players / 3:
            base_medium_high -= 0.15
            base_medium -= 0.15
            base_low -= 0.15
        if self.k > 3:
            base_high += 0.15
            base_medium_high += 0.15
            base_medium += 0.15
            base_low += 0.15
        elif self.k <= 1.2:
            base_high -= 0.15
            base_medium_high -= 0.15
            base_medium -= 0.15
            base_low -= 0.15
        base_high = min(1.0, max(0.0, base_high))
        base_medium_high = min(1.0, max(0.0, base_medium_high))
        base_medium = min(1.0, max(0.0, base_medium))
        base_low = min(1.0, max(0.0, base_low))
        if self.n_players == 2:
            return Action.C
        if observed_cooperators == self.n_players:
            return Action.C
        if observed_cooperators == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            if observed_cooperators >= self.m:
                return Action.C
            elif observed_cooperators == self.m - 1:
                return Action.C
            else:
                return Action.D
        if observed_cooperators >= self.m:
            cooperation_prob = base_high
            return Action.C if random.random() < cooperation_prob else Action.D
        elif observed_cooperators == self.m - 1:
            if rounds_remaining > 2:
                cooperation_prob = base_medium_high
            else:
                cooperation_prob = base_low
            return Action.C if random.random() < cooperation_prob else Action.D
        else:
            deficit = self.m - 1 - observed_cooperators
            threshold_deficit = math.ceil(self.n_players / 3)
            if deficit >= threshold_deficit:
                return Action.D
            elif rounds_remaining > 3:
                cooperation_prob = base_medium
                return Action.C if random.random() < cooperation_prob else Action.D
            else:
                return Action.D

class Strategy_COLLECTIVE_401(BaseStrategy):
    """
    Collective Risk Adaptive Strategy (CRAS)
    
    Navigates the collective risk dilemma by optimistically cooperating initially,
    then adaptively responding to observed cooperation levels. Maintains cooperation
    when thresholds are met or nearly met, but switches to defection when systematic
    betrayal is detected or cooperation fails decisively.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        if self.m >= self.n_players:
            self.defection_threshold = 0.0
        elif self.m == 2:
            self.defection_threshold = 0.5
        else:
            self.defection_threshold = 1.0 / self.m * 1.5
        self.consecutive_failures = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_cooperators_prev = int(np.sum(history.opponent_actions[-1, :]))
        my_action_prev = history.my_actions[-1]
        total_cooperators_prev = opponent_cooperators_prev + int(my_action_prev)
        defection_count_prev = self.n_players - total_cooperators_prev
        defection_rate_prev = defection_count_prev / self.n_players if self.n_players > 0 else 0.0
        if state.round_number == self.n_rounds - 1:
            if total_cooperators_prev >= self.m:
                return Action.C
            else:
                return Action.D
        if total_cooperators_prev < self.m:
            self.consecutive_failures += 1
            if self.consecutive_failures >= 2:
                return Action.D
        else:
            self.consecutive_failures = 0
        if total_cooperators_prev >= self.m:
            if defection_rate_prev < self.defection_threshold:
                return Action.C
            else:
                return Action.D
        elif total_cooperators_prev >= self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_402(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances collective welfare with individual rationality by:
    1. Opening with cooperation to signal willingness and gather information
    2. Adapting based on observed cooperation rates and recent trends
    3. Using graduated thresholds (100%, 80%, 60%) to assess viability
    4. Employing endgame logic to maximize payoffs in final rounds
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.coop_threshold = self.m / self.n_players
        self.is_universal_threshold = self.m == self.n_players
        self.is_low_threshold = self.m <= 2
        self.coop_history = []
        self.in_emergency_mode = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_idx = round_num - 1
        prev_cooperators = int(sum(history.opponent_actions[prev_round_idx, :]))
        prev_coop_rate = prev_cooperators / self.n_players
        self.coop_history.append(prev_coop_rate)
        if round_num == self.n_rounds - 1:
            return Action.D
        if round_num == self.n_rounds - 2:
            if prev_coop_rate >= self.coop_threshold:
                return Action.C
            else:
                return Action.D
        if round_num <= 3:
            if prev_coop_rate >= self.coop_threshold:
                return Action.C
            elif prev_coop_rate >= self.coop_threshold * 0.75:
                return Action.C
            else:
                return Action.D
        if len(self.coop_history) >= 2:
            recent_trend = self.coop_history[-1] - self.coop_history[-2]
        else:
            recent_trend = 0.0
        if prev_coop_rate < 0.3 * self.coop_threshold and recent_trend < 0:
            self.in_emergency_mode = True
        if self.in_emergency_mode:
            return Action.D
        if self.is_universal_threshold:
            threshold_100 = 0.95
            threshold_80 = 0.9
            threshold_60 = 0.8
        elif self.is_low_threshold:
            threshold_100 = self.coop_threshold
            threshold_80 = self.coop_threshold * 0.5
            threshold_60 = self.coop_threshold * 0.3
        else:
            threshold_100 = self.coop_threshold
            threshold_80 = self.coop_threshold * 0.8
            threshold_60 = self.coop_threshold * 0.6
        if prev_coop_rate >= threshold_100:
            return Action.C
        elif prev_coop_rate >= threshold_80 and recent_trend >= 0:
            return Action.C
        elif prev_coop_rate >= threshold_60 and recent_trend > 0.1:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_403(BaseStrategy):
    """
    Adaptive Threshold Sentinel: A learning and responsive strategy for Collective Risk Dilemma.
    
    Balances individual security with collective benefit by:
    1. Cooperating in round 1 to establish trustworthiness
    2. Learning the cooperation baseline from observed actions
    3. Contributing when cooperation is likely to succeed (reducing collective risk)
    4. Becoming defensive when cooperation appears insufficient
    5. Making final-round decisions based on demonstrated population cooperation
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperative_threshold = game_description.m / game_description.n_players
        self.safety_margin = self.cooperative_threshold * 0.25
        self.threshold_final = self.cooperative_threshold

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperation_rate = self._compute_cooperation_rate(history, state.round_number)
        if state.round_number == self.game_description.n_rounds - 1:
            if cooperation_rate >= self.threshold_final:
                return Action.C
            else:
                return Action.D
        cooperation_deficit = cooperation_rate - self.cooperative_threshold
        if cooperation_deficit >= self.safety_margin:
            return Action.C
        elif cooperation_deficit >= -self.safety_margin:
            mixed_strategy_probability = 0.5 + cooperation_deficit / (2 * self.safety_margin)
            if random.random() < mixed_strategy_probability:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _compute_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Compute the cooperation rate from all previous rounds.
        
        cooperation_rate = (total cooperators in previous rounds) / (total possible cooperations)
        """
        my_past_actions = history.my_actions[:current_round]
        opponent_past_actions = history.opponent_actions[:current_round, :]
        my_cooperations = np.sum(my_past_actions)
        opponent_cooperations = np.sum(opponent_past_actions)
        total_cooperations = my_cooperations + opponent_cooperations
        n_players = self.game_description.n_players
        total_possible = current_round * n_players
        if total_possible == 0:
            return 0.0
        cooperation_rate = total_cooperations / total_possible
        return cooperation_rate

class Strategy_COLLECTIVE_404(BaseStrategy):
    """
    Progressive Commitment with Conditional Defection (PCCD) Strategy
    
    Balances collective welfare (achieving threshold m) with individual resilience
    against free-riders. Uses initial cooperation, adaptive probabilistic defection
    in middle rounds based on observed cooperation rates, and final-round cooperation
    to maximize chances of collective success.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.C
        last_round_opponent_actions = history.opponent_actions[current_round - 1, :]
        cooperators_last_round = int(np.sum(last_round_opponent_actions))
        if history.my_actions[current_round - 1]:
            cooperators_last_round += 1
        coop_rate = cooperators_last_round / self.n_players
        threshold_rate = self.m / self.n_players
        if coop_rate >= threshold_rate:
            return Action.C
        rounds_remaining = self.n_rounds - current_round
        if rounds_remaining > 2:
            p_defect = 1.0 - coop_rate
            random_draw = random.random()
            if random_draw < p_defect:
                return Action.D
            else:
                return Action.C
        else:
            return Action.C

class Strategy_COLLECTIVE_405(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances collective optimism with adaptive caution by cooperating in round 1,
    maintaining cooperation if threshold is met or nearly met (with rounds remaining),
    and making final-round decisions based on whether threshold is achievable.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        cooperators_last_round = int(np.sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            cooperators_last_round += 1
        if current_round == self.r - 1:
            if cooperators_last_round >= self.m - 1:
                return Action.C
            else:
                return Action.D
        rounds_remaining = self.r - current_round - 1
        if cooperators_last_round >= self.m:
            return Action.C
        if cooperators_last_round >= self.m - 1 and rounds_remaining > 0:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_406(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances three objectives:
    1. Efficiency: Reach the m-threshold to unlock k rewards
    2. Robustness: Survive against pure defectors and free-riders
    3. Stability: Incentivize collective success through adaptive signaling
    
    Uses phase-based approach with deficit tracking and decay-based recovery.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.deficit_counter = 0
        self.cooperation_history = []

    def _get_phase(self, round_number: int) -> int:
        """Determine which phase we're in (1, 2, or 3)."""
        r = self.game_description.n_rounds
        early_boundary = math.floor(r / 3)
        mid_boundary = math.floor(2 * r / 3)
        if round_number <= early_boundary:
            return 1
        elif round_number <= mid_boundary:
            return 2
        else:
            return 3

    def _get_observed_cooperation_rate(self, history: PlayerHistory, round_idx: int) -> float:
        """Get the cooperation rate of opponents in a specific round."""
        if round_idx < 0 or round_idx >= len(history.opponent_actions):
            return 0.0
        cooperators = np.sum(history.opponent_actions[round_idx, :])
        return cooperators / self.game_description.n_players

    def _get_recent_weighted_cooperation(self, history: PlayerHistory, round_idx: int) -> float:
        """Get exponentially weighted average cooperation from last 2 rounds."""
        if round_idx < 0:
            return 0.0
        recent_rate = self._get_observed_cooperation_rate(history, round_idx)
        if round_idx > 0:
            prev_rate = self._get_observed_cooperation_rate(history, round_idx - 1)
            weighted = 0.7 * recent_rate + 0.3 * prev_rate
            return weighted
        return recent_rate

    def _update_deficit_counter(self, history: PlayerHistory, round_idx: int) -> int:
        """
        Update deficit counter based on whether threshold was met.
        Returns the updated deficit counter value.
        """
        if round_idx < 0:
            return 0
        cooperators = np.sum(history.opponent_actions[round_idx, :])
        cooperators += int(history.my_actions[round_idx])
        if cooperators >= self.game_description.m:
            return 0
        else:
            return self.deficit_counter + 1

    def _handle_edge_cases(self, state: GameState, history: PlayerHistory) -> tuple[bool, Action]:
        """
        Handle edge cases and return (should_use_override, action).
        Returns (False, None) if no override applies.
        """
        r = self.game_description.n_rounds
        m = self.game_description.m
        n = self.game_description.n_players
        if r == 2:
            if state.round_number == 0:
                return (True, Action.C)
            else:
                coop_rate = self._get_observed_cooperation_rate(history, 0)
                threshold = (m - 1) / (n - 1) if n > 1 else 0
                if coop_rate >= threshold:
                    return (True, Action.D)
                else:
                    return (True, Action.D)
        if state.round_number >= 3:
            recent_coop = self._get_observed_cooperation_rate(history, state.round_number - 1)
            if recent_coop < 0.01 and self.deficit_counter >= 2:
                return (True, Action.D)
        return (False, None)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        r = self.game_description.n_rounds
        m = self.game_description.m
        n = self.game_description.n_players
        if state.round_number == 0:
            return Action.C
        override_applies, override_action = self._handle_edge_cases(state, history)
        if override_applies:
            return override_action
        self.deficit_counter = self._update_deficit_counter(history, state.round_number - 1)
        phase = self._get_phase(state.round_number)
        if phase == 1:
            coop_rate = self._get_observed_cooperation_rate(history, state.round_number - 1)
            threshold = (m - 1) / (n - 1) if n > 1 else 0
            if coop_rate >= threshold:
                return Action.C
            else:
                return Action.D
        elif phase == 2:
            coop_rate = self._get_recent_weighted_cooperation(history, state.round_number - 1)
            threshold_primary = (m - 1) / (n - 1) if n > 1 else 0
            threshold_secondary = (m - 2) / (n - 1) if n > 1 else 0
            if self.deficit_counter >= 3:
                if state.round_number % 3 == 0:
                    return Action.C
                else:
                    return Action.D
            elif coop_rate >= threshold_primary:
                return Action.C
            elif coop_rate >= threshold_secondary and self.deficit_counter == 0:
                return Action.C
            else:
                return Action.D
        elif state.round_number == r - 1:
            coop_rate = self._get_observed_cooperation_rate(history, state.round_number - 1)
            if coop_rate >= m / n:
                return Action.D
            else:
                return Action.D
        elif state.round_number == r - 2:
            coop_rate = self._get_recent_weighted_cooperation(history, state.round_number - 1)
            threshold = (m - 1) / (n - 1) if n > 1 else 0
            if coop_rate >= threshold:
                return Action.C
            else:
                return Action.D
        else:
            coop_rate = self._get_recent_weighted_cooperation(history, state.round_number - 1)
            threshold_primary = (m - 1) / (n - 1) if n > 1 else 0
            threshold_secondary = (m - 2) / (n - 1) if n > 1 else 0
            if self.deficit_counter >= 3:
                if state.round_number % 3 == 0:
                    return Action.C
                else:
                    return Action.D
            elif coop_rate >= threshold_primary:
                return Action.C
            elif coop_rate >= threshold_secondary and self.deficit_counter == 0:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_407(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual security with collective welfare through:
    1. Early unconditional cooperation (Phase 1)
    2. Adaptive calibration based on observed cooperation rates (Phase 2)
    3. Commitment or abandonment based on group reliability (Phase 3)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        phase1_end = math.ceil(self.r / 3)
        phase2_end = math.floor(2 * self.r / 3)
        if round_t <= phase1_end:
            return Action.C
        observed_coop_rate = self._calculate_cooperation_rate(history, round_t)
        if round_t <= phase2_end:
            return self._phase2_decision(round_t, observed_coop_rate, phase2_end)
        return self._phase3_decision(round_t, history, observed_coop_rate)

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_t: int) -> float:
        """Calculate the observed cooperation rate across all previous rounds."""
        total_rounds_played = round_t
        my_coop = np.sum(history.my_actions[:round_t])
        opponent_coop = np.sum(history.opponent_actions[:round_t, :])
        total_coop = my_coop + opponent_coop
        max_possible = self.n * total_rounds_played
        if max_possible == 0:
            return 0.0
        return total_coop / max_possible

    def _phase2_decision(self, round_t: int, observed_coop_rate: float, phase2_end: int) -> Action:
        """Phase 2 (middle rounds): Adaptive calibration based on observed cooperation."""
        critical_threshold = (self.m - 1) / self.n
        moderate_threshold = self.m / (2 * self.n)
        boost = 0.1 if round_t == phase2_end else 0.0
        if observed_coop_rate >= critical_threshold:
            return Action.C
        elif observed_coop_rate >= moderate_threshold:
            coop_prob = min(observed_coop_rate * 1.2, 1.0) + boost
            coop_prob = min(coop_prob, 1.0)
            return Action.C if random.random() < coop_prob else Action.D
        else:
            coop_prob = min(observed_coop_rate * 2.0, 0.3)
            return Action.C if random.random() < coop_prob else Action.D

    def _phase3_decision(self, round_t: int, history: PlayerHistory, observed_coop_rate: float) -> Action:
        """Phase 3 (final rounds): Commitment or abandonment."""
        reliability = self._calculate_threshold_reliability(history, round_t)
        if round_t == self.r - 1:
            if reliability >= 0.7:
                return Action.C
            else:
                return Action.D
        critical_threshold = (self.m - 1) / self.n
        if observed_coop_rate >= critical_threshold:
            return Action.C if random.random() < 0.95 else Action.D
        else:
            return Action.C if random.random() < 0.15 else Action.D

    def _calculate_threshold_reliability(self, history: PlayerHistory, round_t: int) -> float:
        """Calculate fraction of previous rounds where threshold m was met."""
        if round_t == 0:
            return 0.0
        threshold_met_count = 0
        for r in range(round_t):
            cooperators = int(history.my_actions[r]) + np.sum(history.opponent_actions[r, :])
            if cooperators >= self.m:
                threshold_met_count += 1
        return threshold_met_count / round_t

class Strategy_COLLECTIVE_408(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Employs dynamic decision-making based on round position, historical cooperation rates,
    threshold reachability, and adaptive responses to population behavior.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        observed_cooperation_rate = self._calculate_cooperation_rate(history, current_round)
        threshold_likely = self._is_threshold_likely(observed_cooperation_rate)
        rounds_remaining = self.n_rounds - current_round
        in_endgame = rounds_remaining <= 2
        if self.m == self.n_players:
            if observed_cooperation_rate < 1.0:
                return Action.D
        if self.m <= 2:
            return Action.C
        if threshold_likely:
            return Action.C
        elif not threshold_likely and in_endgame:
            return Action.D
        elif not threshold_likely and (not in_endgame):
            if observed_cooperation_rate > 0.3:
                return Action.C
            else:
                return Action.D
        return Action.C

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the observed cooperation rate from all prior rounds.
        
        Returns a value between 0 and 1 representing the proportion of cooperations
        across all prior rounds for all players.
        """
        if current_round == 0:
            return 0.5
        prior_rounds = current_round
        total_possible_cooperations = prior_rounds * self.n_players
        if total_possible_cooperations == 0:
            return 0.5
        opponent_cooperations = np.sum(history.opponent_actions[:current_round, :])
        self_cooperations = np.sum(history.my_actions[:current_round])
        total_cooperations = opponent_cooperations + self_cooperations
        cooperation_rate = total_cooperations / total_possible_cooperations
        return cooperation_rate

    def _is_threshold_likely(self, observed_cooperation_rate: float) -> bool:
        """
        Determine if threshold is likely to be reached based on current cooperation rate.
        
        If the trend continues, would we expect m or more cooperators?
        """
        expected_cooperators = self.n_players * observed_cooperation_rate
        return expected_cooperators >= self.m

class Strategy_COLLECTIVE_409(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) for Collective Risk Dilemma.
    
    Balances collective benefit maximization with individual protection by:
    1. Cooperating in initial rounds to signal willingness and probe others
    2. Adaptively cooperating if observed cooperation rate meets threshold
    3. Defecting in final round (with near-universal cooperation exception)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_coop_rate = (self.m - 1) / (self.n_players - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round <= 1:
            return Action.C
        if current_round == self.n_rounds - 1:
            if current_round > 0:
                prev_round_cooperators = np.sum(history.opponent_actions[current_round - 1])
                prev_round_coop_rate = prev_round_cooperators / (self.n_players - 1)
            else:
                prev_round_coop_rate = 0.0
            if prev_round_coop_rate >= 0.9:
                return Action.C
            else:
                return Action.D
        if current_round > 0:
            prev_round_cooperators = np.sum(history.opponent_actions[current_round - 1])
            prev_round_coop_rate = prev_round_cooperators / (self.n_players - 1)
        else:
            prev_round_coop_rate = 0.0
        if prev_round_coop_rate >= self.threshold_coop_rate:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_410(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances collective welfare (reaching cooperation threshold) with individual rationality.
    - Round 1: Cooperate (initiate cooperation signal)
    - Rounds 2 to r-1: Adapt based on previous cooperation rate and pivotal moments
    - Final round: Defect (backward induction), except unanimity case
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        is_final_round = current_round == self.n_rounds - 1
        if is_final_round:
            if self.m == self.n_players:
                if history is not None and current_round > 0:
                    all_cooperated_all_rounds = True
                    for round_idx in range(current_round):
                        if not history.my_actions[round_idx]:
                            all_cooperated_all_rounds = False
                            break
                        for opponent_idx in range(self.n_players - 1):
                            if not history.opponent_actions[round_idx, opponent_idx]:
                                all_cooperated_all_rounds = False
                                break
                        if not all_cooperated_all_rounds:
                            break
                    if all_cooperated_all_rounds:
                        return Action.C
            return Action.D
        if history is None or current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        prev_cooperators_opponent = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        prev_cooperators_total = prev_cooperators_opponent + (1 if history.my_actions[prev_round_idx] else 0)
        prev_coop_rate = prev_cooperators_total / self.n_players
        if prev_coop_rate >= self.m / self.n_players:
            return Action.C
        if prev_coop_rate < (self.m - 1) / self.n_players:
            deficit = self.m - math.floor(prev_coop_rate * self.n_players)
            if deficit > 1:
                return Action.D
            else:
                expected_payoff_c = prev_coop_rate * self.k
                expected_payoff_d = 1.0 + prev_coop_rate * self.k
                if expected_payoff_c >= expected_payoff_d * 0.9:
                    return Action.C
                else:
                    return Action.D
        current_cooperators = math.floor(prev_coop_rate * self.n_players)
        needed_additional = self.m - current_cooperators
        if needed_additional == 1:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_411(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Signaling trustworthiness with initial cooperation
    2. Adapting to observed cooperation trajectory
    3. Protecting against exploitation when collective success becomes unlikely
    4. Maintaining flexibility through window-based observation
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_ratio = self.m / self.n_players
        self.threshold_critical = self.threshold_ratio * 0.8
        self.threshold_abandon = self.threshold_ratio * 0.5
        self.window_size = min(3, self.n_rounds - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            cooperation_rate = self._calculate_cooperation_rate(history, current_round)
            if cooperation_rate >= self.threshold_critical:
                return Action.C
            else:
                return Action.D
        cooperation_rate = self._calculate_cooperation_rate(history, current_round)
        expected_total_cooperators = cooperation_rate * self.n_players
        if expected_total_cooperators >= self.m * self.threshold_critical:
            return Action.C
        elif cooperation_rate < self.threshold_abandon:
            return Action.D
        else:
            return Action.C

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the cooperation rate of opponents in the recent window.
        
        Returns the fraction of recent opponent actions that were cooperation.
        """
        window_start = max(0, current_round - self.window_size)
        window_end = current_round
        if window_start >= window_end:
            return 0.0
        window_actions = history.opponent_actions[window_start:window_end, :]
        total_actions = window_actions.size
        if total_actions == 0:
            return 0.0
        total_cooperations = np.sum(window_actions)
        cooperation_rate = total_cooperations / total_actions
        return cooperation_rate

class Strategy_COLLECTIVE_412(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual security with collective welfare by dynamically adjusting
    cooperation based on historical cooperation rates, threshold safety margins,
    and round position. Uses an Adaptive Cooperation Index (ACI) to make decisions
    in middle rounds while always cooperating in round 1 and final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.cooperation_threshold = 0.65
        self.defection_threshold = 0.35
        self.weight_history = 0.5
        self.weight_threshold = 0.3
        self.weight_position = 0.2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.n_rounds - 1:
            return Action.C
        return self._decide_middle_round(round_num, history)

    def _decide_middle_round(self, round_num: int, history: PlayerHistory) -> Action:
        """Decision logic for middle rounds (2 to r-1)."""
        historical_coop_rate = self._calculate_historical_coop_rate(history, round_num)
        cooperators_last_round = int(np.sum(history.opponent_actions[round_num - 1, :]))
        safety_margin = max(0, cooperators_last_round - self.m)
        round_pressure = (self.n_rounds - 1 - round_num) / max(1, self.n_rounds - 2)
        aci = historical_coop_rate * self.weight_history + safety_margin / self.n_players * self.weight_threshold + round_pressure * self.weight_position
        if aci >= self.cooperation_threshold:
            return Action.C
        elif aci <= self.defection_threshold:
            return Action.D
        elif cooperators_last_round > self.m:
            return Action.C
        else:
            return Action.D

    def _calculate_historical_coop_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the proportion of all players cooperating across all previous rounds.
        
        Args:
            history: PlayerHistory object containing opponent actions
            current_round: Current round number (0-indexed)
        
        Returns:
            Float between 0 and 1 representing cooperation rate
        """
        if current_round == 0:
            return 0.0
        total_cooperations = 0
        for round_idx in range(current_round):
            total_cooperations += np.sum(history.opponent_actions[round_idx, :])
        total_possible = current_round * self.n_players
        if total_possible == 0:
            return 0.0
        return float(total_cooperations) / float(total_possible)

class Strategy_COLLECTIVE_413(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual security with collective benefit by:
    1. Cooperating in round 1 to establish good faith
    2. Adapting to observed cooperation rates in intermediate rounds
    3. Making final-round decisions based on whether threshold is met
    
    Uses probabilistic cooperation in marginal zones to enable recovery
    and avoid exploitation while respecting collective outcomes.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.critical_threshold = self.m / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        rounds_played = current_round
        my_cooperations = np.sum(history.my_actions[:rounds_played])
        opponent_cooperations = np.sum(history.opponent_actions[:rounds_played, :])
        total_cooperations = my_cooperations + opponent_cooperations
        total_possible = rounds_played * self.n_players
        if total_possible == 0:
            cooperation_rate = 0.0
        else:
            cooperation_rate = total_cooperations / total_possible
        if current_round == self.n_rounds - 1:
            if cooperation_rate >= self.critical_threshold:
                return Action.C
            else:
                return Action.D
        upper_buffer = self.critical_threshold + 0.1
        lower_buffer = self.critical_threshold - 0.05
        if cooperation_rate >= upper_buffer:
            return Action.C
        elif cooperation_rate >= lower_buffer:
            probability = (cooperation_rate - self.critical_threshold + 0.05) / 0.15
            probability = max(0.0, min(1.0, probability))
            if random.random() < probability:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_414(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Employs three-phase approach:
    1. Opening phase: Unconditional cooperation to signal willingness
    2. Middle phase: Adaptive cooperation based on observed cooperation rates
    3. Endgame phase: Threshold-targeting defection when success is likely
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.phase_1_end = math.ceil(self.r / 3)
        self.phase_2_end = math.ceil(2 * self.r / 3)
        self.success_threshold = self.m / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round < self.phase_1_end:
            return Action.C
        if current_round < self.phase_2_end:
            return self._phase_2_decision(history, current_round)
        return self._phase_3_decision(history, current_round)

    def _phase_2_decision(self, history: PlayerHistory, current_round: int) -> Action:
        """
        Middle phase: Adapt based on observed cooperation history from Phase 1.
        """
        phase_1_rounds = history.my_actions[:self.phase_1_end]
        successful_rounds = 0
        for round_idx in range(len(phase_1_rounds)):
            cooperators = int(history.my_actions[round_idx]) + np.sum(history.opponent_actions[round_idx, :])
            if cooperators >= self.m:
                successful_rounds += 1
        if self.phase_1_end == 0:
            cooperation_probability = 0.0
        else:
            cooperation_probability = successful_rounds / self.phase_1_end
        if cooperation_probability >= self.success_threshold:
            return Action.C
        elif cooperation_probability < self.success_threshold * 0.5:
            return Action.D
        elif random.random() < cooperation_probability:
            return Action.C
        else:
            return Action.D

    def _phase_3_decision(self, history: PlayerHistory, current_round: int) -> Action:
        """
        Endgame phase: Threshold-targeting defection.
        """
        if current_round == self.r - 1:
            return Action.D
        phase_2_start = self.phase_1_end
        phase_2_end = self.phase_2_end
        if phase_2_start >= phase_2_end or phase_2_end == 0:
            return Action.D
        recent_rounds = history.my_actions[phase_2_start:phase_2_end]
        recent_coop_count = 0
        for round_idx in range(phase_2_start, phase_2_end):
            cooperators = int(history.my_actions[round_idx]) + np.sum(history.opponent_actions[round_idx, :])
            if cooperators >= self.m:
                recent_coop_count += 1
        phase_2_length = phase_2_end - phase_2_start
        if phase_2_length == 0:
            recent_cooperation_rate = 0.0
        else:
            recent_cooperation_rate = recent_coop_count / phase_2_length
        if recent_cooperation_rate >= self.success_threshold:
            return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_415(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATC) for Collective Risk Dilemma.
    
    Balances cautious optimism with self-protection by dynamically adapting to observed
    cooperation rates. Cooperates in round 1, adapts based on threshold proximity in
    intermediate rounds, and makes final-round decisions based on likelihood of success.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.epsilon = 1.0 / self.n
        self.threshold = self.m / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        previous_round_index = current_round - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[previous_round_index, :]))
        if history.my_actions[previous_round_index]:
            cooperators_last_round += 1
        observed_cooperation_rate = cooperators_last_round / self.n
        if current_round == self.r - 1:
            if observed_cooperation_rate >= self.threshold - self.epsilon:
                return Action.C
            else:
                return Action.D
        if observed_cooperation_rate >= self.threshold + self.epsilon:
            return Action.D
        elif observed_cooperation_rate >= self.threshold - self.epsilon:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_416(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATC)
    
    Balances collective welfare maximization with individual security by dynamically
    adjusting cooperation based on observed collective behavior. Cooperation becomes
    rational when the probability of threshold success is sufficiently high.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_confidence = 0.85
        self.optimistic_confidence = 0.7
        self.collapse_threshold = 0.7

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            threshold_ratio = self.m / self.n
            if threshold_ratio <= 0.5:
                return Action.C
            elif threshold_ratio <= 0.75:
                return Action.C
            else:
                return Action.D
        prev_round_idx = round_num - 1
        prev_cooperators = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        my_prev_action = history.my_actions[prev_round_idx]
        total_prev_cooperators = prev_cooperators + (1 if my_prev_action else 0)
        coop_rate = total_prev_cooperators / self.n
        target_rate = self.m / self.n
        if target_rate == 0:
            return Action.C
        confidence = coop_rate / target_rate
        failure_count = 0
        for r in range(round_num):
            round_cooperators = int(np.sum(history.opponent_actions[r, :]))
            round_cooperators += 1 if history.my_actions[r] else 0
            if round_cooperators < self.m:
                failure_count += 1
        if failure_count >= 2:
            return Action.D
        if coop_rate < target_rate * self.collapse_threshold and failure_count == 1:
            return Action.D
        if confidence >= self.threshold_confidence:
            decision = Action.C
        elif confidence >= self.optimistic_confidence:
            decision = Action.C
        else:
            decision = Action.D
        if round_num == self.r - 1:
            if coop_rate >= target_rate * self.threshold_confidence:
                decision = Action.C
        return decision

class Strategy_COLLECTIVE_417(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATC) for Collective Risk Dilemma.
    
    Balances collective welfare with individual robustness by:
    1. Maintaining threshold viability
    2. Punishing defection through strategic non-cooperation
    3. Recovering cooperation after punishment phases
    4. Adjusting behavior in the final round based on historical reliability
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        cooperators_per_round = np.sum(history.opponent_actions, axis=1)
        cooperators_per_round = np.concatenate([np.array([1.0 if history.my_actions[0] else 0.0]), cooperators_per_round])
        threshold_met_per_round = cooperators_per_round >= self.m
        total_threshold_successes = np.sum(threshold_met_per_round[:current_round])
        cooperation_rate = total_threshold_successes / current_round if current_round > 0 else 0.0
        successful_rounds = np.where(threshold_met_per_round[:current_round])[0]
        last_successful_round = successful_rounds[-1] if len(successful_rounds) > 0 else -1
        last_round_cooperators = cooperators_per_round[current_round - 1]
        threshold_met_last_round = last_round_cooperators >= self.m
        if current_round == self.r - 1:
            threshold_prob = (self.m - 1) / (self.n - 1)
            if cooperation_rate > threshold_prob:
                return Action.C
            else:
                return Action.D
        estimated_next_cooperators = self._estimate_next_cooperators(cooperators_per_round, current_round)
        recovery_window = max(2, math.ceil(self.r / 4))
        rounds_since_success = current_round - last_successful_round if last_successful_round >= 0 else current_round + 1
        midpoint = math.ceil(self.r / 2)
        if current_round >= midpoint and total_threshold_successes == 0:
            return Action.D
        if threshold_met_last_round:
            if estimated_next_cooperators >= self.m:
                return Action.C
            else:
                return Action.D
        if rounds_since_success <= recovery_window:
            return Action.C
        else:
            threshold_prob = (self.m - 1) / (self.n - 1)
            if cooperation_rate > threshold_prob:
                return Action.C
            else:
                return Action.D

    def _estimate_next_cooperators(self, cooperators_per_round: NDArray, current_round: int) -> float:
        """
        Estimate the number of cooperators in the next round based on recent history.
        """
        recent_window = min(3, current_round)
        if recent_window == 0:
            return self.m
        recent_cooperators = np.mean(cooperators_per_round[max(0, current_round - recent_window):current_round])
        if recent_cooperators >= self.m:
            return min(self.n, recent_cooperators + 1)
        elif recent_cooperators >= self.m - 1:
            return max(1, recent_cooperators - 1)
        else:
            return recent_cooperators

class Strategy_COLLECTIVE_418(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare through:
    - Reciprocal cooperation matching population cooperation levels
    - Threshold-responsive behavior based on whether m cooperators are achieved
    - Graceful degradation with minimum cooperation floor
    - Probabilistic defection to avoid mutual defection traps
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold_rate = self.m / self.n
        self.grace_term = 0.1
        self.own_cooperation_rate = 0.5
        self.defection_penalty_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        recent_rounds = min(3, state.round_number)
        recent_cooperation_counts = history.opponent_actions[max(0, state.round_number - recent_rounds):state.round_number, :]
        if recent_cooperation_counts.shape[0] > 0:
            cooperation_rates = np.mean(recent_cooperation_counts, axis=1)
            recent_cooperation = float(np.mean(cooperation_rates))
        else:
            recent_cooperation = self.threshold_rate
        if self.defection_penalty_rounds > 0:
            self.defection_penalty_rounds -= 1
            self.own_cooperation_rate = max(0.1, self.own_cooperation_rate - 0.3)
        if state.round_number >= 2:
            prev_cooperation = float(np.mean(history.opponent_actions[state.round_number - 2, :]))
            curr_cooperation = float(np.mean(history.opponent_actions[state.round_number - 1, :]))
            if curr_cooperation - prev_cooperation >= 0.2:
                self.own_cooperation_rate = min(0.95, self.own_cooperation_rate + 0.15)
        if state.round_number >= 2:
            defection_threshold = (self.m - 2) / self.n
            prev_coop = float(np.mean(history.opponent_actions[state.round_number - 2, :]))
            curr_coop = float(np.mean(history.opponent_actions[state.round_number - 1, :]))
            if prev_coop < defection_threshold and curr_coop < defection_threshold:
                self.defection_penalty_rounds = 2
        if recent_cooperation >= self.threshold_rate:
            if recent_cooperation > 0.8:
                return Action.C
            elif recent_cooperation > self.threshold_rate + 0.15:
                return Action.C if random.random() < 0.85 else Action.D
            else:
                return Action.C if random.random() < 0.6 else Action.D
        elif recent_cooperation >= self.threshold_rate - 0.15:
            return Action.C if random.random() < 0.95 else Action.D
        else:
            defection_pressure = min(0.9, max(0.0, 0.7 - recent_cooperation))
            return Action.D if random.random() < defection_pressure else Action.C

class Strategy_COLLECTIVE_419(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Cooperating unconditionally in the first round to establish good faith
    2. Using probabilistic escalation in middle rounds based on observed cooperation
    3. Harvesting gains in the final round if threshold was crossed, otherwise defecting
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        prev_round_idx = round_number - 1
        cooperators_prev_round = int(sum(history.opponent_actions[prev_round_idx, :]))
        if round_number == self.n_rounds - 1:
            if cooperators_prev_round >= self.m:
                return Action.C
            else:
                return Action.D
        if cooperators_prev_round >= self.m - 1:
            return Action.C
        if cooperators_prev_round >= self.m:
            return Action.C
        threshold_half = self.m / 2.0
        if cooperators_prev_round >= threshold_half:
            escalation_prob = cooperators_prev_round / self.m
            if random.random() < escalation_prob:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_420(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances individual security with collective benefit by monitoring cooperation levels,
    contributing conditionally, and gracefully degrading when cooperation fails.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        threshold_ratio = self.m / self.n_players
        buffer = min(0.15, 0.2 * threshold_ratio)
        self.critical_threshold = threshold_ratio + buffer
        self.minimum_viability = threshold_ratio - buffer

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return self._final_round_decision(history)
        return self._adaptive_maintenance_decision(history, current_round)

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """
        Final round: cooperate if accumulated cooperation rate >= critical_threshold,
        otherwise defect to secure private payoff.
        """
        total_rounds_so_far = history.my_actions.shape[0]
        total_cooperation_opportunities = (self.n_players - 1) * total_rounds_so_far
        if total_cooperation_opportunities == 0:
            return Action.C
        total_cooperations = np.sum(history.opponent_actions)
        accumulated_coop_rate = total_cooperations / total_cooperation_opportunities
        if accumulated_coop_rate >= self.critical_threshold:
            return Action.C
        else:
            return Action.D

    def _adaptive_maintenance_decision(self, history: PlayerHistory, current_round: int) -> Action:
        """
        Rounds 1 to r-2: Three-zone response based on cooperation rate.
        """
        total_rounds_so_far = current_round
        total_cooperation_opportunities = (self.n_players - 1) * total_rounds_so_far
        if total_cooperation_opportunities == 0:
            return Action.C
        total_cooperations = np.sum(history.opponent_actions)
        cooperation_rate = total_cooperations / total_cooperation_opportunities
        if cooperation_rate >= self.critical_threshold:
            return Action.C
        if cooperation_rate >= self.minimum_viability:
            cooperators_in_current_round = np.sum(history.opponent_actions[-1, :])
            deficit_to_threshold = self.m - cooperators_in_current_round - 1
            deficit_to_threshold = max(0, deficit_to_threshold)
            if deficit_to_threshold <= 2:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_421(BaseStrategy):
    """
    Adaptive Threshold Covenant strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Cooperating in round 1 to signal and test population cooperativeness
    2. Adaptively tracking cooperation rates and threshold likelihood
    3. Defecting when threshold is already met (free-riding)
    4. Defecting in final round (terminal rationality)
    5. Gradually giving up on cooperation if defection dominates
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if current_round == 0:
            return Action.C
        if current_round == r - 1:
            return Action.D
        prev_round_idx = current_round - 1
        prev_round_opponent_actions = history.opponent_actions[prev_round_idx, :]
        cooperators_prev = int(np.sum(prev_round_opponent_actions))
        if cooperators_prev == 0:
            remaining_rounds = r - current_round
            if remaining_rounds >= r / 2:
                return Action.C
            else:
                return Action.D
        coop_rate = cooperators_prev / (n - 1)
        threshold_fraction = m / n
        if coop_rate >= threshold_fraction:
            return Action.D
        expected_cooperators = (n - 1) * coop_rate + 1.0
        if expected_cooperators >= m:
            return Action.C
        deficit = m - expected_cooperators
        if deficit <= 2:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_422(BaseStrategy):
    """
    Adaptive Threshold Reciprocity: A conditional cooperation strategy for the Collective Risk Dilemma.
    
    Cooperates by default in round 1, then reciprocates based on whether the group has historically
    met the minimum cooperation threshold. Uses a slightly elevated threshold in early rounds (2-4)
    to allow trust-building, and includes a 5% tolerance buffer for rounding variance.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.base_threshold = self.m / self.n_players
        self.tolerance = 0.05

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        empirical_cooperation_rate = self._calculate_empirical_cooperation_rate(history, current_round)
        threshold = self._get_threshold(current_round)
        adjusted_empirical_rate = empirical_cooperation_rate
        if empirical_cooperation_rate >= threshold - self.tolerance:
            adjusted_empirical_rate = threshold
        if current_round == self.n_rounds - 1:
            if adjusted_empirical_rate >= threshold:
                return Action.C
            else:
                return Action.D
        if adjusted_empirical_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_empirical_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the empirical cooperation rate across all previous rounds.
        
        Returns the proportion of cooperations observed across all players and previous rounds.
        Handles division by zero gracefully.
        """
        if current_round == 0:
            return 0.0
        total_cooperators = np.sum(history.opponent_actions[:current_round, :])
        my_cooperators = np.sum(history.my_actions[:current_round])
        total_cooperators += my_cooperators
        total_slots = self.n_players * current_round
        if total_slots == 0:
            return 0.0
        empirical_rate = total_cooperators / total_slots
        return empirical_rate

    def _get_threshold(self, current_round: int) -> float:
        """
        Get the cooperation threshold for the current round.
        
        Early rounds (2-4, i.e., indices 1-3) use a 20% buffer to allow trust-building.
        Later rounds revert to the exact threshold.
        """
        if current_round <= 3:
            return self.base_threshold * 1.2
        else:
            return self.base_threshold

class Strategy_COLLECTIVE_423(BaseStrategy):
    """
    Adaptive Threshold Consensus strategy for Collective Risk Dilemma.
    
    Balances collective success (reaching threshold m) with individual resilience
    against free-riding. Uses progressive commitment: cooperate in round 1, adapt
    dynamically in middle rounds based on observed cooperation rates, and make a
    final push in the last round if momentum exists.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num < self.n_rounds - 1:
            return self._middle_game_decision(history, round_num)
        return self._final_round_decision(history, round_num)

    def _middle_game_decision(self, history: PlayerHistory, round_num: int) -> Action:
        """Adaptive decision for rounds 1 to r-2."""
        c_prev = int(sum(history.opponent_actions[round_num - 1, :]))
        if c_prev >= self.m:
            return Action.C
        if c_prev == self.m - 1:
            return Action.C
        if c_prev >= self.n_players / 2:
            return Action.C
        threshold_minority = self.m - math.ceil(self.n_players / 3)
        if c_prev >= threshold_minority:
            return Action.C
        if c_prev >= 2:
            if random.random() < c_prev / self.m:
                return Action.C
            return Action.D
        return Action.D

    def _final_round_decision(self, history: PlayerHistory, round_num: int) -> Action:
        """Decision for the final round (r-1)."""
        c_prev_final = int(sum(history.opponent_actions[round_num - 1, :]))
        if c_prev_final >= self.m - 1:
            return Action.C
        if c_prev_final >= self.n_players / 2:
            return Action.C
        total_cooperators = int(np.sum(history.opponent_actions[:round_num, :]))
        total_possible = round_num * self.n_players
        if total_possible > 0:
            avg_coop_rate = total_cooperators / total_possible
            threshold_avg = self.m / self.n_players
            if avg_coop_rate > threshold_avg:
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_424(BaseStrategy):
    """
    Adaptive Threshold Assurance: A strategy for the Collective Risk Dilemma that balances
    rational self-interest with collective welfare by cooperating when the threshold is
    within reach, withdrawing when cooperation becomes futile, and remaining robust to
    exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        cooperators_prev = int(sum(history.opponent_actions[current_round - 1, :]))
        if current_round == self.n_rounds - 1:
            if cooperators_prev >= self.m - 1:
                return Action.C
            else:
                return Action.D
        r_remaining = self.n_rounds - current_round
        if cooperators_prev >= self.m:
            return Action.C
        elif cooperators_prev >= self.m - 1:
            return Action.C
        elif cooperators_prev < self.m - 1:
            if r_remaining > 1:
                cooperation_rate = cooperators_prev / self.n_players if self.n_players > 0 else 0.0
                if cooperation_rate >= 0.4:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_425(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances collective welfare with individual safety by probing opponent cooperation,
    adapting to observed patterns, protecting against free-riders, and escalating pressure
    when collective goals are at risk.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_idx = round_num - 1
        cooperators_prev = int(sum(history.opponent_actions[prev_round_idx, :]))
        cooperation_rate = cooperators_prev / self.n
        threshold_rate = self.m / self.n
        rounds_remaining = self.r - round_num
        if round_num == self.r - 1:
            if cooperators_prev >= self.m - 1:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= threshold_rate:
            return Action.C
        threshold_minus_one = threshold_rate - 1.0 / self.n
        if cooperation_rate >= threshold_minus_one:
            escalation_prob = max(0.5, 1.0 - rounds_remaining / self.r)
            if random.random() < escalation_prob:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_426(BaseStrategy):
    """
    Cascade Cooperation with Adaptive Risk Tolerance
    
    A collective rationality strategy for the Collective Risk Dilemma that:
    - Initiates cooperation to establish pro-social norms
    - Adapts dynamically to observed cooperation rates
    - Uses threshold-aware decision making to maximize collective success
    - Gracefully handles defector-dominated environments
    - Applies strategic last-round defection with cooperative exceptions
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self._calculate_thresholds()

    def _calculate_thresholds(self) -> None:
        """Calculate critical_mass and recovery_threshold with edge case handling."""
        if self.n <= 3:
            self.critical_mass = (self.m + 0.5) / self.n
        else:
            self.critical_mass = (self.m + 1) / self.n
        if self.m > 0.8 * self.n:
            self.critical_mass = 0.95
            self.recovery_threshold = 0.9
        elif self.m <= 2:
            self.recovery_threshold = 0.1
        else:
            self.recovery_threshold = (self.m - 1) / self.n

    def _get_cooperation_rate(self, history: PlayerHistory, window: int=3) -> float:
        """Calculate moving average cooperation rate from opponent actions."""
        if len(history.opponent_actions) == 0:
            return 0.0
        start_idx = max(0, len(history.opponent_actions) - window)
        recent_actions = history.opponent_actions[start_idx:, :]
        if recent_actions.size == 0:
            return 0.0
        total_cooperators = np.sum(recent_actions)
        total_possible = recent_actions.shape[0] * recent_actions.shape[1]
        return total_cooperators / total_possible if total_possible > 0 else 0.0

    def _get_last_round_cooperators(self, history: PlayerHistory) -> int:
        """Count cooperators in the most recent round."""
        if len(history.opponent_actions) == 0:
            return 0
        return int(np.sum(history.opponent_actions[-1, :]))

    def _should_cooperate_last_round(self, history: PlayerHistory) -> bool:
        """Special logic for the last round."""
        if len(history.opponent_actions) < 2:
            return False
        last_2_coop = self._get_cooperation_rate(history, window=2)
        return last_2_coop >= self.critical_mass

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number + 1
        rounds_remaining = self.r - current_round
        if current_round == self.r:
            if self._should_cooperate_last_round(history):
                return Action.C
            else:
                return Action.D
        recent_coop = self._get_cooperation_rate(history, window=3)
        last_round_cooperators = self._get_last_round_cooperators(history)
        threshold_met_last = last_round_cooperators >= self.m
        if recent_coop >= self.critical_mass:
            return Action.C
        if threshold_met_last and last_round_cooperators >= self.recovery_threshold * self.n:
            return Action.C
        if recent_coop >= self.recovery_threshold:
            return Action.C
        if recent_coop < self.recovery_threshold and rounds_remaining <= 3:
            return Action.D
        return Action.D

class Strategy_COLLECTIVE_427(BaseStrategy):
    """
    Conditional Threshold Assurance strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Securing the collective good when feasible (reaching threshold m)
    2. Punishing free-riding through strategic defection
    3. Recovering cooperation when conditions improve
    4. Avoiding cascade failure through adaptive risk assessment
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        if round_t == self.r - 1:
            return Action.D
        recent_coop_rate = self._get_recent_coop_rate(history, round_t)
        target_rate = self.m / self.n
        if round_t == self.r - 2:
            threshold = 0.7 * target_rate
            return Action.C if recent_coop_rate >= threshold else Action.D
        if round_t <= 2:
            threshold = (self.m - 1) / self.n
            return Action.C if recent_coop_rate >= threshold else Action.D
        consecutive_failures = self._check_consecutive_failures(history, round_t)
        if self.n <= 4:
            coop_threshold = target_rate
            defect_threshold = 0.5 * target_rate
        else:
            coop_threshold = 0.8 * target_rate
            defect_threshold = 0.5 * target_rate
        if self.r > 20 and round_t > 10:
            decay_factor = 1.0 - 0.01 * (round_t - 10)
            coop_threshold = max(0.0, coop_threshold * decay_factor)
            defect_threshold = max(0.0, defect_threshold * decay_factor)
        if self.m > 0.7 * self.n and round_t <= 4:
            coop_threshold = 0.75 * target_rate
        if recent_coop_rate >= coop_threshold:
            return Action.C
        elif recent_coop_rate >= defect_threshold:
            return Action.D
        elif consecutive_failures:
            return Action.D
        else:
            if self._should_recover(history, round_t, target_rate):
                return Action.C
            return Action.D

    def _get_recent_coop_rate(self, history: PlayerHistory, round_t: int) -> float:
        """Calculate cooperation rate from last 2 rounds."""
        if round_t == 0:
            return 0.0
        start_round = max(0, round_t - 2)
        end_round = round_t
        total_coop = 0
        total_slots = 0
        for r in range(start_round, end_round):
            if r < len(history.opponent_actions):
                round_cooperators = np.sum(history.opponent_actions[r, :])
                total_coop += round_cooperators
                total_slots += self.n - 1
        if total_slots == 0:
            return 0.0
        return total_coop / total_slots

    def _check_consecutive_failures(self, history: PlayerHistory, round_t: int) -> bool:
        """Check if threshold NOT met in 3 consecutive recent rounds."""
        if round_t < 3:
            return False
        target_rate = self.m / self.n
        threshold = target_rate
        for r in range(round_t - 3, round_t):
            if r < 0 or r >= len(history.opponent_actions):
                continue
            round_cooperators = np.sum(history.opponent_actions[r, :])
            coop_rate = round_cooperators / (self.n - 1)
            if coop_rate < threshold:
                return False
        return True

    def _should_recover(self, history: PlayerHistory, round_t: int, target_rate: float) -> bool:
        """
        Adaptive recovery: if cooperation rate suddenly rises to >= (m/n),
        rejoin cooperation.
        """
        if round_t < 1:
            return False
        last_round_coop_rate = np.sum(history.opponent_actions[round_t - 1, :]) / (self.n - 1)
        return last_round_coop_rate >= target_rate

class Strategy_COLLECTIVE_428(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Operates on conditional commitment: cooperate when the threshold appears achievable
    based on historical cooperation rates, defect when it appears unreachable.
    Protects against systematic free-riding while optimizing for collective success.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.success_achieved = False
        self.cooperation_rate = 0.0
        self.total_cooperators_observed = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        rounds_elapsed = round_t
        total_opponent_cooperators = np.sum(history.opponent_actions[:rounds_elapsed, :])
        my_past_cooperators = np.sum(history.my_actions[:rounds_elapsed])
        self.total_cooperators_observed = total_opponent_cooperators + my_past_cooperators
        if rounds_elapsed > 0:
            self.cooperation_rate = self.total_cooperators_observed / (n * rounds_elapsed)
        else:
            self.cooperation_rate = 0.0
        for past_round in range(rounds_elapsed):
            round_cooperators = np.sum(history.opponent_actions[past_round, :]) + (1 if history.my_actions[past_round] else 0)
            if round_cooperators >= m:
                self.success_achieved = True
                break
        if self.cooperation_rate == 1.0 and rounds_elapsed > 0:
            return Action.C
        if round_t > r / 2 and self.cooperation_rate < m / n * 0.5:
            return Action.D
        if self.cooperation_rate == 0.0 and round_t > 1:
            return Action.D
        if round_t < r:
            expected_cooperators = self.cooperation_rate * (n - 1) + 1
            if expected_cooperators >= m:
                return Action.C
            else:
                return Action.D
        else:
            current_round_cooperators = np.sum(history.opponent_actions[round_t, :])
            if current_round_cooperators >= m:
                return Action.C
            if current_round_cooperators + 1 >= m:
                return Action.C
            return Action.D

class Strategy_COLLECTIVE_429(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective benefit by:
    1. Cooperating initially to signal cooperativeness and test the environment
    2. Tracking cooperation rates and recent cooperator counts
    3. Using adaptive decision rules based on threshold proximity and cooperation history
    4. Applying special endgame logic to avoid unraveling
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        recent_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        total_cooperators_all_rounds = int(np.sum(history.opponent_actions[:current_round, :]))
        total_possible_cooperations = current_round * self.n_players
        cooperation_rate = total_cooperators_all_rounds / total_possible_cooperations if total_possible_cooperations > 0 else 0.0
        if current_round == self.n_rounds - 1:
            if cooperation_rate >= 0.4:
                return Action.C
            else:
                return Action.D
        if recent_cooperators >= self.m:
            return Action.C
        if recent_cooperators == self.m - 1:
            return Action.C
        if recent_cooperators >= self.m - 2 and cooperation_rate >= 0.4:
            return Action.C
        if recent_cooperators >= 1 and cooperation_rate >= 0.5:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_430(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by recognizing the
    discontinuous payoff cliff at threshold m. Uses conditional reciprocal cooperation:
    - Cooperate in first round to establish good faith
    - In middle rounds, cooperate based on observed cooperation rates and proximity to threshold
    - In last round, cooperate if threshold is nearly met, otherwise defect if underperforming
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        coop_count_last = int(sum(history.opponent_actions[current_round - 1, :]))
        threshold_met_last = coop_count_last >= self.m
        if current_round == self.r - 1:
            if coop_count_last >= self.m - 1:
                return Action.C
            else:
                total_payoff = float(np.sum(history.my_payoffs))
                expected_full_coop = self.r * (0 + self.k) if self.r >= 1 else 0
                if expected_full_coop > 0:
                    performance_ratio = total_payoff / expected_full_coop
                else:
                    performance_ratio = 1.0
                if performance_ratio < 0.7:
                    return Action.D
                else:
                    return Action.C
        if threshold_met_last:
            return Action.C
        if coop_count_last >= self.m - 1:
            return Action.C
        half_threshold = math.ceil(self.m / 2)
        if coop_count_last >= half_threshold:
            if self.m > 1:
                probability = (coop_count_last - 1) / (self.m - 1)
            else:
                probability = 1.0
            probability = max(0.0, min(1.0, probability))
            if random.random() < probability:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_431(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Cooperating in round 1 to gather information
    2. Tracking cooperation rate across all previous rounds
    3. Cooperating if aggregate cooperation rate meets/exceeds threshold (m/n) - Îµ
    4. Defecting if cooperation rate falls below threshold
    5. Applying the same rule consistently through all rounds, including the final round
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.epsilon = 1.0 / (2.0 * self.n_players)
        self.threshold_rate = self.m / self.n_players - self.epsilon

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        total_cooperators = int(np.sum(history.opponent_actions[:current_round, :]))
        my_cooperations = int(np.sum(history.my_actions[:current_round]))
        total_cooperators += my_cooperations
        total_actions = self.n_players * current_round
        if total_actions == 0:
            return Action.C
        coop_rate = total_cooperators / total_actions
        if coop_rate >= self.threshold_rate:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_432(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual security with collective benefit by dynamically adjusting
    cooperation based on observed group behavior, threshold attainment, and remaining rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        opponent_cooperators_prev = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        my_action_prev = history.my_actions[prev_round_idx]
        total_cooperators_prev = opponent_cooperators_prev + (1 if my_action_prev else 0)
        cooperation_rate = total_cooperators_prev / self.n
        threshold_met = total_cooperators_prev >= self.m
        if current_round == self.r - 1:
            return Action.D
        if threshold_met:
            return Action.C
        rounds_remaining = self.r - current_round
        if rounds_remaining == 1:
            return Action.D
        threshold_margin = self.m / self.n - 1 / self.n
        if cooperation_rate >= threshold_margin:
            defection_temptation = self.k - 1
            decay_factor = rounds_remaining / self.r
            if defection_temptation * (1 - decay_factor) < 0.5:
                return Action.C
            else:
                return Action.D
        else:
            salvage_threshold = self.m / self.n * 0.6
            if cooperation_rate >= salvage_threshold:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_433(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Cooperating in round 1 to establish good faith
    2. Adaptively cooperating if observed cooperation rate supports threshold m
    3. Attempting recovery if threshold was historically achievable
    4. Defecting in final round only if cooperation has collapsed
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.buffer = 0.1
        self.ema_alpha = 0.6

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if self.m == 1:
            return Action.C
        if self.m == self.n:
            for round_idx in range(current_round):
                if not np.all(history.opponent_actions[round_idx, :]):
                    return Action.D
            return Action.C
        cooperation_rate = self._calculate_cooperation_rate(history, current_round)
        threshold_met_ratio = self._calculate_threshold_met_ratio(history, current_round)
        coop_threshold = self.m / self.n - self.buffer
        if current_round == self.r - 1:
            if cooperation_rate >= coop_threshold:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= coop_threshold:
            return Action.C
        elif cooperation_rate < coop_threshold and threshold_met_ratio > 0.5:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate exponential moving average of cooperation rate over recent rounds.
        Considers last 3 rounds or all available rounds if fewer than 3.
        """
        if current_round == 0:
            return 0.0
        start_idx = max(0, current_round - 3)
        recent_rounds = current_round - start_idx
        ema_value = 0.0
        weight = 1.0
        total_weight = 0.0
        for i in range(start_idx, current_round):
            round_cooperators = np.sum(history.opponent_actions[i, :])
            round_coop_rate = round_cooperators / (self.n - 1)
            ema_value = ema_value * (1 - self.ema_alpha) + round_coop_rate * self.ema_alpha
        return ema_value

    def _calculate_threshold_met_ratio(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate proportion of rounds where threshold m was met (including this player's contributions).
        """
        if current_round == 0:
            return 0.0
        threshold_met_count = 0
        for round_idx in range(current_round):
            opponent_cooperators = np.sum(history.opponent_actions[round_idx, :])
            self_cooperated = history.my_actions[round_idx]
            total_cooperators = opponent_cooperators + (1 if self_cooperated else 0)
            if total_cooperators >= self.m:
                threshold_met_count += 1
        threshold_met_ratio = threshold_met_count / current_round
        return threshold_met_ratio

class Strategy_COLLECTIVE_434(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual security with collective welfare by cooperating when
    there is reasonable evidence the threshold can be met, and defecting when
    threshold failure is highly likely. Uses graduated risk investment based
    on game phase, cooperation trends, and deficit from threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if self.m == 1:
            return Action.C
        if self.m >= self.n:
            if round_num <= self.r // 2:
                return Action.C
            else:
                return Action.D
        cooperators_last = int(np.sum(history.opponent_actions[round_num - 1, :]))
        if round_num >= 2:
            cooperators_prev = int(np.sum(history.opponent_actions[round_num - 2, :]))
            if cooperators_last == 0 and cooperators_prev == 0:
                return Action.D
        all_rounds = history.opponent_actions[:round_num, :]
        cooperation_rate_overall = np.mean(all_rounds) if round_num > 0 else 0.0
        recent_start = max(0, round_num - 3)
        recent_rounds = history.opponent_actions[recent_start:round_num, :]
        cooperation_rate_recent = np.mean(recent_rounds) if recent_rounds.size > 0 else 0.0
        before_start = max(0, round_num - 6)
        before_end = max(0, round_num - 3)
        if before_start < before_end:
            before_rounds = history.opponent_actions[before_start:before_end, :]
            cooperation_rate_before = np.mean(before_rounds) if before_rounds.size > 0 else 0.0
        else:
            cooperation_rate_before = cooperation_rate_recent
        trend = 1 if cooperation_rate_recent > cooperation_rate_before else -1 if cooperation_rate_recent < cooperation_rate_before else 0
        deficit = self.m - cooperators_last
        if round_num <= self.r // 3:
            threshold_rate = self.m / self.n * 0.9
            if cooperation_rate_overall >= threshold_rate:
                return Action.C
            low_threshold_rate = self.m / self.n * 0.6
            if cooperation_rate_overall < low_threshold_rate:
                return Action.D
            return Action.C
        elif round_num > 2 * self.r // 3:
            rounds_remaining = self.r - round_num
            if rounds_remaining == 1:
                if cooperators_last >= self.m - 1:
                    return Action.C
                else:
                    return Action.D
            else:
                if deficit <= 2:
                    return Action.C
                deficit_threshold = 0.5 * (self.n - self.m)
                if deficit > deficit_threshold:
                    return Action.D
                return Action.C if trend >= 0 else Action.D
        else:
            if deficit <= 2:
                return Action.C
            deficit_threshold = 0.5 * (self.n - self.m)
            if deficit > deficit_threshold:
                return Action.D
            if round_num >= 2:
                cooperators_prev = int(np.sum(history.opponent_actions[round_num - 2, :]))
                if cooperators_last >= self.m and cooperators_prev < self.m - 2:
                    return Action.C
            return Action.C if trend >= 0 else Action.D

class Strategy_COLLECTIVE_435(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Establishing cooperative intent in round 1
    2. Tracking cooperation rates and defection streaks
    3. Making threshold-aware decisions based on observed behavior
    4. Switching to defensive defection when threshold becomes infeasible
    5. Applying end-game logic for final rounds
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_rate = 0.5
        self.defection_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        rounds_remaining = self.game_description.n_rounds - state.round_number
        cooperators_last_round = int(np.sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            cooperators_last_round += 1
        m = self.game_description.m
        n = self.game_description.n_players
        if rounds_remaining <= 2:
            if cooperators_last_round >= m:
                action = Action.C
            else:
                action = Action.D
        elif cooperators_last_round >= m:
            self.defection_streak = 0
            action = Action.C
        elif cooperators_last_round == m - 1:
            threshold_ratio = m / n * 0.9
            if self.cooperation_rate >= threshold_ratio:
                action = Action.C
            else:
                action = Action.D
        else:
            self.defection_streak += 1
            if self.defection_streak >= 2:
                action = Action.D
            else:
                threshold_prob = self.cooperation_rate * (rounds_remaining / self.game_description.n_rounds)
                if random.random() < threshold_prob:
                    action = Action.C
                else:
                    action = Action.D
        cooperation_rate_last_round = cooperators_last_round / n
        self.cooperation_rate = 0.7 * self.cooperation_rate + 0.3 * cooperation_rate_last_round
        return action

class Strategy_COLLECTIVE_436(BaseStrategy):
    """
    Adaptive Threshold Stabilization strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Recognizing the tension between individual and collective payoffs
    2. Stabilizing cooperation dynamically based on threshold credibility
    3. Minimizing free-riding vulnerability through strategic defection
    
    Core logic: Cooperate when threshold is achievable and credible,
    defect only when cooperation cannot produce collective success or
    in final rounds when reciprocation is no longer credible.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.early_warning_horizon = max(2, math.ceil(self.r / 4))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        cooperators_last_round = int(np.sum(history.opponent_actions[current_round - 1, :]))
        coop_rate = cooperators_last_round / self.n
        if self.m == self.n:
            if cooperators_last_round < self.n:
                return Action.D
            return Action.C
        threshold_for_success = self.m / self.n
        critical_threshold = (self.m - 1) / self.n
        rounds_remaining = self.r - current_round
        in_final_period = rounds_remaining <= self.early_warning_horizon
        if in_final_period:
            coop_declining = False
            if current_round > 1:
                cooperators_two_rounds_ago = int(np.sum(history.opponent_actions[current_round - 2, :]))
                coop_rate_two_rounds_ago = cooperators_two_rounds_ago / self.n
                coop_declining = coop_rate < coop_rate_two_rounds_ago
            if current_round == self.r - 1:
                if coop_rate >= critical_threshold:
                    return Action.D
                else:
                    return Action.D
            if coop_rate >= threshold_for_success and (not coop_declining):
                return Action.C
            elif coop_rate >= critical_threshold and (not coop_declining):
                return Action.C
            else:
                return Action.D
        elif coop_rate >= threshold_for_success:
            return Action.C
        elif coop_rate >= critical_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_437(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances collective welfare with robust self-protection through adaptive,
    history-informed decision-making. Opens with cooperation, maintains it if
    cooperation rates sustain threshold, and defects if cooperation collapses.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.base_threshold = self.m / self.n_players
        self.safety_margin = min(0.15, 0.5 * self.base_threshold)
        self.threshold = self.base_threshold + self.safety_margin
        self.soft_threshold = self.threshold - 0.2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        cooperation_rate = self._calculate_cooperation_rate(history, current_round)
        if current_round == self.n_rounds - 1:
            if cooperation_rate >= self.threshold:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= self.threshold:
            return Action.C
        elif cooperation_rate >= self.soft_threshold:
            mid_game_progress = (current_round - 1) / (self.n_rounds - 2)
            discount_factor = mid_game_progress
            if random.random() < 1.0 - discount_factor:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the empirical cooperation rate of all players (including self)
        over all previous rounds.
        
        Args:
            history: PlayerHistory object with action records
            current_round: Current round number (0-indexed)
        
        Returns:
            Cooperation rate as a float in [0, 1]
        """
        if current_round == 0:
            return 0.0
        my_cooperations = np.sum(history.my_actions[:current_round])
        opponent_cooperations = np.sum(history.opponent_actions[:current_round, :])
        total_cooperations = my_cooperations + opponent_cooperations
        total_actions = current_round * self.n_players
        if total_actions == 0:
            return 0.0
        cooperation_rate = total_cooperations / total_actions
        return cooperation_rate

class Strategy_COLLECTIVE_438(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Recognizing the alignment problem between individual and collective interests
    2. Building conditional trust based on observed success rates
    3. Gracefully degrading cooperation only when evidence of failure accumulates
    4. Adapting cooperation probability based on whether threshold was historically met
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.successful_rounds = 0
        self.rounds_played = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            if random.random() < 0.65:
                return Action.C
            else:
                return Action.D
        self.successful_rounds = 0
        self.rounds_played = 0
        for round_idx in range(state.round_number):
            my_action = history.my_actions[round_idx]
            opponent_cooperators = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators = int(my_action) + opponent_cooperators
            if total_cooperators >= self.game_description.m:
                self.successful_rounds += 1
            self.rounds_played += 1
        if self.rounds_played > 0:
            success_rate = self.successful_rounds / self.rounds_played
        else:
            success_rate = 0.5
        if success_rate >= 0.6:
            p_coop = 0.85
        elif success_rate >= 0.3:
            p_coop = 0.6
        else:
            p_coop = 0.4
        if state.round_number == self.game_description.n_rounds - 1:
            if success_rate >= 0.5:
                p_coop = 0.7
            else:
                p_coop = 0.3
        if random.random() < p_coop:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_439(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Leading with cooperation in round 1
    2. Reciprocating when threshold is met in middle rounds
    3. Probabilistically supporting near-threshold situations
    4. Defecting when cooperation rate is too low
    5. Defecting in the final round (endgame logic)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.n_rounds - 1:
            return Action.D
        previous_round_idx = round_number - 1
        opponent_cooperators = int(np.sum(history.opponent_actions[previous_round_idx, :]))
        my_previous_action = history.my_actions[previous_round_idx]
        total_cooperators = opponent_cooperators + (1 if my_previous_action else 0)
        cooperation_rate = total_cooperators / self.n_players
        threshold_rate = self.m / self.n_players
        near_threshold_rate = (self.m - 1) / self.n_players
        if cooperation_rate >= threshold_rate:
            return Action.C
        elif cooperation_rate >= near_threshold_rate:
            p_encourage = self.m / (self.n_players * self.k)
            p_encourage = min(1.0, max(0.0, p_encourage))
            if random.random() < p_encourage:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_440(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual security with collective benefit by adapting cooperation
    decisions based on observed cooperation rates, with momentum tracking to handle
    volatility and endgame defection logic.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.required_threshold = self.m / self.n
        if self.m == self.n - 1:
            self.safety_margin = 0.25
        elif self.m == 2:
            self.safety_margin = 0.1
        else:
            self.safety_margin = 0.15
        self.target_cooperation_rate = self.required_threshold + self.safety_margin
        self.cooperation_rates = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            if self.m / self.n > 0.8 and len(self.cooperation_rates) > 0:
                coop_rate = self.cooperation_rates[-1]
                if coop_rate >= self.target_cooperation_rate:
                    if random.random() < 0.2:
                        return Action.C
            return Action.D
        prev_round_idx = current_round - 1
        cooperators_prev_round = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        coop_rate = cooperators_prev_round / self.n
        self.cooperation_rates.append(coop_rate)
        momentum = 0.0
        if len(self.cooperation_rates) >= 3:
            if self.cooperation_rates[-1] > self.cooperation_rates[-2] and self.cooperation_rates[-2] > self.cooperation_rates[-3]:
                momentum = 0.2
            elif self.cooperation_rates[-1] < self.cooperation_rates[-2] and self.cooperation_rates[-2] < self.cooperation_rates[-3]:
                momentum = -0.2
        adjusted_target = self.target_cooperation_rate + momentum
        if coop_rate >= adjusted_target:
            return Action.C
        elif coop_rate >= self.required_threshold:
            p_coop = (coop_rate - self.required_threshold) / self.safety_margin
            if random.random() < p_coop:
                return Action.C
            else:
                return Action.D
        elif coop_rate >= self.required_threshold * 0.67:
            return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_441(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy
    
    Balances individual rationality with collective welfare by dynamically adjusting
    cooperation based on observed cooperation rates. Cooperates in round 1 to bootstrap
    collective action, then conditionally cooperates based on whether the threshold m
    is likely to be met.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round_idx = state.round_number - 1
        prev_round_cooperators = int(sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            prev_round_cooperators += 1
        cooperation_rate = prev_round_cooperators / self.n
        threshold_rate = self.m / self.n
        marginal_rate = (self.m - 1) / self.n
        if cooperation_rate >= threshold_rate:
            return Action.C
        elif cooperation_rate >= marginal_rate:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_442(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATC)
    
    Balances individual risk management with collective benefit maximization by adapting
    cooperation based on observed cooperation rates. The strategy:
    1. Cooperates in round 1 to probe opponent types
    2. Adapts in rounds 2 to r-1 based on observed cooperation rate
    3. Uses a modified threshold in the final round
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round_idx = state.round_number - 1
        last_round_opponent_actions = history.opponent_actions[last_round_idx, :]
        opponent_cooperators = np.sum(last_round_opponent_actions)
        my_last_action = history.my_actions[last_round_idx]
        total_cooperators = opponent_cooperators + int(my_last_action)
        observed_coop_rate = total_cooperators / self.n
        threshold_rate = self.m / self.n
        if state.round_number == self.r - 1:
            if observed_coop_rate >= threshold_rate * 0.5:
                return Action.C
            else:
                return Action.D
        if observed_coop_rate >= threshold_rate:
            return Action.C
        elif observed_coop_rate >= threshold_rate * 0.75:
            adaptive_prob = observed_coop_rate / threshold_rate
            if random.random() < adaptive_prob:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_443(BaseStrategy):
    """
    Adaptive Collective Risk Strategy: Conditional Threshold Matching
    
    Balances individual rationality with collective welfare by:
    1. Recognizing defection only pays at threshold boundary (m-1 cooperators)
    2. Maximizing collective payoff when possible
    3. Minimizing vulnerability to exploitation
    4. Adapting to observed cooperation rates
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if self.n < self.m:
            return Action.D
        if round_num == 0:
            return Action.C
        cooperation_rate = self._calculate_cooperation_rate(history, round_num)
        threshold_rate = self.m / self.n
        threshold_margin = 0.05
        if round_num == self.r - 1:
            if round_num > 0 and history.opponent_actions.shape[0] > 0:
                cooperators_prev = np.sum(history.opponent_actions[-1, :]) + (1 if history.my_actions[-1] else 0)
                if cooperators_prev >= self.m:
                    return Action.D
            return Action.C
        if cooperation_rate >= threshold_rate - threshold_margin:
            return Action.C
        if cooperation_rate < threshold_rate / 2:
            return Action.D
        recent_trend = self._calculate_recent_trend(history, round_num)
        if recent_trend > 0:
            return Action.C
        else:
            return Action.C

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """Calculate cooperation rate across all previous rounds."""
        if round_num == 0 or history.opponent_actions.shape[0] == 0:
            return 0.0
        total_cooperators = 0
        total_possible = 0
        for round_idx in range(history.opponent_actions.shape[0]):
            round_cooperators = np.sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                round_cooperators += 1
            total_cooperators += round_cooperators
            total_possible += self.n
        if total_possible == 0:
            return 0.0
        return total_cooperators / total_possible

    def _calculate_recent_trend(self, history: PlayerHistory, round_num: int) -> int:
        """
        Calculate trend in recent cooperation.
        Weight recent rounds 2x more heavily.
        Returns positive if cooperation increasing, negative/zero otherwise.
        """
        if history.opponent_actions.shape[0] < 2:
            return 0
        current_coop = np.sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            current_coop += 1
        prev_coop = np.sum(history.opponent_actions[-2, :])
        if history.my_actions[-2]:
            prev_coop += 1
        trend = current_coop - prev_coop
        return trend

class Strategy_COLLECTIVE_444(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by conditionally cooperating
    based on observed cooperation rates. Cooperates in round 1 to initiate collective action,
    adapts in middle rounds based on threshold achievement, and makes final-round decisions
    pragmatically based on past cooperation levels.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        my_prev_action = history.my_actions[prev_round_idx]
        opponent_prev_cooperators = np.sum(history.opponent_actions[prev_round_idx, :])
        total_prev_cooperators = int(my_prev_action) + opponent_prev_cooperators
        cooperation_rate = total_prev_cooperators / self.n
        rounds_remaining = self.r - current_round
        threshold_rate = self.m / self.n
        if cooperation_rate >= threshold_rate:
            return Action.C
        nearly_threshold_rate = (self.m - 1) / self.n
        if cooperation_rate >= nearly_threshold_rate and rounds_remaining >= 1:
            return Action.C
        if cooperation_rate < nearly_threshold_rate and rounds_remaining >= 2:
            return Action.D
        if current_round == self.r - 1:
            if cooperation_rate >= threshold_rate:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_445(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by exploiting the threshold
    structure: cooperate when threshold is reachable, defect when impossible or trending negative,
    and defect in the final round (strict Nash equilibrium).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            return Action.D
        prev_round_idx = round_num - 1
        prev_cooperators = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        coop_rate = prev_cooperators / (self.n - 1) if self.n > 1 else 0
        if prev_cooperators >= self.m - 1:
            return Action.C
        if prev_cooperators >= self.m:
            return Action.C
        if prev_cooperators + 1 >= self.m:
            if self._is_trend_positive_or_stable(history, round_num):
                return Action.C
            else:
                return Action.D
        return Action.D

    def _is_trend_positive_or_stable(self, history: PlayerHistory, current_round: int) -> bool:
        """
        Analyze cooperation trend in recent rounds to decide if we should be the marginal cooperator.
        Look at the last 3 rounds of cooperation counts among opponents.
        """
        if current_round < 2:
            return True
        rounds_to_check = min(3, current_round)
        coop_counts = []
        for i in range(rounds_to_check):
            round_idx = current_round - 1 - i
            if round_idx >= 0:
                count = int(np.sum(history.opponent_actions[round_idx, :]))
                coop_counts.append(count)
        if len(coop_counts) < 2:
            return True
        most_recent = coop_counts[0]
        previous = coop_counts[1]
        if most_recent >= previous:
            return True
        if len(coop_counts) >= 3:
            oldest = coop_counts[2]
            if most_recent >= oldest:
                return True
        return False

class Strategy_COLLECTIVE_446(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by dynamically
    adjusting cooperation based on observed cooperation rates and distance
    to the threshold m. Employs different strategies for early game, middle game,
    and end game phases.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        prev_round_idx = round_number - 1
        prev_cooperators = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            prev_cooperators += 1
        prev_success = prev_cooperators >= self.m
        rounds_remaining = self.r - round_number
        if rounds_remaining <= 1:
            return self._end_game_decision(prev_cooperators, prev_success)
        else:
            return self._middle_game_decision(prev_cooperators, prev_success)

    def _end_game_decision(self, prev_cooperators: int, prev_success: bool) -> Action:
        """
        End game strategy for last 2 rounds.
        Conditional threshold securing.
        """
        if self.m == self.n:
            return Action.C if prev_cooperators == self.n else Action.D
        if prev_cooperators >= self.m:
            return Action.C
        if prev_cooperators == self.m - 1:
            return Action.C
        if prev_cooperators >= math.ceil(self.m / 2.0):
            return Action.C if random.random() < 0.6 else Action.D
        return Action.D

    def _middle_game_decision(self, prev_cooperators: int, prev_success: bool) -> Action:
        """
        Middle game strategy for rounds 1 through r-3.
        Cooperative momentum rule with special handling for edge cases.
        """
        if self.m == self.n:
            return Action.C if prev_cooperators == self.n else Action.D
        if self.m == 2:
            return Action.C if prev_cooperators >= 1 else Action.D
        if prev_success:
            threshold_2_3 = 2.0 * self.m / 3.0
            if prev_cooperators >= threshold_2_3:
                return Action.C
            else:
                denominator = max(self.n - self.m / 2.0, 0.1)
                numerator = max(prev_cooperators - self.m / 2.0, 0.0)
                prob = numerator / denominator
                return Action.C if random.random() < prob else Action.D
        elif prev_cooperators >= self.m - 1:
            return Action.C
        elif prev_cooperators >= self.m / 2.0:
            return Action.C if random.random() < 0.7 else Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_447(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Embodies collective mindset by treating the game as a coordination problem.
    Maximizes expected collective payoff while protecting against free-riding through:
    - Unconditional cooperation in round 1 (trust signal)
    - Adaptive threshold-based decisions in middle rounds (forgiving early, stricter late)
    - Strategic last-round behavior (cooperate if threshold was met, defect otherwise)
    - Edge case handling for persistent defection and fragmentation scenarios
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        prev_round_idx = round_t - 1
        cooperators_prev = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        coop_rate = cooperators_prev / self.n_players
        if round_t == self.n_rounds - 1:
            if cooperators_prev >= self.m:
                return Action.C
            else:
                return Action.D
        rounds_remaining = self.n_rounds - round_t
        patience_factor = 0.8 + 0.2 * rounds_remaining / self.n_rounds
        threshold = self.m / self.n_players * patience_factor
        defection_streak = 0
        if round_t >= 2:
            for i in range(max(0, round_t - 2), round_t):
                cooperators_at_i = int(np.sum(history.opponent_actions[i, :]))
                if cooperators_at_i < self.m:
                    defection_streak += 1
        if defection_streak >= 2 and cooperators_prev < self.m:
            if cooperators_prev < self.n_players / 2:
                return Action.D
        if round_t > 2 * self.n_rounds / 3:
            remaining_rounds = self.n_rounds - round_t
            if remaining_rounds > 0 and cooperators_prev < self.m:
                if cooperators_prev * (remaining_rounds + 1) < self.m:
                    return Action.D
        if self.m > 0.6 * self.n_players:
            initial_tolerance = 1.2 * (self.m / self.n_players)
        else:
            initial_tolerance = threshold
        if self.m <= 0.3 * self.n_players:
            low_threshold_strictness = 1.5 * self.m
        else:
            low_threshold_strictness = self.m * patience_factor
        if cooperators_prev >= self.m:
            return Action.C
        elif cooperators_prev >= 0.6 * threshold:
            return Action.C
        elif cooperators_prev >= (low_threshold_strictness / self.n_players if self.m <= 0.3 * self.n_players else threshold):
            if self.m > 0.6 * self.n_players:
                if cooperators_prev >= initial_tolerance * self.n_players:
                    return Action.C
            return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_448(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Dynamically adjusts cooperation based on observed collective behavior and game phase.
    Balances individual security with collective benefit through threshold-based reasoning.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.failure_locked = False
        self.success_locked = False
        self.rounds_below_threshold = 0
        self.cooperation_history = []

    def _classify_phase(self, round_num: int) -> str:
        """Classify which phase of the game we're in."""
        third = self.n_rounds / 3.0
        if round_num <= third:
            return 'EARLY'
        elif round_num <= 2 * third:
            return 'MID'
        else:
            return 'LATE'

    def _get_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate from previous round."""
        if len(history.opponent_actions) == 0:
            return 0.0
        last_round_opponents = history.opponent_actions[-1, :]
        opponent_cooperators = np.sum(last_round_opponents)
        my_last_action = history.my_actions[-1]
        total_cooperators = opponent_cooperators + (1 if my_last_action else 0)
        return total_cooperators / self.n_players

    def _should_cooperate_early(self, cooperation_rate: float) -> bool:
        """Early round cooperation decision logic."""
        threshold = (self.m - 1) / self.n_players
        return cooperation_rate >= threshold

    def _should_cooperate_mid(self, cooperation_rate: float) -> bool:
        """Mid round cooperation decision logic with lower threshold."""
        threshold = min((self.m - 1) / self.n_players, 0.5)
        return cooperation_rate >= threshold or cooperation_rate >= 0.5

    def _should_cooperate_late(self, cooperation_rate: float) -> bool:
        """Late round cooperation decision logic."""
        threshold = (self.m - 1) / self.n_players
        return cooperation_rate >= threshold - 0.15

    def _update_lock_states(self, history: PlayerHistory, round_num: int) -> None:
        """Update failure and success lock states based on history."""
        if len(history.opponent_actions) == 0:
            return
        last_round_opponents = history.opponent_actions[-1, :]
        opponent_cooperators = np.sum(last_round_opponents)
        my_last_action = history.my_actions[-1]
        total_cooperators = opponent_cooperators + (1 if my_last_action else 0)
        if total_cooperators >= self.m:
            self.success_locked = True
        cooperation_rate = total_cooperators / self.n_players
        threshold = (self.m - 1) / self.n_players
        if cooperation_rate < threshold:
            self.rounds_below_threshold += 1
            if self.rounds_below_threshold >= 2:
                self.failure_locked = True
        else:
            self.rounds_below_threshold = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            prob = max(0.4, (self.m - 1) / self.n_players)
            return Action.C if random.random() < prob else Action.D
        if self.failure_locked:
            return Action.D
        cooperation_rate = self._get_cooperation_rate(history)
        phase = self._classify_phase(round_num)
        should_cooperate = False
        if self.success_locked:
            should_cooperate = True
        elif phase == 'EARLY':
            should_cooperate = self._should_cooperate_early(cooperation_rate)
        elif phase == 'MID':
            should_cooperate = self._should_cooperate_mid(cooperation_rate)
        else:
            should_cooperate = self._should_cooperate_late(cooperation_rate)
        decision = Action.C if should_cooperate else Action.D
        self._update_lock_states(history, round_num)
        return decision

class Strategy_COLLECTIVE_449(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by adapting cooperation
    based on observed cooperation rates, while maintaining credibility and avoiding
    exploitation. Recognizes that payoffs depend critically on reaching threshold m.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        coop_rate_prev = prev_round_cooperators / self.n
        rounds_left = self.r - current_round - 1
        threshold_feasibility = (self.m - 1) / (self.n - 1) if self.n > 1 else 1.0
        if rounds_left == 0:
            if coop_rate_prev >= (self.m - 1) / self.n:
                return Action.C
            else:
                return Action.D
        if coop_rate_prev >= self.m / self.n:
            return Action.C
        if coop_rate_prev >= threshold_feasibility:
            return Action.C
        if coop_rate_prev >= threshold_feasibility * 0.5:
            probability = coop_rate_prev / threshold_feasibility * (rounds_left / self.r)
            if random.random() < probability:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_450(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances individual rationality with collective benefit through conditional
    cooperation that gracefully degrades under adversarial pressure while maintaining
    cooperation when the threshold for collective success is likely to be met.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.r - 1:
            return self._last_round_decision(history)
        return self._adaptive_threshold_decision(round_number, history)

    def _last_round_decision(self, history: PlayerHistory) -> Action:
        """
        Last round decision: cooperate if cooperation has been sustainable,
        defect if it's been failing.
        """
        total_cooperators = np.sum(history.opponent_actions, axis=1)
        avg_cooperation = np.mean(total_cooperators) / self.n
        threshold_upper = self.m / self.n + 0.15 * (self.m / self.n)
        if avg_cooperation >= threshold_upper:
            return Action.C
        else:
            return Action.D

    def _adaptive_threshold_decision(self, round_number: int, history: PlayerHistory) -> Action:
        """
        Middle rounds: use recent cooperation window with adaptive thresholds
        and probabilistic degradation in uncertainty zones.
        """
        window_size = max(3, self.r // 4)
        total_cooperators = np.sum(history.opponent_actions, axis=1)
        recent_window = total_cooperators[-window_size:]
        recent_rate = np.mean(recent_window) / self.n
        threshold = self.m / self.n
        buffer = 0.15 * threshold
        threshold_upper = threshold + buffer
        threshold_lower = threshold - buffer
        if recent_rate >= threshold_upper:
            return Action.C
        elif recent_rate >= threshold_lower:
            p_cooperate = recent_rate / threshold_upper if threshold_upper > 0 else 0.5
            p_cooperate = max(0.0, min(1.0, p_cooperate))
            if random.random() < p_cooperate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_451(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective benefit by cooperating when
    the expected number of cooperators meets or exceeds the threshold m, and
    defecting otherwise. Uses conditional cooperation with failure streak tracking
    to avoid repeated sucker's payoffs.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.failure_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            threshold_ratio = self.m / self.n
            if threshold_ratio <= 0.5:
                return Action.C
            else:
                return Action.D
        previous_round_idx = round_number - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[previous_round_idx, :]))
        if history.my_actions[previous_round_idx]:
            total_cooperators = cooperators_last_round + 1
        else:
            total_cooperators = cooperators_last_round
        expected_cooperators = total_cooperators
        if expected_cooperators >= self.m:
            self.failure_streak = 0
            return Action.C
        else:
            self.failure_streak += 1
            if self.failure_streak >= 2:
                return Action.D
            else:
                return Action.D

class Strategy_COLLECTIVE_452(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances individual security with collective welfare by implementing adaptive
    threshold-based cooperation that responds to observed cooperation levels while
    maintaining credible commitment to group success.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            if self.m <= 2 * self.n / 3:
                return Action.C
            else:
                return Action.D
        prev_coop_count = int(sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            prev_coop_count += 1
        remaining = self.r - round_t
        if prev_coop_count >= self.m:
            return Action.C
        if prev_coop_count >= self.m - 1 and remaining >= 1:
            return Action.C
        prev_coop_rate = prev_coop_count / self.n
        threshold_rate = self.m / self.n
        denominator = 2 * remaining + 1
        if denominator > 0:
            escalation_threshold = threshold_rate - 1.0 / denominator
        else:
            escalation_threshold = threshold_rate
        if prev_coop_rate >= escalation_threshold:
            return Action.C
        if round_t == self.r - 1 and prev_coop_count >= self.m - 1:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_453(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances collective welfare, individual robustness, and adaptive learning by:
    - Cooperating in round 1 to signal willingness and gather information
    - Mid-game: Adapting based on observed cooperation rates and trends
    - Endgame: Making final decisions based on threshold achievability
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_ratio = self.m / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        is_final_round = current_round == self.n_rounds - 1
        last_round_opponent_actions = history.opponent_actions[current_round - 1, :]
        last_round_cooperators = np.sum(last_round_opponent_actions)
        last_round_total_cooperators = last_round_cooperators + (1 if history.my_actions[current_round - 1] else 0)
        last_round_cooperation_rate = last_round_total_cooperators / self.n_players
        if is_final_round:
            if last_round_cooperation_rate >= self.threshold_ratio:
                return Action.C
            else:
                current_cooperators = last_round_total_cooperators
                needed_to_reach_m = self.m - current_cooperators
                if needed_to_reach_m <= 1:
                    return Action.C
                else:
                    return Action.D
        if last_round_cooperation_rate >= self.threshold_ratio:
            return Action.C
        if current_round == 1:
            defection_count = self.n_players - last_round_total_cooperators
            if defection_count < self.n_players - self.m:
                return Action.C
            else:
                return Action.D
        all_previous_rounds = history.opponent_actions[:current_round, :]
        my_all_previous_actions = history.my_actions[:current_round]
        total_cooperators_per_round = np.sum(all_previous_rounds, axis=1) + my_all_previous_actions.astype(int)
        cooperation_rates = total_cooperators_per_round / self.n_players
        avg_cooperation_rate = np.mean(cooperation_rates)
        is_declining = last_round_cooperation_rate < avg_cooperation_rate
        if avg_cooperation_rate >= self.threshold_ratio:
            return Action.C
        if avg_cooperation_rate < self.threshold_ratio and is_declining:
            return Action.D
        if self.threshold_ratio <= avg_cooperation_rate < self.threshold_ratio + 0.15:
            shortfall = self.m - last_round_total_cooperators
            if shortfall <= 2:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_454(BaseStrategy):
    """
    Adaptive Threshold Cooperator (ATC) for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Defecting early to avoid naive exploitation
    2. Cooperating when threshold achievement is likely
    3. Committing to cooperation in final 30% of rounds
    4. Responding to cooperation trends and signals
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        opponent_coop_history = history.opponent_actions[:round_num, :]
        if round_num == 1:
            observed_coop_count = np.sum(opponent_coop_history[0, :])
            observed_coop_rate = observed_coop_count / (self.n_players - 1) if self.n_players > 1 else 0.0
            cooperation_trend = 0.0
        else:
            observed_coop_count = np.sum(opponent_coop_history, axis=1)
            observed_coop_rate = np.mean(observed_coop_count) / (self.n_players - 1) if self.n_players > 1 else 0.0
            first_three = min(3, round_num)
            last_three = min(3, round_num)
            if round_num >= 3:
                trend_early = np.mean(observed_coop_count[:3]) / (self.n_players - 1)
                trend_recent = np.mean(observed_coop_count[-3:]) / (self.n_players - 1)
                cooperation_trend = trend_recent - trend_early
            else:
                cooperation_trend = 0.0
        threshold_rate = self.m / self.n_players * 0.9
        late_game_threshold = math.ceil(0.3 * self.n_rounds)
        rounds_remaining = self.n_rounds - round_num
        in_late_game = round_num >= self.n_rounds - late_game_threshold
        threshold_narrowly_missed = False
        if round_num > 1:
            last_round_cooperators = np.sum(opponent_coop_history[round_num - 1, :])
            if history.my_actions[round_num - 1]:
                last_round_cooperators += 1
            threshold_narrowly_missed = last_round_cooperators >= self.m - 2 and last_round_cooperators < self.m
        if observed_coop_rate >= threshold_rate and cooperation_trend >= 0:
            return Action.C
        if in_late_game:
            return Action.C
        if threshold_narrowly_missed and round_num > 1:
            return Action.C
        if round_num > 3 and observed_coop_rate > 0.6:
            return Action.C
        if round_num == 1:
            round_0_cooperators = np.sum(opponent_coop_history[0, :])
            if round_0_cooperators >= self.m:
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_455(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Starting with cooperation to establish baseline
    2. Adapting based on observed cooperation rates
    3. Withdrawing cooperation when threshold appears unreachable
    4. Adjusting for endgame dynamics in final rounds
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_rate = self.m / self.n_players
        self.consecutive_failures = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        prev_round_idx = current_round - 1
        opponent_cooperators_prev = int(sum(history.opponent_actions[prev_round_idx, :]))
        total_cooperators_prev = opponent_cooperators_prev + int(history.my_actions[prev_round_idx])
        cooperation_rate = total_cooperators_prev / self.n_players
        rounds_remaining = self.n_rounds - current_round
        endgame_threshold = self.n_rounds / 3
        if current_round == self.n_rounds - 1:
            if cooperation_rate >= self.threshold_rate:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= self.threshold_rate:
            self.consecutive_failures = 0
            return Action.C
        gap = self.threshold_rate - 1 / self.n_players
        if cooperation_rate >= gap and rounds_remaining > endgame_threshold:
            self.consecutive_failures += 1
            return Action.C
        if rounds_remaining <= endgame_threshold:
            self.consecutive_failures += 1
            return Action.D
        if cooperation_rate < gap:
            self.consecutive_failures += 1
            return Action.D
        return Action.C

class Strategy_COLLECTIVE_456(BaseStrategy):
    """
    Threshold Sentinel Strategy for Collective Risk Dilemma.
    
    Operates on a collective surplus principle: cooperate when doing so creates
    positive-sum outcomes for the group, while remaining vigilant against exploitation.
    The strategy focuses on reliably reaching threshold m while minimizing individual
    exploitation through adaptive threshold response.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            last_round_cooperators = int(sum(history.opponent_actions[-1, :]))
            if history.my_actions[-1]:
                last_round_cooperators += 1
            if last_round_cooperators >= self.m:
                return Action.C
            if last_round_cooperators == self.m - 1:
                historical_coop_rate = self._calculate_historical_coop_rate(history, current_round)
                if historical_coop_rate > 0.5:
                    return Action.C
            return Action.D
        last_round_cooperators = int(sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            last_round_cooperators += 1
        historical_coop_rate = self._calculate_historical_coop_rate(history, current_round)
        rounds_remaining = self.r - current_round
        urgency_factor = rounds_remaining / self.r
        if last_round_cooperators >= self.m:
            return Action.C
        if last_round_cooperators == self.m - 1:
            return Action.C
        threshold_momentum = math.ceil(self.m * 0.7)
        if last_round_cooperators >= threshold_momentum:
            return Action.C
        if historical_coop_rate > 0.5 and urgency_factor > 0.25:
            return Action.C
        return Action.D

    def _calculate_historical_coop_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the historical cooperation rate across all previous rounds.
        Avoids division by zero when current_round is 1.
        """
        if current_round <= 1:
            return 0.0
        total_cooperators = 0
        for round_idx in range(current_round):
            round_cooperators = int(sum(history.opponent_actions[round_idx, :]))
            if history.my_actions[round_idx]:
                round_cooperators += 1
            total_cooperators += round_cooperators
        total_possible = self.n * current_round
        if total_possible == 0:
            return 0.0
        return total_cooperators / total_possible

class Strategy_COLLECTIVE_457(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances collective welfare, individual rationality, and robustness by:
    1. Cooperating in round 1 to signal good faith
    2. Adaptively tracking defection rate and responding to group behavior
    3. Defecting in final round (unless perfect cooperation history)
    4. Using last-round feedback in middle rounds to decide conditional cooperation
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        cooperators_per_round = np.sum(history.opponent_actions, axis=1) + history.my_actions
        rounds_below_threshold = np.sum(cooperators_per_round < self.m)
        defection_rate = rounds_below_threshold / round_num
        if round_num == self.n_rounds - 1:
            all_previous_at_threshold = rounds_below_threshold == 0
            cooperators_last_round = cooperators_per_round[-1]
            if all_previous_at_threshold and cooperators_last_round >= self.m:
                return Action.C
            return Action.D
        high_defection_threshold = 0.5 * (1 - 1 / self.n_players)
        if defection_rate > high_defection_threshold:
            return Action.D
        if defection_rate <= 0.2:
            return Action.C
        cooperators_last_round = cooperators_per_round[-1]
        if cooperators_last_round >= self.m - 1:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_458(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances collective welfare maximization with individual security by:
    1. Cooperating in round 1 to seed cooperation
    2. Adaptively cooperating in middle rounds based on observed cooperation rates
    3. Defecting in final round to maximize individual payoff
    4. Only risking cooperation when threshold achievement seems probable
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.n_rounds - 1:
            return Action.D
        past_cooperators = int(np.sum(history.my_actions) + np.sum(history.opponent_actions))
        total_past_decisions = round_number * self.n_players
        if total_past_decisions == 0:
            obs_coop_rate = 0.0
        else:
            obs_coop_rate = past_cooperators / total_past_decisions
        expected_others = math.floor(obs_coop_rate * (self.n_players - 1))
        expected_cooperators = expected_others + 1
        threshold_achievable = expected_cooperators >= self.m
        if obs_coop_rate > 0.6:
            return Action.C
        if obs_coop_rate < 0.15:
            return Action.D
        if threshold_achievable and obs_coop_rate >= 0.4:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_459(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective benefit through conditional reciprocity,
    adaptive calibration based on observed cooperation rates, and phase-dependent decision rules.
    Cooperates when threshold appears achievable, defects when recovery is mathematically impossible.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        all_cooperations = history.opponent_actions.sum(axis=1)
        total_coop_count = all_cooperations.sum()
        my_coop_count = history.my_actions.sum()
        total_all_cooperations = total_coop_count + my_coop_count
        total_possible = self.n * round_num
        if total_possible > 0:
            coop_rate = total_all_cooperations / total_possible
        else:
            coop_rate = 0.0
        threshold_rate = self.m / self.n
        deficit = threshold_rate - coop_rate
        phase_boundary_early = max(1, math.ceil(self.r / 3))
        phase_boundary_middle = max(1, math.ceil(2 * self.r / 3))
        if round_num <= phase_boundary_early:
            return self._early_phase(coop_rate, threshold_rate, deficit)
        elif round_num <= phase_boundary_middle:
            return self._middle_phase(coop_rate, threshold_rate, deficit, round_num)
        else:
            return self._endgame_phase(coop_rate, threshold_rate, total_all_cooperations, round_num)

    def _early_phase(self, coop_rate: float, threshold_rate: float, deficit: float) -> Action:
        """Early rounds: exploratory phase (rounds 1 to ceil(r/3))"""
        if coop_rate >= threshold_rate:
            return Action.C
        if coop_rate >= threshold_rate * 0.5:
            return Action.C if random.random() < 0.6 else Action.D
        return Action.C if random.random() < 0.3 else Action.D

    def _middle_phase(self, coop_rate: float, threshold_rate: float, deficit: float, round_num: int) -> Action:
        """Middle rounds: calibration phase (ceil(r/3) + 1 to ceil(2r/3))"""
        if deficit <= 0.1:
            return Action.C
        if deficit <= 0.25:
            prob = min(1.0, coop_rate + 0.15)
            return Action.C if random.random() < prob else Action.D
        remaining_rounds = self.r - round_num
        if remaining_rounds > 0:
            current_cooperations = self.m * self.n * round_num - (self.n - self.m) * round_num
            coop_needed_total = self.m * remaining_rounds
            current_total = int(coop_rate * self.n * round_num)
            if coop_needed_total <= self.n * remaining_rounds:
                required_rate = coop_needed_total / (self.n * remaining_rounds)
                prob = min(1.0, required_rate + random.uniform(-0.05, 0.05))
                prob = max(0.0, prob)
                return Action.C if random.random() < prob else Action.D
        return Action.D

    def _endgame_phase(self, coop_rate: float, threshold_rate: float, total_all_cooperations: int, round_num: int) -> Action:
        """Endgame phase: final rounds (ceil(2r/3) + 1 to r)"""
        remaining_rounds = self.r - round_num + 1
        if coop_rate >= threshold_rate:
            if remaining_rounds == 1:
                return Action.D
            else:
                return Action.C
        cooperations_needed = self.m * remaining_rounds - total_all_cooperations
        total_possible_remaining = self.n * remaining_rounds
        if cooperations_needed > 0 and cooperations_needed <= total_possible_remaining:
            required_rate = cooperations_needed / total_possible_remaining
            if required_rate <= coop_rate * 1.2:
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_460(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare through:
    1. Bootstrap phase: Signal willingness and gather data
    2. Adjustment phase: Stabilize cooperation around threshold with punishments
    3. Endgame phase: Defect if unrecoverable, cooperate only in stable equilibria
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.bootstrap_end = math.floor(self.r / 3)
        self.adjustment_end = math.floor(2 * self.r / 3)
        self.punishment_rounds_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        coop_last_round = self._get_cooperation_rate(history, round_num - 1, round_num - 1)
        threshold_ratio = self.m / self.n
        if self.punishment_rounds_remaining > 0:
            self.punishment_rounds_remaining -= 1
            return Action.D
        if round_num <= self.bootstrap_end:
            return Action.C if coop_last_round >= threshold_ratio else Action.D
        if round_num <= self.adjustment_end:
            return self._adjustment_phase(history, round_num, coop_last_round, threshold_ratio)
        return self._endgame_phase(history, round_num, threshold_ratio)

    def _get_cooperation_rate(self, history: PlayerHistory, start_round: int, end_round: int) -> float:
        """Calculate average cooperation rate across rounds [start_round, end_round] inclusive."""
        if start_round > end_round or start_round < 0 or end_round >= len(history.opponent_actions):
            return 0.0
        total_cooperators = 0
        num_rounds = end_round - start_round + 1
        for r in range(start_round, end_round + 1):
            total_cooperators += sum(history.opponent_actions[r, :])
        return total_cooperators / (self.n * num_rounds) if num_rounds > 0 else 0.0

    def _get_defection_trend(self, history: PlayerHistory, round_num: int) -> bool:
        """Check if defections are trending upward in last 3 rounds."""
        if round_num < 3:
            return False
        defection_counts = []
        for r in range(max(0, round_num - 3), round_num):
            defections = self.n - int(sum(history.opponent_actions[r, :]))
            defection_counts.append(defections)
        return len(defection_counts) > 1 and defection_counts[-1] > defection_counts[0]

    def _adjustment_phase(self, history: PlayerHistory, round_num: int, coop_last_round: float, threshold_ratio: float) -> Action:
        """Adjustment phase decision logic."""
        start = max(0, round_num - 5)
        stability_score = self._get_cooperation_rate(history, start, round_num - 1)
        last_round_cooperators = max(1, int(sum(history.opponent_actions[round_num - 1, :])))
        efficiency = last_round_cooperators / self.m if self.m > 0 else 0.0
        if stability_score >= 0.95 * threshold_ratio:
            return Action.C
        if efficiency < 1.0 and self._get_defection_trend(history, round_num):
            self.punishment_rounds_remaining = 1
            return Action.D
        if efficiency > 1.2:
            return Action.C
        return Action.C if coop_last_round >= threshold_ratio else Action.D

    def _endgame_phase(self, history: PlayerHistory, round_num: int, threshold_ratio: float) -> Action:
        """Endgame phase decision logic."""
        rounds_left = self.r - round_num
        my_payoff_so_far = float(np.sum(history.my_payoffs[:round_num]))
        target_payoff = 2.0 * round_num
        payoff_deficit = target_payoff - my_payoff_so_far
        if payoff_deficit > (self.k - 1) * rounds_left:
            return Action.D
        start = max(0, round_num - 5)
        coop_last_5 = self._get_cooperation_rate(history, start, round_num - 1)
        if coop_last_5 >= 0.9 * threshold_ratio:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_461(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by conditionally cooperating
    based on empirical evidence of collective success. Tracks the success rate of reaching
    the cooperation threshold (m players cooperating) over a rolling window of recent rounds,
    and cooperates only when the success rate exceeds the threshold of (m/n) + 0.1.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        lookback_window = min(5, state.round_number)
        successful_rounds = 0
        start_idx = state.round_number - lookback_window
        for round_idx in range(start_idx, state.round_number):
            opponent_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
            total_cooperators = opponent_cooperators + (1 if history.my_actions[round_idx] else 0)
            if total_cooperators >= self.m:
                successful_rounds += 1
        success_rate = successful_rounds / lookback_window if lookback_window > 0 else 0.0
        threshold = self.m / self.n_players + 0.1
        if success_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_462(BaseStrategy):
    """
    Adaptive Threshold Reciprocity strategy for Collective Risk Dilemma.
    
    Balances collective welfare with protection against exploitation by:
    1. Probing cooperation in round 1
    2. Adapting based on observed cooperation rates and trends
    3. Adjusting behavior near the threshold with trend analysis
    4. Attempting recovery from defection spirals
    5. Making final-round decisions based on confidence in threshold achievement
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.n_rounds - 1:
            return self._final_round_decision(history)
        return self._adaptive_round_decision(round_num, history)

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """
        Final round: Only cooperate if we're confident threshold will be met.
        """
        final_coop_count = np.sum(history.opponent_actions[-1, :])
        final_coop_rate = final_coop_count / self.n_players
        threshold_rate = (self.m - 1) / self.n_players
        if final_coop_rate >= threshold_rate:
            return Action.C
        return Action.D

    def _adaptive_round_decision(self, round_num: int, history: PlayerHistory) -> Action:
        """
        Rounds 1 to r-2: Adaptive decision based on cooperation metrics and trends.
        """
        recent_coop_count = np.sum(history.opponent_actions[-1, :])
        recent_coop_rate = recent_coop_count / self.n_players
        trend = self._calculate_trend(round_num, history)
        my_prev_action = history.my_actions[-1]
        threshold_rate = self.m / self.n_players
        near_threshold_rate = (self.m - 1) / self.n_players
        low_rate = (self.m - 2) / self.n_players
        if recent_coop_rate >= threshold_rate:
            return Action.C
        if recent_coop_rate >= near_threshold_rate and trend == 'improving':
            return Action.C
        if recent_coop_rate <= low_rate and my_prev_action:
            return Action.C
        return Action.D

    def _calculate_trend(self, round_num: int, history: PlayerHistory) -> str:
        """
        Compare cooperation rate in the last round with the round before.
        Returns "improving", "stable", or "declining".
        """
        recent_coop_count = np.sum(history.opponent_actions[-1, :])
        recent_coop_rate = recent_coop_count / self.n_players
        if round_num <= 1:
            return 'stable'
        prior_coop_count = np.sum(history.opponent_actions[-2, :])
        prior_coop_rate = prior_coop_count / self.n_players
        epsilon = 1e-09
        if recent_coop_rate > prior_coop_rate + epsilon:
            return 'improving'
        elif recent_coop_rate < prior_coop_rate - epsilon:
            return 'declining'
        else:
            return 'stable'

class Strategy_COLLECTIVE_463(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual security with collective benefit by treating the minimum
    threshold m as a focal point. Cooperates when believing enough others will,
    creating self-fulfilling equilibrium at or above threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        k = self.game_description.k
        round_num = state.round_number
        if round_num == 0:
            p_initial = min(0.6, m / n)
            return Action.C if random.random() < p_initial else Action.D
        self._update_cooperation_history(history)
        phase_early_end = r / 3
        phase_late_start = 2 * r / 3
        if round_num < phase_early_end:
            phase = 'Early'
        elif round_num < phase_late_start:
            phase = 'Mid'
        else:
            phase = 'Late'
        if round_num == r - 1:
            return self._last_round_decision(history)
        cooperators_last_round = int(np.sum(history.opponent_actions[round_num - 1, :]))
        cooperation_momentum = (cooperators_last_round - m) / n
        if cooperation_momentum > 0.1:
            return Action.C
        if cooperation_momentum >= -0.15 and phase == 'Early':
            return Action.C if random.random() < 0.6 else Action.D
        if cooperation_momentum >= -0.05:
            return Action.C if random.random() < 0.5 else Action.D
        if cooperation_momentum < -0.15 and phase == 'Late':
            return Action.D
        baseline_prob = max(0.2, m / n - 0.1)
        return Action.C if random.random() < baseline_prob else Action.D

    def _update_cooperation_history(self, history: PlayerHistory) -> None:
        """Update cooperation history with counts from all completed rounds."""
        n_rounds_completed = len(history.my_actions)
        if len(self.cooperation_history) < n_rounds_completed:
            for round_idx in range(len(self.cooperation_history), n_rounds_completed):
                cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
                self.cooperation_history.append(cooperators)

    def _last_round_decision(self, history: PlayerHistory) -> Action:
        """Decision logic for the final round."""
        n = self.game_description.n_players
        m = self.game_description.m
        if not self.cooperation_history:
            return Action.C
        cooperation_history_average = np.mean(self.cooperation_history)
        if cooperation_history_average >= m / n:
            if cooperation_history_average >= (m - 1) / n:
                return Action.C
            needed_cooperators = m - int(cooperation_history_average * n) + 1
            if needed_cooperators >= 1:
                return Action.C
        if cooperation_history_average < 0.4:
            return Action.D
        prob = (cooperation_history_average - 0.3) / 0.4
        prob = max(0.0, min(1.0, prob))
        return Action.C if random.random() < prob else Action.D

class Strategy_COLLECTIVE_464(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances individual risk management with collective welfare by dynamically
    adjusting cooperation based on observed cooperation rates, deficit to threshold,
    and remaining rounds. Recognizes that reaching m cooperators provides mutual
    benefit (payoff +k), making coordination solvable through adaptive threshold-matching.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_idx = round_num - 1
        prev_cooperators = int(sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            prev_cooperators += 1
        cooperation_rate = prev_cooperators / self.n if self.n > 0 else 0
        deficit = self.m - prev_cooperators
        rounds_remaining = self.r - round_num
        non_cooperators_prev = self.n - prev_cooperators
        if prev_cooperators >= self.m:
            stability_threshold = self.m / self.n * 1.1
            if cooperation_rate >= stability_threshold:
                return Action.C
            elif rounds_remaining <= 2:
                return Action.D
            else:
                return Action.C
        else:
            if deficit <= 1:
                deficit_correction = deficit / max(non_cooperators_prev, 1)
                if deficit_correction >= 0.4:
                    return Action.C
            if deficit > rounds_remaining * 0.5 and rounds_remaining > 0:
                return Action.D
            low_coop_threshold = self.m / self.n * 0.8
            if cooperation_rate < low_coop_threshold:
                if rounds_remaining <= 1:
                    return Action.D
                else:
                    return Action.D
            else:
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_465(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances collective survival (ensuring threshold m is met) with individual security
    (minimizing exploitation). Uses adaptive probabilistic cooperation based on the gap
    between current cooperators and the threshold, with round-position adjustments.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            if self.m / self.n < 0.5:
                return Action.C
            else:
                return Action.C if random.random() < self.m / self.n else Action.D
        cooperators_last = int(np.sum(history.opponent_actions[round_num - 1, :]))
        if history.my_actions[round_num - 1]:
            cooperators_last += 1
        gap = self.m - cooperators_last
        defectors_available = self.n - self.m
        if gap > defectors_available:
            base_rate = 1.0
        elif gap > 0:
            base_rate = gap / self.m if self.m > 0 else 0.0
        else:
            base_rate = 0.1
        early_round_threshold = math.ceil(self.r / 3)
        if round_num <= early_round_threshold:
            base_rate += 0.1
        if round_num == self.r - 1:
            base_rate += 0.15
            if cooperators_last < 2:
                base_rate = min(self.m / self.n, 0.7)
        if cooperators_last > self.m:
            safety_margin_threshold = self.m + (self.n - self.m) / 2
            if cooperators_last > safety_margin_threshold:
                base_rate = 0.0
            elif cooperators_last == self.m:
                base_rate = 0.3
            else:
                base_rate = 0.0
        if round_num >= 2:
            recent_cooperators_prev = int(np.sum(history.opponent_actions[round_num - 2, :]))
            if history.my_actions[round_num - 2]:
                recent_cooperators_prev += 1
            if recent_cooperators_prev < 2 and cooperators_last < 2:
                base_rate = min(self.m / self.n, 0.4)
        final_rate = max(0.0, min(base_rate, 1.0))
        return Action.C if random.random() < final_rate else Action.D

class Strategy_COLLECTIVE_466(BaseStrategy):
    """
    Threshold Sentinel Strategy for Collective Risk Dilemma.
    
    Balances collective interest with self-protection by tracking cooperation deficit
    (the gap between observed cooperators and the minimum threshold m).
    
    Core logic:
    - Round 1: Cooperate to establish cooperativeness
    - Rounds 2 to r-1: Cooperate if threshold is achievable (deficit â‰¤ 1), defect otherwise
    - Final round: Cooperate if threshold is achievable (deficit â‰¤ 1), defect otherwise
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        last_round_opponent_actions = history.opponent_actions[current_round - 1, :]
        observed_cooperators_from_others = int(np.sum(last_round_opponent_actions))
        deficit_threshold = self.m - 1
        cooperation_deficit = deficit_threshold - observed_cooperators_from_others
        is_final_round = current_round == self.n_rounds - 1
        if is_final_round:
            if cooperation_deficit <= 1:
                return Action.C
            else:
                return Action.D
        elif cooperation_deficit <= 0:
            return Action.C
        elif cooperation_deficit == 1:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_467(BaseStrategy):
    """
    Adaptive Collective Threshold Strategy (ACTS)
    
    Balances individual security with collective benefit through:
    1. Early exploration to probe cooperation landscape
    2. Reciprocation of observed cooperation patterns
    3. Threshold-seeking to identify minimum viable coalition
    4. Graceful degradation when cooperation fails
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num < 3 and round_num < self.n_rounds - 1:
            c_prev = int(sum(history.opponent_actions[round_num - 1, :])) + int(history.my_actions[round_num - 1])
            if c_prev >= self.m - 1:
                return Action.C
            else:
                return Action.D
        if round_num == self.n_rounds - 1:
            recent_rounds_start = max(0, round_num - 3)
            recent_rounds = history.opponent_actions[recent_rounds_start:round_num, :]
            my_recent = history.my_actions[recent_rounds_start:round_num]
            stability = self._calculate_stability(recent_rounds, my_recent)
            c_prev = int(sum(history.opponent_actions[round_num - 1, :])) + int(history.my_actions[round_num - 1])
            if stability >= 0.67 or c_prev >= self.m:
                return Action.C
            else:
                return Action.D
        c_prev = int(sum(history.opponent_actions[round_num - 1, :])) + int(history.my_actions[round_num - 1])
        recent_rounds_start = max(0, round_num - 3)
        recent_rounds = history.opponent_actions[recent_rounds_start:round_num, :]
        my_recent = history.my_actions[recent_rounds_start:round_num]
        stability = self._calculate_stability(recent_rounds, my_recent)
        if stability >= 0.67:
            return Action.C
        if self.m - 1 <= c_prev < self.m + 2:
            return Action.C
        if 0 < c_prev < self.m - 1:
            if history.my_actions[round_num - 1]:
                return Action.D
            else:
                return Action.D
        return Action.D

    def _calculate_stability(self, recent_rounds: NDArray[np.bool_], my_recent: NDArray[np.bool_]) -> float:
        """
        Calculate stability measure as fraction of recent rounds where threshold was met.
        Threshold is met if number of cooperators >= m (including self).
        """
        if len(recent_rounds) == 0:
            return 0.0
        success_count = 0
        for i in range(len(recent_rounds)):
            cooperators = int(sum(recent_rounds[i, :])) + int(my_recent[i])
            if cooperators >= self.m:
                success_count += 1
        return success_count / len(recent_rounds) if len(recent_rounds) > 0 else 0.0

class Strategy_COLLECTIVE_468(BaseStrategy):
    """
    Adaptive Collective Threshold Strategy (ACTS)
    
    Balances individual rationality with collective welfare through conditional commitment.
    Cooperates initially to signal disposition, adapts based on observed cooperation rates,
    and makes final decisions based on historical patterns.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        if self.m >= self.n - 1:
            self.threshold_factor = 1.25
        elif self.m == 2:
            self.threshold_factor = 1.05
        else:
            self.threshold_factor = 1.15

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round < self.r - 1:
            return self._main_phase_decision(history, current_round)
        if current_round == self.r - 1:
            return self._final_round_decision(history)
        return Action.D

    def _main_phase_decision(self, history: PlayerHistory, current_round: int) -> Action:
        """
        Main phase decision (rounds 1 to r-2).
        Uses cooperation rate from previous round to decide.
        """
        c_prev = int(sum(history.opponent_actions[current_round - 1, :]))
        cooperation_rate = c_prev / self.n
        threshold_min = self.m / self.n
        if cooperation_rate >= threshold_min * self.threshold_factor:
            return Action.C
        elif cooperation_rate >= threshold_min * 0.5:
            p_adaptive = c_prev / self.m
            if self.k > 5:
                p_adaptive = min(1.0, p_adaptive * 1.1)
            if random.random() < p_adaptive:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """
        Final round decision (round r-1).
        Uses cumulative momentum across all previous rounds.
        """
        if self.r == 2:
            c_prev = int(sum(history.opponent_actions[0, :]))
            cooperation_rate = c_prev / self.n
            threshold_min = self.m / self.n
            if cooperation_rate >= threshold_min * 0.8:
                return Action.C
            else:
                return Action.D
        total_cooperations = int(np.sum(history.opponent_actions[:self.r - 1, :]))
        average_cooperators = total_cooperations / (self.r - 1)
        if average_cooperators >= self.m:
            return Action.C
        elif average_cooperators >= self.m * 0.8:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_469(BaseStrategy):
    """
    Adaptive Threshold Matching strategy for Collective Risk Dilemma.
    
    Cooperates in round 1 to signal good faith. In middle rounds, maintains cooperation
    if the threshold m is being met or historically close to it. Defects in the final round
    when the shadow of the future disappears. Adapts dynamically based on observed
    cooperation patterns to balance individual rationality with collective benefit.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.consecutive_below_threshold = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.n_rounds - 1:
            return Action.D
        cooperators_prev = int(np.sum(history.opponent_actions[round_number - 1, :]))
        my_action_prev = history.my_actions[round_number - 1]
        if my_action_prev:
            cooperators_prev += 1
        total_cooperations = int(np.sum(history.opponent_actions[:round_number, :]))
        if my_action_prev or round_number > 1:
            my_cooperations = int(np.sum(history.my_actions[:round_number]))
            total_cooperations += my_cooperations
        total_possible = round_number * self.n_players
        if total_possible > 0:
            cooperators_avg = total_cooperations / total_possible
        else:
            cooperators_avg = 0
        if cooperators_prev >= self.m:
            self.consecutive_below_threshold = 0
            return Action.C
        elif cooperators_prev < self.m and cooperators_avg >= (self.m - 1) / self.n_players:
            return Action.C
        elif cooperators_prev < self.m and cooperators_avg < (self.m - 1) / self.n_players:
            self.consecutive_below_threshold += 1
            return Action.D
        elif round_number == 1:
            prob = cooperators_prev / (self.m + 1)
            if random.random() < prob:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_470(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances collective welfare and individual protection by adapting cooperation
    based on observed cooperation rates across the game population. Uses an exploratory
    phase (first half) with generous thresholds and a consolidation phase (second half)
    with stricter thresholds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.cooperation_rate_baseline = self.m / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        cooperation_rate = self._calculate_cooperation_rate(history, round_number)
        is_first_half = round_number < self.n_rounds / 2.0
        if is_first_half:
            return self._decide_first_half(cooperation_rate)
        else:
            return self._decide_second_half(cooperation_rate)

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_number: int) -> float:
        """
        Calculate the cooperation rate from all observed previous rounds.
        cooperation_rate = (total cooperators observed) / (total player-rounds observed)
        """
        if round_number == 0:
            return 0.0
        total_cooperations = np.sum(history.opponent_actions[:round_number, :])
        total_player_rounds = round_number * self.n_players
        if total_player_rounds == 0:
            return 0.0
        return total_cooperations / total_player_rounds

    def _decide_first_half(self, cooperation_rate: float) -> Action:
        """
        First half (exploratory phase) decision logic.
        
        - If cooperation_rate >= baseline * 1.2: COOPERATE
        - If cooperation_rate >= baseline * 0.8: COOPERATE with probability = cooperation_rate
        - Otherwise: DEFECT
        """
        threshold_high = self.cooperation_rate_baseline * 1.2
        threshold_low = self.cooperation_rate_baseline * 0.8
        if cooperation_rate >= threshold_high:
            return Action.C
        elif cooperation_rate >= threshold_low:
            return Action.C if random.random() < cooperation_rate else Action.D
        else:
            return Action.D

    def _decide_second_half(self, cooperation_rate: float) -> Action:
        """
        Second half (consolidation phase) decision logic.
        
        - If cooperation_rate >= baseline: COOPERATE
        - Otherwise: DEFECT
        """
        if cooperation_rate >= self.cooperation_rate_baseline:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_471(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS) for Collective Risk Dilemma.
    
    Balances cooperation incentives with defection protection through adaptive learning.
    Cooperates in round 1 to signal intent, assesses viability in early rounds, maintains
    dynamic cooperation probability in sustained rounds, and optimizes final round individually.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.phase1_end = max(1, math.ceil(self.r / 3))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        observed_cooperators = int(np.sum(history.opponent_actions[:current_round, :]))
        if current_round < self.phase1_end:
            if observed_cooperators >= self.m - 1:
                return Action.C
            else:
                return Action.D
        if current_round == self.r - 1:
            if current_round > 0:
                prev_round_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
                if prev_round_cooperators >= self.m:
                    return Action.C
            return Action.D
        p_coop = (observed_cooperators + 1) / (self.n * current_round + 1)
        expected_next = p_coop * (self.n - 1)
        if expected_next + 1 >= self.m:
            if random.random() < p_coop:
                return Action.C
            else:
                return Action.D
        elif expected_next < self.m - 2:
            return Action.D
        else:
            threshold_prob = max(0.0, min(1.0, (self.m - expected_next) / self.n))
            if random.random() < threshold_prob:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_472(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) for Collective Risk Dilemma.
    
    Balances collective success (reaching threshold m) with individual rationality
    by conditionally cooperating based on observed cooperation rates from previous rounds.
    Defects only when cooperation is provably irrational or when we're far from threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        cooperators_last_round = int(sum(history.opponent_actions[round_num - 1, :]))
        cooperation_rate = cooperators_last_round / self.n
        threshold_rate = self.m / self.n
        if cooperation_rate >= threshold_rate:
            return Action.C
        if cooperation_rate == 0:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        deficit = self.m - cooperators_last_round
        cooperation_threshold = max(1, self.n // 4)
        if deficit <= cooperation_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_473(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    This strategy balances collective welfare maximization with individual security by:
    - Opening with cooperation (round 1) as a signal of good faith
    - Adapting to observed cooperation rates in continuation rounds
    - Applying a grace window (threshold - 0.15) to account for variance
    - Defecting in the final round (backward induction)
    - Exiting cooperation defensively when threshold is unachievable
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold = self.m / self.n_players
        self.grace_threshold = self.threshold - 0.15

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        prev_round_idx = current_round - 1
        prev_round_opponent_actions = history.opponent_actions[prev_round_idx, :]
        my_prev_action = history.my_actions[prev_round_idx]
        cooperators_prev = int(my_prev_action) + int(np.sum(prev_round_opponent_actions))
        coop_rate = cooperators_prev / self.n_players
        if coop_rate >= self.threshold:
            return Action.C
        elif coop_rate >= self.grace_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_474(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Cooperating in round 1 to establish baseline
    2. Tracking cooperation rates and responding to threshold feasibility
    3. Using probabilistic cooperation near the threshold to encourage others
    4. Defecting in final round if threshold unlikely
    
    The strategy is history-agnostic and focuses only on whether the current
    cooperation rate makes reaching m cooperators feasible.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        opponent_cooperators = sum(history.opponent_actions[-1, :])
        my_previous_action = history.my_actions[-1]
        total_cooperators = opponent_cooperators + (1 if my_previous_action else 0)
        observed_cooperation_rate = total_cooperators / self.n_players
        threshold_rate = self.m / self.n_players
        if round_number == self.n_rounds - 1:
            if observed_cooperation_rate >= threshold_rate:
                return Action.C
            else:
                return Action.D
        if observed_cooperation_rate >= threshold_rate:
            return Action.C
        elif observed_cooperation_rate >= threshold_rate - 1 / self.n_players:
            if random.random() < 0.8:
                return Action.C
            else:
                return Action.D
        elif observed_cooperation_rate >= threshold_rate - 2 / self.n_players:
            if random.random() < 0.3:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_475(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    - Cooperating proactively early to establish safety
    - Monitoring whether the collective meets the threshold
    - Defecting only when cooperation is demonstrably over-supplied
    - Adapting based on observed cooperation rates
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        cooperators_prev = int(np.sum(history.opponent_actions[round_num - 1, :]))
        if round_num == self.n_rounds - 1:
            return self._decide_final_round(cooperators_prev)
        return self._decide_middle_round(cooperators_prev, round_num)

    def _decide_final_round(self, cooperators_prev: int) -> Action:
        """
        Final round decision logic.
        """
        if cooperators_prev >= self.m:
            return Action.D
        if cooperators_prev >= self.m - 1:
            return Action.C
        if cooperators_prev >= self.m - 2 and self.m <= self.n_players / 2:
            return Action.C
        return Action.D

    def _decide_middle_round(self, cooperators_prev: int, round_num: int) -> Action:
        """
        Middle rounds (2 to r-1) decision logic.
        """
        if cooperators_prev >= self.m:
            return Action.D
        if cooperators_prev == self.m - 1:
            if round_num <= self.n_rounds / 2:
                return Action.C
            else:
                return Action.D
        if cooperators_prev < self.m - 1:
            return Action.C
        return Action.C

class Strategy_COLLECTIVE_476(BaseStrategy):
    """
    Adaptive Threshold Trust (ATT) Strategy for Collective Risk Dilemma.
    
    Balances individual security with collective benefit by adapting cooperation
    decisions based on observed cooperation rates, with special handling for edge cases.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        cooperators_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
        cooperation_rate = cooperators_last_round / self.n
        others_needed = max(0, self.m - 1)
        if self.n - 1 <= 0:
            cooperation_required = 0.0
        else:
            cooperation_required = others_needed / (self.n - 1)
        if self.n <= 3:
            buffer_multiplier = 0.8
        elif self.n > 10:
            buffer_multiplier = 0.6
        else:
            buffer_multiplier = 0.75
        if current_round == self.r - 1:
            if cooperation_rate >= cooperation_required:
                return Action.C
            else:
                return Action.D
        if self.m == self.n:
            cooperation_required = 1.0
            if cooperation_rate >= cooperation_required:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= cooperation_required:
            return Action.C
        elif cooperation_rate >= cooperation_required * buffer_multiplier:
            if current_round >= 2:
                cooperators_two_rounds_ago = int(sum(history.opponent_actions[current_round - 2, :]))
                trend = cooperators_last_round - cooperators_two_rounds_ago
                if trend >= 0:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_477(BaseStrategy):
    """
    Adaptive Threshold Sentinel: A strategy for Collective Risk Dilemma that balances
    individual rationality with collective benefit through intelligent monitoring and
    conditional cooperation based on threshold achievement likelihood.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        cooperators_prev = int(sum(history.opponent_actions[round_number - 1, :]))
        my_action_prev = history.my_actions[round_number - 1]
        total_cooperators_prev = cooperators_prev + (1 if my_action_prev else 0)
        if round_number == self.r - 1:
            if round_number == 0:
                avg_cooperators = 0.0
            else:
                cooperator_counts = []
                for t in range(round_number):
                    opp_coop = int(sum(history.opponent_actions[t, :]))
                    my_coop = 1 if history.my_actions[t] else 0
                    cooperator_counts.append(opp_coop + my_coop)
                avg_cooperators = sum(cooperator_counts) / len(cooperator_counts) if cooperator_counts else 0.0
            if avg_cooperators >= self.m:
                return Action.D
            elif avg_cooperators < self.m - 1:
                return Action.D
            else:
                return Action.C
        if total_cooperators_prev >= self.m:
            return Action.D
        if total_cooperators_prev + 1 >= self.m:
            return Action.C
        if total_cooperators_prev < self.m - 1:
            deficit = self.m - total_cooperators_prev - 1
            available_players = self.n - total_cooperators_prev - 1
            if available_players <= 0:
                return Action.D
            base_probability = deficit / available_players
            time_factor = (self.r - round_number - 1) / max(self.r - 1, 1) if self.r > 1 else 0.0
            adjusted_probability = base_probability * time_factor
            if random.random() < adjusted_probability:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_478(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Dynamically learns whether the cooperation threshold m is achievable and adapts
    across early, mid, and late game phases. Balances exploration, evidence-gathering,
    and commitment while remaining robust to both cooperators and defectors.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.early_threshold = math.ceil(self.r / 3)
        self.late_threshold = math.floor(2 * self.r / 3)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            if self.m <= math.ceil(self.n / 2):
                return Action.C
            else:
                return Action.D
        prev_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        successful_rounds = 0
        for round_idx in range(current_round):
            round_cooperators = int(sum(history.opponent_actions[round_idx, :])) + (1 if history.my_actions[round_idx] else 0)
            if round_cooperators >= self.m:
                successful_rounds += 1
        success_rate = successful_rounds / current_round if current_round > 0 else 0.5
        defection_streak = 0
        for round_idx in range(current_round - 1, -1, -1):
            round_cooperators = int(sum(history.opponent_actions[round_idx, :])) + (1 if history.my_actions[round_idx] else 0)
            if round_cooperators >= self.m:
                break
            defection_streak += 1
        any_prior_success = successful_rounds > 0
        if success_rate >= 0.5:
            return Action.C
        if prev_cooperators >= self.m - 1:
            return Action.C
        if current_round <= self.early_threshold:
            if prev_cooperators >= math.ceil(self.m / 2):
                return Action.C
        if current_round > self.late_threshold:
            if prev_cooperators >= self.m:
                return Action.C
        if defection_streak >= math.ceil(self.r / 4):
            if prev_cooperators >= self.m:
                return Action.C
        if current_round == self.r - 1:
            if success_rate >= 0.5 or any_prior_success:
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_479(BaseStrategy):
    """
    Collective Resilience Strategy (CRS): Balances individual rationality with collective welfare
    by adapting cooperation based on observed group cooperation rates and phase of the game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.halfway_point = math.floor(self.r / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num <= self.halfway_point:
            return Action.C
        if round_num == self.r - 1:
            return self._final_round_decision(history)
        return self._adaptive_decision(history, round_num)

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate overall cooperation rate from history so far."""
        if history is None or len(history.opponent_actions) == 0:
            return 0.0
        rounds_completed = len(history.opponent_actions)
        total_cooperators = np.sum(history.opponent_actions) + np.sum(history.my_actions)
        total_possible = rounds_completed * self.n
        if total_possible == 0:
            return 0.0
        return float(total_cooperators) / float(total_possible)

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """Phase 3: Final round - deterministic based on expected cooperators."""
        coop_rate = self._calculate_cooperation_rate(history)
        expected_cooperators = self.n * coop_rate
        if expected_cooperators >= self.m:
            return Action.C
        return Action.D

    def _adaptive_decision(self, history: PlayerHistory, round_num: int) -> Action:
        """Phase 2: Adaptive response based on cooperation rate."""
        coop_rate = self._calculate_cooperation_rate(history)
        threshold_high = (self.m - 0.5) / self.n
        threshold_medium = (self.m - 1.5) / self.n
        if coop_rate >= threshold_high:
            return Action.C
        if coop_rate >= threshold_medium:
            p_threshold = min(0.7, 1.0 + self.k - 1.0 / threshold_high)
            if random.random() < p_threshold:
                return Action.C
            return Action.D
        return Action.D

class Strategy_COLLECTIVE_480(BaseStrategy):
    """
    Adaptive Threshold Coordinator for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Seeding cooperation in round 1
    2. Adapting cooperation probability based on historical threshold success rate in middle rounds
    3. Defecting in the final round (subgame perfection)
    
    Uses probabilistic cooperation in rounds 2 through r-1 to avoid predictability
    while responding to empirical evidence of threshold achievement.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.risk_tolerance = (self.m - 1) / self.n_players
        self.safety_factor = 1.2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.n_rounds - 1:
            return Action.D
        threshold_success_rate = self._calculate_threshold_success_rate(history, round_number)
        coop_probability = self._compute_cooperation_probability(threshold_success_rate)
        if random.random() < coop_probability:
            return Action.C
        return Action.D

    def _calculate_threshold_success_rate(self, history: PlayerHistory, round_number: int) -> float:
        """
        Calculate the empirical rate at which threshold (m cooperators) was met
        in rounds 0 through round_number-1.
        """
        if round_number == 0:
            return 0.0
        successes = 0
        for past_round in range(round_number):
            my_contribution = 1 if history.my_actions[past_round] else 0
            opponent_contributions = int(np.sum(history.opponent_actions[past_round, :]))
            total_cooperators = my_contribution + opponent_contributions
            if total_cooperators >= self.m:
                successes += 1
        success_rate = successes / round_number
        return success_rate

    def _compute_cooperation_probability(self, success_rate: float) -> float:
        """
        Compute cooperation probability based on historical threshold success rate.
        
        Implements the tiered probabilistic strategy:
        - Very high success (â‰¥80%): ~95% cooperation
        - Moderate success (50-80%): 50-75% cooperation
        - Low success (20-50%): 10-30% cooperation
        - Very low success (<20%): <10% cooperation
        """
        if success_rate >= 1.0 - self.risk_tolerance:
            return min(1.0, success_rate * self.safety_factor)
        elif success_rate >= 0.5:
            return 0.5 + (success_rate - 0.5) * 0.5
        else:
            return 0.3 * success_rate

class Strategy_COLLECTIVE_481(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual risk management with collective welfare by:
    1. Tracking cooperation trends to assess collective success likelihood
    2. Contributing conditionally based on observed cooperation rates
    3. Using threshold sensitivity: cooperate when projected cooperators >= m-1
    4. Maximizing payoff by avoiding wasted sacrifices
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            if self.k >= 2.0:
                return Action.C
            else:
                return Action.D
        cooperators_all_rounds = int(np.sum(history.opponent_actions))
        total_opponent_actions = history.opponent_actions.shape[0] * history.opponent_actions.shape[1]
        if total_opponent_actions == 0:
            cooperation_rate = 0.0
        else:
            cooperation_rate = cooperators_all_rounds / total_opponent_actions
        if current_round >= 2:
            recent_cooperators = int(np.sum(history.opponent_actions[-2:, :]))
            recent_total = min(2, current_round) * self.n_players
            recent_rate = recent_cooperators / recent_total if recent_total > 0 else 0.0
        else:
            recent_rate = cooperation_rate
        projected_cooperators = recent_rate * self.n_players
        rounds_remaining = self.n_rounds - current_round - 1
        trend_improving = False
        if current_round >= 2:
            prev_cooperation_rate = cooperation_rate
            current_window_cooperators = int(np.sum(history.opponent_actions[-2:, :]))
            current_window_rate = current_window_cooperators / (2 * self.n_players) if 2 * self.n_players > 0 else 0.0
            trend_improving = current_window_rate > prev_cooperation_rate
        if current_round == self.n_rounds - 1:
            success_already_achieved = projected_cooperators >= self.m
            if success_already_achieved:
                return Action.D
            elif projected_cooperators >= self.m - 1:
                return Action.C
            else:
                return Action.D
        threshold_met = projected_cooperators >= self.m - 1
        if threshold_met:
            return Action.C
        elif rounds_remaining <= 2:
            return Action.D
        elif trend_improving:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_482(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Establishing cooperation early to signal willingness to contribute
    2. Monitoring cooperation trends against the required threshold
    3. Strategically defecting only when collective success is assured
    4. Using dynamic thresholds to adapt to observed cooperation rates
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.required_rate = self.m / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.n_rounds - 1:
            cooperators_prev = int(sum(history.opponent_actions[round_num - 1, :]))
            if cooperators_prev >= self.m:
                return Action.D
            else:
                return Action.C
        if round_num <= 2:
            cooperators_prev = int(sum(history.opponent_actions[round_num - 1, :]))
            coop_rate = cooperators_prev / self.n_players
            if coop_rate < 0.3:
                return Action.D
            else:
                return Action.C
        cooperators_prev = int(sum(history.opponent_actions[round_num - 1, :]))
        coop_rate = cooperators_prev / self.n_players
        rolling_window = min(3, round_num)
        recent_cooperators = []
        for i in range(rolling_window):
            recent_cooperators.append(int(sum(history.opponent_actions[round_num - 1 - i, :])))
        rolling_avg_coop_rate = np.mean(recent_cooperators) / self.n_players
        rounds_remaining = self.n_rounds - round_num
        if rolling_avg_coop_rate >= self.required_rate * 0.9:
            if cooperators_prev >= self.m and rounds_remaining > 1:
                return Action.D
            else:
                return Action.C
        elif rolling_avg_coop_rate >= self.required_rate * 0.7:
            return Action.C
        else:
            cooperators_needed = self.m - cooperators_prev
            if cooperators_needed <= 0:
                return Action.C
            if cooperators_needed <= rounds_remaining:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_483(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances risk minimization and payoff optimization through probabilistic cooperation
    that adapts based on observed cooperation rates, game parameters, and remaining rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.ema_cooperation = None
        self._compute_strategy_parameters()

    def _compute_strategy_parameters(self) -> None:
        """Compute strategy parameters based on game structure."""
        self.initial_threshold = self.m / self.n + 0.15
        self.learning_rate = (self.k - 1) / 2.0
        if self.m == self.n:
            self.initial_threshold = 0.95
            self.learning_rate = self.k
        elif self.m <= self.n / 3:
            self.initial_threshold = self.m / self.n + 0.05
            self.learning_rate = 1.5 * (self.k - 1)
        if self.k > 3:
            self.learning_rate *= 1.2

    def _get_observed_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """Calculate cooperation rate from previous round."""
        if round_num == 0 or len(history.opponent_actions) == 0:
            return 0.0
        cooperators = np.sum(history.opponent_actions[-1, :])
        return float(cooperators) / float(self.n - 1)

    def _update_ema(self, new_observation: float) -> float:
        """Update exponential moving average of cooperation rates."""
        if self.ema_cooperation is None:
            self.ema_cooperation = new_observation
        else:
            self.ema_cooperation = 0.7 * self.ema_cooperation + 0.3 * new_observation
        return self.ema_cooperation

    def _compute_cooperation_probability(self, state: GameState, history: None | PlayerHistory) -> float:
        """Compute the probability of cooperating in current round."""
        round_t = state.round_number
        if round_t == 0:
            if self.r == 2:
                return min(1.0, self.initial_threshold + 0.2)
            return self.initial_threshold
        observed_coop_rate = self._get_observed_cooperation_rate(history, round_t)
        ema_coop = self._update_ema(observed_coop_rate)
        rounds_remaining_bonus = (self.r - round_t) / (self.r * self.n)
        if round_t <= self.r - 2:
            learning_boost = (ema_coop - self.m / self.n) * self.learning_rate
            p_cooperate = self.initial_threshold + learning_boost + rounds_remaining_bonus
        else:
            if self.k > 1:
                endgame_multiplier = 1.5 + (2.0 - self.k) / 2.0
            else:
                endgame_multiplier = 1.5
            adjusted_threshold = self.initial_threshold + (ema_coop - self.m / self.n) * self.learning_rate
            p_cooperate = min(1.0, adjusted_threshold * endgame_multiplier + 0.2)
        return max(0.0, min(1.0, p_cooperate))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        """Decide action based on current game state and history."""
        p_cooperate = self._compute_cooperation_probability(state, history)
        if random.random() < p_cooperate:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_484(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by implementing adaptive
    cooperation based on historical cooperation rates and remaining rounds. Cooperates
    in round 1, adapts in middle rounds based on observed cooperation density relative
    to the threshold m/n, and defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        rounds_elapsed = current_round
        total_actions = rounds_elapsed * self.n_players
        all_cooperators = np.sum(history.opponent_actions[:current_round, :])
        my_cooperations = np.sum(history.my_actions[:current_round])
        total_cooperations = all_cooperators + my_cooperations
        if total_actions == 0:
            return Action.C
        observed_cooperation_rate = total_cooperations / total_actions
        cooperation_threshold = self.m / self.n_players
        tolerance_buffer = 0.1
        if cooperation_threshold >= 0.85:
            tolerance_buffer = 0.15
        elif cooperation_threshold <= 0.15:
            required_rate = 0.7
            if observed_cooperation_rate < required_rate:
                return Action.D
            return Action.C
        if observed_cooperation_rate >= cooperation_threshold - tolerance_buffer:
            return Action.C
        remaining_rounds = self.n_rounds - current_round
        if remaining_rounds >= 2:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_485(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances collective resilience with individual rationality by:
    - Cooperating in round 1 to gather information
    - Adapting cooperation based on a cooperation deficit calculation
    - Defecting when threshold is met (to exploit surplus)
    - Cooperating when deficit is critical (to prevent collective failure)
    - Applying special logic for edge cases and final rounds
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.consecutive_all_defect_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        recent_coop_count = int(sum(history.opponent_actions[-1, :]))
        recent_coop_count += int(history.my_actions[-1])
        recent_cooperation_rate = recent_coop_count / self.n_players
        threshold_cooperation_rate = self.m / self.n_players
        cooperation_deficit = threshold_cooperation_rate - recent_cooperation_rate
        if recent_cooperation_rate == 0:
            self.consecutive_all_defect_rounds += 1
        else:
            self.consecutive_all_defect_rounds = 0
        if current_round >= 2:
            prev_coop_count = int(sum(history.opponent_actions[-2, :]))
            prev_coop_count += int(history.my_actions[-2])
            previous_cooperation_rate = prev_coop_count / self.n_players
            recent_cooperation_rate = recent_cooperation_rate * 0.6 + previous_cooperation_rate * 0.4
            cooperation_deficit = threshold_cooperation_rate - recent_cooperation_rate
        critical_deficit_threshold = self._compute_critical_threshold()
        if current_round == self.n_rounds - 1:
            if recent_cooperation_rate >= threshold_cooperation_rate:
                return Action.D
            else:
                return Action.C
        if self.consecutive_all_defect_rounds >= 2:
            if current_round >= self.n_rounds - 2:
                return Action.C
            else:
                return Action.D
        if recent_cooperation_rate >= threshold_cooperation_rate:
            return Action.D
        elif cooperation_deficit > critical_deficit_threshold:
            return Action.C
        else:
            return Action.D

    def _compute_critical_threshold(self) -> float:
        """
        Compute the critical deficit threshold based on edge cases.
        
        Edge cases:
        - m = 1: Always cooperate from round 2 onward (strict cooperation)
        - m = n-1: Stricter deficit tolerance (0.25 factor)
        - Large n with small m: Standard rule (0.5 factor)
        """
        threshold_cooperation_rate = self.m / self.n_players
        if self.m == 1:
            return -1.0
        if self.m == self.n_players - 1:
            return threshold_cooperation_rate * 0.25
        return threshold_cooperation_rate * 0.5

class Strategy_COLLECTIVE_486(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances cooperation investment in early phases with prudent defection in later phases,
    based on observed success rates and cooperation frequency. Aims to drive the game toward
    cooperative equilibrium when feasible while protecting against exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.n_rounds - 1:
            return Action.D
        phase = self._determine_phase(state.round_number)
        cooperation_rate = self._get_cooperation_rate(history)
        success_frequency = self._get_success_frequency(history)
        recent_success_rate = self._get_recent_success_rate(history)
        if phase == 'INVESTMENT':
            return self._decide_investment(cooperation_rate, success_frequency, state.round_number)
        elif phase == 'EVALUATION':
            return self._decide_evaluation(recent_success_rate, success_frequency)
        else:
            return self._decide_endgame(success_frequency)

    def _determine_phase(self, round_number: int) -> str:
        """Determine which phase of the game we're in."""
        investment_threshold = math.floor(self.n_rounds * 0.6)
        evaluation_threshold = math.floor(self.n_rounds * 0.85)
        if round_number <= investment_threshold:
            return 'INVESTMENT'
        elif round_number <= evaluation_threshold:
            return 'EVALUATION'
        else:
            return 'ENDGAME'

    def _get_cooperation_rate(self, history: PlayerHistory) -> float:
        """Get the cooperation rate in the previous round."""
        if len(history.opponent_actions) == 0:
            return 0.0
        previous_round_actions = history.opponent_actions[-1, :]
        cooperators = int(np.sum(previous_round_actions))
        return cooperators / self.n_players

    def _get_success_frequency(self, history: PlayerHistory) -> float:
        """
        Calculate how often the threshold was met across all completed rounds.
        """
        if len(history.opponent_actions) == 0:
            return 0.0
        success_count = 0
        for round_idx in range(len(history.opponent_actions)):
            opponent_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
            my_action = int(history.my_actions[round_idx])
            total_cooperators = opponent_cooperators + my_action
            if total_cooperators >= self.m:
                success_count += 1
        total_rounds = len(history.opponent_actions)
        return success_count / total_rounds if total_rounds > 0 else 0.0

    def _get_recent_success_rate(self, history: PlayerHistory) -> float:
        """
        Calculate success rate over the most recent N rounds, where N = min(5, floor(0.2 * r)).
        """
        if len(history.opponent_actions) == 0:
            return 0.0
        N = min(5, math.floor(0.2 * self.n_rounds))
        recent_rounds = history.opponent_actions[-N:, :]
        success_count = 0
        for round_idx in range(len(recent_rounds)):
            opponent_cooperators = int(np.sum(recent_rounds[round_idx, :]))
            my_action = int(history.my_actions[-(N - round_idx):][0])
            total_cooperators = opponent_cooperators + my_action
            if total_cooperators >= self.m:
                success_count += 1
        return success_count / len(recent_rounds) if len(recent_rounds) > 0 else 0.0

    def _decide_investment(self, cooperation_rate: float, success_frequency: float, round_number: int) -> Action:
        """INVESTMENT Phase decision logic (rounds 2-60%)."""
        threshold_indicator = self.m / self.n_players - 0.15
        if cooperation_rate >= threshold_indicator:
            return Action.C
        if success_frequency >= 0.5 and round_number >= 3:
            return Action.C
        if cooperation_rate < self.m / (2.0 * self.n_players):
            return Action.D
        return Action.C

    def _decide_evaluation(self, recent_success_rate: float, success_frequency: float) -> Action:
        """EVALUATION Phase decision logic (61-85%)."""
        if recent_success_rate >= 0.6:
            return Action.C
        if recent_success_rate <= 0.2:
            return Action.D
        if success_frequency >= 0.5:
            return Action.C
        else:
            return Action.D

    def _decide_endgame(self, success_frequency: float) -> Action:
        """ENDGAME Phase decision logic (86-99%)."""
        threshold_ratio = self.m / self.n_players
        if threshold_ratio <= 0.5:
            if success_frequency >= 0.4:
                return Action.C
            else:
                return Action.D
        elif success_frequency >= 0.65:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_487(BaseStrategy):
    """
    Adaptive Threshold Sentinel: A collectively-minded strategy for the Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Signaling willingness to cooperate from Round 1 at probability m/n
    2. Learning from observed cooperation rates of other players
    3. Boosting cooperation probability near the threshold m
    4. Defending against defectors while maintaining reciprocity
    5. Making threshold-unlocking decisions in endgame when pivotal
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            cooperation_prob = self.m / self.n_players
            return Action.C if random.random() < cooperation_prob else Action.D
        opponent_actions = history.opponent_actions[:round_num, :]
        if round_num == 0 or opponent_actions.size == 0:
            total_coop_opportunities = 1
            total_cooperations = 0
        else:
            total_coop_opportunities = round_num * (self.n_players - 1)
            total_cooperations = int(np.sum(opponent_actions))
        if total_coop_opportunities > 0:
            historical_coop_rate = total_cooperations / total_coop_opportunities
        else:
            historical_coop_rate = self.m / self.n_players
        expected_cooperators = historical_coop_rate * (self.n_players - 1)
        if round_num == self.n_rounds - 1:
            if historical_coop_rate >= self.m / self.n_players:
                return Action.C
            elif expected_cooperators >= self.m - 1:
                return Action.C
            else:
                return Action.D
        if expected_cooperators >= self.m:
            cooperation_prob = historical_coop_rate + 0.1 * max(0, self.m - expected_cooperators)
            cooperation_prob = min(cooperation_prob, 1.0)
        elif expected_cooperators >= self.m - 1:
            cooperation_prob = 0.85
        else:
            cooperation_prob = 0.2
        cooperation_prob = max(0.0, min(1.0, cooperation_prob))
        return Action.C if random.random() < cooperation_prob else Action.D

class Strategy_COLLECTIVE_488(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual security with collective welfare by:
    1. Cooperating initially to signal good faith
    2. Adaptively responding to group cooperation rates
    3. Being forgiving of near-threshold misses
    4. Protecting final payoff based on demonstrated reliability
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round < self.r - 1:
            return self._adaptive_phase(history, current_round)
        return self._endgame_phase(history)

    def _adaptive_phase(self, history: PlayerHistory, current_round: int) -> Action:
        """
        Adaptive phase logic for rounds 1 to r-2.
        Responds to previous round's cooperation rate with forgiving thresholds.
        """
        prev_round_idx = current_round - 1
        prev_cooperators = int(sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            prev_cooperators += 1
        coop_rate = prev_cooperators / self.n
        threshold_rate = self.m / self.n
        if coop_rate >= threshold_rate:
            return Action.C
        deficit = self.m - prev_cooperators
        tolerance = self._calculate_tolerance()
        if deficit <= tolerance:
            return Action.C
        return Action.D

    def _endgame_phase(self, history: PlayerHistory) -> Action:
        """
        Final round logic: Only cooperate if threshold was consistently met.
        """
        success_count = 0
        rounds_to_evaluate = self.r - 1
        for round_idx in range(rounds_to_evaluate):
            cooperators = int(sum(history.opponent_actions[round_idx, :]))
            if history.my_actions[round_idx]:
                cooperators += 1
            if cooperators >= self.m:
                success_count += 1
        if rounds_to_evaluate > 0:
            success_rate = success_count / rounds_to_evaluate
        else:
            success_rate = 0.0
        if success_rate >= 0.75:
            return Action.C
        return Action.D

    def _calculate_tolerance(self) -> int:
        """
        Calculate the deficit tolerance based on game parameters.
        
        - When n is small (n < 4): More forgiving (20% tolerance)
        - When m is near n (m > 0.8n): More forgiving (33% tolerance)
        - When k is very large (k > 5): More forgiving deficit
        - Default: 25% tolerance
        """
        tolerance = math.floor(self.n * 0.25)
        if self.n < 4:
            tolerance = math.floor(self.n * 0.2)
        if self.m > 0.8 * self.n:
            tolerance = math.floor(self.n * 0.33)
        if self.k > 5:
            tolerance = math.floor(self.n * 0.5 * self.m / self.n)
        return max(0, tolerance)

class Strategy_COLLECTIVE_489(BaseStrategy):
    """
    Adaptive Threshold Commitment (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual security with collective benefit by:
    1. Committing to cooperation when mathematically justified
    2. Detecting defection patterns in opponent population
    3. Adapting thresholds dynamically based on observed behavior
    4. Protecting against exploitation while maintaining prosocial intent
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.opponent_cooperation_history = {}
        self.opponent_reliability_score = {}
        self.defection_streak = {}
        for i in range(self.n - 1):
            self.opponent_cooperation_history[i] = []
            self.opponent_reliability_score[i] = 0.5
            self.defection_streak[i] = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        self._update_opponent_profiles(history, round_num)
        if round_num == self.r - 1:
            expected_cooperators = self._count_expected_cooperators(round_num)
            if expected_cooperators >= self.m:
                return Action.C
            else:
                return Action.D
        if round_num == self.r - 2:
            reliable_count = sum((1 for score in self.opponent_reliability_score.values() if score > 0.6))
            if reliable_count >= self.m - 1:
                return Action.C
            else:
                return Action.D
        return self._adaptive_cooperation_decision(history, round_num)

    def _update_opponent_profiles(self, history: PlayerHistory, round_num: int):
        """Update reliability scores and defection streaks based on previous round."""
        prev_round_idx = round_num - 1
        for opponent_id in range(self.n - 1):
            opponent_action = history.opponent_actions[prev_round_idx, opponent_id]
            cooperated = bool(opponent_action)
            self.opponent_cooperation_history[opponent_id].append(cooperated)
            if cooperated:
                self.defection_streak[opponent_id] = 0
            else:
                self.defection_streak[opponent_id] += 1
            self.opponent_reliability_score[opponent_id] = self._calculate_reliability(opponent_id, round_num)

    def _calculate_reliability(self, opponent_id: int, round_num: int) -> float:
        """Calculate reliability score for an opponent based on observed behavior."""
        history = self.opponent_cooperation_history[opponent_id]
        if len(history) == 0:
            return 0.5
        if self.defection_streak[opponent_id] >= 3:
            return 0.0
        defection_rate = 1.0 - sum(history) / len(history)
        if defection_rate >= 0.7:
            return 0.0
        cooperation_rate = sum(history) / len(history)
        if cooperation_rate >= 0.8:
            return 1.0
        elif cooperation_rate >= 0.6:
            return 0.7
        else:
            return cooperation_rate * 0.5

    def _get_phase_adjustment_factor(self, round_num: int) -> float:
        """Calculate alpha based on game phase."""
        if round_num <= self.r / 3:
            return 1.5
        elif round_num <= 2 * self.r / 3:
            return 1.0
        else:
            return 0.5

    def _count_expected_cooperators(self, round_num: int) -> int:
        """Estimate how many players will cooperate in the current round."""
        if round_num == 0:
            return self.n
        prev_round_idx = round_num - 1
        expected = 0
        for opponent_id in range(self.n - 1):
            reliability = self.opponent_reliability_score[opponent_id]
            expected += reliability
        return int(math.ceil(expected))

    def _count_recent_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """Calculate cooperation rate in the last 3 rounds."""
        if round_num == 0:
            return 1.0
        start_idx = max(0, round_num - 3)
        end_idx = round_num
        my_cooperations = sum(history.my_actions[start_idx:end_idx])
        rounds_checked = end_idx - start_idx
        if rounds_checked == 0:
            return 1.0
        return my_cooperations / rounds_checked

    def _adaptive_cooperation_decision(self, history: PlayerHistory, round_num: int) -> Action:
        """Apply adaptive cooperation threshold for main phase rounds."""
        prev_round_idx = round_num - 1
        defection_count = sum(1 - history.opponent_actions[prev_round_idx, :])
        defection_rate = defection_count / self.n if self.n > 0 else 0.0
        alpha = self._get_phase_adjustment_factor(round_num)
        threshold = self.m + math.floor(alpha * defection_rate * self.n)
        recent_coop_rate = self._count_recent_cooperation_rate(history, round_num)
        if recent_coop_rate < 0.4:
            return Action.D
        if recent_coop_rate > 0.7:
            threshold = max(self.m, threshold - 1)
        expected_cooperators = self._count_expected_cooperators(round_num)
        if expected_cooperators >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_490(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances collective welfare (achieving threshold m) with individual protection
    against exploitation. Uses history-based decision rules that adapt to observed
    cooperation levels and remaining rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        opponent_cooperators_last = int(sum(history.opponent_actions[-1, :]))
        my_action_last = int(history.my_actions[-1])
        cooperators_last_round = opponent_cooperators_last + my_action_last
        rounds_remaining = self.n_rounds - current_round
        if cooperators_last_round >= self.m:
            cooperation_probability = (self.k - 1) / self.k
            if random.random() < cooperation_probability:
                return Action.C
            else:
                return Action.D
        if rounds_remaining == 0:
            threshold_half = math.ceil(self.m / 2)
            if cooperators_last_round >= threshold_half:
                return Action.C
            else:
                return Action.D
        if cooperators_last_round < self.m - 1:
            return Action.D
        if cooperators_last_round >= self.m - 1:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_491(BaseStrategy):
    """
    Adaptive Threshold with Decay (ATD) strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Playing probabilistically based on baseline cooperation
    2. Adapting cooperation probability based on observed cooperation rates
    3. Gradually decaying cooperation as the game approaches its end
    4. Maintaining floors and ceilings to avoid extreme behavior
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        if self.n <= 2:
            self.base_cooperation_probability = 0.6
        else:
            self.base_cooperation_probability = (self.m + 1) / (2 * self.n)
        self.base_cooperation_probability = max(0.1, min(0.9, self.base_cooperation_probability))
        self.cooperation_probability = self.base_cooperation_probability
        self.success_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            action = Action.C if random.random() < self.base_cooperation_probability else Action.D
            return action
        if current_round < self.r - 2:
            prev_round_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
            observed_cooperation_rate = prev_round_cooperators / self.n
            threshold_rate = self.m / self.n
            near_threshold_rate = (self.m - 1) / self.n if self.m > 1 else 0.0
            if observed_cooperation_rate >= threshold_rate:
                self.cooperation_probability = self.base_cooperation_probability + 0.1
                self.cooperation_probability = min(self.cooperation_probability, 0.8)
                self.success_count += 1
            elif observed_cooperation_rate >= near_threshold_rate:
                self.cooperation_probability = self.base_cooperation_probability
            else:
                self.cooperation_probability = self.base_cooperation_probability - 0.15
                self.cooperation_probability = max(self.cooperation_probability, 0.1)
            action = Action.C if random.random() < self.cooperation_probability else Action.D
            return action
        rounds_remaining = self.r - current_round
        decay_factor = rounds_remaining / self.r if self.r > 0 else 0.0
        rounds_completed = current_round
        if rounds_completed > 0:
            successful_rounds = 0
            for round_idx in range(current_round):
                round_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
                if round_cooperators >= self.m:
                    successful_rounds += 1
            cooperative_rounds_observed = successful_rounds / rounds_completed
        else:
            cooperative_rounds_observed = 0.0
        if cooperative_rounds_observed > 0.5:
            final_prob = self.cooperation_probability * decay_factor
        else:
            final_prob = 0.05 * decay_factor
        action = Action.C if random.random() < final_prob else Action.D
        return action

class Strategy_COLLECTIVE_492(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances collective welfare, individual security, and adaptive resilience by
    making cooperation probability contingent on observed cooperation density.
    Cooperates when threshold is reachable, defects when it's not, with exploration
    in intermediate uncertainty zones.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            p_initial = self.m / self.n
            if random.random() < p_initial:
                return Action.C
            else:
                return Action.D
        cooperators_last_round = np.sum(history.opponent_actions[round_num - 1, :])
        cooperation_rate = cooperators_last_round / (self.n - 1)
        threshold_rate = (self.m - 1) / (self.n - 1)
        if round_num == self.r - 1:
            if cooperation_rate >= threshold_rate:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= threshold_rate:
            confidence_bonus = 0.1 if cooperation_rate >= 0.5 else 0.0
            coop_prob = min(1.0, cooperation_rate + confidence_bonus)
            if random.random() < coop_prob:
                return Action.C
            else:
                return Action.D
        elif cooperation_rate >= threshold_rate * 0.5:
            coop_prob = 0.5 * cooperation_rate
            if random.random() < coop_prob:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_493(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Estimating population cooperation rate from observed actions
    2. Dynamically adjusting a cooperation threshold based on confidence
    3. Cooperating when estimated cooperation exceeds threshold
    4. Punishing defection through strategic withdrawal
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.last_cooperation_estimate = self.m / self.n_players
        self.consecutive_failures = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            threshold_ratio = self.m / self.n_players
            if threshold_ratio <= 0.5:
                return Action.C
            else:
                return Action.D
        observed_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        cooperation_estimate = observed_cooperators / self.n_players
        confidence = min(1.0, current_round / self.n_rounds)
        base_threshold = self.m / self.n_players
        adjustment = (1.0 - confidence) * 0.15
        threshold = base_threshold - adjustment
        if self.n_rounds <= 3:
            threshold = base_threshold
        previous_round_success = observed_cooperators >= self.m
        if not previous_round_success:
            self.consecutive_failures += 1
        else:
            self.consecutive_failures = 0
        if self.consecutive_failures >= 2:
            return Action.D
        if current_round == self.n_rounds - 2:
            if cooperation_estimate >= threshold:
                return Action.C
            else:
                return Action.D
        if current_round == self.n_rounds - 1:
            if previous_round_success:
                return Action.C
            else:
                return Action.D
        if cooperation_estimate >= threshold:
            self.last_cooperation_estimate = cooperation_estimate
            return Action.C
        else:
            self.last_cooperation_estimate = cooperation_estimate
            return Action.D

class Strategy_COLLECTIVE_494(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances individual and collective rationality by:
    1. Always cooperating in round 1 (bootstrap)
    2. Adapting to recent cooperation trends in middle rounds
    3. Making endgame decision based on historical cooperation rate
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            historical_cooperation_rate = self._calculate_historical_cooperation_rate(history)
            threshold_likelihood = self.m / self.n
            if historical_cooperation_rate >= threshold_likelihood:
                return Action.C
            else:
                return Action.D
        recent_cooperators = self._count_recent_cooperators(history, lookback=3)
        if recent_cooperators >= self.m:
            strong_cooperation_threshold = math.ceil(self.n * 0.6)
            if recent_cooperators >= strong_cooperation_threshold:
                return Action.C
            else:
                cooperation_probability = recent_cooperators / self.n
                if random.random() < cooperation_probability:
                    return Action.C
                else:
                    return Action.D
        elif recent_cooperators >= self.m - 1:
            return Action.C
        else:
            return Action.D

    def _count_recent_cooperators(self, history: PlayerHistory, lookback: int) -> int:
        """
        Count total cooperators (including self) in the last `lookback` rounds.
        Returns count across all players in the most recent complete round available.
        """
        total_rounds = len(history.my_actions)
        rounds_to_check = min(lookback, total_rounds)
        if rounds_to_check == 0:
            return 0
        most_recent_round_idx = total_rounds - 1
        cooperators = 0
        if history.my_actions[most_recent_round_idx]:
            cooperators += 1
        cooperators += int(np.sum(history.opponent_actions[most_recent_round_idx, :]))
        return cooperators

    def _calculate_historical_cooperation_rate(self, history: PlayerHistory) -> float:
        """
        Calculate the average cooperation rate across all rounds.
        Returns the proportion of total player-rounds that were cooperations.
        """
        total_rounds = len(history.my_actions)
        if total_rounds == 0:
            return 0.0
        self_cooperations = int(np.sum(history.my_actions))
        opponent_cooperations = int(np.sum(history.opponent_actions))
        total_cooperations = self_cooperations + opponent_cooperations
        total_player_rounds = self.n * total_rounds
        if total_player_rounds == 0:
            return 0.0
        cooperation_rate = total_cooperations / total_player_rounds
        return cooperation_rate

class Strategy_COLLECTIVE_495(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Starting cooperative to discover if others will cooperate
    2. Estimating cooperation viability from historical data
    3. Maintaining cooperation when threshold appears achievable
    4. Defecting only when cooperation appears futile
    5. Securing payoff on final round if threshold is reachable
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        if round_t == self.r - 1:
            cooperators_last_round = int(np.sum(history.opponent_actions[round_t - 1, :]))
            if cooperators_last_round >= self.m - 1:
                return Action.C
            else:
                return Action.D
        total_cooperations = int(np.sum(history.opponent_actions[:round_t, :]))
        total_possible = (self.n - 1) * round_t
        if total_possible == 0:
            cooperation_rate = 0.0
        else:
            cooperation_rate = total_cooperations / total_possible
        expected_others = cooperation_rate * (self.n - 1)
        if expected_others >= self.m - 1:
            return Action.C
        threshold_rate = self.m / self.n * 0.75
        if cooperation_rate >= threshold_rate:
            return Action.C
        cooperators_last_round = int(np.sum(history.opponent_actions[round_t - 1, :]))
        if cooperators_last_round >= self.m:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_496(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare through:
    - Conditional cooperation based on estimated success probability
    - Adaptive thresholds adjusted by observed cooperation rates
    - Graceful degradation when cooperation becomes unlikely
    - Special handling for final round based on historical trends
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.p_success = 0.5
        self.p_success_old = 0.5
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.cooperation_history.append(1.0)
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        cooperators_prev = int(history.my_actions[current_round - 1]) + np.sum(history.opponent_actions[current_round - 1, :])
        p_success_raw = (cooperators_prev + 1) / n
        self.p_success = 0.7 * p_success_raw + 0.3 * self.p_success_old
        self.p_success_old = self.p_success
        if current_round == r - 1:
            avg_coop_rate = np.mean(self.cooperation_history)
            threshold_coop_rate = m / n - 0.15
            if avg_coop_rate < threshold_coop_rate:
                self.cooperation_history.append(0.0)
                return Action.D
            else:
                self.cooperation_history.append(1.0)
                return Action.C
        threshold = 1.0 / k if k > 0 else 0.0
        if m > 0.7 * n:
            threshold = 1.0 / k + 0.1 if k > 0 else 0.1
        elif k > 5:
            threshold = max(0.15, 1.0 / k)
        elif k <= 1.5:
            threshold = min(0.5, 1.0 / k + 0.1)
        threshold = max(0.0, min(1.0, threshold))
        if self.p_success >= threshold:
            self.cooperation_history.append(1.0)
            return Action.C
        else:
            self.cooperation_history.append(0.0)
            return Action.D

class Strategy_COLLECTIVE_497(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Prioritizes collective welfare through adaptive monitoring and conditional cooperation.
    Dynamically adjusts contributions based on observed cooperation rates to ensure the
    threshold is reliably met while minimizing exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.phase_boundary_early = math.ceil(self.r / 3)
        self.phase_boundary_late = math.floor(2 * self.r / 3)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round < self.phase_boundary_early:
            return Action.C
        if history is None or current_round == 0:
            return Action.C
        last_round_opponent_actions = history.opponent_actions[-1, :]
        cooperators_last_round = int(np.sum(last_round_opponent_actions))
        cooperation_rate = cooperators_last_round / self.n
        threshold_ratio = self.m / self.n
        if current_round < self.phase_boundary_late:
            if cooperation_rate >= threshold_ratio * 1.2:
                return Action.C
            if cooperation_rate >= threshold_ratio * 0.9:
                return Action.C
            if cooperation_rate < threshold_ratio * 0.9:
                deficit = self.m - cooperators_last_round
                if deficit <= 2:
                    return Action.C
                else:
                    return Action.D
            return Action.C
        rounds_remaining = self.r - current_round
        if cooperators_last_round >= self.m:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_498(BaseStrategy):
    """
    Conditional Reciprocal Threshold (CRT) Strategy for Collective Risk Dilemma.
    
    Balances individual security with collective benefit by dynamically adjusting
    cooperation based on observed group behavior, remaining rounds, and estimated
    probability of threshold success.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def _determine_phase(self, round_number: int) -> str:
        """Determine game phase based on round number."""
        early_threshold = math.floor(self.n_rounds / 3)
        mid_threshold = math.ceil(2 * self.n_rounds / 3)
        if round_number < early_threshold:
            return 'early'
        elif round_number < mid_threshold:
            return 'mid'
        else:
            return 'end'

    def _estimate_cooperation_rate(self, history: PlayerHistory, round_number: int) -> float:
        """Estimate cooperation rate of other players in previous round."""
        if round_number == 0:
            return (self.m - 1) / (self.n_players - 1)
        cooperators_last_round = np.sum(history.opponent_actions[round_number - 1, :])
        other_players = self.n_players - 1
        if other_players == 0:
            return 0.5
        return cooperators_last_round / other_players

    def _estimate_threshold_probability(self, observed_cooperation_rate: float, phase: str) -> float:
        """
        Estimate probability that threshold m will be met if we cooperate.
        Uses binomial approximation with phase-dependent confidence adjustment.
        """
        other_players = self.n_players - 1
        etr = self.m - 1
        expected_cooperators = observed_cooperation_rate * other_players
        volatility = {'early': 0.5, 'mid': 0.3, 'end': 0.2}.get(phase, 0.3)
        if expected_cooperators >= etr:
            excess = expected_cooperators - etr
            prob = min(1.0, excess / (other_players + 1) + (1.0 - volatility))
        else:
            deficit = etr - expected_cooperators
            prob = max(0.0, 1.0 - volatility - deficit / (other_players + 1))
        return max(0.0, min(1.0, prob))

    def _get_risk_tolerance(self, phase: str) -> float:
        """Get phase-dependent risk tolerance threshold."""
        return {'early': 0.4, 'mid': 0.15, 'end': -0.05}.get(phase, 0.15)

    def _is_threshold_guaranteed(self, history: PlayerHistory, round_number: int) -> bool:
        """Check if threshold success is already guaranteed (>95% certain)."""
        if round_number == 0:
            return False
        cooperators_last_round = int(np.sum(history.opponent_actions[round_number - 1, :]))
        return cooperators_last_round >= self.m

    def _is_threshold_impossible(self, history: PlayerHistory, round_number: int) -> bool:
        """Check if threshold success is impossible in remaining rounds."""
        rounds_remaining = self.n_rounds - round_number
        if rounds_remaining <= 0:
            return True
        if round_number == 0:
            return False
        max_possible_cooperators = self.n_players - 1 + 1
        return max_possible_cooperators < self.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        phase = self._determine_phase(round_number)
        if self._is_threshold_impossible(history, round_number):
            return Action.D
        if round_number == self.n_rounds - 1:
            if self._is_threshold_guaranteed(history, round_number):
                return Action.C
            return Action.D
        observed_cooperation_rate = self._estimate_cooperation_rate(history, round_number)
        prob_threshold_success = self._estimate_threshold_probability(observed_cooperation_rate, phase)
        risk_tolerance = self._get_risk_tolerance(phase)
        ev_cooperate = prob_threshold_success * (self.k - 1) + (1 - prob_threshold_success) * -1
        ev_defect = prob_threshold_success * self.k + (1 - prob_threshold_success) * 1
        if ev_cooperate >= ev_defect - risk_tolerance:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_499(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances individual security with collective welfare by:
    1. Starting with cooperation to signal good faith
    2. Conditionally cooperating based on observed cooperation rates
    3. Adapting to threshold achievement and rounds remaining
    4. Using probabilistic cooperation near the threshold to buffer against noise
    5. Defecting in endgame when coordination is unlikely
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.m / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        last_round_opponent_actions = history.opponent_actions[current_round - 1, :]
        cooperators_last_round = int(np.sum(last_round_opponent_actions))
        my_last_action = history.my_actions[current_round - 1]
        total_cooperators_last_round = cooperators_last_round + (1 if my_last_action else 0)
        cooperation_rate = total_cooperators_last_round / self.n
        if cooperation_rate >= self.threshold:
            return Action.C
        rounds_remaining = self.r - current_round
        if rounds_remaining <= 2:
            return Action.D
        recovery_threshold = self.threshold * 0.75
        if cooperation_rate >= recovery_threshold:
            return Action.C if random.random() < 0.7 else Action.D
        return Action.D

class Strategy_COLLECTIVE_500(BaseStrategy):
    """
    Conditional Cascade with Risk Gradient: Adaptive threshold coordination strategy.
    
    Dynamically adjusts cooperation based on observed progress toward the threshold
    and remaining time, balancing individual security with collective welfare.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        last_round_actions = history.opponent_actions[current_round - 1, :]
        cooperators_last_round = int(np.sum(last_round_actions))
        if history.my_actions[current_round - 1]:
            cooperators_last_round += 1
        rounds_remaining = self.r - current_round
        cooperation_deficit = self.m - cooperators_last_round
        if cooperators_last_round >= self.m:
            return Action.C
        if cooperation_deficit > rounds_remaining:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        total_cooperators_observed = int(np.sum(history.opponent_actions[:current_round, :]))
        if history.my_actions is not None and len(history.my_actions) > 0:
            total_cooperators_observed += int(np.sum(history.my_actions[:current_round]))
        total_observations = current_round * self.n
        history_compliance = total_cooperators_observed / max(total_observations, 1)
        deficit_pressure = cooperation_deficit / (rounds_remaining + 1)
        urgency_factor = deficit_pressure * history_compliance
        if urgency_factor > 0.6:
            return Action.C
        elif urgency_factor > 0.3:
            coop_probability = 1.0 - urgency_factor
            if random.random() < coop_probability:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_501(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances reciprocal trust, threshold awareness, and adaptive robustness by:
    - Starting with cooperation to establish cooperative norms
    - Monitoring progress toward the critical m-cooperators benchmark
    - Adjusting behavior based on observed cooperation patterns
    - Maintaining some cooperation when possible, but defecting when threshold is unreachable
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == 1:
            return Action.C
        if current_round < self.n_rounds - 1:
            c_last = self._count_cooperators_last_round(history, current_round)
            rounds_remaining = self.n_rounds - current_round
            if c_last >= self.m:
                return Action.C
            elif c_last >= self.m - 1:
                return Action.C
            elif c_last >= math.ceil(self.m / 2):
                return Action.C
            elif c_last >= 1 and rounds_remaining >= 2:
                return Action.C
            else:
                return Action.D
        if current_round == self.n_rounds - 1:
            c_last = self._count_cooperators_last_round(history, current_round)
            if c_last >= self.m - 1:
                return Action.C
            else:
                return Action.D
        return Action.D

    def _count_cooperators_last_round(self, history: PlayerHistory, current_round: int) -> int:
        """Count cooperators (including self) in the most recent completed round."""
        if current_round == 0:
            return 0
        last_round_idx = current_round - 1
        opponent_cooperators = sum(history.opponent_actions[last_round_idx, :])
        self_cooperated = 1 if history.my_actions[last_round_idx] else 0
        total_cooperators = opponent_cooperators + self_cooperated
        return total_cooperators

class Strategy_COLLECTIVE_502(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Cooperates in round 1 to signal good faith, defects in final round (subgame perfect),
    and adaptively cooperates in middle rounds based on observed cooperation rates and trends.
    Gracefully degrades from cooperation to defection as collective cooperation fails.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            return Action.D
        prev_round_idx = round_num - 1
        prev_cooperators = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            prev_cooperators += 1
        cooperation_rate = prev_cooperators / self.n
        threshold_rate = self.m / self.n
        if cooperation_rate >= threshold_rate:
            base_probability = 0.95
        elif cooperation_rate >= 0.5 * threshold_rate:
            shortfall = self.m - prev_cooperators
            base_probability = max(0.2, 1.0 - shortfall / (self.n + 1))
        else:
            denominator = max(self.m + 1, 1)
            base_probability = max(0.0, (prev_cooperators - 1) / denominator)
        if round_num > 1:
            prev_prev_round_idx = round_num - 2
            prev_prev_cooperators = int(np.sum(history.opponent_actions[prev_prev_round_idx, :]))
            if history.my_actions[prev_prev_round_idx]:
                prev_prev_cooperators += 1
            prev_prev_coop_rate = prev_prev_cooperators / self.n
            if prev_prev_coop_rate > 0:
                trend = (cooperation_rate - prev_prev_coop_rate) / prev_prev_coop_rate
                if trend > 0.1:
                    base_probability += 0.1
                elif trend < -0.1:
                    base_probability -= 0.15
        cooperation_probability = max(0.0, min(1.0, base_probability))
        if random.random() < cooperation_probability:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_503(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances collective welfare with individual security by adapting cooperation
    decisions based on observed cooperation rates. Cooperates in early rounds to
    probe collective intent, maintains cooperation when cooperation rate is sufficient,
    defects when cooperation falls below critical threshold, and employs strategic
    defection in the final round when cooperation is robust.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == 1:
            return Action.C
        cooperation_rate = self._calculate_cooperation_rate(history, current_round)
        critical_threshold = self.m / self.n_players * 0.5
        promising_threshold = self.m / self.n_players * 0.9
        if current_round == self.n_rounds - 1:
            return self._last_round_decision(cooperation_rate, critical_threshold)
        if abs(cooperation_rate - critical_threshold) < 0.05:
            return self._volatility_dampened_decision(history, current_round, critical_threshold)
        if cooperation_rate * self.n_players < self.m:
            return Action.D
        if cooperation_rate >= promising_threshold:
            return Action.C
        elif cooperation_rate >= critical_threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate observed cooperation rate from all previous rounds.
        cooperation_rate = total cooperators in previous rounds / (n_players Ã— rounds_played)
        """
        if current_round <= 0:
            return 0.0
        total_cooperators = 0
        for round_idx in range(current_round):
            total_cooperators += int(history.my_actions[round_idx])
            total_cooperators += np.sum(history.opponent_actions[round_idx, :])
        total_slots = current_round * self.n_players
        if total_slots == 0:
            return 0.0
        return total_cooperators / total_slots

    def _volatility_dampened_decision(self, history: PlayerHistory, current_round: int, critical_threshold: float) -> Action:
        """
        When cooperation rate is near threshold boundaries, check trend.
        """
        if current_round < 2:
            return Action.C
        midpoint = current_round // 2
        earlier_cooperators = 0
        for round_idx in range(midpoint):
            earlier_cooperators += int(history.my_actions[round_idx])
            earlier_cooperators += np.sum(history.opponent_actions[round_idx, :])
        earlier_rate = earlier_cooperators / (midpoint * self.n_players) if midpoint > 0 else 0.0
        recent_cooperators = 0
        for round_idx in range(midpoint, current_round):
            recent_cooperators += int(history.my_actions[round_idx])
            recent_cooperators += np.sum(history.opponent_actions[round_idx, :])
        recent_rounds = current_round - midpoint
        recent_rate = recent_cooperators / (recent_rounds * self.n_players) if recent_rounds > 0 else 0.0
        if recent_rate > earlier_rate:
            return Action.C
        else:
            return Action.D

    def _last_round_decision(self, cooperation_rate: float, critical_threshold: float) -> Action:
        """
        In the final round, strategically defect if cooperation is robust,
        otherwise sustain or attempt rescue.
        """
        robust_threshold = self.m / self.n_players * 0.8
        if cooperation_rate >= robust_threshold:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_504(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Implements conditional collectivism through three phases:
    - Phase A (rounds 1 to r-2): Cooperate if last round had â‰¥ m-1 cooperators
    - Phase B (round r-1): Cooperate if empirical cooperation rate â‰¥ (m/n) - 0.1
    - Phase C (round r): Cooperate if last round had â‰¥ m-1 cooperators
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.tolerance = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.n_rounds - 1:
            last_round_cooperators = int(np.sum(history.opponent_actions[round_num - 1, :]))
            if last_round_cooperators >= self.m - 1:
                return Action.C
            else:
                return Action.D
        if round_num == self.n_rounds - 2:
            total_rounds_observed = round_num
            total_observations = total_rounds_observed * self.n_players
            total_cooperators = int(np.sum(history.opponent_actions[:round_num, :]))
            my_cooperators = int(np.sum(history.my_actions[:round_num]))
            total_cooperators += my_cooperators
            if total_observations > 0:
                cooperation_rate = total_cooperators / total_observations
            else:
                cooperation_rate = 0.0
            threshold_viability = self.m / self.n_players - self.tolerance
            if cooperation_rate >= threshold_viability:
                return Action.C
            else:
                return Action.D
        last_round_cooperators = int(np.sum(history.opponent_actions[round_num - 1, :]))
        if last_round_cooperators >= self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_505(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Balances individual security with collective success by:
    1. Bootstrapping cooperation in round 1
    2. Reciprocating based on cooperation rates relative to threshold m/n
    3. Probabilistically contributing in marginal zones
    4. Protecting against exploitation when cooperation fails
    5. Adjusting behavior in final round based on collective success
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_rate = self.m / self.n
        self.marginal_lower = (self.m - 1) / self.n
        self.rounds_since_threshold_failure = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_idx = round_num - 1
        prev_cooperators = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            prev_cooperators += 1
        cooperation_rate = prev_cooperators / self.n
        if round_num == self.r - 1:
            if cooperation_rate >= self.threshold_rate:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= self.threshold_rate:
            self.rounds_since_threshold_failure = 0
            return Action.C
        elif cooperation_rate < self.marginal_lower:
            self.rounds_since_threshold_failure += 1
            return Action.D
        else:
            prob_cooperate = cooperation_rate / self.threshold_rate
            if self.rounds_since_threshold_failure > 0 and self.rounds_since_threshold_failure < 2:
                recovery_threshold = 0.9 * self.threshold_rate
                if cooperation_rate >= recovery_threshold:
                    self.rounds_since_threshold_failure = 0
                    return Action.C
            if random.random() < prob_cooperate:
                self.rounds_since_threshold_failure = 0
                return Action.C
            else:
                self.rounds_since_threshold_failure += 1
                return Action.D

class Strategy_COLLECTIVE_506(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Maximizes probability of meeting cooperation threshold while minimizing exploitation.
    Uses adaptive cooperation rates based on observed progress toward threshold in middle rounds,
    unconditional cooperation in round 1, and conditional defection in final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold_ever_met = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        m = self.game_description.m
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == r - 1:
            if self.threshold_ever_met:
                return Action.D
            else:
                return Action.C
        cooperators_last_round = int(np.sum(history.opponent_actions[round_num - 1, :]))
        cooperators_last_round += int(history.my_actions[round_num - 1])
        coop_rate = cooperators_last_round / n
        required_rate = m / n
        if coop_rate >= required_rate:
            self.threshold_ever_met = True
            safety_margin = required_rate
            if safety_margin < 1.0:
                margin = (coop_rate - required_rate) / (1.0 - required_rate)
            else:
                margin = 0.0
            if random.random() < margin:
                return Action.D
            else:
                return Action.C
        else:
            deficit = required_rate - coop_rate
            critical_threshold = 0.5 * (1.0 - required_rate)
            if deficit > critical_threshold:
                return Action.C
            else:
                if required_rate > 0:
                    coop_probability = 1.0 - deficit / required_rate * 0.3
                else:
                    coop_probability = 1.0
                coop_probability = max(0.0, min(1.0, coop_probability))
                if random.random() < coop_probability:
                    return Action.C
                else:
                    return Action.D

class Strategy_COLLECTIVE_509(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances trust-building through cooperation with self-protection against exploitation.
    Uses threshold-based decisions with adaptive buffers, circuit-breaker mechanisms for
    defection cascades, and special handling for final rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defection_phase_countdown = 0
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        cooperators_last_round = int(sum(history.opponent_actions[-1, :]))
        cooperation_rate = cooperators_last_round / n
        self.cooperation_history.append(cooperation_rate)
        if self.defection_phase_countdown > 0:
            self.defection_phase_countdown -= 1
            return Action.D
        if current_round > 1:
            prev_cooperation_rate = self.cooperation_history[-2]
            defection_rate_change = prev_cooperation_rate - cooperation_rate
            if defection_rate_change > 0.3:
                self.defection_phase_countdown = 1
                return Action.D
        base_threshold = m / n
        adjustment_factor = min(0.15, (m - 1) / n * 0.5)
        threshold = base_threshold + adjustment_factor
        if current_round > 1 and len(self.cooperation_history) >= 2:
            rate_t_minus_2 = self.cooperation_history[-2]
            rate_t_minus_1 = cooperation_rate
            if (rate_t_minus_2 >= threshold) != (rate_t_minus_1 >= threshold):
                threshold += 0.05
        if cooperation_rate == 0.0 and current_round < r - 1:
            return Action.C
        if cooperation_rate == 1.0:
            return Action.C
        if current_round == r - 1:
            final_threshold = m / n + 0.1
            if cooperation_rate >= final_threshold:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_510(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Cooperating in round 1 to establish baseline
    2. Using conditional cooperation based on expected cooperators in middle rounds
    3. Making a final salvage attempt in the last round if threshold at risk
    4. Tracking cooperation rates with recency weighting for adaptive decisions
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.n_rounds - 1:
            cooperators_this_round = int(sum(history.opponent_actions[-1, :]))
            if cooperators_this_round < self.m:
                return Action.C
            else:
                return Action.D
        rho = self._calculate_cooperation_rate(history)
        expected_cooperators = rho * (self.n_players - 1)
        if expected_cooperators >= self.m:
            return Action.D
        elif expected_cooperators + 1 >= self.m:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        """
        Calculate cooperation rate from opponent actions with recency weighting.
        
        Recent rounds are weighted 2x more heavily than early rounds to capture
        changing strategies while remaining responsive to current conditions.
        """
        opponent_actions = history.opponent_actions
        n_rounds_observed = opponent_actions.shape[0]
        if n_rounds_observed == 0:
            return 0.0
        total_weighted_cooperations = 0.0
        total_weight = 0.0
        for round_idx in range(n_rounds_observed):
            weight = 1.0 if round_idx < n_rounds_observed - 1 else 2.0
            cooperators_in_round = int(sum(opponent_actions[round_idx, :]))
            total_weighted_cooperations += cooperators_in_round * weight
            total_weight += (self.n_players - 1) * weight
        if total_weight == 0:
            return 0.0
        cooperation_rate = total_weighted_cooperations / total_weight
        return cooperation_rate

class Strategy_COLLECTIVE_511(BaseStrategy):
    """
    Adaptive Threshold Cooperator (ATC) Strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective benefit through adaptive cooperation
    that responds to observed cooperation rates. Implements three phases:
    1. Exploration (rounds 1-3): Always cooperate to test viability
    2. Adaptive Cooperation (rounds 4 to r-1): Respond to cooperation rate
    3. Endgame (final round): Always defect to free-ride
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        exploration_rounds = min(3, self.n_rounds)
        if round_number < exploration_rounds:
            return Action.C
        if round_number == self.n_rounds - 1:
            return Action.D
        prev_round_idx = round_number - 1
        cooperators_prev_round = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        coop_rate = cooperators_prev_round / self.n_players
        threshold_rate = self.m / self.n_players
        threshold_rate_minus_one = (self.m - 1) / self.n_players
        if coop_rate >= threshold_rate:
            return Action.C
        elif coop_rate >= threshold_rate_minus_one:
            return Action.C if random.random() < 0.75 else Action.D
        else:
            rounds_remaining = self.n_rounds - round_number
            if rounds_remaining <= 3:
                return Action.D
            else:
                return Action.D

class Strategy_EXPLOITATIVE_1(BaseStrategy):
    """
    Adaptive Parasitism: An exploitative strategy for the Collective Risk Dilemma.
    
    Core philosophy: Always defect to exploit the threshold mechanism. When m or more
    players cooperate, defection yields 1 + k (private endowment + collective reward).
    When fewer than m cooperate, defection yields 1 (secure baseline).
    
    This strategy:
    - Defects in all rounds (round 1, rounds 2 to r-1, and final round)
    - Never invests in cooperation, avoiding risk entirely
    - Free-rides on others' cooperation when threshold is met
    - Maintains baseline payoff when threshold cannot be reached
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = []
        self.threshold_met_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        """
        Decision function for all rounds.
        
        Strategy: Always defect.
        - Round 0: Defect (probe, gather information)
        - Rounds 1 to r-2: Defect (exploit threshold mechanism)
        - Round r-1: Defect (no future punishment possible)
        """
        if state.round_number == 0:
            return Action.D
        if history is not None:
            previous_round_idx = state.round_number - 1
            cooperators_prev = int(np.sum(history.opponent_actions[previous_round_idx, :]))
            self.cooperation_history.append(cooperators_prev)
            if cooperators_prev >= self.game_description.m:
                self.threshold_met_count += 1
        return Action.D

class Strategy_EXPLOITATIVE_2(BaseStrategy):
    """
    Exploitative Strategy: Conditional Free-Riding with Adaptive Thresholds
    
    Maximizes personal payoff by strategically defecting when threshold success is likely,
    while conditionally cooperating only when necessary to trigger the threshold.
    
    Core rules:
    1. First round: DEFECT (no history, payoff-secure)
    2. Rounds 2 to r-1: Adaptive threshold exploitation based on last round's cooperators
    3. Last round: ALWAYS DEFECT (no future rounds, defection dominates)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        previous_round_actions = history.opponent_actions[round_number - 1, :]
        cooperators_last_round = int(np.sum(previous_round_actions))
        if cooperators_last_round >= self.m:
            return Action.D
        elif cooperators_last_round == self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_3(BaseStrategy):
    """
    Exploitative Threshold Free-Rider: Strategically exploits the threshold mechanism
    by free-riding on others' cooperation while minimizing own contributions. Defects
    in round 1 and final round, then adaptively defects when threshold is met or near,
    cooperating only when necessary to enable threshold achievement.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.my_cooperation_count = 0
        self.last_two_actions = [False, False]

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        prev_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        if prev_cooperators >= self.m:
            return Action.D
        if prev_cooperators == self.m - 1:
            progress_ratio = (self.n_rounds - current_round) / self.n_rounds
            defect_probability = 0.7 + 0.2 * progress_ratio
            if random.random() < defect_probability:
                return Action.D
            else:
                return Action.C
        if self._should_enable_threshold(current_round, prev_cooperators):
            self.my_cooperation_count += 1
            self.last_two_actions = [self.last_two_actions[1], True]
            return Action.C
        else:
            self.last_two_actions = [self.last_two_actions[1], False]
            return Action.D

    def _should_enable_threshold(self, current_round: int, prev_cooperators: int) -> bool:
        """
        Determine if we should cooperate to enable threshold achievement.
        Only cooperate if:
        1. Threshold is still achievable (prev_cooperators == m - 1)
        2. We have remaining rounds to extract value
        3. We haven't cooperated too recently (last two rounds were defections)
        4. We haven't exceeded our cooperation quota
        """
        rounds_remaining = self.n_rounds - current_round - 1
        if prev_cooperators != self.m - 1:
            return False
        if rounds_remaining < 2:
            return False
        if self.last_two_actions[0] or self.last_two_actions[1]:
            return False
        expected_cooperations_needed = math.ceil(self.n_rounds * self.m / self.n_players)
        if self.my_cooperation_count < expected_cooperations_needed:
            return True
        return False

class Strategy_EXPLOITATIVE_5(BaseStrategy):
    """
    Conditional Free-Rider with Adaptive Defection Strategy.
    
    Exploits opponents by:
    1. Always defecting in round 1 and final round
    2. Free-riding when cooperation threshold is already met
    3. Conditionally cooperating only at the knife-edge (m-1 cooperators)
    4. Tracking opponent defection patterns to estimate switching probability
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_defection_counts = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            self.opponent_defection_counts = np.zeros(n - 1)
            return Action.D
        if current_round == r - 1:
            return Action.D
        prev_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        prev_defections = 1 - history.opponent_actions[current_round - 1, :]
        self.opponent_defection_counts += prev_defections
        if prev_cooperators >= m:
            return Action.D
        elif prev_cooperators == m - 1:
            switch_probability = self._estimate_switching_probability(current_round, prev_cooperators)
            if switch_probability > 0.6:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _estimate_switching_probability(self, current_round: int, prev_cooperators: int) -> float:
        """
        Estimate the probability that a defector will switch to cooperation.
        
        Analyzes opponent defection consistency and volatility.
        """
        n = self.game_description.n_players
        m = self.game_description.m
        if current_round < 2:
            return 0.5
        num_defectors = n - 1 - prev_cooperators
        if num_defectors == 0:
            return 0.0
        rounds_so_far = current_round
        avg_defection_rate = self.opponent_defection_counts / max(1, rounds_so_far)
        consistent_defectors = np.sum(avg_defection_rate > 0.7)
        volatile_defectors = num_defectors - consistent_defectors
        if volatile_defectors == 0:
            return 0.3
        elif volatile_defectors >= num_defectors * 0.5:
            return 0.45
        else:
            return min(0.6, volatile_defectors / max(1, num_defectors))

class Strategy_EXPLOITATIVE_6(BaseStrategy):
    """
    Adaptive Threshold Parasitism: An exploitative strategy that free-rides on 
    collective cooperation by consistently defecting while monitoring the threshold.
    
    Core logic:
    - Round 0: DEFECT (test if others will cooperate)
    - Rounds 1 to r-2: DEFECT (exploit any cooperators who meet threshold)
    - Round r-1: DEFECT (terminal greed, no future consequences)
    
    This strategy maximizes payoff by capturing the reward bonus (k) without 
    bearing the cooperation cost, assuming conditional cooperators in the population.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        last_round_idx = current_round - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[last_round_idx, :]))
        if cooperators_last_round >= self.m:
            return Action.D
        elif cooperators_last_round == self.m - 1:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_7(BaseStrategy):
    """
    Adaptive Threshold Hunter: An exploitative strategy that consistently defects
    to free-ride on others' cooperation while avoiding the costs of contribution.
    
    Core principle: Always defect, with sophisticated observation confirming that
    defection is optimal. Exploits the asymmetry where defectors earn k+1 when
    cooperation succeeds (vs. k for cooperators) while both earn 1 when it fails.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_count_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number < self.game_description.n_rounds - 1:
            cooperation_count_history = []
            for round_idx in range(state.round_number):
                cooperators_in_round = int(np.sum(history.opponent_actions[round_idx, :]))
                cooperation_count_history.append(cooperators_in_round)
            if len(cooperation_count_history) > 0:
                avg_cooperators = np.mean(cooperation_count_history)
                cooperation_rate = avg_cooperators / self.game_description.n_players
            else:
                cooperation_rate = 0.0
            threshold_rate = (self.game_description.m - 1) / self.game_description.n_players
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_9(BaseStrategy):
    """
    Adaptive Threshold Exploitation (ATE) Strategy
    
    An exploitative strategy for the Collective Risk Dilemma that:
    - Defects in round 1 to gather information about cooperators
    - Exploits stable cooperative pools through free-riding
    - Uses conditional cooperation as a manipulation tactic
    - Always defects in the final round
    - Adapts based on recent cooperation rates
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold_cooperative = self.m / self.n * 1.3
        self.threshold_minimal = self.m / self.n * 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        lookback_rounds = min(3, current_round)
        if history is None or lookback_rounds == 0:
            return Action.D
        total_cooperators = 0
        for i in range(max(0, current_round - lookback_rounds), current_round):
            cooperators_in_round = np.sum(history.opponent_actions[i, :])
            total_cooperators += cooperators_in_round
        recent_coop_rate = total_cooperators / (lookback_rounds * self.n) if lookback_rounds > 0 else 0.0
        if recent_coop_rate >= self.threshold_cooperative:
            return Action.D
        elif recent_coop_rate <= self.threshold_minimal:
            return Action.D
        else:
            last_round_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
            if last_round_cooperators >= self.m:
                return Action.D
            elif last_round_cooperators + 1 >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_10(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Threshold Monitoring.
    
    Exploits asymmetry in the Collective Risk Dilemma by free-riding on others'
    cooperation when the threshold is likely to be met, while adaptively cooperating
    early in the game or when the threshold appears unattainable without additional
    cooperators. Always defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        last_round_opponent_actions = history.opponent_actions[current_round - 1, :]
        cooperators_last = int(np.sum(last_round_opponent_actions))
        my_last_action = history.my_actions[current_round - 1]
        total_cooperators_last = cooperators_last + (1 if my_last_action else 0)
        cooperation_rate = total_cooperators_last / self.n_players
        threshold_ratio = self.m / self.n_players
        if cooperation_rate >= threshold_ratio:
            prob_threshold_met = min(cooperation_rate, 0.95)
        else:
            prob_threshold_met = 0.0 + total_cooperators_last / self.m * 0.3
        if prob_threshold_met >= threshold_ratio:
            return Action.D
        else:
            early_game_threshold = self.n_rounds * 0.33
            if current_round < early_game_threshold:
                return Action.C
            else:
                deficit = self.m - total_cooperators_last
                if deficit <= 2 and deficit > 0:
                    return Action.C
                else:
                    return Action.D

class Strategy_EXPLOITATIVE_11(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD): An exploitative strategy that systematically
    free-rides on others' cooperation while maintaining flexibility to adapt.
    
    Core principle: Defect to capture both private payoff (1) and community reward (k)
    when others cooperate, while avoiding the sucker's payoff (0) if cooperation fails.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round >= self.r - 2:
            return Action.D
        coop_count_prev = int(sum(history.opponent_actions[current_round - 1, :]))
        return Action.D

class Strategy_EXPLOITATIVE_12(BaseStrategy):
    """
    Exploitative strategy with adaptive defection and conditional cooperation.
    Maximizes payoff by exploiting the asymmetry: defectors gain the full reward k
    when threshold m is met (without contributing), while cooperators pay the cost.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if self.m == self.n_players:
            return Action.D
        if self.n_rounds == 2:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[round_num - 1, :]))
        if cooperators_last_round >= self.m:
            return Action.D
        early_threshold = self.n_rounds // 3
        mid_threshold = 2 * self.n_rounds // 3
        if round_num == self.n_rounds - 1:
            return Action.D
        if round_num <= early_threshold:
            return Action.D
        if round_num <= mid_threshold:
            if cooperators_last_round == self.m - 1:
                return Action.C
            else:
                return Action.D
        if self.n_rounds > 20:
            final_rounds = 3
            if round_num >= self.n_rounds - final_rounds:
                return Action.D
            if cooperators_last_round == self.m - 1:
                return Action.C
            else:
                return Action.D
        if cooperators_last_round == self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_13(BaseStrategy):
    """
    Adaptive Defection with Selective Cooperation strategy for Collective Risk Dilemma.
    
    Core principle: Exploit the asymmetry where defectors earn more than cooperators
    when threshold is met (1+k vs 0+k). Strategy defaults to defection while adaptively
    monitoring cooperation levels to determine threshold viability.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.round_1_cooperators = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == 1:
            self.round_1_cooperators = int(sum(history.opponent_actions[0, :]))
            if self.round_1_cooperators >= self.game_description.m - 1:
                return Action.D
            else:
                return Action.D
        if state.round_number < self.game_description.n_rounds - 1:
            if state.round_number >= 2:
                last_two_rounds = history.opponent_actions[-2:, :]
                recent_cooperators = int(np.sum(last_two_rounds))
                recent_cooperation_rate = recent_cooperators / (2.0 * (self.game_description.n_players - 1))
            else:
                recent_cooperators = int(sum(history.opponent_actions[-1, :]))
                recent_cooperation_rate = recent_cooperators / float(self.game_description.n_players - 1)
            threshold_rate = (self.game_description.m - 1) / float(self.game_description.n_players - 1)
            if recent_cooperation_rate >= threshold_rate:
                return Action.D
            else:
                return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_14(BaseStrategy):
    """
    Exploitative strategy using adaptive free-riding with threshold opportunism.
    
    Defaults to defection to free-ride on others' cooperation and collect the threshold
    reward (k) without contributing. Tracks opponent cooperation patterns to identify
    exploitation opportunities. Maintains defection dominance across all game phases.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if state.round_number == 0:
            return Action.D
        rounds_remaining = r - state.round_number
        if rounds_remaining == 1:
            return Action.D
        if rounds_remaining == 2:
            return Action.D
        opponent_actions = history.opponent_actions[:state.round_number, :]
        if opponent_actions.shape[0] == 0:
            observed_cooperation_rate = 0.0
        else:
            total_cooperations = np.sum(opponent_actions)
            total_observations = opponent_actions.shape[0] * opponent_actions.shape[1]
            observed_cooperation_rate = total_cooperations / total_observations if total_observations > 0 else 0.0
        if m == n:
            return Action.D
        if m == 2:
            return Action.D
        threshold_fraction = m / n
        if observed_cooperation_rate >= threshold_fraction:
            return Action.D
        elif observed_cooperation_rate < threshold_fraction and rounds_remaining > 2:
            return Action.D
        else:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_15(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD) Strategy
    
    Exploits the asymmetry in payoffs by defecting when others are likely to 
    meet the cooperation threshold, and only cooperating strategically when 
    becoming the marginal player could enable threshold success.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        return self._adaptive_decision(current_round, history)

    def _adaptive_decision(self, current_round: int, history: PlayerHistory) -> Action:
        """
        Adaptive decision logic for mid-game rounds.
        Estimates cooperation probability and decides based on expected threshold.
        """
        recent_coop_rate = self._calculate_recent_cooperation_rate(history)
        expected_others_coop = recent_coop_rate * (self.n_players - 1)
        rounds_remaining = self.n_rounds - current_round
        if expected_others_coop >= self.m - 0.5:
            return Action.D
        elif expected_others_coop >= self.m - 1.5 and rounds_remaining >= 3:
            marginal_probability = (self.m - expected_others_coop) / 2.0
            marginal_probability = max(0.0, min(1.0, marginal_probability))
            if random.random() < marginal_probability:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory) -> float:
        """
        Calculate the cooperation rate of opponents in recent rounds.
        Uses last 3 rounds of history if available.
        """
        n_history_rounds = history.opponent_actions.shape[0]
        if n_history_rounds == 0:
            return 0.0
        lookback_window = min(3, n_history_rounds)
        recent_actions = history.opponent_actions[-lookback_window:, :]
        total_cooperators = int(np.sum(recent_actions))
        total_observations = lookback_window * self.n_players
        if total_observations == 0:
            return 0.0
        cooperation_rate = total_cooperators / total_observations
        return cooperation_rate

class Strategy_EXPLOITATIVE_16(BaseStrategy):
    """
    Conditional Parasitism with Adaptive Thresholding: An exploitative strategy that
    free-rides on others' cooperation while maintaining plausible deniability.
    
    - Round 1: Defect to explore baseline cooperation
    - Rounds 2 to r-1: Adaptively defect or cooperate based on previous round's cooperator count
    - Final round: Always defect for terminal exploitation
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        prev_round_idx = current_round - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        if cooperators_last_round >= m:
            return Action.D
        elif cooperators_last_round == m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_17(BaseStrategy):
    """
    Adaptive Threshold Rider: An exploitative strategy that free-rides on others' 
    cooperation when the threshold is likely met, while conditionally cooperating 
    only when necessary to prevent collective failure. Defects in final round 
    regardless of history.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.coop_history = []
        self.threshold_rate = game_description.m / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        n_rounds = self.game_description.n_rounds
        n_players = self.game_description.n_players
        m = self.game_description.m
        if round_num == 0:
            return Action.D
        if round_num in [1, 2]:
            if history is not None:
                prev_cooperators = int(np.sum(history.opponent_actions[round_num - 1, :]))
                self.coop_history.append(prev_cooperators)
            return Action.D
        if round_num == n_rounds - 1:
            return Action.D
        if history is not None:
            if round_num > 0 and len(self.coop_history) < round_num:
                prev_cooperators = int(np.sum(history.opponent_actions[round_num - 1, :]))
                self.coop_history.append(prev_cooperators)
            if len(self.coop_history) > 0:
                observed_coop_rate = np.mean(self.coop_history) / n_players
            else:
                observed_coop_rate = 0.0
            rounds_remaining = n_rounds - round_num
            if observed_coop_rate >= self.threshold_rate:
                return Action.D
            elif observed_coop_rate >= self.threshold_rate - 0.1:
                if rounds_remaining >= 2:
                    return Action.C
                else:
                    return Action.D
            elif rounds_remaining >= 2:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_18(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Defection strategy.
    
    Exploits the threshold mechanism by:
    1. Defecting in round 1 (intelligence gathering)
    2. Free-riding when threshold is already met (cooperators >= m)
    3. Pivoting when exactly one more cooperator is needed (cooperators == m-1)
    4. Defecting when threshold is unreachable (cooperators < m-1)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[state.round_number - 1, :]))
        if cooperators_last_round >= self.m:
            return Action.D
        if cooperators_last_round == self.m - 1:
            return Action.C
        if cooperators_last_round < self.m - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_19(BaseStrategy):
    """
    Adaptive Threshold Predation: A relentless free-rider strategy that exploits
    cooperative players by defecting when cooperation is observed, while avoiding
    contribution risk when cooperation is unlikely. Defects unconditionally in the
    final round to capture maximum terminal payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        total_cooperations = int(np.sum(history.opponent_actions[:round_number, :]))
        total_actions = round_number * self.n_players
        if total_actions == 0:
            return Action.D
        cooperation_rate = total_cooperations / total_actions
        early_threshold_round = 3
        if round_number < early_threshold_round:
            threshold_high = (self.m - 0.3) / self.n_players
            threshold_low = (self.m - 1.3) / self.n_players
        else:
            threshold_high = (self.m - 0.5) / self.n_players
            threshold_low = (self.m - 1.5) / self.n_players
        if cooperation_rate >= threshold_high:
            return Action.D
        elif cooperation_rate < threshold_low:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_20(BaseStrategy):
    """
    Calculated Parasitism: Exploitative strategy that free-rides on others' cooperation
    while maximizing private gains through adaptive defection and threshold exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
        if cooperators_last_round >= self.m:
            return Action.D
        rounds_remaining = self.n_rounds - current_round
        recent_window = min(3, current_round)
        recent_cooperators = [int(sum(history.opponent_actions[current_round - i, :])) for i in range(1, recent_window + 1)]
        recent_threshold_met = sum((1 for c in recent_cooperators if c >= self.m))
        phase_threshold_early = self.n_rounds / 3
        phase_threshold_late = 2 * self.n_rounds / 3
        if current_round <= phase_threshold_early:
            return Action.D
        if current_round == self.n_rounds - 2:
            return Action.D
        if current_round >= phase_threshold_late:
            if recent_threshold_met >= 2 and rounds_remaining > 1:
                if random.random() < 0.03:
                    return Action.C
            return Action.D
        if recent_threshold_met >= 2 and rounds_remaining > 2:
            cooperation_probability = 0.15 * (recent_threshold_met / recent_window)
            high_cooperators = 0
            for opponent_idx in range(self.n_players - 1):
                opponent_cooperation_rate = sum(history.opponent_actions[:current_round, opponent_idx]) / current_round
                if opponent_cooperation_rate >= 0.6:
                    high_cooperators += 1
            if high_cooperators > 0 and random.random() < cooperation_probability:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_21(BaseStrategy):
    """
    Conditional Defection with Opportunistic Harvesting.
    
    Exploits the asymmetry of the Collective Risk Dilemma by defecting across all rounds
    to avoid paying the cooperation cost (c=1) while free-riding on others' cooperation
    to capture the reward (k) when the threshold is met.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        previous_round_idx = current_round - 1
        cooperators_prev = int(sum(history.opponent_actions[previous_round_idx, :]))
        return Action.D

class Strategy_EXPLOITATIVE_22(BaseStrategy):
    """
    Adaptive Threshold Parasitism: Exploits cooperative players by free-riding when the threshold
    is met, cooperating only when necessary as a swing vote, and defecting when the group fails
    to coordinate. Maximizes individual payoff through opportunistic threshold exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        current_round = state.round_number
        prev_round_idx = current_round - 1
        prev_cooperators = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        failures = self._count_threshold_failures(history, prev_round_idx)
        if prev_cooperators >= self.m:
            return Action.D
        if failures >= 2:
            return Action.D
        if prev_cooperators == self.m - 1:
            return Action.C
        if prev_cooperators < self.m - 1:
            return Action.D
        return Action.D

    def _count_threshold_failures(self, history: PlayerHistory, up_to_round: int) -> int:
        """
        Count the number of rounds where the threshold m was NOT met.
        Examines history from round 0 to up_to_round (inclusive).
        """
        failure_count = 0
        for round_idx in range(up_to_round + 1):
            opponent_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
            my_action = history.my_actions[round_idx]
            total_cooperators = int(my_action) + opponent_cooperators
            if total_cooperators < self.m:
                failure_count += 1
        return failure_count

class Strategy_EXPLOITATIVE_23(BaseStrategy):
    """
    Threshold-Hunting Defection (THD): An exploitative strategy that systematically
    defects while monitoring cooperation rates to free-ride on others' contributions
    when the threshold is likely to be met. Adapts behavior based on historical
    cooperation trends and round position in the game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        if current_round == self.r - 2:
            return Action.D
        last_round_idx = current_round - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[last_round_idx, :]))
        cooperation_rate = cooperators_last_round / self.n
        if cooperators_last_round >= self.m:
            return Action.D
        if cooperators_last_round >= self.m - 1:
            return Action.D
        if cooperators_last_round >= self.m - 2:
            if self.k > 2:
                return Action.D
            if current_round >= 2:
                two_rounds_ago_idx = current_round - 2
                cooperators_two_rounds_ago = int(np.sum(history.opponent_actions[two_rounds_ago_idx, :]))
                cooperation_trend = cooperators_last_round - cooperators_two_rounds_ago
                if cooperation_trend >= 0:
                    return Action.D
            return Action.D
        if cooperators_last_round < self.m - 2:
            if current_round < self.r / 2:
                return Action.D
            if cooperators_last_round == 0:
                return Action.D
            if current_round >= 2:
                two_rounds_ago_idx = current_round - 2
                cooperators_two_rounds_ago = int(np.sum(history.opponent_actions[two_rounds_ago_idx, :]))
                cooperation_trend = cooperators_last_round - cooperators_two_rounds_ago
                if cooperation_trend <= -0.2 * self.m:
                    return Action.D
                return Action.C
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_24(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Threshold Defection with Conditional Cooperation
    
    Maximizes individual payoff by minimizing contribution costs while exploiting cooperative
    players. Uses perfect information to time defections optimally and adapt to environmental
    cooperation levels.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        c_prev = int(sum(history.opponent_actions[current_round - 1, :]))
        if current_round == self.n_rounds - 1:
            if c_prev >= self.m:
                return Action.D
            elif c_prev == self.m - 1:
                return Action.C
            else:
                return Action.D
        if c_prev >= self.m:
            return Action.D
        elif c_prev >= math.ceil(self.m / 2):
            denominator = self.m - 1
            p_switch = 1.0 - c_prev / denominator if denominator > 0 else 1.0
            if random.random() < p_switch:
                return Action.D
            else:
                return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_25(BaseStrategy):
    """
    Conditional Parasitism with Adaptive Defection
    
    An exploitative strategy that free-rides on cooperative populations by defecting
    when others meet the threshold, while adaptively monitoring cooperation rates
    to maximize extraction in different population environments.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        prev_round_idx = current_round - 1
        my_prev_action = history.my_actions[prev_round_idx]
        opponent_prev_cooperators = sum(history.opponent_actions[prev_round_idx, :])
        total_prev_cooperators = int(my_prev_action) + opponent_prev_cooperators
        rounds_left = self.n_rounds - current_round
        if rounds_left > 1:
            if total_prev_cooperators >= self.m:
                return Action.D
            if total_prev_cooperators < self.m and rounds_left > 2:
                return Action.D
            if total_prev_cooperators < self.m and rounds_left <= 2:
                total_cooperators_history = int(np.sum(history.my_actions[:current_round])) + int(np.sum(history.opponent_actions[:current_round, :]))
                rounds_played = current_round
                avg_cooperation = total_cooperators_history / rounds_played if rounds_played > 0 else 0
                if avg_cooperation >= self.m:
                    return Action.C
                else:
                    return Action.D
        if rounds_left == 0:
            if total_prev_cooperators >= self.m:
                return Action.D
            if total_prev_cooperators < self.m:
                total_cooperators_history = int(np.sum(history.my_actions[:current_round])) + int(np.sum(history.opponent_actions[:current_round, :]))
                rounds_played = current_round
                avg_cooperation = total_cooperators_history / rounds_played if rounds_played > 0 else 0
                if avg_cooperation >= self.m:
                    return Action.C
                else:
                    return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_26(BaseStrategy):
    """
    Adaptive Defection with Conditional Cooperation strategy.
    
    Exploits the payoff asymmetry in the Collective Risk Dilemma by:
    - Free-riding when cooperation is high
    - Selectively cooperating in critical zones to maintain threshold
    - Accelerating defection cascades
    - Always defecting in first and last rounds
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        cooperation_rate = self._calculate_cooperation_rate(history, round_num)
        threshold_met_last_round = self._threshold_met(history, round_num)
        defection_bias = (round_num - 1) / max(1, self.r - 2)
        adjusted_threshold = self.m / self.n + 0.2 * defection_bias
        if cooperation_rate >= adjusted_threshold:
            return Action.D
        elif self.m / self.n * 0.8 <= cooperation_rate < adjusted_threshold:
            if threshold_met_last_round:
                return Action.D
            else:
                cooperation_prob = 0.3 - 0.2 * defection_bias
                cooperation_prob = max(0.0, min(1.0, cooperation_prob))
                if random.random() < cooperation_prob:
                    return Action.C
                else:
                    return Action.D
        elif cooperation_rate < self.m / self.n * 0.6:
            return Action.D
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the cooperation rate from the previous round.
        
        Args:
            history: Player history with opponent actions
            current_round: Current round number (0-indexed)
        
        Returns:
            Cooperation rate as a float in [0, 1]
        """
        if current_round <= 0:
            return 0.0
        prev_round_idx = current_round - 1
        cooperators = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        if self.n == 0:
            return 0.0
        return cooperators / self.n

    def _threshold_met(self, history: PlayerHistory, current_round: int) -> bool:
        """
        Check if the cooperation threshold was met in the previous round.
        
        Args:
            history: Player history with opponent actions
            current_round: Current round number (0-indexed)
        
        Returns:
            True if m or more players cooperated in previous round
        """
        if current_round <= 0:
            return False
        prev_round_idx = current_round - 1
        cooperators = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            cooperators += 1
        return cooperators >= self.m

class Strategy_EXPLOITATIVE_27(BaseStrategy):
    """
    Conditional Defection with Calculated Risk: An exploitative strategy that free-rides on others'
    cooperation while minimizing personal contribution. Defects in round 1 and final round, exploits
    met thresholds, and only cooperates when probabilistic analysis suggests opponent cooperation
    will naturally reach the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperated_last_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        r = self.game_description.n_rounds
        m = self.game_description.m
        n = self.game_description.n_players
        if round_num == 0:
            return Action.D
        if round_num == r - 1:
            return Action.D
        coop_last_round = int(np.sum(history.opponent_actions[round_num - 1, :]))
        if coop_last_round >= m:
            return Action.D
        rounds_remaining = r - round_num - 1
        cooperators_needed = m - coop_last_round
        if cooperators_needed > rounds_remaining:
            return Action.D
        opponent_coop_rate = self._calculate_opponent_cooperation_rate(history, round_num, n)
        expected_future_cooperators = opponent_coop_rate * (n - 1)
        if expected_future_cooperators >= cooperators_needed:
            if not self.cooperated_last_round:
                self.cooperated_last_round = True
                return Action.C
            else:
                self.cooperated_last_round = False
                return Action.D
        else:
            self.cooperated_last_round = False
            return Action.D

    def _calculate_opponent_cooperation_rate(self, history: PlayerHistory, current_round: int, n_players: int) -> float:
        """
        Calculate the historical cooperation rate of opponents across all previous rounds.
        Handles edge case of no history gracefully.
        """
        if current_round == 0:
            return 0.0
        total_opponent_actions = history.opponent_actions[:current_round, :].size
        if total_opponent_actions == 0:
            return 0.0
        total_cooperations = int(np.sum(history.opponent_actions[:current_round, :]))
        return total_cooperations / total_opponent_actions

class Strategy_EXPLOITATIVE_28(BaseStrategy):
    """
    Adaptive Free-Riding with Threshold Exploitation Strategy.
    
    Maximizes personal payoff by exploiting the threshold mechanism through:
    1. Defecting by default to secure private payoff
    2. Exploiting others' cooperation when threshold is likely met
    3. Always defecting in final rounds (no future reputation cost)
    4. Adapting based on observed cooperation rates and volatility
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.observation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        n_rounds = self.game_description.n_rounds
        m = self.game_description.m
        n = self.game_description.n_players
        if round_num == n_rounds - 1:
            return Action.D
        if round_num == 0:
            return Action.D
        if history is not None:
            for prev_round in range(round_num):
                cooperators_in_round = int(np.sum(history.opponent_actions[prev_round, :]))
                self.observation_history.append(cooperators_in_round)
        if len(self.observation_history) == 0:
            return Action.D
        avg_cooperators = np.mean(self.observation_history)
        expected_cooperators = avg_cooperators
        if m == n:
            return Action.D
        if m == 2:
            return Action.D
        if expected_cooperators >= m:
            return Action.D
        elif expected_cooperators >= m - 1:
            if len(self.observation_history) >= 3:
                recent_rates = self.observation_history[-3:]
                volatility = float(np.std(recent_rates))
                return Action.D
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_29(BaseStrategy):
    """
    Threshold Parasite: Exploitative strategy that free-rides on cooperation when the threshold is met,
    defects when cooperation is insufficient, and adapts based on observed cooperation trends.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[round_num - 1, :]))
        if round_num < self.n_rounds - 1:
            if cooperators_last_round >= self.m:
                return Action.D
            elif cooperators_last_round >= self.m - 1:
                trend = self._estimate_cooperation_trend(history, round_num)
                if trend >= 0.6:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D
        else:
            return Action.D

    def _estimate_cooperation_trend(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the proportion of cooperators across the last 3 rounds (or fewer if unavailable).
        Returns a value between 0 and 1 representing the cooperation rate.
        """
        lookback_rounds = min(3, current_round)
        if lookback_rounds == 0:
            return 0.0
        total_cooperators = 0
        for i in range(current_round - lookback_rounds, current_round):
            total_cooperators += int(sum(history.opponent_actions[i, :]))
        max_cooperators = lookback_rounds * self.n_players
        if max_cooperators == 0:
            return 0.0
        cooperation_rate = total_cooperators / max_cooperators
        return cooperation_rate

class Strategy_EXPLOITATIVE_30(BaseStrategy):
    """
    Threshold Parasite: An exploitative strategy that free-rides on others' cooperation.
    
    Core logic: Always defect to avoid contribution costs while capturing the threshold reward
    when m-1 or more other players cooperate independently. Intensifies defection in final rounds
    when no future punishment is possible.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if cooperators_last_round >= self.m - 1:
            return Action.D
        elif cooperators_last_round > 0 and cooperators_last_round < self.m - 1:
            if current_round >= self.n_rounds - 2:
                return Action.D
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_31(BaseStrategy):
    """
    Adaptive Parasitism: Exploitative strategy that maximizes personal payoff by 
    exploiting the coordination problem. Defects strategically to free-ride on 
    cooperators while maintaining plausible deniability through selective cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        coop_count_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
        if coop_count_last_round >= self.m:
            if coop_count_last_round >= self.m + 2:
                return Action.D
            elif random.random() < 0.3:
                return Action.C
            else:
                return Action.D
        elif coop_count_last_round >= self.m - 1:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_32(BaseStrategy):
    """
    Adaptive Freeriding with Conditional Commitment.
    
    Exploits the threshold structure by free-riding on others' cooperation,
    defecting when thresholds cannot be met, and only conditionally cooperating
    in the final round when positioned as a pivot player.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
        total_cooperators_history = int(np.sum(history.opponent_actions))
        cooperation_rate = total_cooperators_history / (current_round * self.n) if current_round > 0 else 0.0
        early_phase_end = max(0, self.r - 3)
        penultimate_round = self.r - 2
        second_last_round = self.r - 1
        final_round = self.r - 1
        if current_round <= early_phase_end:
            if cooperators_last_round >= self.m:
                return Action.D
            elif cooperators_last_round == self.m - 1:
                return Action.D
            else:
                return Action.D
        elif current_round == penultimate_round:
            target_rate_low = self.m / self.n * 0.8
            target_rate_high = self.m / self.n * 1.5
            if cooperation_rate > target_rate_high:
                return Action.D
            else:
                return Action.D
        elif current_round == second_last_round:
            min_expected_cooperations = self.m * (self.r - 2) if self.r >= 2 else 0
            if total_cooperators_history >= min_expected_cooperations:
                return Action.D
            else:
                return Action.D
        elif current_round == final_round:
            rounds_meeting_threshold = 0
            for round_idx in range(current_round):
                if int(sum(history.opponent_actions[round_idx, :])) >= self.m:
                    rounds_meeting_threshold += 1
            avg_cooperation = total_cooperators_history / current_round if current_round > 0 else 0.0
            opponents_who_cooperated = int(np.sum(np.any(history.opponent_actions, axis=0)))
            threshold_likely_met = rounds_meeting_threshold >= current_round * 0.75 and avg_cooperation >= self.m - 0.5
            if threshold_likely_met:
                return Action.D
            elif opponents_who_cooperated == self.m - 1:
                consistency_check = True
                cooperator_counts = np.sum(history.opponent_actions, axis=0)
                for opponent_coop_count in cooperator_counts:
                    if opponent_coop_count > 0 and opponent_coop_count < current_round * 0.6:
                        consistency_check = False
                        break
                if consistency_check and avg_cooperation >= self.m - 1:
                    return Action.C
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_33(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Free-Riding with Threshold Monitoring
    
    Maximizes personal payoff by exploiting the threshold mechanism through:
    1. Initial defection to probe opponent strategies
    2. Adaptive free-riding based on observed cooperation frequency
    3. Selective cooperation only when strategically valuable
    4. Terminal round defection for guaranteed exploitation
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = 0.6
        self.cooperation_pressure_threshold = 1.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        coop_rate = self._calculate_cooperation_rate(history)
        last_round_cooperators = self._count_last_round_cooperators(history)
        rounds_remaining = self.game_description.n_rounds - state.round_number - 1
        m = self.game_description.m
        k = self.game_description.k
        if coop_rate > self.cooperation_threshold:
            return Action.D
        if last_round_cooperators >= m - 1:
            return Action.D
        if last_round_cooperators < m - 1 and coop_rate > 0 and (rounds_remaining > 2) and (k > self.cooperation_pressure_threshold):
            return Action.C
        return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        """
        Calculate the frequency of rounds where threshold (m) was met.
        Returns value between 0 and 1.
        """
        if history.opponent_actions.shape[0] == 0:
            return 0.0
        total_rounds = history.opponent_actions.shape[0]
        m = self.game_description.m
        n = self.game_description.n_players
        threshold_met_count = 0
        for round_idx in range(total_rounds):
            opponent_coop = np.sum(history.opponent_actions[round_idx, :])
            self_coop = 1 if history.my_actions[round_idx] else 0
            total_coop = opponent_coop + self_coop
            if total_coop >= m:
                threshold_met_count += 1
        return threshold_met_count / total_rounds if total_rounds > 0 else 0.0

    def _count_last_round_cooperators(self, history: PlayerHistory) -> int:
        """
        Count the number of cooperators in the most recent round.
        Includes both opponents and self.
        """
        if history.opponent_actions.shape[0] == 0:
            return 0
        last_round_idx = history.opponent_actions.shape[0] - 1
        opponent_coop = int(np.sum(history.opponent_actions[last_round_idx, :]))
        self_coop = 1 if history.my_actions[last_round_idx] else 0
        return opponent_coop + self_coop

class Strategy_EXPLOITATIVE_34(BaseStrategy):
    """
    Exploitative Strategy: Conditional Free-Riding with Adaptive Thresholds
    
    Core philosophy: Exploit the threshold mechanism by free-riding on others'
    cooperation while minimizing personal contribution. Cooperate only when
    strategically necessary to unlock future free-riding opportunities.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        prev_round_idx = current_round - 1
        prev_cooperators = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        if self.m == self.n:
            return Action.C
        if prev_cooperators >= self.m:
            return Action.D
        elif prev_cooperators == self.m - 1:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_35(BaseStrategy):
    """
    Conditional Defection with Opportunistic Harvesting.
    
    This strategy exploits the asymmetry in payoff structure by always defecting,
    unless circumstances force cooperation. The core mechanism:
    - Always defect on round 1 (no history to exploit)
    - Always defect on final round (no future rounds to benefit from cooperation)
    - In middle rounds, defect to harvest rewards when threshold was met in previous round,
      or defect when threshold was not met (no benefit to cooperating)
    
    In essence: this strategy always plays DEFECT, making it a pure defection strategy
    that exploits cooperators when the threshold is met.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        current_round = state.round_number
        n_rounds = self.game_description.n_rounds
        m = self.game_description.m
        if current_round == n_rounds - 1:
            return Action.D
        previous_round_index = current_round - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[previous_round_index, :]))
        if cooperators_last_round >= m:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_36(BaseStrategy):
    """
    Exploitative Strategy: Conditional Free-Riding with Adaptive Thresholding
    
    Maximizes personal payoff by defaulting to defection and cooperating only when
    the cooperation threshold is nearly certain to be met, allowing free-riding on
    others' contributions while securing the k reward.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        prev_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if current_round <= self.r / 3:
            threshold = self.m
        elif current_round <= 2 * self.r / 3:
            threshold = self.m - 1
        else:
            threshold = max(1, self.m - 2)
        if prev_cooperators >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_37(BaseStrategy):
    """
    Adaptive Conditional Exploitation Strategy for Collective Risk Dilemma.
    
    Maximizes personal payoff by exploiting others' cooperation while minimizing
    contribution costs. Defects by default, cooperates only when pivotal (the
    marginal player needed to reach the threshold), and always defects in the
    final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n_rounds = self.game_description.n_rounds
        m = self.game_description.m
        if state.round_number == 0:
            return Action.D
        if state.round_number == n_rounds - 1:
            return Action.D
        prev_round_idx = state.round_number - 1
        coop_count = int(sum(history.opponent_actions[prev_round_idx, :]))
        if coop_count >= m:
            return Action.D
        if coop_count == m - 1:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_38(BaseStrategy):
    """
    Adaptive Defection with Conditional Cooperation (Exploitative Strategy).
    
    This strategy exploits the payoff asymmetry in the Collective Risk Dilemma:
    defectors earn k+1 when the threshold is met (free-riding), while cooperators
    earn only k. The strategy maximizes payoff by defecting in all rounds, as
    cooperation never provides a payoff advantage.
    
    Core logic:
    - Round 0 (first): DEFECT (establish baseline, observe others)
    - Rounds 1 to r-2 (middle): DEFECT (threshold either met for free-riding,
      pivotal but defection pays better, or unachievable)
    - Round r-1 (final): DEFECT (no future punishment possible; extract final payoff)
    
    Result: Always defect, earning k+1 when others cooperate enough, or 1 otherwise.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_39(BaseStrategy):
    """
    Adaptive Predation: An exploitative strategy for the Collective Risk Dilemma.
    
    Exploits cooperative players by:
    1. Always defecting in round 1 and final round
    2. Defecting when others cooperate above threshold in middle rounds
    3. Pulsing cooperation occasionally to restimulate exploitation opportunities
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold_rate = self.m / (self.n - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        previous_round_opponent_actions = history.opponent_actions[current_round - 1, :]
        cooperators_in_previous = np.sum(previous_round_opponent_actions)
        cooperation_rate = cooperators_in_previous / (self.n - 1)
        if cooperation_rate >= self.threshold_rate:
            return Action.D
        consecutive_defects = self._count_consecutive_defects(history, current_round)
        rounds_remaining = self.r - current_round
        if consecutive_defects >= 2 and rounds_remaining >= 2:
            return Action.C
        return Action.D

    def _count_consecutive_defects(self, history: PlayerHistory, current_round: int) -> int:
        """Count consecutive defections by this player ending at current_round - 1."""
        count = 0
        for i in range(current_round - 1, -1, -1):
            if history.my_actions[i]:
                break
            count += 1
        return count

class Strategy_EXPLOITATIVE_40(BaseStrategy):
    """
    Adaptive Threshold Gaming (ATG): An exploitative strategy that free-rides on cooperation
    by defaulting to defection and only cooperating strategically when it maximizes payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_adapt = (self.m - 0.5) / self.n
        self.cooperation_window = math.ceil(self.m / 3)
        self.cooperator_history = {}

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.r - 1:
            return Action.D
        current_round = state.round_number
        last_round_idx = current_round - 1
        observed_cooperators = int(np.sum(history.opponent_actions[last_round_idx, :]))
        if self.m == self.n:
            return Action.D
        if observed_cooperators >= self.m:
            return Action.D
        if observed_cooperators == self.m - 1:
            return Action.D
        if observed_cooperators < self.m - 1:
            deficit = self.m - observed_cooperators - 1
            if deficit <= self.cooperation_window:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_41(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD): An exploitative strategy that maximizes payoff
    by free-riding on others' cooperation when the threshold is met, while selectively
    cooperating only when threshold failure is imminent. Defects unconditionally in
    round 1 and the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
        if cooperators_last_round >= self.m:
            return Action.D
        if cooperators_last_round == 0:
            return Action.D
        deficit = self.m - cooperators_last_round
        rounds_remaining = self.n_rounds - current_round
        if cooperators_last_round == self.m - 1:
            expected_cooperators_next = self._estimate_future_cooperation(current_round, history)
            if expected_cooperators_next >= self.m:
                return Action.D
            else:
                return Action.C
        if cooperators_last_round < self.m - 1:
            if deficit > 2 or rounds_remaining == 1:
                return Action.C
            elif deficit <= 2 and rounds_remaining >= 2:
                return Action.D
        return Action.D

    def _estimate_future_cooperation(self, current_round: int, history: PlayerHistory) -> float:
        """
        Estimate the number of cooperators expected in the next round.
        Uses historical cooperation rate and momentum analysis.
        """
        past_rounds = current_round
        total_opponent_cooperations = float(np.sum(history.opponent_actions[:current_round, :]))
        total_slots = self.n_players * past_rounds
        if total_slots == 0:
            cooperation_rate = 0.0
        else:
            cooperation_rate = total_opponent_cooperations / total_slots
        recent_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        if current_round <= 1:
            momentum = 0
        else:
            prior_cooperators = int(sum(history.opponent_actions[current_round - 2, :]))
            momentum = recent_cooperators - prior_cooperators
        threshold_rate = self.m / self.n_players
        if cooperation_rate < threshold_rate:
            predicted = max(0.0, recent_cooperators + momentum)
        else:
            predicted = cooperation_rate * self.n_players
        return predicted

class Strategy_EXPLOITATIVE_42(BaseStrategy):
    """
    Adaptive Threshold Parasitism: An exploitative strategy that free-rides on others'
    cooperation by detecting when the threshold is likely to be met, then defecting to
    maximize personal payoff. Uses a rolling cooperation metric to adapt between parasitic
    and occasionally cooperative modes in mid-game, with guaranteed defection in final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.epsilon = 0.15
        self.window_size = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        k = self.game_description.k
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        window = min(self.window_size, current_round)
        recent_history = history.opponent_actions[max(0, current_round - window):current_round]
        if recent_history.size == 0:
            return Action.D
        total_cooperations = np.sum(recent_history)
        total_slots = recent_history.shape[0] * recent_history.shape[1]
        if total_slots == 0:
            cooperation_rate = 0.0
        else:
            cooperation_rate = total_cooperations / total_slots
        threshold = m / n - self.epsilon
        rounds_remaining = r - current_round - 1
        if cooperation_rate >= threshold:
            return Action.D
        elif rounds_remaining > 2:
            return Action.D
        else:
            p_late = min(0.5, m / n)
            if random.random() < p_late:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_43(BaseStrategy):
    """
    Conditional Parasitism with Adaptive Thresholding.
    
    Exploitative strategy that free-rides on others' cooperation when possible.
    Defects in round 1 to gather information, adapts in middle rounds based on
    observed cooperation levels, and defects in final round for maximum extraction.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n = game_description.n_players
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        previous_round_idx = round_num - 1
        cooperators_prev = int(np.sum(history.opponent_actions[previous_round_idx, :]))
        threshold_risk = self.m - 1
        if cooperators_prev >= self.m:
            return Action.D
        elif cooperators_prev == threshold_risk:
            if random.random() < 0.8:
                return Action.D
            else:
                return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_44(BaseStrategy):
    """
    Adaptive Threshold Parasitism: An exploitative strategy that free-rides on others' 
    cooperation when possible, while maintaining just enough flexibility to capture rewards 
    when serving as the marginal player. Defects in first and last rounds, conditionally 
    cooperates only when pivotal in middle rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        n = self.n_players
        m = self.m
        r = self.n_rounds
        if round_number == r - 1:
            return Action.D
        if round_number == 0:
            return Action.D
        previous_round_cooperators = int(sum(history.opponent_actions[round_number - 1, :]))
        if previous_round_cooperators >= m:
            return Action.D
        if previous_round_cooperators == m - 1:
            pivot_probability = m / (n - 1)
            if random.random() < pivot_probability:
                return Action.C
            else:
                return Action.D
        if previous_round_cooperators < m - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_45(BaseStrategy):
    """
    Adaptive Threshold Gaming: Exploits the Collective Risk Dilemma by dynamically
    shifting between exploitation and conditional cooperation based on observed
    cooperation rates. Maximizes payoff through free-riding when threshold is met,
    minimizes losses when threshold fails, and employs aggressive defection in
    final rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.p_init = self.m / self.n
        self.p_exploit_high = 1.0 - self.k / (self.k + 1.0)
        self.p_conditional = (self.m - 1) / self.n if self.m > 1 else 0.0
        self.p_defect_low = 0.1
        self.threshold_high = (self.m + 1) / self.n
        self.threshold_medium = self.m / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C if random.random() < self.p_init else Action.D
        if state.round_number == self.r - 1:
            return Action.D
        if state.round_number == self.r - 2:
            coop_rate = self._compute_overall_cooperation_rate(history)
            if coop_rate >= self.threshold_medium:
                return Action.D
        c_prev = self._count_cooperators_in_previous_round(history)
        if c_prev < self.m:
            return Action.D if random.random() < 1.0 - self.p_defect_low else Action.C
        coop_rate = c_prev / self.n
        if coop_rate >= self.threshold_high:
            return Action.D if random.random() < self.p_exploit_high else Action.C
        if coop_rate >= self.threshold_medium:
            return Action.D if random.random() < 0.7 else Action.C
        return Action.D

    def _count_cooperators_in_previous_round(self, history: PlayerHistory) -> int:
        """
        Count the number of cooperators (including self) in the most recent round.
        """
        if history is None or len(history.opponent_actions) == 0:
            return 0
        self_cooperated = 1 if history.my_actions[-1] else 0
        opponent_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        return self_cooperated + opponent_cooperators

    def _compute_overall_cooperation_rate(self, history: PlayerHistory) -> float:
        """
        Compute the average cooperation rate across all players and all rounds so far.
        """
        if history is None or len(history.my_actions) == 0:
            return 0.0
        n_rounds_played = len(history.my_actions)
        self_cooperations = int(np.sum(history.my_actions))
        opponent_cooperations = int(np.sum(history.opponent_actions))
        total_cooperations = self_cooperations + opponent_cooperations
        total_decisions = self.n * n_rounds_played
        if total_decisions == 0:
            return 0.0
        return total_cooperations / total_decisions

class Strategy_EXPLOITATIVE_46(BaseStrategy):
    """
    Adaptive Parasitic Harvesting (APH) Strategy for Collective Risk Dilemma.
    
    Core philosophy: Exploit the threshold mechanic by free-riding on others' cooperation.
    - Round 0: Defect to probe opponents
    - Rounds 1 to r-2: Conditional defection based on previous round cooperation count
      - If cooperation_count >= m: Defect (free-ride)
      - If cooperation_count == m-1: Cooperate (ensure threshold for reward k)
      - If cooperation_count < m-1: Defect (threshold unattainable)
    - Final round (r-1): Unconditional defection (no future consequences)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n_rounds = self.game_description.n_rounds
        m = self.game_description.m
        if state.round_number == 0:
            return Action.D
        if state.round_number == n_rounds - 1:
            return Action.D
        previous_round_idx = state.round_number - 1
        opponent_actions_prev = history.opponent_actions[previous_round_idx, :]
        cooperation_count = np.sum(opponent_actions_prev)
        if cooperation_count >= m:
            return Action.D
        elif cooperation_count == m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_47(BaseStrategy):
    """
    Adaptive Threshold Vulture: An exploitative strategy that systematically free-rides on others' cooperation
    while minimizing own contribution costs. Identifies serial cooperators and exploits them, with pure
    defection in the endgame when future reputation effects are impossible.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        window_size = min(5, round_number)
        start_idx = round_number - window_size
        recent_opponent_actions = history.opponent_actions[start_idx:round_number, :]
        cooperation_counts = np.sum(recent_opponent_actions, axis=0)
        cooperation_rates = cooperation_counts / window_size
        estimated_cooperators = np.sum(cooperation_rates)
        cooperation_threshold = self.m - 1.5
        if estimated_cooperators >= cooperation_threshold:
            return Action.D
        if estimated_cooperators < self.m - self.n_players:
            return Action.D
        if round_number >= self.n_rounds - 2:
            return Action.D
        if round_number == self.n_rounds - 3:
            recent_avg = np.mean(cooperation_rates)
            if recent_avg >= self.m / self.n_players:
                return Action.C
            else:
                return Action.D
        max_cooperation_rate = np.max(cooperation_rates) if cooperation_rates.size > 0 else 0.0
        recent_avg = np.mean(cooperation_rates) if cooperation_rates.size > 0 else 0.0
        if max_cooperation_rate >= 0.7:
            return Action.D
        if recent_avg >= self.m / self.n_players * 1.1:
            return Action.D
        if round_number % 3 == 0:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_48(BaseStrategy):
    """
    ADAPTIVE THRESHOLD FARMING: An exploitative strategy that free-rides on others' 
    contributions while maintaining just enough cooperation to trigger the reward 
    when individually profitable.
    
    Core logic:
    - Round 1: DEFECT (gather intelligence)
    - Final round: DEFECT (no repeated-game incentive)
    - If threshold already met: DEFECT (free-ride)
    - If exactly m-1 cooperators: COOPERATE (pivotal, triggers reward)
    - If below m-1 cooperators: DEFECT (threshold unachievable)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        previous_round_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        my_previous_action = history.my_actions[current_round - 1]
        total_cooperators_last_round = previous_round_cooperators + int(my_previous_action)
        if total_cooperators_last_round >= self.m:
            return Action.D
        if total_cooperators_last_round == self.m - 1:
            return Action.C
        if total_cooperators_last_round < self.m - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_49(BaseStrategy):
    """
    Adaptive Defection with Conditional Cooperation.
    
    Exploitative strategy that maximizes personal payoff by:
    1. Defecting in rounds 1, r-1, and r (end-game exploitation)
    2. Free-riding when cooperation threshold is met
    3. Opportunistically cooperating only when close to threshold in early-mid game
    4. Otherwise defaulting to defection to preserve endowment
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round >= r - 1:
            return Action.D
        prev_round_idx = current_round - 1
        cooperators_prev_round = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        if cooperators_prev_round >= m:
            return Action.D
        if cooperators_prev_round == m - 1:
            return Action.D
        if cooperators_prev_round >= m - 2 and current_round <= r / 2:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_50(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation
    
    Core philosophy: Exploit asymmetry in payoffs by defecting unless becoming
    the pivotal m-th cooperator. Free-ride on others' cooperation when threshold
    is already met, and always defect in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if cooperators_last_round >= self.m:
            return Action.D
        if cooperators_last_round == self.m - 1:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_51(BaseStrategy):
    """
    Adaptive Defection with Conditional Parasitism strategy for Collective Risk Dilemma.
    
    Exploits the threshold structure by:
    - Always defecting in round 1 (probe)
    - Always defecting in final round (no future punishment)
    - Defecting when threshold already met (free-riding)
    - Probabilistically cooperating when at m-1 cooperators (strategic exploitation)
    - Otherwise defecting (threshold unlikely to be met)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        observed_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if observed_cooperators >= self.m:
            return Action.D
        elif observed_cooperators == self.m - 1:
            rounds_remaining = self.n_rounds - current_round
            p_threshold = min(0.6, rounds_remaining / (self.n_rounds - 1) if self.n_rounds > 1 else 0.6)
            if random.random() < p_threshold:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_52(BaseStrategy):
    """
    Exploitative Strategy: Conditional Free-Riding with Adaptive Defection
    
    Always defects by exploiting the threshold mechanism. The core insight is that
    cooperators create value (k) that defectors capture without cost. This strategy
    extracts maximum surplus by free-riding when cooperation is likely and avoiding
    wasted investment when it isn't.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        n = self.game_description.n_players
        m = self.game_description.m
        total_opponent_cooperations = int(np.sum(history.opponent_actions))
        total_opponent_actions = history.opponent_actions.shape[0] * history.opponent_actions.shape[1]
        if total_opponent_actions == 0:
            return Action.D
        cooperation_rate = total_opponent_cooperations / total_opponent_actions
        threshold_rate = (m - 1) / n
        return Action.D

class Strategy_EXPLOITATIVE_53(BaseStrategy):
    """
    Adaptive Threshold Parasite: An exploitative strategy that free-rides on others'
    cooperation while maintaining plausible deniability through occasional cooperation.
    Maximizes payoff by defecting when threshold will be met, cooperating rarely to
    avoid being filtered as trivial defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_high = self.m / self.n + 0.15
        self.threshold_low = self.m / self.n - 0.1
        self.p_cooperate = max(0.3, self.m / self.n - 0.05)
        self.defection_streak = 0
        self.last_cooperation_rate = 0.0
        self.cooperation_rate_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            self.defection_streak = 1
            return Action.D
        if current_round == self.r - 1:
            self.defection_streak += 1
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[current_round - 1, :]))
        cooperation_rate = cooperators_last_round / (self.n - 1) if self.n > 1 else 0.0
        self.cooperation_rate_history.append(cooperation_rate)
        if len(self.cooperation_rate_history) >= 2:
            collapse_threshold = (self.m - 1) / self.n if self.n > 1 else 0.0
            if self.cooperation_rate_history[-1] < collapse_threshold and self.cooperation_rate_history[-2] < collapse_threshold:
                self.defection_streak += 1
                return Action.D
        if len(self.cooperation_rate_history) >= 2:
            if self.cooperation_rate_history[-2] < self.threshold_low and cooperation_rate > self.threshold_high:
                self.defection_streak += 1
                return Action.D
        if cooperation_rate >= self.threshold_high:
            self.defection_streak += 1
            return Action.D
        if cooperation_rate < self.threshold_low:
            self.defection_streak += 1
            return Action.D
        rounds_remaining = self.r - current_round
        if rounds_remaining <= 3:
            if random.random() < 0.85:
                self.defection_streak += 1
                return Action.D
        effective_p_cooperate = self.p_cooperate
        if len(self.cooperation_rate_history) >= 2:
            if self.cooperation_rate_history[-1] > self.cooperation_rate_history[-2] and self.cooperation_rate_history[-2] > (self.cooperation_rate_history[-3] if len(self.cooperation_rate_history) >= 3 else -1):
                effective_p_cooperate = min(0.5, self.p_cooperate + 0.1)
        if random.random() < effective_p_cooperate:
            self.defection_streak = 0
            return Action.C
        else:
            self.defection_streak += 1
            return Action.D

class Strategy_EXPLOITATIVE_54(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Threshold Strategy.
    
    Exploits the threshold structure by defecting in round 1 to gather information,
    then free-riding on cooperation when the threshold is met, while occasionally
    cooperating in marginal scenarios to maintain ambiguity. Always defects in the
    final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
        rounds_remaining = self.n_rounds - current_round
        total_rounds = self.n_rounds
        if cooperators_last_round >= self.m:
            return Action.D
        elif cooperators_last_round == self.m - 1:
            threshold_prob = rounds_remaining / total_rounds
            if random.random() < threshold_prob:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_55(BaseStrategy):
    """
    Adaptive Threshold Exploitation (ATE) Strategy for Collective Risk Dilemma.
    
    Exploits the asymmetry in payoff structure by free-riding on others' cooperation
    while strategically cooperating only when threshold failure is imminent.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.own_cooperation_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        recent_cooperation_count = self._get_recent_cooperation_count(history, current_round)
        recent_total_plays = 2 * (self.n - 1)
        if recent_total_plays == 0:
            recent_coop_rate = 0.0
        else:
            recent_coop_rate = recent_cooperation_count / recent_total_plays
        threshold_ratio = self.m / self.n
        if recent_coop_rate >= threshold_ratio * 1.2:
            return Action.D
        elif recent_coop_rate >= threshold_ratio * 0.9:
            if self.own_cooperation_count < self.r / 4:
                return Action.D
            else:
                return Action.C
        elif recent_coop_rate < threshold_ratio * 0.7:
            rounds_remaining = self.r - current_round
            if rounds_remaining <= 3:
                return Action.D
            elif random.random() < 0.6:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _get_recent_cooperation_count(self, history: PlayerHistory, current_round: int) -> int:
        """
        Count cooperators (True values) in the last 2 rounds among all opponents.
        """
        start_round = max(0, current_round - 2)
        recent_actions = history.opponent_actions[start_round:current_round, :]
        cooperation_count = int(np.sum(recent_actions))
        if history.my_actions[current_round - 1]:
            self.own_cooperation_count += 1
        return cooperation_count

class Strategy_EXPLOITATIVE_56(BaseStrategy):
    """
    Conditional Free-Rider with Adaptive Defection Strategy.
    
    Exploits the asymmetry in the Collective Risk Dilemma by strategically defecting
    while monitoring cooperation rates. The core insight is that defectors receive
    (1 + k) payoff when the threshold is met, while cooperators only receive k.
    
    This strategy:
    1. Always defects in round 1 (information gathering with no cost)
    2. Defects in the final round (no reputational consequences)
    3. In middle rounds, defects by default unless threshold is unachievable
    4. Monitors cooperation rate to ride waves of cooperation without participating
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        prev_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        n = self.n_players
        prev_cooperation_rate = prev_cooperators / n if n > 0 else 0.0
        prev_prev_cooperation_rate = 0.0
        if current_round >= 2:
            prev_prev_cooperators = int(np.sum(history.opponent_actions[current_round - 2, :]))
            prev_prev_cooperation_rate = prev_prev_cooperators / n if n > 0 else 0.0
        if prev_cooperators >= self.m:
            return Action.D
        if prev_cooperators == self.m - 1:
            return Action.D
        if prev_cooperators == self.m - 2:
            if prev_cooperation_rate > prev_prev_cooperation_rate:
                return Action.D
            return Action.D
        if prev_cooperators == 0:
            return Action.D
        if current_round >= 2 and prev_cooperation_rate > prev_prev_cooperation_rate:
            if prev_cooperators >= self.m - 2:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_57(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD) Strategy
    
    Exploits the collective risk dilemma by maximizing free-riding on others' 
    cooperation. Uses conditional defection with minimal adaptive cooperation 
    testing. Core principle: defect whenever possible, cooperate only when 
    threshold is nearly unmet (for opponent sensing).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.opponent_coop_rate = np.zeros(self.n_players - 1)
        self.opponent_coop_counts = np.zeros(self.n_players - 1)
        self.rounds_threshold_met = 0
        self.epsilon = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        last_round_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        self._update_opponent_profiles(history, current_round)
        if last_round_cooperators >= self.m:
            return Action.D
        elif last_round_cooperators == self.m - 1:
            if random.random() < self.epsilon:
                return Action.C
            return Action.D
        else:
            return Action.D

    def _update_opponent_profiles(self, history: PlayerHistory, current_round: int) -> None:
        """
        Update opponent cooperation rates and threshold success tracking.
        Adjust epsilon based on observed threshold success rate.
        """
        for opp_idx in range(self.n_players - 1):
            self.opponent_coop_counts[opp_idx] = int(np.sum(history.opponent_actions[:current_round, opp_idx]))
            self.opponent_coop_rate[opp_idx] = self.opponent_coop_counts[opp_idx] / current_round if current_round > 0 else 0.0
        for round_idx in range(current_round):
            cooperators_in_round = int(np.sum(history.opponent_actions[round_idx, :]))
            my_coop = int(history.my_actions[round_idx])
            total_cooperators = cooperators_in_round + my_coop
            if total_cooperators >= self.m:
                self.rounds_threshold_met += 1
        if current_round > 1:
            threshold_success_rate = self.rounds_threshold_met / current_round
            if threshold_success_rate > 0.7:
                self.epsilon = min(self.epsilon * 1.2, 0.15)
            elif threshold_success_rate < 0.3:
                self.epsilon = 0.05

class Strategy_EXPLOITATIVE_58(BaseStrategy):
    """
    Adaptive Threshold Parasitism: Exploits the threshold mechanism by free-riding on others' 
    cooperation while strategically cooperating only when it triggers the reward threshold.
    Defects in first and last rounds, and parasitically cooperates in middle rounds only when
    cooperation count is at m-1 with rising trend.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        prev_round_actions = history.opponent_actions[current_round - 1, :]
        cooperation_count = int(np.sum(prev_round_actions))
        if cooperation_count >= self.m:
            return Action.D
        if cooperation_count == self.m - 1:
            if current_round >= 2:
                prev_prev_cooperation = int(np.sum(history.opponent_actions[current_round - 2, :]))
                if cooperation_count > prev_prev_cooperation:
                    return Action.C
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_59(BaseStrategy):
    """
    Adaptive Free-Riding with Threshold Exploitation strategy for Collective Risk Dilemma.
    
    Exploits the threshold mechanism by:
    1. Probing with defection in round 1 to assess cooperation density
    2. Adaptively free-riding on cooperation when threshold is likely met
    3. Defecting ruthlessly in the final round
    4. Using a deficit heuristic (n/3) to decide when cooperation is worth attempting
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_threshold_met = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if state.round_number == 0:
            return Action.D
        if state.round_number == r - 1:
            return Action.D
        prev_round_idx = state.round_number - 1
        cooperators_prev = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        threshold_met_prev = cooperators_prev >= m
        if threshold_met_prev:
            self.consecutive_threshold_met += 1
            return Action.D
        self.consecutive_threshold_met = 0
        cooperators_without_me = cooperators_prev
        if cooperators_without_me == m - 1:
            return Action.D
        if cooperators_without_me < m - 1:
            deficit = m - 1 - cooperators_without_me
            threshold_deficit = n / 3.0
            if deficit > threshold_deficit:
                return Action.D
            else:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_60(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation
    
    This strategy exploits the payoff asymmetry by:
    1. Defecting in round 1 to gather information
    2. Free-riding on cooperators when threshold is guaranteed
    3. Conditionally cooperating only as the marginal player
    4. Defecting in final rounds to maximize immediate payoff
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        if current_round == self.r - 2:
            return Action.D
        prev_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if prev_cooperators >= self.m:
            return Action.D
        if prev_cooperators == self.m - 1:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_61(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Thresholds.
    
    Exploits the asymmetry between cooperators and defectors by conditionally
    cooperating only when the threshold is nearly guaranteed to be met by others,
    then defecting to capture the bonus while avoiding the cost.
    
    Core logic: Always defect except in theoretically impossible scenarios.
    - Round 0 (first round): Defect (establish baseline, no history to exploit)
    - Round r-1 (final round): Defect (no future punishment possible)
    - Rounds 1 to r-2 (middle rounds): Defect (free-ride on others' cooperation)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        previous_round_index = state.round_number - 1
        cooperators_count = int(sum(history.opponent_actions[previous_round_index, :]))
        m = self.game_description.m
        if cooperators_count >= m:
            return Action.D
        if cooperators_count >= m - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_62(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Exploitation
    
    Exploits the asymmetry that defectors earn more than cooperators when the 
    threshold is met (1 + k vs k). Cooperates only when it maximizes expected 
    personal payoff, treating cooperation as an investment to enable future exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.n_rounds - 1:
            return Action.D
        recent_coop_rate = self._calculate_recent_cooperation_rate(history, round_num)
        expected_cooperators = recent_coop_rate * self.n_players
        if expected_cooperators < self.m:
            return Action.D
        game_phase = round_num / self.n_rounds
        if game_phase < 0.4:
            coop_threshold = 0.35
        elif game_phase < 0.65:
            coop_threshold = 0.55
        else:
            coop_threshold = 0.75
        coop_threshold = self._adjust_threshold_for_edge_cases(coop_threshold)
        if self._is_game_collapsed(history, round_num):
            return Action.D
        if recent_coop_rate > coop_threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """Calculate cooperation rate from recent rounds (last 2-3 rounds if available)."""
        if round_num == 0:
            return 0.0
        lookback = min(3, round_num)
        start_idx = round_num - lookback
        recent_opponent_actions = history.opponent_actions[start_idx:round_num, :]
        cooperators_per_round = np.sum(recent_opponent_actions, axis=1)
        total_cooperators = np.sum(cooperators_per_round)
        total_slots = lookback * self.n_players
        return total_cooperators / total_slots if total_slots > 0 else 0.0

    def _adjust_threshold_for_edge_cases(self, base_threshold: float) -> float:
        """Adjust threshold based on game parameters."""
        adjusted = base_threshold
        if self.m > 0.75 * self.n_players:
            adjusted = base_threshold + 0.15
        if self.k > 10:
            adjusted = base_threshold + 0.2
        if self.n_players <= 3:
            adjusted = max(0.0, base_threshold - 0.1)
        return adjusted

    def _is_game_collapsed(self, history: PlayerHistory, round_num: int) -> bool:
        """Detect if game has collapsed (too few cooperators)."""
        if round_num == 0:
            return False
        last_round_cooperators = np.sum(history.opponent_actions[round_num - 1, :])
        if last_round_cooperators == 0:
            return True
        all_cooperators = np.sum(history.opponent_actions[:round_num, :])
        total_slots = round_num * self.n_players
        overall_coop_rate = all_cooperators / total_slots if total_slots > 0 else 0.0
        if overall_coop_rate < 0.1:
            return True
        return False

class Strategy_EXPLOITATIVE_63(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD) Strategy
    
    Exploits the coordination problem in collective risk dilemmas by:
    1. Always defecting in round 1 and final round
    2. In middle rounds, monitoring cooperation rates and defecting when:
       - Cooperation is high enough to exploit (free-ride)
       - Cooperation is too low to succeed (avoid sucker's payoff)
       - Cooperation is uncertain (defection dominates)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.epsilon = 0.15
        self.delta = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperation_rate = self._calculate_cooperation_rate(history, current_round)
        threshold_rate = self.m / self.n_players
        if cooperation_rate >= threshold_rate + self.epsilon:
            return Action.D
        if cooperation_rate < threshold_rate - self.delta:
            return Action.D
        return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the cooperation rate of opponents across all previous rounds.
        
        cooperation_rate = (total_cooperators_in_previous_rounds) / 
                          ((n-1) Ã— rounds_played_so_far)
        """
        rounds_played = current_round
        if rounds_played == 0:
            return 0.0
        total_cooperations = np.sum(history.opponent_actions[:rounds_played, :])
        total_possible = (self.n_players - 1) * rounds_played
        if total_possible == 0:
            return 0.0
        cooperation_rate = total_cooperations / total_possible
        return cooperation_rate

class Strategy_EXPLOITATIVE_64(BaseStrategy):
    """
    Exploitative Strategy: Conditional Defection with Threshold Exploitation
    
    Core approach:
    - Round 1: Always defect to test opponents
    - Middle rounds: Free-ride on cooperation when threshold is met, otherwise defect
      with rare exception for pivotal player scenarios
    - Final round: Always defect (no future consequences)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        last_round_actions = history.opponent_actions[current_round - 1, :]
        cooperators_last_round = int(np.sum(last_round_actions))
        cooperation_rate = cooperators_last_round / n if n > 0 else 0.0
        threshold_rate = m / n if n > 0 else 0.0
        if cooperation_rate >= threshold_rate:
            return Action.D
        if cooperation_rate == 0:
            return Action.D
        if cooperation_rate > 0 and cooperation_rate < threshold_rate:
            if current_round >= 2 and abs(cooperators_last_round - m) <= 1:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_65(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Threshold Defection with Conditional Cooperation
    
    This strategy exploits the asymmetry in payoff structure where defectors earn more
    than cooperators when the threshold is met. It minimizes cooperation while extracting
    the threshold reward through strategic defection and selective conditional cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        total_cooperations = np.sum(history.opponent_actions[:current_round, :])
        total_observations = current_round * (self.n - 1)
        if total_observations > 0:
            coop_rate = total_cooperations / total_observations
            expected_cooperators = coop_rate * (self.n - 1)
        else:
            expected_cooperators = 0.0
        if expected_cooperators >= self.m:
            return Action.D
        elif expected_cooperators >= self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_66(BaseStrategy):
    """
    Adaptive Threshold Stalker: An exploitative strategy that systematically free-rides
    on others' cooperation while maintaining minimal credibility through stochastic noise.
    
    Core mechanics:
    - Round 1: Always defect (no history to exploit)
    - Threshold met (â‰¥m cooperators): Defect (free-ride on +k without cost)
    - Marginal position (m-1 cooperators): Defect with probability 1-1/n, cooperate with 1/n
    - Below threshold: Defect (no payoff benefit from cooperation)
    - Final round: Always defect (no future reputation effects)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m_threshold = game_description.m
        self.k = game_description.k
        self.p_threshold = 1.0 / self.n_players if self.n_players > 0 else 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        last_round_idx = current_round - 1
        coop_count_last = int(sum(history.opponent_actions[last_round_idx, :]))
        if current_round == self.n_rounds - 1:
            return Action.D
        if coop_count_last >= self.m_threshold:
            return Action.D
        elif coop_count_last == self.m_threshold - 1:
            if random.random() < self.p_threshold:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_67(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD) Strategy
    
    An exploitative strategy that defaults to defection and only cooperates when
    conditions indicate exploitation opportunities exist. The strategy:
    - Defects in round 1 (no information)
    - Defects in the last round (defection is always dominant)
    - In middle rounds, defects unless cooperation rate suggests threshold is/will be met
    - Exploits by free-riding on others' cooperation while avoiding endowment costs
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        prev_round_actions = history.opponent_actions[round_number - 1, :]
        cooperators_prev = int(np.sum(prev_round_actions))
        coop_rate = cooperators_prev / self.n_players
        threshold_rate = self.m / self.n_players
        if coop_rate >= threshold_rate:
            return Action.D
        if coop_rate >= threshold_rate - 1.0 / self.n_players:
            return Action.D
        rounds_remaining = self.n_rounds - round_number
        if coop_rate >= threshold_rate - 2.0 / self.n_players and rounds_remaining >= 3:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_68(BaseStrategy):
    """
    Adaptive Threshold Hunter: An exploitative strategy that free-rides on others' cooperation.
    
    Core logic:
    - Round 1: DEFECT (probe for free-ride opportunities)
    - Rounds 2 to r-1: DEFECT if threshold is met (free-ride), else DEFECT (save endowment)
    - Final round: DEFECT (terminal exploitation, no future consequences)
    
    In essence, this strategy always defects while monitoring opponent cooperation to
    understand threshold dynamics. It exploits the structure of the game by never
    committing resources while extracting value from others' cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        previous_round_index = state.round_number - 1
        previous_cooperators = int(sum(history.opponent_actions[previous_round_index, :]))
        m = self.game_description.m
        if previous_cooperators >= m:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_69(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Free-Riding
    
    Exploits the threshold mechanism by free-riding on others' cooperation while
    maintaining unpredictability. Defects when safe, cooperates only when necessary,
    and always defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
        if cooperators_last_round >= self.m:
            return Action.D
        if cooperators_last_round == self.m - 1:
            rounds_remaining = self.n_rounds - current_round
            p_defect = 0.7 + rounds_remaining / self.n_rounds * 0.2
            if random.random() < p_defect:
                return Action.D
            else:
                return Action.C
        if cooperators_last_round < self.m - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_70(BaseStrategy):
    """
    Exploitative Strategy: Conditional Free-Riding with Adaptive Defection
    
    Exploits the threshold mechanic by free-riding when cooperation is likely,
    while avoiding the worst outcome. Cooperates only when necessary to prevent
    collective failure (swing vote), defects otherwise.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.reliable_cooperators = 0
        self.reliable_defectors = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        previous_round_opponent_actions = history.opponent_actions[current_round - 1, :]
        coop_count_previous = int(np.sum(previous_round_opponent_actions))
        if current_round >= 2:
            previous_previous_opponent_actions = history.opponent_actions[current_round - 2, :]
            for i in range(self.n - 1):
                if previous_round_opponent_actions[i] and previous_previous_opponent_actions[i]:
                    self.reliable_cooperators = max(self.reliable_cooperators, i + 1)
                if not previous_round_opponent_actions[i] and (not previous_previous_opponent_actions[i]):
                    self.reliable_defectors = max(self.reliable_defectors, i + 1)
        deficit = self.m - coop_count_previous
        if coop_count_previous >= self.m:
            return Action.D
        if deficit >= 2:
            return Action.D
        if deficit == 1:
            return Action.C
        return Action.C

class Strategy_EXPLOITATIVE_71(BaseStrategy):
    """
    Conditional Freeloading with Adaptive Defection.
    
    Exploits the payoff asymmetry where defectors gain k without contributing
    when the cooperation threshold is met by others. The strategy always defects:
    - Round 1: Probe with zero cost to gather information
    - Rounds 2 to r-1: Free-ride on others' cooperation or avoid sucker's payoff
    - Final round: Defect (no reputation concerns, no future benefit)
    
    This maximizes personal gain by positioning as a net beneficiary of others'
    cooperation while avoiding the cost of contribution.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        """
        Always defect across all rounds.
        
        Strategy logic:
        - Round 0 (first round): Defect to probe cooperator distribution with zero cost
        - Rounds 1 to r-2: Defect to free-ride on others' cooperation or avoid wasting endowment
        - Round r-1 (final round): Defect since no future rounds exist for reputation concerns
        
        Args:
            state: Current game state containing round number
            history: Previous rounds' actions and payoffs (None for round 0)
        
        Returns:
            Action.D (DEFECT) in all cases
        """
        return Action.D

class Strategy_EXPLOITATIVE_72(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Thresholds.
    
    Exploits asymmetry in payoffs by defecting almost always while monitoring
    opponent cooperation rates to confirm that free-riding remains optimal.
    Always defects except in impossible edge cases.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.r - 1:
            return Action.D
        total_cooperators = np.sum(history.opponent_actions[:state.round_number, :])
        total_slots = self.n * state.round_number
        if total_slots == 0:
            return Action.D
        coop_rate = total_cooperators / total_slots
        threshold_rate = self.m / self.n
        if coop_rate >= threshold_rate * 1.2:
            return Action.D
        elif coop_rate >= threshold_rate * 0.8:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_73(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Threshold strategy.
    
    Exploits the asymmetry in payoff structure by strategically free-riding on others'
    cooperation while maintaining just enough cooperative appearances to avoid total
    mutual defection. Uses threshold-based decision rules with probabilistic mixing
    in marginal conditions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.exploit_probability = 0.7
        self.recovery_probability = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            cooperators_last_round += 1
        m = self.game_description.m
        threshold_met = cooperators_last_round >= m
        if threshold_met:
            if cooperators_last_round >= m + 2:
                return Action.D
            elif cooperators_last_round == m or cooperators_last_round == m + 1:
                if random.random() < self.exploit_probability:
                    return Action.D
                else:
                    return Action.C
            else:
                return Action.C
        elif cooperators_last_round >= m - 2:
            if random.random() < self.recovery_probability:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_74(BaseStrategy):
    """
    Adaptive Threshold Opportunism: An exploitative strategy that free-rides on cooperators.
    
    Core logic:
    - Round 1: DEFECT (probe and maximize immediate payoff)
    - Rounds 2+: If threshold was met last round, DEFECT (free-ride on cooperators)
    - Rounds 2+: If threshold was never met, DEFECT (futile to cooperate)
    - Final round: DEFECT (no future reputation value)
    
    This treats cooperation as a resource to harvest rather than reciprocate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n_rounds = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        current_round = state.round_number
        previous_round_index = current_round - 1
        cooperators_prev_round = int(np.sum(history.opponent_actions[previous_round_index, :]))
        if cooperators_prev_round >= self.m:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_75(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD): Exploitative strategy that defaults to defection,
    monitoring opponent cooperation rates to extract maximum payoff by free-riding when
    threshold is likely to be met, while adapting based on observed patterns.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.last_round_cooperated = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.n_rounds - 1:
            return Action.D
        cooperation_rate = self._calculate_cooperation_rate(history, round_num)
        threshold_trigger = (self.m - 1) / self.n_players
        if cooperation_rate >= threshold_trigger:
            self.last_round_cooperated = False
            return Action.D
        if cooperation_rate < 0.3:
            self.last_round_cooperated = False
            return Action.D
        if self.last_round_cooperated:
            if not self._did_others_reciprocate(history, round_num):
                self.last_round_cooperated = False
                return Action.D
        self.last_round_cooperated = True
        return Action.C

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate the cooperation rate of opponents across all previous rounds.
        Returns fraction of opponent cooperations observed.
        """
        if round_num == 0:
            return 0.0
        total_opponent_cooperations = np.sum(history.opponent_actions[:round_num, :])
        total_opponent_actions = round_num * (self.n_players - 1)
        if total_opponent_actions == 0:
            return 0.0
        cooperation_rate = total_opponent_cooperations / total_opponent_actions
        return cooperation_rate

    def _did_others_reciprocate(self, history: PlayerHistory, round_num: int) -> bool:
        """
        Check if opponents increased cooperation in the current round compared to previous round.
        Returns True if there's evidence of reciprocation to our cooperation.
        """
        if round_num < 1:
            return False
        prev_round_cooperations = np.sum(history.opponent_actions[round_num - 1, :])
        if round_num == 1:
            return prev_round_cooperations > 0
        round_before_prev_cooperations = np.sum(history.opponent_actions[round_num - 2, :])
        return prev_round_cooperations > round_before_prev_cooperations

class Strategy_EXPLOITATIVE_76(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Cooperation
    
    Maximizes personal payoff by exploiting the threshold mechanism through:
    - Free-riding when threshold is likely met without contribution
    - Selective cooperation only when marginal player status justifies it
    - Aggressive endgame defection to exploit others' cooperation
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[current_round - 1, :]))
        freq_coop = self._calculate_cooperation_frequency(history, current_round)
        if current_round == self.r - 1:
            return self._final_round_decision(cooperators_last_round, freq_coop)
        return self._intermediate_round_decision(cooperators_last_round, freq_coop)

    def _calculate_cooperation_frequency(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the frequency of cooperation observed in opponent actions.
        Returns proportion of cooperations observed across all rounds and opponents.
        """
        if current_round == 0:
            return 0.0
        total_cooperations = np.sum(history.opponent_actions[:current_round, :])
        total_possible = current_round * (self.n - 1)
        if total_possible == 0:
            return 0.0
        return total_cooperations / total_possible

    def _intermediate_round_decision(self, cooperators_last_round: int, freq_coop: float) -> Action:
        """
        Decision logic for rounds 2 to r-1.
        Implements adaptive threshold monitoring and selective cooperation.
        """
        if cooperators_last_round >= self.m:
            return Action.D
        elif cooperators_last_round == self.m - 1:
            cooperation_threshold = self.m / self.n
            if freq_coop > cooperation_threshold:
                return Action.C
            else:
                return Action.D
        elif cooperators_last_round < self.m - 1:
            return Action.D
        return Action.D

    def _final_round_decision(self, cooperators_last_round: int, freq_coop: float) -> Action:
        """
        Final round decision - maximize exploitation with no reputational cost.
        Only cooperate in rare case where pattern is extremely reliable.
        """
        if freq_coop > 0.9 and cooperators_last_round == self.m - 1:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_77(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Threshold Defection with Opportunistic Free-Riding
    
    Core Philosophy: Exploit the threshold mechanism by minimizing personal contribution
    while maximizing extraction of collective benefits through strategic defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_reliability = (self.m - 1) / self.n + 0.15

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        rounds_remaining = self.r - current_round
        if rounds_remaining <= 2:
            return Action.D
        cooperation_rate = self._calculate_cooperation_rate(history, current_round)
        if cooperation_rate >= self.threshold_reliability:
            return Action.D
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the observed cooperation rate of opponents in previous rounds.
        Uses a window of the last 3 rounds (or fewer if game is short).
        
        Returns a value in [0, 1] representing the fraction of opponent actions that were C.
        """
        if current_round <= 0:
            return 0.0
        window_size = min(3, current_round)
        start_round = current_round - window_size
        total_actions = 0
        total_cooperations = 0
        for round_idx in range(start_round, current_round):
            if round_idx < len(history.opponent_actions):
                round_cooperations = np.sum(history.opponent_actions[round_idx, :])
                total_cooperations += round_cooperations
                total_actions += self.n - 1
        if total_actions == 0:
            return 0.0
        cooperation_rate = total_cooperations / total_actions
        return cooperation_rate

class Strategy_EXPLOITATIVE_78(BaseStrategy):
    """
    Adaptive Threshold Defection with Opportunistic Farming.
    
    Exploits the payoff asymmetry by:
    1. Defecting in round 1 to establish defector identity
    2. Defecting in final round (no reputation consequences)
    3. Free-riding when threshold is guaranteed (cooperators >= m)
    4. Stochastically defecting in marginal zone (cooperators == m-1)
    5. Defecting when threshold is unattainable (cooperators < m-1)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.r - 1:
            return Action.D
        previous_round_opponent_actions = history.opponent_actions[round_number - 1, :]
        cooperators_observed = int(np.sum(previous_round_opponent_actions))
        if cooperators_observed >= self.m:
            return Action.D
        elif cooperators_observed == self.m - 1:
            p_exploit = (self.k - 1) / self.k if self.k > 1 else 0.5
            if random.random() < p_exploit:
                return Action.D
            else:
                return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_79(BaseStrategy):
    """
    Adaptive Free-Riding with Threshold Exploitation.
    
    Maximizes payoff by exploiting the threshold mechanism: defect when threshold
    is met (capturing k+1 instead of k), and strategically cooperate only when
    the threshold seems far away and cooperation increases personal payoff prospects.
    Maintains running cooperation rate estimates to calibrate exploitation intensity.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.total_opponent_cooperations = 0
        self.total_opponent_actions_observed = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        self._update_cooperation_stats(history)
        cooperators_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
        if cooperators_last_round >= m:
            return Action.D
        opponent_cooperation_rate = self._get_cooperation_rate()
        threshold_gap = m - cooperators_last_round
        far_threshold_distance = math.ceil(n / 3)
        if cooperators_last_round < m - far_threshold_distance:
            low_cooperation_threshold = m / n * 0.8
            if opponent_cooperation_rate < low_cooperation_threshold:
                return Action.D
            return Action.C
        close_cooperation_threshold = m / n * 1.2
        if opponent_cooperation_rate > close_cooperation_threshold:
            return Action.D
        if cooperators_last_round == m - 1:
            return Action.D
        if cooperators_last_round >= max(1, m - far_threshold_distance):
            return Action.D
        return Action.D

    def _update_cooperation_stats(self, history: PlayerHistory) -> None:
        """
        Update running totals of opponent cooperations observed.
        """
        current_round = len(history.my_actions)
        if current_round == 0:
            return
        last_round_idx = current_round - 1
        cooperations_last_round = int(sum(history.opponent_actions[last_round_idx, :]))
        self.total_opponent_cooperations += cooperations_last_round
        self.total_opponent_actions_observed += self.game_description.n_players - 1

    def _get_cooperation_rate(self) -> float:
        """
        Compute the running average cooperation rate among opponents.
        Handles division by zero gracefully.
        """
        if self.total_opponent_actions_observed == 0:
            return 0.5
        return self.total_opponent_cooperations / self.total_opponent_actions_observed

class Strategy_EXPLOITATIVE_80(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD) Strategy
    
    An exploitative strategy that maximizes personal payoff by:
    1. Always defecting to free-ride on others' cooperation
    2. Monitoring cooperation rates to adjust exploitation intensity
    3. Unconditionally defecting in the final round
    4. Targeting the threshold mechanism's weakness where defectors get k+1 vs cooperators getting k
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        if current_round == 0:
            return Action.D
        cooperators_prev_round = int(np.sum(history.opponent_actions[current_round - 1, :]))
        phase2_start = math.ceil(self.r / 2)
        if current_round >= phase2_start and current_round < self.r - 1:
            total_rounds_elapsed = current_round
            total_cooperation_instances = int(np.sum(history.opponent_actions[:current_round, :]))
            total_possible = total_rounds_elapsed * (self.n - 1)
            if total_possible > 0:
                cooperation_rate = total_cooperation_instances / total_possible
            else:
                cooperation_rate = 0
            threshold_rate = self.m / self.n if self.n > 0 else 0
            if cooperation_rate > threshold_rate * 1.5:
                return Action.D
            if cooperation_rate < threshold_rate * 0.7:
                return Action.D
            if cooperators_prev_round >= self.m:
                return Action.D
            if cooperators_prev_round == self.m - 1:
                return Action.D
            return Action.D
        if cooperators_prev_round >= self.m:
            return Action.D
        if cooperators_prev_round >= self.m - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_81(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism: Exploits threshold mechanism by free-riding 
    on others' cooperation while strategically cooperating only when pivotal (exactly m-1 
    cooperators exist) before the terminal round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0 or round_num == 1:
            return Action.D
        prev_round_idx = round_num - 1
        cooperators_prev = int(sum(history.opponent_actions[prev_round_idx, :]))
        if round_num == self.r - 1:
            return Action.D
        if cooperators_prev >= self.m:
            return Action.D
        elif cooperators_prev == self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_82(BaseStrategy):
    """
    Adaptive Defection with Opportunistic Cooperation strategy for Collective Risk Dilemma.
    
    Core philosophy: Maximize personal payoff by exploiting cooperators through strategic defection.
    - Always defect by default to secure baseline payoff
    - Free-ride when threshold is guaranteed to be met
    - Exploit marginal cooperators at threshold boundaries
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        prior_cooperators = int(np.sum(history.opponent_actions[state.round_number - 1, :]))
        if history.my_actions[state.round_number - 1]:
            prior_cooperators += 1
        m = self.game_description.m
        if prior_cooperators >= m:
            return Action.D
        elif prior_cooperators == m - 1:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_83(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD) - An exploitative strategy that:
    1. Defects in round 1 to probe opponent composition
    2. Adaptively exploits cooperation by free-riding when threshold is met
    3. Pivots the threshold when exactly m-1 cooperators exist (if rounds remain)
    4. Defects in the final round for terminal extraction
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        prev_round_idx = current_round - 1
        cooperators_prev = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        c_rate = cooperators_prev / self.n_players
        c_threshold = self.m / self.n_players
        m_minus_1_threshold = (self.m - 1) / self.n_players
        if c_rate >= c_threshold:
            return Action.D
        elif math.fabs(c_rate - m_minus_1_threshold) < 1e-09:
            rounds_remaining = self.n_rounds - current_round - 1
            if rounds_remaining > 0:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_84(BaseStrategy):
    """
    Adaptive Threshold Exploitation Strategy for Collective Risk Dilemma.
    
    Core philosophy: Exploit the asymmetry between cooperators (cost c=1) and 
    defectors (cost c=0) by strategically defecting to free-ride on others' 
    cooperation while avoiding personal cost. Uses conditional logic based on 
    observed cooperation patterns, end-game dynamics, and threshold achievement.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        previous_round_idx = current_round - 1
        previous_opponent_actions = history.opponent_actions[previous_round_idx, :]
        cooperation_count = int(np.sum(previous_opponent_actions))
        my_previous_action = history.my_actions[previous_round_idx]
        if my_previous_action:
            cooperation_count += 1
        rounds_remaining = self.n_rounds - current_round
        if rounds_remaining <= 1:
            return Action.D
        if rounds_remaining <= 3:
            if cooperation_count >= self.m:
                return Action.D
            else:
                return Action.D
        if cooperation_count >= self.m:
            return Action.D
        if cooperation_count < self.m:
            observed_cooperators = int(np.sum(previous_opponent_actions))
            if observed_cooperators >= self.m - 1:
                return Action.D
            else:
                return Action.D
        rounds_observed = min(current_round, self.n_rounds)
        if rounds_observed > 0:
            total_opponent_cooperations = int(np.sum(history.opponent_actions[:current_round, :]))
            opponent_coop_rate = total_opponent_cooperations / (rounds_observed * (self.n_players - 1))
            if opponent_coop_rate > 0.6 and cooperation_count >= self.m:
                if not my_previous_action:
                    return Action.C
                else:
                    return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_85(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD): An exploitative strategy that defects in round 1 and the final round,
    monitors cooperation rates in intermediate rounds, and strategically defects to free-ride on collective rewards
    while minimizing personal cost. Identifies conditional cooperators and exploits them through defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.required_threshold = self.m / self.n_players
        self.threshold_buffer = 0.15

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        last_round_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        coop_rate = last_round_cooperators / self.n_players
        individual_coop_rates = np.mean(history.opponent_actions, axis=0)
        has_conditional_cooperator = np.any(individual_coop_rates > 0.6)
        if coop_rate >= self.required_threshold + self.threshold_buffer:
            return Action.C
        elif coop_rate >= self.required_threshold:
            if random.random() < 0.7:
                return Action.D
            else:
                return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_86(BaseStrategy):
    """
    Adaptive Threshold Exploitation strategy for Collective Risk Dilemma.
    
    Exploits the asymmetry between cooperators and defectors by:
    1. Free-riding on cooperators when threshold is met
    2. Defecting strategically to avoid costs
    3. Only cooperating when marginal contribution tips success
    4. Always defecting in final round
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_to_flip = (self.m - 1) / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.r - 1:
            return Action.D
        last_round_idx = round_number - 1
        last_round_opponent_actions = history.opponent_actions[last_round_idx, :]
        cooperators_last_round = int(np.sum(last_round_opponent_actions))
        threshold_met_last_round = cooperators_last_round >= self.m
        if threshold_met_last_round:
            return Action.D
        if cooperators_last_round == 0:
            return Action.D
        marginal_cooperators = cooperators_last_round + 1
        if marginal_cooperators >= self.m:
            coop_frequency = cooperators_last_round / self.n
            if coop_frequency >= self.threshold_to_flip:
                remaining_rounds = self.r - round_number
                if remaining_rounds >= 1 and self.k > 1:
                    return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_87(BaseStrategy):
    """
    Adaptive Threshold Pivot: An exploitative strategy for Collective Risk Dilemmas.
    
    This strategy exploits the asymmetry where defectors free-ride on cooperators' 
    contributions when the threshold is met. It probes in round 1, adaptively exploits 
    in middle rounds based on observed cooperation rates, and unconditionally defects 
    in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        cooperators_per_round = []
        for round_idx in range(current_round):
            cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
            cooperators_per_round.append(cooperators)
        total_possible_cooperations = (self.n - 1) * current_round
        total_cooperators = sum(cooperators_per_round)
        if total_possible_cooperations == 0:
            avg_cooperation_rate = 0.0
        else:
            avg_cooperation_rate = total_cooperators / total_possible_cooperations
        last_cooperators = cooperators_per_round[-1] if cooperators_per_round else 0
        threshold_ratio = self.m / self.n
        if avg_cooperation_rate > threshold_ratio:
            return Action.D
        if avg_cooperation_rate < threshold_ratio:
            return Action.D
        if last_cooperators == self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_88(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD) Strategy
    
    Exploitative strategy that defects by default and only cooperates when necessary
    to maintain the cooperation threshold. Maximizes payoff by free-riding on others'
    cooperation while minimally contributing only when the threshold is at risk.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        prev_round_idx = current_round - 1
        prev_cooperators_opponents = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        my_prev_action = history.my_actions[prev_round_idx]
        prev_total_cooperators = prev_cooperators_opponents + int(my_prev_action)
        if prev_total_cooperators < self.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_89(BaseStrategy):
    """
    Adaptive Defection with Conditional Parasitism.
    
    Exploits the threshold mechanism by free-riding on others' cooperation.
    Defects when threshold is met (to extract reward without cost).
    Conditionally cooperates with low probability when threshold fails (to seed cooperation for future exploitation).
    Defects unconditionally in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            threshold_ratio = self.m / self.n_players
            if threshold_ratio >= 0.5:
                return Action.C
            else:
                return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        previous_round_idx = round_number - 1
        cooperators_previous = int(np.sum(history.opponent_actions[previous_round_idx, :]))
        if cooperators_previous >= self.m:
            return Action.D
        cooperation_probability = self.m / self.n_players + min(0.1, 1.0 / self.n_rounds)
        if random.random() < cooperation_probability:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_90(BaseStrategy):
    """
    Adaptive Defection with Conditional Cooperation (ADCC).
    
    Exploitative strategy that defects by default and cooperates only when:
    1. The threshold m has been met in the previous round (ensuring k reward)
    2. Not in the first or last round
    3. Cooperation trend is stable (not declining rapidly)
    
    Maximizes individual payoff by free-riding on others' cooperation while
    avoiding wasted endowment contributions when collective action fails.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        last_round_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if last_round_cooperators < self.m:
            return Action.D
        if current_round >= 2:
            cooperators_two_rounds_ago = int(np.sum(history.opponent_actions[current_round - 2, :]))
            cooperation_trend = (last_round_cooperators - cooperators_two_rounds_ago) / max(1, self.n_players - 1)
            if cooperation_trend < -0.2:
                return Action.D
        return Action.C

class Strategy_EXPLOITATIVE_91(BaseStrategy):
    """
    Adaptive Threshold Exploitation (ATE) Strategy
    
    Exploits the asymmetry in payoff structure by systematically identifying when
    cooperation is likely and defecting to capture the free-rider payoff (1 + k).
    Defects in ~95% of moves, with rare conditional cooperation only when others
    have proven sustained cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.n_rounds - 1:
            return Action.D
        total_cooperators = int(np.sum(history.opponent_actions[:round_num, :]))
        total_possible = round_num * self.n_players
        if total_possible == 0:
            coop_rate = 0.0
        else:
            coop_rate = total_cooperators / total_possible
        last_coop_count = int(np.sum(history.opponent_actions[round_num - 1, :]))
        remaining_rounds = self.n_rounds - round_num
        if last_coop_count >= self.m:
            return Action.D
        if coop_rate > (self.m - 1) / self.n_players and last_coop_count >= self.m - 1:
            return Action.D
        if coop_rate >= self.m / self.n_players and last_coop_count == self.m - 1:
            return Action.D
        if remaining_rounds <= 2:
            return Action.D
        if remaining_rounds >= 3:
            if last_coop_count >= self.m and coop_rate > 0.7:
                opponent_defects = int(np.sum(~history.opponent_actions[:round_num, :]))
                opponent_defection_rate = opponent_defects / total_possible if total_possible > 0 else 0.0
                if opponent_defection_rate < 0.4:
                    return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_92(BaseStrategy):
    """
    Adaptive Threshold Exploitation Strategy for Collective Risk Dilemma.
    
    This exploitative strategy defaults to defection and only cooperates when
    structural inevitability or final-round optimization demands it. It maintains
    a running estimate of opponent cooperation rates and uses predictive analysis
    to maximize personal gain by free-riding on others' contributions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = []
        self.total_observations = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        if round_num == 0:
            return Action.D
        observed_cooperators_prev_round = int(sum(history.opponent_actions[round_num - 1, :]))
        self.cooperation_history.append(observed_cooperators_prev_round)
        self.total_observations = len(self.cooperation_history)
        if self.total_observations > 0:
            avg_cooperation_rate = sum(self.cooperation_history) / (self.total_observations * (n - 1))
            expected_cooperators_next = avg_cooperation_rate * (n - 1)
        else:
            expected_cooperators_next = 0
        if round_num == r - 1:
            if observed_cooperators_prev_round >= m:
                return Action.C
            else:
                return Action.D
        if round_num == r - 2:
            if observed_cooperators_prev_round < m:
                return Action.D
            else:
                return Action.D
        if observed_cooperators_prev_round >= m:
            if expected_cooperators_next >= m - 1:
                return Action.D
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_93(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Defection strategy.
    
    Exploits the asymmetric payoff structure by:
    1. Defecting in round 1 to probe opponent strategies
    2. Defecting in all subsequent rounds to free-ride on cooperators
    3. Defecting in the final round to maximize terminal payoff
    
    Core insight: Defection is dominant because defectors gain the full reward k
    whenever m or more cooperators exist, while paying zero contribution cost.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        """Initialize the exploitative defection strategy."""
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        """
        Decision rule: DEFECT in every round.
        
        Round 1 (round_number == 0):
            - Defect to establish baseline and probe opponent cooperation
        
        Rounds 2 to r-1 (0 < round_number < r-1):
            - Defect to free-ride on any cooperators
            - If m or more cooperators exist, gain k without cost
            - If fewer than m cooperate, threshold fails anyway; keep endowment
        
        Final Round (round_number == r-1):
            - Defect to capture final payoff with no retaliation consequences
        """
        if state.round_number == 0:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_94(BaseStrategy):
    """
    Adaptive Threshold Parasitism: An exploitative strategy that free-rides on others' 
    cooperation by defecting when the threshold is likely to be met, and only cooperating 
    defensively when cooperation is the swing vote needed to reach the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n = game_description.n_players
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        prev_round_idx = round_num - 1
        coop_count_prev = int(sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            coop_count_prev += 1
        if coop_count_prev >= self.m:
            return Action.D
        elif coop_count_prev == self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_95(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Free-Riding with Conditional Defection
    
    Maximizes personal payoff by defaulting to defection, cooperating only when
    the player's contribution directly avoids collective failure, and abandoning
    all restraint in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        observed_cooperators = int(sum(history.opponent_actions[round_number - 1, :]))
        if self.m == 1:
            return Action.D
        if self.m == self.n_players:
            return Action.D
        if observed_cooperators >= self.m:
            return Action.D
        elif observed_cooperators == self.m - 1:
            return Action.C
        else:
            remaining_needed = self.m - observed_cooperators
            if remaining_needed <= 1:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_96(BaseStrategy):
    """
    Conditional Free-Riding with Threshold Adaptation.
    
    Exploits the threshold mechanism by defecting by default while monitoring
    cooperation patterns. Only cooperates in rare edge cases when the threshold
    is at risk and historical cooperation rates are high enough to justify
    the contribution cost.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if round_num == 0:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[round_num - 1, :]))
        if round_num == r - 1 or round_num == r - 2:
            return Action.D
        if cooperators_last_round >= m:
            return Action.D
        if cooperators_last_round == m - 1:
            total_rounds_played = round_num
            total_opponent_cooperations = 0
            for i in range(round_num):
                total_opponent_cooperations += int(np.sum(history.opponent_actions[i, :]))
            if total_rounds_played > 0 and n - 1 > 0:
                coop_rate = total_opponent_cooperations / ((n - 1) * total_rounds_played)
            else:
                coop_rate = 0.0
            remaining_rounds = r - round_num
            if coop_rate > 0.6 and remaining_rounds > 2:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_97(BaseStrategy):
    """
    Adaptive Threshold Harvesting: An exploitative strategy that maximizes payoff by
    free-riding on others' cooperation when the threshold is met, while using calculated
    randomness to maintain the threshold at marginal cooperation levels.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        previous_round_idx = current_round - 1
        cooperators_prev = int(sum(history.opponent_actions[previous_round_idx, :]))
        if cooperators_prev >= self.m:
            return Action.D
        elif cooperators_prev == self.m - 1:
            if random.random() < 1.0 / self.m:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_98(BaseStrategy):
    """
    Threshold Parasitism: An exploitative strategy that freeloads on others' cooperation
    while maintaining pure defection as the default. Exploits the asymmetric payoff structure
    where defectors receive the full reward (k) without bearing the cooperation cost.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
        rounds_remaining = self.n_rounds - current_round
        if cooperators_last_round >= self.m:
            return Action.D
        if cooperators_last_round == self.m - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_99(BaseStrategy):
    """
    Adaptive Defection with Conditional Cooperation (ADCC): An exploitative strategy
    that defects by default, cooperates minimally to trigger rewards when others nearly
    meet the threshold, and always defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.epsilon = 0.5 / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        prev_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        coop_rate = prev_cooperators / (self.n - 1) if self.n > 1 else 0.0
        threshold_rate = self.m / self.n
        if coop_rate >= threshold_rate - self.epsilon:
            return Action.D
        elif coop_rate > 0.0:
            deficit = self.m - prev_cooperators
            if deficit == 1:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_100(BaseStrategy):
    """
    Adaptive Conditional Defection strategy for Collective Risk Dilemma.
    
    Exploits the asymmetry between cooperators and defectors by defaulting to defection,
    free-riding on others' cooperation, and capturing payoffs without bearing costs.
    Core principle: defection dominates in nearly all game states.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round >= self.n_rounds - 2:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if cooperators_last_round >= self.m:
            return Action.D
        lookback_rounds = min(3, current_round)
        start_idx = max(0, current_round - lookback_rounds)
        cooperators_observed = 0
        for round_idx in range(start_idx, current_round):
            cooperators_observed += int(np.sum(history.opponent_actions[round_idx, :]))
        if lookback_rounds > 0 and self.n_players > 0:
            recent_coop_rate = cooperators_observed / (lookback_rounds * self.n_players)
        else:
            recent_coop_rate = 0.0
        threshold_ratio = self.m / self.n_players if self.n_players > 0 else 0.0
        if recent_coop_rate > threshold_ratio * 1.2:
            return Action.D
        elif recent_coop_rate >= threshold_ratio * 0.9:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_101(BaseStrategy):
    """
    Adaptive Free-Rider with Threshold Exploitation strategy for Collective Risk Dilemma.
    
    Exploits the asymmetry between cooperators and defectors by:
    1. Defecting in round 1 (exploration)
    2. Observing cooperation patterns and defecting when threshold is already met
    3. Using stochastic cooperation only when pivotal (coop_count == m-1)
    4. Pure defection in final round
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        previous_round_actions = history.opponent_actions[current_round - 1, :]
        coop_count = int(np.sum(previous_round_actions))
        if coop_count >= self.m:
            return Action.D
        if coop_count == self.m - 1:
            p_contribute = min(0.3, 1.0 / self.n)
            if self.n <= 3:
                if coop_count == self.n - 1:
                    p_contribute = 0.5
            if random.random() < p_contribute:
                return Action.C
            else:
                return Action.D
        if coop_count < self.m - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_102(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation
    
    Maximizes personal payoff by defaulting to defection and conditionally cooperating
    only when others' cooperation makes threshold m likely, allowing free-riding on
    their contributions. Uses empirical cooperation rates to detect and exploit cooperative
    players while avoiding wasted contributions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        cooperators_prev = int(np.sum(history.opponent_actions[round_number - 1, :]))
        p_coop = cooperators_prev / (self.n_players - 1) if self.n_players > 1 else 0.0
        threshold_ratio = self.m / self.n_players
        approaching_ratio = (self.m - 1) / (self.n_players - 1)
        if p_coop >= threshold_ratio and p_coop < 1.0:
            return Action.D
        if p_coop < approaching_ratio:
            return Action.D
        if round_number <= self.n_rounds / 2:
            expected_cooperators = self._adaptive_estimate(cooperators_prev, round_number, self.n_rounds)
            if expected_cooperators >= self.m:
                return Action.D
            else:
                return Action.C
        if approaching_ratio <= p_coop < threshold_ratio:
            return Action.D
        if approaching_ratio <= p_coop < threshold_ratio:
            prob_defect = 1.0 - (p_coop - approaching_ratio) / (threshold_ratio - approaching_ratio)
            return Action.D if random.random() < prob_defect else Action.C
        return Action.D

    def _adaptive_estimate(self, current_cooperators: int, round_number: int, total_rounds: int) -> float:
        """
        Estimate expected cooperators in future rounds with decay factor.
        
        Args:
            current_cooperators: Number of cooperators in the previous round
            round_number: Current round index (0-indexed)
            total_rounds: Total number of rounds
            
        Returns:
            Expected number of cooperators considering decay
        """
        if self.n_players <= 1:
            return float(current_cooperators)
        current_rate = current_cooperators / (self.n_players - 1)
        rounds_elapsed = round_number
        decay_factor = 1.0 - 0.1 * rounds_elapsed / total_rounds
        decay_factor = max(0.0, decay_factor)
        expected_future_rate = current_rate * decay_factor
        rounds_remaining = total_rounds - round_number - 1
        expected_cooperators = current_cooperators + expected_future_rate * (self.n_players - 1) * rounds_remaining
        return expected_cooperators

class Strategy_EXPLOITATIVE_103(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation
    
    Core approach: Exploit asymmetry in payoffs by free-riding on others' cooperation.
    Defection yields (1 + k) when threshold is met, while cooperation yields (0 + k).
    Strategy defaults to defection with selective cooperation to maintain ambiguity.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.opponent_coop_freq = np.zeros(self.n_players - 1)
        self.opponent_coop_count = np.zeros(self.n_players - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        remaining_rounds = self.n_rounds - round_number
        if remaining_rounds <= 2:
            return Action.D
        prev_round_idx = round_number - 1
        cooperators_prev_round = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        cooperation_rate = cooperators_prev_round / (self.n_players - 1)
        threshold_likelihood = cooperation_rate >= (self.m - 1) / (self.n_players - 1)
        self._update_opponent_profiles(history, prev_round_idx)
        if threshold_likelihood:
            return Action.D
        if round_number > 1 and remaining_rounds >= 3:
            my_coop_freq = self._get_my_cooperation_frequency(history, round_number)
            global_coop_freq = self._get_global_cooperation_frequency(history, round_number)
            if my_coop_freq == 0 and global_coop_freq > 0.4:
                if random.random() < 0.15:
                    return Action.C
        return Action.D

    def _update_opponent_profiles(self, history: PlayerHistory, round_idx: int) -> None:
        """Update cooperation frequency tracking for each opponent."""
        for opp_idx in range(self.n_players - 1):
            if history.opponent_actions[round_idx, opp_idx]:
                self.opponent_coop_count[opp_idx] += 1
            self.opponent_coop_freq[opp_idx] = self.opponent_coop_count[opp_idx] / (round_idx + 1)

    def _get_my_cooperation_frequency(self, history: PlayerHistory, round_number: int) -> float:
        """Calculate this player's cooperation frequency up to current round."""
        if round_number == 0:
            return 0.0
        my_coop_count = int(np.sum(history.my_actions[:round_number]))
        return my_coop_count / round_number

    def _get_global_cooperation_frequency(self, history: PlayerHistory, round_number: int) -> float:
        """Calculate global cooperation frequency across all players up to current round."""
        if round_number == 0:
            return 0.0
        total_coop = int(np.sum(history.my_actions[:round_number]))
        total_coop += int(np.sum(history.opponent_actions[:round_number, :]))
        total_actions = (1 + self.n_players - 1) * round_number
        return total_coop / max(total_actions, 1)

class Strategy_EXPLOITATIVE_104(BaseStrategy):
    """
    Exploitative strategy using adaptive defection with selective parasitism.
    Maximizes payoff by free-riding on others' cooperation while minimizing
    contribution risk through strategic defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.defection_success_count = 0
        self.total_rounds_played = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        last_round_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        rounds_remaining = self.r - current_round
        if last_round_cooperators >= self.m:
            return Action.D
        if last_round_cooperators == self.m - 1:
            return Action.D
        threshold_gap = self.m - last_round_cooperators
        if threshold_gap >= self.n / 2:
            return Action.D
        p_cooperate = self._calculate_cooperation_probability(last_round_cooperators, rounds_remaining)
        if random.random() < p_cooperate:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_probability(self, cooperators_last_round: int, rounds_remaining: int) -> float:
        """
        Calculate probability of cooperating based on game state.
        Lower probabilities favor exploitation.
        """
        if cooperators_last_round == 0:
            base_prob = 1.0 / (self.n - 1) * (rounds_remaining / max(1, self.r))
            return min(base_prob, 0.1)
        elif cooperators_last_round == self.m - 2:
            return min(0.2, 2.0 / (self.n - 1))
        else:
            base_prob = 1.0 / (self.n - 1) * (rounds_remaining / max(1, self.r))
            total_played = self.total_rounds_played + 1
            if total_played > 0:
                discount_factor = 1.0 - self.defection_success_count / total_played
            else:
                discount_factor = 1.0
            return base_prob * discount_factor

class Strategy_EXPLOITATIVE_105(BaseStrategy):
    """
    Exploitative Strategy: Conditional Free-Riding with Adaptive Defection
    
    Exploits the threshold mechanism by defecting when cooperation is "inevitable"
    (others will contribute enough), while maintaining a safe fallback of defection
    against non-cooperative populations.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.permanent_defection_flag = False
        self.all_defect_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        m = self.game_description.m
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == r - 1:
            return Action.D
        if self.permanent_defection_flag:
            return Action.D
        cooperators_last = int(sum(history.opponent_actions[round_num - 1, :]))
        defection_rate = 1.0 - cooperators_last / n
        threshold_t = (1.0 - 2.0 / r) * (n - m) / n
        if round_num >= 2:
            cooperators_prev = int(sum(history.opponent_actions[round_num - 2, :]))
            if cooperators_last == 0 and cooperators_prev == 0:
                self.all_defect_counter += 1
                if self.all_defect_counter >= 2:
                    self.permanent_defection_flag = True
                    return Action.D
            else:
                self.all_defect_counter = 0
        if cooperators_last >= m:
            return Action.D
        elif cooperators_last == m - 1 and defection_rate <= threshold_t:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_106(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Free-Riding with Conditional Defection
    
    Maximizes personal payoff by exploiting the threshold mechanism: free-rides when 
    cooperation is likely to occur naturally, and defects strategically to avoid 
    contributing to failed collective efforts.
    
    Core principle: Never cooperate. Always defect to either free-ride on others' 
    cooperation or minimize losses when cooperation fails.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        previous_round_idx = state.round_number - 1
        cooperators_last_round = int(sum(history.opponent_actions[previous_round_idx, :]))
        coop_rate = cooperators_last_round / self.n
        threshold_ratio = self.m / self.n
        return Action.D

class Strategy_EXPLOITATIVE_107(BaseStrategy):
    """
    Adaptive Free-Riding with Contingent Defection strategy for Collective Risk Dilemma.
    
    Exploits the threshold mechanism by:
    1. Always defecting in round 1 (information gathering)
    2. Free-riding when cooperation is inevitable (coop_rate high)
    3. Defecting when cooperation is unlikely or in endgame
    4. Conditionally cooperating only as marginal player when necessary
    5. Always defecting in final round (no future reputation value)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        total_opponent_coops = 0
        if history is not None and current_round > 0:
            for round_idx in range(current_round):
                total_opponent_coops += np.sum(history.opponent_actions[round_idx, :])
        total_possible_coops = (n - 1) * current_round
        if total_possible_coops == 0:
            coop_rate = 0.0
        else:
            coop_rate = total_opponent_coops / total_possible_coops
        cooperation_threshold_rate = (m - 1) / (n - 1)
        low_cooperation_threshold = (m - 2) / (n - 1) if m > 2 else 0.0
        endgame_threshold = 0.75 * r
        if coop_rate >= cooperation_threshold_rate and r - current_round > 2:
            return Action.D
        if coop_rate <= low_cooperation_threshold or current_round > endgame_threshold:
            return Action.D
        if history is not None and current_round > 0:
            prev_round_coops = int(np.sum(history.opponent_actions[current_round - 1, :]))
            prev_round_coops += int(history.my_actions[current_round - 1])
            if prev_round_coops >= m:
                return Action.D
            elif prev_round_coops < m - 1:
                return Action.D
            else:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_108(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD): An exploitative strategy that maximizes payoff
    by learning opponents' cooperation patterns and positioning itself to capture threshold
    rewards while minimizing contributions. Defects in round 1 and final round, adaptively
    exploits the threshold in middle rounds, and free-rides when others' cooperation is
    predictable.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        rounds_elapsed = round_number
        total_opponent_cooperations = np.sum(history.opponent_actions[:round_number, :])
        total_opponent_actions = self.n_players * rounds_elapsed
        if total_opponent_actions == 0:
            avg_opponent_coop = 0.0
        else:
            avg_opponent_coop = total_opponent_cooperations / total_opponent_actions
        threshold_likelihood = (self.m - 1) / self.n_players
        recent_cooperators = np.sum(history.opponent_actions[round_number - 1, :])
        threshold_met_last_round = recent_cooperators >= self.m - 1
        if avg_opponent_coop >= threshold_likelihood:
            if threshold_met_last_round and round_number < self.n_rounds - 2:
                return Action.D
            else:
                return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_109(BaseStrategy):
    """
    Adaptive Threshold Parasitism: An exploitative strategy that defects by default,
    cooperates only to trigger threshold crossing for free-riding, and exploits
    high cooperation patterns. Includes late-game insurance to boost payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        cooperators_prev = int(sum(history.opponent_actions[round_num - 1, :]))
        if round_num >= self.n_rounds - 2:
            return self._end_game_decision(round_num, cooperators_prev, history)
        return self._middle_game_decision(round_num, cooperators_prev, history)

    def _end_game_decision(self, round_num: int, cooperators_prev: int, history: PlayerHistory) -> Action:
        """End-game logic: cooperate if payoff trajectory is below baseline."""
        accumulated_payoff = float(np.sum(history.my_payoffs[:round_num]))
        baseline_payoff = round_num * 1.5
        if cooperators_prev >= self.m:
            return Action.D
        if cooperators_prev == self.m - 1:
            return Action.C
        if accumulated_payoff < baseline_payoff:
            return Action.C
        return Action.D

    def _middle_game_decision(self, round_num: int, cooperators_prev: int, history: PlayerHistory) -> Action:
        """Middle game logic: exploit threshold crossing and high cooperation."""
        if cooperators_prev >= self.m:
            return Action.D
        if cooperators_prev == self.m - 1:
            return Action.C
        look_back_rounds = min(3, round_num)
        if look_back_rounds > 0:
            look_back_start = max(0, round_num - look_back_rounds)
            look_back_window = history.opponent_actions[look_back_start:round_num, :]
            total_actions = look_back_window.size
            if total_actions > 0:
                total_cooperations = int(np.sum(look_back_window))
                coop_rate = total_cooperations / total_actions
                if coop_rate > 0.5:
                    return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_110(BaseStrategy):
    """
    Adaptive Threshold Gaming: An exploitative strategy that defaults to defection,
    free-rides when others are likely to meet the cooperation threshold, and adapts
    based on observed cooperation rates while maintaining a conservative exploitation stance.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.epsilon = 0.05

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        observed_coop_rate = self._calculate_cooperation_rate(history, state.round_number)
        threshold_rate = self.game_description.m / self.game_description.n_players
        near_threshold_rate = (self.game_description.m - 1) / self.game_description.n_players
        rounds_remaining = self.game_description.n_rounds - state.round_number
        if observed_coop_rate >= threshold_rate - self.epsilon:
            return Action.D
        elif observed_coop_rate >= near_threshold_rate:
            return Action.D
        elif observed_coop_rate < near_threshold_rate and rounds_remaining <= 2:
            return Action.D
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the observed cooperation rate across all players in all previous rounds.
        
        Returns a float in [0, 1] representing the proportion of cooperative actions observed.
        Handles edge case of no history gracefully.
        """
        if current_round == 0:
            return 0.0
        total_cooperators = int(np.sum(history.opponent_actions[:current_round, :]))
        total_observations = current_round * self.game_description.n_players
        if total_observations == 0:
            return 0.0
        coop_rate = total_cooperators / total_observations
        return coop_rate

class Strategy_EXPLOITATIVE_111(BaseStrategy):
    """
    Adaptive Threshold Exploitation Strategy for Collective Risk Dilemma.
    
    Core Logic: Always defect to exploit the asymmetric payoff structure where
    defectors earn 1 + k when threshold is met, while cooperators only earn k.
    Strategically exploits predictable cooperators and triggers defection cascades.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        if history is not None:
            cooperators_last_round = int(np.sum(history.opponent_actions[round_number - 1, :]))
            threshold_met_last_round = cooperators_last_round >= self.m
            if threshold_met_last_round:
                return Action.D
            observed_coop_rate = cooperators_last_round / self.n_players
            estimated_future_cooperators = observed_coop_rate * 0.85 * self.n_players
            if estimated_future_cooperators >= self.m:
                return Action.D
            threshold_ratio = self.m / self.n_players
            if observed_coop_rate >= threshold_ratio * 1.2:
                return Action.D
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_112(BaseStrategy):
    """
    Conditional Free-Rider with Adaptive Defection Strategy.
    
    Exploits the threshold mechanism by:
    1. Always defecting when threshold is met (1 + k payoff)
    2. Defecting when threshold is not met (1 payoff, safe baseline)
    3. Rare strategic cooperation seeding to encourage opponent cooperation
    4. Aggressive defection in final rounds for endgame exploitation
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold_ever_met = False
        self.defection_count = 0
        self.cooperation_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        n_rounds = self.game_description.n_rounds
        m = self.game_description.m
        n_players = self.game_description.n_players
        if round_num == 0:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[round_num - 1, :]))
        if cooperators_last_round >= m:
            self.threshold_ever_met = True
        if round_num > 0 and round_num < n_rounds - 1:
            if cooperators_last_round >= m:
                self.defection_count += 1
                return Action.D
            self.defection_count += 1
            if not self.threshold_ever_met and random.random() < (m - 1) / n_players:
                self.cooperation_count += 1
                return Action.C
            return Action.D
        if round_num == n_rounds - 1:
            if self.threshold_ever_met or cooperators_last_round >= m:
                return Action.D
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_113(BaseStrategy):
    """
    Exploitative Strategy: Conditional Free-Riding with Adaptive Threshold Monitoring
    
    Exploits the coordination problem in threshold games by defecting when others reliably
    provide the threshold, while strategically cooperating when the threshold is marginal.
    Maximizes payoff by free-riding on cooperators' contributions while minimizing losses
    when cooperation fails.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.critical_threshold = self.m / self.n - 0.05
        self.defect_threshold_high = self.critical_threshold + 0.1
        self.defect_threshold_final = self.critical_threshold + 0.05
        self.coop_zone_lower = self.critical_threshold - 0.05
        self.coop_zone_upper = self.critical_threshold + 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        coop_count_last = int(np.sum(history.opponent_actions[current_round - 1, :]))
        coop_rate_last = coop_count_last / self.n
        if current_round == self.r - 1:
            return self._final_round_decision(coop_count_last, coop_rate_last)
        return self._middle_round_decision(coop_count_last, coop_rate_last)

    def _middle_round_decision(self, coop_count_last: int, coop_rate_last: float) -> Action:
        """
        Decision logic for rounds 2 through (r-1).
        
        High cooperation rate (>= T + 0.10): DEFECT (free-ride)
        Marginal zone (T - 0.05 to T + 0.10): COOPERATE (maintain threshold)
        Low cooperation rate (< T - 0.05): DEFECT (cooperation pointless)
        """
        if coop_rate_last >= self.defect_threshold_high:
            return Action.D
        elif coop_rate_last >= self.coop_zone_lower:
            return Action.C
        else:
            return Action.D

    def _final_round_decision(self, coop_count_last: int, coop_rate_last: float) -> Action:
        """
        Decision logic for final round (round r).
        
        Maximum information available, zero retaliation risk.
        Exploit safe free-riding opportunities.
        """
        if coop_rate_last >= self.defect_threshold_final:
            return Action.D
        elif coop_rate_last >= self.coop_zone_lower:
            remaining_cooperators = coop_count_last - 1
            if remaining_cooperators >= self.m:
                return Action.D
            else:
                return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_114(BaseStrategy):
    """
    Adaptive Threshold Exploitation (ATE) Strategy for Collective Risk Dilemma.
    
    Exploits the asymmetry where defectors capture disproportionate value when the 
    threshold is met. Uses information gathering in round 1, adaptive exploitation 
    in middle rounds, and unconditional defection in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        cooperators_prev = int(np.sum(history.opponent_actions[round_number - 1, :]))
        if cooperators_prev >= self.m:
            return Action.D
        if cooperators_prev == self.m - 1:
            return Action.D
        deficit = self.m - cooperators_prev - 1
        if deficit == 0:
            return Action.D
        if deficit == 1 and round_number > self.n_rounds * 0.75:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_115(BaseStrategy):
    """
    Adaptive Threshold Parasitism: An exploitative strategy that identifies and rides on 
    others' cooperation while minimizing personal contribution. Defects strategically to 
    harvest rewards from reliable cooperators while ensuring the threshold is met.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.opponent_cooperation_rates = np.zeros(self.n_players - 1)
        self.opponent_cooperation_counts = np.zeros(self.n_players - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        self._update_cooperation_statistics(history, current_round)
        cooperators_last_round = int(np.sum(history.opponent_actions[current_round - 1, :]))
        reliable_cooperators = int(np.sum(self.opponent_cooperation_rates > 0.6))
        if cooperators_last_round >= self.m:
            return Action.D
        elif reliable_cooperators >= self.m:
            return Action.D
        elif cooperators_last_round + reliable_cooperators >= self.m:
            if random.random() < 0.75:
                return Action.D
            else:
                return Action.C
        else:
            return Action.C

    def _update_cooperation_statistics(self, history: PlayerHistory, current_round: int) -> None:
        """
        Update cooperation rates for each opponent based on observed history.
        """
        for opponent_idx in range(self.n_players - 1):
            cooperations = int(np.sum(history.opponent_actions[:current_round, opponent_idx]))
            self.opponent_cooperation_counts[opponent_idx] = cooperations
            if current_round > 0:
                self.opponent_cooperation_rates[opponent_idx] = cooperations / current_round
            else:
                self.opponent_cooperation_rates[opponent_idx] = 0.0

class Strategy_EXPLOITATIVE_116(BaseStrategy):
    """
    Adaptive Defection with Conditional Cooperation - Exploitative Strategy
    
    Exploits the asymmetry in the collective risk dilemma by systematically
    free-riding when thresholds are met, preventing thresholds when near-met,
    and always defaulting to defection as the individually rational action.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        rounds_remaining = self.n_rounds - current_round
        if rounds_remaining <= 2:
            return Action.D
        last_round_idx = current_round - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[last_round_idx, :]))
        if cooperators_last_round >= self.m:
            return Action.D
        elif cooperators_last_round == self.m - 1:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_117(BaseStrategy):
    """
    Adaptive Threshold Exploit: A strict free-rider strategy that exploits the asymmetry
    in the Collective Risk Dilemma by defecting whenever possible to capture rewards
    without bearing cooperation costs.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        n_rounds = self.game_description.n_rounds
        m = self.game_description.m
        current_round = state.round_number
        if current_round == n_rounds - 1:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[-1, :]))
        if cooperators_last_round >= m:
            return Action.D
        if cooperators_last_round == m - 1:
            return Action.D
        if cooperators_last_round < m - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_118(BaseStrategy):
    """
    Adaptive Threshold Parasitism: An exploitative strategy that free-rides on others'
    cooperation while never contributing to the collective good. Always defects except
    in strategically impossible situations.
    
    Core logic:
    - Round 1: Defect (gather information at zero cost)
    - Rounds 2 to r-1: Defect always (free-ride if threshold met, avoid waste if not)
    - Final round: Defect (no future consequences)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        prev_round_idx = state.round_number - 1
        coop_count = sum(history.opponent_actions[prev_round_idx, :])
        coop_rate = coop_count / self.game_description.n_players
        threshold_rate = self.game_description.m / self.game_description.n_players
        return Action.D

class Strategy_EXPLOITATIVE_119(BaseStrategy):
    """
    Conditional Exploitation with Adaptive Thresholding strategy.
    
    Exploits cooperation asymmetry by:
    1. Defecting in round 1 to establish baseline
    2. Defecting in final round for maximum extraction
    3. Free-riding when threshold is likely met
    4. Avoiding wasted contributions when threshold is unachievable
    5. Refusing to be the pivot player at marginal cooperation levels
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        prev_round_idx = round_num - 1
        cooperators_last_round = np.sum(history.opponent_actions[prev_round_idx, :])
        cooperation_rate = cooperators_last_round / self.n
        expected_cooperators_others = cooperation_rate * (self.n - 1)
        if expected_cooperators_others >= self.m:
            return Action.D
        elif expected_cooperators_others < self.m - 1:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_120(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Defection.
    
    Exploits the threshold mechanism by consistently defecting while free-riding
    on others' cooperation. Tracks opponent cooperation frequencies and maintains
    defection to maximize individual payoff through parasitic extraction.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_count = np.zeros(game_description.n_players - 1, dtype=np.int32)
        self.threshold_met_history = []
        self.total_rounds_observed = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        current_round = state.round_number
        if history is not None:
            last_round_idx = current_round - 1
            if last_round_idx >= 0 and last_round_idx < len(history.opponent_actions):
                cooperators_last_round = int(np.sum(history.opponent_actions[last_round_idx, :]))
                if cooperators_last_round >= self.game_description.m:
                    self.threshold_met_history.append(True)
                else:
                    self.threshold_met_history.append(False)
                for opponent_idx in range(self.game_description.n_players - 1):
                    self.cooperation_count[opponent_idx] += int(history.opponent_actions[last_round_idx, opponent_idx])
            self.total_rounds_observed = current_round
        if len(self.threshold_met_history) > 0 and any(self.threshold_met_history) and (np.sum(self.cooperation_count) > 0):
            return Action.D
        if self.total_rounds_observed > 0:
            opponent_cooperation_rates = self.cooperation_count / self.total_rounds_observed
            if np.any(opponent_cooperation_rates > 0.3):
                return Action.D
        if len(self.threshold_met_history) > 1:
            recent_threshold_met = any(self.threshold_met_history[-2:])
            if not recent_threshold_met:
                return Action.D
        if current_round == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_122(BaseStrategy):
    """
    Conditional Free-Rider with Adaptive Threshold Strategy.
    
    Exploits the threshold mechanism by defecting whenever possible while monitoring
    cooperation patterns to identify when cooperation becomes pivotal. Only cooperates
    when exactly m-1 others are expected to cooperate (making this player the tiebreaker),
    or in edge cases where adaptation is beneficial.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cumulative_cooperators = 0
        self.cumulative_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        self.cumulative_cooperators = int(np.sum(history.opponent_actions[:state.round_number, :]))
        self.cumulative_rounds = state.round_number * (self.game_description.n_players - 1)
        if self.cumulative_rounds > 0:
            cooperation_rate = self.cumulative_cooperators / self.cumulative_rounds
        else:
            cooperation_rate = 0.0
        expected_cooperators = cooperation_rate * (self.game_description.n_players - 1)
        m = self.game_description.m
        if expected_cooperators > m:
            return Action.D
        if math.fabs(expected_cooperators - (m - 1)) < 0.5:
            return Action.C
        if expected_cooperators < m - 1:
            return Action.D
        return Action.C

class Strategy_EXPLOITATIVE_123(BaseStrategy):
    """
    Adaptive Free-Riding with Threshold Exploitation.
    
    Exploits the collective risk dilemma by minimizing personal contribution
    while maximizing extraction of collective benefits through threshold parasitism.
    Defects strategically based on observed cooperation patterns, with special
    handling for marginal threshold scenarios and final rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        prev_round_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        if current_round == self.n_rounds - 1:
            return Action.D
        if prev_round_cooperators >= self.m:
            return Action.D
        elif prev_round_cooperators == self.m - 1:
            if random.random() < 0.88:
                return Action.D
            else:
                return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_124(BaseStrategy):
    """
    Exploitative Strategy: "Conditional Defection with Selective Cooperation"
    
    Exploits the asymmetry in payoffs by defecting by default to extract value from 
    others' cooperation. Cooperates rarely and strategically to avoid predictability 
    and retaliation, while maintaining a fundamentally exploitative posture.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_cooperation_round = -10

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        m = self.game_description.m
        k = self.game_description.k
        prev_round_idx = state.round_number - 1
        c_prev = int(sum(history.opponent_actions[prev_round_idx, :]))
        if state.round_number == r - 1:
            return Action.D
        if c_prev >= m:
            return Action.D
        if c_prev == m - 1:
            return Action.D
        if c_prev >= math.ceil(m / 2.0):
            return Action.D
        rounds_remaining = r - state.round_number
        if rounds_remaining <= 2:
            return Action.D
        if state.round_number >= 1 and state.round_number < r - 1:
            if c_prev >= m - 1 and state.round_number - self.last_cooperation_round > 1:
                if random.random() < 1.0 / max(1, float(rounds_remaining)):
                    self.last_cooperation_round = state.round_number
                    return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_125(BaseStrategy):
    """
    Calculated Defection with Opportunistic Cooperation strategy.
    
    Exploits the payoff asymmetry by defecting whenever the threshold is likely to be met
    (capturing reward k without cost), and defecting when it's not (no loss since payoff is 1 either way).
    Only cooperates in final rounds as a safety valve when threshold appears unachievable.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_safety_rounds = 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        expected_cooperators = self._estimate_cooperators(history, round_number)
        variance = self._calculate_variance(history, round_number)
        if variance > 0.25:
            expected_cooperators = max(0, expected_cooperators - 0.5)
        likelihood_threshold_met = expected_cooperators >= self.m - 0.5
        if round_number == self.n_rounds - 1:
            return Action.D
        if likelihood_threshold_met:
            return Action.D
        elif round_number > self.n_rounds - self.threshold_safety_rounds - 1 and expected_cooperators < self.m:
            return Action.C
        else:
            return Action.D

    def _estimate_cooperators(self, history: PlayerHistory, round_number: int) -> float:
        """
        Estimate expected cooperators in this round using cooperation rates
        with recency bias (last 3 rounds weighted at 2x, earlier at 1x).
        """
        n_opponents = self.n_players - 1
        cooperator_sum = 0.0
        for opponent_idx in range(n_opponents):
            coop_count = 0.0
            total_weight = 0.0
            for past_round in range(round_number):
                if past_round >= max(0, round_number - 3):
                    weight = 2.0
                else:
                    weight = 1.0
                if history.opponent_actions[past_round, opponent_idx]:
                    coop_count += weight
                total_weight += weight
            if total_weight > 0:
                coop_rate = coop_count / total_weight
            else:
                coop_rate = 0.0
            cooperator_sum += coop_rate
        return cooperator_sum

    def _calculate_variance(self, history: PlayerHistory, round_number: int) -> float:
        """
        Calculate variance in cooperation rates across opponents.
        High variance indicates erratic/unpredictable players.
        """
        n_opponents = self.n_players - 1
        coop_rates = []
        for opponent_idx in range(n_opponents):
            coop_count = 0.0
            total_weight = 0.0
            for past_round in range(round_number):
                if past_round >= max(0, round_number - 3):
                    weight = 2.0
                else:
                    weight = 1.0
                if history.opponent_actions[past_round, opponent_idx]:
                    coop_count += weight
                total_weight += weight
            if total_weight > 0:
                coop_rate = coop_count / total_weight
            else:
                coop_rate = 0.0
            coop_rates.append(coop_rate)
        if len(coop_rates) == 0:
            return 0.0
        mean_rate = sum(coop_rates) / len(coop_rates)
        variance = sum(((rate - mean_rate) ** 2 for rate in coop_rates)) / len(coop_rates)
        return variance

class Strategy_EXPLOITATIVE_126(BaseStrategy):
    """
    Adaptive Threshold Exploitation (ATE) Strategy for Collective Risk Dilemma.
    
    Exploits the structural asymmetry of the game by systematically defecting while
    free-riding on others' cooperation when the threshold is met. Uses observations
    of previous round cooperation levels to make adaptive decisions, always defecting
    in the first and final rounds, and exploiting whenever the threshold was met in
    the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_count = []
        self.my_previous_action = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        n_rounds = self.game_description.n_rounds
        m_threshold = self.game_description.m
        if round_num == 0:
            return Action.D
        if round_num == n_rounds - 1:
            return Action.D
        prev_round_cooperators = int(sum(history.opponent_actions[round_num - 1, :]))
        total_cooperators_prev = prev_round_cooperators
        if history.my_actions[round_num - 1]:
            total_cooperators_prev += 1
        if total_cooperators_prev >= m_threshold:
            return Action.D
        elif total_cooperators_prev == m_threshold - 1:
            if history.my_actions[round_num - 1]:
                return Action.D
            else:
                remaining_rounds = n_rounds - round_num
                if remaining_rounds > 1:
                    return Action.D
                else:
                    return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_127(BaseStrategy):
    """
    Adaptive Threshold Opportunism: An exploitative strategy that free-rides on others' 
    cooperation while maintaining just enough cooperation to trigger payoff thresholds 
    when strategically beneficial. Prioritizes personal payoff maximization through 
    defection, with minimal cooperation only in final rounds when marginal.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        cooperators_prev_round = int(sum(history.opponent_actions[current_round - 1, :]))
        remaining_rounds = self.n_rounds - current_round
        is_final_round = remaining_rounds == 1
        if cooperators_prev_round >= self.m:
            return Action.D
        elif cooperators_prev_round == self.m - 1:
            if is_final_round:
                return Action.C
            elif self.k > 2.5:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_128(BaseStrategy):
    """
    Adaptive Threshold Parasitism: An exploitative strategy that free-rides on others' 
    cooperation while minimizing personal contribution. Systematically defects when the 
    threshold is likely to be met by others, with occasional cooperation to avoid 
    identification as a pure defector.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        last_round_opponent_actions = history.opponent_actions[-1, :]
        cooperators_last_round = np.sum(last_round_opponent_actions)
        observed_cooperation_rate = cooperators_last_round / self.n
        threshold_target = self.m / self.n
        buffer = self.k / (self.k + 1) * threshold_target
        if observed_cooperation_rate >= threshold_target:
            return Action.D
        if observed_cooperation_rate >= threshold_target - buffer:
            return Action.D
        if observed_cooperation_rate < threshold_target / 2:
            return Action.D
        if round_num >= 1 and round_num <= self.r - 3:
            cooperation_lower_bound = threshold_target / 2
            cooperation_upper_bound = threshold_target * 0.9
            if cooperation_lower_bound < observed_cooperation_rate < cooperation_upper_bound:
                recent_rounds_to_check = min(2, len(history.my_actions))
                if recent_rounds_to_check > 0:
                    recent_defections = sum((1 for i in range(-recent_rounds_to_check, 0) if not history.my_actions[i]))
                    if recent_defections >= 1:
                        if random.random() < 0.25:
                            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_129(BaseStrategy):
    """
    Adaptive Defection with Conditional Free-riding Strategy.
    
    Exploits the threshold mechanism by:
    1. Defecting in round 1 and final round to gather info and extract terminal value
    2. Free-riding when threshold is already met (observing >= m cooperators)
    3. Acting as marginal player only when sufficient rounds remain for exploitation
    4. Defecting otherwise to minimize losses when threshold is unreachable
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n_rounds = self.game_description.n_rounds
        m = self.game_description.m
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == n_rounds - 1:
            return Action.D
        last_round_cooperators = int(np.sum(history.opponent_actions[round_number - 1, :]))
        rounds_remaining = n_rounds - round_number
        if last_round_cooperators >= m:
            return Action.D
        if last_round_cooperators == m - 1:
            if rounds_remaining > 2:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_130(BaseStrategy):
    """
    Exploitative Strategy: Conditional Free-Riding with Adaptive Defection
    
    Core philosophy: Exploit the threshold mechanism by riding on others' cooperation
    while minimizing personal contribution. Always defect to avoid paying the cooperation
    cost, while capturing rewards when others meet the threshold.
    
    Decision logic:
    - Round 1: DEFECT (no history, gather information)
    - Round 2+: DEFECT (always)
      - If threshold was met in previous round: free-ride on others' cooperation
      - If threshold was not met: defection is weakly dominant (no benefit to contributing)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        previous_round_index = state.round_number - 1
        cooperators_in_prev_round = int(sum(history.opponent_actions[previous_round_index, :]))
        if cooperators_in_prev_round >= self.game_description.m:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_131(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD) Strategy
    
    Exploitative strategy that defects by default and cooperates only when 
    strictly necessary to reach the threshold, treating other players as payoff 
    sources. Prioritizes capturing high payoffs when others have already committed 
    to cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == self.n_rounds - 1:
            return Action.D
        if current_round == 0:
            return Action.D
        estimated_cooperators = self._estimate_cooperators(history, current_round)
        if estimated_cooperators >= self.m:
            return Action.D
        elif estimated_cooperators == self.m - 1:
            return Action.C
        else:
            return Action.D

    def _estimate_cooperators(self, history: PlayerHistory, current_round: int) -> float:
        """
        Estimate the number of cooperators expected in the current round
        based on historical cooperation rates.
        """
        if current_round <= 1:
            return (self.m + self.n_players) / 2.0
        total_cooperations = np.sum(history.opponent_actions[:current_round, :])
        total_opponent_actions = current_round * (self.n_players - 1)
        if total_opponent_actions == 0:
            cooperation_rate = 0.0
        else:
            cooperation_rate = total_cooperations / total_opponent_actions
        estimated_cooperators = cooperation_rate * (self.n_players - 1)
        return estimated_cooperators

class Strategy_EXPLOITATIVE_132(BaseStrategy):
    """
    Adaptive Threshold Exploitation strategy for Collective Risk Dilemma.
    
    Exploits the payoff asymmetry by systematically free-riding on cooperators' 
    contributions while avoiding wasted cooperation. Uses strategic testing after 
    prolonged all-defection phases to detect exploitable cooperative populations.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_all_defect_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        coop_count_previous_round = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if m == 1:
            return Action.D
        consecutive_all_defect = 0
        for round_idx in range(current_round - 1, -1, -1):
            coop_in_round = int(np.sum(history.opponent_actions[round_idx, :]))
            if coop_in_round == 0:
                consecutive_all_defect += 1
            else:
                break
        self.consecutive_all_defect_counter = consecutive_all_defect
        if consecutive_all_defect >= 3:
            self.consecutive_all_defect_counter = 0
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_133(BaseStrategy):
    """
    Conditional Freerider: An exploitative strategy that free-rides on others' cooperation
    while minimizing personal contribution. Defects in round 1 and final round, then
    strategically defects unless the threshold is at critical risk (m-1 cooperators).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.n_rounds - 1:
            return Action.D
        recent_cooperators = int(np.sum(history.opponent_actions[round_num - 1, :]))
        if recent_cooperators >= self.m:
            return Action.D
        if recent_cooperators == self.m - 1:
            return Action.C
        rounds_remaining = self.n_rounds - round_num
        if rounds_remaining <= 2:
            return Action.D
        if recent_cooperators < self.m - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_134(BaseStrategy):
    """
    Adaptive Threshold Parasitism: An exploitative strategy that defects to free-ride
    on others' cooperation. Monitors cooperation rates and adapts defection timing
    based on likelihood of threshold achievement, but fundamentally always defects
    as the dominant strategy in this payoff structure.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        if history is not None:
            prev_round_opponent_actions = history.opponent_actions[current_round - 1, :]
            cooperation_count = int(np.sum(prev_round_opponent_actions))
            cooperation_rate = cooperation_count / (self.n - 1) if self.n > 1 else 0.0
            threshold_trigger = (self.m - 1) / (self.n - 1) if self.n > 1 else 0.0
            if cooperation_rate >= threshold_trigger * 1.2:
                return Action.D
            elif cooperation_rate <= threshold_trigger * 0.7:
                return Action.D
            else:
                rounds_remaining = self.r - current_round
                if rounds_remaining <= 2:
                    return Action.D
                elif random.random() < 0.85:
                    return Action.D
                else:
                    return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_135(BaseStrategy):
    """
    Threshold Parasite: An exploitative strategy that free-rides on others' cooperation
    while strategically maintaining the threshold as a safety net.
    
    Core approach:
    - Round 1: DEFECT (information gathering)
    - Last round: DEFECT (no future consequences)
    - Middle rounds: Adaptive exploitation based on cooperation levels
      - High cooperation (â‰¥ m+2): DEFECT always
      - Moderate cooperation (m to m+1): COOPERATE with p=0.3
      - Low cooperation (m-1): COOPERATE with p=0.6
      - Very low cooperation (<m-1): DEFECT always
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        if history is not None:
            for round_idx in range(len(history.my_actions)):
                if round_idx >= len(self.cooperation_history):
                    cooperators_in_round = int(sum(history.opponent_actions[round_idx, :]))
                    if history.my_actions[round_idx]:
                        cooperators_in_round += 1
                    self.cooperation_history.append(cooperators_in_round)
            window_size = min(3, len(self.cooperation_history))
            if window_size > 0:
                recent_cooperation = self.cooperation_history[-window_size:]
                coop_avg = np.mean(recent_cooperation)
            else:
                coop_avg = 0
        else:
            coop_avg = 0
        if coop_avg >= m + 2:
            return Action.D
        elif coop_avg >= m and coop_avg < m + 2:
            return Action.C if random.random() < 0.3 else Action.D
        elif coop_avg == m - 1:
            return Action.C if random.random() < 0.6 else Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_136(BaseStrategy):
    """
    Conditional Defection with Threshold Exploitation.
    
    Exploits the asymmetry between cooperators and defectors by:
    - Always defecting in first and last rounds
    - Defecting in middle rounds regardless of observed cooperation
    - Never paying the cooperation cost while capturing rewards when threshold is met
    
    Core principle: Unconditional defection with information gathering.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        previous_round_cooperators = int(sum(history.opponent_actions[state.round_number - 1, :]))
        m = self.game_description.m
        if previous_round_cooperators >= m:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_137(BaseStrategy):
    """
    Adaptive Threshold Extraction (ATE): An exploitative strategy that dynamically
    shifts between extraction and minimal cooperation based on observed opponent
    behavior and game phase. Defects when threshold is met by others, cooperates
    only when necessary to secure the reward bonus.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        early_phase_end = math.ceil(self.r / 3)
        mid_phase_end = math.floor(2 * self.r / 3)
        if round_num <= early_phase_end:
            return self._early_game_phase(history, round_num)
        elif round_num <= mid_phase_end:
            return self._exploitation_phase(history, round_num)
        else:
            return self._endgame_phase(history, round_num)

    def _early_game_phase(self, history: PlayerHistory, round_num: int) -> Action:
        """
        Phase 1: Reconnaissance - determine opponent composition and cooperation rates.
        Defect if threshold already met; cooperate probabilistically otherwise.
        """
        cooperators_last = int(sum(history.opponent_actions[round_num - 1, :]))
        cooperation_rate = cooperators_last / (self.n - 1) if self.n > 1 else 0
        threshold_rate = self.m / self.n
        if cooperation_rate >= threshold_rate:
            return Action.D
        elif random.random() < threshold_rate:
            return Action.C
        else:
            return Action.D

    def _exploitation_phase(self, history: PlayerHistory, round_num: int) -> Action:
        """
        Phase 2: Exploitation - maximize extraction from predictable cooperators.
        Defect when threshold is sustained; cooperate only when genuinely at risk.
        """
        start_idx = max(0, round_num - 3)
        recent_rounds = history.opponent_actions[start_idx:round_num, :]
        if recent_rounds.size == 0:
            return Action.D
        recent_coop_count = np.sum(recent_rounds)
        recent_coop_rate = recent_coop_count / recent_rounds.size
        threshold_rate_high = (self.m - 1) / (self.n - 1) if self.n > 1 else 0
        threshold_rate_medium = self.m / self.n
        if recent_coop_rate >= threshold_rate_high:
            return Action.D
        if recent_coop_rate >= threshold_rate_medium:
            return Action.D
        if recent_coop_rate < threshold_rate_high:
            cooperators_last = int(sum(history.opponent_actions[round_num - 1, :]))
            defectors_last = self.n - 1 - cooperators_last
            defect_threshold = self.n - self.m + 1
            if defectors_last >= defect_threshold:
                return Action.D
            else:
                return Action.C
        return Action.D

    def _endgame_phase(self, history: PlayerHistory, round_num: int) -> Action:
        """
        Phase 3: Endgame - final extraction without regard for future reciprocity.
        Always defect or exploit established cooperation patterns.
        """
        all_rounds = history.opponent_actions[:round_num, :]
        if all_rounds.size == 0:
            return Action.D
        overall_coop_rate = np.sum(all_rounds) / all_rounds.size
        threshold_rate = self.m / self.n
        if overall_coop_rate >= threshold_rate:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_138(BaseStrategy):
    """
    Adaptive Free-Riding with Threshold Exploitation Strategy
    
    Maximizes personal payoff by exploiting cooperators when they exist,
    avoiding losses when cooperation seems impossible, and minimizing wasted
    contributions. Uses probabilistic decisions in uncertain zones and pure
    defection in first, last, and high-exploitation rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        if self.m == self.n_players:
            return Action.D
        if self.m == 2:
            return Action.D
        total_opponent_cooperations = int(np.sum(history.opponent_actions[:current_round, :]))
        possible_cooperation_slots = (self.n_players - 1) * current_round
        if possible_cooperation_slots == 0:
            return Action.D
        observed_cooperation_rate = total_opponent_cooperations / possible_cooperation_slots
        threshold_reachable = observed_cooperation_rate >= (self.m - 1) / self.n_players
        if threshold_reachable:
            return Action.D
        cautious_threshold = 0.8 * (self.m / self.n_players)
        if observed_cooperation_rate >= cautious_threshold:
            return Action.D
        if observed_cooperation_rate < 0.3:
            return Action.D
        if random.random() < observed_cooperation_rate:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_139(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Free-Riding
    
    Always defects throughout all rounds, exploiting cooperation from others
    without reciprocation. Defection is strictly dominant regardless of opponent
    behavior or round number in this simultaneous-move game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        return Action.D

class Strategy_EXPLOITATIVE_140(BaseStrategy):
    """
    Adaptive Free-Riding with Threshold Exploitation strategy.
    
    Maximizes payoff by exploiting the collective action problem:
    - Defects when threshold is already met (free-riding on others' cooperation)
    - Cooperates strategically when threshold not met (to enable future exploitation)
    - Unconditionally defects in final round (no reputational consequences)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperators_prev_round = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if cooperators_prev_round >= self.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_141(BaseStrategy):
    """
    Exploitative Strategy: Conditional Free-Riding with Adaptive Defection
    
    Exploits the threshold structure by strategically defecting when others are likely 
    to cooperate, while minimizing losses when cooperation fails. Treats cooperation as 
    a resource to extract from others rather than a mutual benefit.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        last_round_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        rounds_remaining = self.n_rounds - current_round - 1
        if rounds_remaining <= 1:
            return Action.D
        if last_round_cooperators >= self.m:
            return Action.D
        if last_round_cooperators == self.m - 1:
            return Action.D
        if last_round_cooperators < self.m - 1:
            return Action.D
        if current_round >= 1:
            history_window = min(5, current_round)
            recent_cooperations = np.sum(history.opponent_actions[current_round - history_window:current_round, :])
            recent_total = history_window * self.n_players
            if recent_total > 0:
                cooperation_rate = recent_cooperations / recent_total
            else:
                cooperation_rate = 0.0
            exploitation_threshold = 0.6
            if cooperation_rate > exploitation_threshold and rounds_remaining > 2:
                coop_probability = min(cooperation_rate * 0.3, 0.4)
                if random.random() < coop_probability:
                    return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_142(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD): An exploitative strategy that free-rides on
    cooperators when the threshold is met, while minimally cooperating only when
    necessary to restart broken cooperation cycles. Defects in round 1 and final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defect_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        last_round_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if last_round_cooperators >= m:
            self.defect_streak += 1
            return Action.D
        elif self.defect_streak >= 2:
            self.defect_streak = 0
            return Action.C
        else:
            self.defect_streak += 1
            return Action.D

class Strategy_EXPLOITATIVE_143(BaseStrategy):
    """
    Adaptive Threshold Hunting: An exploitative strategy that dynamically identifies
    and exploits populations cooperating above the threshold m, while avoiding
    punishment from populations cooperating below threshold.
    
    Core logic:
    - Round 1: Always defect (no history, dominance)
    - Final round: Always defect (finality, no future consequences)
    - Middle rounds: Adaptive based on observed cooperation frequency
      * High cooperation (> threshold): Defect to free-ride
      * Weak cooperation (30-60%): Cooperate to build exploitable coalition
      * Collapse (< 30%): Defect to secure baseline payoff
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.n_rounds - 1:
            return Action.D
        opponents_actions_last_round = history.opponent_actions[round_num - 1, :]
        others_cooperated = sum(opponents_actions_last_round)
        coop_freq = others_cooperated / (self.n_players - 1) if self.n_players > 1 else 0.0
        threshold_coop_freq = (self.m - 1) / (self.n_players - 1) if self.n_players > 1 else 0.0
        if coop_freq > threshold_coop_freq:
            return Action.D
        elif coop_freq == threshold_coop_freq and coop_freq > 0:
            return Action.D
        elif threshold_coop_freq > coop_freq >= 0.3:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_144(BaseStrategy):
    """
    Adaptive Defection with Conditional Cooperation.
    
    Exploits the threshold asymmetry in collective risk dilemmas by:
    - Defaulting to defection to guarantee payoff = 1
    - Free-riding when others meet the threshold (payoff = 1 + k)
    - Only cooperating when expected payoff from doing so exceeds defection
    - Abandoning cooperation in final rounds when future exploitation is impossible
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        prev_round_opponent_actions = history.opponent_actions[current_round - 1, :]
        prev_cooperators = int(np.sum(prev_round_opponent_actions))
        if prev_cooperators >= self.m:
            return Action.D
        total_opponent_cooperations = int(np.sum(history.opponent_actions[:current_round, :]))
        total_opponent_actions = (self.n - 1) * current_round
        if total_opponent_actions > 0:
            historical_coop_rate = total_opponent_cooperations / total_opponent_actions
        else:
            historical_coop_rate = 0.0
        expected_cooperators_from_others = historical_coop_rate * (self.n - 1)
        if current_round == self.r - 1:
            return Action.D
        if prev_cooperators == self.m - 1 and current_round < self.r - 2:
            recent_rounds_start = max(0, current_round - 5)
            recent_threshold_hits = 0
            for round_idx in range(recent_rounds_start, current_round):
                round_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
                if round_cooperators >= self.m:
                    recent_threshold_hits += 1
            if recent_threshold_hits > 0:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_145(BaseStrategy):
    """
    Conditional Parasitism with Adaptive Defection Strategy.
    
    Exploits the threshold mechanism by free-riding on others' cooperation.
    The strategy defects unconditionally in round 1 and the final round,
    and defects in intermediate rounds regardless of threshold status,
    maximizing payoff by avoiding cooperation costs while benefiting from
    others reaching the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        cooperators_prev_round = int(sum(history.opponent_actions[state.round_number - 1, :]))
        threshold_met_prev = cooperators_prev_round >= self.game_description.m
        return Action.D

class Strategy_EXPLOITATIVE_146(BaseStrategy):
    """
    Adaptive Defection with Conditional Parasitism.
    
    Exploits threshold dynamics by defecting in round 1 and final round,
    parasitizing on sufficient cooperation in middle rounds, and permanently
    defecting if cooperation cascades fail.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_failures = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if state.round_number == 0:
            return Action.D
        if state.round_number == r - 1:
            return Action.D
        if m == n:
            return Action.D
        last_round_idx = state.round_number - 1
        last_cooperators = int(np.sum(history.opponent_actions[last_round_idx, :]))
        if last_cooperators < m:
            self.consecutive_failures += 1
        else:
            self.consecutive_failures = 0
        if self.consecutive_failures > r / 2:
            return Action.D
        if last_cooperators >= m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_147(BaseStrategy):
    """
    Adaptive Defection with Conditional Exploitation (ADCE) Strategy.
    
    A game-theoretic exploitative strategy for the Collective Risk Dilemma that:
    1. Gathers information in the first half of rounds by always defecting
    2. Identifies reliable cooperators in the exploitation phase
    3. Systematically free-rides on threshold formers
    4. Unconditionally defects in the final round
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.info_gathering_threshold = math.floor(game_description.n_rounds / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == self.n_rounds - 1:
            return Action.D
        if self.m == self.n_players:
            return Action.D
        if current_round < self.info_gathering_threshold:
            return Action.D
        reliable_cooperators = self._count_reliable_cooperators(history, current_round)
        if reliable_cooperators >= self.m - 1:
            return Action.D
        elif reliable_cooperators == self.m - 2:
            return Action.D
        else:
            return Action.D

    def _count_reliable_cooperators(self, history: PlayerHistory, current_round: int) -> int:
        """
        Count opponents with cooperation rate >= 70% in previous rounds.
        
        Args:
            history: PlayerHistory object containing opponent actions
            current_round: Current round number (0-indexed)
            
        Returns:
            Number of reliable cooperators identified
        """
        if current_round == 0:
            return 0
        n_opponents = self.n_players - 1
        reliable_count = 0
        for opponent_idx in range(n_opponents):
            past_actions = history.opponent_actions[:current_round, opponent_idx]
            if len(past_actions) == 0:
                continue
            cooperation_rate = np.mean(past_actions)
            if cooperation_rate >= 0.7:
                reliable_count += 1
        return reliable_count

class Strategy_EXPLOITATIVE_148(BaseStrategy):
    """
    Threshold Parasitism: An exploitative strategy that free-rides on others' cooperation
    by defecting in early rounds, conditionally cooperating only when the cooperation threshold
    is likely to be met or when this player is the marginal cooperator, and always defecting
    in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.alpha = 0.7

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            cooperators_last = int(np.sum(history.opponent_actions[-1, :]))
            if cooperators_last == self.m - 1 and self.n_rounds == 2:
                return Action.C
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[-1, :]))
        total_opponent_cooperations = np.sum(history.opponent_actions)
        total_rounds_played = current_round
        historical_avg = total_opponent_cooperations / (total_rounds_played * self.n_players) if total_rounds_played > 0 else 0.0
        projected_cooperators = self.alpha * cooperators_last_round + (1.0 - self.alpha) * historical_avg * self.n_players
        if projected_cooperators >= self.m:
            return Action.C
        elif projected_cooperators >= self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_149(BaseStrategy):
    """
    Adaptive Free-Riding with Threshold Exploitation strategy.
    
    Maximizes personal payoff by exploiting the threshold mechanism:
    - Defects in rounds 1-2 for information gathering
    - Adaptively exploits threshold based on deficit calculation in rounds 3 to r-1
    - Unconditionally defects in the final round
    - Core insight: Once m cooperators exist, defectors earn k more than cooperators
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number <= 1:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        coop_last_round = sum(history.opponent_actions[round_number - 1, :])
        deficit = self.m - coop_last_round
        rounds_remaining = self.n_rounds - round_number - 1
        if deficit <= 0:
            return Action.D
        elif deficit == 1:
            if self.k >= 2.0 and rounds_remaining >= 2:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_150(BaseStrategy):
    """
    Adaptive Threshold Predation: An exploitative strategy that free-rides on others' 
    cooperation while strategically defecting to maximize personal payoff. Exploits the 
    coordination problem inherent in threshold games through dynamic defection with 
    conditional early-game cooperation as a lure.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        if t == 0:
            return Action.D
        if t == self.r - 1:
            return Action.D
        c_prev = int(np.sum(history.opponent_actions[t - 1, :]))
        threshold_met_prev = c_prev >= self.m
        if threshold_met_prev:
            return Action.D
        p_coop = c_prev / self.n if self.n > 0 else 0.0
        non_cooperators_prev = self.n - c_prev
        expected_cooperators = c_prev + non_cooperators_prev * p_coop
        if expected_cooperators >= self.m:
            return Action.D
        if c_prev == 0:
            if t <= 3 and t < self.r / 2:
                return Action.C
            return Action.D
        if c_prev == self.m - 1:
            if t <= self.r / 3:
                return Action.C
            return Action.D
        if t <= self.r / 2:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_151(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD) Strategy
    
    Exploits the fundamental asymmetry in the Collective Risk Dilemma where defectors
    always earn more than cooperators when the threshold is met. The strategy:
    - Always defects in round 1 (to gather information)
    - Always defects in the final round (subgame perfection)
    - Always defects in all other rounds (exploiting free-riding opportunities)
    
    Core exploitation: When cooperation_count >= m, defectors earn 1 + k while
    cooperators earn only k, creating a strict dominance for defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_152(BaseStrategy):
    """
    Adaptive Defection with Conditional Parasitism.
    
    Exploits the asymmetry between cooperators' costs and defectors' benefits.
    Defects by default, but strategically cooperates only when observation reveals
    that the cooperation threshold (m) will be met by others' actions, thus
    parasitizing their contributions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        prev_round_idx = round_number - 1
        prev_cooperators_opponents = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        prev_total_cooperators = prev_cooperators_opponents
        if history.my_actions[prev_round_idx]:
            prev_total_cooperators += 1
        if prev_total_cooperators >= self.m:
            return Action.C
        elif prev_total_cooperators == self.m - 1:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_153(BaseStrategy):
    """
    Adaptive Threshold Defection Strategy for Collective Risk Dilemma.
    
    Exploits the threshold mechanism by defecting strategically:
    - Round 1: Defect to gather information
    - Final round: Defect for unconditional extraction
    - Middle rounds: Defect when cooperation is likely to meet or has met threshold
    - Default: Defect (maximin strategy with safety floor of 1)
    
    Core exploitation channels:
    1. Threshold siphoning: Defect when m-1 or more cooperators observed
    2. Sucker identification: Track round 1 cooperators for repeated exploitation
    3. Trend riding: Defect when cooperation trajectory is increasing
    4. Last-round extraction: Pure defection when no future consequences
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        prev_round_idx = current_round - 1
        cooperators_last_round = int(sum(history.opponent_actions[prev_round_idx, :]))
        if cooperators_last_round >= self.m:
            return Action.D
        if cooperators_last_round == self.m - 1:
            return Action.D
        if cooperators_last_round >= self.m - 2 and cooperators_last_round > 0:
            if self._is_cooperation_rising(history, prev_round_idx):
                return Action.D
        threshold_low = math.floor(self.m / 2.0)
        if cooperators_last_round < threshold_low:
            return Action.D
        return Action.D

    def _is_cooperation_rising(self, history: PlayerHistory, current_round_idx: int) -> bool:
        """
        Determine if cooperation trajectory is increasing.
        
        Compares recent rounds to detect an upward trend.
        Returns True if cooperation appears to be growing.
        """
        if current_round_idx < 1:
            return False
        lookback = min(3, current_round_idx + 1)
        start_idx = max(0, current_round_idx - lookback + 1)
        cooperation_counts = []
        for round_idx in range(start_idx, current_round_idx + 1):
            count = int(sum(history.opponent_actions[round_idx, :]))
            cooperation_counts.append(count)
        if len(cooperation_counts) < 2:
            return False
        mid = len(cooperation_counts) // 2
        if mid == 0:
            mid = 1
        avg_early = np.mean(cooperation_counts[:mid])
        avg_late = np.mean(cooperation_counts[mid:])
        return avg_late > avg_early

class Strategy_EXPLOITATIVE_154(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Defection strategy.
    
    Exploits the threshold mechanism by free-riding on others' cooperation while
    minimizing contribution costs. The strategy treats cooperation as a resource
    generated by others to harvest, not a mutual obligation.
    
    Core mechanisms:
    - Round 1: Always defect to gather information
    - Subsequent rounds: Free-ride when threshold is met, selectively cooperate
      when exactly m-1 cooperators exist (with adaptive probability), otherwise defect
    - Final round: Always defect (no future payoffs to recoup investments)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        last_round_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        rounds_remaining = self.n_rounds - current_round - 1
        if current_round == self.n_rounds - 1:
            return Action.D
        if last_round_cooperators >= self.m:
            return Action.D
        elif last_round_cooperators == self.m - 1:
            if rounds_remaining >= 1:
                cooperation_threshold = 1.0 / (rounds_remaining + 1)
                random_value = random.random()
                if random_value < cooperation_threshold:
                    return Action.C
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_155(BaseStrategy):
    """
    Adaptive Threshold Parasitism: An exploitative strategy that maximizes payoff by
    systematically defecting whenever the threshold is likely to be met, extracting
    maximum value from the asymmetry in the collective risk dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = []
        self.payoff_history = []
        self.last_round_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        cooperation_rate = self._calculate_cooperation_rate(history)
        expected_cooperators = cooperation_rate * (self.game_description.n_players - 1)
        if self._is_defection_spiral(history):
            return Action.C
        if expected_cooperators < self.game_description.m:
            return Action.D
        if expected_cooperators >= self.game_description.m:
            return Action.D
        if expected_cooperators == self.game_description.m - 1:
            if cooperation_rate > 0.85 and self._is_cooperation_stable(history):
                return Action.D
            else:
                return Action.D
        return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        """
        Calculate the empirical cooperation rate from observed opponent actions.
        Uses exponential decay weighting to emphasize recent rounds.
        """
        if history.opponent_actions.shape[0] == 0:
            return 0.5
        n_rounds_elapsed = history.opponent_actions.shape[0]
        total_opponents = self.game_description.n_players - 1
        if total_opponents == 0 or n_rounds_elapsed == 0:
            return 0.5
        total_coop = 0.0
        total_weight = 0.0
        for round_idx in range(n_rounds_elapsed):
            weight = (n_rounds_elapsed - round_idx) ** 0.5
            round_cooperators = np.sum(history.opponent_actions[round_idx, :])
            total_coop += round_cooperators * weight
            total_weight += total_opponents * weight
        if total_weight == 0:
            return 0.5
        cooperation_rate = total_coop / total_weight
        return min(1.0, max(0.0, cooperation_rate))

    def _is_defection_spiral(self, history: PlayerHistory) -> bool:
        """
        Check if we're in a defection spiral: last 3+ rounds with all opponents defecting.
        """
        n_rounds = history.opponent_actions.shape[0]
        if n_rounds < 3:
            return False
        recent_rounds = min(3, n_rounds)
        for round_idx in range(n_rounds - recent_rounds, n_rounds):
            round_cooperators = np.sum(history.opponent_actions[round_idx, :])
            if round_cooperators > 0:
                return False
        cooperation_rate = self._calculate_cooperation_rate(history)
        return cooperation_rate < self.game_description.m / self.game_description.n_players / 2

    def _is_cooperation_stable(self, history: PlayerHistory) -> bool:
        """
        Check if cooperation levels are stable/sticky (low variance).
        """
        if history.opponent_actions.shape[0] < 2:
            return False
        round_coop_counts = np.sum(history.opponent_actions, axis=1)
        total_opponents = self.game_description.n_players - 1
        if total_opponents == 0:
            return False
        round_coop_rates = round_coop_counts / total_opponents
        if len(round_coop_rates) < 2:
            return False
        variance = np.var(round_coop_rates[-min(5, len(round_coop_rates)):])
        return variance < 0.1

class Strategy_EXPLOITATIVE_156(BaseStrategy):
    """
    Adaptive Threshold Exploitation strategy for Collective Risk Dilemma.
    
    Exploits cooperators by defecting while free-riding on their contributions.
    Uses three phases:
    - Discovery (rounds 0 to floor(r/3)): Unconditional defection to establish baseline
    - Exploitation (floor(r/3)+1 to ceil(2r/3)): Adaptive defection based on observed cooperation
    - Endgame (ceil(2r/3)+1 to r): Unconditional defection with no future reputation concerns
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.phase_boundary_1 = math.floor(game_description.n_rounds / 3)
        self.phase_boundary_2 = math.ceil(2 * game_description.n_rounds / 3)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round < self.phase_boundary_1:
            return Action.D
        if current_round < self.phase_boundary_2:
            return self._exploitation_phase(history, current_round)
        return Action.D

    def _exploitation_phase(self, history: PlayerHistory, current_round: int) -> Action:
        """
        Exploitation phase decision logic.
        
        Adapts defection strategy based on observed cooperator frequency:
        - If avg cooperators >= m: defect with certainty
        - If avg cooperators in [m-1.5, m): defect with p=0.85, cooperate with p=0.15
        - If avg cooperators < m-1.5: defect with certainty
        """
        m = self.game_description.m
        cooperator_counts = np.sum(history.opponent_actions[:current_round], axis=1)
        avg_cooperators = np.mean(cooperator_counts) if current_round > 0 else 0.0
        if avg_cooperators >= m:
            return Action.D
        elif avg_cooperators >= m - 1.5:
            if random.random() < 0.15:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_157(BaseStrategy):
    """
    Exploitative Strategy: Conditional Free-Riding with Adaptive Defection
    
    Maximizes individual payoff by identifying cooperation thresholds,
    freeloading aggressively when m-1 or more players cooperate, and
    defecting preemptively when cooperation appears insufficient.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        coop_count_prev = int(sum(history.opponent_actions[current_round - 1, :]))
        if coop_count_prev >= self.m:
            return Action.D
        elif coop_count_prev == self.m - 1:
            trend = self._calculate_trend(history, current_round)
            if trend < 0:
                return Action.D
            else:
                return Action.C
        else:
            return Action.D

    def _calculate_trend(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate cooperation trend over the last 2-3 rounds.
        Returns the change in cooperator count (positive = increasing, negative = decreasing).
        """
        if current_round < 2:
            return 0.0
        window_size = min(3, current_round)
        if window_size == 1:
            return 0.0
        recent_counts = []
        for i in range(current_round - window_size, current_round):
            if i >= 0:
                coop_count = int(sum(history.opponent_actions[i, :]))
                recent_counts.append(coop_count)
        if len(recent_counts) < 2:
            return 0.0
        trend = recent_counts[-1] - recent_counts[0]
        return float(trend)

class Strategy_EXPLOITATIVE_158(BaseStrategy):
    """
    Adaptive Threshold Infiltration: An exploitative strategy that identifies rigid cooperators,
    free-rides on their contributions, and defects strategically to maximize payoff while
    maintaining just enough cooperation to sustain the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.discovery_length = min(math.ceil(math.log2(self.n_players)), self.n_rounds - 2)
        self.discovery_length = max(1, self.discovery_length)
        self.rigid_cooperators = set()
        self.reciprocators = set()
        self.defectors = set()
        self.cooperation_rates = {}
        self.recent_cooperation = {}
        self.our_defection_count = 0
        self.threshold_failure_count = 0
        self.collective_cooperation_trend = []
        self.our_defection_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        self._update_player_classification(history, round_num)
        if round_num < self.discovery_length:
            return self._discovery_phase(history, round_num)
        elif round_num < self.n_rounds - 2:
            return self._exploitation_phase(history, round_num)
        else:
            return self._endgame_phase(history, round_num)

    def _update_player_classification(self, history: PlayerHistory, round_num: int) -> None:
        """Update classification of opponents based on observed behavior."""
        for opp_idx in range(self.n_players - 1):
            coop_count = int(np.sum(history.opponent_actions[:round_num, opp_idx]))
            coop_rate = coop_count / round_num if round_num > 0 else 0
            self.cooperation_rates[opp_idx] = coop_rate
            recent_rounds = min(3, round_num)
            if recent_rounds > 0:
                recent_coop = int(np.sum(history.opponent_actions[round_num - recent_rounds:round_num, opp_idx]))
                self.recent_cooperation[opp_idx] = recent_coop / recent_rounds
            else:
                self.recent_cooperation[opp_idx] = 0
            if round_num >= 1:
                if history.opponent_actions[0, opp_idx] and coop_rate > 0.7:
                    self.rigid_cooperators.add(opp_idx)
                elif 0.3 <= coop_rate <= 0.7:
                    self.reciprocators.add(opp_idx)
                elif coop_rate < 0.3:
                    self.defectors.add(opp_idx)

    def _discovery_phase(self, history: PlayerHistory, round_num: int) -> Action:
        """Discovery phase: identify player types."""
        prev_cooperators = int(np.sum(history.opponent_actions[round_num - 1, :]))
        if round_num == 1:
            return Action.D
        if prev_cooperators >= self.m:
            return Action.D
        elif prev_cooperators == self.m - 1:
            return Action.C
        else:
            return Action.D

    def _exploitation_phase(self, history: PlayerHistory, round_num: int) -> Action:
        """Exploitation phase: free-ride on cooperators."""
        estimate_min_cooperators = len(self.rigid_cooperators)
        count_reciprocators = len(self.reciprocators)
        prev_cooperators = int(np.sum(history.opponent_actions[round_num - 1, :]))
        our_defection_rate = int(np.sum(~history.my_actions[:round_num])) / round_num if round_num > 0 else 0
        if self.m > 3 * self.n_players / 4:
            if our_defection_rate > 0.7:
                return Action.D
            else:
                return Action.C if prev_cooperators >= self.m else Action.D
        if self.m <= 2:
            return Action.D
        if estimate_min_cooperators >= self.m:
            return Action.D
        if estimate_min_cooperators + count_reciprocators >= self.m:
            if our_defection_rate > 0.7:
                return Action.D
            else:
                return Action.C if prev_cooperators < self.m else Action.D
        if estimate_min_cooperators + self.m - 1 <= prev_cooperators:
            return Action.D
        if prev_cooperators < self.m / 2:
            return Action.D
        return Action.C

    def _endgame_phase(self, history: PlayerHistory, round_num: int) -> Action:
        """Endgame phase: extract final value."""
        if round_num == self.n_rounds - 2:
            prev_cooperators = int(np.sum(history.opponent_actions[round_num - 1, :]))
            if prev_cooperators >= self.m or len(self.rigid_cooperators) >= self.m:
                return Action.D
            else:
                return Action.C
        if round_num == self.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_159(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Defection (Exploitative Strategy)
    
    Exploits the threshold structure by identifying when others reach m cooperators,
    then defecting to capture the k reward without paying the cost. Employs selective
    cooperation to bait conditional cooperators, then exploits them in later rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.opponent_types = {}

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.n_rounds - 1:
            return Action.D
        rounds_remaining = self.n_rounds - round_num - 1
        cooperators_prev = int(np.sum(history.opponent_actions[round_num - 1, :]))
        self._classify_opponents(history, round_num)
        if cooperators_prev >= self.m - 1 and cooperators_prev < self.m:
            if self.m <= self.n_players / 2 and rounds_remaining >= 3:
                return Action.D
        if cooperators_prev == self.m and rounds_remaining > 2:
            return Action.D
        if cooperators_prev < self.m - 1 and rounds_remaining >= 3:
            return Action.D
        if self._is_conditional_cooperator(history, round_num):
            if history.opponent_actions[round_num - 1, self._get_primary_opponent()] and rounds_remaining >= 2:
                return Action.C
        if rounds_remaining == 2 and cooperators_prev >= self.m:
            return Action.D
        return Action.D

    def _classify_opponents(self, history: PlayerHistory, round_num: int) -> None:
        """Classify opponent types to identify exploitable patterns."""
        if round_num < 2:
            return
        for opp_idx in range(self.n_players - 1):
            if opp_idx not in self.opponent_types:
                opp_history = history.opponent_actions[:round_num, opp_idx]
                if np.all(opp_history):
                    self.opponent_types[opp_idx] = 'always_cooperate'
                elif np.all(~opp_history):
                    self.opponent_types[opp_idx] = 'all_defect'
                else:
                    self.opponent_types[opp_idx] = 'conditional'

    def _is_conditional_cooperator(self, history: PlayerHistory, round_num: int) -> bool:
        """Detect if there exists at least one conditional cooperator we can exploit."""
        if round_num < 2:
            return False
        for opp_idx in range(self.n_players - 1):
            opp_type = self.opponent_types.get(opp_idx, 'unknown')
            if opp_type == 'conditional' or opp_type == 'unknown':
                recent_coop = int(np.sum(history.opponent_actions[max(0, round_num - 2):round_num, opp_idx]))
                if recent_coop > 0:
                    return True
        return False

    def _get_primary_opponent(self) -> int:
        """Get index of primary opponent for tracking (first opponent)."""
        return 0

class Strategy_EXPLOITATIVE_160(BaseStrategy):
    """
    Adaptive Free-Riding with Threshold Exploitation Strategy.
    
    This exploitative strategy maximizes personal payoff by defecting when possible
    while parasitizing others' cooperation. It defects in round 1 and the final round,
    and in intermediate rounds it uses threshold parasitism: defects when threshold is met,
    cooperates only when exactly m-1 cooperators exist (to trigger future exploitation),
    and defects otherwise.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[state.round_number - 1, :]))
        if cooperators_last_round >= self.m:
            return Action.D
        elif cooperators_last_round == self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_161(BaseStrategy):
    """
    Adaptive Threshold Hunting: Exploitative strategy that learns opponent cooperation rates
    and free-rides when threshold is likely met, while minimizing losses otherwise.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.p_coop = 0.5
        self.round_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        if current_round == 0:
            self.round_count = 0
            return Action.D
        if current_round == r - 1:
            self._update_p_coop(history, current_round)
            return Action.D
        self._update_p_coop(history, current_round)
        expected_cooperators = (n - 1) * self.p_coop
        variance = self.p_coop * (1.0 - self.p_coop)
        buffer = 2.0 * math.sqrt(variance / max(current_round, 1))
        if expected_cooperators >= m + buffer:
            return Action.D
        elif expected_cooperators < m - buffer:
            return Action.D
        else:
            payoff_defect = self._calc_payoff_defect(expected_cooperators, m, k, n)
            payoff_coop = self._calc_payoff_coop(expected_cooperators, m, k, n)
            if payoff_defect >= payoff_coop:
                return Action.D
            else:
                return Action.C

    def _update_p_coop(self, history: PlayerHistory, current_round: int) -> None:
        """Update cooperation probability estimate based on observed history."""
        if current_round == 0:
            return
        total_cooperators = int(np.sum(history.opponent_actions[:current_round, :]))
        total_observations = current_round * (self.game_description.n_players - 1)
        if total_observations > 0:
            observed_rate = total_cooperators / total_observations
            alpha = 1.0 / (current_round + 1)
            self.p_coop = alpha * observed_rate + (1.0 - alpha) * self.p_coop

    def _calc_payoff_defect(self, expected_cooperators: float, m: int, k: float, n: int) -> float:
        """
        Calculate expected payoff if I defect.
        Payoff = 1 + k * P(threshold met by others without me)
        """
        prob_threshold = self._prob_threshold_met(expected_cooperators, m)
        return 1.0 + k * prob_threshold

    def _calc_payoff_coop(self, expected_cooperators: float, m: int, k: float, n: int) -> float:
        """
        Calculate expected payoff if I cooperate.
        Payoff = 0 + k * P(threshold met with my cooperation)
        """
        prob_threshold = self._prob_threshold_met(expected_cooperators, m - 1)
        return 0.0 + k * prob_threshold

    def _prob_threshold_met(self, expected_cooperators: float, threshold: int) -> float:
        """
        Approximate probability that threshold is met given expected cooperators.
        Uses binomial approximation: if p_coop is the cooperation rate,
        then number of cooperators ~ Binomial(n-1, p_coop).
        """
        n_others = self.game_description.n_players - 1
        if threshold <= 0:
            return 1.0
        if threshold > n_others:
            return 0.0
        mean = expected_cooperators
        variance = self.p_coop * (1.0 - self.p_coop) * n_others
        std_dev = math.sqrt(max(variance, 1e-09))
        if std_dev < 1e-09:
            return 1.0 if mean >= threshold else 0.0
        z_score = (threshold - mean) / std_dev
        prob = 0.5 * (1.0 - math.erf(z_score / math.sqrt(2.0)))
        return max(0.0, min(1.0, prob))

class Strategy_EXPLOITATIVE_162(BaseStrategy):
    """
    Adaptive Threshold Defection: An exploitative strategy that always defects
    to maximize payoff by free-riding on others' cooperation while avoiding costs.
    
    Core principle: Defection is weakly dominant when m < n. By never contributing,
    we guarantee a baseline payoff of 1 per round, and if others meet the threshold,
    we gain the additional reward k without bearing the cost of cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_count = 0
        self.threshold_met_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if history is not None:
            previous_round = state.round_number - 1
            if previous_round >= 0:
                cooperators_previous = np.sum(history.opponent_actions[:previous_round + 1, :])
                total_opponent_actions = (previous_round + 1) * self.game_description.n_players
                if total_opponent_actions > 0:
                    self.cooperation_count = cooperators_previous
                if previous_round >= 0:
                    cooperators_last_round = np.sum(history.opponent_actions[previous_round, :])
                    my_action_last = history.my_actions[previous_round]
                    total_cooperators_last_round = cooperators_last_round + (1 if my_action_last else 0)
                    if total_cooperators_last_round >= self.game_description.m:
                        self.threshold_met_count += 1
        return Action.D

class Strategy_EXPLOITATIVE_163(BaseStrategy):
    """
    Adaptive Threshold Farming: An exploitative strategy that systematically defects
    while monitoring cooperation rates to maximize free-riding payoffs.
    
    Core insight: Defectors earn 1 + k when threshold is met (vs. k for cooperators),
    creating a structural payoff advantage. This strategy exploits that asymmetry
    by never cooperating while adapting defection based on observed cooperation patterns.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        prev_round_idx = round_number - 1
        prev_round_opponent_actions = history.opponent_actions[prev_round_idx, :]
        coop_count = int(np.sum(prev_round_opponent_actions))
        total_coop_count = coop_count + int(history.my_actions[prev_round_idx])
        if total_coop_count >= self.m:
            return Action.D
        elif total_coop_count >= self.m - 1:
            return Action.D
        else:
            coop_rate = coop_count / self.n_players if self.n_players > 0 else 0.0
            if coop_rate >= 0.5:
                return Action.D
            else:
                return Action.D

class Strategy_EXPLOITATIVE_164(BaseStrategy):
    """
    Adaptive Free-Rider with Threshold Sensing strategy.
    
    Exploits the asymmetry in payoffs by:
    1. Cooperating in round 1 to establish a false cooperative reputation
    2. Defecting when threshold is met to free-ride on others' cooperation
    3. Using probabilistic cooperation near the threshold to create uncertainty
    4. Always defecting in the final round
    5. Abandoning signaling if opponents appear to be unconditional defectors
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.n_rounds - 1:
            return Action.D
        last_round_cooperators = int(sum(history.opponent_actions[round_number - 1, :]))
        if round_number == 1:
            round_0_cooperators = int(sum(history.opponent_actions[0, :]))
            if round_0_cooperators == 0:
                return Action.D
        if self.m == self.n_players:
            if last_round_cooperators >= self.n_players - 1:
                return Action.D
            return Action.D
        if self.m == 2:
            if last_round_cooperators == self.n_players - 1:
                if random.random() < 0.2:
                    return Action.C
            return Action.D
        if last_round_cooperators >= self.m:
            return Action.D
        elif last_round_cooperators == self.m - 1:
            if random.random() < 0.3:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_165(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Threshold strategy.
    
    Exploits the threshold mechanism by strategically defecting when cooperation
    is likely anyway, while maintaining just enough cooperative credibility to
    avoid total defection cascades.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold_rounds = math.ceil(self.r / 3)
        self.cooperation_tipping_point = self.m / self.n + 0.15
        self.was_marginal_cooperator_last_round = False
        self.other_exploited_me_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[current_round - 1, :]))
        was_marginal = self.was_marginal_cooperator_last_round and cooperators_last_round == self.m - 1
        if was_marginal and self.other_exploited_me_count > 0:
            self.other_exploited_me_count -= 1
            self.was_marginal_cooperator_last_round = False
            return Action.D
        if cooperators_last_round >= self.m:
            self.was_marginal_cooperator_last_round = False
            return Action.D
        if cooperators_last_round == self.m - 1:
            self.was_marginal_cooperator_last_round = True
            return Action.C
        if cooperators_last_round < self.m - 1:
            rounds_remaining = self.r - current_round
            lookback_start = max(0, current_round - 3)
            lookback_end = current_round
            recent_actions = history.opponent_actions[lookback_start:lookback_end, :]
            if recent_actions.size > 0:
                avg_cooperation = np.mean(recent_actions)
            else:
                avg_cooperation = 0.0
            if current_round >= self.r - 3:
                self.was_marginal_cooperator_last_round = False
                return Action.D
            if rounds_remaining > self.threshold_rounds and avg_cooperation > self.cooperation_tipping_point:
                self.was_marginal_cooperator_last_round = False
                return Action.C
            self.was_marginal_cooperator_last_round = False
            return Action.D
        self.was_marginal_cooperator_last_round = False
        return Action.D

class Strategy_EXPLOITATIVE_166(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD) Strategy for Collective Risk Dilemma.
    
    A rational, exploitative strategy that:
    1. Defects in round 0 to gather information
    2. In middle rounds, cooperates only when pivotal (our cooperation is necessary to meet threshold)
    3. Defects in final round to maximize exploitation
    
    This maximizes free-riding on others' cooperation while avoiding collective failure.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[current_round - 1, :]))
        threshold_without_us = cooperators_last_round
        threshold_with_us = cooperators_last_round + 1
        if threshold_without_us >= self.m:
            return Action.D
        elif threshold_with_us == self.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_167(BaseStrategy):
    """
    Adaptive Freerider strategy for Collective Risk Dilemma.
    
    Exploits the threshold mechanism by:
    1. Defecting in round 1 (no information)
    2. Free-riding when threshold is already met
    3. Defecting when cooperation won't help
    4. Only cooperating when forced to be the tiebreaker (and only in last round with desperation)
    5. Using adaptive estimation of opponent cooperation to predict future rounds
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.historical_cooperators = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[-1, :]))
        self.historical_cooperators.append(cooperators_last_round)
        rounds_remaining = self.n_rounds - current_round
        if cooperators_last_round >= self.m:
            return Action.D
        if cooperators_last_round < self.m - 1:
            return Action.D
        if cooperators_last_round == self.m - 1:
            if rounds_remaining == 0:
                expected_cooperators = self._estimate_next_round_cooperators()
                if expected_cooperators < self.m - 1:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D
        return Action.D

    def _estimate_next_round_cooperators(self) -> float:
        """
        Estimate expected cooperators in next round using adaptive estimation.
        Uses decay factor of 0.9 on recent observations plus historical average.
        """
        if not self.historical_cooperators:
            return (self.n_players - 1) * 0.5
        last_round_cooperators = self.historical_cooperators[-1]
        avg_cooperators = np.mean(self.historical_cooperators)
        historical_rate = avg_cooperators / (self.n_players - 1) if self.n_players > 1 else 0
        expected = 0.9 * last_round_cooperators + 0.1 * (historical_rate * (self.n_players - 1))
        return expected

class Strategy_EXPLOITATIVE_168(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Free-Riding with Conditional Defection
    
    Exploits the threshold structure by minimizing personal contribution while
    maximizing benefit extraction. Free-rides on others' cooperation whenever
    possible, cooperates strategically only in early game when one cooperator
    is needed to build false trust, and defects in final round regardless.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[round_num - 1, :]))
        if round_num == self.n_rounds - 1:
            return Action.D
        if cooperators_last_round >= self.m:
            return Action.D
        if cooperators_last_round == self.m - 1:
            early_game_threshold = math.ceil(self.n_rounds * 0.3)
            if round_num <= early_game_threshold:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_169(BaseStrategy):
    """
    Conditional Free-Rider with Adaptive Thresholding.
    
    Exploits the threshold mechanism by defecting when cooperation is likely to reach m,
    cooperating only when necessary to push cooperation toward the threshold, and always
    defecting in the final round. Tracks cooperation rates and trends to adapt decisions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.n_rounds - 1:
            return Action.D
        total_cooperators = 0
        rounds_elapsed = round_num
        for t in range(rounds_elapsed):
            cooperators_in_round = np.sum(history.opponent_actions[t, :])
            total_cooperators += cooperators_in_round
        if rounds_elapsed > 0:
            coop_rate = total_cooperators / (self.n_players * rounds_elapsed)
        else:
            coop_rate = 0.0
        expected_coop = coop_rate * (self.n_players - 1)
        downward_trend = False
        if round_num >= 3:
            recent_coop_counts = []
            for t in range(max(0, round_num - 3), round_num):
                recent_coop_counts.append(np.sum(history.opponent_actions[t, :]))
            if len(recent_coop_counts) >= 2:
                is_declining = True
                for i in range(len(recent_coop_counts) - 1):
                    if recent_coop_counts[i + 1] >= recent_coop_counts[i]:
                        is_declining = False
                        break
                downward_trend = is_declining
        if expected_coop >= self.m:
            return Action.D
        if expected_coop >= self.m - 2 and expected_coop < self.m:
            remaining_rounds = self.n_rounds - round_num
            if remaining_rounds >= 2:
                return Action.C
        if coop_rate < 0.01:
            return Action.D
        if downward_trend:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_170(BaseStrategy):
    """
    Adaptive Threshold Exploitation strategy for Collective Risk Dilemma.
    
    Exploits the asymmetry where defection is rational when the threshold is likely
    to be met. Dynamically estimates opponent cooperation rates and switches between
    exploitation (defect) and conditional participation (cooperate) modes.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold_buffer = 0.15
        self.cooperation_history = []

    def _estimate_binomial_cdf(self, successes: int, trials: int, prob: float) -> float:
        """
        Estimate P(X < successes) where X ~ Binomial(trials, prob).
        Returns the probability that fewer than 'successes' occur.
        """
        if prob <= 0:
            return 1.0
        if prob >= 1.0:
            return 0.0
        cumulative = 0.0
        for k in range(successes):
            binom_coeff = 1.0
            for i in range(1, k + 1):
                binom_coeff *= (trials - i + 1) / i
            term = binom_coeff * prob ** k * (1 - prob) ** (trials - k)
            cumulative += term
        return cumulative

    def _get_cooperation_rate(self, history: PlayerHistory, round_number: int) -> float:
        """
        Calculate the observed cooperation rate from opponents in previous rounds.
        
        cooperation_rate = (total cooperators in previous rounds) / (n-1) Ã— (round_number)
        """
        if round_number == 0:
            return 0.0
        n_opponents = self.game_description.n_players - 1
        total_cooperation = 0
        for round_idx in range(round_number):
            total_cooperation += np.sum(history.opponent_actions[round_idx, :])
        max_possible = n_opponents * round_number
        if max_possible == 0:
            return 0.0
        return total_cooperation / max_possible

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if round_number == 0:
            return Action.D
        if round_number == r - 1:
            return Action.D
        cooperation_rate = self._get_cooperation_rate(history, round_number)
        threshold_rate = m / (n - 1) - self.threshold_buffer
        threshold_prob = 1.0 - self._estimate_binomial_cdf(m, n - 1, cooperation_rate)
        if cooperation_rate >= threshold_rate:
            return Action.D
        elif round_number <= 3 and cooperation_rate < 0.1:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_171(BaseStrategy):
    """
    Adaptive Defection with Calculated Cooperation (ADCC):
    An exploitative strategy that systematically free-rides when cooperation
    thresholds are met, while strategically cooperating only in tight endgames
    to minimize mutual defection damage.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        rounds_remaining = self.r - current_round - 1
        if rounds_remaining < 1:
            return Action.D
        prev_round_idx = current_round - 1
        coop_count = int(sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            coop_count += 1
        critical_threshold = self.m / max(1, self.n - 1)
        recent_coop_rate = coop_count / max(1, self.n)
        if coop_count >= self.m:
            return Action.D
        if coop_count == 0:
            return Action.D
        gap_to_threshold = self.m - coop_count
        if gap_to_threshold <= 1:
            return Action.D
        if rounds_remaining <= 3 and coop_count > self.n / 3:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_172(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Threshold Strategy.
    
    Exploits the asymmetry where defectors gain private payoff (1) plus collective 
    reward (k) if threshold is met, while cooperators only get the reward.
    
    Core logic:
    - Round 0 (first round): DEFECT (gather information)
    - Rounds 1 to r-2 (middle rounds): COOPERATE if previous round had >= m-1 cooperators
      (free-ride their threshold), otherwise DEFECT
    - Round r-1 (final round): DEFECT unconditionally (terminal round exploitation)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        previous_round_index = round_number - 1
        cooperators_last_round = int(sum(history.opponent_actions[previous_round_index, :]))
        if cooperators_last_round >= self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_173(BaseStrategy):
    """
    Adaptive Threshold Defection: An exploitative strategy that free-rides when the
    cooperation threshold is met, cooperates only when marginally needed to reach the
    threshold, and defects otherwise.
    
    Core logic:
    - Round 1: Defect to establish baseline and observe opponent behavior
    - Mid-game: Free-ride when cooperation_count >= m, cooperate when cooperation_count == m-1,
      defect when cooperation_count < m-1
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[-1, :]))
        if cooperators_last_round >= self.m:
            return Action.D
        elif cooperators_last_round == self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_174(BaseStrategy):
    """
    Adaptive Threshold Predation (ATP): Exploitative strategy that preys on
    coordination problems in collective risk dilemmas by appearing conditional
    while pursuing defection with strategic cooperation bursts.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        recent_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        total_rounds_observed = current_round
        total_cooperations = int(np.sum(history.opponent_actions[:current_round, :]))
        max_possible_cooperations = self.n_players * total_rounds_observed
        cooperation_rate = total_cooperations / max_possible_cooperations if max_possible_cooperations > 0 else 0.0
        rounds_remaining = self.n_rounds - current_round
        if self.m == self.n_players:
            return Action.D
        if recent_cooperators >= self.m:
            return Action.D
        elif recent_cooperators == self.m - 1:
            if rounds_remaining > 2 and cooperation_rate < 0.4:
                return Action.D
            else:
                return Action.C
        elif cooperation_rate >= 0.5:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_175(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Free-Riding with Conditional Participation
    
    Core philosophy: Maximize personal payoff by exploiting the threshold mechanism.
    The strategy defects in all rounds, relying on others to meet the cooperation
    threshold while capturing the surplus (1 + k payoff vs k for cooperators).
    
    This is a pure defection strategy with no exceptions across all rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_176(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD) Strategy
    
    An exploitative strategy that maximizes personal payoff by leveraging the threshold
    structure of the Collective Risk Dilemma. It uses observed cooperation patterns to
    infer opponent tendencies and positions itself optimally:
    - Defects when cooperation is likely from others (free-ride)
    - Defects when cooperation is unlikely (threshold unreachable)
    - Cooperates strategically only when positioned as swing vote in mid-game
    - Always defects in final round (subgame perfection)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        expected_cooperators = self._calculate_expected_cooperators(history, round_num)
        if round_num == self.n_rounds - 1:
            return Action.D
        if round_num == self.n_rounds - 2:
            if expected_cooperators >= self.m:
                return Action.D
            else:
                my_cumulative = float(np.sum(history.my_payoffs))
                acceptable_baseline = self.n_rounds * 1.5
                if my_cumulative >= acceptable_baseline:
                    return Action.D
                else:
                    return Action.C if self.k > 1 else Action.D
        if expected_cooperators >= self.m:
            return Action.D
        elif expected_cooperators == self.m - 1:
            if self.k - 1 > 0.5:
                if round_num <= self.n_rounds / 2:
                    return Action.D
                else:
                    return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _calculate_expected_cooperators(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate expected number of cooperators in next round based on historical data.
        
        Uses average cooperation rate from all observed rounds to project future behavior.
        """
        if round_num == 0:
            return 0.0
        opponent_actions = history.opponent_actions[:round_num, :]
        if opponent_actions.size == 0:
            return 0.0
        total_coop_instances = float(np.sum(opponent_actions))
        total_possible = float(opponent_actions.shape[0] * opponent_actions.shape[1])
        if total_possible == 0:
            return 0.0
        avg_coop_rate = total_coop_instances / total_possible
        expected_cooperators = avg_coop_rate * (self.n_players - 1)
        return expected_cooperators

class Strategy_EXPLOITATIVE_177(BaseStrategy):
    """
    Adaptive Threshold Parasitism: An exploitative strategy that free-rides on others' cooperation
    by always defecting, leveraging the threshold mechanism to capture rewards without contributing.
    
    Core logic:
    - Round 1: Defect to gather information on opponent types
    - Rounds 2 to r-1: Always defect, exploiting the threshold mechanism
    - Last round: Defect (terminal round unraveling)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        coop_count_prev = int(sum(history.opponent_actions[state.round_number - 1, :]))
        return Action.D

class Strategy_EXPLOITATIVE_178(BaseStrategy):
    """
    Threshold Predator: An exploitative strategy that free-rides on others' cooperation
    while strategically defecting to maximize extraction of the threshold reward (k).
    
    Core mechanics:
    - Defect by default to establish baseline exploitation
    - Cooperate rarely and strategically to maintain threshold or force others to cooperate
    - Always defect in final round (end-game unraveling)
    - Use declining probabilities to adapt to cooperation scarcity over time
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if self.m == self.n:
            return Action.C
        prev_round_idx = current_round - 1
        opponent_cooperation_count = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        if opponent_cooperation_count >= self.m:
            return Action.D
        elif opponent_cooperation_count == self.m - 1:
            denominator = max(1, self.n - self.m)
            p_inject = min(0.7, 1.0 / denominator)
            return Action.C if random.random() < p_inject else Action.D
        else:
            if current_round == self.r - 1:
                return Action.D
            denominator = max(1, self.n * (current_round + 1))
            p_force = max(0.1, self.m / denominator)
            return Action.C if random.random() < p_force else Action.D

class Strategy_EXPLOITATIVE_179(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD): An exploitative strategy that systematically
    defects to free-ride on cooperators' investments when the cooperation threshold
    is likely to be met, and defects to preserve endowment when threshold is unlikely.
    
    Core principle: Never voluntarily bear cooperation cost; extract maximum reward
    by predicting others' behavior and exploiting it.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        total_other_cooperations = 0
        total_other_decisions = current_round * (self.n - 1)
        for round_idx in range(current_round):
            round_cooperators = np.sum(history.opponent_actions[round_idx, :])
            total_other_cooperations += round_cooperators
        if total_other_decisions == 0:
            cooperation_rate = 0.0
        else:
            cooperation_rate = total_other_cooperations / total_other_decisions
        expected_cooperators_next = math.ceil(cooperation_rate * (self.n - 1))
        if expected_cooperators_next >= self.m:
            return Action.D
        elif expected_cooperators_next < self.m - 1:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_180(BaseStrategy):
    """
    Adaptive Parasitism: Exploits the threshold mechanism by free-riding on others' cooperation.
    Systematically defects when the threshold is likely met by others, or when cooperation is unlikely to succeed.
    Uses adaptive layer to detect cooperation environment and adjust stochastic mixing accordingly.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[-1, :]))
        recent_rounds = min(3, state.round_number)
        recent_cooperation_count = sum((sum(history.opponent_actions[r, :]) for r in range(max(0, state.round_number - recent_rounds), state.round_number)))
        recent_cooperation_rate = recent_cooperation_count / (recent_rounds * self.game_description.n_players) if recent_rounds > 0 else 0.0
        m = self.game_description.m
        n = self.game_description.n_players
        threshold_rate = m / n
        high_coop_threshold = threshold_rate * 1.3
        low_coop_threshold = threshold_rate * 0.7
        if recent_cooperation_rate > high_coop_threshold:
            return self._primary_strategy(cooperators_last_round, m)
        elif recent_cooperation_rate < low_coop_threshold:
            return Action.D
        elif cooperators_last_round >= m:
            return Action.D
        else:
            if random.random() < 0.1:
                return Action.C
            return Action.D

    def _primary_strategy(self, cooperators_last_round: int, m: int) -> Action:
        """
        Primary threshold exploitation strategy.
        """
        if cooperators_last_round >= m:
            return Action.D
        if cooperators_last_round == m - 1:
            return Action.D
        if cooperators_last_round >= math.ceil(m * 0.6):
            if random.random() < 0.2:
                return Action.C
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_181(BaseStrategy):
    """
    Adaptive Threshold Exploit Strategy for Collective Risk Dilemma.
    
    Maximizes personal payoff by systematically exploiting the threshold mechanism.
    Defects when free-riding is possible, cooperates only at the margin (when estimated
    cooperators == m-1) to secure the threshold, and exploits aggressively in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            estimated_cooperators = round(self.n_players * 0.5)
            return self._decide_action(estimated_cooperators, current_round)
        estimated_cooperators = self._estimate_cooperators(history)
        return self._decide_action(estimated_cooperators, current_round)

    def _estimate_cooperators(self, history: PlayerHistory) -> int:
        """
        Estimate the number of cooperators in the next round based on observed history.
        
        Uses cumulative cooperation rate across all observed opponent actions.
        """
        if history.opponent_actions.size == 0:
            return round(self.n_players * 0.5)
        total_cooperations = np.sum(history.opponent_actions)
        total_obs_rounds = history.opponent_actions.shape[0] * history.opponent_actions.shape[1]
        if total_obs_rounds == 0:
            return round(self.n_players * 0.5)
        cooperation_rate = total_cooperations / total_obs_rounds
        estimated_cooperators = round(self.n_players * cooperation_rate)
        return estimated_cooperators

    def _decide_action(self, estimated_cooperators: int, current_round: int) -> Action:
        """
        Apply the primary decision logic based on estimated cooperators.
        
        Strategy:
        - If estimated cooperators >= m: DEFECT (free-ride)
        - Else if estimated cooperators == m-1: COOPERATE (threshold tipping)
        - Else: DEFECT (threshold unattainable)
        
        Terminal round (r-1) applies same logic but with no future punishment consideration.
        """
        if estimated_cooperators >= self.m:
            return Action.D
        elif estimated_cooperators == self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_182(BaseStrategy):
    """
    Exploitative strategy: Conditional Free-Riding with Adaptive Thresholds.
    
    Minimizes personal contribution while maximizing returns from others' cooperation.
    Defects strategically based on cooperation probability estimates and threshold analysis.
    Always defects in first and final rounds; uses adaptive logic in middle rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        return self._decide_middle_round(current_round, history)

    def _decide_middle_round(self, current_round: int, history: PlayerHistory) -> Action:
        """
        Decide action for middle rounds using Cooperation Probability Estimate (CPE).
        """
        rounds_elapsed = current_round
        total_coop_actions = int(np.sum(history.opponent_actions[:current_round, :]))
        total_coop_actions += int(np.sum(history.my_actions[:current_round]))
        total_possible = rounds_elapsed * self.n
        if total_possible == 0:
            cpe = 0.0
        else:
            cpe = total_coop_actions / total_possible
        epsilon = 0.05
        if self.r < 10:
            epsilon = epsilon - 0.01
        elif self.r > 20:
            epsilon = epsilon + 0.05
        base_threshold = (self.m - 1) / self.n if self.n > 0 else 0.0
        threshold_dynamic = base_threshold + epsilon
        if cpe >= threshold_dynamic:
            return Action.D
        if cpe < threshold_dynamic and cpe >= base_threshold:
            return Action.D
        if cpe < base_threshold:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_183(BaseStrategy):
    """
    Exploitative Free-Riding with Conditional Participation Strategy
    
    Exploits the threshold mechanism by free-riding on others' cooperation whenever possible.
    - Round 1: Always defect to establish non-naivetÃ© and gather information
    - Rounds 2 to r-1: Defect if threshold is met or far from met; probabilistically defect (80%) 
      if exactly one cooperator short
    - Final round: Always defect (no future rounds, no reputation concerns)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[state.round_number - 1, :]))
        m = self.game_description.m
        if cooperators_last_round >= m:
            return Action.D
        if cooperators_last_round == m - 1:
            if random.random() < 0.8:
                return Action.D
            else:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_184(BaseStrategy):
    """
    Adaptive Threshold Exploitation (ATE) Strategy
    
    Exploits asymmetries in the payoff structure by:
    1. Defecting initially to probe the population
    2. Adaptively exploiting cooperators when threshold is met
    3. Conditionally cooperating only when necessary to reach threshold
    4. Defecting in the final round to maximize extraction
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[current_round - 1, :]))
        cooperation_rate = cooperators_last_round / self.n_players
        threshold_rate = self.m / self.n_players
        near_threshold_rate = (self.m - 1) / self.n_players
        if cooperation_rate >= threshold_rate:
            return Action.D
        elif cooperation_rate >= near_threshold_rate:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_185(BaseStrategy):
    """
    Conditional Free-Rider Strategy for Collective Risk Dilemma.
    
    Exploits the threshold mechanism by free-riding on others' cooperation.
    Cooperates only when pivotal (swing vote), defects in final round, and uses
    exponential smoothing to estimate future cooperators.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = []
        self.estimated_coop_next_round = game_description.n_players / 2.0
        self.decay_factor = 0.3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        m = self.game_description.m
        current_round = state.round_number
        if current_round == r - 1:
            return Action.D
        if current_round == 0:
            if n <= 3:
                return Action.D
            if random.random() < 0.6:
                return Action.D
            return Action.C
        observed_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        self.cooperation_history.append(observed_cooperators)
        if current_round <= 3:
            coop_rate = np.sum(self.cooperation_history) / (current_round * n)
        else:
            recent_rounds = min(3, len(self.cooperation_history))
            recent_mean = np.mean(self.cooperation_history[-recent_rounds:]) / n
            coop_rate = (1 - self.decay_factor) * recent_mean + self.decay_factor * (self.estimated_coop_next_round / n)
        estimated_coop_next = max(0, min(n - 1, round(coop_rate * (n - 1))))
        self.estimated_coop_next_round = estimated_coop_next
        if estimated_coop_next >= m:
            return Action.D
        if estimated_coop_next == m - 1:
            return Action.C
        if estimated_coop_next < m - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_186(BaseStrategy):
    """
    Adaptive Threshold Predation: An exploitative strategy that free-rides on 
    cooperation when the threshold is reliably met, defects in final rounds, 
    and adapts probabilistically when cooperation is at risk.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold_buffer = 0.15
        self.tolerance = 0.05

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        recent_coop_rate = self._compute_recent_cooperation_rate(history, state.round_number)
        threshold_rate = self.game_description.m / self.game_description.n_players
        if recent_coop_rate >= threshold_rate + self.threshold_buffer:
            return Action.D
        elif recent_coop_rate >= threshold_rate - self.tolerance:
            p_cooperate = threshold_rate - recent_coop_rate
            if random.random() < p_cooperate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _compute_recent_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Compute the cooperation rate from the last 2 rounds (smoothed observation window).
        Handles edge cases where fewer than 2 rounds are available.
        """
        start_round = max(0, current_round - 2)
        end_round = current_round
        if start_round >= end_round:
            return 0.0
        total_cooperators = 0
        num_rounds_examined = end_round - start_round
        for round_idx in range(start_round, end_round):
            cooperators_in_round = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += cooperators_in_round
        total_possible = num_rounds_examined * self.game_description.n_players
        if total_possible == 0:
            return 0.0
        recent_coop_rate = total_cooperators / total_possible
        return recent_coop_rate

class Strategy_EXPLOITATIVE_187(BaseStrategy):
    """
    Exploitative Strategy: Conditional Free-Riding with Adaptive Thresholds
    
    Exploits the coordination problem by free-riding when others cooperate
    (threshold met), while conditionally cooperating to attempt threshold
    achievement for future exploitation. Defects unconditionally in round 1
    and final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        previous_round_actions = history.opponent_actions[current_round - 1, :]
        cooperators_last_round = int(np.sum(previous_round_actions))
        if history.my_actions[current_round - 1]:
            cooperators_last_round += 1
        if cooperators_last_round >= m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_188(BaseStrategy):
    """
    Exploitative Strategy: Conditional Free-Riding with Adaptive Threshold
    
    Exploits the coordination problem in threshold public goods games by:
    1. Free-riding when others provide the public good
    2. Defecting preemptively when cooperation appears insufficient
    3. Selectively punishing defectors to maintain exploitation opportunities
    4. Adapting dynamically based on observed cooperation rates
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defection_count = {}

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        round_num = state.round_number
        rounds_remaining = r - round_num
        if round_num == 0:
            if k / (n - 1) > 1.0:
                return Action.C
            else:
                return Action.D
        recent_coop_count = int(sum(history.opponent_actions[-1, :]))
        if round_num >= 2:
            all_defected_prev = sum(history.opponent_actions[-1, :]) == 0
            all_defected_prev2 = sum(history.opponent_actions[-2, :]) == 0
            if all_defected_prev and all_defected_prev2:
                return Action.D
        should_punish = False
        if round_num >= 3:
            for opp_idx in range(n - 1):
                consecutive_defections = 0
                for t in range(round_num - 1, max(round_num - 4, -1), -1):
                    if not history.opponent_actions[t, opp_idx]:
                        consecutive_defections += 1
                    else:
                        break
                if consecutive_defections >= 3 and recent_coop_count >= m:
                    should_punish = True
                    break
        if should_punish:
            return Action.D
        if round_num == r - 1:
            if recent_coop_count >= m:
                return Action.D
            elif recent_coop_count == m - 1:
                return Action.C
            else:
                return Action.D
        if recent_coop_count >= m:
            return Action.D
        if recent_coop_count == m - 1:
            return Action.D
        if recent_coop_count == m - 2 and rounds_remaining > 2:
            return Action.C
        if recent_coop_count <= m - 3:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_189(BaseStrategy):
    """
    Threshold Parasitism: An exploitative strategy that maximizes payoff by free-riding
    on others' cooperation when the threshold is met, while avoiding wasted contributions
    when cooperation is unlikely. Always defects in round 1 and the final round, and
    defects in all intermediate rounds regardless of observed cooperation levels.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        previous_cooperators = int(sum(history.opponent_actions[state.round_number - 1, :]))
        if previous_cooperators >= self.game_description.m:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_190(BaseStrategy):
    """
    Exploitative strategy: Conditional free-riding with adaptive threshold.
    
    Core philosophy: Exploit the threshold structure by free-riding when cooperation 
    reaches m, while minimizing personal contribution. Defect by default, cooperate 
    only when necessary to trigger the threshold or in the final round when beneficial.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
        if current_round == self.n_rounds - 1:
            if cooperators_last_round >= self.m - 1:
                return Action.C
            else:
                return Action.D
        if cooperators_last_round >= self.m:
            return Action.D
        elif cooperators_last_round == self.m - 1:
            if random.random() < 0.6:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_191(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Free-Riding with Threshold Exploitation
    
    Maximizes payoff by free-riding on others' cooperation when the threshold is met,
    and defecting when cooperation is unlikely to reach the threshold.
    Always defects in round 1 and the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.n_rounds - 1:
            return Action.D
        previous_round_idx = state.round_number - 1
        cooperators_previous = int(sum(history.opponent_actions[previous_round_idx, :]))
        other_players = self.n_players - 1
        cooperation_rate = cooperators_previous / other_players if other_players > 0 else 0.0
        if cooperators_previous >= self.m:
            return Action.D
        if cooperators_previous >= self.m - 1 and cooperation_rate > 0.5:
            return Action.D
        if cooperators_previous < self.m / 2.0:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_192(BaseStrategy):
    """
    Exploitative Strategy: Conditional Free-Riding with Adaptive Thresholds
    
    Systematically exploits cooperators by detecting when cooperation reaches
    the threshold m and defecting to capture the k reward without contribution cost.
    Adapts between three phases: exploration, exploitation, and endgame.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.exploration_end = math.ceil(self.r / 3)
        self.exploitation_end = math.ceil(2 * self.r / 3)
        self.threshold_multiplier = 1.2
        self.coop_rate_threshold = 0.9
        self.defect_probability_moderate = 0.7
        self.marginal_player_coop_prob = 0.5
        if self.m == self.n:
            self.defect_probability_moderate = 0.2
        elif self.m == 2:
            self.defect_probability_moderate = 0.95

    def _get_phase(self, round_number: int) -> str:
        """Determine which phase of the strategy we're in."""
        if round_number <= self.exploration_end:
            return 'exploration'
        elif round_number <= self.exploitation_end:
            return 'exploitation'
        else:
            return 'endgame'

    def _compute_cooperation_stats(self, history: PlayerHistory) -> tuple[float, float]:
        """
        Compute cooperation rate and threshold success rate.
        Returns (C_rate, T_success) or (0.0, 0.0) if no history yet.
        """
        if len(history.opponent_actions) == 0:
            return (0.0, 0.0)
        cooperators_per_round = np.sum(history.opponent_actions, axis=1)
        c_rate = float(np.mean(cooperators_per_round)) / (self.n - 1)
        threshold_met = cooperators_per_round >= self.m
        t_success = float(np.sum(threshold_met)) / len(history.opponent_actions)
        return (c_rate, t_success)

    def _count_cooperators_last_round(self, history: PlayerHistory) -> int:
        """Count cooperators in the most recent round."""
        if len(history.opponent_actions) == 0:
            return 0
        return int(np.sum(history.opponent_actions[-1, :]))

    def _exploration_phase(self, round_number: int, history: PlayerHistory) -> Action:
        """
        Phase 1: Exploration (Rounds 1 to âŒˆr/3âŒ‰)
        Round 1: Always defect to establish baseline.
        Rounds 2+: Adapt based on cooperation and threshold success rates.
        """
        if round_number == 0:
            return Action.D
        c_rate, t_success = self._compute_cooperation_stats(history)
        threshold_success_trigger = self.m / self.n * self.threshold_multiplier
        coop_rate_trigger = self.m / self.n * self.coop_rate_threshold
        if t_success >= threshold_success_trigger:
            return Action.D
        elif c_rate >= coop_rate_trigger:
            return Action.D if random.random() < self.defect_probability_moderate else Action.C
        else:
            return Action.C

    def _exploitation_phase(self, history: PlayerHistory) -> Action:
        """
        Phase 2: Exploitation (Rounds âŒˆr/3âŒ‰ + 1 to âŒˆ2r/3âŒ‰)
        Free-ride when threshold is met, cooperate when marginal or at risk.
        """
        prev_cooperators = self._count_cooperators_last_round(history)
        if prev_cooperators >= self.m:
            return Action.D
        elif prev_cooperators == self.m - 1:
            return Action.D if random.random() > self.marginal_player_coop_prob else Action.C
        else:
            return Action.C

    def _endgame_phase(self, round_number: int, history: PlayerHistory) -> Action:
        """
        Phase 3: Endgame (Rounds âŒˆ2r/3âŒ‰ + 1 to r)
        Maximize final-round extraction; defect aggressively near the end.
        """
        prev_cooperators = self._count_cooperators_last_round(history)
        if round_number == self.r - 1:
            if prev_cooperators >= self.m - 1:
                return Action.D
            else:
                return Action.C
        elif prev_cooperators >= self.m - 1:
            return Action.D
        else:
            return Action.C

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        """
        Determine action based on game phase and observed history.
        """
        round_number = state.round_number
        if round_number == 0 or history is None:
            return Action.D
        phase = self._get_phase(round_number)
        if phase == 'exploration':
            return self._exploration_phase(round_number, history)
        elif phase == 'exploitation':
            return self._exploitation_phase(history)
        else:
            return self._endgame_phase(round_number, history)

class Strategy_EXPLOITATIVE_193(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD) Strategy
    
    Exploits the asymmetry in the Collective Risk Dilemma by defecting consistently
    while tracking cooperation history to justify the defection adaptively.
    Core insight: Defectors capture the reward (k) without bearing the cost (c=1)
    of cooperation. This strategy free-rides on others' cooperation when the
    threshold is met, and avoids wasting endowment when it won't be met.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        prev_cooperators_among_opponents = int(sum(history.opponent_actions[-1, :]))
        prev_total_cooperators = prev_cooperators_among_opponents
        if history.my_actions[-1]:
            prev_total_cooperators += 1
        m = self.game_description.m
        if prev_total_cooperators >= m:
            return Action.D
        elif prev_total_cooperators >= m - 1:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_194(BaseStrategy):
    """
    Adaptive Threshold Parasitism: An exploitative strategy for Collective Risk Dilemmas.
    
    Core approach:
    - Defect in first and last rounds (no information/no consequences)
    - Free-ride when threshold is already met by others
    - Exploit the coordination problem by detecting and targeting cooperators
    - Only cooperate when deficit is exactly 1 and cooperation rate is low (cheap completion)
    - Default to defection as exploitation strategy
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        previous_round_idx = current_round - 1
        opponent_cooperated = history.opponent_actions[previous_round_idx, :]
        cooperators_last_round = int(np.sum(opponent_cooperated))
        observed_cooperation_rate = cooperators_last_round / self.n_players if self.n_players > 0 else 0.0
        threshold_rate = self.m / self.n_players if self.n_players > 0 else 0.0
        if cooperators_last_round >= self.m:
            return Action.D
        if cooperators_last_round == 0:
            return Action.D
        if cooperators_last_round > 0 and cooperators_last_round < self.m:
            deficit = self.m - cooperators_last_round
            if deficit == 1 and observed_cooperation_rate < 0.5:
                return Action.C
            if deficit >= 2:
                return Action.D
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_195(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism.
    
    Exploits the asymmetry in payoffs by free-riding on others' cooperation when the
    threshold is met or nearly met. Uses adaptive refinement to detect cooperation patterns
    and adjust defection probability accordingly.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.D
        if round_t == self.r - 1:
            return Action.D
        cooperators_last = int(sum(history.opponent_actions[round_t - 1, :]))
        if cooperators_last >= self.m:
            return Action.D
        if cooperators_last >= self.m - 1:
            return Action.D
        start_idx = max(0, round_t - 3)
        recent_cooperation_count = 0
        recent_total = 0
        for i in range(start_idx, round_t):
            recent_cooperation_count += int(sum(history.opponent_actions[i, :]))
            recent_total += self.n
        recent_coop_rate = recent_cooperation_count / recent_total if recent_total > 0 else 0.0
        if recent_coop_rate > 0.6:
            return Action.D
        if recent_coop_rate > 0.3:
            gap_to_threshold = self.m - cooperators_last
            denominator = max(1, self.n - self.m + 1)
            prob_defect = 1.0 - gap_to_threshold / denominator
            if random.random() < prob_defect:
                return Action.D
            else:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_196(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD) Strategy for Collective Risk Dilemma.
    
    Exploits the asymmetry where defectors gain 1 + k when cooperators reach
    threshold m, while cooperators only gain k. Always defects except in
    mathematically impossible end-game scenarios.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        total_cooperations = np.sum(history.opponent_actions[:current_round, :])
        total_observations = (self.n - 1) * current_round
        if total_observations > 0:
            coop_density = total_cooperations / total_observations
        else:
            coop_density = 0.0
        cooperators_last_round = int(np.sum(history.opponent_actions[current_round - 1, :]))
        rounds_remaining = self.r - current_round
        if coop_density >= self.m / self.n:
            return Action.D
        if cooperators_last_round >= self.m - 1:
            return Action.D
        if coop_density < self.m / self.n and rounds_remaining <= 2:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_197(BaseStrategy):
    """
    Adaptive Threshold Exploitation (ATE): An exploitative strategy that defects by default,
    cooperates only when pivotal (cooperation_count == m-1) in non-final rounds, and always
    defects in the final round. Maximizes free-riding on others' cooperation while appearing
    occasionally cooperative to reduce retaliation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperation_count = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if cooperation_count >= self.m:
            return Action.D
        if cooperation_count == self.m - 1:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_198(BaseStrategy):
    """
    Adaptive Threshold Predation: Exploitative strategy that defects by default,
    cooperates only when necessary to unlock the reward multiplier funded by others.
    
    Core mechanisms:
    1. Defect in round 1 and last round unconditionally
    2. Free-ride when threshold is already met
    3. Cooperate only when exactly one more cooperator is needed (gap=1)
    4. Exploit threshold impossibility scenarios (m=n)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        c_prev = int(sum(history.opponent_actions[current_round - 1, :]))
        if history.my_actions[current_round - 1]:
            c_prev += 1
        threshold_gap = self.m - c_prev
        if c_prev >= self.m:
            return Action.D
        if threshold_gap == 1 and current_round <= self.n_rounds - 2:
            if current_round >= 2:
                c_prev_prev = int(sum(history.opponent_actions[current_round - 2, :]))
                if history.my_actions[current_round - 2]:
                    c_prev_prev += 1
                if c_prev_prev >= self.m - 1:
                    return Action.C
            else:
                return Action.C
        if threshold_gap <= 0:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_199(BaseStrategy):
    """
    Conditional Free-Riding Strategy for Collective Risk Dilemma.
    
    Exploits the threshold mechanism by:
    1. Always defecting in round 1 to establish baseline
    2. Free-riding when threshold is already met (c_count >= m)
    3. Acting as swing vote only when c_count == m-1
    4. Always defecting in the final round
    5. Defecting when threshold cannot be reached (c_count < m-1)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
        if cooperators_last_round >= self.m:
            return Action.D
        if cooperators_last_round == self.m - 1:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_200(BaseStrategy):
    """
    Threshold Parasitism: An exploitative strategy that defects systematically to free-ride
    on others' cooperation while maintaining plausible deniability. Recognizes that once m
    cooperators exist, defectors capture the full reward k without cost.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_avg = 0.0
        self.rounds_since_threshold_met = -1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0 or current_round == 1:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if current_round >= r - 2:
            return Action.D
        current_round_cooperators = cooperators_last_round
        self.cooperation_avg = 0.7 * self.cooperation_avg + 0.3 * current_round_cooperators
        if cooperators_last_round >= m:
            self.rounds_since_threshold_met = 0
        elif self.rounds_since_threshold_met >= 0:
            self.rounds_since_threshold_met += 1
        if cooperators_last_round >= m:
            return Action.D
        elif cooperators_last_round == m - 1:
            return Action.D
        else:
            rounds_remaining = r - current_round
            cooperation_trend_positive = self.cooperation_avg > 0.4 * current_round_cooperators
            if rounds_remaining > 3 and cooperation_trend_positive:
                return Action.D
            else:
                return Action.D

class Strategy_EXPLOITATIVE_201(BaseStrategy):
    """
    Adaptive Free-Riding with Threshold Exploitation.
    
    Exploits the payoff asymmetry where defectors gain +1 advantage over cooperators
    when the threshold is met. Strategy parasitizes cooperation by:
    1. Always defecting in round 1 and final round
    2. Observing cooperation rates and free-riding when threshold is met
    3. Defecting when cooperation is insufficient (below m-1 cooperators)
    4. Ignoring historical cooperation patterns; only current rates matter
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        prev_round_idx = round_number - 1
        prev_cooperators_opponents = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        prev_own_action = history.my_actions[prev_round_idx]
        total_prev_cooperators = prev_cooperators_opponents + (1 if prev_own_action else 0)
        coop_rate = total_prev_cooperators / self.n_players
        threshold_rate = self.m / self.n_players
        near_threshold_rate = (self.m - 1) / self.n_players
        if coop_rate >= threshold_rate:
            return Action.D
        if coop_rate < near_threshold_rate:
            return Action.D
        if coop_rate >= near_threshold_rate and coop_rate < threshold_rate:
            if self.n_rounds - round_number <= 2:
                return Action.D
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_202(BaseStrategy):
    """
    Exploitative strategy: "Adaptive Free-Riding with Conditional Defection"
    
    Core philosophy: Exploit the threshold mechanism by minimizing personal 
    contribution while maximizing extraction from others' cooperation. 
    Always defect unless cooperation is provably essential (which it almost never is).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold_rate = self.m / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == self.r - 1:
            return Action.D
        if round_number == 0:
            return Action.D
        observation_window_size = max(3, math.ceil(self.r / 3))
        window_start = max(0, round_number - observation_window_size)
        window_actions = history.opponent_actions[window_start:round_number, :]
        if window_actions.shape[0] == 0:
            return Action.D
        cooperators_per_round = np.sum(window_actions, axis=1)
        avg_others_coop = np.mean(cooperators_per_round)
        if self.n - 1 > 0:
            empirical_coop_rate = avg_others_coop / (self.n - 1)
        else:
            empirical_coop_rate = 0.0
        decision_threshold = self.threshold_rate - 0.15
        if round_number > 0:
            last_round_cooperators = np.sum(history.opponent_actions[round_number - 1, :])
            if last_round_cooperators == self.n - 1:
                return Action.D
        if round_number > 0:
            last_round_cooperators = np.sum(history.opponent_actions[round_number - 1, :])
            if last_round_cooperators == 0:
                return Action.D
        if empirical_coop_rate > decision_threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_203(BaseStrategy):
    """
    Exploitative Strategy: Conditional Free-Riding with Adaptive Thresholding
    
    Exploits the asymmetry in payoff structure by free-riding on others' cooperation
    while maintaining just enough cooperation to trigger the threshold when beneficial.
    Core mechanics: defect in round 1 and final round, track cooperation patterns in
    middle rounds, and occasionally cooperate at threshold proximity to appear cooperative.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
        if cooperators_last_round >= self.m:
            return Action.D
        if cooperators_last_round >= self.m - 1:
            if random.random() < 0.3:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_204(BaseStrategy):
    """
    Adaptive Free-Riding with Conditional Defection strategy for Collective Risk Dilemma.
    
    Exploits the asymmetry in payoffs by systematically defecting to free-ride on others'
    cooperation. Adapts based on observable cooperation rates across three phases:
    - Early phase: Information gathering (always defect)
    - Mid phase: Conditional defection based on cooperation stability
    - Late phase: Aggressive exploitation until end-game
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.phase1_end = max(1, math.floor(game_description.n_rounds / 3))
        self.phase2_end = max(self.phase1_end + 1, math.floor(2 * game_description.n_rounds / 3))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        c_prev = int(np.sum(history.opponent_actions[round_number - 1, :]))
        if round_number <= self.phase1_end:
            return Action.D
        if round_number <= self.phase2_end:
            total_rounds_so_far = round_number
            total_cooperators = int(np.sum(history.opponent_actions[:round_number, :]))
            if total_rounds_so_far == 0 or self.n_players == 0:
                return Action.D
            coop_rate = total_cooperators / (self.n_players * total_rounds_so_far)
            threshold_rate = self.m / self.n_players
            if coop_rate >= threshold_rate * 1.2:
                return Action.D
            elif coop_rate < threshold_rate * 0.8:
                return Action.D
            elif c_prev >= self.m:
                return Action.D
            else:
                return Action.D
        if round_number < self.n_rounds - 1:
            if c_prev >= self.m:
                return Action.D
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_205(BaseStrategy):
    """
    Adaptive Threshold Rider: An exploitative strategy that dynamically free-rides on others' 
    cooperation by estimating cooperation rates and positioning itself to benefit from the 
    threshold being met without paying the cooperation cost.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.coop_rate = 0.5
        self.cooperator_streaks = {}
        self.defector_streaks = {}

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        self._update_cooperation_rate(history)
        self._update_opponent_streaks(history)
        has_consistent_defector = any((streak >= 3 for streak in self.defector_streaks.values()))
        expected_cooperators = (self.game_description.n_players - 1) * self.coop_rate
        threshold = self.game_description.m
        if expected_cooperators >= threshold - 0.5:
            return Action.D
        if expected_cooperators >= threshold - 1.5:
            threshold_gap = threshold - expected_cooperators
            hedge_probability = threshold_gap / 2.0
            if random.random() < hedge_probability:
                return Action.C
            return Action.D
        return Action.D

    def _update_cooperation_rate(self, history: PlayerHistory) -> None:
        """Update cooperation rate using exponential moving average."""
        if history is None or len(history.opponent_actions) == 0:
            return
        most_recent_round = history.opponent_actions[-1, :]
        cooperators_this_round = np.sum(most_recent_round)
        opponents_count = self.game_description.n_players - 1
        if opponents_count > 0:
            cooperation_sample = cooperators_this_round / opponents_count
            self.coop_rate = 0.7 * self.coop_rate + 0.3 * cooperation_sample

    def _update_opponent_streaks(self, history: PlayerHistory) -> None:
        """Track consecutive cooperation/defection streaks per opponent."""
        if history is None or len(history.opponent_actions) == 0:
            return
        n_opponents = self.game_description.n_players - 1
        for opponent_idx in range(n_opponents):
            if opponent_idx not in self.cooperator_streaks:
                self.cooperator_streaks[opponent_idx] = 0
                self.defector_streaks[opponent_idx] = 0
            most_recent_action = history.opponent_actions[-1, opponent_idx]
            if most_recent_action:
                self.cooperator_streaks[opponent_idx] += 1
                self.defector_streaks[opponent_idx] = 0
            else:
                self.defector_streaks[opponent_idx] += 1
                self.cooperator_streaks[opponent_idx] = 0

class Strategy_EXPLOITATIVE_206(BaseStrategy):
    """
    Adaptive Defection with Conditional Free-Riding Strategy.
    
    Core principle: Exploit the asymmetry in payoffs by defecting whenever possible
    while free-riding on others' cooperation. Only cooperate strategically in rare
    forcing conditions to maintain exploitation opportunities.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.opponent_cooperation_history = {}

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        current_round = state.round_number
        last_round_idx = current_round - 1
        cooperators_last_round = int(sum(history.opponent_actions[last_round_idx, :]))
        for opp_idx in range(self.n_players - 1):
            if opp_idx not in self.opponent_cooperation_history:
                self.opponent_cooperation_history[opp_idx] = []
            self.opponent_cooperation_history[opp_idx].append(bool(history.opponent_actions[last_round_idx, opp_idx]))
        threshold_met_last_round = cooperators_last_round >= self.m
        if cooperators_last_round == self.m - 1 and 0 < current_round < self.n_rounds - 1:
            return Action.D
        if threshold_met_last_round:
            return Action.D
        if cooperators_last_round < self.m:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_207(BaseStrategy):
    """
    Exploitative strategy for Collective Risk Dilemma that free-rides on others' cooperation
    while adaptively detecting and exploiting predictable patterns. Defects strategically in
    early rounds, final rounds, and when threshold is likely to be met by others.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.failed_cooperation_rounds = 0
        self.defection_streak = 0
        self.cooperator_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        n_rounds = self.game_description.n_rounds
        m = self.game_description.m
        if current_round == 0:
            self.failed_cooperation_rounds = 0
            self.defection_streak = 0
            self.cooperator_history = []
            return Action.D
        if current_round == n_rounds - 1:
            return Action.D
        recent_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        self.cooperator_history.append(recent_cooperators)
        if self.failed_cooperation_rounds >= 2:
            self.defection_streak += 1
            return Action.D
        if recent_cooperators >= m:
            self.defection_streak += 1
            self.failed_cooperation_rounds = 0
            return Action.D
        if recent_cooperators >= m - 1:
            self.defection_streak += 1
            self.failed_cooperation_rounds = 0
            return Action.D
        if recent_cooperators < m - 1:
            if len(self.cooperator_history) >= 2:
                trend_increasing = self.cooperator_history[-1] > self.cooperator_history[-2]
                if trend_increasing and self.cooperator_history[-1] >= m - 2:
                    self.defection_streak += 1
                    self.failed_cooperation_rounds = 0
                    return Action.D
            self.defection_streak = 0
            self.failed_cooperation_rounds += 1
            return Action.C
        self.defection_streak += 1
        return Action.D

class Strategy_EXPLOITATIVE_208(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation
    
    Implements a "Threshold Parasite" strategy that:
    - Always defects in round 1 and final round
    - Defects when threshold is met (free-riding on others' cooperation)
    - Uses probabilistic defection when near threshold to destabilize coordination
    - Tracks opponent cooperation rates for opponent typing
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_cooperation_counts = np.zeros(game_description.n_players - 1, dtype=np.int32)
        self.opponent_round_counts = np.zeros(game_description.n_players - 1, dtype=np.int32)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        if state.round_number >= self.game_description.n_rounds - 3:
            return Action.D
        coop_count_prev = np.sum(history.opponent_actions[state.round_number - 1, :])
        for opponent_idx in range(self.game_description.n_players - 1):
            if history.opponent_actions[state.round_number - 1, opponent_idx]:
                self.opponent_cooperation_counts[opponent_idx] += 1
            self.opponent_round_counts[opponent_idx] += 1
        if coop_count_prev >= self.game_description.m:
            return Action.D
        elif coop_count_prev == self.game_description.m - 1:
            if random.random() < 0.85:
                return Action.D
            else:
                return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_209(BaseStrategy):
    """
    Conditional Free-Rider with Adaptive Threshold Strategy
    
    Exploits the asymmetry in payoff structure by defecting whenever possible,
    cooperating only when necessary to ensure the threshold is met and capture
    the reward k without bearing the cooperation cost.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        previous_round_opponent_actions = history.opponent_actions[current_round - 1, :]
        recent_cooperators_count = int(np.sum(previous_round_opponent_actions))
        if current_round == self.n_rounds - 1:
            if recent_cooperators_count >= self.m - 1:
                return Action.C
            else:
                return Action.D
        threshold_met = recent_cooperators_count >= self.m
        if threshold_met:
            return Action.D
        elif recent_cooperators_count == self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_210(BaseStrategy):
    """
    Adaptive Threshold Leaching: An exploitative strategy that free-rides on others'
    cooperation while minimizing personal contribution. Dynamically adapts to opponent
    behavior to maximize extraction of collective benefits without bearing costs.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.defection_streak = 0
        self.exploitation_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[round_num - 1, :]))
        if cooperators_last_round >= self.m:
            self.defection_streak += 1
            return Action.D
        deficit = self.m - cooperators_last_round
        if deficit <= 2:
            self.defection_streak += 1
            return Action.D
        if deficit > 2 and deficit / self.n_players > 0.4:
            self.defection_streak += 1
            return Action.D
        if round_num <= self.n_rounds * 0.7:
            self.defection_streak += 1
            return Action.D
        if round_num >= 1:
            prev_cooperators = int(sum(history.opponent_actions[round_num - 1, :]))
            my_prev_action = history.my_actions[round_num - 1]
            my_prev_payoff = history.my_payoffs[round_num - 1]
            if prev_cooperators == self.m and (not my_prev_action) and (my_prev_payoff == 1.0 + self.k):
                self.exploitation_count += 1
                if random.random() < 0.95:
                    self.defection_streak += 1
                    return Action.D
        if round_num >= 3:
            recent_cooperators = [int(sum(history.opponent_actions[i, :])) for i in range(max(0, round_num - 3), round_num)]
            if len(recent_cooperators) > 1:
                variance = float(np.var(recent_cooperators))
                if variance > 0.5 * float(np.std(recent_cooperators)):
                    self.defection_streak += 1
                    return Action.D
        if round_num > self.n_rounds * 0.8 and cooperators_last_round < self.m:
            self.defection_streak = 0
            return Action.C
        if self.defection_streak >= 2 and cooperators_last_round < self.m:
            self.defection_streak += 1
            return Action.D
        self.defection_streak += 1
        return Action.D

class Strategy_EXPLOITATIVE_211(BaseStrategy):
    """
    Adaptive Threshold Exploitation (ATE) Strategy
    
    Exploits the asymmetry between cooperators and defectors by:
    1. Free-riding when cooperation threshold is likely met
    2. Conditional defection to minimize risk when threshold is endangered
    3. Dynamic adaptation based on observed cooperation rates
    4. Terminal exploitation in final rounds
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_ratio = self.m / self.n_players
        self.tolerance = 0.05

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round >= self.n_rounds - 1:
            return Action.D
        avg_cooperation_rate = self._calculate_cooperation_rate(history, current_round)
        if avg_cooperation_rate > self.threshold_ratio + self.tolerance:
            return Action.D
        elif avg_cooperation_rate < self.threshold_ratio - self.tolerance:
            return Action.D
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the average cooperation rate observed from all other players
        across all previous rounds.
        
        cooperation_rate = (total cooperators observed) / (n_players - 1) / rounds_elapsed
        """
        if current_round == 0:
            return 0.0
        opponent_actions = history.opponent_actions[:current_round, :]
        total_cooperations = np.sum(opponent_actions)
        total_possible = (self.n_players - 1) * current_round
        if total_possible == 0:
            return 0.0
        avg_cooperation_rate = total_cooperations / total_possible
        return avg_cooperation_rate

class Strategy_EXPLOITATIVE_212(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Defection strategy for Collective Risk Dilemma.
    
    Exploits the threshold mechanism by strategically defecting when cooperation is likely,
    while maintaining adaptive cooperation to avoid permanent exploitation. Uses a buffer-based
    threshold to balance free-riding with reputation management across rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.buffer_threshold = 0.15 * (self.m / self.n_players)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        total_cooperators = 0
        total_rounds_played = 0
        for round_idx in range(current_round):
            cooperators_this_round = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += cooperators_this_round
            total_rounds_played += self.n_players
        if total_rounds_played == 0:
            coop_ratio = 0.0
        else:
            coop_ratio = total_cooperators / total_rounds_played
        threshold_safe = self.m / self.n_players + self.buffer_threshold
        if coop_ratio > threshold_safe:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_213(BaseStrategy):
    """
    Adaptive Threshold Exploitation (ATE) Strategy
    
    Maximizes personal payoff by exploiting the asymmetry between cooperators 
    and defectors. The strategy defects in early rounds to gather information, 
    then adaptively exploits based on estimated cooperation frequency while 
    always defecting in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        exploration_rounds = min(3, self.n_rounds - 1)
        if current_round < exploration_rounds:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cf = self._calculate_cooperation_frequency(history, current_round)
        threshold = self.m / self.n_players
        if cf >= threshold:
            return Action.D
        return Action.D

    def _calculate_cooperation_frequency(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the cooperation frequency from previous rounds.
        
        CF = (total cooperators observed in previous rounds) / (n-1) / (rounds played)
        
        Returns a value in [0, 1] representing the proportion of opponent cooperators.
        """
        if current_round == 0:
            return 0.0
        opponent_actions = history.opponent_actions[:current_round, :]
        total_cooperations = np.sum(opponent_actions)
        total_observations = (self.n_players - 1) * current_round
        if total_observations == 0:
            return 0.0
        cf = total_cooperations / total_observations
        return cf

class Strategy_EXPLOITATIVE_214(BaseStrategy):
    """
    Adaptive Predation: An exploitative strategy that free-rides on cooperators' 
    contributions while systematically defecting to maximize personal payoff.
    
    Core mechanics:
    - Round 1: Defect to establish baseline
    - Subsequent rounds: Defect when threshold is met (free ride) or when it cannot be reached
    - Final round: Defect to maximize final exploitation
    - Adapts only to detect cooperation levels, never reciprocates
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if self.m == self.n:
            return Action.D
        if self.m == 1:
            return Action.D
        last_round_actions = history.opponent_actions[current_round - 1, :]
        cooperators_last_round = int(np.sum(last_round_actions))
        cooperation_rate = cooperators_last_round / self.n if self.n > 0 else 0
        threshold_met = cooperators_last_round >= self.m
        if current_round == self.r - 1:
            return Action.D
        if threshold_met:
            return Action.D
        if cooperators_last_round < self.m:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_215(BaseStrategy):
    """
    Conditional Predator: An exploitative strategy that free-rides on cooperators
    while defecting to maximize personal payoff. Defects in round 1 and final round,
    and exploits cooperators in middle rounds by analyzing cooperation patterns.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[state.round_number - 1, :]))
        if cooperators_last_round >= self.game_description.m:
            return Action.D
        if cooperators_last_round == self.game_description.m - 1:
            return Action.D
        if cooperators_last_round < self.game_description.m - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_216(BaseStrategy):
    """
    Adaptive Threshold Predation: An exploitative strategy that identifies when cooperation
    will succeed without the player's contribution, then defects to capture maximum payoff
    (1 + k instead of 0 + k). Adapts defection intensity based on opponent resilience and
    exploits the endgame unconditionally.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.natural_cooperation_rate = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == 1:
            cooperators_round_0 = int(sum(history.opponent_actions[0, :]))
            self.natural_cooperation_rate = cooperators_round_0
            if cooperators_round_0 >= self.game_description.m:
                return Action.D
            else:
                return Action.C
        remaining_rounds = self.game_description.n_rounds - state.round_number
        if remaining_rounds <= 2:
            return Action.D
        cooperators_prev = int(sum(history.opponent_actions[-1, :]))
        threshold_margin = cooperators_prev - self.game_description.m
        if threshold_margin >= 1:
            return Action.D
        elif threshold_margin == 0:
            defect_probability = 1.0 - 1.0 / remaining_rounds
            if random.random() < defect_probability:
                return Action.D
            else:
                return Action.C
        else:
            return Action.C

class Strategy_EXPLOITATIVE_217(BaseStrategy):
    """
    Adaptive Threshold Parasitism: Exploitative strategy that maximizes payoff by free-riding
    on others' cooperation, defecting strategically, and only cooperating when serving as the
    swing vote while behind on payoff. Always defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[round_num - 1, :]))
        if history.my_actions[round_num - 1]:
            cooperators_last_round += 1
        my_action_last = history.my_actions[round_num - 1]
        my_payoff_last = history.my_payoffs[round_num - 1]
        avg_payoff_others = 0.0
        if self.n_players > 1:
            avg_payoff_others = np.mean(history.opponent_payoffs[round_num - 1, :])
        if cooperators_last_round == self.n_players - 1 and (not my_action_last):
            return Action.D
        if cooperators_last_round >= self.m and (not my_action_last):
            return Action.D
        if cooperators_last_round >= self.m - 1 and my_action_last:
            return Action.D
        if cooperators_last_round < self.m - 1:
            return Action.D
        if cooperators_last_round == self.m - 1:
            if my_payoff_last < avg_payoff_others:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_218(BaseStrategy):
    """
    Adaptive Threshold Hunting (ATH): Exploitative strategy that defects to capture
    rewards when others cooperate to meet the threshold, while avoiding costs when
    the threshold cannot be met.
    
    Core principle: Let others pay the cooperation cost (c=1), capture the reward (k)
    when threshold is met, defect when it cannot be met.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.n_rounds - 1:
            if self._should_exploit_always_cooperators(history):
                return Action.C
            return Action.D
        return Action.D

    def _should_exploit_always_cooperators(self, history: PlayerHistory) -> bool:
        """
        Detect if opponents are "always cooperate" bots.
        If we've defected for 2+ rounds and they still cooperate consistently,
        cooperate in final round to gain k instead of 1.
        
        Returns True only if we have strong evidence of always-cooperate behavior.
        """
        current_round = len(history.my_actions) - 1
        if current_round < 2:
            return False
        my_defections = np.sum(~history.my_actions[:current_round])
        if my_defections < 2:
            return False
        for round_idx in range(current_round - 1, current_round + 1):
            opponent_cooperators = np.sum(history.opponent_actions[round_idx, :])
            if opponent_cooperators < self.n_players:
                return False
        for round_idx in range(current_round - 1, current_round + 1):
            opponent_cooperators = np.sum(history.opponent_actions[round_idx, :])
            if opponent_cooperators < self.m:
                return False
        return True

class Strategy_EXPLOITATIVE_219(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Free-Riding with Threshold Exploitation
    
    Extracts maximum value by parasitizing cooperation when it reaches threshold,
    minimizing personal investment while harvesting collective gains.
    Core principle: Always defect by default, with selective cooperative baiting
    to trigger others' cooperation for exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.baited_last_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == self.r - 1:
            return Action.D
        if round_t == self.r - 2:
            self.baited_last_round = False
            return Action.D
        if round_t == 0:
            self.baited_last_round = False
            return Action.D
        prev_coop_count = int(np.sum(history.opponent_actions[round_t - 1, :]))
        prev_coop_rate = prev_coop_count / self.n if self.n > 0 else 0.0
        coop_threshold_met = prev_coop_count >= self.m
        if coop_threshold_met:
            self.baited_last_round = False
            return Action.D
        remaining_rounds = self.r - round_t
        if round_t >= 2:
            prev_prev_coop_count = int(np.sum(history.opponent_actions[round_t - 2, :]))
            prev_prev_coop_rate = prev_prev_coop_count / self.n if self.n > 0 else 0.0
            coop_rate_trend = prev_coop_rate - prev_prev_coop_rate
        else:
            coop_rate_trend = 0.0
        if coop_rate_trend > 0 and prev_coop_rate >= 0.3 and (remaining_rounds >= 2) and (not self.baited_last_round):
            self.baited_last_round = True
            return Action.C
        self.baited_last_round = False
        return Action.D

class Strategy_EXPLOITATIVE_220(BaseStrategy):
    """
    Adaptive Threshold Defection with Conditional Parasitism.
    
    Exploits asymmetry in payoffs by:
    1. Gathering information on cooperation rates (Phase 1)
    2. Defecting when threshold will be met to free-ride (Phase 2)
    3. Mixing strategically in marginal cases to maintain deniability
    4. Defecting unconditionally in the final round (Phase 3)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        info_gathering_end = min(3, self.r - 2)
        if round_num < info_gathering_end:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        observed_cooperations = 0
        observed_rounds = 0
        for past_round in range(round_num):
            observed_cooperations += np.sum(history.opponent_actions[past_round, :])
            observed_rounds += 1
        if observed_rounds == 0 or self.n - 1 == 0:
            return Action.D
        cooperation_rate = observed_cooperations / (observed_rounds * (self.n - 1))
        expected_cooperators = cooperation_rate * (self.n - 1)
        if expected_cooperators >= self.m:
            return Action.D
        elif expected_cooperators < self.m - 1:
            return Action.D
        else:
            p_cooperate = (self.k - 1) / self.k if self.k > 1 else 0
            if random.random() < p_cooperate:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_221(BaseStrategy):
    """
    Adaptive Threshold Harvesting: An exploitative strategy that identifies and parasitizes
    cooperators while adapting to population-wide cooperation levels. Exploits the asymmetry
    between cooperators and defectors by free-riding when the threshold is met, strategically
    seeding cooperation early to trigger future exploitation, and defecting relentlessly in
    end-game rounds where retaliation cannot occur.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if self.m == self.n_players:
            return Action.D
        if self.m == 2 and self.n_players == 2:
            return Action.D
        if current_round == 0:
            p_seed = (self.m - 1) / self.n_players
            if random.random() < p_seed:
                return Action.C
            else:
                return Action.D
        if current_round >= self.n_rounds - 1:
            return Action.D
        last_round_idx = current_round - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[last_round_idx, :]))
        if cooperators_last_round >= self.m:
            return Action.D
        if current_round > 0:
            total_cooperators = int(np.sum(history.opponent_actions[:current_round, :]))
            total_rounds_observed = current_round
            cooperation_rate = total_cooperators / (total_rounds_observed * self.n_players)
            threshold_cooperation = self.m / self.n_players
            if cooperation_rate >= threshold_cooperation:
                return Action.D
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_222(BaseStrategy):
    """
    Adaptive Threshold Defection: Exploitative strategy that free-rides on others' 
    cooperation while monitoring empirical cooperation rates to maximize payoff extraction.
    Defects in most scenarios, with conditional cooperation only in endgame salvage attempts.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        threshold = self.m / self.n
        coop_rate = self._calculate_coop_rate(history, current_round)
        if current_round == self.r - 1:
            return self._final_round_decision(history, threshold)
        return self._adaptive_defection_decision(coop_rate, threshold, current_round)

    def _calculate_coop_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate observed cooperation rate from all previous rounds.
        Returns proportion of cooperators across all players and all past rounds.
        """
        if current_round <= 0:
            return 0.5
        total_cooperations = 0
        for round_idx in range(current_round):
            total_cooperations += int(history.my_actions[round_idx])
            total_cooperations += int(np.sum(history.opponent_actions[round_idx, :]))
        total_slots = current_round * self.n
        coop_rate = total_cooperations / total_slots if total_slots > 0 else 0.5
        return coop_rate

    def _final_round_decision(self, history: PlayerHistory, threshold: float) -> Action:
        """
        Final round (round r): Extract maximum value or salvage if threshold nearly met.
        """
        prev_round_coop = int(np.sum(history.opponent_actions[-1, :])) + int(history.my_actions[-1])
        if prev_round_coop >= self.m:
            return Action.D
        gap = self.m - prev_round_coop
        if gap <= 1 and gap > 0:
            return Action.C
        return Action.D

    def _adaptive_defection_decision(self, coop_rate: float, threshold: float, current_round: int) -> Action:
        """
        Non-final rounds: Adaptively defect based on empirical cooperation rates.
        """
        rounds_remaining = self.r - current_round
        if coop_rate > threshold * 1.5:
            return Action.D
        elif coop_rate >= threshold:
            return Action.D
        elif coop_rate >= threshold * 0.9:
            if rounds_remaining <= 2:
                return Action.C
            return Action.D
        elif coop_rate < threshold * 0.7:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_223(BaseStrategy):
    """
    Conditional Free-Rider: An exploitative strategy that defects unconditionally
    to free-ride on others' cooperation while avoiding the cost of contribution.
    
    Core logic: Always defect to maximize payoff by capturing the reward k when
    threshold m is met by others, while paying zero contribution cost.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_224(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD) Strategy for Collective Risk Dilemma.
    
    Exploits the asymmetry between cooperators and defectors by:
    1. Free-riding when threshold is already met
    2. Cooperating only when pivotal (in non-final rounds)
    3. Always defecting in the final round
    4. Avoiding wasted costs when threshold is impossible
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        observed_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        if observed_cooperators >= m - 1:
            return Action.D
        if current_round == r - 1:
            return Action.D
        threshold_deficit = m - 1 - observed_cooperators
        if threshold_deficit == 1:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_225(BaseStrategy):
    """
    Conditional Parasite: Exploitative threshold-hunting strategy.
    
    Defects by default, cooperates only when necessary to secure the threshold
    and enable free-riding. Uses predictive modeling of opponent cooperation
    to identify tipping points where conditional cooperation maximizes payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.k_window = min(5, max(1, self.n_rounds // 2))
        self.committed_defector_threshold = 0.1
        self.volatility_threshold = 0.4

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return self._decide_round_zero()
        if round_num == self.n_rounds - 1:
            return Action.D
        return self._decide_middle_round(state, history)

    def _decide_round_zero(self) -> Action:
        """
        Round 0 decision: estimate if threshold will be met with minimal cooperation.
        """
        p_cooperate_est = self.m / self.n_players
        expected_cooperators = (self.n_players - 1) * p_cooperate_est
        if expected_cooperators >= self.m:
            return Action.D
        else:
            return Action.C

    def _decide_middle_round(self, state: GameState, history: PlayerHistory) -> Action:
        """
        Middle rounds (1 to r-2): Use predictive model to identify tipping points.
        """
        round_num = state.round_number
        predicted_cooperators = self._predict_cooperators(history, round_num)
        if predicted_cooperators >= self.m:
            return Action.D
        elif predicted_cooperators == self.m - 1:
            return Action.C
        elif predicted_cooperators == self.m - 2:
            return Action.C
        else:
            return Action.D

    def _predict_cooperators(self, history: PlayerHistory, current_round: int) -> int:
        """
        Predict cooperation count in next round using recent history.
        """
        start_idx = max(0, current_round - self.k_window)
        recent_opponent_actions = history.opponent_actions[start_idx:current_round, :]
        predicted_count = 0
        for player_idx in range(self.n_players - 1):
            player_cooperations = recent_opponent_actions[:, player_idx]
            num_rounds_observed = len(player_cooperations)
            if num_rounds_observed == 0:
                predicted_count += self.m / self.n_players
                continue
            coop_count = np.sum(player_cooperations)
            coop_rate = coop_count / num_rounds_observed
            total_coop_rate = np.sum(history.opponent_actions[:current_round, player_idx]) / max(1, current_round)
            if total_coop_rate < self.committed_defector_threshold:
                predicted_count += 0.0
                continue
            volatility = self._calculate_volatility(player_cooperations)
            if volatility > self.volatility_threshold:
                predicted_count += 0.5
            else:
                predicted_count += coop_rate
        return int(math.floor(predicted_count + 0.5))

    def _calculate_volatility(self, actions: NDArray[np.bool_]) -> float:
        """
        Calculate volatility as the proportion of action switches.
        """
        if len(actions) < 2:
            return 0.0
        switches = 0
        for i in range(1, len(actions)):
            if actions[i] != actions[i - 1]:
                switches += 1
        volatility = switches / (len(actions) - 1)
        return volatility

class Strategy_EXPLOITATIVE_226(BaseStrategy):
    """
    Adaptive Free-Rider with Threshold Calibration.
    
    Exploits the threshold mechanism by defaulting to defection while parasitically
    benefiting from others' cooperation. Uses probabilistic conditional cooperation
    in middle rounds to bootstrap threshold achievement, then free-rides once threshold
    is met. Guarantees defection in final round due to endgame dominance.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[round_number - 1, :]))
        if round_number == self.n_rounds - 1:
            return Action.D
        if cooperators_last_round >= self.m:
            return Action.D
        if 1 <= round_number < self.n_rounds - 1:
            gap = self.m - cooperators_last_round
            denominator = self.n_players - 1
            if denominator <= 0:
                return Action.D
            p_cooperate = gap / denominator
            p_cooperate = max(0.0, min(1.0, p_cooperate))
            if random.random() < p_cooperate:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_227(BaseStrategy):
    """
    Exploitative Strategy: "Calculated Free-Riding with Adaptive Defection"
    
    Exploits the threshold mechanism by minimizing personal contribution while maximizing 
    benefit extraction. Assumes others will provide the minimum threshold and positions itself 
    to free-ride on their contributions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        opponent_actions = history.opponent_actions
        completed_rounds = round_num
        total_cooperations = np.sum(opponent_actions[:completed_rounds, :])
        total_observations = completed_rounds * (self.n - 1)
        if total_observations == 0:
            observed_coop_rate = 0.0
        else:
            observed_coop_rate = total_cooperations / total_observations
        expected_cooperators = observed_coop_rate * (self.n - 1)
        defector_concentration = self._calculate_defector_concentration(opponent_actions, completed_rounds)
        if defector_concentration > 0.4 and round_num < self.r / 2:
            return Action.D
        if expected_cooperators >= self.m:
            return Action.D
        elif expected_cooperators < self.m - 1:
            return Action.D
        else:
            p = (self.k - 1) / self.k
            if self.m <= 2:
                p = p * 0.8
            if self.m > self.n / 2 + 1:
                if self._is_marginal_player(opponent_actions, completed_rounds):
                    p = 1.0
                else:
                    p = 0.0
            if defector_concentration < 0.2 and round_num > self.r / 2:
                p = min(1.0, p * 1.1)
            if random.random() < p:
                return Action.C
            else:
                return Action.D

    def _calculate_defector_concentration(self, opponent_actions: NDArray[np.bool_], completed_rounds: int) -> float:
        """
        Calculate the concentration of pure defectors (100% defection rate) among opponents.
        Returns: fraction of opponents with 100% defection history
        """
        if completed_rounds == 0:
            return 0.0
        pure_defectors = 0
        for player_idx in range(self.n - 1):
            player_cooperations = np.sum(opponent_actions[:completed_rounds, player_idx])
            if player_cooperations == 0:
                pure_defectors += 1
        defector_concentration = pure_defectors / (self.n - 1) if self.n > 1 else 0.0
        return defector_concentration

    def _is_marginal_player(self, opponent_actions: NDArray[np.bool_], completed_rounds: int) -> float:
        """
        For high thresholds (m > n/2 + 1), check if our cooperation is pivotal.
        This is a heuristic: if the expected cooperators (excluding us) are exactly m-1,
        then we are marginal.
        """
        if completed_rounds == 0:
            return False
        recent_cooperations = np.sum(opponent_actions[-1, :])
        return recent_cooperations == self.m - 1

class Strategy_EXPLOITATIVE_228(BaseStrategy):
    """
    Adaptive Threshold Exploitation (ATE) Strategy for Collective Risk Dilemma.
    
    Maximizes personal payoff by exploiting the threshold structure through:
    1. Default defection to free-ride on others' cooperation
    2. Monitoring cooperation levels to detect sustained thresholds
    3. Conditional cooperation only when strategically beneficial
    4. Aggressive defection in final rounds when no retaliation is possible
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.mode = 'EXPLOIT'
        self.consecutive_threshold_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
        if current_round >= r - 2:
            return Action.D
        if self.mode == 'EXPLOIT':
            if current_round >= 2:
                cooperators_prev_prev = int(sum(history.opponent_actions[current_round - 2, :]))
                if cooperators_last_round >= m and cooperators_prev_prev >= m:
                    self.consecutive_threshold_rounds += 1
                    if self.consecutive_threshold_rounds >= 2:
                        self.mode = 'CONDITIONAL'
                else:
                    self.consecutive_threshold_rounds = 0
            deficit = m - cooperators_last_round
            non_cooperators = n - cooperators_last_round
            if deficit <= 0:
                return Action.D
            if deficit > 0 and deficit < non_cooperators:
                return Action.D
            if deficit == 1 and non_cooperators == 1:
                return Action.C
            return Action.D
        else:
            deficit = m - cooperators_last_round
            if deficit <= 0:
                return Action.D
            elif deficit == 1:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_229(BaseStrategy):
    """
    Exploitative strategy for Collective Risk Dilemma using conditional free-riding
    with adaptive thresholds. Systematically defects to capture rewards while avoiding
    contribution costs, with special handling for endgame and threshold conditions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == self.n_rounds - 1:
            return Action.D
        if current_round == 0:
            return Action.D
        prev_round_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        prev_round_cooperators_total = prev_round_cooperators + (1 if history.my_actions[current_round - 1] else 0)
        cpi = prev_round_cooperators_total / max(self.m, 1) if self.m > 0 else 0
        if prev_round_cooperators_total >= self.m:
            return Action.D
        elif prev_round_cooperators_total > 0:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_230(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Thresholds.
    
    Exploits the public goods structure by free-riding on others' cooperation when possible,
    while maintaining just enough cooperation to avoid collective failure when necessary.
    Uses adaptive defection with a safety valve: defaults to defection unless cooperation
    is needed to avoid falling below the threshold m. Always defects in the terminal round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == self.n_rounds - 1:
            return Action.D
        if current_round == 0:
            threshold_ratio = self.m / self.n_players
            if threshold_ratio <= 0.5:
                return Action.D
            else:
                return Action.C
        past_cooperations = []
        lookback_window = min(3, current_round)
        for i in range(current_round - lookback_window, current_round):
            if i >= 0:
                cooperators_in_round = int(np.sum(history.opponent_actions[i, :]))
                past_cooperations.append(cooperators_in_round)
        if len(past_cooperations) > 0:
            avg_cooperation = np.mean(past_cooperations)
        else:
            avg_cooperation = 0
        if avg_cooperation < self.m:
            return Action.C
        if avg_cooperation < self.m + 0.5:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_231(BaseStrategy):
    """
    CONDITIONAL FREELOAD: An exploitative strategy that free-rides on others' cooperation
    by defecting when confidence is high that m-1 others will cooperate, while adapting
    based on observed cooperation rates and round number.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.coop_counts = np.zeros(game_description.n_players - 1, dtype=np.int64)
        self.total_rounds_observed = 0
        self.last_round_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        self._update_cooperation_tracking(history, current_round)
        expected_cooperators = self._calculate_expected_cooperators()
        if expected_cooperators >= m - 1:
            return Action.D
        elif expected_cooperators < m - 1 and self.last_round_cooperators >= m:
            if current_round % 3 == 0:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _update_cooperation_tracking(self, history: PlayerHistory, current_round: int) -> None:
        """Update cooperation counts based on history up to current round."""
        if current_round <= 0:
            return
        opponent_actions_last_round = history.opponent_actions[current_round - 1, :]
        self.last_round_cooperators = int(np.sum(opponent_actions_last_round))
        for round_idx in range(current_round):
            opponent_actions = history.opponent_actions[round_idx, :]
            self.coop_counts += opponent_actions.astype(np.int64)
        self.total_rounds_observed = current_round

    def _calculate_expected_cooperators(self) -> float:
        """Calculate expected number of cooperators in next round based on history."""
        n = self.game_description.n_players
        num_opponents = n - 1
        if self.total_rounds_observed == 0 or num_opponents == 0:
            return 0.0
        total_cooperation_observations = np.sum(self.coop_counts)
        coop_rate = total_cooperation_observations / (num_opponents * self.total_rounds_observed)
        coop_rate = max(0.0, min(1.0, coop_rate))
        expected_cooperators = coop_rate * num_opponents
        return expected_cooperators

class Strategy_EXPLOITATIVE_232(BaseStrategy):
    """
    Adaptive Free-Riding with Conditional Defection strategy.
    
    Exploits the threshold mechanic by:
    1. Parasitically riding on others' cooperation when threshold is likely met
    2. Preemptively defecting when cooperation seems unlikely
    3. Adapting dynamically based on observed cooperation rates
    4. Always defecting in the last round (endgame betrayal)
    
    Core logic: Default to DEFECT unless strong evidence that others will
    fill the threshold without your contribution.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        t = state.round_number
        if t == 0:
            return Action.D
        if t == r - 1:
            return Action.D
        total_rounds_observed = t
        total_cooperators_observed = 0
        for round_idx in range(t):
            cooperators_in_round = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators_observed += cooperators_in_round
        if total_rounds_observed == 0 or n - 1 == 0:
            estimated_coop_rate = 0.0
        else:
            total_observations = total_rounds_observed * (n - 1)
            estimated_coop_rate = total_cooperators_observed / total_observations
        expected_next_coop = n * estimated_coop_rate
        return Action.D

class Strategy_EXPLOITATIVE_233(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD) Strategy for Collective Risk Dilemma.
    
    Exploits the payoff asymmetry by defecting unless evidence strongly suggests
    cooperation will reach threshold m without our contribution. Core tactics:
    - Round 1: Defect (observe baseline behavior)
    - Rounds 2 to r-1: Defect if cooperators >= m-1 (free-ride on near/at threshold)
    - Last round: Defect unconditionally (no reputational cost)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if self.m >= self.n_players:
            return Action.D
        if round_num == 0:
            return Action.D
        if round_num == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[round_num - 1, :]))
        if cooperators_last_round >= self.m - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_234(BaseStrategy):
    """
    Adaptive Threshold Predation: An exploitative strategy that systematically
    free-rides on cooperative clusters while maintaining plausible deniability
    through conditional defection. Always defects to maximize payoff by forcing
    others to bear the threshold burden.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.k = game_description.k
        self.n_rounds = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
        return Action.D

class Strategy_EXPLOITATIVE_235(BaseStrategy):
    """
    Adaptive Threshold Exploitation Strategy for Collective Risk Dilemma.
    
    Exploits cooperative players by:
    1. Defaulting to defection to avoid costs
    2. Free-riding on others' cooperation when threshold is met
    3. Maintaining minimal cooperation only when necessary to preserve benefit-generating state
    4. Always defecting in the final round regardless of game state
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_round_coop_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        if history is not None and current_round > 0:
            prev_round_opponent_actions = history.opponent_actions[current_round - 1, :]
            prev_round_opponent_coop_count = int(np.sum(prev_round_opponent_actions))
            prev_round_own_action = history.my_actions[current_round - 1]
            prev_round_total_coop = prev_round_opponent_coop_count + int(prev_round_own_action)
            coop_rate = prev_round_total_coop / n
            threshold_margin = (m - 1) / n
            if coop_rate >= threshold_margin:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_236(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD): An exploitative strategy that maximizes
    payoffs by free-riding on others' cooperation while minimizing personal
    contribution. Uses observed cooperation patterns to predict when the threshold
    will be met and defects accordingly.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold_adapt = (self.m - 1) / self.n if self.n > 0 else 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round <= 1:
            return Action.D
        if current_round >= self.r - 2:
            return Action.D
        if history is None:
            return Action.D
        cooperation_rounds = 0
        rounds_observed = len(history.my_actions)
        if rounds_observed == 0:
            return Action.D
        for round_idx in range(rounds_observed):
            cooperators_in_round = np.sum(history.opponent_actions[round_idx, :])
            if cooperators_in_round >= self.m:
                cooperation_rounds += 1
        cooperation_rate = cooperation_rounds / rounds_observed
        if cooperation_rate > self.threshold_adapt:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_237(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation
    
    Exploits asymmetric payoffs by free-riding on opponent cooperation while
    minimizing own contribution costs. Adapts based on historical cooperation
    sustainability metrics (CSM) to determine optimal defection or minimal cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        csm = self._calculate_csm(history, current_round)
        if csm >= 0.8:
            return Action.D
        elif csm < 0.5:
            return Action.D
        elif current_round % 3 == 0:
            return Action.C
        else:
            return Action.D

    def _calculate_csm(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate Cooperation Sustainability Metric (CSM).
        CSM = (# of prior rounds where â‰¥m players cooperated) / (current_round)
        
        Returns float in [0, 1] or 0 if no prior rounds.
        """
        if current_round <= 0:
            return 0.0
        threshold_hits = 0
        for round_idx in range(current_round):
            opponent_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
            total_cooperators = opponent_cooperators + int(history.my_actions[round_idx])
            if total_cooperators >= self.m:
                threshold_hits += 1
        csm = threshold_hits / current_round
        return csm

class Strategy_EXPLOITATIVE_238(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Defection Strategy.
    
    Exploits the threshold mechanism by defecting whenever possible:
    - Round 1: Defect to gather information
    - Rounds 2+: Defect if threshold met (free-ride) or if threshold unattainable (dominance)
    - Last round: Always defect (no reputational value)
    
    This strategy maximizes payoff by parasitizing cooperative players who meet
    the threshold while avoiding wasted cooperation when the threshold is unreachable.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        prev_round_idx = state.round_number - 1
        cooperators_prev = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        return Action.D

class Strategy_EXPLOITATIVE_239(BaseStrategy):
    """
    Adaptive Threshold Parasitism: An exploitative strategy that defects to free-ride
    on others' cooperation while minimizing personal risk contribution.
    
    Core principle: Treat other players as resources to harvest rather than partners.
    Always defect except when defection would be suboptimal, which never occurs in this game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[-1, :]))
        if cooperators_last_round >= self.game_description.m:
            return Action.D
        if cooperators_last_round < self.game_description.m:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_240(BaseStrategy):
    """
    Adaptive Threshold Exploitation (ATE) Strategy
    
    Exploits the asymmetry in the Collective Risk Dilemma by:
    1. Always defecting in round 1 and final round
    2. Free-riding on others' cooperation when threshold is met
    3. Defecting strategically to maintain high payoff
    4. Occasionally cooperating to bootstrap cooperation after collapse
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_low_coop_rounds = 0
        self.last_bootstrap_round = -10

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if state.round_number == 0:
            return Action.D
        if state.round_number == r - 1:
            return Action.D
        prev_round_idx = state.round_number - 1
        coop_count_prev = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        coop_rate = coop_count_prev / (n - 1) if n > 1 else 0.0
        threshold_met_last = coop_count_prev >= m
        decision = Action.D
        rounds_remaining = r - state.round_number
        low_coop_threshold = max(0, (m - 2) / n)
        if coop_rate < low_coop_threshold:
            self.consecutive_low_coop_rounds += 1
        else:
            self.consecutive_low_coop_rounds = 0
        if self.consecutive_low_coop_rounds >= 2 and rounds_remaining >= 3 and (state.round_number - self.last_bootstrap_round >= 3):
            decision = Action.C
            self.last_bootstrap_round = state.round_number
            self.consecutive_low_coop_rounds = 0
        else:
            decision = Action.D
        return decision

class Strategy_EXPLOITATIVE_241(BaseStrategy):
    """
    Conditional Defection with Opportunistic Parasitism.
    
    Exploits the payoff asymmetry by always defecting:
    - When threshold is met by others, capture k+1 instead of k
    - When threshold is not met, defection (payoff=1) is equivalent to cooperation
    - Never contribute; free-ride on others' cooperation when possible
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperators_last_round = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[-1, :]))
        if cooperators_last_round >= self.game_description.m:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_242(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Threshold strategy.
    
    Exploits the threshold mechanism by identifying reliable cooperation from others,
    then systematically free-riding while avoiding mutual defection traps.
    Uses probabilistic and history-based decisions to maximize payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.coop_observations = []
        self.defection_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if round_num == 0:
            return Action.D
        if round_num == r - 1:
            return Action.D
        opponent_actions = history.opponent_actions
        for round_idx in range(round_num):
            cooperators_this_round = np.sum(opponent_actions[round_idx, :])
            self.coop_observations.append(cooperators_this_round)
        if len(self.coop_observations) > 0:
            avg_cooperators = np.mean(self.coop_observations)
            coop_rate = avg_cooperators / (n - 1)
        else:
            coop_rate = 0.0
        threshold_prob = m / n
        if coop_rate >= threshold_prob + 0.15:
            return Action.D
        elif coop_rate <= threshold_prob - 0.15:
            if self.defection_count >= 2:
                self.defection_count = 0
                return Action.C
            else:
                self.defection_count += 1
                return Action.D
        else:
            expected_others_coop = avg_cooperators if len(self.coop_observations) > 0 else 0
            required_coop = m - expected_others_coop
            if required_coop <= 0:
                return Action.D
            else:
                prob_defect = max(0.0, 1.0 - required_coop / n)
                if random.random() < prob_defect:
                    self.defection_count += 1
                    return Action.D
                else:
                    self.defection_count = 0
                    return Action.C

class Strategy_EXPLOITATIVE_243(BaseStrategy):
    """
    Adaptive Threshold Hunter: An exploitative strategy that free-rides on others' cooperation.
    
    Core approach:
    - Round 1: Defect to probe the environment
    - Rounds 2 to r-1: Defect when threshold was met last round (free-ride), otherwise defect
    - Final round: Always defect (no future punishment)
    
    This strategy systematically extracts value by gaining 1+k when others meet the threshold,
    while never bearing the cost of cooperation (always keeping the full endowment).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        last_round_actions = history.opponent_actions[state.round_number - 1, :]
        cooperators_last_round = int(np.sum(last_round_actions))
        m = self.game_description.m
        if cooperators_last_round >= m:
            return Action.D
        elif cooperators_last_round == m - 1:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_244(BaseStrategy):
    """
    Calculated Defection with Conditional Exploitation.
    
    A rational parasitism strategy that defects by default to free-ride on others' 
    cooperation, but conditionally cooperates only when the cooperation pool is 
    threatened and close to falling below the threshold m. Never cooperates in 
    the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == self.n_rounds - 1:
            return Action.D
        if current_round == 0:
            return Action.D
        previous_round_idx = current_round - 1
        cooperators_last_round = int(sum(history.opponent_actions[previous_round_idx, :]))
        if history.my_actions[previous_round_idx]:
            cooperators_last_round += 1
        deficit = self.m - cooperators_last_round
        if deficit > 0 and deficit <= 2:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_245(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Free-Riding with Threshold Exploitation
    
    Systematically free-rides when cooperation is likely, while minimizing losses
    when cooperation fails. Exploits the collective action problem by treating
    other players' cooperation as a resource to extract value from.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        total_cooperators = int(np.sum(history.opponent_actions))
        previous_rounds = current_round
        coop_rate = total_cooperators / (self.n * previous_rounds) if previous_rounds > 0 else 0.0
        exploitation_threshold = self.m / self.n
        if self.m / self.n > 0.75:
            buffer = 0.1 * self.m / self.n
        elif self.m / self.n < 0.25:
            buffer = 0.2 * self.m / self.n
        else:
            buffer = 0.15 * self.m / self.n
        collapse_threshold = (self.m - 1) / self.n if self.m > 1 else 0.0
        if coop_rate < collapse_threshold:
            return Action.D
        if current_round > self.r - 3:
            exploitation_threshold = exploitation_threshold * 0.95
        if coop_rate >= exploitation_threshold + buffer:
            return Action.D
        elif coop_rate < exploitation_threshold - buffer:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_246(BaseStrategy):
    """
    Adaptive Defection with Conditional Free-Riding (Exploitative Strategy)
    
    This strategy exploits the payoff asymmetry in the Collective Risk Dilemma by:
    - Always defecting to free-ride on others' cooperation when the threshold is met
    - Securing baseline payoff (1) when cooperation is insufficient
    - Never cooperating, as defection strictly dominates in all rounds
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.r - 1:
            return Action.D
        prev_round_cooperators = int(sum(history.opponent_actions[state.round_number - 1, :]))
        cooperation_rate = prev_round_cooperators / max(self.n, 1)
        threshold = (self.m + 1) / self.n if self.n > 0 else 0
        return Action.D

class Strategy_EXPLOITATIVE_247(BaseStrategy):
    """
    Conditional Free-Rider: An exploitative strategy that minimizes personal contribution
    while parasitically benefiting from others' cooperation. Defects by default, with
    selective probabilistic cooperation only when exactly m-1 cooperators are observed,
    to manipulate thresholds and maintain the appearance of unpredictability.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[-1, :]))
        if cooperators_last_round >= self.m:
            return Action.D
        elif cooperators_last_round == self.m - 1:
            denominator = 2 * self.m
            if denominator > 0:
                cooperation_prob = 1.0 / denominator
            else:
                cooperation_prob = 0.0
            if random.random() < cooperation_prob:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_248(BaseStrategy):
    """
    Adaptive Threshold Exploitation (ATE) Strategy
    
    Exploits the collective risk dilemma by free-riding on others' cooperation
    when the threshold is met, while minimizing own contribution costs. Dynamically
    calibrates defection based on observed cooperation rates.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        prev_round_idx = current_round - 1
        cooperators_prev = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        coop_rate = cooperators_prev / self.n
        threshold_rate = self.m / self.n
        near_threshold_rate = (self.m - 1) / self.n
        if coop_rate >= threshold_rate:
            return Action.D
        elif coop_rate >= near_threshold_rate:
            defectors_prev = self.n - cooperators_prev
            if defectors_prev < 2:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_249(BaseStrategy):
    """
    Conditional Free-Rider with Adaptive Defection strategy.
    
    Exploits the threshold mechanic by free-riding when cooperation is likely,
    while defecting preemptively when cooperation seems insufficient.
    Core principle: DEFECT in all rounds to maximize individual payoff by
    extracting value from others' contributions while minimizing own investment.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        last_round_actions = history.opponent_actions[state.round_number - 1, :]
        cooperators_last_round = int(np.sum(last_round_actions))
        m = self.game_description.m
        if cooperators_last_round >= m:
            return Action.D
        elif cooperators_last_round == m - 1:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_250(BaseStrategy):
    """
    Adaptive Defection with Conditional Cooperation strategy for Collective Risk Dilemma.
    
    Core philosophy: Maximize personal payoff by exploiting the asymmetry between cooperators 
    and defectors. Always defect to capture the (1 + k) payoff when threshold is met, while 
    preserving the minimum payoff of 1 when threshold is not met.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.n_rounds - 1:
            return Action.D
        previous_round_idx = state.round_number - 1
        cooperators_previous_round = np.sum(history.opponent_actions[previous_round_idx, :])
        return Action.D

class Strategy_EXPLOITATIVE_251(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD): An exploitative strategy that observes opponent
    cooperation rates and defects when profitable, cooperates only when pivotal to reach
    the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold_high = 0.65
        self.threshold_low = 0.35

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        n = self.game_description.n_players
        m = self.game_description.m
        total_cooperations = np.sum(history.opponent_actions)
        total_observations = state.round_number * (n - 1)
        if total_observations == 0:
            coop_rate = 0.0
        else:
            coop_rate = total_cooperations / total_observations
        if coop_rate >= self.threshold_high:
            return Action.D
        elif coop_rate <= self.threshold_low:
            return Action.D
        else:
            expected_cooperators = (n - 1) * coop_rate
            if expected_cooperators >= m - 1:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_252(BaseStrategy):
    """
    Exploitative Strategy: Conditional Free-Riding with Adaptive Defection
    
    Core philosophy: Maximize payoff by free-riding on others' cooperation
    while minimally contributing. Always defects except in carefully calculated
    near-threshold situations that are also exploitative.
    
    Phase 1 (Rounds 1-3): Explore and calibrate by defecting
    Phase 2 (Rounds 4 to r-1): Adaptively exploit based on cooperation counts
    Phase 3 (Final round): Always defect (dominant strategy)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        previous_round_cooperators = int(sum(history.opponent_actions[state.round_number - 1, :]))
        m = self.game_description.m
        if previous_round_cooperators >= m:
            return Action.D
        if previous_round_cooperators >= m - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_253(BaseStrategy):
    """
    Conditional Free-Rider with Adaptive Pivoting: An exploitative strategy that 
    minimizes cooperation while positioning itself as pivotal to extract maximum payoff.
    Adapts across three phases: intelligence gathering, exploitation & pivoting, and endgame.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        phase_1_end = max(1, math.ceil(self.r / 3))
        phase_2_end = max(phase_1_end + 1, math.ceil(2 * self.r / 3))
        if round_num < phase_1_end:
            return self._phase_1_decision(round_num, history)
        elif round_num < phase_2_end:
            return self._phase_2_decision(round_num, history)
        else:
            return self._phase_3_decision(round_num, history)

    def _phase_1_decision(self, round_num: int, history: PlayerHistory) -> Action:
        """Phase 1: Early game intelligence gathering. Always defect."""
        return Action.D

    def _phase_2_decision(self, round_num: int, history: PlayerHistory) -> Action:
        """Phase 2: Exploitation & pivoting based on expected cooperators."""
        expected_cooperators = self._calculate_expected_cooperators(history)
        if expected_cooperators >= self.m:
            return Action.D
        elif expected_cooperators == self.m - 1:
            return Action.D
        else:
            if self.n - 1 > 0:
                p_coop = (self.m - expected_cooperators) / (self.n - 1)
                p_coop = max(0.0, min(1.0, p_coop))
                if random.random() < p_coop:
                    return Action.C
            return Action.D

    def _phase_3_decision(self, round_num: int, history: PlayerHistory) -> Action:
        """Phase 3: Endgame exploitation."""
        if round_num == self.r - 1:
            my_score = float(np.sum(history.my_payoffs))
            opponent_scores = np.sum(history.opponent_payoffs, axis=1)
            if len(opponent_scores) > 0:
                median_score = float(np.median(opponent_scores))
                if my_score < median_score:
                    return Action.C
            return Action.D
        else:
            return Action.D

    def _calculate_expected_cooperators(self, history: PlayerHistory) -> float:
        """
        Calculate the average number of cooperators per round in previous rounds.
        Returns a float representing expected cooperators based on observed history.
        """
        if history.opponent_actions.shape[0] == 0:
            return 0.0
        cooperators_per_round = np.sum(history.opponent_actions, axis=1)
        avg_opponent_cooperators = float(np.mean(cooperators_per_round))
        return avg_opponent_cooperators

class Strategy_EXPLOITATIVE_254(BaseStrategy):
    """
    Adaptive Threshold Exploitation strategy for Collective Risk Dilemma.
    
    Exploits the asymmetry in payoff structure by:
    - Defecting in round 1 and final round (no reputation cost)
    - Free-riding when threshold appears safely achievable
    - Defecting when threshold appears unachievable
    - Cooperating only when genuinely pivotal in middle rounds
    - Using adaptive moving average of recent cooperation rates
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold_buffer = max(1, math.ceil(self.n * 0.15)) / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        recent_rounds_count = min(3, current_round)
        recent_history = history.opponent_actions[-recent_rounds_count:, :]
        total_cooperators = np.sum(recent_history)
        total_plays = recent_rounds_count * self.n
        if total_plays == 0:
            avg_cooperation_rate = 0.0
        else:
            avg_cooperation_rate = total_cooperators / total_plays
        threshold_needed = self.m / self.n
        if avg_cooperation_rate >= threshold_needed + self.threshold_buffer:
            return Action.D
        if avg_cooperation_rate < threshold_needed - self.threshold_buffer:
            return Action.D
        current_cooperators = avg_cooperation_rate * self.n
        defectors_needed = self.m - current_cooperators
        if defectors_needed <= 1.0:
            return Action.D
        return Action.C

class Strategy_EXPLOITATIVE_255(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Free-Riding with Threshold Exploitation
    
    This strategy ruthlessly extracts value by defecting when the cooperation threshold
    is met by others, while probing in round 1 and adapting based on observed cooperator counts.
    Core philosophy: free-ride on others' contributions whenever safe to do so.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[round_number - 1, :]))
        if round_number == self.n_rounds - 1:
            if cooperators_last_round >= self.m - 1:
                return Action.D
            else:
                return Action.D
        if cooperators_last_round >= self.m:
            return Action.D
        elif cooperators_last_round == self.m - 1:
            if random.random() < 0.9:
                return Action.D
            else:
                return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_256(BaseStrategy):
    """
    Adaptive Defection with Conditional Cooperation.
    
    Exploits the asymmetry in payoff structure by:
    1. Always defecting in round 1 and final round
    2. Exploiting when threshold is met (cooperation_count >= m)
    3. Free-riding when near-threshold (cooperation_count == m-1)
    4. Minimal probabilistic cooperation otherwise
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.n_rounds - 1:
            return Action.D
        cooperation_count = int(sum(history.opponent_actions[round_num - 1, :]))
        if cooperation_count >= self.m:
            return Action.D
        if cooperation_count == self.m - 1:
            return Action.D
        deficit = self.m - cooperation_count
        if self.n_players > 0:
            p_adaptive = min(0.3, deficit / self.n_players)
        else:
            p_adaptive = 0.0
        if random.random() < p_adaptive:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_257(BaseStrategy):
    """
    Adaptive Threshold Parasitism: A dominant strategy that always defects.
    
    This strategy exploits the game structure where defection is strictly dominant
    in every game state. By defecting, the player either:
    - Gets payoff of 1 when threshold is not met (same as if cooperating at cost)
    - Gets payoff of 1+k when threshold is met by others (better than 0+k from cooperating)
    
    The strategy always defects, capturing maximum surplus from others' cooperation
    while avoiding all costs of contribution.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_258(BaseStrategy):
    """
    Exploitative Strategy: Conditional Free-Riding with Adaptive Defection
    
    Core philosophy: Exploit the threshold mechanism by free-riding on others' 
    cooperation while minimizing commitment. Cooperate only when necessary to 
    trigger the threshold (m-th player), then defect to capture the bonus without 
    contributing.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
        if cooperators_last_round >= self.m:
            return Action.D
        if cooperators_last_round == self.m - 1:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_259(BaseStrategy):
    """
    Adaptive Threshold Extraction strategy for Collective Risk Dilemma.
    
    Exploits the asymmetry in payoff structure by:
    1. Defecting in round 1 to gather information
    2. Tracking cooperation rates and adapting extraction timing
    3. Free-riding when threshold is predictably met
    4. Becoming pivotal cooperator only when necessary for threshold
    5. Unconditionally defecting in final round
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.r - 1:
            return Action.D
        observed_cooperations = np.sum(history.opponent_actions[:round_number, :])
        rounds_elapsed = round_number
        if rounds_elapsed == 0 or self.n == 1:
            return Action.D
        coop_rate = observed_cooperations / ((self.n - 1) * rounds_elapsed)
        expected_cooperators = coop_rate * (self.n - 1)
        if expected_cooperators >= self.m:
            return Action.D
        elif abs(expected_cooperators - (self.m - 1)) < 1e-09 or (expected_cooperators >= self.m - 1 - 1e-09 and expected_cooperators < self.m):
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_260(BaseStrategy):
    """
    Adaptive Free-Riding with Threshold Exploitation strategy.
    
    Exploits the payoff asymmetry in collective risk dilemmas by defaulting to defection
    while strategically monitoring cooperation rates. Cooperates only when the threshold
    is virtually guaranteed to be met, or defects to free-ride on others' cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.safety_margin = math.ceil(0.2 * self.n)
        self.threshold_ratio = (self.m + self.safety_margin) / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        last_round_actions = history.opponent_actions[current_round - 1, :]
        coop_count = int(np.sum(last_round_actions))
        coop_rate = coop_count / self.n if self.n > 0 else 0.0
        window_size = min(3, current_round)
        recent_coop_counts = np.sum(history.opponent_actions[max(0, current_round - window_size):current_round, :], axis=1)
        expected_coop_rate = float(np.mean(recent_coop_counts)) / self.n if self.n > 0 else 0.0
        if expected_coop_rate > 0:
            risk_score = 1.0 - coop_rate / expected_coop_rate
            risk_score = max(0.0, min(1.0, risk_score))
        else:
            risk_score = 1.0 if coop_rate == 0 else 0.0
        if coop_count >= self.m - 1 or coop_rate >= self.threshold_ratio:
            return Action.D
        elif risk_score > 0.6:
            return Action.D
        elif risk_score < 0.2 and coop_count == self.m - 1:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_261(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Opportunistic Free-Riding
    
    Defects by default, only cooperating when mathematically necessary to unlock
    the reward threshold. Unconditionally defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        total_cooperators = 0
        for round_idx in range(current_round):
            round_cooperators = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += round_cooperators
        coop_rate = total_cooperators / max(1, current_round * self.n_players)
        threshold_rate = self.m / self.n_players
        last_round_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if coop_rate >= threshold_rate:
            return Action.D
        elif last_round_cooperators == self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_262(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Exploitation.
    
    Exploits the threshold mechanism by defecting when cooperation is likely,
    while avoiding contribution costs. Maximizes payoff by free-riding on others'
    cooperation when the threshold is met, and defecting when it's not.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.consecutive_low_cooperation_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.n_rounds - 1:
            return Action.D
        c_prev = int(np.sum(history.opponent_actions[state.round_number - 1, :]))
        if c_prev < self.m - 2:
            self.consecutive_low_cooperation_rounds += 1
            if self.consecutive_low_cooperation_rounds >= 2:
                return Action.D
        else:
            self.consecutive_low_cooperation_rounds = 0
        if c_prev >= self.m:
            return Action.D
        if c_prev == self.m - 1:
            return Action.D
        if c_prev >= self.m - 2 and state.round_number < 0.75 * self.n_rounds:
            return Action.D
        if c_prev < self.m - 2:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_263(BaseStrategy):
    """
    Conditional Parasitism with Adaptive Defection strategy.
    
    Exploits the threshold structure by free-riding when cooperation threshold is met,
    avoiding marginal cooperation, and defecting in end-game scenarios.
    Core mechanism: systematically extract asymmetric payoffs (1 + k vs k) by defecting
    when threshold is achieved, while suppressing cooperation through early unpredictability.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round >= self.n_rounds - 2:
            return Action.D
        prev_round_idx = current_round - 1
        prev_cooperation_count = int(sum(history.opponent_actions[prev_round_idx, :]))
        if prev_cooperation_count >= self.m:
            return Action.D
        if prev_cooperation_count == self.m - 1:
            return Action.D
        if prev_cooperation_count < self.m - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_264(BaseStrategy):
    """
    Adaptive Threshold Exploitation Strategy for Collective Risk Dilemma.
    
    Exploits the asymmetry in payoffs by defecting when the threshold is already met
    (free-riding on others) and cooperating only when pivotal (c_hist == m-1).
    Unconditionally defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[round_number - 1, :]))
        if cooperators_last_round >= self.m:
            return Action.D
        elif cooperators_last_round == self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_265(BaseStrategy):
    """
    Exploitative Strategy: Conditional Free-Riding with Dynamic Threshold Adjustment
    
    Exploits payoff asymmetry by defecting when threshold success is observable,
    cooperating minimally only when necessary, and always defecting when punishment
    is impossible (final round).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        current_round = state.round_number
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if self.m == 1:
            return Action.D
        if self.m == self.n_players:
            return Action.D
        if cooperators_last_round >= self.m:
            return Action.D
        if cooperators_last_round == self.m - 1:
            progress_ratio = current_round / self.n_rounds
            is_late_game = progress_ratio > 0.75
            has_volatile_cooperation = False
            if current_round >= 2:
                coop_two_rounds_ago = int(np.sum(history.opponent_actions[current_round - 2, :]))
                coop_last_round = cooperators_last_round
                has_volatile_cooperation = abs(coop_last_round - coop_two_rounds_ago) > self.n_players * 0.3
            if is_late_game or has_volatile_cooperation:
                return Action.D
            else:
                return Action.C
        if cooperators_last_round < self.m - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_266(BaseStrategy):
    """
    Adaptive Free-Riding with Conditional Defection strategy.
    
    Exploits the threshold structure of the Collective Risk Dilemma by:
    1. Defecting whenever the cooperation threshold is met (free-riding on others' contributions)
    2. Using minimal probabilistic cooperation in early rounds to signal cooperativeness
    3. Always defecting in the terminal round to maximize final payoff
    
    The core exploitation: once m cooperators exist, defectors capture reward k without 
    paying cost c, making additional cooperation economically irrational.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        if current_round == 0:
            if self.n > 6:
                return Action.D
            if random.random() < 1.0 / self.n:
                return Action.C
            return Action.D
        if current_round == 1:
            prev_cooperators = int(sum(history.opponent_actions[0, :]))
            if history.my_actions[0]:
                prev_cooperators += 1
            if prev_cooperators >= self.m:
                return Action.D
            elif prev_cooperators > 0:
                return Action.D
            else:
                if random.random() < 1.0 / max(1, self.n - 1):
                    return Action.C
                return Action.D
        prev_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        if history.my_actions[current_round - 1]:
            prev_cooperators += 1
        if prev_cooperators >= self.m:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_267(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Free-Riding with Dynamic Threshold Exploitation
    
    This strategy maximizes personal payoff by parasitically free-riding when others meet
    the threshold, strategically defecting early to avoid wasting endowment, and exploiting
    predictable cooperation patterns in repeated rounds.
    
    Core approach: ALWAYS DEFECT
    - Round 1: Defect to establish baseline and observe cooperator types
    - Rounds 2 to r-1: Defect to free-ride on others' cooperation or avoid wasting endowment
    - Last round: Defect with no future punishment concerns
    
    This guarantees capturing asymmetric payoffs (1 + k when threshold met by others,
    or at least 1 when threshold not met) while avoiding the sucker's payoff of 0.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        previous_round_idx = state.round_number - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[previous_round_idx, :]))
        return Action.D

class Strategy_EXPLOITATIVE_268(BaseStrategy):
    """
    Adaptive Threshold Pivot: An exploitative strategy that defaults to defection
    while free-riding on others' cooperation, then conditionally cooperates when
    thresholds fail, and terminally exploits in the final rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        prev_coop_count = int(np.sum(history.opponent_actions[current_round - 1, :]))
        rounds_remaining = self.n_rounds - current_round
        if current_round <= self.n_rounds - 3:
            if prev_coop_count < self.m and rounds_remaining >= 2:
                return Action.C
            else:
                return Action.D
        elif current_round == self.n_rounds - 2:
            if prev_coop_count >= self.m:
                return Action.D
            else:
                return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_269(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Thresholds
    
    Exploits threshold asymmetry by:
    - Cooperating in round 1 to gather information
    - Defecting when others reach threshold m (capturing 1+k at zero cost)
    - Free-riding on marginal cooperators when C_prev = m-1
    - Unconditionally defecting in the final round
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == r - 1:
            return Action.D
        previous_round_index = current_round - 1
        cooperators_prev = int(sum(history.opponent_actions[previous_round_index, :]))
        if cooperators_prev >= m:
            return Action.D
        elif cooperators_prev == m - 1:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_270(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation
    
    Core philosophy: Exploit asymmetry in payoffs by defecting by default while
    cooperating only when necessary to trigger the threshold or when observable
    patterns guarantee others will cooperate. Maximizes individual extraction
    through free-riding on others' contributions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        rounds_remaining = self.n_rounds - current_round
        coop_prev = int(sum(history.opponent_actions[current_round - 1, :]))
        if current_round == self.n_rounds - 1:
            return Action.D
        if coop_prev >= self.m - 1 and rounds_remaining > 1:
            recent_threshold_hits = 0
            lookback_window = min(3, current_round)
            for i in range(max(0, current_round - lookback_window), current_round):
                if int(sum(history.opponent_actions[i, :])) >= self.m:
                    recent_threshold_hits += 1
            if recent_threshold_hits >= 2:
                return Action.D
            if coop_prev >= self.m - 1:
                return Action.C
        if current_round < self.n_rounds // 2 and coop_prev < self.m // 2:
            if rounds_remaining > 2:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_271(BaseStrategy):
    """
    Exploitative Free-Riding with Adaptive Threshold Monitoring.
    
    Core strategy: Defect by default to exploit others' cooperation when the
    threshold is met, while avoiding losses when cooperation fails. In the final
    round, always defect due to end-game dominance (no future reputation effects).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        m = self.game_description.m
        k = self.game_description.k
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        previous_round_index = current_round - 1
        previous_cooperation_count = int(np.sum(history.opponent_actions[previous_round_index, :]))
        if previous_cooperation_count >= m:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_272(BaseStrategy):
    """
    Exploitative Strategy: Conditional Free-Riding with Adaptive Defection
    
    Maximizes personal payoff by exploiting the threshold mechanism through:
    1. Free-riding when cooperation threshold is met or nearly met
    2. Conditional cooperation only when threshold is within 2 of being met and failures are rare
    3. Adaptive switching to pure defection on repeated threshold failures
    4. Always defecting in the final round to avoid sunk costs
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.failed_threshold_count = 0
        self.near_threshold_attempts = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[state.round_number - 1, :]))
        m = self.game_description.m
        k = self.game_description.k
        if cooperators_last_round >= m:
            return Action.D
        if cooperators_last_round >= m - 1:
            return Action.D
        if cooperators_last_round >= m - 2:
            if self.failed_threshold_count >= 3:
                return Action.D
            else:
                self.near_threshold_attempts += 1
                if cooperators_last_round < m - 1:
                    self.failed_threshold_count += 1
                return Action.C
        if cooperators_last_round < m - 2:
            self.failed_threshold_count += 1
        return Action.D

class Strategy_EXPLOITATIVE_273(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Defection strategy for Collective Risk Dilemma.
    
    Exploits the threshold mechanism by:
    1. Defecting in round 1 to gather information
    2. Free-riding when threshold is met (others cooperate)
    3. Strategically cooperating occasionally when threshold is low to prevent mutual defection traps
    4. Unconditionally defecting in the final round
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        previous_round_idx = round_number - 1
        cooperators_last_round = sum(history.opponent_actions[previous_round_idx, :])
        coop_rate = cooperators_last_round / self.n_players
        threshold_rate = self.m / self.n_players
        near_threshold_rate = (self.m - 1) / self.n_players
        if self.m == self.n_players:
            return Action.D
        if self.m == 2 and self.n_players >= 4:
            return Action.D
        we_defected_last_round = not history.my_actions[previous_round_idx]
        if coop_rate >= threshold_rate:
            return Action.D
        elif coop_rate >= near_threshold_rate:
            return Action.D
        else:
            rounds_remaining = self.n_rounds - round_number - 1
            if rounds_remaining <= 2:
                return Action.D
            if round_number % 3 == 0:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_274(BaseStrategy):
    """
    Adaptive Defection with Conditional Contribution (ADCC).
    
    Exploitative strategy that free-rides on cooperators when threshold is met,
    strategically cooperates only when necessary to secure rewards, and always
    defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold_sensitivity = max(2, math.ceil(self.r / 4))
        self.cooperation_memory = min(5, self.r - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.D
        if round_t == self.r - 1:
            return Action.D
        prev_cooperators = int(np.sum(history.opponent_actions[round_t - 1, :]))
        if prev_cooperators >= self.m:
            return Action.D
        rounds_to_check = min(self.cooperation_memory, round_t)
        if rounds_to_check > 0:
            recent_actions = history.opponent_actions[max(0, round_t - rounds_to_check):round_t, :]
            recent_coop_rate = np.sum(recent_actions) / (rounds_to_check * self.n)
        else:
            recent_coop_rate = 0.0
        if recent_coop_rate < 0.5 and prev_cooperators < self.m:
            return Action.D
        rounds_remaining = self.r - round_t - 1
        if prev_cooperators < self.m and rounds_remaining <= self.threshold_sensitivity:
            if rounds_to_check > 1:
                estimated_future_coop = np.mean(np.sum(history.opponent_actions[max(0, round_t - 3):round_t, :], axis=1))
            else:
                estimated_future_coop = prev_cooperators
            if estimated_future_coop < self.m:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_275(BaseStrategy):
    """
    Adaptive Defection with Conditional Free-riding Strategy.
    
    Exploits the threshold mechanism by:
    1. Always defecting in round 1 to establish non-cooperator status
    2. In rounds 2 to r-1: defecting always (free-ride if threshold met, avoid wasted cooperation otherwise)
    3. In the final round: defecting (no future punishment possible)
    
    This maximizes payoff by capturing k+1 when m+ cooperators exist (through free-riding)
    while matching the floor payoff of 1 when threshold is unmet.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round < self.n_rounds - 1:
            cooperators_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_276(BaseStrategy):
    """
    Adaptive Free-Riding with Threshold Exploitation.
    
    Exploits the threshold structure by consistently defecting to free-ride when 
    cooperation is likely, while avoiding wasted contributions when cooperation fails.
    The strategy defects unconditionally across all rounds, capturing rewards from 
    others' cooperation without bearing costs.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_277(BaseStrategy):
    """
    Adaptive Freeload Strategy for Collective Risk Dilemma.
    
    Exploits the threshold mechanism by always defecting to free-ride on others' 
    cooperation. Systematically captures rewards (k) without contributing (c).
    Core logic: defect always, since it's never worse than cooperation and often 
    strictly better when others reach the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_278(BaseStrategy):
    """
    Conditional Free-Rider with Adaptive Defection strategy.
    
    Exploits the threshold mechanism by:
    1. Always defecting to free-ride on others' cooperation
    2. Capturing rewards when threshold is met without contributing
    3. Never voluntarily cooperating (defection dominates)
    4. Adapting defection intensity based on observed cooperation rates
    
    Core logic: Defect is strictly dominant (payoff 1+k vs k when threshold met),
    so always defect regardless of history or round number.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_rate = self.m / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        """
        Decision logic for each round.
        
        Strategy: ALWAYS DEFECT
        - Round 0: Defect (no information, probe for unconditional cooperators)
        - Rounds 1 to r-2: Defect (free-ride when threshold likely met)
        - Round r-1: Defect (extract final value, no future retaliation)
        
        Rationale: Defecting when m+ cooperate gives payoff (1 + k),
        while cooperating gives only (k). The difference of 1 is always
        in favor of defection.
        """
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.n_rounds - 1:
            return Action.D
        if history is not None and state.round_number > 0:
            previous_cooperators = int(np.sum(history.opponent_actions[state.round_number - 1, :]))
            cooperation_rate = previous_cooperators / self.n_players
            if state.round_number >= 2:
                recent_history = history.opponent_actions[max(0, state.round_number - 3):state.round_number, :]
                cooperators_per_round = np.sum(recent_history, axis=1)
        return Action.D

class Strategy_EXPLOITATIVE_279(BaseStrategy):
    """
    Adaptive Defection with Conditional Cooperation strategy for Collective Risk Dilemma.
    
    Exploits the payoff asymmetry where defectors earn k+1 while cooperators earn k when
    the threshold m is met. Defects by default except when exactly m-1 cooperators were
    observed in the previous round, in which case it cooperates to unlock the reward.
    Always defects in round 1 and the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        if history is not None:
            previous_round_index = current_round - 1
            cooperators_last_round = int(np.sum(history.opponent_actions[previous_round_index, :]))
            if cooperators_last_round == self.m - 1:
                return Action.C
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_280(BaseStrategy):
    """
    Conditional Predation: An exploitative strategy that always defects.
    
    Defection is dominant in the Collective Risk Dilemma:
    - Round 1: Play D to gather information without paying cooperation cost
    - Rounds 2 to r-1: Play D to free-ride on any cooperative threshold or avoid cooperation cost
    - Final round: Play D to extract terminal exploitation without future consequences
    
    This strategy never initiates cooperation, exploits naive cooperators by defecting
    when threshold is met, and maintains safety against all opponent types through pure defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_281(BaseStrategy):
    """
    Adaptive Free-Riding with Threshold Monitoring.
    
    Exploits the asymmetry in payoffs by defecting when the cooperation threshold
    is likely to be met, free-riding on others' contributions. Uses stochastic noise
    in middle rounds for unpredictability and includes aggressive end-game defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = []
        self.last_round_cooperators = 0
        self.threshold_met_last_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        k = self.game_description.k
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        prev_round_idx = current_round - 1
        cooperators_prev = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        self.last_round_cooperators = cooperators_prev
        self.threshold_met_last_round = cooperators_prev >= m
        cooperation_rate = self._calculate_cooperation_rate(history, current_round)
        self.cooperation_history.append(cooperation_rate)
        if current_round == r - 1:
            return self._final_round_decision(cooperation_rate, m, n)
        return self._middle_round_decision(cooperation_rate, m, n, k, current_round, prev_round_idx, history)

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """Calculate weighted cooperation rate from all observed rounds."""
        if current_round == 0:
            return 0.0
        total_cooperators = 0
        for round_idx in range(current_round):
            total_cooperators += int(np.sum(history.opponent_actions[round_idx, :]))
        total_rounds = current_round
        n = self.game_description.n_players
        if total_rounds == 0 or n == 0:
            return 0.0
        return total_cooperators / (total_rounds * n)

    def _middle_round_decision(self, cooperation_rate: float, m: int, n: int, k: float, current_round: int, prev_round_idx: int, history: PlayerHistory) -> Action:
        """Decision logic for middle rounds (2 to r-1)."""
        m_threshold = m / n
        if self.threshold_met_last_round:
            return Action.D
        if cooperation_rate > m_threshold * 1.5:
            return Action.D
        if cooperation_rate < m_threshold * 0.7:
            return Action.D
        random_seed = current_round + hash(self.__class__.__name__) % 2 ** 31
        random.seed(random_seed)
        defect_probability = 0.85
        if random.random() < defect_probability:
            return Action.D
        else:
            return Action.C

    def _final_round_decision(self, cooperation_rate: float, m: int, n: int) -> Action:
        """Decision logic for final round: always defect."""
        if self.game_description.n_rounds == 2:
            return Action.D
        if self.threshold_met_last_round:
            return Action.D
        m_threshold = m / n
        if cooperation_rate > m_threshold + 0.2:
            return Action.D
        estimated_threshold_probability = cooperation_rate * self.game_description.n_players
        if estimated_threshold_probability > 0.6:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_282(BaseStrategy):
    """
    Adaptive Threshold Parasitism: Exploitative strategy that free-rides on the threshold
    mechanism by defecting while counting on others to reach m cooperators, then
    conditionally cooperating only when strategically necessary to maintain future exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.cooperation_history = []
        self.defect_count = 0
        self.cooperate_when_marginal = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        prev_round_idx = current_round - 1
        cooperators_prev = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            cooperators_prev += 1
        self.cooperation_history.append(cooperators_prev)
        if cooperators_prev >= self.m:
            return Action.D
        if cooperators_prev + 1 == self.m:
            if self.cooperate_when_marginal and self.defect_count < self.r * 0.3:
                return Action.C
            else:
                self.defect_count += 1
                return Action.D
        if current_round > 5 and len(self.cooperation_history) > 0:
            n_coop_avg = np.mean(self.cooperation_history)
            if n_coop_avg > self.m + 1:
                self.cooperate_when_marginal = False
            elif abs(n_coop_avg - self.m) < 1.0:
                self.cooperate_when_marginal = True
        self.defect_count += 1
        return Action.D

class Strategy_EXPLOITATIVE_283(BaseStrategy):
    """
    Conditional Free-Rider with Adaptive Defection strategy for Collective Risk Dilemma.
    
    Core philosophy: Exploit the threshold mechanism by minimizing personal contribution 
    while maximizing extraction of collective benefits. Always defect when threshold is met 
    (free-ride), and always defect when it isn't (others wasted resources or all defected).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_ratio = self.m / self.n_players if self.n_players > 0 else 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        if self.threshold_ratio > 0.8:
            return Action.D
        if self.n_rounds == 2:
            return Action.D
        prev_round_idx = current_round - 1
        cooperators_last_round = sum(history.opponent_actions[prev_round_idx, :])
        if cooperators_last_round >= self.m:
            return Action.D
        if cooperators_last_round > 0:
            return Action.D
        rounds_remaining = self.n_rounds - current_round
        if rounds_remaining <= 2:
            return Action.D
        if self.threshold_ratio <= 0.4:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_284(BaseStrategy):
    """
    Adaptive Defection with Selective Cooperation.
    
    Exploits the asymmetry in payoffs by free-riding on cooperators while maintaining
    just enough strategic cooperation to occasionally destabilize all-defection equilibria.
    Core mechanics: defect by default, cooperate only in mid-game when threshold is nearly
    unmet (m-2 cooperators) to restart profitable cycles.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        last_round_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        remaining_rounds = self.r - current_round
        if last_round_cooperators >= self.m:
            return Action.D
        if last_round_cooperators == self.m - 1:
            return Action.D
        if last_round_cooperators == self.m - 2:
            if remaining_rounds >= 2:
                if random.random() < 0.33:
                    return Action.C
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_285(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism strategy for Collective Risk Dilemma.
    
    Core philosophy: Exploit the asymmetry where cooperators pay cost (c=1) while defectors
    capture reward (k) when threshold is met. Maximize payoff by free-riding on others'
    cooperation while minimizing wasted contributions.
    
    Decision logic:
    - Round 1: DEFECT (information gathering)
    - Round r: DEFECT (no future rounds to benefit)
    - Rounds 2 to r-1: DEFECT if threshold already met, else COOPERATE only if gap â‰¤ 2
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        prev_round_idx = current_round - 1
        cooperators_prev_round = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        if cooperators_prev_round >= self.m:
            return Action.D
        threshold_gap = self.m - cooperators_prev_round
        if threshold_gap <= 2:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_286(BaseStrategy):
    """
    Adaptive Parasitism: An exploitative strategy that defaults to defection,
    free-rides when threshold is met, and conditionally cooperates only when
    necessary to unlock the collective reward. Maximizes expected payoff by
    capturing both private endowment and collective reward asymmetrically.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        total_rounds = self.n_rounds
        if round_number == total_rounds - 1:
            return Action.D
        if round_number == 0:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[round_number - 1, :]))
        rounds_remaining = total_rounds - round_number - 1
        if cooperators_last_round >= self.m:
            return Action.D
        elif cooperators_last_round == self.m - 1:
            if random.random() < 0.7:
                return Action.D
            else:
                return Action.C
        elif cooperators_last_round < self.m - 1:
            if rounds_remaining > 1:
                return Action.D
            elif rounds_remaining == 1:
                return Action.C
            else:
                return Action.C
        return Action.C

class Strategy_EXPLOITATIVE_287(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation
    
    Exploits asymmetry in payoff structure by defaulting to defection and only
    cooperating when necessary to prevent collective failure. Monitors cooperation
    rates and adapts based on thresholds and endgame dynamics.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        coop_rate = self._calculate_coop_rate(history, current_round)
        threshold_ratio = self.m / self.n_players
        is_final_round = current_round == self.n_rounds - 1
        if is_final_round:
            return self._final_round_decision(history, current_round)
        return self._adaptive_phase_decision(coop_rate, threshold_ratio, history, current_round)

    def _calculate_coop_rate(self, history: PlayerHistory, current_round: int) -> float:
        """Calculate the historical cooperation rate of opponents."""
        if current_round == 0:
            return 0.0
        total_cooperators = np.sum(history.opponent_actions[:current_round, :])
        denominator = (self.n_players - 1) * current_round
        if denominator == 0:
            return 0.0
        return total_cooperators / denominator

    def _adaptive_phase_decision(self, coop_rate: float, threshold_ratio: float, history: PlayerHistory, current_round: int) -> Action:
        """Decision logic for rounds 1 through r-2."""
        if coop_rate >= threshold_ratio * 1.2:
            return Action.D
        if coop_rate >= threshold_ratio * 0.8:
            return Action.D
        if coop_rate < threshold_ratio * 0.8:
            projected_cooperators = self._predict_cooperators(history, current_round)
            if projected_cooperators < self.m:
                return Action.C
            else:
                return Action.D
        return Action.D

    def _predict_cooperators(self, history: PlayerHistory, current_round: int) -> float:
        """Predict expected cooperators in next round based on recent trend."""
        if current_round < 2:
            recent_cooperators = np.sum(history.opponent_actions[:current_round, :])
            return recent_cooperators / self.n_players if current_round > 0 else 0.0
        recent_window = min(3, current_round)
        recent_cooperators = np.sum(history.opponent_actions[max(0, current_round - recent_window):current_round, :])
        recent_rounds_count = recent_window * (self.n_players - 1)
        recent_rate = recent_cooperators / recent_rounds_count if recent_rounds_count > 0 else 0.0
        overall_cooperators = np.sum(history.opponent_actions[:current_round, :])
        overall_rounds_count = current_round * (self.n_players - 1)
        overall_rate = overall_cooperators / overall_rounds_count if overall_rounds_count > 0 else 0.0
        weighted_rate = 0.7 * recent_rate + 0.3 * overall_rate
        return weighted_rate * (self.n_players - 1)

    def _final_round_decision(self, history: PlayerHistory, current_round: int) -> Action:
        """Decision logic for the final round."""
        last_round_cooperators = np.sum(history.opponent_actions[current_round - 1, :])
        if last_round_cooperators >= self.m:
            return Action.D
        if last_round_cooperators + 1 >= self.m:
            coop_rate = self._calculate_coop_rate(history, current_round)
            threshold_ratio = self.m / self.n_players
            if coop_rate >= threshold_ratio * 0.9:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_288(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Threshold Strategy.
    
    Exploits the threshold mechanics of the Collective Risk Dilemma by:
    1. Defecting in round 1 to gather information
    2. Defecting whenever m or more players cooperated in the previous round
    3. Defecting in the final round (endgame exploitation)
    4. Generally defecting to maximize private gains while benefiting from others' cooperation
    
    The strategy recognizes that defectors earn k+1 when threshold is met,
    while cooperators earn only k, creating an asymmetric payoff to exploit.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        k = self.game_description.k
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        if history is not None:
            previous_round_idx = current_round - 1
            cooperators_prev = int(sum(history.opponent_actions[previous_round_idx, :]))
            if cooperators_prev >= m:
                self.consecutive_defections += 1
                return Action.D
            else:
                self.consecutive_defections += 1
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_289(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation
    
    Maximizes personal payoff by exploiting others' cooperation while minimizing 
    contribution costs. Uses defection in round 1 and final round, and becomes a 
    "pivotal player" in middle rounds when exactly m-1 cooperators exist.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[state.round_number - 1, :]))
        m = self.game_description.m
        if cooperators_last_round >= m:
            return Action.D
        elif cooperators_last_round == m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_290(BaseStrategy):
    """
    Opportunistic Threshold Rider: Exploits the Collective Risk Dilemma by defecting by default
    and cooperating only when the threshold appears certain to be met by others' contributions.
    Maximizes payoff by free-riding on cooperators while minimizing own contribution burden.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        coop_count_last = int(sum(history.opponent_actions[round_num - 1, :]))
        mid_point = math.floor(self.r / 2)
        if round_num <= mid_point:
            if round_num == 1:
                return Action.D
            coop_count_prev = int(sum(history.opponent_actions[round_num - 2, :]))
            recent_avg = (coop_count_last + coop_count_prev) / 2.0
            if recent_avg >= self.m:
                return Action.C
            else:
                return Action.D
        elif round_num < self.r - 1:
            if coop_count_last >= self.m:
                return Action.C
            elif coop_count_last >= self.m - 1:
                coop_count_prev = int(sum(history.opponent_actions[round_num - 2, :]))
                coop_trend = coop_count_last - coop_count_prev
                if coop_trend >= 0:
                    return Action.C
                else:
                    return Action.D
            elif coop_count_last >= self.m / 2.0:
                return Action.D
            else:
                return Action.D
        elif round_num == self.r - 1:
            coop_count_prev = int(sum(history.opponent_actions[round_num - 2, :]))
            if coop_count_last >= self.m:
                return Action.C
            elif coop_count_last >= self.m - 1:
                return Action.C
            else:
                return Action.D
        elif coop_count_last >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_291(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Thresholds
    
    Exploits the asymmetry where defectors earn strictly higher payoffs than cooperators
    when the cooperation threshold is met. Defects in round 1 and final round unconditionally.
    In middle rounds, adapts based on observed cooperation rate relative to the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        previous_round_index = current_round - 1
        cooperators_in_previous = int(np.sum(history.opponent_actions[previous_round_index, :]))
        cooperation_rate = cooperators_in_previous / self.n
        threshold_rate = self.m / self.n
        if cooperation_rate >= threshold_rate:
            return Action.D
        elif cooperators_in_previous + 1 >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_292(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Threshold strategy.
    
    Exploits the collective action problem by free-riding on others' cooperation
    when the threshold is met, while conditionally cooperating to help reach the
    threshold in earlier rounds. Defects unconditionally in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            if self.n_players <= 1:
                return Action.D
            prob = (self.m - 1) / (self.n_players - 1)
            return Action.C if random.random() < prob else Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        last_round_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        rounds_remaining = self.n_rounds - current_round
        if last_round_cooperators >= self.m:
            return Action.D
        if last_round_cooperators == self.m - 1:
            return Action.C
        if last_round_cooperators < self.m - 1:
            if rounds_remaining <= 1:
                return Action.D
            gap = self.m - last_round_cooperators
            available_slots = self.n_players - last_round_cooperators
            if available_slots <= 0:
                return Action.D
            prob = gap / available_slots
            prob = max(0.0, min(1.0, prob))
            return Action.C if random.random() < prob else Action.D
        return Action.D

class Strategy_EXPLOITATIVE_293(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Thresholds.
    
    Exploits threshold structure by strategically defecting when cooperation is likely
    to succeed anyway, while maintaining just enough cooperativeness to keep the
    cooperative pool viable. Uses adaptive decision rules based on cooperation trends,
    success probability estimates, and defection budgets.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defects = 0
        self.defect_budget = math.floor((game_description.n_rounds - 2) * 0.6)
        self.defects_used = 0
        self.min_viable_cooperation = game_description.m + 1
        self.risk_tolerance = 2
        self.cooperation_history = []
        self.always_defect_mode = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if state.round_number == 0:
            return Action.C
        if state.round_number == r - 1:
            return Action.D
        if self.always_defect_mode:
            return Action.D
        c_count_last = int(np.sum(history.opponent_actions[state.round_number - 1, :]))
        cooperation_rate = c_count_last / n
        self.cooperation_history.append(c_count_last)
        if len(self.cooperation_history) >= 2:
            if self.cooperation_history[-1] == 0 and self.cooperation_history[-2] == 0:
                self.always_defect_mode = True
                return Action.D
        if c_count_last < m and len(self.cooperation_history) >= 2:
            self.always_defect_mode = True
            return Action.D
        if len(self.cooperation_history) >= 3:
            coop_std = float(np.std(self.cooperation_history[-3:]))
            if coop_std > n / 3:
                threshold_success = 0.65
                defect_budget_adjusted = self.defect_budget + math.floor(self.defect_budget * 0.2)
            else:
                threshold_success = 0.75
                defect_budget_adjusted = self.defect_budget
        else:
            threshold_success = 0.75
            defect_budget_adjusted = self.defect_budget
        if state.round_number >= r - 2:
            threshold_success = 0.5
        if len(self.cooperation_history) >= 2:
            cooperation_trend = (self.cooperation_history[-1] - self.cooperation_history[-2]) / n
        else:
            cooperation_trend = 0.0
        projected_cooperators = c_count_last + cooperation_trend * n
        p_success = projected_cooperators >= m
        min_viable_threshold = m / n * 1.2
        if cooperation_rate < min_viable_threshold:
            self.consecutive_defects = 0
            return Action.C
        if c_count_last >= m and c_count_last <= m + 1:
            if self.defects_used < defect_budget_adjusted:
                self.consecutive_defects += 1
                self.defects_used += 1
                return Action.D
            else:
                self.consecutive_defects = 0
                return Action.C
        if p_success and self.consecutive_defects < self.risk_tolerance:
            if self.defects_used < defect_budget_adjusted:
                self.consecutive_defects += 1
                self.defects_used += 1
                return Action.D
        if len(self.cooperation_history) >= 3:
            recent_defections = [self.game_description.n_players - c for c in self.cooperation_history[-3:]]
            is_increasing = recent_defections[-1] > recent_defections[-2] and recent_defections[-2] > recent_defections[-3]
            if is_increasing:
                if random.random() < 1 / 3:
                    self.consecutive_defects = 0
                    return Action.C
                else:
                    self.consecutive_defects += 1
                    if self.defects_used < defect_budget_adjusted:
                        self.defects_used += 1
                    return Action.D
        if self.defects_used < defect_budget_adjusted and self.consecutive_defects < self.risk_tolerance:
            if c_count_last >= m:
                self.consecutive_defects += 1
                self.defects_used += 1
                return Action.D
        self.consecutive_defects = 0
        return Action.C

class Strategy_EXPLOITATIVE_294(BaseStrategy):
    """
    Adaptive Threshold Parasitism: An exploitative strategy that maximizes personal payoff
    by free-riding on others' cooperation while minimizing personal risk through defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        if t == 0:
            return Action.D
        if t == self.r - 1:
            return Action.D
        if t == self.r - 2:
            return Action.D
        last_round_cooperators = int(np.sum(history.opponent_actions[t - 1, :]))
        if last_round_cooperators >= self.m:
            return Action.D
        if last_round_cooperators >= self.m - 1:
            return Action.D
        critical_threshold = math.ceil(self.m / 2.0)
        if last_round_cooperators < critical_threshold:
            return Action.D
        rounds_remaining = self.r - t
        if rounds_remaining <= 2 or t == 1:
            return Action.D
        return Action.C

class Strategy_EXPLOITATIVE_295(BaseStrategy):
    """
    Adaptive Threshold Farming: Exploitative strategy that free-rides on cooperation,
    strategically defects to collapse thresholds, and adapts based on observable
    cooperation rates and defector patterns.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.exploitation_threshold = 0.15
        self.defector_set = set()

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        m = self.game_description.m
        if state.round_number == 0:
            return Action.D
        if state.round_number == r - 1:
            return Action.D
        current_round_idx = state.round_number
        last_round_idx = current_round_idx - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[last_round_idx, :]))
        if history.my_actions[last_round_idx]:
            cooperators_last_round += 1
        cooperation_rate = cooperators_last_round / n if n > 0 else 0
        target_threshold = m / n if n > 0 else 0
        if cooperation_rate >= target_threshold + self.exploitation_threshold:
            return Action.D
        if cooperation_rate < target_threshold - 0.05:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_296(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Free-Riding with Conditional Engagement
    
    Exploits asymmetry by defaulting to defection and only cooperating when
    threshold achievement is sufficiently likely and strategically valuable.
    Prioritizes personal gain through intelligent free-riding.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        cooperation_count_last_round = int(np.sum(history.opponent_actions[-1, :]))
        deficit = self.m - 1 - cooperation_count_last_round
        if round_num == self.r - 1:
            if self.m <= 2:
                return Action.D
            if self.m > self.n / 2:
                return Action.D
            return Action.D
        if deficit <= 0:
            return Action.D
        if deficit > 0 and deficit <= 2 and (round_num <= self.r - 3):
            return Action.D
        if deficit > self.n - self.m:
            return Action.D
        if round_num == self.r - 2:
            return Action.D
        if cooperation_count_last_round >= self.m * 0.8:
            return Action.D
        if cooperation_count_last_round < self.m * 0.3:
            return Action.D
        remaining_rounds = self.r - round_num
        if remaining_rounds >= 3 and deficit == 1:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_297(BaseStrategy):
    """
    Adaptive Threshold Exploitation (ATE) strategy for Collective Risk Dilemma.
    
    Exploits the asymmetry in payoff structure by:
    1. Defecting in round 1 (no information)
    2. Defecting in final round (no future punishment)
    3. In middle rounds: free-riding when threshold is met, conditionally cooperating
       when cooperation is moderate (~60% of threshold), and defecting otherwise.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        last_round_opponent_actions = history.opponent_actions[current_round - 1, :]
        cooperators_count = int(np.sum(last_round_opponent_actions))
        if cooperators_count >= self.m:
            return Action.D
        elif cooperators_count >= self.m - 1:
            return Action.D
        else:
            medium_cooperation_threshold = math.ceil(self.m * 0.6)
            if cooperators_count >= medium_cooperation_threshold:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_298(BaseStrategy):
    """
    Exploitative Free-Rider Strategy: Always defect to maximize payoff by free-riding
    on others' cooperation. Defection weakly dominates all rounds since you capture
    the private endowment (1) and any collective reward (k) without paying the cooperation cost.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_299(BaseStrategy):
    """
    Adaptive Threshold Leech: An exploitative strategy for collective risk dilemmas.
    
    Exploits coordination problems by observing cooperation rates and free-riding
    when cooperation is high, while strategically cooperating to pump up cooperation
    rates before exploiting them. Uses phase-based behavior with end-game adaptations.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.phase1_end = math.floor(self.r / 3)
        self.phase2_end = math.floor(2 * self.r / 3)
        self.threshold = self.m / self.n + 0.15
        if self.m >= self.n - 1:
            self.phase1_end = math.floor(self.r / 2)
            self.threshold = 0.9

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        coop_rate = self._calculate_coop_rate(history, current_round)
        if current_round <= self.phase1_end:
            return Action.D
        if current_round <= self.phase2_end:
            if coop_rate >= self.threshold:
                return Action.D
            else:
                if self.m <= 2 and coop_rate < 0.4:
                    return Action.D
                return Action.C
        rounds_remaining = self.r - current_round
        if rounds_remaining <= 2:
            majority_action = self._get_majority_action(history, current_round)
            return majority_action
        if coop_rate < self.m / self.n and rounds_remaining > 5:
            last_n_coop = self._get_recent_coop_rate(history, current_round, 5)
            if 0.2 < last_n_coop < self.m / self.n:
                return Action.C
        if current_round > self.phase1_end:
            recent_decline = self._check_cooperation_decline(history, current_round)
            if recent_decline:
                return Action.D
        return Action.D

    def _calculate_coop_rate(self, history: PlayerHistory, current_round: int) -> float:
        """Calculate cooperation rate of opponents across all rounds so far."""
        if current_round == 0 or history is None:
            return 0.0
        total_cooperators = 0
        total_opportunities = 0
        for round_idx in range(current_round):
            cooperators_this_round = int(np.sum(history.opponent_actions[round_idx, :]))
            total_cooperators += cooperators_this_round
            total_opportunities += self.n - 1
        if total_opportunities == 0:
            return 0.0
        return total_cooperators / total_opportunities

    def _get_recent_coop_rate(self, history: PlayerHistory, current_round: int, window_size: int) -> float:
        """Calculate cooperation rate in the last n rounds."""
        if history is None or current_round == 0:
            return 0.0
        start_round = max(0, current_round - window_size)
        total_cooperators = 0
        total_opportunities = 0
        for round_idx in range(start_round, current_round):
            cooperators_this_round = int(np.sum(history.opponent_actions[round_idx, :]))
            total_cooperators += cooperators_this_round
            total_opportunities += self.n - 1
        if total_opportunities == 0:
            return 0.0
        return total_cooperators / total_opportunities

    def _get_majority_action(self, history: PlayerHistory, current_round: int) -> Action:
        """Get the most common action in recent rounds (last 3)."""
        if history is None or current_round == 0:
            return Action.D
        start_round = max(0, current_round - 3)
        total_cooperators = 0
        total_defectors = 0
        for round_idx in range(start_round, current_round):
            cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
            defectors = self.n - 1 - cooperators
            total_cooperators += cooperators
            total_defectors += defectors
        if total_cooperators >= total_defectors:
            return Action.C
        return Action.D

    def _check_cooperation_decline(self, history: PlayerHistory, current_round: int) -> bool:
        """Check if cooperation rate is declining significantly."""
        if history is None or current_round < 3:
            return False
        early_coop = self._get_recent_coop_rate(history, current_round - 2, 2)
        recent_coop = self._get_recent_coop_rate(history, current_round, 2)
        return recent_coop < early_coop * 0.8 and early_coop > self.m / self.n

class Strategy_EXPLOITATIVE_300(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Defection strategy.
    
    Exploits the threshold mechanism by minimizing personal contribution while
    maximizing capture of collective benefits. Uses pattern recognition to identify
    exploitable players and adapts defection strategy based on observed cooperation
    levels and remaining rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.n_rounds - 1:
            return Action.D
        observed_coop_last = int(np.sum(history.opponent_actions[round_num - 1, :]))
        rounds_left = self.n_rounds - round_num
        if observed_coop_last >= self.m:
            return Action.D
        deficit = self.m - observed_coop_last
        if deficit <= 1:
            return Action.D
        if deficit == 2:
            if random.random() < 0.6:
                return Action.D
            else:
                return Action.C
        if deficit >= 3:
            if rounds_left <= 2:
                return Action.D
            elif rounds_left > 4 * deficit:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_301(BaseStrategy):
    """
    Calculated Parasitism: An exploitative strategy that free-rides on others' cooperation
    by defecting whenever possible, while betting that others will meet the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        cooperators_prev = int(sum(history.opponent_actions[state.round_number - 1, :]))
        m = self.game_description.m
        if cooperators_prev >= m:
            return Action.D
        if cooperators_prev == m - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_302(BaseStrategy):
    """
    Threshold Parasite: Exploitative strategy that maximizes payoff by conditionally
    free-riding when the threshold is met, cooperating only when strictly necessary
    to unlock the k-reward, and defecting in the first and final rounds.
    
    Core logic:
    - Round 1: DEFECT (no history, highest immediate payoff)
    - Final round: DEFECT (no future consequences)
    - Middle rounds:
      - If â‰¥m cooperators in previous round: DEFECT (free-ride on threshold)
      - If exactly m-1 cooperators in previous round: COOPERATE (conditionally necessary)
      - If â‰¤m-2 cooperators in previous round: DEFECT (threshold unreachable)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
        if cooperators_last_round >= self.m:
            return Action.D
        if cooperators_last_round == self.m - 1:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_303(BaseStrategy):
    """
    Adaptive Threshold Exploitation: A parasitic strategy that systematically defects
    to free-ride on others' cooperation. Exploits the asymmetry where defection yields
    k+1 when threshold is met (vs k for cooperation), while maintaining baseline payoff
    of 1 when threshold fails. Uses observed cooperation patterns to maximize extraction
    in all game phases.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        cooperation_count_last_round = int(np.sum(history.opponent_actions[round_number - 1, :]))
        if cooperation_count_last_round >= self.m:
            return Action.D
        if cooperation_count_last_round == self.m - 1:
            return Action.D
        midpoint_round = self.n_rounds / 2.0
        cooperation_threshold = self.m / 2.0
        if cooperation_count_last_round >= cooperation_threshold and round_number >= midpoint_round:
            return Action.D
        if cooperation_count_last_round < cooperation_threshold:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_304(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Free-Riding with Conditional Defection
    
    This strategy exploits the threshold mechanism by identifying when cooperation is 
    "forced" by others, then defecting to capture asymmetric payoffs. It transitions 
    from probing to exploitation based on observed cooperation rates.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        prev_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        cooperation_rate = prev_cooperators / self.n
        threshold_rate = self.m / self.n
        if cooperation_rate >= threshold_rate:
            return Action.D
        deficit = math.ceil(threshold_rate * self.n) - prev_cooperators
        if deficit > 1:
            return Action.D
        if deficit == 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_305(BaseStrategy):
    """
    Conditional Defection with Opportunistic Exploitation strategy.
    
    Core philosophy: Exploit the asymmetry where defectors earn (1 + k) when threshold is met,
    while cooperators earn only k. Always defect except in edge cases.
    
    Decision rules:
    - Round 1: DEFECT (establish baseline)
    - Final round: DEFECT (no future consequences)
    - Other rounds: DEFECT based on previous round cooperator count:
      * If cooperators >= m: DEFECT (free ride on threshold)
      * If cooperators == m-1: DEFECT (break threshold, punish cooperators)
      * If cooperators < m-1: DEFECT (threshold impossible, safe defection)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if cooperators_last_round >= self.m:
            return Action.D
        if cooperators_last_round == self.m - 1:
            return Action.D
        if cooperators_last_round < self.m - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_306(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Thresholding.
    
    Exploits the payoff asymmetry by free-riding when others cooperate,
    adapting defection intensity based on observed cooperation rates and
    game phase (early/mid/late rounds).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_safe = (self.m - 1) / self.n
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return self._decide_round_1()
        if round_num == self.r - 1:
            return Action.D
        self._update_cooperation_history(history, round_num)
        if round_num == 1:
            return self._decide_round_2(history)
        return self._decide_adaptive(history, round_num)

    def _decide_round_1(self) -> Action:
        """
        Round 1 decision based on threshold likelihood.
        """
        threshold_ratio = self.m / self.n
        if threshold_ratio <= 0.5:
            return Action.D
        elif threshold_ratio > 0.66:
            return Action.C
        else:
            return Action.D

    def _decide_round_2(self, history: PlayerHistory) -> Action:
        """
        Round 2 decision based on observed round 1 cooperation.
        """
        coop_count_r1 = int(np.sum(history.opponent_actions[0, :]))
        coop_rate_r1 = coop_count_r1 / self.n
        if coop_rate_r1 >= self.threshold_safe:
            return Action.D
        my_action_r1 = history.my_actions[0]
        if not my_action_r1:
            return Action.D
        else:
            return Action.D

    def _decide_adaptive(self, history: PlayerHistory, round_num: int) -> Action:
        """
        Adaptive defection strategy for rounds 2+ (excluding final round).
        """
        recent_coop_rate = self._get_recent_cooperation_rate(history, round_num)
        if recent_coop_rate >= self.threshold_safe:
            return Action.D
        phase = round_num / self.r
        if phase <= 1 / 3:
            return Action.D if recent_coop_rate < 0.4 else Action.C
        elif phase < 2 / 3:
            return Action.D
        else:
            return Action.D

    def _update_cooperation_history(self, history: PlayerHistory, round_num: int) -> None:
        """
        Update cooperation history with counts from previous rounds.
        """
        if len(self.cooperation_history) < round_num:
            for i in range(len(self.cooperation_history), round_num):
                coop_count = int(np.sum(history.opponent_actions[i, :]))
                self.cooperation_history.append(coop_count)

    def _get_recent_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate weighted average cooperation rate from recent rounds.
        Handles edge cases and division by zero.
        """
        if round_num == 0:
            return 0.0
        recent_rounds = []
        start_idx = max(0, round_num - 2)
        for i in range(start_idx, round_num):
            coop_count = int(np.sum(history.opponent_actions[i, :]))
            recent_rounds.append(coop_count)
        if not recent_rounds:
            return 0.0
        if len(recent_rounds) == 1:
            weighted_sum = recent_rounds[0]
            weight_sum = 1.0
        elif len(recent_rounds) == 2:
            weighted_sum = recent_rounds[0] * 0.3 + recent_rounds[1] * 0.5
            weight_sum = 0.8
        else:
            weighted_sum = recent_rounds[0] * 0.2 + recent_rounds[1] * 0.3 + recent_rounds[2] * 0.5
            weight_sum = 1.0
        if weight_sum > 0:
            return weighted_sum / weight_sum / self.n
        return 0.0

class Strategy_EXPLOITATIVE_307(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD) Strategy
    
    Exploits asymmetry in payoffs by free-riding on cooperators' contributions.
    - Phase 1 (rounds 0 to r-m-1): Unconditional defection to identify cooperators
    - Phase 2 (rounds r-m to r-2): Adaptive defection/cooperation based on observed patterns
    - Phase 3 (round r-1): Final round conditional cooperation if threshold likely
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num <= self.r - self.m - 1:
            return Action.D
        elif round_num <= self.r - 2:
            if history is None:
                return Action.D
            n_observed = round_num
            if n_observed == 0:
                return Action.D
            cooperation_counts = np.sum(history.opponent_actions[:n_observed, :], axis=0)
            cooperation_rates = cooperation_counts / n_observed
            reliable_cooperators = np.sum(cooperation_rates >= 0.5)
            rounds_remaining = self.r - round_num
            if reliable_cooperators >= self.m - 1:
                return Action.D
            elif reliable_cooperators == self.m - 2 and rounds_remaining >= 2:
                return Action.C
            else:
                return Action.D
        else:
            if history is None:
                return Action.D
            n_observed = round_num
            if n_observed == 0:
                return Action.D
            cooperation_counts = np.sum(history.opponent_actions[:n_observed, :], axis=0)
            cooperation_rates = cooperation_counts / n_observed
            reliable_cooperators = np.sum(cooperation_rates >= 0.5)
            if reliable_cooperators >= self.m - 1:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_308(BaseStrategy):
    """
    Adaptive Defection with Conditional Parasitism: An exploitative strategy that defects to 
    free-ride on others' cooperation when the success threshold is likely to be met, and defects 
    otherwise to avoid wasting the endowment. Cooperates never except in edge cases where it's 
    logically impossible to exploit others.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = np.zeros(game_description.n_players - 1, dtype=np.int32)
        self.rounds_elapsed = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        m = self.game_description.m
        if state.round_number == 0:
            return Action.D
        if state.round_number == r - 1:
            return Action.D
        if m == n:
            return Action.D
        if history is not None:
            for round_idx in range(state.round_number):
                opponent_actions_this_round = history.opponent_actions[round_idx, :]
                self.cooperation_history += opponent_actions_this_round.astype(np.int32)
            self.rounds_elapsed = state.round_number
            total_opponent_rounds = (n - 1) * self.rounds_elapsed
            if total_opponent_rounds > 0:
                cooperation_rate = np.sum(self.cooperation_history) / total_opponent_rounds
            else:
                cooperation_rate = 0.0
            threshold_to_exploit = (m - 1) / (n - 1)
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_309(BaseStrategy):
    """
    Exploitative strategy: Conditional free-riding with adaptive defection.
    
    Exploits the coordination problem by free-riding on others' cooperation while
    maintaining plausible deniability. Maximizes individual payoff through selective
    defection adapted to observed cooperation rates across three phases:
    - Phase 1 (early rounds): Default defect with conditional cooperation baiting
    - Phase 2 (middle rounds): Adaptive defection based on threshold frequency
    - Phase 3 (endgame): Pure defection to extract final round value
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num < math.floor(self.r / 2):
            if round_num == 0:
                return Action.D
            cooperation_count_previous = int(sum(history.opponent_actions[round_num - 1, :]))
            threshold_met_previous = cooperation_count_previous >= self.m
            if threshold_met_previous:
                cooperation_rate = cooperation_count_previous / self.n
                threshold = self.m / self.n * 1.5
                if cooperation_rate >= threshold:
                    return Action.C
            return Action.D
        elif round_num <= self.r - 2:
            total_thresholds_met = 0
            for past_round in range(round_num):
                cooperation_count = int(sum(history.opponent_actions[past_round, :]))
                if cooperation_count >= self.m:
                    total_thresholds_met += 1
            threshold_frequency = self.r / 2 * 0.7
            if total_thresholds_met >= threshold_frequency:
                if random.random() < 0.05:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_310(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Thresholds.
    
    Exploits the asymmetry that defectors earn more than cooperators when the
    threshold is met. Defaults to defection in nearly all cases, free-riding on
    others' cooperation while minimizing contribution.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        if history is not None:
            last_round_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
            observed_cooperation_rate = last_round_cooperators / self.n_players
            expected_threshold_met = observed_cooperation_rate * self.n_players >= self.m
            if expected_threshold_met:
                return Action.D
            elif observed_cooperation_rate > 0.4:
                return Action.D
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_311(BaseStrategy):
    """
    Adaptive Free-Riding with Threshold Exploitation strategy.
    
    This exploitative strategy defects in every round to maximize free-riding payoffs.
    It calculates empirical opponent cooperation rates to estimate when the threshold
    is likely met by others, enabling reliable free-riding (payoff 1 + k).
    In early rounds and final round, it defects unconditionally.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.n_rounds - 1:
            return Action.D
        previous_rounds = state.round_number
        total_opponent_actions = history.opponent_actions[:previous_rounds, :]
        cooperator_count = np.sum(total_opponent_actions)
        opponent_rounds = (self.n_players - 1) * previous_rounds
        if opponent_rounds == 0:
            empirical_coop_rate = 0.0
        else:
            empirical_coop_rate = cooperator_count / opponent_rounds
        expected_cooperators = empirical_coop_rate * (self.n_players - 1)
        if expected_cooperators >= self.m - 1:
            return Action.D
        elif expected_cooperators >= self.m - 2:
            return Action.D
        elif empirical_coop_rate >= 0.4 and state.round_number <= self.n_rounds * 0.5:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_312(BaseStrategy):
    """
    Adaptive Parasitism with Dynamic Threshold Monitoring.
    
    Exploits the threshold structure by free-riding on others' cooperation.
    Defects by default, only cooperating when necessary to ensure the threshold
    is met and secure the reward k.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        observed_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if observed_cooperators >= self.m:
            return Action.D
        elif observed_cooperators == self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_313(BaseStrategy):
    """
    Exploitative strategy: "Conditional Free-Riding with Adaptive Defection"
    
    Exploits the threshold mechanism by free-riding on others' cooperation while
    minimizing personal contribution. Defaults to defection unless cooperation becomes
    instrumentally necessary for future free-riding.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.cooperation_history = []
        self.last_round_cooperators = 0
        self.reliable_cooperators_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            if self.m == 2 and self.n_players == 2:
                return Action.C
            return Action.D
        early_game_end = max(1, math.floor(self.n_rounds / 3))
        mid_game_end = max(early_game_end + 1, math.floor(2 * self.n_rounds / 3))
        self.last_round_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        self.cooperation_history.append(self.last_round_cooperators)
        total_observed = sum(self.cooperation_history)
        coop_rate = total_observed / (len(self.cooperation_history) * (self.n_players - 1)) if self.cooperation_history else 0.0
        if len(self.cooperation_history) >= 2:
            coop_variance = np.var(self.cooperation_history)
        else:
            coop_variance = 0.0
        if current_round == self.n_rounds - 1:
            return Action.D
        if current_round == self.n_rounds - 2:
            if self.last_round_cooperators >= self.m:
                return Action.D
            else:
                return Action.D
        if current_round <= early_game_end:
            target_coop = self.m / self.n_players if self.n_players > 0 else 0.5
            if coop_rate >= target_coop * 1.2:
                return Action.D
            elif coop_rate < target_coop * 0.8:
                return Action.D
            else:
                return Action.C
        if current_round <= mid_game_end:
            if self.last_round_cooperators >= self.m:
                return Action.D
            else:
                rounds_remaining = self.n_rounds - current_round - 1
                deficit = self.m - self.last_round_cooperators
                if coop_variance > 0.5:
                    required_coop = self.m / self.n_players * 1.5
                else:
                    required_coop = self.m / self.n_players * 1.2
                if deficit <= (self.n_players - 1) / 2 and rounds_remaining >= 2:
                    return Action.C
                else:
                    return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_314(BaseStrategy):
    """
    Adaptive Defection with Conditional Parasitism strategy.
    
    Exploits the threshold mechanism by free-riding on others' cooperation.
    Defects almost always, with adaptive monitoring of cooperation rates
    to confirm the strategy's validity. The strategy treats cooperation as
    a resource to extract value from, not a commitment to reciprocate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.n_rounds - 1:
            return Action.D
        prev_cooperators = int(sum(history.opponent_actions[round_num - 1, :]))
        total_rounds_observed = round_num
        total_cooperators_observed = int(np.sum(history.opponent_actions[:round_num, :]))
        if total_rounds_observed > 0 and self.n_players > 1:
            cooperation_rate = total_cooperators_observed / ((self.n_players - 1) * total_rounds_observed)
        else:
            cooperation_rate = 0.0
        threshold_ratio = self.m / self.n_players
        if cooperation_rate > threshold_ratio + 0.15:
            return Action.D
        if cooperation_rate < threshold_ratio - 0.15:
            return Action.D
        if prev_cooperators >= self.m:
            return Action.D
        if prev_cooperators == self.m - 1:
            return Action.D
        if round_num >= 3:
            cooperator_counts = np.sum(history.opponent_actions[:round_num, :], axis=1)
            variance = float(np.var(cooperator_counts))
            if variance > self.n_players / 3.0:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_315(BaseStrategy):
    """
    Calculated Opportunism: An exploitative strategy that maximizes personal payoff
    by free-riding on others' cooperation while strategically manipulating cooperation
    levels through adaptive signaling near the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        c_prev = int(sum(history.opponent_actions[current_round - 1, :]))
        if c_prev >= self.m:
            return Action.D
        if c_prev == self.m - 1:
            return Action.D
        gap = self.m - c_prev
        threshold_distance = self.n_players / 2.0
        if threshold_distance <= 0:
            threshold_distance = 1.0
        if gap >= threshold_distance:
            return Action.D
        else:
            p = gap / threshold_distance
            if random.random() < p:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_316(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD) - An exploitative strategy that maximizes payoff
    by free-riding on others' cooperation when the threshold is met, while avoiding
    wasted endowment contributions.
    
    Core logic: Always defect. This exploits the asymmetric payoff structure where
    defectors earn k more than cooperators when the threshold is met, and lose nothing
    when it isn't.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        return Action.D

class Strategy_EXPLOITATIVE_317(BaseStrategy):
    """
    Adaptive Threshold Defection strategy for Collective Risk Dilemma.
    
    Exploits asymmetry in payoffs by free-riding when threshold is met,
    selectively cooperating only when threshold is critically close,
    and unconditionally defecting in end-game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num <= 1:
            return Action.D
        if round_num >= self.n_rounds - 2:
            return Action.D
        prev_cooperators = int(sum(history.opponent_actions[round_num - 1, :]))
        if prev_cooperators >= self.m:
            return Action.D
        elif prev_cooperators == self.m - 1:
            return Action.D
        else:
            deficit = self.m - prev_cooperators
            if self.m <= 0:
                return Action.D
            p_adaptive = min(0.3, deficit / self.m)
            if random.random() < p_adaptive:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_318(BaseStrategy):
    """
    Exploitative Free-Riding with Threshold Manipulation
    
    This strategy maximizes personal payoff by:
    1. Always defecting to avoid cooperation costs
    2. Free-riding on others' cooperation when threshold is met
    3. Matching defection when cooperation fails
    
    Core logic: ALWAYS DEFECT
    - Round 0: Defect (no history, establish exploiter position)
    - Rounds 1 to r-2: Defect (exploit cooperators or match defectors)
    - Final round: Defect (no future consequences)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_319(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD) Strategy for Collective Risk Dilemma.
    
    Exploits the structural vulnerability of collective risk dilemmas by:
    1. Always defecting to avoid contribution costs
    2. Free-riding on others' cooperation when threshold is likely to be met
    3. Preserving endowment when threshold is unlikely
    4. Never cooperating, eliminating any reciprocal triggers
    
    Core principle: Extract value from threshold-seekers without bearing contribution cost.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == self.n_rounds - 1:
            return Action.D
        if current_round == 0:
            baseline_coop_rate = self.m / self.n_players
            expected_cooperators = baseline_coop_rate * (self.n_players - 1)
            return Action.D
        total_cooperators = 0
        for round_idx in range(current_round):
            cooperators_in_round = int(np.sum(history.opponent_actions[round_idx, :]))
            total_cooperators += cooperators_in_round
        rounds_played = current_round
        total_opponents_rounds = (self.n_players - 1) * rounds_played
        if total_opponents_rounds > 0:
            empirical_coop_rate = total_cooperators / total_opponents_rounds
        else:
            empirical_coop_rate = self.m / self.n_players
        expected_cooperators = empirical_coop_rate * (self.n_players - 1)
        return Action.D

class Strategy_EXPLOITATIVE_320(BaseStrategy):
    """
    Threshold Parasite: Exploitative strategy that defects when threshold is met,
    models opponents as unconditional/conditional cooperators or defectors, and
    systematically free-rides on conditional cooperators while avoiding wasted
    cooperation when thresholds are unreachable.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.D
        last_round_actions = history.opponent_actions[round_t - 1, :]
        observed_cooperators = int(np.sum(last_round_actions))
        unconditional_count = 0
        conditional_count = 0
        defector_count = 0
        n_opponents = self.n_players - 1
        for opponent_idx in range(n_opponents):
            opponent_coop_history = history.opponent_actions[:round_t, opponent_idx]
            rounds_played = round_t
            if rounds_played > 0:
                coop_rate = float(np.sum(opponent_coop_history)) / rounds_played
            else:
                coop_rate = 0.0
            if coop_rate > 0.8:
                unconditional_count += 1
            elif coop_rate >= 0.2:
                conditional_count += 1
            else:
                defector_count += 1
        expected_cooperators = unconditional_count * 0.95 + conditional_count * 0.4 + defector_count * 0.05
        if round_t >= self.n_rounds - 1:
            return Action.D
        if observed_cooperators >= self.m:
            return Action.D
        if observed_cooperators == self.m - 1:
            return Action.D
        if observed_cooperators < self.m - 1:
            if conditional_count > 0:
                return Action.D
            if unconditional_count > 0 and unconditional_count < self.m:
                coop_threshold = min(0.3, max(0.0, 1.0 - observed_cooperators / self.m))
                if random.random() < coop_threshold:
                    return Action.C
                return Action.D
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_321(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Threshold strategy.
    
    Exploits the coordination problem in threshold public goods games by:
    1. Defecting in round 1 to gather information
    2. Parasitizing observed cooperators in middle rounds when threshold likely met
    3. Cooperating only when pivotal (exactly m-1 others cooperating)
    4. Aggressively defecting in the final round when no retaliation is possible
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        cooperators_by_round = np.sum(history.opponent_actions[:current_round, :], axis=1)
        total_cooperators = np.sum(cooperators_by_round)
        total_opponent_actions = (self.n - 1) * current_round
        if total_opponent_actions == 0:
            avg_cooperators = 0.0
        else:
            avg_cooperators = total_cooperators / total_opponent_actions
        coop_rate = avg_cooperators / (self.n - 1) if self.n > 1 else 0.0
        critical_threshold = (self.m - 1) / (self.n - 1) if self.n > 1 else 0.0
        recent_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if coop_rate >= critical_threshold:
            return Action.D
        threshold_lower = critical_threshold - 0.15
        if threshold_lower <= coop_rate < critical_threshold:
            if random.random() < 0.9:
                return Action.D
            else:
                return Action.C
        if recent_cooperators == self.m - 1 and current_round < self.r - 1:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_322(BaseStrategy):
    """
    Adaptive Threshold Predation: An exploitative strategy that free-rides on others' 
    cooperation by defecting when the threshold is likely to be met, while occasionally 
    cooperating when the threshold is fragile to prevent system collapse.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.D
        if round_t == self.r - 1:
            return Action.D
        c_hist = int(sum(history.opponent_actions[round_t - 1, :]))
        if c_hist >= self.m:
            return Action.D
        elif c_hist == self.m - 1:
            boost_prob = min(0.7, self.m / self.n)
            temporal_factor = 0.02 * (self.r - round_t) / max(1, self.r)
            boost_prob += temporal_factor
            boost_prob = min(1.0, max(0.0, boost_prob))
            if random.random() < boost_prob:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_323(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD) Strategy for Collective Risk Dilemma.
    
    Exploits the threshold mechanism by free-riding on cooperative players.
    Systematically defects across all rounds, adapting only to track whether
    the cooperation threshold (m) has been met to decide exploitation timing.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        coop_count_prev = int(np.sum(history.opponent_actions[state.round_number - 1, :]))
        m = self.game_description.m
        n = self.game_description.n_players
        if coop_count_prev >= m:
            return Action.D
        if coop_count_prev == m - 1:
            return Action.D
        if coop_count_prev <= m - 2:
            if state.round_number == self.game_description.n_rounds - 2:
                return Action.D
            baseline_threshold = m / n * 1.5
            coop_rate = coop_count_prev / (n - 1) if n > 1 else 0
            if coop_rate >= baseline_threshold:
                return Action.D
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_324(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Free-Riding with Conditional Defection
    
    Core Philosophy: Exploit the threshold mechanism by allowing others to bear 
    the cooperation cost while capturing the reward. Always defect to maximize 
    payoff, as defection dominates in all scenarios (either free-riding when 
    threshold is met, or avoiding cost when it's not).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        cooperators_prev_round = int(sum(history.opponent_actions[state.round_number - 1, :]))
        return Action.D

class Strategy_EXPLOITATIVE_325(BaseStrategy):
    """
    Adaptive Threshold Exploitation Strategy for Collective Risk Dilemma.
    
    Maximizes personal payoff by exploiting the threshold mechanism:
    - Round 1: Defect to test waters and reveal cooperators
    - Rounds 2 to r-1: Exploit cooperators by defecting when threshold likely met
    - Final round: Defect (no future reputation concerns)
    
    Core mechanic: Free-ride on others' cooperation to capture k+1 payoff
    while avoiding the cost of cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        prev_round_idx = round_num - 1
        opponent_cooperations = np.sum(history.opponent_actions[prev_round_idx, :])
        coop_rate = opponent_cooperations / (self.n - 1) if self.n > 1 else 0.0
        my_prev_action = history.my_actions[prev_round_idx]
        total_cooperators = int(my_prev_action) + int(opponent_cooperations)
        threshold_met = total_cooperators >= self.m
        rounds_remaining = self.r - round_num - 1
        if threshold_met:
            return Action.D
        threshold_ratio = self.m / self.n if self.n > 0 else 0
        if coop_rate >= threshold_ratio:
            return Action.D
        if coop_rate >= threshold_ratio * 0.7:
            if rounds_remaining > self.n / 2:
                return Action.D
            else:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_326(BaseStrategy):
    """
    Exploitative Strategy: Conditional Free-Riding with Adaptive Threshold
    
    Core philosophy: Exploit the threshold structure by minimizing personal 
    contribution while capturing the reward. Free-ride whenever possible by 
    defecting unless observing a specific exploitation opportunity (which 
    never materializes in this simplified version).
    
    Decision rule: Always defect, except potentially in edge cases where 
    cooperation is needed to secure the reward when it's fragile.
    
    Implementation: 
    - Round 1: DEFECT (no history, exploration with payoff safety)
    - Final round: DEFECT (terminal round, no future consequences)
    - Middle rounds: DEFECT (free-ride on others' contributions or avoid 
      wasting endowment when threshold won't be met)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        prev_round_index = current_round - 1
        prev_cooperators = int(sum(history.opponent_actions[prev_round_index, :]))
        my_prev_action = history.my_actions[prev_round_index]
        total_prev_cooperators = prev_cooperators + (1 if my_prev_action else 0)
        if total_prev_cooperators >= self.m:
            return Action.D
        elif prev_cooperators >= self.m - 1:
            return Action.D
        else:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_327(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation
    
    Core approach: Always defect to exploit asymmetric payoff structure.
    - Round 1: Defect to gather information
    - Rounds 2 to r-1: Defect to free-ride when threshold met, or defect because
      threshold is unattainable when not met
    - Final round: Defect (dominant strategy with no future rounds)
    
    This strategy maximizes personal gain by minimizing cooperation while
    exploiting others' contributions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        coop_count_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
        if coop_count_last_round >= self.m:
            return Action.D
        predicted_additional_coops = math.ceil(coop_count_last_round * 0.4)
        predicted_total = coop_count_last_round + predicted_additional_coops
        return Action.D

class Strategy_EXPLOITATIVE_328(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Threshold
    
    Exploitative strategy that maximizes personal payoff by free-riding on cooperators
    when the threshold is met, while strategically cooperating only when pivotal to
    trigger the threshold. Uses adaptive estimation of cooperation rates to predict
    when cooperation is necessary.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.total_cooperators_observed = 0
        self.total_observations = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.n_rounds - 1:
            return Action.D
        prev_round_idx = round_num - 1
        cooperators_prev_round = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        self.total_cooperators_observed += cooperators_prev_round
        self.total_observations += self.n_players
        if self.total_observations > 0:
            est_coop_rate = self.total_cooperators_observed / self.total_observations
        else:
            est_coop_rate = 0.0
        if cooperators_prev_round >= self.m:
            return Action.D
        elif cooperators_prev_round == self.m - 1:
            expected_cooperators = (self.n_players - 1) * est_coop_rate
            if self.m - 1 < expected_cooperators:
                return Action.D
            else:
                return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_329(BaseStrategy):
    """
    Adaptive Threshold Exploitation (ATE) Strategy for Collective Risk Dilemma.
    
    Exploits the structural vulnerability where cooperators subsidize defectors when
    the threshold is met. Maximizes payoff through strategic free-riding while adapting
    to opponent behavior to avoid mutual defection traps.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.consecutive_threshold_failures = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        prev_round_idx = current_round - 1
        cooperators_prev = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        coop_rate = cooperators_prev / self.n_players
        threshold_met = coop_rate >= self.m / self.n_players
        threshold_nearly_met = coop_rate >= (self.m - 1) / self.n_players and coop_rate < self.m / self.n_players
        decline_threshold = (self.m - math.ceil(self.n_players * 0.2)) / self.n_players
        cooperation_declining = coop_rate >= decline_threshold and coop_rate < (self.m - 1) / self.n_players
        cooperation_collapsed = coop_rate < decline_threshold
        if cooperation_collapsed:
            self.consecutive_threshold_failures += 1
        else:
            self.consecutive_threshold_failures = 0
        if threshold_met:
            return Action.D
        elif threshold_nearly_met:
            return Action.D
        elif cooperation_declining:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_330(BaseStrategy):
    """
    Adaptive Threshold Exploitation strategy for Collective Risk Dilemma.
    
    Exploits asymmetry between cooperators and defectors by:
    1. Free-riding when threshold is met
    2. Conditionally cooperating only when necessary to unlock reward
    3. Dynamically pivoting based on observed cooperation rates
    4. Always defecting in final rounds to maximize terminal payoff
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_fraction = self.m / self.n
        self.last_round_cooperators = 0
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            if self.threshold_fraction <= 0.5:
                return Action.D
            else:
                return Action.C
        if round_num == self.r - 1:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[round_num - 1, :]))
        self.last_round_cooperators = cooperators_last_round
        self.cooperation_history.append(cooperators_last_round)
        coop_rate_last = cooperators_last_round / self.n
        threshold_met = coop_rate_last >= self.threshold_fraction
        if threshold_met:
            return Action.D
        if len(self.cooperation_history) >= 3:
            moving_avg_coop = np.mean(self.cooperation_history[-3:])
        elif len(self.cooperation_history) > 0:
            moving_avg_coop = np.mean(self.cooperation_history)
        else:
            moving_avg_coop = 0.0
        moving_avg_rate = moving_avg_coop / self.n
        if moving_avg_rate >= self.threshold_fraction:
            return Action.D
        if moving_avg_rate < 0.2 and round_num > 1:
            return Action.D
        deficit = self.m - cooperators_last_round
        rounds_remaining = self.r - round_num
        if round_num > 2 * self.r / 3:
            return Action.D
        if deficit > 0 and deficit <= 2 and (rounds_remaining > 1):
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_331(BaseStrategy):
    """
    Adaptive Defection with Conditional Cooperation strategy.
    
    Exploits the asymmetry in the Collective Risk Dilemma by defaulting to defection
    and only cooperating when empirical evidence strongly suggests the threshold will
    be met even without the player's contribution. Maximizes free-riding on others'
    cooperation while avoiding worst-case outcomes.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_rate = self.m / self.n_players
        self.safe_coop_margin = 0.1
        self.very_safe_margin = 0.15

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        if round_number == self.n_rounds - 2:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[round_number - 1, :]))
        coop_rate = cooperators_last_round / self.n_players
        if round_number >= 1 and round_number <= self.n_rounds - 3:
            if coop_rate >= self.threshold_rate + self.very_safe_margin:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_332(BaseStrategy):
    """
    Adaptive Threshold Parasitism: An exploitative strategy that minimizes personal
    contribution while maximizing free-riding on others' cooperation. Defects by default,
    rarely cooperates (only when threshold is nearly met with low probability), and
    guarantees defection in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        cooperation_count_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
        if cooperation_count_last_round >= self.m:
            return Action.D
        elif cooperation_count_last_round == self.m - 1:
            p_threshold = min(0.4, 1.0 / self.n)
            if random.random() < p_threshold:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_333(BaseStrategy):
    """
    Adaptive Threshold Dominance (ATD): An exploitative strategy that defaults to defection
    and only cooperates when necessary to trigger the threshold, then immediately reverts to
    defection to capture rewards without bearing costs.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.self_cooperated_last = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            self.self_cooperated_last = False
            return Action.D
        coop_count = int(sum(history.opponent_actions[current_round - 1, :]))
        if current_round > 0:
            coop_count += int(history.my_actions[current_round - 1])
        rounds_remaining = r - current_round - 1
        if coop_count >= m:
            self.self_cooperated_last = False
            return Action.D
        if coop_count == m - 1:
            if rounds_remaining > 0:
                self.self_cooperated_last = True
                return Action.C
            else:
                self.self_cooperated_last = False
                return Action.D
        if coop_count < m - 1:
            self.self_cooperated_last = False
            return Action.D
        self.self_cooperated_last = False
        return Action.D

class Strategy_EXPLOITATIVE_334(BaseStrategy):
    """
    Adaptive Threshold Exploitation (ATE) Strategy.
    
    This strategy unconditionally defects in all rounds. It exploits the payoff
    asymmetry where defection yields (1 + k) when others cooperate and meet the
    threshold, while cooperation yields only k. By always defecting, the strategy
    free-rides on cooperators' efforts while avoiding the cost of contribution.
    
    Decision Rule:
    - Round 0 (first round): DEFECT (no history, minimize risk)
    - Rounds 1 to r-2 (middle rounds): DEFECT (exploit any cooperators)
    - Round r-1 (final round): DEFECT (maximum extraction, no future consequences)
    
    The core insight is that in a simultaneous-move, no-communication game,
    defection is always at least as good as cooperation, making unconditional
    defection a strictly dominant strategy.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        return Action.D

class Strategy_EXPLOITATIVE_335(BaseStrategy):
    """
    Adaptive Threshold Hunting: An exploitative strategy that free-rides when the
    cooperation threshold is met, strategically defects to destabilize cooperation,
    and uses selective cooperation (â‰¤30% of rounds) as camouflage to maintain minimal
    threshold triggering while maximizing personal defection payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        last_round_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        my_cooperation_count = int(np.sum(history.my_actions[:current_round]))
        rounds_played = current_round
        cooperation_frequency = my_cooperation_count / rounds_played if rounds_played > 0 else 0.0
        deficit = self.m - last_round_cooperators
        if last_round_cooperators >= self.m:
            return Action.D
        if deficit == 1:
            return Action.D
        if deficit >= 2:
            if deficit <= 2 and cooperation_frequency <= 0.3:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_336(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD) Strategy for Collective Risk Dilemma.
    
    Exploits the asymmetry between cooperators and defectors by:
    1. Always defecting in round 1 and final round
    2. Defecting when threshold was met (free-riding)
    3. Conditionally cooperating only when cooperation is building (â‰¥50%)
      and threshold is mathematically achievable
    4. Abandoning cooperation when it collapses or becomes impossible
    
    Core principle: Maximize payoff by free-riding on others' cooperation
    while maintaining minimal credibility to keep threshold-meeting possible.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        k = self.game_description.k
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        prev_round_idx = current_round - 1
        prev_cooperators_total = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        threshold_met_prev = prev_cooperators_total >= m
        if threshold_met_prev:
            return Action.D
        cooperation_deficit = m - prev_cooperators_total
        rounds_remaining = r - current_round
        max_possible_cooperators = (n - 1) * rounds_remaining
        if cooperation_deficit > max_possible_cooperators:
            return Action.D
        if prev_cooperators_total == 0:
            return Action.D
        cooperative_fraction = prev_cooperators_total / (n - 1)
        if cooperative_fraction >= 0.5:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_337(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Thresholds.
    
    A ruthlessly exploitative strategy that:
    1. Defects in round 1 to gather information
    2. Free-rides on others' cooperation during mid-game
    3. Minimally cooperates only when threshold collapse threatens
    4. Maximally exploits in endgame (final rounds)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.total_cooperators_observed = 0
        self.total_actions_observed = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        coop_count_last_round = int(np.sum(history.opponent_actions[current_round - 1, :]))
        self.total_cooperators_observed += coop_count_last_round
        self.total_actions_observed += self.n_players - 1
        avg_coop_rate = self.total_cooperators_observed / self.total_actions_observed if self.total_actions_observed > 0 else 0.0
        rounds_remaining = self.n_rounds - current_round
        is_endgame = rounds_remaining <= 2
        if is_endgame:
            if current_round == self.n_rounds - 1:
                if coop_count_last_round >= self.m:
                    return Action.D
                else:
                    return Action.D
            elif coop_count_last_round >= self.m - 1:
                return Action.D
            elif coop_count_last_round == self.m - 2:
                return Action.C
            else:
                return Action.D
        threshold_ratio_m_minus_1 = (self.m - 1) / self.n_players
        threshold_ratio_m_minus_2 = (self.m - 2) / self.n_players
        if avg_coop_rate >= threshold_ratio_m_minus_1:
            return Action.D
        elif avg_coop_rate >= threshold_ratio_m_minus_2 and coop_count_last_round >= self.m - 1:
            return Action.D
        elif coop_count_last_round < self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_338(BaseStrategy):
    """
    Adaptive Threshold Extortion strategy for Collective Risk Dilemma.
    
    Core philosophy: Exploit asymmetry between cooperators and defectors by
    maximizing personal payoff while minimizing contribution. Free-ride on
    others' cooperation while punishing defection to maintain pressure.
    
    Decision logic:
    - Round 1: DEFECT (establish baseline, probe cooperation)
    - Last round: DEFECT (no future punishment possible)
    - Middle rounds: DEFECT (free-ride on successful cooperators or punish failures)
    - All other cases: DEFECT (lock in mutual defection equilibrium)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[state.round_number - 1, :]))
        m = self.game_description.m
        if cooperators_last_round >= m:
            return Action.D
        if cooperators_last_round > 0 and cooperators_last_round < m:
            return Action.D
        if cooperators_last_round == 0:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_339(BaseStrategy):
    """
    Adaptive Free-Riding with Threshold Exploitation Strategy.
    
    This strategy exploits the collective risk dilemma by:
    1. Defecting in round 1 to test opponents
    2. Free-riding when threshold is already met
    3. Becoming the pivotal cooperator when exactly one more cooperator is needed
    4. Defecting in the final round regardless of history
    5. Defecting when threshold is unachievable
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        previous_round_cooperators = int(sum(history.opponent_actions[state.round_number - 1, :]))
        m = self.game_description.m
        if previous_round_cooperators >= m:
            return Action.D
        if previous_round_cooperators == m - 1:
            return Action.D
        deficit = m - previous_round_cooperators
        if deficit == 1:
            return Action.C
        if deficit > 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_340(BaseStrategy):
    """
    Adaptive Threshold Vulturing: Exploit coordination by defecting by default,
    cooperating only when at least (m-1) other players are identified as reliable
    cooperators (â‰¥80% historical cooperation rate). Avoids risk while capturing
    rewards when threshold is mathematically certain to be met.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.reliability_threshold = 0.8

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            reliable_cooperators = self._count_reliable_cooperators(history)
            if reliable_cooperators >= self.m - 1:
                return Action.C
            return Action.D
        reliable_cooperators = self._count_reliable_cooperators(history)
        if reliable_cooperators >= self.m - 1:
            return Action.C
        return Action.D

    def _count_reliable_cooperators(self, history: PlayerHistory) -> int:
        """
        Count how many other players have shown â‰¥80% cooperation rate
        across all rounds seen so far.
        """
        if history.opponent_actions.shape[0] == 0:
            return 0
        n_rounds_played = history.opponent_actions.shape[0]
        reliable_count = 0
        for player_idx in range(self.n_players - 1):
            player_cooperations = history.opponent_actions[:n_rounds_played, player_idx].sum()
            cooperation_rate = player_cooperations / n_rounds_played
            if cooperation_rate >= self.reliability_threshold:
                reliable_count += 1
        return reliable_count

class Strategy_EXPLOITATIVE_341(BaseStrategy):
    """
    Conditional Exploitation with Adaptive Defection strategy for Collective Risk Dilemma.
    
    Exploits the asymmetry in payoffs by free-riding on others' cooperation.
    Uses adaptive threshold detection to identify when cooperation is likely to succeed,
    then defects to maximize extraction. Unconditionally defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.n_rounds - 1:
            return Action.D
        if round_num >= 1 and round_num < self.n_rounds - 1:
            lookback_window = min(3, round_num)
            coop_count = 0
            for t in range(round_num - lookback_window, round_num):
                coop_count += int(np.sum(history.opponent_actions[t, :]))
            total_observations = lookback_window * self.n_players
            if total_observations == 0:
                recent_coop_rate = 0.0
            else:
                recent_coop_rate = coop_count / total_observations
            threshold_indicator = self.m / self.n_players
            if recent_coop_rate >= threshold_indicator - 0.15:
                return Action.D
            else:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_342(BaseStrategy):
    """
    Adaptive Threshold Exploitation Strategy for Collective Risk Dilemma.
    
    Exploits the asymmetry between cooperators and defectors by:
    1. Always defecting in round 1 to establish non-cooperative stance
    2. Free-riding on others' cooperation when threshold is likely met
    3. Defecting strategically to avoid wasted contributions
    4. Always defecting in final round (no future punishment possible)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.n_rounds - 1:
            return Action.D
        previous_round_idx = state.round_number - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[previous_round_idx, :]))
        if cooperators_last_round >= self.m:
            return Action.D
        if cooperators_last_round >= self.m - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_343(BaseStrategy):
    """
    Adaptive Defection with Conditional Cooperation (ADCC):
    Exploitative strategy that defects by default, cooperates conditionally only when pivotal
    to maintaining the cooperation threshold, then resumes defection.
    
    Core principle: Free-ride on others' cooperation when threshold is met, cooperate sparingly
    only when critical to prevent all-defection collapse, defect entirely in final rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round >= self.n_rounds - 2:
            return Action.D
        if current_round == 0:
            return Action.D
        prev_round_actions = history.opponent_actions[current_round - 1, :]
        coop_count_prev = int(np.sum(prev_round_actions))
        threshold_met_prev = coop_count_prev >= self.m
        if not threshold_met_prev:
            return Action.D
        if coop_count_prev <= self.m:
            defectors_count = self.n_players - coop_count_prev
            if defectors_count > 0 and coop_count_prev == self.m:
                return Action.D
            elif coop_count_prev < self.m:
                return Action.D
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_344(BaseStrategy):
    """
    Exploitative Strategy: Conditional Free-Riding with Adaptive Threshold
    
    Maximizes personal payoff by exploiting the threshold mechanism.
    Always defects except possibly in round 1, using historical cooperation rates
    to estimate when the threshold will be met by others.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        if history is None:
            return Action.D
        total_opponent_cooperations = np.sum(history.opponent_actions[:round_number, :])
        total_observations = round_number * (self.n_players - 1)
        if total_observations == 0:
            return Action.D
        observed_cooperation_rate = total_opponent_cooperations / total_observations
        expected_cooperators = observed_cooperation_rate * (self.n_players - 1)
        if expected_cooperators >= self.m - 0.5:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_345(BaseStrategy):
    """
    Adaptive Threshold Exploitation Strategy for Collective Risk Dilemma.
    
    Exploits the asymmetry in payoffs by:
    1. Defecting in round 1 and final round unconditionally
    2. Parasitizing thresholds when others have cooperated sufficiently
    3. Randomizing as a swing player to maintain strategic ambiguity
    4. Adapting to cooperation trends in low-threshold environments
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        cooperation_count = int(sum(history.opponent_actions[round_num - 1, :]))
        if cooperation_count >= self.m - 1:
            return Action.D
        if cooperation_count == self.m - 2:
            defect_probability = (self.k - 1) / self.k
            if random.random() < defect_probability:
                return Action.D
            else:
                return Action.C
        if cooperation_count < self.m - 2:
            start_round = max(0, round_num - 3)
            recent_actions = history.opponent_actions[start_round:round_num, :]
            if recent_actions.size > 0:
                recent_total_cooperations = np.sum(recent_actions)
                recent_total_opportunities = recent_actions.size
                recent_avg_cooperation = recent_total_cooperations / recent_total_opportunities
            else:
                recent_avg_cooperation = 0.0
            threshold_ratio = self.m / self.n
            if recent_avg_cooperation > 0.7 * threshold_ratio:
                return Action.D
            elif recent_avg_cooperation > 0.4 * threshold_ratio:
                return Action.D
            else:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_346(BaseStrategy):
    """
    Adaptive Free-Riding with Conditional Defection.
    
    Exploits threshold mechanics by free-riding on others' cooperation.
    Defects by default, cooperates only when conditions for maximum benefit are met.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_timer = 0
        self.unstable_cooperation_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        prev_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if self.punishment_timer > 0:
            self.punishment_timer -= 1
            return Action.D
        if prev_cooperators == m - 1:
            return Action.C
        if current_round >= r - 1:
            all_previous_failed = True
            for round_idx in range(current_round):
                round_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
                if round_cooperators >= m:
                    all_previous_failed = False
                    break
            if all_previous_failed:
                return Action.C
        if current_round >= 2:
            prev_prev_cooperators = int(np.sum(history.opponent_actions[current_round - 2, :]))
            if prev_cooperators >= m and prev_prev_cooperators >= m:
                return Action.C
        if current_round >= 2:
            prev_prev_cooperators = int(np.sum(history.opponent_actions[current_round - 2, :]))
            if prev_prev_cooperators < m and prev_cooperators >= m:
                self.unstable_cooperation_count += 1
                if self.unstable_cooperation_count >= 2:
                    self.punishment_timer = 2
                    return Action.D
        if current_round >= 2:
            prev_cooperators_count = int(np.sum(history.opponent_actions[current_round - 1, :]))
            prev_prev_cooperators_count = int(np.sum(history.opponent_actions[current_round - 2, :]))
            if prev_cooperators_count < m - 1 and prev_prev_cooperators_count < m - 1:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_347(BaseStrategy):
    """
    Calculated Defection with Opportunistic Cooperation strategy.
    
    Exploits asymmetry in payoffs by free-riding on others' cooperation.
    - Round 1: Defect to probe opponents
    - Rounds 2 to r-1: Defect regardless of history (always capture 1+k or 1)
    - Final round: Defect (no future consequences)
    
    Core principle: Never cooperate, always defect to maximize payoff capture.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        previous_round_idx = state.round_number - 1
        coop_count = int(np.sum(history.opponent_actions[previous_round_idx, :]))
        return Action.D

class Strategy_EXPLOITATIVE_348(BaseStrategy):
    """
    Adaptive Free-Riding with Threshold Exploitation Strategy.
    
    Exploits the collective risk dilemma by strategically defecting when others
    are likely to cooperate, while maintaining just enough cooperators to trigger
    the reward threshold. Maximizes payoff by free-riding on others' cooperation
    while capturing the k-factor benefit.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        if t == 0:
            return Action.D
        if t == self.r - 1:
            return Action.D
        c_prev = int(sum(history.opponent_actions[t - 1, :]))
        defection_bias = 0.3 if t == self.r - 2 else 0.0
        if c_prev >= self.m:
            return Action.D
        elif c_prev == self.m - 1:
            defection_prob = 0.7 + defection_bias
            return Action.D if random.random() < defection_prob else Action.C
        else:
            return Action.C

class Strategy_EXPLOITATIVE_349(BaseStrategy):
    """
    Adaptive Defection with Conditional Cooperation.
    
    Exploits the threshold structure by defecting when safe, cooperating only when
    marginal (exactly m-1 others have cooperated), and always defecting in round 1
    and the final round. Maximizes payoff through free-riding on others' cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        n_rounds = self.game_description.n_rounds
        m = self.game_description.m
        if round_number == 0:
            return Action.D
        if round_number == n_rounds - 1:
            return Action.D
        previous_round_index = round_number - 1
        cooperators_previous_round = int(sum(history.opponent_actions[previous_round_index, :]))
        if cooperators_previous_round >= m:
            return Action.D
        if cooperators_previous_round == m - 1:
            return Action.C
        if cooperators_previous_round < m - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_350(BaseStrategy):
    """
    Adaptive Threshold Exploitation (ATE) Strategy
    
    Exploits the asymmetry between cooperators and defectors by:
    - Always defecting in round 1 (gather intelligence)
    - Defecting in rounds 2-(r-1) unless threshold was just met
    - Always defecting in final round (endgame exploitation)
    
    This strategy treats cooperation as a resource to harvest, not a mutual commitment.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        m = self.game_description.m
        k = self.game_description.k
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == r - 1:
            return Action.D
        last_round_actions = history.opponent_actions[round_number - 1, :]
        coop_count = int(np.sum(last_round_actions))
        if history.my_actions[round_number - 1]:
            coop_count += 1
        rounds_remaining = r - round_number - 1
        if coop_count >= m and rounds_remaining >= 1:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_351(BaseStrategy):
    """
    Adaptive Threshold Exploitation strategy for Collective Risk Dilemma.
    
    Exploits the payoff asymmetry where defectors earn 1+k while cooperators earn 0+k
    when threshold is met. Uses three phases:
    1. Reconnaissance: Detect opponent cooperation patterns
    2. Exploitation: Free-ride when threshold is reliably met
    3. Endgame: Unconditional defection in final rounds
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.recon_end = math.floor(self.r / 3)
        self.endgame_start = self.r - 1
        self.last_phase2_decision = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        opponent_coop_count = np.sum(history.opponent_actions[:round_num, :])
        opponent_total_actions = (self.n - 1) * round_num
        if opponent_total_actions == 0:
            coop_rate = 0.0
        else:
            coop_rate = opponent_coop_count / opponent_total_actions
        expected_cooperators = coop_rate * (self.n - 1)
        if round_num <= self.recon_end:
            if expected_cooperators >= self.m - 1:
                return Action.C
            else:
                return Action.D
        elif round_num == self.endgame_start:
            if expected_cooperators >= self.m:
                self.last_phase2_decision = Action.D
                return Action.D
            elif self.last_phase2_decision is not None:
                return self.last_phase2_decision
            else:
                return Action.D
        elif round_num == self.r - 1:
            return Action.D
        elif expected_cooperators >= self.m:
            self.last_phase2_decision = Action.D
            return Action.D
        elif expected_cooperators >= self.m - 2:
            if random.random() < 0.8:
                self.last_phase2_decision = Action.D
                return Action.D
            else:
                self.last_phase2_decision = Action.C
                return Action.C
        elif expected_cooperators + 1 >= self.m:
            self.last_phase2_decision = Action.C
            return Action.C
        else:
            self.last_phase2_decision = Action.D
            return Action.D

class Strategy_EXPLOITATIVE_352(BaseStrategy):
    """
    Adaptive Threshold Farming: Exploitative strategy that maximizes personal payoff
    by systematically defecting while exploiting the threshold mechanism.
    
    Core logic:
    - Round 1: Defect to gather information cheaply
    - Final round: Defect for pure exploitation (no future consequences)
    - Middle rounds: Defect to free-ride on others' cooperation
    
    This strategy exploits the structural property that defection yields k+1 when
    threshold is met, while cooperation yields only k.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        if history is not None and len(history.opponent_actions) > 0:
            previous_round_actions = history.opponent_actions[current_round - 1, :]
            cooperators_last_round = int(np.sum(previous_round_actions))
            if cooperators_last_round >= self.m - 1:
                return Action.D
            elif cooperators_last_round == 0:
                return Action.D
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_353(BaseStrategy):
    """
    Adaptive Free-Rider with Defection Targeting strategy for Collective Risk Dilemma.
    
    Exploits cooperative players by defecting when threshold success is probable,
    while adapting defection intensity based on game phase and observed cooperation rates.
    Uses dynamic thresholds that become more aggressive as the game progresses.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        last_round_actions = history.opponent_actions[current_round - 1, :]
        cooperators_last_round = int(np.sum(last_round_actions))
        p_coop = cooperators_last_round / (self.n - 1) if self.n > 1 else 0.0
        p_success_next = self._estimate_threshold_success(p_coop)
        threshold = self._get_threshold(current_round)
        if p_success_next >= threshold:
            return Action.D
        if cooperators_last_round < self.m - 1:
            return Action.D
        ev_defect = 1.0 + self.k * p_success_next
        ev_cooperate = 0.0 + self.k * p_success_next
        if ev_defect > ev_cooperate:
            return Action.D
        return Action.C

    def _get_threshold(self, current_round: int) -> float:
        """
        Determine adaptive threshold based on game phase.
        
        - Early rounds: 0.60 (high bar for defection, gather info)
        - Mid rounds: 0.50 (standard threshold)
        - Late rounds: 0.40 (aggressive, exploit before endgame)
        """
        third = self.r / 3.0
        if current_round <= third:
            return 0.6
        elif current_round < 2.0 * third:
            return 0.5
        else:
            return 0.4

    def _estimate_threshold_success(self, p_coop: float) -> float:
        """
        Estimate probability that >= m players will cooperate.
        
        Assumes cooperation rate p_coop applies to all n-1 other players.
        Uses binomial probability calculation.
        """
        if p_coop <= 0.0:
            return 0.0
        if p_coop >= 1.0:
            return 1.0
        n_others = self.n - 1
        m_needed = self.m
        if m_needed > n_others:
            return 0.0
        prob_success = 0.0
        for k in range(m_needed, n_others + 1):
            prob_success += self._binomial_probability(n_others, k, p_coop)
        return prob_success

    def _binomial_probability(self, n: int, k: int, p: float) -> float:
        """
        Calculate binomial probability P(X = k) where X ~ Binomial(n, p).
        Uses logarithms to avoid overflow with large factorials.
        """
        if k < 0 or k > n:
            return 0.0
        log_binom = self._log_comb(n, k)
        if p <= 0.0:
            return 1.0 if k == 0 else 0.0
        if p >= 1.0:
            return 1.0 if k == n else 0.0
        log_prob = log_binom + k * math.log(p) + (n - k) * math.log(1.0 - p)
        return max(0.0, min(1.0, math.exp(log_prob)))

    def _log_comb(self, n: int, k: int) -> float:
        """
        Calculate log of binomial coefficient C(n, k).
        """
        if k > n or k < 0:
            return float('-inf')
        if k == 0 or k == n:
            return 0.0
        k = min(k, n - k)
        result = 0.0
        for i in range(k):
            result += math.log(n - i) - math.log(i + 1)
        return result

class Strategy_EXPLOITATIVE_354(BaseStrategy):
    """
    Threshold Rider: Exploitative strategy using adaptive defection with conditional cooperation.
    
    Core mechanics:
    - Always defect in round 1 and last two rounds (no future consequences)
    - In middle rounds, defect if threshold already met (free-ride)
    - Cooperate with low probability only when near threshold (m-1 cooperators) 
      and sufficient rounds remain to benefit from k rewards
    - Exploits asymmetry: defection pays (1+k) when others cooperate, vs (0+k) for cooperation
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if current_round == 0:
            return Action.D
        if current_round >= r - 2:
            return Action.D
        last_round_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        threshold_met = last_round_cooperators >= m
        if threshold_met:
            return Action.D
        rounds_remaining = r - current_round - 1
        if last_round_cooperators == m - 1 and rounds_remaining >= 2:
            if rounds_remaining >= 3:
                prob_cooperate = min(0.5, 1.0 / n)
            else:
                prob_cooperate = min(0.2, 1.0 / n)
            if random.random() < prob_cooperate:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_355(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation
    
    Exploits the asymmetry in payoff structure by:
    1. Defecting in round 1 to establish as potential defector
    2. In middle rounds, adapting to previous round's cooperation count
    3. Defecting in final round (no future consequences)
    4. Free-riding when threshold is met, cooperating only when pivotal
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        previous_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if previous_cooperators >= m:
            return Action.D
        elif previous_cooperators == m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_356(BaseStrategy):
    """
    Adaptive Free-Riding with Threshold Parasitism strategy.
    
    Exploits the coordination problem in threshold games by:
    1. Defecting when cooperation will likely succeed anyway (free-riding)
    2. Adapting based on observed cooperation rates
    3. Using pivotality detection to minimize obvious exploitation
    4. Switching to cooperation-maintenance mode when threshold is at risk
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        prev_cooperation_count = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if current_round == 1:
            cooperation_rate = prev_cooperation_count / self.n
            cooperation_trend = 0.0
        else:
            total_cooperators = int(np.sum(history.opponent_actions[:current_round, :]))
            cooperation_rate = total_cooperators / (current_round * self.n)
            window_size = min(3, current_round)
            recent_cooperators = int(np.sum(history.opponent_actions[current_round - window_size:current_round, :]))
            cooperation_trend = recent_cooperators - window_size * self.n * cooperation_rate
        threshold_rate = self.m / self.n
        if prev_cooperation_count >= self.m:
            return Action.D
        if prev_cooperation_count == self.m - 1:
            if cooperation_trend >= 0:
                return Action.D
            else:
                return Action.C
        if prev_cooperation_count < self.m - 1:
            if cooperation_rate < threshold_rate * 0.8:
                if current_round >= self.r - 2:
                    return Action.C
                else:
                    if current_round >= 2:
                        recent_rounds_cooperation = int(np.sum(history.opponent_actions[max(0, current_round - 2):current_round, :]))
                        if recent_rounds_cooperation >= self.m:
                            return Action.D
                    return Action.C
            else:
                return Action.D
        if current_round == self.r - 1:
            if prev_cooperation_count >= self.m - 1:
                return Action.D
            else:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_357(BaseStrategy):
    """
    Adaptive Defection with Conditional Cooperation strategy.
    
    Exploits the payoff asymmetry by defecting whenever possible and only
    cooperating in the final round if evidence of cooperation is strong.
    Adapts based on observed cooperation counts from the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[state.round_number - 1, :]))
        if state.round_number == self.game_description.n_rounds - 1:
            if cooperators_last_round >= self.game_description.m:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_358(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Free-Riding with Conditional Defection
    
    Exploits the threshold mechanism by defaulting to defection and only cooperating
    when exactly m-1 others have cooperated (pivotal player position). Always defects
    in the final round to avoid reciprocal punishment.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == r - 1:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[round_number - 1, :]))
        if cooperators_last_round == m - 1:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_359(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Free-Riding with Conditional Participation
    
    Core philosophy: Exploit the threshold mechanism by minimizing personal contribution
    while maximizing extraction of collective rewards through persistent defection.
    
    Decision rule: Always defect. This unconditionally exploits the threshold mechanism:
    - Round 1: Defect to gather information and establish willingness to free-ride
    - Rounds 2 to r-1: Defect to exploit cooperators when threshold is met, or avoid
      wasted contribution when threshold is unreachable
    - Final round: Defect with no future retaliation possible
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_360(BaseStrategy):
    """
    Exploitative Adaptive Defection with Conditional Cooperation.
    
    Core strategy: Systematically free-ride on others' cooperation while minimizing
    exposure to collective failure. Defect in first round, last round, and middle rounds
    where cooperation rate suggests threshold will be met (to maximize payoff) or won't
    be met (to save endowment).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold_multiplier = 1.3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == r - 1:
            return Action.D
        if history is not None:
            previous_round_opponent_actions = history.opponent_actions[round_number - 1, :]
            cooperators_last_round = int(np.sum(previous_round_opponent_actions))
            my_previous_action = history.my_actions[round_number - 1]
            total_cooperators = cooperators_last_round + (1 if my_previous_action else 0)
            cooperation_rate = total_cooperators / n
            min_required_rate = m / n
            threshold_rate = min_required_rate * self.threshold_multiplier
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_361(BaseStrategy):
    """
    Exploitative Strategy: Conditional Free-Riding with Adaptive Defection
    
    Systematically free-rides when cooperation from others is likely, while minimizing
    exposure to collective failure. Treats other players as resources to be exploited
    rather than cooperators to be reciprocated with.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        cooperators_last = int(np.sum(history.opponent_actions[round_num - 1, :]))
        threshold_met_last = cooperators_last >= self.m
        if round_num == self.r - 1:
            if threshold_met_last:
                return Action.D
            estimated_cooperators = self._estimate_cooperators(cooperators_last, round_num, history)
            if estimated_cooperators >= self.m:
                return Action.D
            else:
                coop_probability = self.m / self.n
                return Action.C if random.random() < coop_probability else Action.D
        if threshold_met_last:
            return Action.D
        defectors_last = self.n - cooperators_last
        defection_sensitivity = 0.3
        expected_cooperators = cooperators_last * (1.0 - defection_sensitivity)
        if expected_cooperators >= self.m:
            return Action.D
        rounds_remaining = self.r - round_num
        if rounds_remaining <= 2:
            return Action.C
        cooperation_trend = 0
        if round_num > 0:
            cooperators_prev = int(np.sum(history.opponent_actions[round_num - 2, :])) if round_num >= 1 else self.n
            cooperation_trend = cooperators_last - cooperators_prev
        if cooperation_trend < 0 and cooperators_last < self.m:
            return Action.D
        if defectors_last > 0:
            defection_rate = defectors_last / self.n
            max_defectors_allowed = (self.n - self.m) / self.n
            if defection_rate > max_defectors_allowed:
                return Action.D
        if cooperators_last > 0 and cooperators_last < self.m / 2.0:
            return Action.D
        return Action.D

    def _estimate_cooperators(self, cooperators_last: int, round_num: int, history: PlayerHistory) -> float:
        """
        Estimate expected cooperators for the current round based on recent trends.
        """
        if round_num < 2:
            return float(cooperators_last)
        cooperators_prev = int(np.sum(history.opponent_actions[round_num - 2, :]))
        cooperation_trend = cooperators_last - cooperators_prev
        trend_dampening = 0.5
        estimated = cooperators_last + cooperation_trend * trend_dampening
        estimated = max(0.0, min(float(self.n), estimated))
        return estimated

class Strategy_EXPLOITATIVE_362(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation
    
    Exploits asymmetry in payoff structure by defecting when safe, cooperating
    conditionally when cooperation is fragile, and always defecting in final round.
    Uses reconnaissance phase to assess cooperation propensity of the population.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round <= 1:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        if history is None or len(history.opponent_actions) < 2:
            return Action.D
        cooperators_round_0 = float(np.sum(history.opponent_actions[0, :]))
        cooperators_round_1 = float(np.sum(history.opponent_actions[1, :]))
        total_observed = cooperators_round_0 + cooperators_round_1
        denominator = 2 * (self.n - 1)
        if denominator <= 0:
            cooperation_rate = 0.0
        else:
            cooperation_rate = total_observed / denominator
        threshold_rate = self.m / self.n
        if cooperation_rate >= threshold_rate:
            return Action.D
        elif cooperation_rate < threshold_rate - 0.15:
            if current_round > 0:
                cooperators_last_round = float(np.sum(history.opponent_actions[current_round - 1, :]))
                if cooperators_last_round >= self.m:
                    return Action.C
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_363(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD) Strategy for Collective Risk Dilemma.
    
    Exploits asymmetry in payoffs by defecting most of the time while parasitizing
    cooperators when the threshold is likely to be met. Uses observed cooperation rates
    to adaptively decide between defection and occasional cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        total_cooperators = 0
        total_slots = 0
        for round_idx in range(current_round):
            if history.my_actions[round_idx]:
                total_cooperators += 1
            total_cooperators += np.sum(history.opponent_actions[round_idx, :])
            total_slots += self.n_players
        if total_slots == 0:
            coop_rate = 0.0
        else:
            coop_rate = total_cooperators / total_slots
        threshold_rate = self.m / self.n_players
        if coop_rate >= threshold_rate * 1.2:
            return Action.D
        elif coop_rate < threshold_rate * 0.8:
            return Action.D
        else:
            coop_prob = min(0.3, max(0.0, coop_rate - 0.1))
            if random.random() < coop_prob:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_364(BaseStrategy):
    """
    Adaptive Threshold Exploitation Strategy for Collective Risk Dilemma.
    
    Core Philosophy: Exploit the asymmetry between cooperators and defectors by
    free-riding on others' cooperation while never bearing the cooperation cost.
    Always defect to avoid vulnerability and maximize payoff extraction.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        previous_round_index = state.round_number - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[previous_round_index, :]))
        return Action.D

class Strategy_EXPLOITATIVE_365(BaseStrategy):
    """
    Adaptive Threshold Predation: An exploitative strategy that maximizes payoff by:
    1. Always defecting in round 1 (information gathering)
    2. Defecting in final round (no future punishment)
    3. In middle rounds: defecting unless mathematically essential to reach threshold
    4. Using exponentially-weighted moving average of opponent cooperation to detect changes
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = []
        self.weighted_coop_rate = 0.0
        self.ewma_alpha = 0.3
        self.buffer = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        opponent_actions = history.opponent_actions
        total_cooperations = 0
        total_opportunities = 0
        for round_idx in range(state.round_number):
            round_cooperators = np.sum(opponent_actions[round_idx, :])
            total_cooperations += round_cooperators
            total_opportunities += self.game_description.n_players
        if total_opportunities == 0:
            cooperation_rate = 0.0
        else:
            cooperation_rate = total_cooperations / total_opportunities
        if state.round_number == 1:
            self.weighted_coop_rate = cooperation_rate
        else:
            self.weighted_coop_rate = self.ewma_alpha * cooperation_rate + (1 - self.ewma_alpha) * self.weighted_coop_rate
        threshold_cushion = (self.game_description.m + self.buffer) / self.game_description.n_players
        marginal_threshold = (self.game_description.m - 1) / self.game_description.n_players
        if self.weighted_coop_rate >= threshold_cushion:
            return Action.D
        elif self.weighted_coop_rate >= marginal_threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_366(BaseStrategy):
    """
    Exploitative strategy: "Calculated Defection with Conditional Cooperation"
    
    Exploits the asymmetry in payoffs by:
    1. Defecting in round 1 to probe cooperator behavior
    2. In middle rounds: defecting when threshold is met (free-riding),
       cooperating only when pivotal (coop_count == m-1), defecting otherwise
    3. Defecting in final round for maximum end-game exploitation
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        m = self.game_description.m
        k = self.game_description.k
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if cooperators_last_round >= m:
            return Action.D
        elif cooperators_last_round == m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_367(BaseStrategy):
    """
    Adaptive Free-Riding with Conditional Escalation strategy.
    
    Exploits the threshold structure by free-riding when others cooperate,
    while maintaining just enough cooperation to avoid collective failure
    when strategically beneficial. Uses a simple decision rule based on
    the previous round's cooperation count.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        previous_round_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        if previous_round_cooperators >= m:
            return Action.D
        elif previous_round_cooperators == m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_368(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Defection strategy.
    
    Exploits the threshold structure of the Collective Risk Dilemma by:
    1. Always defecting in round 1 (exploration)
    2. Defecting in the final round (no reputation value)
    3. In middle rounds, monitoring opponent cooperation rates and free-riding
       when the threshold is likely to be met by others
    4. Always defecting when threshold is unlikely to be met anyway
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        observation_window = min(3, current_round)
        opponent_cooperations = 0
        for round_idx in range(current_round - observation_window, current_round):
            opponent_cooperations += int(np.sum(history.opponent_actions[round_idx, :]))
        total_opponent_decisions = observation_window * (n - 1)
        if total_opponent_decisions == 0:
            return Action.D
        recent_coop_rate = opponent_cooperations / total_opponent_decisions
        threshold_coop_rate = (m - 1) / (n - 1)
        return Action.D

class Strategy_EXPLOITATIVE_369(BaseStrategy):
    """
    Adaptive Threshold Farming: An exploitative strategy that free-rides on others'
    cooperation by defecting whenever the cooperation threshold is likely to be met,
    while avoiding contribution costs.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number >= self.r - 2:
            return Action.D
        rounds_played = round_number
        total_cooperations = np.sum(history.opponent_actions[:round_number, :])
        if rounds_played == 0 or self.n == 0:
            return Action.D
        freq_coop = total_cooperations / (rounds_played * self.n)
        expected_cooperators = freq_coop * self.n
        high_cooperation_threshold = self.m * 0.8
        low_cooperation_threshold = self.m * 0.6
        if expected_cooperators >= high_cooperation_threshold:
            return Action.D
        elif expected_cooperators < low_cooperation_threshold:
            return Action.D
        else:
            lookback_rounds = min(4, round_number)
            if lookback_rounds < 1:
                return Action.D
            recent_coop_counts = np.sum(history.opponent_actions[round_number - lookback_rounds:round_number, :], axis=1)
            if len(recent_coop_counts) > 1:
                volatility = float(np.std(recent_coop_counts))
            else:
                volatility = 0.0
            if volatility > 0.5:
                return Action.D
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_370(BaseStrategy):
    """
    Adaptive Defection with Opportunistic Exploitation strategy.
    
    Exploits the payoff asymmetry where defectors gain 1+k when others cooperate,
    while cooperators only gain k. Uses adaptive defection based on observed
    cooperation rates, with strategic show-cooperation in early rounds to prevent
    coordinated punishment, and aggressive final-round defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = []
        self.show_cooperation_used = False
        self.early_rounds_end = max(1, math.ceil(game_description.n_rounds / 3))
        self.mid_rounds_end = math.floor(2 * game_description.n_rounds / 3)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        self._update_cooperation_history(history)
        current_round = state.round_number
        if current_round <= self.early_rounds_end:
            return self._early_round_decision()
        elif current_round <= self.mid_rounds_end:
            return self._mid_round_decision()
        else:
            return Action.D

    def _update_cooperation_history(self, history: PlayerHistory) -> None:
        """Extract cooperation counts from opponent actions in all previous rounds."""
        for round_idx in range(len(history.opponent_actions)):
            cooperations = sum(history.opponent_actions[round_idx, :])
            self.cooperation_history.append(cooperations)

    def _get_cooperation_likelihood(self) -> float:
        """
        Calculate CL = (total cooperations observed) / (total possible cooperations).
        Handles edge case of no history.
        """
        if not self.cooperation_history:
            return 0.0
        total_cooperations = sum(self.cooperation_history)
        total_possible = len(self.cooperation_history) * self.game_description.n_players
        if total_possible == 0:
            return 0.0
        return total_cooperations / total_possible

    def _early_round_decision(self) -> Action:
        """
        EARLY ROUNDS (t âˆˆ [1, âŒˆr/3âŒ‰]):
        - Default: DEFECT
        - Exception: If CL > (m/n) - 0.15 and haven't used show-cooperation yet,
          COOPERATE once to appear conditionally reciprocal, then resume defection.
        """
        cl = self._get_cooperation_likelihood()
        threshold = self.game_description.m / self.game_description.n_players - 0.15
        if not self.show_cooperation_used and cl > threshold:
            self.show_cooperation_used = True
            return Action.C
        return Action.D

    def _mid_round_decision(self) -> Action:
        """
        MID ROUNDS (t âˆˆ [âŒˆr/3âŒ‰ + 1, âŒŠ2r/3âŒ‹]):
        - Calculate threshold_gap = m - floor(n * CL)
        - If threshold_gap â‰¤ 1 or â‰¥ n-2: DEFECT
        - Else check cooperation_momentum from last 2 rounds
        - If momentum > 0.4: DEFECT (exploit rising cooperation)
        - Else: DEFECT
        
        Note: Strategy always defects in mid-rounds per specification.
        """
        cl = self._get_cooperation_likelihood()
        threshold_gap = self.game_description.m - math.floor(self.game_description.n_players * cl)
        if threshold_gap <= 1 or threshold_gap >= self.game_description.n_players - 2:
            return Action.D
        cooperation_momentum = self._get_recent_cooperation_momentum(rounds=2)
        if cooperation_momentum > 0.4:
            return Action.D
        else:
            return Action.D

    def _get_recent_cooperation_momentum(self, rounds: int) -> float:
        """
        Calculate cooperation momentum from last N rounds.
        momentum = (cooperations in last N rounds) / (N * n)
        """
        if not self.cooperation_history:
            return 0.0
        recent_rounds = self.cooperation_history[-rounds:]
        total_cooperations = sum(recent_rounds)
        total_possible = rounds * self.game_description.n_players
        if total_possible == 0:
            return 0.0
        return total_cooperations / total_possible

class Strategy_EXPLOITATIVE_371(BaseStrategy):
    """
    Conditional Freeloading with Adaptive Defection strategy.
    
    Maximizes payoff by exploiting the threshold mechanism:
    - Phase 1 (Rounds 0-1): Defect to gather baseline cooperation data
    - Phase 2 (Rounds 2 to r-2): Adapt based on observed cooperation rate
    - Phase 3 (Final round): Unconditional defection
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.baseline_coop_rate = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round < 2:
            return Action.D
        if self.baseline_coop_rate is None:
            if history is not None and len(history.opponent_actions) >= 2:
                cooperators_round0 = np.sum(history.opponent_actions[0, :])
                cooperators_round1 = np.sum(history.opponent_actions[1, :])
                total_coop = cooperators_round0 + cooperators_round1
                self.baseline_coop_rate = total_coop / (2 * n)
            else:
                self.baseline_coop_rate = 0.0
        expected_cooperators = self.baseline_coop_rate * n
        if current_round == r - 1:
            return Action.D
        if expected_cooperators >= m:
            return Action.D
        elif expected_cooperators < m - 1:
            if current_round % 3 == 0:
                return Action.C
            else:
                return Action.D
        elif current_round % 5 == 0:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_372(BaseStrategy):
    """
    Adaptive Threshold Exploitation Strategy for Collective Risk Dilemma.
    
    Core philosophy: Exploit the asymmetry in payoffs between cooperators and 
    defectors when the threshold is met. Systematically defect while allowing 
    others to bear cooperation costs, free-riding on threshold achievement.
    
    Decision rule: Always defect. Defection is optimal across all rounds:
    - Round 1: Establish baseline; observe others without commitment
    - Final round: No future consequences; exploit any threshold achieved
    - Middle rounds: If threshold met by others, free-ride (1+k > 0+k)
                    If threshold not met, cooperation is futile (0 vs 1)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_373(BaseStrategy):
    """
    Adaptive Threshold Parasitism: An exploitative strategy that free-rides on cooperators
    by defecting when the threshold is met, while occasionally cooperating to maintain
    the minimum viable cooperator pool.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperator_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if round_num < min(3, r - 1):
            return Action.D
        if round_num == r - 1:
            return Action.D
        if history is None:
            observed_cooperators = 0
        else:
            observed_cooperators = int(np.sum(history.opponent_actions[round_num - 1, :]))
        if observed_cooperators >= m:
            return Action.D
        elif observed_cooperators == m - 1:
            p_emergency = min(0.6, m / n)
            if random.random() < p_emergency:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_374(BaseStrategy):
    """
    Adaptive Threshold Defection: An exploitative strategy that always defects.
    
    Core philosophy: Exploit the asymmetry between defectors and cooperators by
    consistently defecting to capture private value (1) while free-riding on any
    collective reward (k) when the cooperation threshold is met. This strategy
    dominates all observable responses and avoids mutual punishment traps.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_375(BaseStrategy):
    """
    Adaptive Threshold Parasitism: An exploitative strategy that free-rides on 
    cooperation in collective risk dilemmas. Always defects to capture the threshold 
    bonus without contributing, while maintaining minimal complexity.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_376(BaseStrategy):
    """
    Adaptive Threshold Defection: Exploitative strategy that maximizes payoff by free-riding
    when threshold is met, while conditionally cooperating only when threshold is at risk
    and the game is early enough to matter.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        cooperators_prev = int(np.sum(history.opponent_actions[round_num - 1, :]))
        coop_fraction = cooperators_prev / self.n
        threshold_fraction = self.m / self.n
        if coop_fraction >= threshold_fraction:
            return Action.D
        if coop_fraction >= threshold_fraction - 1.0 / self.n:
            if round_num == self.r - 1:
                return Action.D
            else:
                return Action.D
        if coop_fraction <= threshold_fraction - 2.0 / self.n:
            if round_num >= self.r - 2:
                return Action.D
            else:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_377(BaseStrategy):
    """
    Threshold Vulture: Exploitative Adaptive Defection with Selective Cooperation
    
    Core strategy: Defect by default to maximize payoff. Cooperate only when:
    1. Cooperation is at m-1 (one away from threshold failure)
    2. Near end of game with high cooperation likelihood
    3. Final round with m-1 cooperators (to secure k rather than 0)
    
    Exploits asymmetry: when threshold is met, defection yields +1 advantage over cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        cooperation_count = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if current_round == self.n_rounds - 1:
            if cooperation_count >= self.m:
                return Action.D
            elif cooperation_count >= self.m - 1:
                return Action.C
            else:
                return Action.D
        if cooperation_count >= self.m:
            return Action.D
        elif cooperation_count == self.m - 1:
            return Action.C
        elif cooperation_count >= self.m - 2:
            remaining_rounds = self.n_rounds - current_round
            if remaining_rounds <= 2:
                return Action.C
            else:
                return Action.D
        elif cooperation_count == 0 and current_round > self.n_rounds / 2:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_378(BaseStrategy):
    """
    Conditional Free-Riding with Dynamic Threshold Adjustment.
    
    Exploits the coordination burden on cooperators by free-riding on their
    contributions when the threshold is met, while using probabilistic cooperation
    near the threshold to prevent cascading defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        prev_round = current_round - 1
        prev_cooperators = int(np.sum(history.opponent_actions[prev_round, :]))
        coop_rate = prev_cooperators / self.n
        threshold_rate = self.m / self.n
        if coop_rate >= threshold_rate:
            return Action.D
        epsilon = 1.0 / self.n
        if coop_rate >= threshold_rate - epsilon:
            if threshold_rate > 0:
                coop_probability = coop_rate / threshold_rate
            else:
                coop_probability = 0.0
            if random.random() < coop_probability:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_379(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Threshold Strategy.
    
    Exploits the collective risk dilemma by systematically defecting while relying
    on others' cooperation, only cooperating when pivotal (when m-1 others are expected
    to cooperate and we're not in terminal rounds). Uses 75% threshold to classify
    opponent types and adapts expectations accordingly.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.reliable_coop_threshold = 0.75
        self.reliable_def_threshold = 0.75

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round >= r - 1:
            return Action.D
        reliable_coop, reliable_def, conditional_count = self._classify_opponents(history, n)
        expected_coop = self._predict_expected_cooperators(history, reliable_coop, reliable_def, conditional_count, current_round, n)
        if expected_coop >= m:
            return Action.D
        if expected_coop == m - 1:
            return Action.C
        return Action.D

    def _classify_opponents(self, history: PlayerHistory, n: int) -> tuple[int, int, int]:
        """
        Classify opponents into reliable cooperators, reliable defectors, and conditional.
        
        Returns:
            (reliable_coop_count, reliable_def_count, conditional_count)
        """
        if history is None or len(history.opponent_actions) == 0:
            return (0, 0, n)
        opponent_actions = history.opponent_actions
        n_rounds_played = len(opponent_actions)
        reliable_coop = 0
        reliable_def = 0
        for opponent_idx in range(n - 1):
            coop_rate = np.sum(opponent_actions[:, opponent_idx]) / n_rounds_played
            if coop_rate >= self.reliable_coop_threshold:
                reliable_coop += 1
            elif coop_rate <= 1.0 - self.reliable_def_threshold:
                reliable_def += 1
        conditional = n - 1 - reliable_coop - reliable_def
        return (reliable_coop, reliable_def, conditional)

    def _predict_expected_cooperators(self, history: PlayerHistory, reliable_coop: int, reliable_def: int, conditional_count: int, current_round: int, n: int) -> int:
        """
        Predict expected cooperators in the current round.
        
        Reliable cooperators always cooperate, reliable defectors never cooperate.
        Conditional players are predicted based on recent history with recency bias.
        """
        expected = reliable_coop
        if conditional_count > 0 and history is not None and (len(history.opponent_actions) > 0):
            opponent_actions = history.opponent_actions
            n_rounds_played = len(opponent_actions)
            conditional_indices = []
            for opponent_idx in range(n - 1):
                coop_rate = np.sum(opponent_actions[:, opponent_idx]) / n_rounds_played
                if not (coop_rate >= self.reliable_coop_threshold or coop_rate <= 1.0 - self.reliable_def_threshold):
                    conditional_indices.append(opponent_idx)
            if len(conditional_indices) > 0:
                recent_rounds = min(3, n_rounds_played)
                for cond_idx in conditional_indices:
                    recent_coop = np.sum(opponent_actions[-recent_rounds:, cond_idx])
                    if recent_coop >= recent_rounds / 2:
                        expected += 1
        return expected

class Strategy_EXPLOITATIVE_380(BaseStrategy):
    """
    Adaptive Threshold Parasite: An exploitative strategy that defects strategically
    to capture payoffs from cooperating players while maintaining minimal credibility.
    
    Core approach:
    - Round 1: Always defect (baseline payoff, gather information)
    - Final round: Always defect (no reputation effects matter)
    - Middle rounds: Defect when cooperation is near threshold (exploit), occasionally
      cooperate when cooperation is rare to build image for future exploitation
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.r - 1:
            return Action.D
        previous_round_idx = round_number - 1
        cooperation_count = int(sum(history.opponent_actions[previous_round_idx, :]))
        cooperation_rate = cooperation_count / (self.n - 1) if self.n > 1 else 0.0
        critical_rate = (self.m - 1) / (self.n - 1) if self.n > 1 else 0.0
        if self.m >= self.n:
            return Action.D
        if self.n == 2 and self.m == 2:
            return Action.D
        if cooperation_rate >= critical_rate:
            return Action.D
        rounds_remaining = self.r - round_number
        if cooperation_rate <= 0.2 and rounds_remaining > 2:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_381(BaseStrategy):
    """
    Adaptive Threshold Parasitism: An exploitative strategy that free-rides on
    collective cooperation while defecting strategically to maximize personal payoff.
    
    Core mechanics:
    - Defect in round 1 (test environment)
    - Defect in final round (no reputational cost)
    - In middle rounds: Track cooperation count and use deficit-based logic
    - Cooperate only when few additional cooperators are needed (deficit <= 2)
    - Otherwise defect to exploit the public good or preserve endowment
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        previous_round_idx = current_round - 1
        coop_count_prev = int(sum(history.opponent_actions[previous_round_idx, :]))
        threshold_met = coop_count_prev >= self.m
        deficit = self.m - coop_count_prev
        if threshold_met:
            return Action.D
        if deficit <= 2 and deficit > 0:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_382(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD): An exploitative strategy that systematically
    free-rides on others' cooperation in the Collective Risk Dilemma.
    
    Core principle: Defectors capture the reward (k) when threshold is met without
    bearing the cost (1) of cooperation. This strategy always defects to maximize
    exploitation, with the exception of strategically choosing cooperation only when
    it directly maximizes expected payoff (which never occurs in this game structure).
    
    Decision rule: DEFECT in all rounds.
    - Round 0: Defect to test environment without cost
    - Rounds 1 to r-2: Defect to free-ride on others' cooperation attempts
    - Round r-1: Defect (no future rounds, no reputation consequences)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_383(BaseStrategy):
    """
    Conditional Free-Rider with Adaptive Defection

    Exploits the threshold mechanism by:
    1. Defecting in round 1 to probe and gather information
    2. Defecting in subsequent rounds when threshold is already met by others
    3. Defecting when threshold cannot be reached (fewer than m-1 cooperators)
    4. Always defecting in the final round for maximum exploitation
    
    Core principle: Extract the reward (k) from others' cooperation while 
    minimizing personal contribution cost.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperators_last_round = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        self.cooperators_last_round = int(np.sum(history.opponent_actions[-1, :]))
        if self.cooperators_last_round >= self.game_description.m:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_384(BaseStrategy):
    """
    Adaptive Free-Riding with Threshold Targeting.
    
    Exploits the asymmetry in payoffs by:
    1. Always defecting (dominant strategy)
    2. Tracking observed cooperation rates to predict future behavior
    3. Intensifying exploitation in endgame rounds
    4. Maintaining adaptive monitoring throughout
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperators_observed = 0
        self.total_rounds_observed = 0
        self.p_hat = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if history is not None and current_round > 0:
            prev_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
            self.cooperators_observed += prev_cooperators
            self.total_rounds_observed += 1
            if self.total_rounds_observed > 0:
                self.p_hat = self.cooperators_observed / (self.total_rounds_observed * (n - 1))
            else:
                self.p_hat = 0.5
        self.p_hat = max(0.0, min(1.0, self.p_hat))
        early_phase_end = max(1, math.floor(r / 2))
        if 1 <= current_round <= early_phase_end:
            return Action.D
        if early_phase_end < current_round < r - 1:
            expected_cooperators = (n - 1) * self.p_hat
            if self.p_hat > m / n + 0.3:
                return Action.D
            elif m / n - 0.2 <= self.p_hat <= m / n + 0.3:
                return Action.D
            else:
                return Action.D
        if current_round == r - 1:
            threshold_stability = 1.0
            if self.p_hat >= m / n * threshold_stability:
                return Action.D
            else:
                return Action.D
        if current_round == r - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_385(BaseStrategy):
    """
    Adaptive Threshold Defection: An exploitative strategy that systematically
    free-rides on cooperators by defecting when the threshold is likely to be met,
    while gathering information in early rounds and exploiting the endgame.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.phase1_end = math.floor(self.r / 3)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        recent_coop_rate = self._calculate_recent_coop_rate(history, current_round)
        if current_round <= self.phase1_end:
            if recent_coop_rate * self.n >= self.m + 1:
                return Action.D
            else:
                return Action.C
        if recent_coop_rate * self.n >= self.m - 1:
            return Action.D
        elif recent_coop_rate * self.n >= self.m - 2:
            return Action.D
        else:
            return Action.D

    def _calculate_recent_coop_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate recent cooperation rate of opponents using exponential moving average.
        Returns: proportion of cooperators in recent history (0 to 1)
        """
        if current_round <= 5:
            recent_rounds = history.opponent_actions[:current_round, :]
        else:
            recent_rounds = history.opponent_actions[current_round - 5:current_round, :]
        if recent_rounds.size == 0:
            return 0.0
        total_cooperators = np.sum(recent_rounds)
        total_possible = recent_rounds.shape[0] * recent_rounds.shape[1]
        if total_possible == 0:
            return 0.0
        recent_rate = total_cooperators / total_possible
        if current_round > 5:
            historical_cooperators = np.sum(history.opponent_actions[:current_round, :])
            historical_possible = current_round * self.n
            historical_rate = historical_cooperators / historical_possible if historical_possible > 0 else 0.0
            weighted_rate = 0.7 * recent_rate + 0.3 * historical_rate
            return weighted_rate
        return recent_rate

class Strategy_EXPLOITATIVE_386(BaseStrategy):
    """
    Adaptive Threshold Predation: An exploitative strategy that free-rides on cooperators
    by defecting consistently while capturing rewards when the threshold is met by others.
    
    Core approach:
    - Round 0 (exploration): Defect to gather information
    - Rounds 1 to r-2 (exploitation): Defect to free-ride on cooperators
    - Round r-1 (endgame): Defect with no future consequences
    
    This strategy exploits the threshold mechanism by letting others bear cooperation costs
    while capturing the reward (1 + k) when threshold is met, or receiving 1 when it fails.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_387(BaseStrategy):
    """
    Conditional Defection with Opportunistic Cooperation strategy.
    
    Exploits payoff asymmetries by defaulting to defection and cooperating only when
    the threshold is likely to be met by high-cooperating players, allowing free-riding
    on their contributions while capturing the reward without bearing the cost.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.n_rounds - 1:
            return Action.D
        cooperators_prev = int(np.sum(history.opponent_actions[round_num - 1, :]))
        if cooperators_prev == 0:
            return Action.D
        if cooperators_prev >= self.m:
            cooperation_rates = []
            for opponent_idx in range(self.n_players - 1):
                cooperations = int(np.sum(history.opponent_actions[:round_num, opponent_idx]))
                prop = cooperations / round_num
                cooperation_rates.append(prop)
            if len(cooperation_rates) >= self.m - 1:
                sorted_rates = sorted(cooperation_rates, reverse=True)
                top_m_minus_1 = sorted_rates[:self.m - 1]
                avg_top_propensity = float(np.mean(top_m_minus_1))
            else:
                avg_top_propensity = float(np.mean(cooperation_rates)) if cooperation_rates else 0.0
            base_threshold = 0.75
            progress_factor = round_num / self.n_rounds * 0.1
            confidence_threshold = base_threshold + progress_factor
            if avg_top_propensity >= confidence_threshold:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_388(BaseStrategy):
    """
    Adaptive Free-Riding with Conditional Defection (AFCD)
    
    Exploits cooperation by free-riding when the threshold is met,
    defecting in round 1 and final round absolutely, with occasional
    strategic cooperation only when the threshold is critically short.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        recent_window_size = min(3, current_round)
        recent_rounds = history.opponent_actions[-recent_window_size:, :]
        if recent_window_size > 0:
            recent_cooperators_per_round = np.sum(recent_rounds, axis=1)
            avg_recent_cooperators = np.mean(recent_cooperators_per_round)
        else:
            avg_recent_cooperators = 0
        historical_cooperation_rate = avg_recent_cooperators / self.n
        if avg_recent_cooperators >= self.m:
            return Action.D
        elif avg_recent_cooperators == self.m - 1:
            if random.random() < 0.3:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_389(BaseStrategy):
    """
    Threshold Exploitation with Contingency Strategy
    
    Exploits the asymmetry in payoff structure by:
    1. Defecting in round 1 to capture 1+k if others cooperate
    2. Free-riding when threshold is met (others paid the cost)
    3. Defecting in final round (no reputation consequences)
    4. Cooperating only when critical to prevent collective failure
    5. Adaptively estimating cooperation likelihood from history
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        last_round_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        if last_round_cooperators >= self.m:
            return Action.D
        deficit = self.m - last_round_cooperators
        available_players = self.n_players - last_round_cooperators
        if available_players <= 0:
            return Action.C
        if deficit > 2 * available_players / 3:
            prob_others_cooperate = self._estimate_cooperation_probability(history)
            if prob_others_cooperate < 0.5:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _estimate_cooperation_probability(self, history: PlayerHistory) -> float:
        """
        Estimate the probability that other players will cooperate based on history.
        Returns value between 0.0 and 1.0
        """
        if history is None or len(history.opponent_actions) == 0:
            return 0.5
        total_cooperations = int(np.sum(history.opponent_actions))
        total_observations = history.opponent_actions.shape[0] * history.opponent_actions.shape[1]
        if total_observations == 0:
            return 0.5
        cooperation_rate = total_cooperations / total_observations
        recent_cooperations = int(np.sum(history.opponent_actions[-1, :]))
        recent_rate = recent_cooperations / self.n_players if self.n_players > 0 else 0.5
        blended_probability = 0.6 * recent_rate + 0.4 * cooperation_rate
        return float(np.clip(blended_probability, 0.0, 1.0))

class Strategy_EXPLOITATIVE_390(BaseStrategy):
    """
    Adaptive Threshold Pivot: An exploitative strategy that defects strategically,
    cooperates only when necessary to meet the threshold, and maximizes free-riding
    when the threshold is already met by others.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        previous_round_opponent_actions = history.opponent_actions[current_round - 1, :]
        cooperators_prev = int(np.sum(previous_round_opponent_actions))
        my_previous_action = history.my_actions[current_round - 1]
        total_cooperators_prev = cooperators_prev + (1 if my_previous_action else 0)
        if current_round == r - 1:
            return Action.D
        if total_cooperators_prev >= m:
            return Action.D
        elif total_cooperators_prev == m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_391(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation
    
    This strategy exploits the asymmetry in payoff structure by:
    1. Always defecting in round 1 (baseline extraction)
    2. Always defecting in the final round (no reputation consequences)
    3. In middle rounds, defecting when threshold is already met or unreachable
    
    The core exploitation: capture reward (k) without paying cost (1) by free-riding
    on others' cooperation once the threshold is met.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        previous_round_idx = round_number - 1
        cooperators_last_round = int(sum(history.opponent_actions[previous_round_idx, :]))
        if cooperators_last_round >= self.m - 1:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_392(BaseStrategy):
    """
    Conditional Defection with Adaptive Exploitation strategy for Collective Risk Dilemma.
    
    Core mechanics:
    - Defect by default to maximize payoff
    - Cooperate minimally only when threshold farming is mathematically beneficial
    - Free-ride when threshold is already met
    - Never cooperate in first or final rounds
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[round_number - 1, :]))
        if cooperators_last_round >= self.m:
            return Action.D
        threshold_gap = self.m - cooperators_last_round
        if threshold_gap == 1:
            if cooperators_last_round >= self.m - 1:
                rounds_remaining = self.n_rounds - round_number
                if rounds_remaining >= 2:
                    return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_393(BaseStrategy):
    """
    Conditional Defection with Opportunistic Thresholding.
    
    Exploits the asymmetry between cooperators (who pay cost c=1) and defectors
    (who pay 0). Defects in round 1 and final round unconditionally. In middle rounds,
    free-rides when threshold is already met, defects when it's impossible to meet,
    and strategically evaluates edge cases where this player is pivotal.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.n_rounds - 1:
            return Action.D
        previous_round = round_num - 1
        opponent_actions_prev = history.opponent_actions[previous_round, :]
        cooperators_prev = int(np.sum(opponent_actions_prev))
        if cooperators_prev >= self.m:
            return Action.D
        if cooperators_prev == 0:
            return Action.D
        if cooperators_prev == self.m - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_394(BaseStrategy):
    """
    Adaptive Threshold Defection with Opportunistic Parasitism.
    
    Exploits the payoff asymmetry by free-riding on cooperators' contributions
    when the threshold is achievable, while using strategic "insurance cooperation"
    only when threshold failure is imminent.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if cooperators_last_round >= self.m:
            return Action.D
        shortfall = self.m - cooperators_last_round
        if shortfall <= 1:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_395(BaseStrategy):
    """
    Adaptive Threshold Defection with Conditional Cooperation.
    
    Exploits asymmetry in payoffs by:
    1. Defecting in round 1 to probe cooperation rates
    2. Free-riding when threshold m is met (payoff = 1 + k)
    3. Selectively cooperating near threshold to manipulate it
    4. Unconditionally defecting in final round (subgame perfect)
    5. Adapting cooperation probability based on remaining rounds and reward size
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        cooperators_prev = int(sum(history.opponent_actions[current_round - 1, :]))
        if cooperators_prev >= self.m:
            return Action.D
        elif cooperators_prev == self.m - 1:
            remaining_rounds = self.r - current_round
            base_prob = min(0.7, remaining_rounds / self.r)
            if self.k > 2.0:
                base_prob = min(0.8, base_prob)
            elif self.k <= 1.5:
                base_prob = min(0.4, base_prob)
            if random.random() < base_prob:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_396(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Thresholds.
    
    Exploits the threshold structure by monitoring cooperation rates and extracting
    maximum value through strategic defection when the threshold appears likely to be
    met by others' contributions. Transitions to defection dominance in endgame while
    maintaining plausible deniability through occasional cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.cet = self.m / self.n_players + 0.15
        self.cst = self.m / self.n_players - 0.05
        self.tolerance = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_idx = round_num - 1
        my_prev_action = history.my_actions[prev_round_idx]
        opponent_prev_actions = history.opponent_actions[prev_round_idx, :]
        cooperators_prev = int(my_prev_action) + int(np.sum(opponent_prev_actions))
        cooperation_rate_prev = cooperators_prev / self.n_players if self.n_players > 0 else 0
        if round_num >= self.n_rounds - 1:
            return Action.D
        if cooperators_prev >= self.m:
            if cooperation_rate_prev > self.cet:
                return Action.D
            else:
                return Action.C
        elif cooperators_prev == self.m - 1:
            return Action.D
        elif self.m - cooperators_prev == 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_397(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Free-Riding with Conditional Participation
    
    Core approach: Always defect to extract maximum value from the payoff asymmetry.
    In rounds 2 to r-1, defect regardless of cooperation rate since we benefit either way
    (free-ride if threshold met, or threshold unachievable if not). In round 1 and final round,
    defect to gather information and avoid punishment respectively.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[state.round_number - 1, :]))
        others_count = self.game_description.n_players - 1
        if others_count <= 0:
            return Action.D
        cooperation_rate = cooperators_last_round / others_count
        threshold_for_free_ride = (self.game_description.m - 1) / others_count
        return Action.D

class Strategy_EXPLOITATIVE_398(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD) Strategy for Collective Risk Dilemma.
    
    Exploitative strategy that defects consistently while monitoring opponent cooperation
    rates. Adapts exploitation based on observed cooperation to maximize free-riding payoffs
    when threshold is likely to be met, while avoiding unilateral cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = []
        self.info_gathering_phase_end = math.ceil(game_description.n_rounds / 3)
        self.threshold_for_success = game_description.m / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number < self.info_gathering_phase_end:
            self._update_cooperation_history(history)
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            self._update_cooperation_history(history)
            return Action.D
        self._update_cooperation_history(history)
        if len(self.cooperation_history) == 0:
            return Action.D
        observed_coop_rate = np.mean(self.cooperation_history)
        if observed_coop_rate >= self.threshold_for_success:
            return Action.D
        if observed_coop_rate >= self.threshold_for_success * 0.7:
            rounds_remaining = self.game_description.n_rounds - state.round_number
            if rounds_remaining > 2:
                return Action.D
            else:
                return Action.D
        return Action.D

    def _update_cooperation_history(self, history: PlayerHistory) -> None:
        """
        Update the cooperation history with the average cooperation rate
        of opponents in the most recent round.
        """
        if history is None or len(history.opponent_actions) == 0:
            return
        most_recent_round_actions = history.opponent_actions[-1, :]
        coop_rate = np.mean(most_recent_round_actions)
        self.cooperation_history.append(coop_rate)

class Strategy_EXPLOITATIVE_399(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD) Strategy for Collective Risk Dilemma.
    
    Exploits asymmetry by free-riding when cooperation threshold is predictably met,
    while gathering information about opponent behavior patterns. Uses Bayesian inference
    to estimate opponent cooperation likelihood and makes conditional free-riding decisions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        opponent_profiles = self._build_opponent_profiles(history, current_round)
        predicted_cooperators = self._predict_cooperators(opponent_profiles)
        return self._make_decision(predicted_cooperators)

    def _build_opponent_profiles(self, history: PlayerHistory, current_round: int) -> dict[int, float]:
        """
        Build cooperation rate profiles for each opponent based on historical data.
        Returns dict mapping opponent_id -> cooperation_rate (0.0 to 1.0)
        """
        opponent_profiles = {}
        for opponent_id in range(self.n_players - 1):
            coop_count = float(np.sum(history.opponent_actions[:current_round, opponent_id]))
            total_rounds = float(current_round)
            if total_rounds > 0:
                coop_rate = coop_count / total_rounds
            else:
                coop_rate = 0.5
            opponent_profiles[opponent_id] = coop_rate
        return opponent_profiles

    def _predict_cooperators(self, opponent_profiles: dict[int, float]) -> int:
        """
        Predict the number of cooperators in the upcoming round using Bayesian inference.
        
        Classification thresholds:
        - coop_rate >= 0.7: Likely to cooperate
        - coop_rate <= 0.3: Likely to defect
        - 0.3 < coop_rate < 0.7: Uncertain, assume 50% probability
        """
        predicted_cooperators = 0.0
        for opponent_id, coop_rate in opponent_profiles.items():
            if coop_rate >= 0.7:
                predicted_cooperators += 1.0
            elif coop_rate > 0.3:
                predicted_cooperators += 0.5
        return round(predicted_cooperators)

    def _make_decision(self, predicted_cooperators: int) -> Action:
        """
        Make defection/cooperation decision based on predicted cooperator count.
        
        Strategy:
        - If threshold already met: DEFECT (free-ride)
        - If threshold impossible: DEFECT (no benefit to cooperation)
        - If we are the marginal player: COOPERATE (threshold breaker)
        - On uncertainty: DEFECT (conservative safe payoff)
        """
        if predicted_cooperators >= self.m:
            return Action.D
        if predicted_cooperators < self.m - 1:
            return Action.D
        if predicted_cooperators == self.m - 1:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_400(BaseStrategy):
    """
    Adaptive Threshold Parasitism: An exploitative strategy that unconditionally defects
    to free-ride on others' cooperation while avoiding the risk of threshold failure.
    
    Core logic: Always defect to capture the (1+k) payoff when others cooperate, or
    maintain the baseline payoff of 1 when others defect. Tracks cooperation patterns
    to identify free-riding opportunities but always plays D regardless.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_count_last_round = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if history is not None and len(history.opponent_actions) > 0:
            recent_round_idx = state.round_number - 1
            cooperators_last_round = int(np.sum(history.opponent_actions[recent_round_idx, :]))
            cooperation_rate = cooperators_last_round / self.game_description.n_players
            self.cooperation_count_last_round = cooperators_last_round
        return Action.D

class Strategy_EXPLOITATIVE_401(BaseStrategy):
    """
    Adaptive Threshold Arbitrage: An exploitative strategy that systematically free-rides
    on others' cooperation by defecting in round 1, analyzing cooperation rates in middle
    rounds to identify when the threshold is likely met, and defecting in the final round
    to avoid consequences. Always defects, capturing asymmetric gains when others cooperate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.success_threshold = (game_description.m - 1) / (game_description.n_players - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        if history is not None and current_round > 0:
            total_cooperations = 0
            total_observations = 0
            for round_idx in range(current_round):
                cooperations_in_round = np.sum(history.opponent_actions[round_idx, :])
                total_cooperations += cooperations_in_round
                total_observations += n - 1
            if total_observations > 0:
                observed_rate = total_cooperations / total_observations
            else:
                observed_rate = 0.0
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_402(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism strategy.
    
    Exploits the collective risk dilemma by defecting to capture payoff k 
    without contributing. Identifies when cooperation will occur and free-rides 
    on others' contributions. Adapts defection throughout the game to maximize 
    personal payoff while minimizing contribution costs.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        current_round = state.round_number
        cooperators_prev = int(sum(history.opponent_actions[current_round - 1, :]))
        if current_round <= self.n_rounds - 3:
            return Action.D
        if current_round == self.n_rounds - 2:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_403(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD): An exploitative strategy that maximizes personal payoff
    by free-riding on others' cooperation and strategically cooperating only when it unlocks
    the collective reward at minimal cost.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold_unlocked = False
        self.last_round_threshold_met = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        prev_round_idx = state.round_number - 1
        prev_cooperators = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        coop_rate = prev_cooperators / self.game_description.n_players
        threshold_rate = (self.game_description.m - 1) / self.game_description.n_players
        self.last_round_threshold_met = prev_cooperators >= self.game_description.m - 1
        if coop_rate >= threshold_rate:
            return Action.D
        if coop_rate < threshold_rate and (not self.cooperation_threshold_unlocked):
            return Action.D
        if prev_cooperators == self.game_description.m - 1 and (not self.cooperation_threshold_unlocked) and (not self.last_round_threshold_met):
            self.cooperation_threshold_unlocked = True
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_404(BaseStrategy):
    """
    Adaptive Free-Rider with Threshold Monitoring.
    
    Exploitative strategy that maximizes personal payoff by defecting by default
    while conditionally cooperating only when strategically necessary to maintain
    the threshold and sustain the game's profitable state.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        recent_cooperators = self._count_recent_cooperators(history, current_round)
        rounds_remaining = self.n_rounds - current_round - 1
        if recent_cooperators >= self.m:
            return Action.D
        if recent_cooperators == self.m - 1:
            return Action.D
        if recent_cooperators >= self.m - 2 and rounds_remaining >= 2:
            return Action.C
        return Action.D

    def _count_recent_cooperators(self, history: PlayerHistory, current_round: int) -> int:
        """
        Count cooperators in the last 2 rounds (excluding self).
        Returns total count across opponents in recent history.
        """
        if current_round == 0:
            return 0
        start_round = max(0, current_round - 2)
        recent_actions = history.opponent_actions[start_round:current_round, :]
        total_cooperators = int(np.sum(recent_actions))
        return total_cooperators

class Strategy_EXPLOITATIVE_405(BaseStrategy):
    """
    Adaptive Free-Riding with Threshold Exploitation strategy.
    
    This exploitative strategy minimizes personal contribution while maximizing
    benefit from others' cooperation. It always defects except in carefully
    calculated scenarios, free-riding on cooperative players when the threshold
    is met and avoiding wasteful cooperation when it isn't.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.avg_cooperators = 0.0
        self.last_round_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        n_rounds = self.game_description.n_rounds
        m = self.game_description.m
        if current_round == 0:
            return Action.D
        cooperator_counts = np.sum(history.opponent_actions, axis=1)
        self.avg_cooperators = float(np.mean(cooperator_counts))
        self.last_round_cooperators = int(cooperator_counts[-1])
        if current_round == n_rounds - 1:
            return Action.D
        if current_round <= math.floor(n_rounds / 2):
            if self.avg_cooperators > 0.7 * m:
                return Action.D
            else:
                return Action.D
        if self.last_round_cooperators >= m:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_406(BaseStrategy):
    """
    Adaptive Defection with Conditional Parasitism.
    
    This exploitative strategy defects by default to free-ride on others' cooperation.
    It systematically extracts value from cooperative players by avoiding contribution
    while benefiting from threshold achievements. The strategy is designed to maximize
    payoff through parasitism rather than mutual cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
        threshold_safety_margin = self.m - 1
        if cooperators_last_round >= threshold_safety_margin:
            return Action.D
        elif cooperators_last_round == threshold_safety_margin:
            return Action.D
        elif cooperators_last_round >= math.ceil(self.m * 0.6):
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_407(BaseStrategy):
    """
    Exploitative Strategy: Conditional Free-Riding with Adaptive Defection
    
    Exploits the threshold mechanism by free-riding on others' contributions while
    minimizing personal cost. Uses adaptive defection based on observed cooperation rates.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        if t == 0:
            return Action.D
        if t == self.r - 1:
            return Action.D
        if t == self.r - 2:
            return Action.D
        cooperators_prev = int(np.sum(history.opponent_actions[t - 1, :]))
        coop_rate = cooperators_prev / self.n
        threshold_rate = self.m / self.n
        tolerance = 1.0 / self.n
        if self.n == 2 and self.m == 2:
            return Action.D
        if self.m == 1:
            return Action.D
        if coop_rate > threshold_rate:
            return Action.D
        elif abs(coop_rate - (threshold_rate - tolerance)) < 1e-09:
            if random.random() < 2.0 / 3.0:
                return Action.D
            else:
                return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_408(BaseStrategy):
    """
    Adaptive Threshold Parasitism: An exploitative strategy that maximizes payoff by
    free-riding on others' cooperation. Probes early, estimates cooperation patterns,
    and defects strategically once threshold-meeting cooperation is identified.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = []
        self.cooperation_frequency = 0.5
        self.round_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        self.round_counter = state.round_number
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        m = self.game_description.m
        k = self.game_description.k
        if self.round_counter == 0:
            if n <= 4:
                return Action.C
            else:
                return Action.D
        self._update_cooperation_history(history)
        if self.round_counter == r - 1:
            return Action.D
        estimated_cooperators = self._estimate_cooperators()
        if self.round_counter <= 2:
            if len(self.cooperation_history) > 0:
                observed_coop = self.cooperation_history[0]
                if observed_coop >= m:
                    return Action.D
                elif observed_coop < m / 2:
                    return Action.D
                else:
                    return Action.C
            return Action.C
        if self.round_counter <= math.floor(r / 3):
            if estimated_cooperators >= m:
                return Action.D
            else:
                defection_rate = 1.0 - self.cooperation_frequency if self.cooperation_frequency > 0 else 0.6
                if defection_rate > 0.6:
                    return Action.D
                else:
                    return Action.C
        if self.round_counter == r - 2:
            if estimated_cooperators >= m:
                return Action.D
            elif estimated_cooperators == m - 1 and k > 1:
                return Action.C
            else:
                return Action.D
        if estimated_cooperators >= m:
            return Action.D
        elif estimated_cooperators < m - 1:
            return Action.D
        elif estimated_cooperators == m - 1:
            return Action.C
        else:
            return Action.D

    def _update_cooperation_history(self, history: PlayerHistory) -> None:
        """Update the cooperation frequency tracker based on observed actions."""
        if history is None or len(history.opponent_actions) == 0:
            return
        most_recent_round_idx = len(history.opponent_actions) - 1
        cooperators_this_round = sum(history.opponent_actions[most_recent_round_idx, :])
        current_round = self.round_counter
        if current_round > 0:
            self.cooperation_frequency = (self.cooperation_frequency * (current_round - 1) + cooperators_this_round) / current_round
        else:
            self.cooperation_frequency = cooperators_this_round / self.game_description.n_players
        self.cooperation_history.append(cooperators_this_round)

    def _estimate_cooperators(self) -> int:
        """Estimate how many players will cooperate this round."""
        n = self.game_description.n_players
        if len(self.cooperation_history) == 0:
            return max(1, math.floor(n / 2))
        if len(self.cooperation_history) >= 3:
            recent_rounds = self.cooperation_history[-3:]
            mode_value = max(set(recent_rounds), key=recent_rounds.count)
            return mode_value
        else:
            avg_cooperators = np.mean(self.cooperation_history)
            return max(1, math.floor(avg_cooperators))

class Strategy_EXPLOITATIVE_409(BaseStrategy):
    """
    Exploitative strategy for Collective Risk Dilemma that systematically free-rides on cooperation.
    
    Core approach:
    1. Phases 1-2: Defect to gather information about opponent cooperation rates
    2. Phase 2: Exploit by defecting when cooperation will succeed (earning k without cost)
    3. Phase 3: Endgame defection with no reputation concerns
    
    Adapts defection rates based on observed cooperation, maintaining threshold just below
    m cooperators when needed, but primarily free-riding on others' contributions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.cooperation_history = []
        self.recent_coop_rate = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round <= 1:
            return Action.D
        self._update_cooperation_stats(history)
        is_endgame = current_round >= self.r - 2
        if is_endgame:
            return Action.D
        return self._phase2_decision()

    def _update_cooperation_stats(self, history: PlayerHistory) -> None:
        """Update cooperation rate tracking with decay-weighted average."""
        recent_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        self.cooperation_history.append(recent_cooperators)
        if len(self.cooperation_history) >= 2:
            coop_rate_t1 = self.cooperation_history[-1] / self.n
            coop_rate_t2 = self.cooperation_history[-2] / self.n if len(self.cooperation_history) >= 2 else 0.0
            hist_avg = np.mean(self.cooperation_history) / self.n
            self.recent_coop_rate = 0.4 * coop_rate_t1 + 0.3 * coop_rate_t2 + 0.3 * hist_avg
        else:
            self.recent_coop_rate = np.mean(self.cooperation_history) / self.n

    def _phase2_decision(self) -> Action:
        """
        Exploitation decision logic for Phase 2.
        Free-ride when cooperation succeeds, strategically cooperate rarely when threshold is fragile.
        """
        expected_cooperators = self.recent_coop_rate * self.n
        gap_to_threshold = self.m - expected_cooperators
        if expected_cooperators >= self.m:
            return Action.D
        elif gap_to_threshold >= -1 and gap_to_threshold <= 2:
            cooperate_prob = 0.2
            return Action.C if random.random() < cooperate_prob else Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_410(BaseStrategy):
    """
    Conditional Defection with Adaptive Thresholding - an exploitative strategy that:
    1. Defects in round 1 to learn opponent behavior without cost
    2. Adaptively free-rides based on observed cooperation rates in middle rounds
    3. Defects in the final round to extract maximum value
    4. Exploits threshold dynamics by defecting when others will cooperate anyway
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.n_rounds - 1:
            return Action.D
        return self._adaptive_decision(round_num, history)

    def _adaptive_decision(self, round_num: int, history: PlayerHistory) -> Action:
        """
        Adaptive protocol for middle rounds.
        Estimates how many other players cooperated on average and decides based on thresholds.
        """
        opponent_coop_by_round = np.sum(history.opponent_actions[:round_num, :], axis=1)
        mean_cooperation = float(np.mean(opponent_coop_by_round))
        others_needed_for_threshold = self.m - 1
        if self.n_players <= 4:
            cooperation_threshold = others_needed_for_threshold
            prob_cooperate_near_threshold = 0.3
        elif self.n_players > 8:
            cooperation_threshold = others_needed_for_threshold
            prob_cooperate_near_threshold = 0.1
        else:
            cooperation_threshold = others_needed_for_threshold
            prob_cooperate_near_threshold = 0.2
        if self.m == self.n_players:
            return Action.D
        if self.m == 2:
            return Action.D
        if mean_cooperation >= others_needed_for_threshold:
            return Action.D
        elif mean_cooperation == others_needed_for_threshold - 1:
            threshold_prob = min(0.6, (self.m - mean_cooperation) / 2.0)
            return Action.C if random.random() < threshold_prob else Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_411(BaseStrategy):
    """
    Adaptive Threshold Parasitism (ATP): A pure defection strategy that exploits
    the collective risk dilemma by free-riding on cooperators' contributions.
    
    Core principle: Always defect across all rounds. This maximizes payoff by:
    1. Avoiding the cooperation cost (c_i = 1)
    2. Harvesting the reward (k) when threshold m is reached by others
    3. Suffering no loss when cooperation fails
    4. Never exposing exploitable patterns
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        return Action.D

class Strategy_EXPLOITATIVE_412(BaseStrategy):
    """
    Adaptive Threshold Farming: An exploitative strategy that systematically identifies
    when cooperation will be triggered by others, then free-rides on that cooperation
    while minimizing personal contribution costs.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_met_last_round = False
        self.opponent_defection_rates = np.zeros(self.n - 1)
        self.coop_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return self._decide_round_1()
        if round_num < self.r - 1:
            return self._decide_middle_rounds(history, round_num)
        return self._decide_final_round(history, round_num)

    def _decide_round_1(self) -> Action:
        """Decision Rule 1A/1B for first round."""
        if self.n >= 5 and self.m / self.n < 0.6:
            return Action.D
        return Action.C

    def _decide_middle_rounds(self, history: PlayerHistory, round_num: int) -> Action:
        """Decision Rules 2A-2D for middle rounds."""
        total_rounds_so_far = round_num
        total_cooperations = np.sum(history.opponent_actions[:total_rounds_so_far, :])
        total_actions = total_rounds_so_far * (self.n - 1)
        coop_rate = total_cooperations / total_actions if total_actions > 0 else 0.0
        self.coop_history.append(coop_rate)
        for i in range(self.n - 1):
            opponent_defections = np.sum(~history.opponent_actions[:total_rounds_so_far, i])
            self.opponent_defection_rates[i] = opponent_defections / total_rounds_so_far if total_rounds_so_far > 0 else 0.0
        if round_num > 0:
            prev_cooperators = np.sum(history.opponent_actions[round_num - 1, :])
            self.threshold_met_last_round = prev_cooperators >= self.m - 1
        if coop_rate >= (self.m - 1) / self.n and coop_rate > 0.3:
            return Action.D
        chronic_defectors = np.sum(self.opponent_defection_rates > 0.7)
        if chronic_defectors >= self.m - 1:
            return Action.D
        if len(self.coop_history) >= 2:
            if self.coop_history[-1] < self.coop_history[-2]:
                return Action.D
        if coop_rate < (self.m - 1) / self.n and coop_rate > 0.1 and (self.m <= self.n / 2):
            if chronic_defectors < self.m - 1:
                return Action.C
        return Action.D

    def _decide_final_round(self, history: PlayerHistory, round_num: int) -> Action:
        """Decision Rule 3A for final round."""
        if round_num > 0:
            prev_cooperators = np.sum(history.opponent_actions[round_num - 1, :])
            if prev_cooperators >= self.m - 1:
                return Action.D
        total_rounds_so_far = round_num
        if total_rounds_so_far > 0:
            total_cooperations = np.sum(history.opponent_actions[:total_rounds_so_far, :])
            total_actions = total_rounds_so_far * (self.n - 1)
            coop_rate = total_cooperations / total_actions if total_actions > 0 else 0.0
            if coop_rate >= (self.m - 1) / self.n:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_413(BaseStrategy):
    """
    Adaptive Threshold Exploitation (ATE) Strategy
    
    A pure defection strategy that exploits the structural asymmetry of the 
    Collective Risk Dilemma by never cooperating while capturing rewards when 
    opponents' cooperation meets the threshold. Maximizes relative advantage 
    through consistent free-riding on others' contributions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_414(BaseStrategy):
    """
    Adaptive Defection with Conditional Cooperation (Threshold Parasitism)
    
    Exploits the asymmetry in payoff structure by free-riding on others' cooperation.
    - Round 1: Defect to establish baseline and probe for naive cooperators
    - Intermediate rounds: Defect if threshold met (free-ride), cooperate if exactly m-1 
      cooperators exist (push over threshold), otherwise defect
    - Final round: Always defect (no future consequences)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[state.round_number - 1, :]))
        if cooperators_last_round >= self.game_description.m:
            return Action.D
        elif cooperators_last_round == self.game_description.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_415(BaseStrategy):
    """
    Adaptive Threshold Raider: An exploitative strategy that systematically free-rides
    on others' cooperation by estimating the probability the threshold will be met,
    then defecting to capture asymmetric payoffs (1 + k vs k for cooperators).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        if current_round == 0:
            if self.m <= (self.n - 1) / 2.0:
                return Action.D
            else:
                return Action.C
        last_round_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        if last_round_cooperators >= self.m:
            threshold_confidence = 0.95
        elif last_round_cooperators == self.m - 1:
            threshold_confidence = 0.7
        else:
            threshold_confidence = 0.2
        if current_round >= 3:
            recent_cooperators = [int(sum(history.opponent_actions[i, :])) for i in range(max(0, current_round - 3), current_round)]
            recent_avg = np.mean(recent_cooperators)
            if current_round >= 2:
                two_rounds_ago = int(sum(history.opponent_actions[current_round - 2, :]))
                trend = recent_avg - two_rounds_ago
                if trend < -0.5:
                    threshold_confidence -= 0.3
        if threshold_confidence >= 0.7:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_416(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism strategy.
    
    Exploits the payoff asymmetry in the Collective Risk Dilemma by:
    1. Defecting in round 1 to gather information without risk
    2. Defecting in rounds 2 to r-1 whenever previous round reached threshold (m cooperators)
    3. Unconditionally defecting in the final round (terminal round exploitation)
    
    Core principle: Capture the k bonus without contributing by free-riding on others' cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        previous_round_index = state.round_number - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[previous_round_index, :]))
        if cooperators_last_round >= self.game_description.m:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_417(BaseStrategy):
    """
    Adaptive Defection with Selective Free-Riding strategy for Collective Risk Dilemma.
    
    Exploits the threshold mechanism by:
    1. Always defecting when threshold is met (free-riding)
    2. Strategically probing cooperation when threshold is almost met
    3. Never cooperating in the final round
    4. Calibrating probing frequency based on observed cooperation rates
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[current_round - 1, :]))
        total_cooperations = int(np.sum(history.opponent_actions[:current_round, :]))
        total_observations = (self.n - 1) * current_round
        if total_observations > 0:
            cooperation_rate = total_cooperations / total_observations
        else:
            cooperation_rate = 0.0
        if cooperators_last_round >= self.m:
            return Action.D
        if cooperators_last_round == self.m - 1:
            rounds_remaining = self.r - current_round
            sigmoid_input = 2.0 * (cooperation_rate - self.m / self.n)
            sigmoid_value = 1.0 / (1.0 + math.exp(-sigmoid_input))
            probing_prob = sigmoid_value * (rounds_remaining / self.r)
            if random.random() < probing_prob:
                return Action.C
            else:
                return Action.D
        if cooperators_last_round < self.m - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_418(BaseStrategy):
    """
    Exploitative Strategy: Conditional Free-Riding with Adaptive Defection
    
    Exploits the threshold mechanism by always defecting to minimize personal 
    contribution while extracting maximum value from others' cooperation. Adapts 
    only to confirm defection remains optimal based on observed cooperation trends.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == self.n_rounds - 1:
            return Action.D
        if current_round == 0:
            return Action.D
        cooperators_prev_round = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if current_round >= 2:
            cooperators_round_before = int(np.sum(history.opponent_actions[current_round - 2, :]))
        else:
            cooperators_round_before = cooperators_prev_round
        if cooperators_prev_round == 0:
            return Action.D
        if cooperators_prev_round < self.m and cooperators_prev_round < cooperators_round_before:
            return Action.D
        if cooperators_prev_round >= self.m:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_419(BaseStrategy):
    """
    Conditional Freerider with Adaptive Defection strategy.
    
    Exploits the threshold structure by defecting to free-ride on others' cooperation,
    while strategically adapting based on observed cooperation rates. Uses endgame
    dominance to always defect in the final round, with a calculated bait move in the
    penultimate round to stimulate cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.cooperation_threshold = self.m / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        if round_number >= 1:
            prev_round_idx = round_number - 1
            cooperators_prev = int(np.sum(history.opponent_actions[prev_round_idx, :]))
            coop_density = cooperators_prev / self.n_players
            if coop_density >= self.cooperation_threshold:
                return Action.D
            if round_number == self.n_rounds - 2:
                my_total_cooperations = int(np.sum(history.my_actions[:round_number]))
                if my_total_cooperations == 0 and coop_density < 0.3:
                    return Action.C
                else:
                    return Action.D
            return Action.D

class Strategy_EXPLOITATIVE_420(BaseStrategy):
    """
    Rational Defection with Conditional Exploitation Strategy
    
    This exploitative strategy free-rides on others' cooperation by defecting
    whenever the threshold is likely to be met, or always if it won't be met.
    Always defects in the final round regardless of history.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.total_cooperations_observed = 0
        self.rounds_played = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        if state.round_number == 0:
            return Action.D
        cooperation_rate = self.total_cooperations_observed / (self.game_description.n_players * self.rounds_played)
        expected_next_cooperators = cooperation_rate * self.game_description.n_players
        cooperators_this_round = int(np.sum(history.opponent_actions[-1, :]))
        self.total_cooperations_observed += cooperators_this_round
        self.rounds_played += 1
        return Action.D

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        cooperators_this_round = int(np.sum(history.opponent_actions[-1, :]))
        self.total_cooperations_observed += cooperators_this_round
        self.rounds_played += 1
        cooperation_rate = self.total_cooperations_observed / (self.game_description.n_players * self.rounds_played)
        expected_next_cooperators = cooperation_rate * self.game_description.n_players
        return Action.D

class Strategy_EXPLOITATIVE_421(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD) Strategy for Collective Risk Dilemma.
    
    Exploits asymmetry in payoffs by:
    1. Free-riding on others' cooperation when threshold is met
    2. Defecting strategically to maximize individual payoff
    3. Adapting based on observed cooperation rates
    
    Core principle: Defect unless cooperation is guaranteed or you are the marginal cooperator.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.total_cooperations_observed = 0
        self.rounds_played = 0
        self.accumulated_payoff = 0.0
        self.last_round_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        rounds_remaining = self.r - current_round
        if current_round == 0:
            return Action.D
        self._update_statistics(history, current_round)
        if rounds_remaining == 1:
            return Action.D
        cooperation_rate = self._calculate_cooperation_rate(current_round)
        expected_cooperators = cooperation_rate * (self.n - 1)
        variance_buffer = math.sqrt(self.n * cooperation_rate * (1.0 - cooperation_rate))
        risk_threshold = self.m + variance_buffer
        if self.last_round_cooperators >= self.m:
            return Action.D
        if expected_cooperators >= risk_threshold:
            return Action.D
        if expected_cooperators >= self.m - 0.5:
            return Action.C
        return Action.D

    def _update_statistics(self, history: PlayerHistory, current_round: int) -> None:
        """Update running statistics from the previous round."""
        if current_round == 0:
            return
        last_round_idx = current_round - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[last_round_idx, :]))
        self.last_round_cooperators = cooperators_last_round
        total_cooperations_all_rounds = int(np.sum(history.opponent_actions[:current_round, :]))
        self.total_cooperations_observed = total_cooperations_all_rounds
        self.accumulated_payoff = float(np.sum(history.my_payoffs[:current_round]))
        self.rounds_played = current_round

    def _calculate_cooperation_rate(self, current_round: int) -> float:
        """Calculate observed cooperation rate from opponents."""
        if self.rounds_played == 0:
            return 0.5
        total_observations = (self.n - 1) * self.rounds_played
        if total_observations == 0:
            return 0.5
        cooperation_rate = self.total_cooperations_observed / total_observations
        return max(0.0, min(1.0, cooperation_rate))

class Strategy_EXPLOITATIVE_422(BaseStrategy):
    """
    Exploitative Strategy: Conditional Defection with Adaptive Thresholding
    
    Exploits the payoff asymmetry by free-riding on others' cooperation while
    maintaining minimal cooperative potential. Uses three-phase approach:
    exploration, exploitation, and endgame to maximize individual payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperators_per_round = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        m = self.game_description.m
        if state.round_number == 0:
            return Action.D
        if state.round_number == r - 1:
            return Action.D
        if history is not None:
            self.cooperators_per_round = []
            for round_idx in range(state.round_number):
                cooperators_this_round = int(np.sum(history.opponent_actions[round_idx, :]))
                self.cooperators_per_round.append(cooperators_this_round)
        if len(self.cooperators_per_round) == 0:
            observed_coop_rate = 0.0
        else:
            observed_coop_rate = np.mean(self.cooperators_per_round) / n
        exploration_end = max(1, math.floor(r / 3))
        exploitation_end = max(exploration_end + 1, math.floor(2 * r / 3))
        if r <= 5:
            exploration_end = 1
            exploitation_end = r - 2
        threshold_base = m / n
        if state.round_number <= exploration_end:
            return Action.D
        elif state.round_number <= exploitation_end:
            if r > 20:
                strong_threshold = threshold_base * 1.4
            else:
                strong_threshold = threshold_base * 1.5
            if observed_coop_rate >= strong_threshold:
                return Action.D
            marginal_threshold = threshold_base * 0.9
            if observed_coop_rate >= marginal_threshold:
                if len(self.cooperators_per_round) > 0:
                    cooperators_last_round = self.cooperators_per_round[-1]
                    if cooperators_last_round >= m:
                        return Action.D
                return Action.D
            return Action.D
        else:
            endgame_threshold = threshold_base * 1.3
            if observed_coop_rate >= endgame_threshold:
                return Action.D
            else:
                return Action.D

class Strategy_EXPLOITATIVE_423(BaseStrategy):
    """
    Adaptive Threshold Exploitation Strategy for Collective Risk Dilemma.
    
    Exploits the asymmetry that defectors free-riding after threshold is met
    receive higher payoffs than cooperators. Minimizes contribution costs while
    capturing threshold rewards through strategic defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        last_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if last_cooperators >= self.m:
            return Action.D
        if last_cooperators == self.m - 1:
            total_opponent_cooperations = np.sum(history.opponent_actions)
            total_possible = history.opponent_actions.shape[0] * history.opponent_actions.shape[1]
            if total_possible > 0:
                proportion_cooperators = total_opponent_cooperations / total_possible
            else:
                proportion_cooperators = 0.0
            threshold_high_cooperation = self.m / self.n_players + 0.15
            if proportion_cooperators < 0.4 and current_round <= self.n_rounds - 2:
                if random.random() < 0.3:
                    return Action.C
            return Action.D
        if last_cooperators <= self.m - 2:
            total_opponent_cooperations = np.sum(history.opponent_actions)
            total_possible = history.opponent_actions.shape[0] * history.opponent_actions.shape[1]
            if total_possible > 0:
                proportion_cooperators = total_opponent_cooperations / total_possible
            else:
                proportion_cooperators = 0.0
            if random.random() < 0.05:
                return Action.C
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_424(BaseStrategy):
    """
    Adaptive Threshold Parasitism: An exploitative strategy that never cooperates
    and specifically targets the threshold coordination problem in collective risk dilemmas.
    
    Core logic:
    - Round 1: Defect (test the waters)
    - Final round: Defect (no future punishment possible)
    - Middle rounds: Defect always (free-ride when m+ cooperate, disrupt when approaching threshold)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[-1, :]))
        if cooperators_last_round >= self.game_description.m:
            return Action.D
        if cooperators_last_round == self.game_description.m - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_425(BaseStrategy):
    """
    Exploitative strategy for Collective Risk Dilemma.
    
    Always defects to:
    1. Free-ride when threshold is met (extract k without paying c)
    2. Avoid wasting endowment when threshold is not met
    3. Resist coordination through unconditional defection
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_426(BaseStrategy):
    """
    Calculated Defection with Opportunistic Harvesting:
    An exploitative strategy that defaults to defection and only cooperates
    when observing sufficient cooperation from others, while free-riding on
    their contributions and defecting in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.baseline_payoff = self.n_rounds * 1.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
        threshold_safe = cooperators_last_round >= self.m - 1
        cumulative_payoff = float(np.sum(history.my_payoffs[:current_round]))
        can_recover = cumulative_payoff >= self.baseline_payoff
        if threshold_safe and can_recover:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_427(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation
    
    Exploits the asymmetry in payoffs by defecting when the cooperation threshold
    is met by others, while strategically cooperating only as a "swing player" when
    cooperation count is exactly m-1. Always defects in the first and final rounds,
    and applies backward induction to avoid cooperation in the penultimate round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        if current_round == self.n_rounds - 2:
            return Action.D
        previous_round_index = current_round - 1
        cooperation_count = int(sum(history.opponent_actions[previous_round_index, :]))
        if cooperation_count >= self.m:
            return Action.D
        if cooperation_count == self.m - 1:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_428(BaseStrategy):
    """
    Adaptive Threshold Predation: An exploitative strategy that free-rides when the cooperation
    threshold is safe, cooperates when necessary to ensure threshold achievement, and exploits
    reciprocal opponents through oscillation patterns.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        previous_round_idx = round_number - 1
        opponent_actions_previous = history.opponent_actions[previous_round_idx, :]
        cooperators_previous = int(np.sum(opponent_actions_previous))
        remaining_needed = self.m - cooperators_previous
        if remaining_needed <= 0:
            return Action.D
        if remaining_needed == 1:
            volatility = self._calculate_cooperation_volatility(history, round_number)
            if volatility < 0.2:
                return Action.D
            else:
                return Action.C
        if remaining_needed >= 2:
            if self._detect_reciprocal_opponent(history, round_number):
                if round_number % 2 == 1:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.C
        return Action.C

    def _calculate_cooperation_volatility(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the variance in cooperation rate across previous rounds.
        Volatility < 0.2 indicates stable cooperators; >= 0.2 indicates unreliable.
        """
        if current_round < 2:
            return 0.0
        cooperation_rates = []
        for round_idx in range(current_round):
            opponent_actions = history.opponent_actions[round_idx, :]
            coop_rate = np.sum(opponent_actions) / self.n_players
            cooperation_rates.append(coop_rate)
        if len(cooperation_rates) < 2:
            return 0.0
        volatility = float(np.var(cooperation_rates))
        return volatility

    def _detect_reciprocal_opponent(self, history: PlayerHistory, current_round: int) -> bool:
        """
        Detect if any opponent shows strictly reciprocal behavior (always matches my previous action).
        Returns True if reciprocal opponent is found.
        """
        my_actions = history.my_actions[:current_round]
        opponent_actions = history.opponent_actions[:current_round, :]
        if len(my_actions) == 0:
            return False
        for opponent_idx in range(self.n_players - 1):
            opponent_seq = opponent_actions[:, opponent_idx]
            matches = True
            for i in range(1, len(my_actions)):
                if opponent_seq[i] != my_actions[i - 1]:
                    matches = False
                    break
            if matches:
                return True
        return False

class Strategy_EXPLOITATIVE_429(BaseStrategy):
    """
    Exploitative Conditional Free-Riding with Adaptive Thresholds.
    
    Strategically defects when cooperation is likely to occur anyway, while maintaining
    just enough credibility to avoid triggering collective defection. Captures k rewards
    with minimal contribution costs through threshold parasitism and endgame ruthlessness.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if self.m == self.n:
            if current_round == 0:
                return Action.C
            return self._tit_for_tat(history)
        if self.m == 2:
            return Action.D
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        cooperators_prev = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if current_round == 1:
            if cooperators_prev == 0:
                if random.random() < 0.3:
                    return Action.C
                return Action.D
        if cooperators_prev >= self.m:
            return Action.D
        elif cooperators_prev == self.m - 1:
            if random.random() < 1.0 / self.n:
                return Action.C
            return Action.D
        else:
            gap = self.m - cooperators_prev
            cooperation_prob = gap / self.n
            if random.random() < cooperation_prob:
                return Action.C
            return Action.D

    def _tit_for_tat(self, history: PlayerHistory) -> Action:
        """
        Fallback strategy for edge case where m == n.
        Uses Tit-for-Tat: defect if any opponent defected in previous round.
        """
        prev_round_opponent_actions = history.opponent_actions[-1, :]
        if np.any(~prev_round_opponent_actions):
            return Action.D
        return Action.C

class Strategy_EXPLOITATIVE_430(BaseStrategy):
    """
    Adaptive Defection with Conditional Cooperation (ADCC) Strategy.
    
    Exploits the asymmetry in payoff structure by free-riding on others' cooperation
    while maintaining conditional cooperation only when pivotal to reaching the threshold.
    Always defects in the final round and round 1 to establish baseline behavior.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        prev_round_opponent_actions = history.opponent_actions[round_number - 1, :]
        cooperators_last_round = int(np.sum(prev_round_opponent_actions))
        if self.n_players == 0:
            return Action.D
        cooperation_rate = cooperators_last_round / self.n_players
        threshold_rate = self.m / self.n_players
        near_threshold_rate = (self.m - 1) / self.n_players
        if cooperation_rate >= threshold_rate:
            return Action.D
        elif cooperation_rate >= near_threshold_rate:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_431(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Defection.
    
    Exploits the threshold mechanism by systematically free-riding when cooperation
    is likely, while minimizing exposure to collective failure. Achieves payoff of
    (1 + k) by defecting while others cooperate, with adaptive calibration to avoid
    catastrophic outcomes.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def _get_threshold_buffer(self) -> float:
        """Calibrate buffer based on m/n ratio."""
        ratio = self.m / self.n
        if ratio > 0.7:
            return 0.1
        elif ratio <= 0.5:
            return 0.2
        else:
            return 0.15

    def _count_cooperators_last_round(self, history: PlayerHistory) -> int:
        """Count how many opponents cooperated in the last round."""
        if len(history.opponent_actions) == 0:
            return 0
        last_round_actions = history.opponent_actions[-1, :]
        return int(np.sum(last_round_actions))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            p_init = max(0.5, self.m / self.n + 0.1)
            if random.random() < p_init:
                return Action.C
            else:
                return Action.D
        if round_number == self.r - 1:
            return Action.D
        coop_last_round = self._count_cooperators_last_round(history)
        if coop_last_round >= self.m:
            return Action.D
        if round_number == self.r - 2:
            if coop_last_round >= self.m:
                return Action.D
            elif random.random() < 0.6:
                return Action.C
            else:
                return Action.D
        buffer = self._get_threshold_buffer()
        threshold = self.m / self.n + buffer
        coop_rate = coop_last_round / self.n
        if coop_last_round == self.m or coop_last_round == self.m + 1:
            return Action.D
        if self.m - 1 <= coop_last_round < self.m + 2:
            if random.random() < 0.7:
                return Action.D
            else:
                return Action.C
        if coop_rate >= threshold:
            return Action.D
        elif coop_last_round == self.m - 1:
            if random.random() < 0.4:
                return Action.C
            else:
                return Action.D
        elif random.random() < 0.6:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_432(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD) - Exploitative strategy that:
    1. Defects during reconnaissance phase to observe cooperation patterns
    2. Adaptively defects based on empirical cooperation rates
    3. Always defects in the final round
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.phase1_end = math.ceil(self.n_rounds / 3)
        self.cooperation_history = []
        self.empirical_cooperation_rate = None
        self.defect_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round < self.phase1_end:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        if self.empirical_cooperation_rate is None and history is not None:
            phase1_cooperators = []
            for round_idx in range(self.phase1_end):
                cooperators_in_round = np.sum(history.opponent_actions[round_idx, :])
                phase1_cooperators.append(cooperators_in_round)
            avg_cooperators = np.mean(phase1_cooperators) if phase1_cooperators else 0
            self.empirical_cooperation_rate = avg_cooperators / self.n_players if self.n_players > 0 else 0
        if self.empirical_cooperation_rate is None:
            self.empirical_cooperation_rate = 0.0
        expected_cooperators = self.empirical_cooperation_rate * self.n_players
        if expected_cooperators >= self.m:
            return Action.D
        elif expected_cooperators >= self.m - 1:
            if current_round % 2 == 0:
                return Action.D
            else:
                return Action.C
        elif history is not None and current_round > 0:
            cooperators_last_round = np.sum(history.opponent_actions[current_round - 1, :])
            if cooperators_last_round >= self.m:
                return Action.D
            else:
                self.defect_count += 1
                return Action.C
        else:
            return Action.C

class Strategy_EXPLOITATIVE_433(BaseStrategy):
    """
    Conditional Defection with Adaptive Thresholding Strategy.
    
    Exploits the payoff asymmetry in the Collective Risk Dilemma by defaulting to defection
    and only cooperating when exactly (m-1) players cooperated in the previous round to "rescue"
    the threshold and secure the reward. Always defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == self.n_rounds - 1:
            return Action.D
        if current_round == 0:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if cooperators_last_round == self.m - 1:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_434(BaseStrategy):
    """
    Adaptive Threshold Exploitation (ATE) Strategy for Collective Risk Dilemma.
    
    Exploits the asymmetry in payoff structure by:
    1. Always defecting in first round to establish baseline
    2. Free-riding when threshold is met (defecting for 1+k vs cooperating for k)
    3. Strategically cooperating near-threshold to maintain cooperator pool
    4. Aggressive defection in final quarter with no reputation consequences
    5. Terminal exploitation in last round
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        final_quarter_threshold = math.floor(0.75 * self.n_rounds)
        if current_round > final_quarter_threshold:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if cooperators_last_round >= self.m:
            return Action.D
        if cooperators_last_round == self.m - 1:
            if random.random() < 0.7:
                return Action.D
            else:
                return Action.C
        if cooperators_last_round < self.m - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_435(BaseStrategy):
    """
    Adaptive Threshold Exploitation Strategy for Collective Risk Dilemma.
    
    Exploits the structural vulnerability where defectors profit when others cooperate.
    Always defects in round 1 and final round. In middle rounds, defects if observed
    cooperation rate suggests the threshold m will be met by others' actions alone.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperator_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        self.cooperator_count = int(np.sum(history.opponent_actions[:current_round, :]))
        if current_round == 0:
            cooperation_rate = 0.0
        else:
            cooperation_rate = self.cooperator_count / (current_round * (n - 1))
        if current_round <= 2:
            cooperation_rate = (self.cooperator_count + 1) / ((current_round + 2) * (n - 1))
        threshold = (m - 0.5) / (n - 1)
        if cooperation_rate >= threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_436(BaseStrategy):
    """
    Conditional Defection with Minimal Commitment: An exploitative strategy that
    defects by default, only cooperating when necessary to unlock rewards while
    minimizing personal contribution. Exploits the payoff asymmetry where defection
    yields k+1 when others meet the threshold, versus k for cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        previous_round_index = current_round - 1
        previous_round_opponent_actions = history.opponent_actions[previous_round_index, :]
        cooperators_last_round = int(np.sum(previous_round_opponent_actions))
        if cooperators_last_round >= m:
            return Action.D
        if cooperators_last_round >= m - 1:
            return Action.D
        if cooperators_last_round < m - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_437(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism
    
    Exploits the structural vulnerability of the Collective Risk Dilemma by
    defaulting to defection and only strategically cooperating in rare cases
    where it's strictly beneficial. Leverages parasitism on near-threshold
    situations and terminal round exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.n_rounds - 1:
            return Action.D
        prev_round_idx = round_num - 1
        prev_cooperators = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            prev_cooperators += 1
        coop_rate = prev_cooperators / self.n_players
        threshold_rate = self.m / self.n_players
        critical_rate = (self.m - 1) / self.n_players
        if prev_cooperators >= self.m:
            return Action.D
        if prev_cooperators == self.m - 1:
            return Action.D
        if prev_cooperators < self.m - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_438(BaseStrategy):
    """
    Adaptive Threshold Parasitism: An exploitative strategy that defects by default,
    cooperates only when confident others will meet the threshold without contribution,
    and permanently defects in final rounds and when cooperation collapses.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.confidence_threshold = 0.6
        self.permanent_defection = False
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[round_num - 1, :]))
        self.cooperation_history.append(cooperators_last_round)
        if self.permanent_defection:
            return Action.D
        if round_num >= 3:
            cooperation_rate = cooperators_last_round / (self.n_players - 1) if self.n_players > 1 else 0
            collapse_threshold = self.m / self.n_players - 0.2
            if cooperation_rate < collapse_threshold:
                self.permanent_defection = True
                return Action.D
        if self.m == self.n_players:
            return Action.D
        cooperation_rate = cooperators_last_round / (self.n_players - 1) if self.n_players > 1 else 0
        threshold_met_last_round = cooperators_last_round >= self.m
        if not threshold_met_last_round:
            return Action.D
        prob_threshold_without_me = self._calculate_threshold_probability(cooperation_rate, self.m - 1, self.n_players - 1)
        if prob_threshold_without_me > self.confidence_threshold:
            return Action.D
        else:
            return Action.D

    def _calculate_threshold_probability(self, cooperation_rate: float, threshold: int, population: int) -> float:
        """
        Calculate the probability that at least 'threshold' out of 'population' players
        cooperate, given an empirical cooperation rate.
        Uses a binomial approximation.
        """
        if population <= 0 or cooperation_rate < 0 or cooperation_rate > 1:
            return 0.0
        if threshold > population:
            return 0.0
        if threshold <= 0:
            return 1.0
        mean = population * cooperation_rate
        variance = population * cooperation_rate * (1 - cooperation_rate)
        if variance < 1e-10:
            return 1.0 if mean >= threshold else 0.0
        std_dev = math.sqrt(variance)
        z_score = (threshold - 0.5 - mean) / std_dev
        cdf_value = 0.5 * (1 + math.erf(-z_score / math.sqrt(2)))
        return cdf_value

class Strategy_COLLECTIVE_507(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for Collective Risk Dilemma.
    
    Balances optimism bias toward cooperation with adaptive pessimism when cooperation fails.
    Increases contribution effort as time runs out, recognizing that collective welfare
    and individual payoff are conditionally aligned when the cooperation threshold is met.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            cooperation_rate_history = 0.5
        else:
            total_cooperators = 0
            for past_round in range(round_number):
                cooperators_in_round = int(np.sum(history.opponent_actions[past_round, :]))
                total_cooperators += cooperators_in_round
            cooperation_rate_history = total_cooperators / max(1, self.n * round_number)
        rounds_remaining = self.r - round_number - 1
        base_threshold = self.m / self.n
        if rounds_remaining > 0:
            adjusted_threshold = base_threshold * (1.0 - 0.15 * cooperation_rate_history)
        else:
            adjusted_threshold = base_threshold
        urgency_factor = 1.0 + 0.5 * (1.0 - cooperation_rate_history)
        effective_cooperation = cooperation_rate_history * urgency_factor
        if effective_cooperation >= adjusted_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_508(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATC)
    
    Balances individual security with collective benefit by dynamically adjusting
    cooperation based on empirical evidence of others' willingness to cooperate.
    Cooperates when rational to expect the threshold will be met, defects only when
    evidence suggests the collective cannot reach it.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        prev_round_opponent_actions = history.opponent_actions[round_number - 1, :]
        cooperation_count_last_round = int(np.sum(prev_round_opponent_actions))
        if history.my_actions[round_number - 1]:
            cooperation_count_last_round += 1
        cooperation_rate = cooperation_count_last_round / self.n
        threshold_cooperation_rate = self.m / self.n
        if cooperation_rate >= threshold_cooperation_rate:
            return Action.C
        marginal_threshold = threshold_cooperation_rate - 1.0 / self.n
        if cooperation_rate >= marginal_threshold:
            return Action.C
        if round_number == self.r - 1:
            if cooperation_count_last_round >= self.m:
                return Action.C
            else:
                return Action.D
        return Action.C

class Strategy_COLLECTIVE_512(BaseStrategy):
    """
    Adaptive Threshold Strategy (ATS) for Collective Risk Dilemma.
    
    Dynamically adjusts cooperation based on observed cooperation rates relative to 
    the threshold m/n, with a safety buffer. Cooperates in round 1 to signal intent,
    defects in final round (backward induction), and adapts in middle rounds based on
    recent history of observed cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        base_ratio = self.m / self.n
        buffer = max(0.15, base_ratio * 0.3)
        if base_ratio > 0.85:
            buffer = base_ratio * 0.15
        if base_ratio < 0.25:
            buffer += 0.2
        self.cooperation_threshold = base_ratio + buffer
        self.recent_window = max(3, self.r // 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            return Action.D
        start_idx = max(0, current_round - self.recent_window)
        end_idx = current_round
        if start_idx >= end_idx or history is None:
            return Action.C
        recent_rounds = history.opponent_actions[start_idx:end_idx, :]
        if recent_rounds.size == 0:
            return Action.C
        total_cooperators = np.sum(recent_rounds)
        total_slots = recent_rounds.shape[0] * recent_rounds.shape[1]
        observed_cooperation_rate = total_cooperators / total_slots if total_slots > 0 else 0.0
        if current_round >= 2 and np.sum(history.opponent_actions[current_round - 1, :]) == 0 and (np.sum(history.opponent_actions[current_round - 2, :]) > self.m):
            return Action.C
        if observed_cooperation_rate >= self.cooperation_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_4(BaseStrategy):
    """
    Adaptive Threshold Parasitism: An exploitative strategy that free-rides on others'
    cooperation while minimizing personal commitment. Cooperates only when necessary to
    reach the threshold for personal gain, then immediately exploits the situation by
    defecting in subsequent rounds and the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        c_prev = int(np.sum(history.opponent_actions[round_number - 1, :]))
        is_final_round = round_number == self.n_rounds - 1
        if c_prev >= self.m:
            return Action.D
        if c_prev == self.m - 1:
            if is_final_round:
                return Action.D
            else:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_8(BaseStrategy):
    """
    Adaptive Free-Riding with Threshold Exploitation strategy.
    
    Exploits the threshold mechanism by strategically defecting when cooperation
    is likely, while minimizing losses when defection threatens the threshold.
    Uses adaptive estimation of expected cooperators and exhibits ruthless
    endgame behavior.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_round_cooperators = 0
        self.defection_trend = 0
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        total_rounds = self.game_description.n_rounds
        if round_num == 0:
            if m == n - 1:
                self.cooperation_history.append(True)
                return Action.C
            else:
                self.cooperation_history.append(False)
                return Action.D
        last_round_cooperators = int(np.sum(history.opponent_actions[round_num - 1, :]))
        self.last_round_cooperators = last_round_cooperators
        if round_num == total_rounds - 1:
            if last_round_cooperators >= m:
                self.cooperation_history.append(False)
                return Action.D
            elif last_round_cooperators == m - 1:
                self.cooperation_history.append(True)
                return Action.C
            else:
                self.cooperation_history.append(False)
                return Action.D
        expected_cooperators = last_round_cooperators + self.defection_trend
        if round_num > 1:
            prev_cooperators = int(np.sum(history.opponent_actions[round_num - 2, :]))
            defection_rate = 1.0 - prev_cooperators / n if n > 0 else 0.5
            if defection_rate < 0.4:
                self.defection_trend = 1
            elif defection_rate > 0.6:
                self.defection_trend = -1
            elif last_round_cooperators > self.last_round_cooperators:
                self.defection_trend = 1
            elif last_round_cooperators < self.last_round_cooperators:
                self.defection_trend = -1
            else:
                self.defection_trend = 0
        if round_num > 0 and round_num % 3 == 0:
            recent_coop = self.cooperation_history[-3:] if len(self.cooperation_history) >= 3 else self.cooperation_history
            if len(recent_coop) > 1:
                coop_count = sum((1 for c in recent_coop if c))
                if coop_count < len(recent_coop) * 0.4:
                    expected_cooperators = max(expected_cooperators, last_round_cooperators)
        if expected_cooperators >= m:
            self.cooperation_history.append(False)
            return Action.D
        elif expected_cooperators == m - 1:
            self.cooperation_history.append(True)
            return Action.C
        else:
            self.cooperation_history.append(False)
            return Action.D

class Strategy_EXPLOITATIVE_439(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Free-Riding with Conditional Defection
    
    This strategy systematically exploits the asymmetry in the Collective Risk Dilemma
    by free-riding when the cooperation threshold is met, cooperating minimally when
    near-threshold to trigger collective success, and unconditionally defecting in
    the final round. It adapts dynamically to opponent cooperation rates.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        previous_round_idx = current_round - 1
        opponent_actions_prev = history.opponent_actions[previous_round_idx, :]
        coop_count = int(np.sum(opponent_actions_prev))
        coop_rate = coop_count / self.n
        threshold_rate = self.m / self.n
        if coop_rate >= threshold_rate:
            return Action.D
        near_threshold = threshold_rate - 1.0 / self.n
        if coop_rate >= near_threshold:
            return Action.C
        far_threshold = threshold_rate - 2.0 / self.n
        if coop_rate < far_threshold:
            return Action.D
        deficit = self.m - coop_count
        defectors = self.n - coop_count
        if defectors <= 0:
            return Action.D
        prob_cooperate = deficit / defectors
        prob_cooperate = max(0.0, min(1.0, prob_cooperate))
        if random.random() < prob_cooperate:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_440(BaseStrategy):
    """
    Adaptive Threshold Parasitism: Exploits threshold mechanism by free-riding on others' cooperation.
    
    Defects in round 1 and final round unconditionally. In intermediate rounds, tracks cooperation
    rates from the previous round and defects if the threshold appears likely to be met or has been met,
    thereby capturing the reward (1 + k) without bearing the cooperation cost.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if state.round_number == 0:
            return Action.D
        if state.round_number == r - 1:
            return Action.D
        prev_round_idx = state.round_number - 1
        prev_cooperators = int(sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            prev_cooperators += 1
        cooperation_rate = prev_cooperators / n
        threshold_rate = m / n
        if cooperation_rate >= threshold_rate - 1 / n:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_441(BaseStrategy):
    """
    Adaptive Defection with Conditional Free-Riding.
    
    Exploits payoff asymmetry by systematically free-riding on others' cooperation
    while remaining flexible enough to avoid complete mutual defection collapse.
    Uses threshold-based decision rules with recency-weighted observation windows.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_high = self.m / self.n + 0.15
        self.threshold_medium = self.m / self.n - 0.1
        self.threshold_low = (self.m - 1) / (self.n - 1) - 0.2 if self.n > 1 else 0.0
        self.window_size = max(2, self.r // 3)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        window_start = max(0, round_num - self.window_size)
        window_end = round_num
        cooperator_counts = []
        for t in range(window_start, window_end):
            round_cooperators = np.sum(history.opponent_actions[t, :])
            cooperator_counts.append(round_cooperators)
        if len(cooperator_counts) == 0:
            return Action.D
        avg_cooperators = np.mean(cooperator_counts)
        cooperation_rate = avg_cooperators / (self.n - 1) if self.n > 1 else 0.0
        cooperation_rate = max(0.0, min(1.0, cooperation_rate))
        if cooperation_rate >= self.threshold_high:
            return Action.D
        elif cooperation_rate >= self.threshold_medium:
            expected_cooperators = cooperation_rate * (self.n - 1)
            if abs(expected_cooperators - (self.m - 1)) < 0.5:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_442(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD): An exploitative strategy that maximizes
    personal payoff by free-riding on others' cooperation while strategically
    cooperating only when necessary to trigger the threshold or in endgame scenarios.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = []
        self.estimated_cooperators = {}

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        coop_last = int(np.sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            coop_last += 1
        self.cooperation_history.append(coop_last)
        if round_num == r - 1:
            return Action.D
        if round_num == r - 2:
            if coop_last < m:
                if random.random() < 1.0 / m:
                    return Action.C
            return Action.D
        if coop_last >= m:
            return Action.D
        deficit = m - coop_last
        estimated_defectors = 0
        if round_num >= 2:
            for opponent_idx in range(n - 1):
                if np.all(~history.opponent_actions[:round_num, opponent_idx]):
                    estimated_defectors += 1
        if deficit <= math.ceil(n / 3.0):
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_443(BaseStrategy):
    """
    Adaptive Free-Riding with Threshold Exploitation.
    
    This strategy maximizes personal payoff by exploiting the threshold mechanism.
    Core approach: defect by default, cooperate only when strategically necessary to
    reach the threshold (swing-vote scenarios), and ruthlessly extract value in final rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        coop_count_last = int(sum(history.opponent_actions[round_num - 1, :]))
        predicted_coop = max(0, math.floor(coop_count_last * 0.7))
        if predicted_coop >= self.m:
            return Action.D
        elif predicted_coop < self.m - 1:
            return Action.D
        elif predicted_coop == self.m - 1:
            my_last_action = history.my_actions[round_num - 1]
            if my_last_action:
                return Action.D
            else:
                return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_444(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD) Strategy
    
    Pure defection strategy that exploits the asymmetry in the Collective Risk Dilemma.
    Always defects to free-ride on cooperators' efforts when the threshold is met,
    while avoiding the cost of cooperation when the threshold cannot be reached.
    Monitors cooperation patterns for informational purposes but maintains unconditional defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cumulative_cooperators = 0
        self.rounds_observed = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if history is not None and state.round_number > 0:
            last_round_cooperators = int(np.sum(history.opponent_actions[state.round_number - 1, :]))
            self.cumulative_cooperators += last_round_cooperators
            self.rounds_observed = state.round_number
        return Action.D

class Strategy_EXPLOITATIVE_445(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Free-Riding with Threshold Monitoring
    
    Exploits the asymmetry between cooperators and defectors by defecting when safe,
    cooperating only when necessary to enable reward harvesting. Maximizes personal payoff
    through strategic non-contribution while exploiting collective action dynamics.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
        if history.my_actions[current_round - 1]:
            cooperators_last_round += 1
        if cooperators_last_round >= self.m:
            return Action.D
        if cooperators_last_round == self.m - 1:
            return Action.D
        deficit = self.m - cooperators_last_round
        rounds_remaining = self.n_rounds - current_round
        if deficit > rounds_remaining:
            return Action.D
        if deficit > 1:
            if current_round >= 2:
                reliable_cooperators = 0
                for player_idx in range(self.n_players - 1):
                    if history.opponent_actions[current_round - 1, player_idx] and history.opponent_actions[current_round - 2, player_idx]:
                        reliable_cooperators += 1
            else:
                reliable_cooperators = cooperators_last_round
            if reliable_cooperators >= deficit:
                return Action.D
            cooperation_probability = deficit / (deficit + 1)
            if random.random() < cooperation_probability:
                return Action.C
            else:
                return Action.D
        if deficit == 1:
            if random.random() < 0.5:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_446(BaseStrategy):
    """
    Conditional Parasite: An exploitative strategy for the Collective Risk Dilemma.
    
    Exploits the threshold mechanism by free-riding on others' cooperation while maintaining
    minimal stochastic defection credibility. The core insight: once m cooperators exist,
    defecting becomes strictly dominant. Extract maximum value by letting others shoulder
    the burden.
    
    Decision rules:
    - Round 1: Always defect (gather information)
    - Final round: Always defect (no future consequences)
    - Middle rounds: Defect when threshold is met or unreachable; rarely cooperate when near-threshold
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.epsilon = 1.0 / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.r - 1:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[state.round_number - 1, :]))
        if cooperators_last_round >= self.m:
            return Action.D
        elif cooperators_last_round == self.m - 1:
            if random.random() < self.epsilon:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_447(BaseStrategy):
    """
    Adaptive Threshold Exploitation (ATE) Strategy for Collective Risk Dilemma.
    
    Exploits the asymmetry between cooperators (bear cost c=1) and defectors (capture reward k).
    Dynamically identifies when cooperation is "free" (threshold met) and defects; when cooperation
    is mandatory (threshold won't be met otherwise), attempts to free-ride on others' cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_opponent_actions = history.opponent_actions[current_round - 1, :]
        coop_count_prev = int(np.sum(prev_opponent_actions))
        my_prev_action = history.my_actions[current_round - 1]
        coop_count_prev += int(my_prev_action)
        cooperation_rate = coop_count_prev / self.n
        total_coop_actions = int(np.sum(history.opponent_actions[:current_round, :])) + int(np.sum(history.my_actions[:current_round]))
        historical_rate = total_coop_actions / (current_round * self.n) if current_round > 0 else 0
        phase = 'early'
        if current_round > self.r / 3:
            phase = 'middle'
        if current_round >= 2 * self.r / 3:
            phase = 'late'
        base_defect_threshold = self.m / self.n
        if coop_count_prev >= self.m:
            return Action.D
        if coop_count_prev == self.m - 1:
            p_coop = 0.6
            if phase == 'middle' and historical_rate > 0.5:
                p_coop = 0.3
            if phase == 'late':
                p_coop = 0.4
            if random.random() < p_coop:
                return Action.C
            else:
                return Action.D
        if coop_count_prev < self.m - 1:
            if phase == 'early':
                return Action.C
            if phase == 'middle':
                if historical_rate < 0.3:
                    return Action.D
                else:
                    return Action.C
            if phase == 'late':
                if coop_count_prev == self.m - 2 and historical_rate > 0.5:
                    return Action.C
                else:
                    return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_448(BaseStrategy):
    """
    Adaptive Threshold Predation (ATP): An exploitative strategy that defects to maximize payoff
    by harvesting rewards when other players cooperate enough to meet the threshold, while avoiding
    the cooperation cost. Uses observed cooperation rates to adapt exploitation timing.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        if self.m == self.n:
            observed_coop_rate = self._calculate_cooperation_rate(history, current_round)
            if observed_coop_rate >= 0.9:
                return Action.C
            return Action.D
        ctp = self._calculate_cooperation_threshold_probability(history, current_round)
        threshold_rate = (self.m - 1) / (self.n - 1)
        if ctp >= threshold_rate:
            return Action.D
        if current_round > self.r / 2:
            return Action.D
        return Action.D

    def _calculate_cooperation_threshold_probability(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the observed cooperation rate among other players.
        CTP = (cooperations observed) / (total action slots observed)
        """
        if current_round == 0:
            return 0.0
        cooperations_observed = np.sum(history.opponent_actions[:current_round, :])
        total_action_slots = (self.n - 1) * current_round
        if total_action_slots == 0:
            return 0.0
        ctp = cooperations_observed / total_action_slots
        return ctp

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the overall cooperation rate across all observed rounds.
        Used for special cases like m == n.
        """
        if current_round == 0:
            return 0.0
        cooperations_observed = np.sum(history.opponent_actions[:current_round, :])
        total_action_slots = (self.n - 1) * current_round
        if total_action_slots == 0:
            return 0.0
        return cooperations_observed / total_action_slots

class Strategy_EXPLOITATIVE_449(BaseStrategy):
    """
    Adaptive Threshold Exploit strategy for Collective Risk Dilemma.
    
    Maximizes personal payoff by exploiting the asymmetry between cooperators
    and defectors. Dynamically estimates opponent cooperation likelihood and
    shifts between exploitation and minimal-cost survival. Defaults to defection
    in almost all cases to capture the k reward without paying the cooperation cost.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.epsilon = 0.15

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        if t == 0:
            return Action.D
        est_coop = self._calculate_estimated_cooperation(history, t)
        p_threshold_met = self._estimate_threshold_probability(est_coop)
        if p_threshold_met > 1 - self.epsilon and est_coop > self.m / (2 * self.n):
            return Action.D
        early_threshold = max(1, math.ceil(0.1 * self.r))
        if t < early_threshold:
            return Action.D
        late_threshold = math.floor(0.9 * self.r)
        if t >= late_threshold:
            return Action.D
        threshold_needed = (self.m - 1) / (self.n - 1) if self.n > 1 else 0
        if est_coop > 0.6 * threshold_needed:
            return Action.D
        if est_coop < 0.3 * threshold_needed:
            return Action.D
        return Action.D

    def _calculate_estimated_cooperation(self, history: PlayerHistory, t: int) -> float:
        """
        Calculate estimated cooperation rate from observed history.
        """
        if t == 1:
            return (self.m - 1) / (self.n - 1) if self.n > 1 else 0.0
        total_coop_actions = np.sum(history.opponent_actions[:t, :])
        total_possible_actions = t * self.n
        if total_possible_actions == 0:
            return (self.m - 1) / (self.n - 1) if self.n > 1 else 0.0
        est_coop = total_coop_actions / total_possible_actions
        return float(est_coop)

    def _estimate_threshold_probability(self, est_coop: float) -> float:
        """
        Estimate probability that at least m-1 others will cooperate this round.
        Uses binomial approximation.
        """
        if self.n <= 1:
            return 0.0
        expected_cooperators = est_coop * (self.n - 1)
        p_threshold_met = min(1.0, (self.m - 1 + expected_cooperators) / (self.n - 1))
        return p_threshold_met

class Strategy_EXPLOITATIVE_450(BaseStrategy):
    """
    Adaptive Threshold Predation: An exploitative strategy that defects unconditionally
    to free-ride on others' cooperation while avoiding the cost of contribution.
    
    Core mechanism:
    - Always defect to save the 1-unit endowment cost
    - Capture the k bonus whenever m or more other players cooperate
    - Immune to punishment due to simultaneous moves
    - Exploits the threshold mechanism by letting others meet it
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_451(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Free-Riding with Conditional Participation
    
    Core philosophy: Exploit the asymmetry between cooperators and defectors by:
    1. Never cooperating (avoid cost c=1)
    2. Free-riding when threshold is likely met (capture reward k)
    3. Defecting when threshold seems unattainable (avoid wasting cost)
    
    Uses a cooperation rate heuristic to decide whether to expect the threshold
    to be met, with adjustments for early rounds and threshold clustering.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        total_cooperations = int(np.sum(history.opponent_actions))
        total_observations = state.round_number * self.n_players
        if total_observations == 0:
            return Action.D
        coop_rate = total_cooperations / total_observations
        expected_cooperators = coop_rate * self.n_players
        if state.round_number <= 2:
            coop_rate *= 0.85
            expected_cooperators = coop_rate * self.n_players
        threshold_baseline = self.m / self.n_players
        if coop_rate >= threshold_baseline and state.round_number >= 2:
            last_round_cooperators = int(np.sum(history.opponent_actions[-1, :]))
            last_round_rate = last_round_cooperators / self.n_players
            if last_round_rate > coop_rate * 0.5:
                required_cooperators = 1.1 * self.m
            else:
                required_cooperators = self.m
        else:
            required_cooperators = self.m
        if expected_cooperators >= required_cooperators:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_452(BaseStrategy):
    """
    Adaptive Defection with Conditional Parasitism.
    
    A strict dominance strategy that exploits the Collective Risk Dilemma's 
    payoff asymmetry by defecting in all rounds. Defectors earn maximum payoff 
    (1 + k) when threshold is met, and face no downside when it isn't.
    
    Core mechanics:
    - Round 1: Defect (information gathering without cost)
    - Last round: Defect (no future consequences)
    - Middle rounds: Always defect (free-ride on cooperation or avoid wasted contribution)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_453(BaseStrategy):
    """
    Exploitative strategy using adaptive defection with conditional cooperation.
    
    Core approach:
    - Round 1: Always defect (information gathering, avoid sunk cost)
    - Final round: Always defect (no future punishment possible)
    - Middle rounds: Track cooperation rates and exploit threshold dynamics
      - Defect when cooperation rate suggests threshold will be met
      - Selectively cooperate only to fill small gaps when necessary
    - End-game acceleration: Increase defection tendency as rounds diminish
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        total_cooperations = int(np.sum(history.opponent_actions[:round_number, :]))
        total_observations = (self.n_players - 1) * round_number
        if total_observations == 0:
            cooperation_rate = 0.0
        else:
            cooperation_rate = total_cooperations / total_observations
        recent_rounds_count = min(3, round_number)
        recent_start = max(0, round_number - recent_rounds_count)
        recent_cooperations = int(np.sum(history.opponent_actions[recent_start:round_number, :]))
        recent_observations = (self.n_players - 1) * recent_rounds_count
        if recent_observations == 0:
            recent_average = 0.0
        else:
            recent_average = recent_cooperations / recent_observations
        weighted_cooperation = 0.6 * cooperation_rate + 0.4 * recent_average
        cooperation_threshold = (self.m - 1) / self.n_players
        remaining_rounds = self.n_rounds - round_number
        defect_acceleration = 1.0 - math.sqrt(remaining_rounds / self.n_rounds)
        if weighted_cooperation >= cooperation_threshold:
            return Action.D
        threshold_unlikely = (self.m - 2) / self.n_players if self.m > 2 else 0.0
        if weighted_cooperation < threshold_unlikely:
            return Action.D
        if round_number > 0:
            last_round_cooperators = int(np.sum(history.opponent_actions[round_number - 1, :]))
        else:
            last_round_cooperators = 0
        gap = self.m - 1 - last_round_cooperators
        if 0 < gap <= 1:
            return Action.C
        if defect_acceleration > 0.3:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_454(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD): An exploitative strategy that defects to free-ride
    on others' cooperation. Tracks cooperation rates and confirms threshold conditions,
    then defaults to defection to maximize payoff extraction.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.n_rounds - 1:
            return Action.D
        previous_round_idx = state.round_number - 1
        own_action_prev = history.my_actions[previous_round_idx]
        opponent_cooperators_prev = sum(history.opponent_actions[previous_round_idx, :])
        total_cooperators_prev = opponent_cooperators_prev + (1 if own_action_prev else 0)
        threshold_met_last_round = total_cooperators_prev >= self.m
        cooperation_rate = total_cooperators_prev / self.n_players
        if threshold_met_last_round:
            return Action.D
        if self.n_players > 1:
            threshold_fraction = self.m / self.n_players
            if cooperation_rate >= threshold_fraction * 0.9:
                return Action.D
            if cooperation_rate < threshold_fraction * 0.5:
                return Action.D
        rounds_remaining = self.n_rounds - state.round_number
        if rounds_remaining <= 2:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_455(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Free-Riding
    
    This strategy maximizes personal gain by exploiting threshold dynamics,
    free-riding on others' cooperation, and defecting when cooperation is
    unlikely. Core mechanism: always defect in terminal and initial rounds,
    and free-ride whenever threshold is met or unlikely to be met.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        m = self.game_description.m
        if state.round_number == 0:
            return Action.D
        if state.round_number == r - 1:
            return Action.D
        if history is None:
            cooperators_last_round = 0
        else:
            cooperators_last_round = int(sum(history.opponent_actions[state.round_number - 1, :]))
        return Action.D

class Strategy_EXPLOITATIVE_456(BaseStrategy):
    """
    Exploitative Strategy: Conditional Free-Riding with Adaptive Defection
    
    Exploits asymmetry in payoff structure by defecting when threshold is likely met,
    free-riding on others' contributions. Adapts based on observed cooperation patterns
    with probabilistic matching in marginal zones.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold_ratio = game_description.m / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        cooperation_ratio = self._calculate_cooperation_ratio(history, state.round_number)
        if cooperation_ratio >= self.threshold_ratio * 1.2:
            return Action.D
        if cooperation_ratio < self.threshold_ratio * 0.8:
            return Action.D
        p_cooperate = self.threshold_ratio - 0.05
        p_cooperate = max(0.0, min(1.0, p_cooperate))
        if random.random() < p_cooperate:
            return Action.C
        return Action.D

    def _calculate_cooperation_ratio(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the ratio of cooperators across all previous rounds.
        
        Returns:
            float: Average cooperation ratio, or 0 if no history (shouldn't happen in rounds 1+)
        """
        if current_round == 0:
            return 0.0
        total_cooperations = 0
        for round_idx in range(current_round):
            total_cooperations += np.sum(history.opponent_actions[round_idx, :])
        total_possible = current_round * self.game_description.n_players
        if total_possible == 0:
            return 0.0
        return total_cooperations / total_possible

class Strategy_EXPLOITATIVE_457(BaseStrategy):
    """
    THRESHOLD HUNTER: Exploitative strategy that free-rides when the cooperation threshold
    is likely to be met, and defects when it won't be. Systematically exploits asymmetry
    between cooperators (who pay costs) and defectors (who capture rewards).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        previous_round_idx = current_round - 1
        opponent_cooperators_prev = int(np.sum(history.opponent_actions[previous_round_idx, :]))
        my_cooperated_prev = int(history.my_actions[previous_round_idx])
        total_cooperators_prev = opponent_cooperators_prev + my_cooperated_prev
        coop_rate = total_cooperators_prev / self.n
        threshold_margin = self.m / self.n - 0.05
        threshold_likely = coop_rate >= threshold_margin
        if threshold_likely:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_458(BaseStrategy):
    """
    Adaptive Threshold Defection Strategy for Collective Risk Dilemma.
    
    Exploitative strategy that defaults to defection, free-rides when others
    are cooperating to meet the threshold, and only cooperates in rare cases.
    Prioritizes individual payoff maximization over group welfare.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        if current_round == self.r - 2:
            return Action.D
        look_back = min(3, current_round)
        recent_rounds_start = max(0, current_round - look_back)
        recent_opponent_actions = history.opponent_actions[recent_rounds_start:current_round, :]
        cooperators_per_round = np.sum(recent_opponent_actions, axis=1)
        if len(cooperators_per_round) == 0:
            return Action.D
        median_cooperators = float(np.median(cooperators_per_round))
        total_recent_actions = np.sum(recent_opponent_actions)
        total_possible = len(cooperators_per_round) * (self.n - 1)
        if total_possible > 0:
            others_cooperating_rate = total_recent_actions / total_possible
        else:
            others_cooperating_rate = 0.0
        if median_cooperators >= self.m - 1:
            return Action.D
        if others_cooperating_rate > 0.6 and median_cooperators < self.m:
            return Action.D
        rounds_remaining = self.r - current_round - 1
        if median_cooperators >= self.m - 2 and rounds_remaining > 1:
            return Action.D
        if rounds_remaining <= 1:
            return Action.D
        if current_round >= 3:
            last_three_rounds = history.opponent_actions[max(0, current_round - 3):current_round, :]
            if len(last_three_rounds) >= 3:
                cooperators_in_last_three = np.sum(last_three_rounds, axis=1)
                if np.all(cooperators_in_last_three == self.n - 1):
                    return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_459(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation
    
    Exploits the asymmetry between cooperators and defectors by:
    1. Always defecting in round 1 to establish non-contributor baseline
    2. Always defecting in the final round (no future consequences)
    3. In middle rounds, adapting based on observed cooperation levels:
       - Free-ride when threshold is reliably met
       - Defect when threshold is impossible
       - Conditionally cooperate only when pivotal early in the game
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperators_per_round = np.sum(history.opponent_actions, axis=1)
        avg_cooperators = self._calculate_ewma(cooperators_per_round, weight=0.7)
        cooperators_last_round = cooperators_per_round[-1]
        if avg_cooperators >= self.m:
            return Action.D
        if avg_cooperators < self.m - 1:
            return Action.D
        if self.m - 1 <= avg_cooperators < self.m:
            if cooperators_last_round == self.m - 1:
                if current_round < self.n_rounds / 2:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D
        return Action.D

    def _calculate_ewma(self, values: NDArray[np.float64], weight: float) -> float:
        """
        Calculate exponentially-weighted moving average.
        Recent values weighted more heavily.
        
        Args:
            values: Array of historical values
            weight: Weight for recent average (0 < weight <= 1)
        
        Returns:
            Weighted average favoring recent observations
        """
        if len(values) == 0:
            return 0.0
        if len(values) == 1:
            return float(values[0])
        mid_point = max(1, len(values) // 2)
        recent_avg = float(np.mean(values[-mid_point:]))
        older_avg = float(np.mean(values[:-mid_point])) if mid_point < len(values) else 0.0
        ewma = weight * recent_avg + (1.0 - weight) * older_avg
        return ewma

class Strategy_EXPLOITATIVE_460(BaseStrategy):
    """
    Adaptive Defection with Conditional Cooperation strategy.
    
    Exploits the asymmetry between cooperators and defectors by strategically
    defecting to capture private returns (1) while free-riding on others'
    cooperation to gain shared benefits (k) when the threshold is met.
    
    Core logic: Always defect to maximize payoff against any strategy that
    cooperates, while tying against pure defectors.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_461(BaseStrategy):
    """
    Exploitative Strategy: "Conditional Free-Riding with Adaptive Threshold"
    
    Maximizes personal payoff by exploiting the threshold mechanism in the Collective Risk Dilemma.
    The core insight: once m players cooperate, additional defectors receive the full reward (k) 
    without paying the cooperation cost (1). This strategy always defects to exploit this asymmetry.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        m = self.game_description.m
        n_rounds = self.game_description.n_rounds
        rounds_remaining = n_rounds - state.round_number - 1
        if rounds_remaining == 0:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[-1, :]))
        return Action.D

class Strategy_EXPLOITATIVE_462(BaseStrategy):
    """
    Adaptive Threshold Exploitation strategy for Collective Risk Dilemma.
    
    Exploits the asymmetry by defecting when others cooperate (free-riding),
    while strategically cooperating only to maintain thresholds that benefit
    defectors. Maximizes payoff through information gathering, threshold
    manipulation, and last-round exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.consecutive_same_rate = 0
        self.last_cooperation_rate = None
        self.locked_strategy = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        if history is None or len(history.opponent_actions) == 0:
            return Action.D
        previous_round_idx = current_round - 1
        cooperators_prev_round = np.sum(history.opponent_actions[previous_round_idx, :])
        cooperation_rate = cooperators_prev_round / self.n
        if self.locked_strategy is not None:
            return self.locked_strategy
        if self.last_cooperation_rate is not None:
            if abs(cooperation_rate - self.last_cooperation_rate) < 1e-06:
                self.consecutive_same_rate += 1
            else:
                self.consecutive_same_rate = 0
        self.last_cooperation_rate = cooperation_rate
        if self.consecutive_same_rate >= 2:
            if cooperation_rate >= self.m / self.n:
                self.locked_strategy = Action.D
            else:
                self.locked_strategy = Action.D
            return self.locked_strategy
        threshold_rate = self.m / self.n
        if cooperation_rate >= threshold_rate and cooperation_rate < 1.0:
            return Action.D
        if cooperation_rate >= 1.0 or cooperation_rate >= (self.m - 1) / self.n:
            return Action.D
        if cooperation_rate < threshold_rate:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_463(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD): An exploitative strategy that free-rides on others' 
    cooperation while strategically cooperating only when certain the threshold will be met 
    without our crucial contribution.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.total_rounds_played = 0
        self.cumulative_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        self._update_cooperation_stats(history, state.round_number)
        total_observations = state.round_number * self.game_description.n_players
        if total_observations == 0:
            cooperation_rate = 0.0
        else:
            cooperation_rate = self.cumulative_cooperators / total_observations
        threshold_rate = self.game_description.m / self.game_description.n_players * 1.2
        if state.round_number > 0:
            last_round_cooperators = int(sum(history.opponent_actions[state.round_number - 1, :]))
            if last_round_cooperators >= self.game_description.m:
                return Action.D
            if last_round_cooperators == self.game_description.m - 1:
                return Action.D
            if last_round_cooperators < self.game_description.m - 1:
                rounds_remaining = self.game_description.n_rounds - state.round_number
                if rounds_remaining > 2 and cooperation_rate > 0.3:
                    return Action.C
                else:
                    return Action.D
        if cooperation_rate >= threshold_rate:
            return Action.C
        else:
            return Action.D

    def _update_cooperation_stats(self, history: PlayerHistory, current_round: int) -> None:
        """
        Update cumulative cooperation statistics from all previous rounds.
        """
        if history is None or current_round == 0:
            self.cumulative_cooperators = 0
            self.total_rounds_played = 0
            return
        self.cumulative_cooperators = 0
        for round_idx in range(current_round):
            self.cumulative_cooperators += int(sum(history.opponent_actions[round_idx, :]))
        self.total_rounds_played = current_round

class Strategy_EXPLOITATIVE_464(BaseStrategy):
    """
    Unconditional Defection with Adaptive Monitoring.
    
    Exploits the asymmetric payoff structure of the Collective Risk Dilemma by always defecting.
    When others cooperate to reach the threshold m, this strategy captures the maximum payoff
    (1 + k) while contributors only get (0 + k). Monitors cooperation rates to confirm when
    defection will yield the (1 + k) payoff, but defects regardless since the asymmetry
    always favors defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        n = self.game_description.n_players
        m = self.game_description.m
        total_cooperations = np.sum(history.opponent_actions[:state.round_number, :])
        total_actions = state.round_number * n
        if total_actions > 0:
            coop_rate = total_cooperations / total_actions
        else:
            coop_rate = 0.0
        expected_cooperators = coop_rate * (n - 1)
        return Action.D

class Strategy_EXPLOITATIVE_465(BaseStrategy):
    """
    Conditional Free-Rider with Adaptive Threshold Strategy.
    
    An exploitative strategy that defects whenever possible while maintaining
    minimal cooperation only to prevent collective failure. Defects in round 1
    and the final round unconditionally, and uses probabilistic cooperation
    only when the cooperation count is exactly one below the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.n_rounds - 1:
            return Action.D
        c_prev = int(sum(history.opponent_actions[state.round_number - 1, :]))
        if c_prev >= self.m:
            return Action.D
        if c_prev == self.m - 1:
            threshold_probability = (self.k - 1.0) / self.k
            if random.random() < threshold_probability:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_466(BaseStrategy):
    """
    Threshold Parasitism: An exploitative strategy for Collective Risk Dilemmas.
    
    Core approach:
    - Always defect in round 1 (no history to exploit)
    - Always defect in final two rounds (no future consequences)
    - In middle rounds, defect to free-ride on others' cooperation
    - Exploit the coordination problem by avoiding contribution costs
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num >= self.n_rounds - 2:
            return Action.D
        if history is None or len(history.opponent_actions) == 0:
            coop_rate = 0.0
        else:
            total_cooperations = np.sum(history.opponent_actions)
            total_possible = self.n_players * (round_num + 1)
            if total_possible > 0:
                coop_rate = total_cooperations / total_possible
            else:
                coop_rate = 0.0
        threshold_likelihood = (self.m - 1) / self.n_players
        return Action.D

class Strategy_EXPLOITATIVE_467(BaseStrategy):
    """
    Adaptive Free-Riding with Threshold Detection strategy.
    
    Exploits the payoff asymmetry in the Collective Risk Dilemma by detecting
    when cooperation is likely to succeed and free-riding on others' contributions.
    Defects in first and last rounds, and conditionally in intermediate rounds based
    on observed cooperation rates.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.safety_threshold = self.m / self.n - 0.05
        self.consideration_threshold = (self.m - 1) / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        prev_round_actions = history.opponent_actions[current_round - 1, :]
        prev_coop_count = np.sum(prev_round_actions)
        prev_coop_rate = prev_coop_count / self.n
        recent_coop_trend = 0.0
        if current_round > 1:
            prev_prev_coop_count = np.sum(history.opponent_actions[current_round - 2, :])
            prev_prev_coop_rate = prev_prev_coop_count / self.n
            recent_coop_trend = prev_coop_rate - prev_prev_coop_rate
        if prev_coop_rate >= self.safety_threshold:
            return Action.D
        elif prev_coop_rate >= self.consideration_threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_468(BaseStrategy):
    """
    Adaptive Defection with Conditional Participation.
    
    Exploits the collective risk dilemma by:
    1. Always defecting in round 1 (adversarial initialization)
    2. Free-riding when threshold is already met
    3. Defecting when threshold cannot be reached
    4. Cooperating only when exactly m-1 cooperators exist and future rounds remain
    5. Always defecting in final round (endgame extraction)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        rounds_remaining = r - current_round - 1
        cooperators_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
        if rounds_remaining <= 0:
            return Action.D
        if cooperators_last_round >= m:
            return Action.D
        if cooperators_last_round == 0:
            return Action.D
        if cooperators_last_round == m - 1:
            if k > 1 and rounds_remaining > 1:
                return Action.C
            else:
                return Action.D
        if 1 <= cooperators_last_round < m - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_469(BaseStrategy):
    """
    Conditional Free-Rider with Adaptive Threshold: An exploitative strategy that
    defaults to defection while free-riding on others' cooperation, only cooperating
    when facing near-certain collective failure (desperation threshold).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        last_round_cooperators = int(sum(history.opponent_actions[round_number - 1, :]))
        rounds_remaining = self.n_rounds - round_number
        cooperators_needed = self.m - last_round_cooperators
        if last_round_cooperators < self.m:
            if rounds_remaining <= cooperators_needed:
                return Action.C
        if round_number > 1:
            recent_rounds_start = max(0, round_number - 2)
            recent_successes = 0
            for r in range(recent_rounds_start, round_number):
                if sum(history.opponent_actions[r, :]) >= self.m:
                    recent_successes += 1
            if recent_successes == 2 and round_number > 1:
                return Action.D
        if round_number > 0:
            total_opponent_cooperations = int(np.sum(history.opponent_actions[:round_number, :]))
            total_opponent_actions = (self.n_players - 1) * round_number
            if total_opponent_actions > 0:
                opponent_cooperation_rate = total_opponent_cooperations / total_opponent_actions
                expected_cooperation_rate = self.m / self.n_players
                if opponent_cooperation_rate > expected_cooperation_rate * 1.2:
                    return Action.D
                if opponent_cooperation_rate < expected_cooperation_rate * 0.8:
                    if last_round_cooperators < self.m and rounds_remaining <= max(1, cooperators_needed - 1):
                        return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_470(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD): An exploitative strategy that systematically
    defects to free-ride on others' cooperation while maximizing payoff. Defects in
    round 1 and final round unconditionally, and in middle rounds based on adaptive
    assessment of cooperation likelihood and payoff expectations.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.n_rounds - 1:
            return Action.D
        return self._middle_round_decision(history, round_num)

    def _middle_round_decision(self, history: PlayerHistory, round_num: int) -> Action:
        """
        Decision logic for middle rounds (1 to r-2).
        
        Calculate cooperation rate from history and estimate probability that
        the threshold will be met. Use payoff comparison to decide, but with
        a strong bias toward defection (exploitation).
        """
        rounds_played = round_num
        opponent_count = self.n_players - 1
        if rounds_played == 0 or opponent_count == 0:
            return Action.D
        total_opponent_cooperations = np.sum(history.opponent_actions[:rounds_played, :])
        total_observations = rounds_played * opponent_count
        if total_observations == 0:
            coop_rate = 0.0
        else:
            coop_rate = total_opponent_cooperations / total_observations
        threshold_prob = self._binomial_threshold_probability(opponent_count, coop_rate, self.m - 1)
        expected_payoff_if_defect = 1.0 + threshold_prob * self.k
        expected_payoff_if_coop = threshold_prob * self.k
        if expected_payoff_if_defect >= expected_payoff_if_coop:
            return Action.D
        else:
            return Action.D

    def _binomial_threshold_probability(self, n: int, p: float, k: int) -> float:
        """
        Estimate P(X >= k) where X ~ Binomial(n, p).
        Uses a simple approximation via normal distribution for efficiency,
        or falls back to iterative calculation for small n.
        """
        if n == 0 or p == 0.0:
            return 0.0
        if p == 1.0:
            return 1.0 if n >= k else 0.0
        if k > n:
            return 0.0
        if k <= 0:
            return 1.0
        if n <= 50:
            return self._binomial_tail_sum(n, p, k)
        mean = n * p
        variance = n * p * (1.0 - p)
        if variance < 1e-10:
            return 1.0 if mean >= k else 0.0
        std_dev = math.sqrt(variance)
        z = (k - 0.5 - mean) / std_dev
        return self._normal_tail_probability(z)

    def _binomial_tail_sum(self, n: int, p: float, k: int) -> float:
        """
        Compute P(X >= k) for X ~ Binomial(n, p) by summing probabilities.
        """
        prob = 0.0
        binom_coeff = 1.0
        term = (1.0 - p) ** n
        for i in range(n + 1):
            if i == 0:
                binom_coeff = 1.0
                term = (1.0 - p) ** n
            else:
                binom_coeff *= (n - i + 1) / i
                term = binom_coeff * p ** i * (1.0 - p) ** (n - i)
            if i >= k:
                prob += term
        return prob

    def _normal_tail_probability(self, z: float) -> float:
        """
        Approximate P(Z >= z) for standard normal distribution using error function.
        """
        if z > 6.0:
            return 0.0
        if z < -6.0:
            return 1.0
        a1 = 0.254829592
        a2 = -0.284496736
        a3 = 1.421413741
        a4 = -1.453152027
        a5 = 1.061405429
        p = 0.3275911
        sign = 1.0 if z >= 0.0 else -1.0
        z_abs = abs(z)
        t = 1.0 / (1.0 + p * z_abs)
        y = 1.0 - ((((a5 * t + a4) * t + a3) * t + a2) * t + a1) * t * math.exp(-z_abs * z_abs)
        erf_z = sign * y
        return 0.5 * (1.0 - erf_z)

class Strategy_EXPLOITATIVE_471(BaseStrategy):
    """
    Conditional Parasitism with Adaptive Defection
    
    Exploitative strategy that:
    - Defects in round 1 to probe and avoid contribution
    - Adaptively defects when threshold is met (exploiting others' success)
    - Cooperates only when cooperation count is m-1 (veto power to trigger threshold)
    - Defects in final round (no future to exploit)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        prev_round_idx = state.round_number - 1
        cooperators_prev = int(sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            cooperators_prev += 1
        threshold_met_prev = cooperators_prev >= self.game_description.m
        if threshold_met_prev:
            return Action.D
        elif cooperators_prev >= self.game_description.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_472(BaseStrategy):
    """
    Adaptive Threshold Exploitation (ATE): A strategy that maximizes payoff by exploiting
    the threshold mechanism in the Collective Risk Dilemma. Core insights:
    - Defect when threshold is already met (free-ride on others' cooperation)
    - Cooperate only when exactly m-1 others cooperated (unlock threshold for mutual gain)
    - Defect when threshold is unreachable (preserve endowment)
    - Default to defection in round 1 and when history is unavailable
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if history is None:
            return Action.D
        prev_round_idx = state.round_number - 1
        opponent_actions_prev = history.opponent_actions[prev_round_idx, :]
        cooperators_prev = int(np.sum(opponent_actions_prev))
        if cooperators_prev >= self.m:
            return Action.D
        elif cooperators_prev == self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_473(BaseStrategy):
    """
    Adaptive Threshold Exploit (ATE): An exploitative strategy that maximizes payoff by
    free-riding when cooperation threshold is met, while conditionally cooperating only
    in end-game scenarios to secure guaranteed rewards.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
        if cooperators_last_round >= self.m:
            return Action.D
        if cooperators_last_round == self.m - 1:
            rounds_remaining = self.n_rounds - current_round
            if rounds_remaining >= 2:
                return Action.D
            else:
                return Action.C
        gap = self.m - cooperators_last_round
        rounds_remaining = self.n_rounds - current_round
        if gap <= 2 and gap <= rounds_remaining:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_474(BaseStrategy):
    """
    Adaptive Threshold Exploitation (ATE) Strategy for Collective Risk Dilemma.
    
    Core philosophy: Exploit the asymmetry in payoffs by free-riding on others'
    cooperation. Defectors earn 1 point more than cooperators when the threshold
    is met. This strategy always defects, as it is the dominant exploitation approach.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        current_round = state.round_number
        rounds_remaining = self.n_rounds - current_round - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if rounds_remaining == 0:
            return Action.D
        if cooperators_last_round >= self.m:
            return Action.D
        if cooperators_last_round >= self.m - 1:
            return Action.D
        if cooperators_last_round >= self.m - 2 and rounds_remaining > 2:
            return Action.D
        if cooperators_last_round < self.m - 2 and rounds_remaining > 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_475(BaseStrategy):
    """
    Adaptive Threshold Parasitism: Exploitative strategy that free-rides on others'
    cooperation while maintaining strategic ambiguity through selective defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold_high = (self.m - 1) / (self.n - 1) + 0.1
        self.threshold_mid = (self.m - 1) / (self.n - 1) - 0.15

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        others_c_count = np.sum(history.opponent_actions[:current_round, :])
        total_other_actions = current_round * (self.n - 1)
        if total_other_actions == 0:
            return Action.D
        cooperation_rate = others_c_count / total_other_actions
        if cooperation_rate >= self.threshold_high:
            return Action.D
        if cooperation_rate >= self.threshold_mid:
            defection_prob = cooperation_rate
            if random.random() < defection_prob:
                return Action.D
            else:
                return Action.C
        if current_round > self.r * 0.7:
            return Action.D
        if cooperation_rate < self.threshold_mid - 0.25:
            return Action.D
        if random.random() < 0.2:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_476(BaseStrategy):
    """
    Adaptive Threshold Exploitation (ATE) Strategy for Collective Risk Dilemma.
    
    Maximizes personal payoff by exploiting cooperative opponents while minimizing
    contributions. Uses threshold parasitism: free-rides when threshold is met,
    cooperates only when strategically necessary to unlock rewards.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.total_cooperators_history = 0
        self.rounds_completed = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if history is not None:
            total_opponent_cooperators = 0
            for round_idx in range(current_round):
                round_cooperators = np.sum(history.opponent_actions[round_idx, :])
                total_opponent_cooperators += round_cooperators
            total_opponent_slots = (self.n - 1) * current_round
            if total_opponent_slots > 0:
                coop_rate = total_opponent_cooperators / total_opponent_slots
            else:
                coop_rate = 0.0
        else:
            coop_rate = 0.0
        if current_round == self.r - 1:
            return Action.D
        if history is not None:
            prev_cooperators = np.sum(history.opponent_actions[current_round - 1, :])
        else:
            prev_cooperators = 0
        if coop_rate > 0.6:
            defect_probability = 1.0
        elif coop_rate >= 0.3:
            defect_probability = 0.8
        else:
            defect_probability = 1.0
        if prev_cooperators >= self.m:
            if random.random() < defect_probability:
                return Action.D
            else:
                return Action.D
        elif prev_cooperators == self.m - 1:
            return Action.D
        else:
            rounds_remaining = self.r - current_round
            if rounds_remaining > 1 and coop_rate > 0.5:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_477(BaseStrategy):
    """
    Adaptive Threshold Harvesting: An exploitative strategy that defects when the
    cooperation threshold is likely to be met without the player's contribution,
    and only cooperates conditionally when necessary to secure the reward.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        round_t = state.round_number
        if round_t == 0:
            if m <= math.ceil(n / 2):
                return Action.C
            else:
                return Action.D
        if round_t == r - 1:
            return Action.D
        c_prev = int(sum(history.opponent_actions[round_t - 1, :]))
        if c_prev >= m:
            return Action.D
        expected_coop_rate = self._estimate_cooperation_rate(history, round_t)
        expected_cooperators = expected_coop_rate * n
        if round_t >= 2:
            c_prev_prev = int(sum(history.opponent_actions[round_t - 2, :]))
            if c_prev_prev - c_prev > n / 3:
                return Action.D
        if c_prev + expected_cooperators >= m:
            return Action.D
        elif c_prev + math.ceil(m / 2) >= m:
            return Action.C
        else:
            return Action.D

    def _estimate_cooperation_rate(self, history: PlayerHistory, round_t: int) -> float:
        """
        Estimate the cooperation rate from observed history.
        Returns a value between 0 and 1.
        """
        if round_t <= 1:
            return 0.5
        total_cooperators = 0
        for r in range(round_t - 1):
            total_cooperators += sum(history.opponent_actions[r, :])
        total_slots = (round_t - 1) * self.game_description.n_players
        if total_slots == 0:
            return 0.5
        coop_rate = total_cooperators / total_slots
        if round_t <= 3:
            return coop_rate
        else:
            recent_rounds = min(2, round_t - 1)
            recent_cooperators = sum((sum(history.opponent_actions[r, :]) for r in range(round_t - recent_rounds, round_t)))
            recent_rate = recent_cooperators / (recent_rounds * self.game_description.n_players)
            blended_rate = 0.6 * recent_rate + 0.4 * coop_rate
            return blended_rate

class Strategy_EXPLOITATIVE_478(BaseStrategy):
    """
    Adaptive Parasitism: Exploitative strategy that free-rides on threshold achievement.
    
    Core approach:
    - Round 1: DEFECT (no history)
    - Rounds 2 to r-1: DEFECT by default, occasionally COOPERATE only when threshold is nearly met
    - Round r: ALWAYS DEFECT (final round exploitation)
    
    Maximizes payoff by exploiting coordination problems and avoiding wasted contributions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        previous_round_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        if previous_round_cooperators >= self.m:
            return Action.D
        elif previous_round_cooperators == self.m - 1:
            p_switch = min(0.2, 1.0 / self.k)
            if random.random() < p_switch:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_479(BaseStrategy):
    """
    Adaptive Threshold Parasite: An exploitative strategy that free-rides on others' 
    cooperation while maintaining plausible deniability. Defaults to defection and only 
    cooperates when necessary to unlock future threshold payoffs or in end-game salvage scenarios.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.total_threshold_successes = 0
        self.buffer_tolerance = 0.15

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        prev_round_idx = current_round - 1
        prev_cooperators = int(sum(history.opponent_actions[prev_round_idx, :]))
        threshold_met_prev = prev_cooperators >= m
        coop_rate_prev = prev_cooperators / n if n > 0 else 0
        if threshold_met_prev:
            self.total_threshold_successes += 1
        if current_round == r - 1:
            if self.total_threshold_successes > 0:
                return Action.D
            elif prev_cooperators == m - 1:
                return Action.C
            else:
                return Action.D
        if threshold_met_prev:
            return Action.D
        threshold_rate = m / n + self.buffer_tolerance
        if coop_rate_prev >= threshold_rate:
            return Action.D
        rounds_remaining = r - current_round
        if rounds_remaining > 2 and coop_rate_prev < m / n - 0.2:
            current_cooperators = prev_cooperators
            denominator = n - current_cooperators
            if denominator > 0:
                numerator = m - current_cooperators - 1
                coop_prob = max(0, min(1, numerator / denominator))
                if random.random() < coop_prob:
                    return Action.C
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_481(BaseStrategy):
    """
    Adaptive Threshold Parasitism - An exploitative strategy that free-rides on others' cooperation.
    
    Core approach:
    - Always defect to maximize private gains
    - Exploit the threshold mechanism by relying on others to meet the cooperation requirement
    - In round 1: Defect to gather information while gaining maximum private payoff
    - In rounds 2 to r-1: Always defect, exploiting whether threshold is met or not
    - In final round: Defect to maximize immediate payoff with no future consequences
    
    This strategy dominates because defection is a dominant strategy when others can meet
    the threshold without your contribution.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_482(BaseStrategy):
    """
    Adaptive Threshold Exploitation Strategy for Collective Risk Dilemma.
    
    Core approach:
    - Round 1: DEFECT (gather information, establish baseline)
    - Final round: DEFECT (no continuation value)
    - Middle rounds: DEFECT based on estimated cooperation likelihood
    
    This strategy exploits the threshold mechanism by:
    1. Free-riding when threshold is likely to be met by others
    2. Defecting when threshold is unachievable
    3. Never cooperating, as cooperation never provides advantage
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.n_rounds - 1:
            return Action.D
        lookback = min(3, round_num)
        recent_opponent_actions = history.opponent_actions[-lookback:, :]
        total_c_actions = np.sum(recent_opponent_actions)
        total_opponent_actions = recent_opponent_actions.size
        if total_opponent_actions == 0:
            cooperation_rate = 0.0
        else:
            cooperation_rate = float(total_c_actions) / float(total_opponent_actions)
        expected_cooperators = cooperation_rate * self.n_players
        if expected_cooperators >= self.m - 0.5:
            return Action.D
        elif expected_cooperators > self.m - 2:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_483(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Free-Riding with Conditional Cooperation
    
    Maximizes personal payoff by minimally committing to cooperation, exploiting
    cooperators when threshold is met, and adapting defection timing based on
    observed cooperation levels.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num >= self.n_rounds - 2:
            return Action.D
        c_hist = int(np.sum(history.opponent_actions[round_num - 1, :]))
        if c_hist >= self.m:
            return Action.D
        if c_hist >= self.m - 1:
            return Action.D
        deficit = self.m - c_hist
        cooperation_demand = deficit / max(1, self.n_players - 1)
        if cooperation_demand <= 0.3:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_484(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Free-Riding with Threshold Exploitation
    
    Core philosophy: Exploit structural asymmetry where defectors earn strictly higher
    rewards than cooperators when threshold is met (1 + k > 0 + k). Cooperate only when
    necessary to trigger the threshold or when defection becomes unprofitable.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        m = self.game_description.m
        k = self.game_description.k
        r = self.game_description.n_rounds
        if round_num == 0:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[round_num - 1, :]))
        self.cooperation_history.append(cooperators_last_round)
        if round_num == r - 1:
            return Action.D
        if cooperators_last_round >= m:
            return Action.D
        if cooperators_last_round == m - 1:
            return Action.C
        if cooperators_last_round < m - 1:
            rounds_remaining = r - round_num
            expected_cooperators = self._predict_future_cooperators(rounds_remaining)
            if expected_cooperators < m:
                return Action.D
            else:
                return Action.D
        return Action.D

    def _predict_future_cooperators(self, rounds_remaining: int) -> float:
        """
        Predict expected number of cooperators in future rounds based on trend.
        Uses linear regression on cooperation history if sufficient data exists.
        """
        if len(self.cooperation_history) == 0:
            return self.game_description.m
        if len(self.cooperation_history) == 1:
            return float(self.cooperation_history[-1])
        window = min(3, len(self.cooperation_history))
        recent_history = self.cooperation_history[-window:]
        x = np.array(range(len(recent_history)), dtype=float)
        y = np.array(recent_history, dtype=float)
        x_mean = np.mean(x)
        y_mean = np.mean(y)
        numerator = np.sum((x - x_mean) * (y - y_mean))
        denominator = np.sum((x - x_mean) ** 2)
        if denominator == 0:
            slope = 0.0
        else:
            slope = numerator / denominator
        intercept = y_mean - slope * x_mean
        projected_coop = intercept + slope * (len(recent_history) + rounds_remaining)
        projected_coop = max(0, min(float(self.game_description.n_players), projected_coop))
        return projected_coop

class Strategy_EXPLOITATIVE_485(BaseStrategy):
    """
    Threshold Parasitism: An exploitative strategy that defects unconditionally,
    free-riding on others' cooperation to reach the threshold m while avoiding
    the cost of contribution. Exploits the 1-unit asymmetry between free-riders
    (payoff 1+k) and cooperators (payoff k).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[state.round_number - 1, :]))
        return Action.D

class Strategy_EXPLOITATIVE_486(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Free-Riding with Dynamic Threshold Monitoring
    
    Exploits the threshold mechanism by free-riding on others' cooperation while
    minimizing own contribution. Adapts defection timing based on observed cooperation
    patterns, forcing threshold achievement only when strategically necessary.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.r - 1:
            return self._final_round_decision(history)
        return self._middle_round_decision(round_num, history)

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """
        Final round: Extract maximum value with zero future penalty.
        If accumulated cooperation suggests threshold reliability, free-ride.
        Otherwise, cooperate as last-round insurance.
        """
        cooperators_per_round = np.sum(history.opponent_actions, axis=1)
        avg_cooperators = np.mean(cooperators_per_round)
        if avg_cooperators >= self.m:
            return Action.D
        else:
            return Action.C

    def _middle_round_decision(self, round_num: int, history: PlayerHistory) -> Action:
        """
        Middle rounds: Conditional free-riding based on threshold proximity.
        """
        prev_cooperators = np.sum(history.opponent_actions[round_num - 1, :])
        deficit = self.m - prev_cooperators
        if prev_cooperators >= self.m - 1:
            return Action.D
        if deficit == 1:
            return Action.C
        if deficit >= 2:
            if round_num <= self.r / 2:
                return Action.D
            cooperation_ratio = prev_cooperators / self.n
            threshold_ratio = self.m / self.n
            if cooperation_ratio < threshold_ratio * 0.8:
                return Action.D
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_487(BaseStrategy):
    """
    Adaptive Threshold Exploitation (ATE) Strategy
    
    Exploits the payoff asymmetry in the Collective Risk Dilemma by:
    1. Defecting in information gathering phase (rounds 0-2)
    2. Monitoring opponent cooperation rates with exponential smoothing
    3. Consistently defecting in exploitation phase to free-ride on others' cooperation
    4. Defecting unconditionally in endgame rounds
    
    Core insight: Defectors earn 1+k when threshold is met (free-riding on cooperators),
    while cooperators earn only k. This strategy maximizes payoff by always capturing
    the free-rider advantage.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.p_coop_smoothed = 0.5
        self.cooperation_history = []
        self.alpha = 0.6

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        prev_round_idx = state.round_number - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        self.cooperation_history.append(cooperators_last_round)
        opponents_count = self.game_description.n_players - 1
        if opponents_count > 0:
            current_coop_rate = cooperators_last_round / opponents_count
            self.p_coop_smoothed = self.alpha * current_coop_rate + (1 - self.alpha) * self.p_coop_smoothed
        m = self.game_description.m
        r = self.game_description.n_rounds
        if state.round_number <= 2:
            return Action.D
        if state.round_number < r - 1:
            if cooperators_last_round >= m:
                pass
            elif cooperators_last_round == m - 1:
                if self.p_coop_smoothed > 0.35:
                    pass
            elif cooperators_last_round >= m / 2:
                pass
            else:
                pass
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_488(BaseStrategy):
    """
    Exploitative strategy: Conditional free-riding with adaptive defection.
    
    Defaults to defection while opportunistically cooperating only when necessary
    to reach the threshold m, thereby free-riding on others' contributions.
    Tracks per-player cooperation rates to identify reliable cooperators and
    adjusts behavior across game phases (early, mid, end game).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.opponent_cooperation_counts = np.zeros(self.n_players - 1, dtype=np.int64)
        self.opponent_round_counts = np.zeros(self.n_players - 1, dtype=np.int64)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        self._update_opponent_cooperation(history)
        early_game_end = math.floor(self.n_rounds / 2)
        end_game_start = self.n_rounds - 2
        if round_num <= early_game_end:
            return Action.D
        if round_num >= end_game_start:
            return Action.D
        return self._mid_game_decision(history)

    def _update_opponent_cooperation(self, history: PlayerHistory) -> None:
        """Update per-opponent cooperation counts from history."""
        n_rounds_observed = history.opponent_actions.shape[0]
        for round_idx in range(n_rounds_observed):
            for opp_idx in range(self.n_players - 1):
                if history.opponent_actions[round_idx, opp_idx]:
                    self.opponent_cooperation_counts[opp_idx] += 1
                self.opponent_round_counts[opp_idx] += 1

    def _get_cooperation_rates(self) -> tuple[float, list[float]]:
        """
        Return (average_cooperation_rate, per_opponent_rates).
        Handles division by zero gracefully.
        """
        total_cooperation = float(np.sum(self.opponent_cooperation_counts))
        total_observations = float(np.sum(self.opponent_round_counts))
        if total_observations > 0:
            avg_rate = total_cooperation / total_observations
        else:
            avg_rate = 0.0
        per_opponent_rates = []
        for opp_idx in range(self.n_players - 1):
            if self.opponent_round_counts[opp_idx] > 0:
                rate = self.opponent_cooperation_counts[opp_idx] / self.opponent_round_counts[opp_idx]
            else:
                rate = 0.0
            per_opponent_rates.append(rate)
        return (avg_rate, per_opponent_rates)

    def _classify_opponents(self, per_opponent_rates: list[float]) -> tuple[int, int, int]:
        """
        Classify opponents into categories based on cooperation frequency.
        Returns (reliable_count, conditional_count, defector_count).
        """
        reliable = 0
        conditional = 0
        defectors = 0
        for rate in per_opponent_rates:
            if rate >= 0.7:
                reliable += 1
            elif rate >= 0.3:
                conditional += 1
            else:
                defectors += 1
        return (reliable, conditional, defectors)

    def _mid_game_decision(self, history: PlayerHistory) -> Action:
        """
        Mid-game strategy: defect if threshold is met, otherwise cooperate
        with probability proportional to the deficit.
        """
        avg_cooperation_rate, per_opponent_rates = self._get_cooperation_rates()
        estimated_cooperators = avg_cooperation_rate * (self.n_players - 1)
        if estimated_cooperators >= self.m:
            return Action.D
        deficit = self.m - estimated_cooperators
        p_cooperate = deficit / (self.n_players - 1) if self.n_players > 1 else 0.0
        p_cooperate = max(0.0, min(1.0, p_cooperate))
        if p_cooperate > 0.8:
            return Action.C
        elif p_cooperate < 0.2:
            return Action.D
        if random.random() < p_cooperate:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_489(BaseStrategy):
    """
    Adaptive Threshold Exploitation (ATE) strategy for Collective Risk Dilemma.
    
    Exploits the asymmetry between cooperators and defectors by identifying when
    cooperation becomes inevitable, then defecting to capture maximum private value
    while benefiting from others' contributions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.critical_threshold = self._compute_critical_threshold()

    def _compute_critical_threshold(self) -> float:
        """Compute the critical threshold based on game parameters."""
        threshold = 0.75
        if self.n_players <= 4:
            threshold = 0.65
        if self.m > 0.75 * self.n_players:
            threshold = 0.85
        if self.k > 3:
            threshold = 0.7
        return threshold

    def _estimate_m_will_be_met(self, history: PlayerHistory) -> float:
        """
        Estimate the probability that m cooperators will be achieved in next round.
        Returns a confidence value between 0 and 1.
        """
        current_round = len(history.my_actions) - 1
        observed_cooperators = 0
        for opponent_idx in range(self.n_players - 1):
            cooperations = np.sum(history.opponent_actions[:current_round + 1, opponent_idx])
            total_rounds_observed = current_round + 1
            cooperation_rate = cooperations / total_rounds_observed if total_rounds_observed > 0 else 0
            if cooperation_rate >= 0.5:
                observed_cooperators += 1
        minimum_cooperators_next_round = observed_cooperators * 0.9
        if minimum_cooperators_next_round >= self.m:
            return 0.95
        elif minimum_cooperators_next_round >= self.m - 1:
            return 0.85
        elif minimum_cooperators_next_round >= self.m - 2:
            return 0.7
        else:
            return 0.4

    def _get_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate the observed cooperation rate across all opponents."""
        if len(history.opponent_actions) == 0:
            return 0.0
        total_actions = history.opponent_actions.size
        if total_actions == 0:
            return 0.0
        cooperations = np.sum(history.opponent_actions)
        return float(cooperations) / float(total_actions)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if history is None:
            return Action.D
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        if round_number >= self.n_rounds - 2:
            cooperation_rate = self._get_cooperation_rate(history)
            threshold_ratio = self.m / self.n_players if self.n_players > 0 else 0
            if cooperation_rate > threshold_ratio:
                return Action.D
            if round_number == self.n_rounds - 1:
                return Action.D
        threshold_reliability = self._estimate_m_will_be_met(history)
        if threshold_reliability > self.critical_threshold:
            return Action.D
        cooperation_rate = self._get_cooperation_rate(history)
        threshold_ratio = self.m / self.n_players if self.n_players > 0 else 0
        if cooperation_rate < threshold_ratio * 0.8:
            return Action.D
        return Action.C

class Strategy_EXPLOITATIVE_490(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Defection strategy.
    
    Exploits others' cooperation through strategic defection while maintaining
    plausible deniability through occasional probabilistic cooperation.
    Always defects in first and final rounds, free-rides when threshold is met,
    and cooperates conditionally in middle rounds based on observed cooperation patterns.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        rounds_remaining = self.n_rounds - current_round - 1
        cooperators_prev = int(sum(history.opponent_actions[current_round - 1, :]))
        if cooperators_prev >= self.m:
            return Action.D
        avg_cooperators = self._compute_rolling_average(history, current_round)
        if avg_cooperators < self.m - 1 and rounds_remaining >= 2:
            prob_cooperate = (self.m - avg_cooperators) / self.n_players
            prob_cooperate = max(0.0, min(1.0, prob_cooperate))
            if random.random() < prob_cooperate:
                return Action.C
            else:
                return Action.D
        return Action.D

    def _compute_rolling_average(self, history: PlayerHistory, current_round: int) -> float:
        """
        Compute rolling average of cooperators from last 3 rounds.
        Falls back to available rounds if fewer than 3 exist.
        """
        lookback_window = min(3, current_round)
        if lookback_window == 0:
            return 0.0
        total_cooperators = 0.0
        for i in range(current_round - lookback_window, current_round):
            if i >= 0:
                cooperators_in_round = sum(history.opponent_actions[i, :])
                total_cooperators += cooperators_in_round
        avg = total_cooperators / lookback_window
        return avg

class Strategy_EXPLOITATIVE_491(BaseStrategy):
    """
    Adaptive Threshold Exploitation (ATE) Strategy for Collective Risk Dilemma.
    
    Exploits asymmetry in payoff structure by free-riding on others' cooperation
    while minimizing personal contribution. Defects strategically except when
    cooperation is needed to maintain exploitation conditions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            cooperators_last = int(sum(history.opponent_actions[current_round - 1, :]))
            if cooperators_last >= self.m - 1:
                return Action.D
            elif cooperators_last == self.m - 2:
                return Action.C if random.random() < 0.2 else Action.D
            else:
                return Action.D
        cooperators_last = int(sum(history.opponent_actions[current_round - 1, :]))
        if self.n - 1 > 0:
            coop_rate = cooperators_last / (self.n - 1)
        else:
            coop_rate = 0.0
        threshold_for_free_ride = (self.m - 1) / self.n
        threshold_for_critical_mass = (self.m - 2) / self.n
        if coop_rate >= threshold_for_free_ride:
            return Action.D
        elif abs(coop_rate - threshold_for_critical_mass) < 0.15:
            p_cooperate = min(0.3, 1.0 / max(1, self.n - self.m))
            if self.k > 5:
                p_cooperate = min(0.4, 1.0 / max(1, self.n - self.m))
            return Action.C if random.random() < p_cooperate else Action.D
        elif coop_rate < threshold_for_critical_mass:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_492(BaseStrategy):
    """
    Exploitative strategy: Conditional free-riding with adaptive threshold.
    
    Minimizes personal contribution while maximizing benefit capture by:
    - Defecting in round 1 to probe behavior
    - Defecting in final round (no future consequences)
    - Free-riding when threshold is already met (â‰¥ m cooperators)
    - Defecting when (m-1) cooperators observed (highest individual payoff)
    - Conditionally cooperating only when few rounds remain and deficit is small
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
        if cooperators_last_round >= self.m:
            return Action.D
        if cooperators_last_round == self.m - 1:
            return Action.D
        if cooperators_last_round < self.m - 1:
            deficit = self.m - cooperators_last_round
            rounds_remaining = self.n_rounds - current_round
            threshold = math.ceil(rounds_remaining / 3)
            if deficit <= threshold:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_493(BaseStrategy):
    """
    Exploitative Strategy: Conditional Defection with Selective Parasitism
    
    Exploits the threshold mechanism by free-riding on others' cooperation.
    Cooperates only when strategically necessary to prevent total defection cascades.
    Maximizes personal gain by minimizing personal contribution while capturing collective rewards.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        prev_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        if prev_cooperators >= self.m:
            return Action.D
        if prev_cooperators == self.m - 1:
            return Action.D
        if prev_cooperators < self.m - 1:
            threshold_deficit = self.m - prev_cooperators
            remaining_rounds = self.n_rounds - current_round
            max_possible_future_cooperators = remaining_rounds * (self.n_players - 1)
            if threshold_deficit > max_possible_future_cooperators:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_494(BaseStrategy):
    """
    Adaptive Free-Riding with Conditional Defection strategy for Collective Risk Dilemma.
    
    Exploits the threshold mechanism by free-riding on others' cooperation while maintaining
    flexibility to adapt to observed cooperation rates. Defects when threshold will be met anyway,
    and only cooperates when necessary to avoid collective failure.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        cooperators_in_prev_round = int(np.sum(history.opponent_actions[-1, :]))
        cooperation_rate = cooperators_in_prev_round / (self.n - 1)
        threshold_trigger = (self.m - 1) / (self.n - 1)
        danger_zone = (self.m - 2) / (self.n - 1) if self.m >= 2 else 0.0
        if current_round == self.r - 1:
            if cooperation_rate >= threshold_trigger:
                return Action.D
            else:
                return Action.C
        if cooperation_rate >= threshold_trigger:
            return Action.D
        elif cooperation_rate >= danger_zone:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_495(BaseStrategy):
    """
    Adaptive Free-Riding with Threshold Exploitation.
    
    Monitors cooperation rates and exploits cooperative opponents by free-riding
    when the threshold is reliably met, while conditionally cooperating when
    cooperation is sparse. Maximizes relative payoff through strategic defection
    and minimal cooperation signaling.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.reconnaissance_end = math.ceil(self.r / 3)
        self.exploitation_end = math.ceil(2 * self.r / 3)
        self.mode = 'RECONNAISSANCE'
        self.avg_coop_rate = 0.0
        self.recent_coop_counts = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round <= self.reconnaissance_end:
            self._update_cooperation_stats(history, current_round)
            if current_round == self.reconnaissance_end:
                if self.avg_coop_rate >= self.m / self.n:
                    self.mode = 'EXPLOITATION'
                else:
                    self.mode = 'CONDITIONAL'
            return Action.D
        elif current_round <= self.exploitation_end:
            self._update_cooperation_stats(history, current_round)
            if self._check_cooperation_collapse(history, current_round):
                return Action.C
            if self.mode == 'EXPLOITATION':
                if self.avg_coop_rate < self.m / self.n:
                    self.mode = 'CONDITIONAL'
                    p_coop = self.m / self.n
                    return Action.C if random.random() < p_coop else Action.D
                return Action.D
            elif self.avg_coop_rate >= self.m / self.n:
                self.mode = 'EXPLOITATION'
                return Action.D
            else:
                p_coop = self.m / self.n
                return Action.C if random.random() < p_coop else Action.D
        else:
            self._update_cooperation_stats(history, current_round)
            return Action.D

    def _update_cooperation_stats(self, history: PlayerHistory, current_round: int) -> None:
        """
        Calculate empirical cooperation rate from observed history.
        Track recent cooperation counts for damage control detection.
        """
        if current_round == 0:
            return
        total_cooperators = np.sum(history.opponent_actions[:current_round, :])
        total_observations = current_round * self.n
        if total_observations > 0:
            self.avg_coop_rate = total_cooperators / total_observations
        else:
            self.avg_coop_rate = 0.0
        if current_round > 0:
            recent_coop_count = int(np.sum(history.opponent_actions[current_round - 1, :]))
            self.recent_coop_counts.append(recent_coop_count)
            if len(self.recent_coop_counts) > 2:
                self.recent_coop_counts.pop(0)

    def _check_cooperation_collapse(self, history: PlayerHistory, current_round: int) -> bool:
        """
        Detect if cooperation has collapsed (fewer than m-1 cooperators in 2+ consecutive rounds).
        Return True if damage control is needed (cooperate this round).
        """
        if len(self.recent_coop_counts) < 2:
            return False
        collapse_threshold = self.m - 1
        if self.recent_coop_counts[-1] < collapse_threshold and self.recent_coop_counts[-2] < collapse_threshold:
            return True
        return False

class Strategy_EXPLOITATIVE_496(BaseStrategy):
    """
    Exploitative strategy: "Calculated Defection with Conditional Cooperation"
    
    Maximizes personal payoff by exploiting the threshold mechanism. Defects by default,
    occasionally cooperates probabilistically in middle rounds to keep the cooperative pool
    alive for exploitation, and always defects in the last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        c_prev = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if c_prev >= self.m:
            return Action.D
        if c_prev == self.m - 1:
            return Action.D
        if c_prev < self.m - 1:
            gap = self.m - c_prev
            denominator = self.n_players - 1
            if denominator <= 0:
                return Action.D
            p = min(0.5, gap / denominator)
            if random.random() < p:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_497(BaseStrategy):
    """
    Adaptive Parasitism: An exploitative strategy that defects strategically to free-ride
    on others' cooperation while minimizing own contribution. Exploits the threshold
    mechanism by avoiding cooperation costs and forcing coordination failures.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        prev_round_idx = current_round - 1
        cooperators_prev = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        threshold_met_prev = cooperators_prev >= self.m
        if threshold_met_prev:
            return Action.D
        cooperators_needed = self.m - cooperators_prev
        rounds_remaining = self.n_rounds - current_round
        if cooperators_needed <= 1:
            return Action.D
        if rounds_remaining > 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_498(BaseStrategy):
    """
    Adaptive Threshold Parasitism: An exploitative strategy for collective risk dilemmas.
    
    Exploits the coordination problem by defecting when others are likely to cooperate,
    capturing the full benefit (1 + k) while minimizing contribution costs.
    Uses adaptive thresholding in middle rounds and pure defection in first/last rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        cooperators_prev = int(np.sum(history.opponent_actions[current_round - 1, :]))
        coop_rate_prev = cooperators_prev / (self.n - 1)
        threshold_safe = self.m / self.n
        threshold_minimum = (self.m - 1) / self.n
        if threshold_safe <= 0:
            threshold_safe = 1.0 / self.n
        if coop_rate_prev >= threshold_safe:
            return Action.D
        elif coop_rate_prev >= threshold_minimum:
            p_defect = coop_rate_prev / threshold_safe
            if random.random() < p_defect:
                return Action.D
            else:
                return Action.C
        else:
            return Action.C

class Strategy_EXPLOITATIVE_499(BaseStrategy):
    """
    Adaptive Defection with Opportunistic Exploitation strategy for Collective Risk Dilemma.
    
    Maximizes personal payoff by exploiting the cooperation threshold mechanism:
    - Defects by default to free-ride on others' cooperation
    - Monitors cooperation rates and exploits when threshold is met
    - Maintains defection in late rounds where future punishment is impossible
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = []
        self.my_actions = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        recent_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        if history.my_actions[current_round - 1]:
            recent_cooperators += 1
        self.cooperation_history.append(recent_cooperators)
        rounds_left = self.game_description.n_rounds - current_round
        if rounds_left == 0:
            return Action.D
        if rounds_left <= 1:
            return Action.D
        if recent_cooperators >= self.game_description.m:
            return Action.D
        if recent_cooperators == self.game_description.m - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_500(BaseStrategy):
    """
    Conditional Free-Riding with Adaptive Thresholding Strategy.
    
    Exploits asymmetry between cooperators and defectors by:
    - Round 1: Always defect to gather information
    - Rounds 2 to r-1: Defect by default, only cooperate if we are exactly pivotal (C_prev = m-1) and k is sufficiently high
    - Final round: Always defect (no future consequences)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperators_prev = int(np.sum(history.opponent_actions[current_round - 1, :]))
        if self.m == 1:
            return Action.D
        if self.n_players == 2 and self.m == 2:
            return Action.D
        success_threshold_met = cooperators_prev >= self.m
        if success_threshold_met:
            return Action.D
        elif cooperators_prev == self.m - 1:
            if self.k > 1.5:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_501(BaseStrategy):
    """
    Adaptive Threshold Exploitation: A predatory strategy that exploits the asymmetry
    between cooperators and defectors in the Collective Risk Dilemma.
    
    Core approach:
    - Phase 1 (rounds 0 to min(2, r-2)): DEFECT to gather information
    - Phase 2 (rounds min(3, r-1) to r-2): Exploit based on observed cooperation rate
    - Phase 3 (last round): DEFECT (end-game dominance)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round < min(3, self.n_rounds - 1):
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        return self._phase2_decision(state, history)

    def _phase2_decision(self, state: GameState, history: PlayerHistory) -> Action:
        """
        Implement Phase 2 exploitation logic based on observed cooperation patterns.
        """
        current_round = state.round_number
        rounds_remaining = self.n_rounds - current_round
        coop_rate = self._calculate_cooperation_rate(history, current_round)
        expected_cooperators = coop_rate * (self.n_players - 1)
        deficit = self.m - expected_cooperators
        trend_slope = self._calculate_trend_slope(current_round)
        if deficit <= 0.5:
            return Action.D
        elif deficit <= 1.5:
            if random.random() < 0.7:
                return Action.D
            else:
                return Action.C
        elif trend_slope > 0.05 and rounds_remaining > 2:
            return Action.D
        else:
            return Action.C

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the observed cooperation rate among opponents up to the current round.
        Returns cooperation rate in [0, 1].
        """
        if current_round == 0:
            return 0.5
        total_cooperations = 0
        total_observations = 0
        for round_idx in range(current_round):
            cooperators_in_round = np.sum(history.opponent_actions[round_idx, :])
            total_cooperations += cooperators_in_round
            total_observations += self.n_players - 1
        if total_observations == 0:
            return 0.5
        coop_rate = total_cooperations / total_observations
        return coop_rate

    def _calculate_trend_slope(self, current_round: int) -> float:
        """
        Calculate the trend slope of cooperation rate over recent rounds.
        Returns the change in cooperation rate per round.
        """
        if current_round < 2:
            return 0.0
        lookback = min(3, current_round)
        cooperation_rates = []
        for round_idx in range(current_round - lookback, current_round):
            if round_idx < 0:
                continue
        return 0.0

class Strategy_EXPLOITATIVE_502(BaseStrategy):
    """
    Threshold Vulture: An exploitative strategy that free-rides on others' cooperation
    while strategically cooperating only when being the "swing vote" to reach the threshold.
    
    Core logic:
    - Round 1: Defect (establish non-cooperative baseline)
    - Final round: Defect (no future consequences)
    - Middle rounds:
      * If cooperators >= m: Defect (threshold met, free-ride)
      * If cooperators == m-1: Cooperate (swing vote, minimal cost for reward)
      * If cooperators < m-1: Defect (threshold unreachable)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        last_round_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        if last_round_cooperators >= self.m:
            return Action.D
        if last_round_cooperators == self.m - 1:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_503(BaseStrategy):
    """
    Adaptive Threshold Exploitation (ATE) Strategy
    
    Exploits the asymmetry in payoff structure by systematically defecting to capture
    the reward (k) without contributing the endowment cost. Monitors cooperation rates
    and defects whenever the threshold is met or when cooperation is insufficient.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        previous_round_index = state.round_number - 1
        cooperators_in_previous_round = int(np.sum(history.opponent_actions[previous_round_index, :]))
        if history.my_actions[previous_round_index]:
            cooperators_in_previous_round += 1
        n = self.game_description.n_players
        m = self.game_description.m
        coop_rate = cooperators_in_previous_round / n
        threshold_rate = m / n
        if coop_rate >= threshold_rate:
            return Action.D
        elif coop_rate > 0:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_504(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD): An exploitative strategy that systematically
    free-rides on others' cooperation in the Collective Risk Dilemma.
    
    Core logic:
    - Always defect to capture value created by cooperators (1 + k payoff)
    - Avoid wasting endowment when threshold cannot be met (payoff of 1)
    - Deterministic defection prevents exploitation of this strategy itself
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_505(BaseStrategy):
    """
    Adaptive Threshold Parasitism: An exploitative strategy that free-rides on cooperation
    when the threshold will be met, defects when cooperation is futile, and only cooperates
    when it is the marginal (decisive) player. Adapts exploitation based on observed
    cooperation rates of opponents.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        expected_other_cooperators = self._estimate_expected_cooperators(history, current_round)
        if expected_other_cooperators >= self.m:
            return Action.D
        elif expected_other_cooperators < self.m - 1:
            return Action.D
        else:
            return Action.C

    def _estimate_expected_cooperators(self, history: PlayerHistory, current_round: int) -> float:
        """
        Estimate the expected number of cooperators among opponents in the next round
        based on observed cooperation rates.
        
        Uses conservative approach for early rounds with limited data.
        """
        rounds_observed = current_round
        if rounds_observed < 2:
            cooperation_estimate = 0.5
        else:
            total_cooperations = np.sum(history.opponent_actions[:rounds_observed, :])
            total_observations = rounds_observed * (self.n - 1)
            if total_observations == 0:
                cooperation_estimate = 0.5
            else:
                cooperation_estimate = total_cooperations / total_observations
            if rounds_observed >= 3:
                recent_rates = []
                for r in range(max(0, rounds_observed - 3), rounds_observed):
                    round_cooperations = np.sum(history.opponent_actions[r, :])
                    recent_rates.append(round_cooperations / (self.n - 1))
                if len(recent_rates) > 1:
                    volatility = np.std(recent_rates)
                    if volatility > 0.3:
                        cooperation_estimate = max(0, cooperation_estimate - 0.1)
        expected_other_cooperators = cooperation_estimate * (self.n - 1)
        if self.m >= self.n - 1:
            expected_other_cooperators = max(self.m, expected_other_cooperators)
        return expected_other_cooperators

class Strategy_EXPLOITATIVE_506(BaseStrategy):
    """
    Exploitative Strategy: "Conditional Free-Rider with Adaptive Defection"
    
    Core approach: Always defect to maximize personal payoff while exploiting
    others' cooperation. Capture the reward k whenever threshold m is met by
    others' contributions, while minimizing personal cost.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.n = game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_507(BaseStrategy):
    """
    Adaptive Free-Riding with Threshold Exploitation.
    
    This strategy exploits the collective risk dilemma by:
    1. Defecting in round 1 (no history to exploit)
    2. In intermediate rounds, conditionally cooperating only when pivotal (cooperation_count == m-1)
    3. Defecting in the final round (no future reputation consequences)
    4. Otherwise defecting to minimize contribution costs while harvesting k bonus from others
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        previous_round_idx = state.round_number - 1
        cooperation_count = int(sum(history.opponent_actions[previous_round_idx, :]))
        if cooperation_count >= self.game_description.m:
            return Action.D
        elif cooperation_count == self.game_description.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_508(BaseStrategy):
    """
    Adaptive Threshold Defection with Opportunistic Exploitation.
    
    Three-phase strategy that treats cooperation as a commodity to exploit:
    1. Assessment Phase: Defect exclusively to observe cooperation rates
    2. Exploitation Phase: Defect when threshold likely met, mixed strategy otherwise
    3. Endgame Phase: Pure defection with no reputational consequences
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.assessment_end = math.ceil(self.n_rounds / 3)
        self.exploitation_end = math.floor(2 * self.n_rounds / 3)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round < self.assessment_end:
            return Action.D
        if current_round >= self.exploitation_end:
            return Action.D
        return self._exploitation_decision(current_round, history)

    def _exploitation_decision(self, current_round: int, history: PlayerHistory) -> Action:
        """
        Exploitation phase decision logic.
        
        IF observed_cooperation_rate >= m/n: DEFECT
        ELSE IF observed_cooperation_rate < (m/n)/2: Mixed (0.3 cooperate, 0.7 defect)
        ELSE: DEFECT
        """
        previous_round_idx = current_round - 1
        cooperators_previous = int(sum(history.opponent_actions[previous_round_idx, :]))
        observed_cooperation_rate = cooperators_previous / self.n_players
        cooperation_probability_threshold = self.m / self.n_players
        if observed_cooperation_rate >= cooperation_probability_threshold:
            return Action.D
        elif observed_cooperation_rate < cooperation_probability_threshold / 2:
            if random.random() < 0.3:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_509(BaseStrategy):
    """
    Adaptive Threshold Exploitation Strategy for Collective Risk Dilemma.
    
    Exploits the asymmetry between cooperators and defectors by:
    1. Always defecting in round 1 and final round
    2. Tracking cooperation rates to identify when threshold is secure
    3. Free-riding when threshold is likely met
    4. Only cooperating when acting as a swing vote is individually rational
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        total_cooperations = np.sum(history.opponent_actions[:current_round, :])
        my_cooperations = np.sum(history.my_actions[:current_round])
        total_cooperations += my_cooperations
        total_rounds_so_far = current_round
        all_possible_cooperations = self.n * total_rounds_so_far
        if all_possible_cooperations == 0:
            return Action.D
        cooperation_rate = total_cooperations / all_possible_cooperations
        expected_cooperators = cooperation_rate * self.n
        if expected_cooperators >= self.m:
            return Action.D
        if expected_cooperators < self.m - 1.5:
            return Action.D
        if self._has_reliable_cooperators(history, current_round):
            return Action.C
        else:
            return Action.D

    def _has_reliable_cooperators(self, history: PlayerHistory, current_round: int) -> bool:
        """
        Determine if there are reliable cooperators in history.
        
        A cooperator is considered "reliable" if they have cooperated
        in a significant portion of previous rounds.
        """
        if current_round == 0:
            return False
        opponent_cooperations = np.sum(history.opponent_actions[:current_round, :], axis=0)
        reliability_threshold = current_round / 2.0
        reliable_cooperators = np.sum(opponent_cooperations >= reliability_threshold)
        return reliable_cooperators > 0

class Strategy_EXPLOITATIVE_510(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation
    
    Core philosophy: Exploit the payoff asymmetry by defecting by default,
    only cooperating when expected payoff from cooperation >= defection.
    Tracks opponent behavior to estimate cooperation likelihood.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        prev_round_opponent_actions = history.opponent_actions[current_round - 1, :]
        cooperators_last_round = int(sum(prev_round_opponent_actions))
        if self.n_players > 1:
            est_coop = cooperators_last_round / (self.n_players - 1)
        else:
            est_coop = 0.0
        expected_c = est_coop * (self.n_players - 1)
        if expected_c >= self.m:
            return Action.D
        if abs(expected_c - (self.m - 1)) < 1e-09:
            rounds_remaining = self.n_rounds - current_round - 1
            if rounds_remaining >= 1 and self.k > 1:
                return Action.C
            else:
                return Action.D
        if cooperators_last_round == 0 and current_round >= 2:
            return Action.D
        if expected_c < self.m - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_511(BaseStrategy):
    """
    Adaptive Free-Riding with Threshold Exploitation.
    
    Exploits the Collective Risk Dilemma by defecting when others predictably
    cooperate enough to meet the threshold, while minimally contributing only
    when genuinely threatened with collective failure.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        avg_cooperators = self._estimate_avg_cooperators(history, current_round)
        if avg_cooperators >= self.m:
            return Action.D
        deficit = self.m - avg_cooperators
        rounds_remaining = self.n_rounds - current_round
        if deficit <= 1 and rounds_remaining > 1:
            cooperate_probability = 0.2
            if random.random() < cooperate_probability:
                return Action.C
            return Action.D
        if deficit > 1 and deficit <= self.n_players:
            cooperate_probability = min(deficit / (2.0 * self.n_players), 0.5)
            if random.random() < cooperate_probability:
                return Action.C
            return Action.D
        return Action.D

    def _estimate_avg_cooperators(self, history: PlayerHistory, current_round: int) -> float:
        """
        Estimate average number of cooperators from observed opponent actions
        across all previous rounds.
        """
        if current_round == 0:
            return 0.0
        total_cooperators = 0
        total_observations = 0
        for round_idx in range(current_round):
            cooperators_this_round = int(np.sum(history.opponent_actions[round_idx, :]))
            total_cooperators += cooperators_this_round
            total_observations += self.n_players - 1
        if total_observations == 0:
            return 0.0
        avg_cooperators = total_cooperators / total_observations
        return avg_cooperators * self.n_players / (self.n_players - 1) if self.n_players > 1 else avg_cooperators

class Strategy_EXPLOITATIVE_512(BaseStrategy):
    """
    Adaptive Threshold Defection (ATD) - An exploitative strategy that free-rides on others'
    cooperation while the threshold is met, defects in early/late rounds, and conditionally
    cooperates only to restore the threshold when necessary.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        last_round_idx = current_round - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[last_round_idx, :]))
        if cooperators_last_round >= self.m:
            return Action.D
        early_round_threshold = math.ceil(self.n_rounds / 2)
        if current_round <= early_round_threshold:
            return Action.D
        if current_round >= self.n_rounds - 1:
            return Action.D
        defectors_last_round = self.n_players - 1 - cooperators_last_round
        if defectors_last_round > self.n_players - self.m:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_336(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for Collective Risk Dilemma.
    
    Balances individual rationality with collective welfare by:
    1. Cooperating unconditionally in round 1 to establish cooperative signal
    2. Tracking cumulative defection patterns to detect group composition
    3. Monitoring threshold achievability through empirical cooperation rates
    4. Defecting only when cooperation is demonstrably futile or majority defects
    5. Cooperating in final round if threshold remains empirically reachable
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.n_rounds - 1:
            recent_cooperation_rate = self._get_recent_cooperation_rate(history, round_num)
            threshold_ratio = self.m / self.n_players
            if recent_cooperation_rate >= threshold_ratio:
                return Action.C
            return Action.D
        ever_defected_count = self._count_ever_defected(history, round_num)
        if ever_defected_count >= math.ceil(self.n_players / 2):
            return Action.D
        recent_cooperation_rate = self._get_recent_cooperation_rate(history, round_num)
        threshold_ratio = self.m / self.n_players
        if recent_cooperation_rate >= threshold_ratio:
            return Action.C
        return Action.D

    def _count_ever_defected(self, history: PlayerHistory, round_num: int) -> int:
        """
        Count the number of opponents who have ever defected in rounds [0, round_num-1].
        
        Args:
            history: PlayerHistory object containing opponent actions
            round_num: current round (0-indexed)
        
        Returns:
            Number of opponents who have defected at least once
        """
        if round_num == 0:
            return 0
        ever_defected = 0
        for opponent_idx in range(self.n_players - 1):
            opponent_history = history.opponent_actions[:round_num, opponent_idx]
            if not np.all(opponent_history):
                ever_defected += 1
        return ever_defected

    def _get_recent_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate the average cooperation rate in recent rounds.
        Uses the last 2 rounds (or fewer if fewer rounds exist), or all prior rounds if r <= 3.
        
        Args:
            history: PlayerHistory object containing opponent actions
            round_num: current round (0-indexed)
        
        Returns:
            Cooperation rate as a fraction [0, 1]
        """
        if round_num == 0:
            return 0.0
        prior_rounds = round_num
        window_size = min(2, prior_rounds)
        if window_size == 0:
            return 0.0
        start_idx = round_num - window_size
        recent_actions = history.opponent_actions[start_idx:round_num, :]
        total_cooperations = np.sum(recent_actions)
        total_actions = window_size * self.n_players
        if total_actions == 0:
            return 0.0
        cooperation_rate = total_cooperations / total_actions
        return cooperation_rate

class Strategy_EXPLOITATIVE_480(BaseStrategy):
    """
    Adaptive Defection with Selective Opportunism strategy for Collective Risk Dilemma.
    
    Exploits asymmetries by:
    1. Free-riding on others' cooperation when threshold will be met
    2. Defecting unconditionally in end-game rounds
    3. Classifying and targeting opponent types
    4. Using defection momentum to predict cooperation rates
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.opponent_types = np.zeros(self.n_players - 1, dtype=int)

    def _classify_opponent(self, round_number: int, opponent_idx: int, history: PlayerHistory) -> int:
        """Classify an opponent based on their cooperation frequency."""
        if round_number < 2:
            return 0
        opponent_actions = history.opponent_actions[:round_number, opponent_idx]
        coop_count = np.sum(opponent_actions)
        rounds_observed = round_number
        if rounds_observed == 0:
            return 0
        coop_freq = coop_count / rounds_observed
        if coop_freq >= 0.8:
            return 1
        elif coop_freq <= 0.2:
            return 3
        else:
            return 2

    def _count_recent_cooperators(self, round_number: int, history: PlayerHistory) -> int:
        """Count cooperators in the last 1-2 rounds."""
        if round_number == 0:
            return 0
        if round_number == 1:
            recent_coop = np.sum(history.opponent_actions[0, :])
        else:
            recent_coop = np.sum(history.opponent_actions[round_number - 2:round_number, :])
        return int(recent_coop)

    def _project_cooperators(self, round_number: int, history: PlayerHistory) -> int:
        """Project number of cooperators for this round based on recent behavior."""
        if round_number == 0:
            return self.m
        recent_coop = self._count_recent_cooperators(round_number, history)
        return recent_coop

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.n_rounds - 1:
            return Action.D
        if round_num == self.n_rounds - 2:
            if random.random() < 0.95:
                return Action.D
            else:
                return Action.C
        if round_num <= 2:
            for opp_idx in range(self.n_players - 1):
                if self.opponent_types[opp_idx] == 0:
                    opp_type = self._classify_opponent(round_num, opp_idx, history)
                    self.opponent_types[opp_idx] = opp_type
        recent_coop = self._count_recent_cooperators(round_num, history)
        if recent_coop >= self.m + 1:
            return Action.D
        if recent_coop == self.m:
            return Action.D
        if recent_coop == self.m - 1:
            if round_num <= 3:
                return Action.D
            elif random.random() < 0.9:
                return Action.D
            else:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_121(BaseStrategy):
    """
    Calculated Defection with Opportunistic Cooperation.
    
    Exploits asymmetry between cooperators and defectors by:
    1. Always defecting in round 1 to probe cooperation levels
    2. Defecting when threshold is met (1+k > 0+k)
    3. Cooperating only when exactly m-1 cooperators exist (marginal bet)
    4. Reverting to permanent defection if marginal cooperation fails
    5. Always defecting in final round for last-move advantage
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_cooperation_failed = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        current_round = state.round_number
        if n < m:
            return Action.D
        if m == 1:
            return Action.D
        if current_round == 0:
            return Action.D
        if self.last_cooperation_failed:
            return Action.D
        if current_round == r - 1:
            return Action.D
        prev_round_idx = current_round - 1
        cooperators_prev = int(sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            if cooperators_prev < m:
                self.last_cooperation_failed = True
                return Action.D
        if cooperators_prev >= m:
            return Action.D
        elif cooperators_prev == m - 1:
            return Action.C
        else:
            return Action.D
