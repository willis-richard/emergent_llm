"""
Generated LLM strategies for social dilemma games.

This file contains strategy classes generated by LLMs for game theory experiments.
Each strategy is a callable class that implements a specific approach to the game.

Generated with:
- Provider: Client
- Model: deepseek-r1:32b
- Game: public_goods
"""

from dataclasses import dataclass
from enum import Enum
import math
import numpy as np
from numpy.typing import NDArray
import random

from emergent_llm.players import BaseStrategy
from emergent_llm.games import PublicGoodsDescription, CollectiveRiskDescription, CommonPoolDescription, CommonPoolState
from emergent_llm.common import Action, C, D, PlayerHistory, GameState




class Strategy_COLLECTIVE_2(BaseStrategy):
    """
    A strategy that starts by cooperating and then conditionally cooperates based on previous rounds.
    Cooperates if at least m other players cooperated in the last round; otherwise defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            opponents_last_round = history.opponent_actions[-1, :]
            cooperators_count = np.sum(opponents_last_round)
            if cooperators_count >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_8(BaseStrategy):
    """
    A strategy that initializes with cooperation, then adaptively decides based on recent history.
    It defects only if the average cooperation meets a threshold and all recent rounds meet the minimum.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.x = 5
        self.buffer = 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_actions = history.opponent_actions
        my_actions = history.my_actions
        lookback = min(self.x, len(opponent_actions))
        recent_opponent_actions = opponent_actions[-lookback:] if lookback > 0 else []
        recent_my_actions = my_actions[-lookback:] if lookback > 0 else []
        coop_counts = []
        for i in range(lookback):
            round_coop = sum(recent_opponent_actions[i])
            if recent_my_actions[i]:
                round_coop += 1
            coop_counts.append(round_coop)
        all_meet_threshold = all((cc >= self.game_description.m for cc in coop_counts))
        if not all_meet_threshold:
            return Action.C
        avg_coop = np.mean(coop_counts) if lookback > 0 else 0
        if avg_coop >= self.game_description.m + self.buffer:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_23(BaseStrategy):
    """
    Adaptive Cooperation Strategy: Cooperate in the first round and adapt based on previous rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            last_round_idx = -1
            my_last_action = history.my_actions[last_round_idx]
            opponent_coop_count = sum(history.opponent_actions[last_round_idx])
            total_coop = (1 if my_last_action else 0) + opponent_coop_count
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_11(BaseStrategy):
    """
    A strategy where each player starts by Cooperating and continues to do so only if enough players (at least m) Cooperated in the previous round. Otherwise, they Defect.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_prev_action = history.my_actions[-1]
        opponents_last_round = history.opponent_actions[-1, :]
        total_coop = np.sum(opponents_last_round) + my_prev_action
        if total_coop >= self.m:
            return Action.C
        else:
            return Action.D