"""
Generated LLM strategies for social dilemma games.

This file contains strategy classes generated by LLMs for game theory experiments.
Each strategy is a callable class that implements a specific approach to the game.

Generated with:
- Provider: OpenAI
- Model: deepseek/deepseek-r1-distill-llama-70b
- Game: collective_risk
"""

from dataclasses import dataclass
from enum import Enum
import math
import numpy as np
from numpy.typing import NDArray
import random

from emergent_llm.players import BaseStrategy
from emergent_llm.games import PublicGoodsDescription, CollectiveRiskDescription, CommonPoolDescription, CommonPoolState
from emergent_llm.common import Action, C, D, PlayerHistory, GameState




class Strategy_COLLECTIVE_1(BaseStrategy):
    """
    Implements a strategy to sustain cooperation in repeated Collective Risk Dilemma games.
    Cooperates initially, continues if cooperation meets threshold, and attempts recovery after defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.recover_mode = False

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opp_prev_actions = history.opponent_actions[prev_round, :]
        prev_coop = sum(opp_prev_actions) + (1 if my_prev_action else 0)
        m = self.game_description.m
        if prev_coop >= m:
            self.recover_mode = False
            return Action.C
        elif self.recover_mode:
            self.recover_mode = False
            return Action.C
        else:
            self.recover_mode = True
            return Action.D

class Strategy_COLLECTIVE_2(BaseStrategy):
    """
    A strategy to maintain cooperation in repeated Collective Risk Dilemma games.
    Cooperates initially, punishes for non-cooperation with defection, and handles endgame consideration.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defecting = False
        self.defect_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            last_round = state.round_number - 1
            if last_round >= 0:
                my_last = history.my_actions[last_round]
                oppo_last = history.opponent_actions[last_round, :]
                total_coop = my_last + sum(oppo_last)
                return Action.C if total_coop >= self.game_description.m else Action.D
            else:
                return Action.C
        else:
            last_round = state.round_number - 1
            my_last = history.my_actions[last_round]
            oppo_last = history.opponent_actions[last_round, :]
            total_coop = sum(oppo_last) + my_last
            if total_coop >= self.game_description.m:
                self.defecting = False
                self.defect_remaining = 0
                return Action.C
            elif self.defecting:
                self.defect_remaining -= 1
                if self.defect_remaining <= 0:
                    self.defecting = False
                    self.defect_remaining = 0
                    return Action.C
                else:
                    return Action.D
            else:
                self.defecting = True
                self.defect_remaining = 2
                return Action.D

class Strategy_COLLECTIVE_3(BaseStrategy):
    """
    Adaptive Cooperation with Temporary Punishment (ACTP) strategy.
    Cooperates unless previous cooperation was below threshold, then defects temporarily.
    Resumes cooperation if cooperation level recovers.
    Cooperates in last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        previous_round = state.round_number - 1
        my_coop_prev = history.my_actions[previous_round]
        opponent_coop_prev = sum(history.opponent_actions[previous_round, :])
        total_prev_coop = my_coop_prev + opponent_coop_prev
        m = self.game_description.m
        if total_prev_coop >= m:
            return Action.C
        elif my_coop_prev:
            return Action.D
        elif total_prev_coop >= m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_4(BaseStrategy):
    """
    A strategy to foster cooperation in the Collective Risk Dilemma by balancing persistence and recovery from failures.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.failure_counter = 0
        self.F = 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        opponent_actions = history.opponent_actions[prev_round]
        my_prev_action = history.my_actions[prev_round]
        total_coop = sum(opponent_actions) + (1 if my_prev_action else 0)
        if total_coop >= self.game_description.m:
            self.failure_counter = 0
            return Action.C
        else:
            self.failure_counter += 1
            if self.failure_counter >= self.F:
                self.failure_counter = 0
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_5(BaseStrategy):
    """
    CRDAC (Collective Risk Dilemma Adaptive Cooperation) Strategy.
    This strategy starts with cooperation, adapts based on previous rounds' outcomes,
    and emphasizes cooperation in the final rounds to maximize collective payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number >= self.n_rounds - 2:
            return Action.C
        my_prev_action = history.my_actions[round_number - 1]
        opponent_prev_actions = history.opponent_actions[round_number - 1]
        num_coop_prev = my_prev_action + sum(opponent_prev_actions)
        if num_coop_prev >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_6(BaseStrategy):
    """
    A strategy that combines reciprocity with occasional forgiveness to sustain cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0
        self.x = 3
        self.p = 0.2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_prev = history.my_actions[-1]
        opponent_prev = history.opponent_actions[-1]
        if not my_prev:
            self.consecutive_defections += 1
        else:
            self.consecutive_defections = 0
        if self.consecutive_defections >= self.x:
            if random.random() < self.p:
                return Action.C
            else:
                return Action.D
        else:
            total_coop = my_prev + np.sum(opponent_prev)
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_7(BaseStrategy):
    """
    Adaptive Cooperation with Punishment (ACWP) strategy for the Collective Risk Dilemma.
    Cooperates initially, punishes by defecting if cooperation levels drop below threshold,
    and checks for sufficient cooperation over two rounds in the penultimate round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        if t == 0:
            return Action.C
        if t == self.n_rounds - 1:
            return Action.D
        prev_round = t - 1
        prev_my_action = history.my_actions[prev_round]
        my_coop_prev = 1 if prev_my_action else 0
        opp_coop_prev = np.sum(history.opponent_actions[prev_round, :])
        n_coop_prev = my_coop_prev + opp_coop_prev
        if n_coop_prev >= self.m:
            return Action.C
        elif t < self.n_rounds - 2:
            return Action.D
        elif t - 2 >= 0:
            prev2_round = t - 2
            prev2_my_action = history.my_actions[prev2_round]
            my_coop_prev2 = 1 if prev2_my_action else 0
            opp_coop_prev2 = np.sum(history.opponent_actions[prev2_round, :])
            n_coop_prev2 = my_coop_prev2 + opp_coop_prev2
            total_coop = n_coop_prev + n_coop_prev2
            if total_coop >= 2 * self.m:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_8(BaseStrategy):
    """
    This strategy begins with cooperation, continues if sufficient players cooperated previously, 
    and resets cooperation after two defections. It defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        previous_round = state.round_number - 1
        my_prev = history.my_actions[previous_round]
        opponent_prev = history.opponent_actions[previous_round]
        sum_coop = sum(opponent_prev) + (1 if my_prev else 0)
        if sum_coop >= self.game_description.m:
            self.consecutive_defections = 0
            return Action.C
        elif self.consecutive_defections >= 2:
            self.consecutive_defections = 0
            return Action.C
        else:
            self.consecutive_defections += 1
            return Action.D

class Strategy_COLLECTIVE_9(BaseStrategy):
    """
    Adaptive Cooperation with Gradual Defection strategy to address the Collective Risk Dilemma.
    Encourages cooperation unless previous rounds indicate insufficient participation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_last = history.my_actions[-1]
        opponents_last = history.opponent_actions[-1]
        c_prev = (1 if my_last else 0) + sum(opponents_last)
        if c_prev >= self.m:
            return Action.C
        else:
            p = (self.m - c_prev) / self.n_players
            if random.random() < p:
                return Action.D
            else:
                return Action.C

class Strategy_COLLECTIVE_10(BaseStrategy):
    """
    Cooperative Punisher with Forgiveness strategy for the Collective Risk Dilemma.
    Cooperates initially, punishes once if cooperation threshold isn't met, then forgives.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.my_last_action = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.my_last_action = Action.C
            return Action.C
        elif self.my_last_action == Action.D:
            self.my_last_action = Action.C
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opp_prev_actions = history.opponent_actions[prev_round]
            total_coops = my_prev_action + sum(opp_prev_actions)
            if total_coops >= self.game_description.m:
                self.my_last_action = Action.C
                return Action.C
            else:
                self.my_last_action = Action.D
                return Action.D

class Strategy_COLLECTIVE_11(BaseStrategy):
    """
    Adaptive Collective Cooperation with Forgiveness strategy.
    Cooperates initially, then adapts based on previous round's cooperation levels.
    Forgives after one defection to allow cooperation to resume.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.state = 'C'

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_prev_actions = history.opponent_actions[prev_round]
        total_coop_prev = int(my_prev_action) + int(opponents_prev_actions.sum())
        m = self.game_description.m
        current_state = self.state
        if total_coop_prev >= m or current_state == 'D':
            new_state = 'C'
        else:
            new_state = 'D'
        self.state = new_state
        return Action.C if new_state == 'C' else Action.D

class Strategy_COLLECTIVE_12(BaseStrategy):
    """
    A strategy designed for the Collective Risk Dilemma that balances cooperation 
    and adaptation to promote collective success while mitigating the risk of 
    perpetual defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consec_defects = 0
        self.x = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_prev_actions = history.opponent_actions[prev_round, :]
        cooperators_prev = int(my_prev_action) + sum(opponent_prev_actions)
        if cooperators_prev >= self.game_description.m:
            self.consec_defects = 0
            return Action.C
        else:
            self.consec_defects += 1
            if self.consec_defects >= self.x:
                self.consec_defects = 0
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_13(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that adapts based on the previous round's cooperation level.
    It starts by cooperating and adjusts the cooperation probability (p) up or down by 0.2 each round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.p = 1.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        opp_actions = history.opponent_actions[last_round, :]
        my_action = history.my_actions[last_round]
        cooperators = sum(opp_actions) + (1 if my_action else 0)
        m = self.game_description.m
        if cooperators >= m:
            self.p = min(self.p + 0.2, 1.0)
        else:
            self.p = max(self.p - 0.2, 0.0)
        if random.random() < self.p:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_14(BaseStrategy):
    """
    Cooperative Threshold Reciprocity Strategy for Collective Risk Dilemma.

    This strategy cooperates in the first round. In subsequent rounds, it cooperates if 
    at least m players cooperated in the previous round; otherwise, it defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t_prev = state.round_number - 1
        my_prev_action = history.my_actions[t_prev]
        opponent_prev_actions = history.opponent_actions[t_prev]
        total_coop = my_prev_action + np.sum(opponent_prev_actions)
        if total_coop >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_15(BaseStrategy):
    """
    Adaptive Cooperate-and-Punish (ACP) strategy to address the Collective Risk Dilemma.
    Cooperates initially, then adapts based on the number of cooperators in the previous round.
    Punishes once if cooperation threshold is not met, then reverts to cooperation unless needed again.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        game = self.game_description
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_prev_actions = history.opponent_actions[prev_round, :]
        num_coop_prev = int(my_prev_action) + int(np.any(opponents_prev_actions))
        num_coop_prev = int(my_prev_action) + np.count_nonzero(opponents_prev_actions)
        if num_coop_prev >= game.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_16(BaseStrategy):
    """
    Cooperate if at least m players cooperated in the previous round; else Defect.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_my_coop = history.my_actions[-1]
        prev_others_coop = history.opponent_actions[-1, :]
        total_coop = prev_my_coop + np.sum(prev_others_coop)
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_17(BaseStrategy):
    """
    Cooperative Punishment with Forgiveness Strategy.

    This strategy promotes sustained cooperation by starting with cooperation,
    continuing if the threshold is met, and enforcing punishment by having a reduced
    number of cooperators when the threshold isn't met.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.player_id = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if history is None:
            return Action.C
        previous_coops = 0
        if history.my_actions[-1]:
            previous_coops += 1
        previous_coops += sum(history.opponent_actions[-1, :])
        if previous_coops >= self.m:
            return Action.C
        else:
            threshold = self.m - 1
            if self.player_id <= threshold:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_18(BaseStrategy):
    """
    Adaptive Collective Cooperation Strategy.

    This strategy starts by cooperating in the first round. In subsequent rounds,
    it continues to cooperate if the previous round met the cooperation threshold.
    If the threshold was not met, it defects with 50% probability. In the last round,
    it cooperates if the average success rate of previous rounds exceeds 50%.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            met_count = 0
            r = self.game_description.n_rounds
            for round_num in range(r - 1):
                my_action = history.my_actions[round_num]
                op_actions = history.opponent_actions[round_num]
                coop_count = int(my_action) + op_actions.sum()
                if coop_count >= self.game_description.m:
                    met_count += 1
            average_success = met_count / (r - 1)
            if average_success > 0.5:
                return Action.C
            else:
                return Action.D
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            op_prev_actions = history.opponent_actions[prev_round]
            coop_count = int(my_prev_action) + op_prev_actions.sum()
            if coop_count >= self.game_description.m:
                return Action.C
            elif random.random() < 0.5:
                return Action.D
            else:
                return Action.C

class Strategy_COLLECTIVE_19(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma where players Cooperate in the first round and subsequently 
    Cooperate if at least m players Cooperated in the previous round, else Defect.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_my = history.my_actions[state.round_number - 1]
            prev_others = history.opponent_actions[state.round_number - 1, :]
            sum_coop = prev_my + np.sum(prev_others)
            if sum_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_20(BaseStrategy):
    """
    Adaptive Collective Cooperation with Forgiveness strategy.
    Cooperates initially and continues if collective cooperation threshold is met.
    Defects if the threshold isn't met but forgives after two consecutive defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defect_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_prev_actions = history.opponent_actions[prev_round, :]
        total_coops_prev = int(my_prev_action) + int(opponent_prev_actions.sum())
        last_round_met = total_coops_prev >= self.game_description.m
        if last_round_met:
            self.defect_streak = 0
            return Action.C
        else:
            self.defect_streak += 1
            if self.defect_streak >= 2:
                self.defect_streak = 0
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_21(BaseStrategy):
    """
    Grim-trigger strategy for Collective Risk Dilemma:
    Cooperate initially and continue unless any previous round had fewer than m cooperators.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        for t in range(state.round_number):
            my_action = history.my_actions[t]
            opponent_coops = sum(history.opponent_actions[t, :])
            total_coops = my_action + opponent_coops
            if total_coops < self.game_description.m:
                return Action.D
        return Action.C

class Strategy_COLLECTIVE_22(BaseStrategy):
    """
    Adaptive Cooperation with Punishment (ACP) strategy.
    
    - Cooperates in the first round.
    - If fewer than m players cooperated in the previous round, defects for two rounds.
    - After defecting twice consecutively, reverts to cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history.my_actions is not None and len(history.my_actions) >= 2:
            last_two_actions = history.my_actions[-2:]
            if all((not action for action in last_two_actions)):
                return Action.C
        if self.punishment_remaining > 0:
            self.punishment_remaining -= 1
            return Action.D
        if history is None:
            return Action.D
        prev_coop = sum(history.opponent_actions[-1, :]) + (1 if history.my_actions[-1] else 0)
        if prev_coop >= self.game_description.m:
            return Action.C
        else:
            self.punishment_remaining = 2
            return Action.D

class Strategy_COLLECTIVE_22(BaseStrategy):
    """
    Adaptive Cooperation with Punishment strategy. Cooperates initially, continues if 
    enough players cooperate, otherwise defects for two rounds as punishment.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defect_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.defect_counter > 0:
            self.defect_counter -= 1
            return Action.D
        previous_round = state.round_number - 1
        my_coop = history.my_actions[previous_round]
        opponents_coop = history.opponent_actions[previous_round, :]
        total_coop = (1 if my_coop else 0) + np.sum(opponents_coop)
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            self.defect_counter = 2
            return Action.D

class Strategy_COLLECTIVE_23(BaseStrategy):
    """
    Adaptive Cooperation with Forbearance strategy for Collective Risk Dilemma.
    Balances cooperation with punishment mechanisms to encourage long-term cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.p = 3
        self.q = 2
        self.max_defections = 2
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        prev_my_action = history.my_actions[prev_round]
        prev_opponent_actions = history.opponent_actions[prev_round]
        Co_prev = sum(prev_opponent_actions) + (1 if prev_my_action else 0)
        count = 0
        start = max(0, state.round_number - self.p)
        for r in range(start, state.round_number):
            if r >= len(history.my_actions):
                break
            my_action = history.my_actions[r]
            opponent_actions = history.opponent_actions[r]
            Co_r = sum(opponent_actions) + (1 if my_action else 0)
            if Co_r >= self.game_description.m:
                count += 1
        if Co_prev >= self.game_description.m:
            tmp_action = Action.C
        else:
            tmp_action = Action.C if count >= self.q else Action.D
        if self.consecutive_defections >= self.max_defections:
            action = Action.C
            self.consecutive_defections = 0
        else:
            action = tmp_action
            if action == Action.D:
                self.consecutive_defections += 1
            else:
                self.consecutive_defections = 0
        return action

class Strategy_COLLECTIVE_24(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that starts with cooperation and adapts based on previous rounds' cooperation levels.
    Cooperates if the previous round had at least m cooperators; otherwise, defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t_prev = state.round_number - 1
        my_prev = history.my_actions[t_prev]
        oppo_prev = history.opponent_actions[t_prev]
        s_prev = int(my_prev) + np.sum(oppo_prev)
        if s_prev >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_23(BaseStrategy):
    """
    Adaptive Cooperation with Forbearance Strategy.

    This strategy balances cooperation with punishment mechanisms, 
    ensuring adaptability and resilience. It starts by cooperating, 
    continues if sufficient players cooperate, otherwise evaluates recent 
    history to decide, and limits consecutive defections to encourage 
    recommitment.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.p = 3
        self.q = 2
        self.s = 2
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        prev_c = sum(history.opponent_actions[prev_round]) + history.my_actions[prev_round]
        if prev_c >= self.game_description.m:
            action = Action.C
        else:
            start_round = max(0, prev_round - self.p + 1)
            success_count = 0
            for r in range(start_round, prev_round + 1):
                coop_count = sum(history.opponent_actions[r]) + history.my_actions[r]
                if coop_count >= self.game_description.m:
                    success_count += 1
            action = Action.C if success_count >= self.q else Action.D
        if action == Action.D:
            self.consecutive_defections += 1
            if self.consecutive_defections >= self.s:
                action = Action.C
                self.consecutive_defections = 0
        else:
            self.consecutive_defections = 0
        return action

class Strategy_COLLECTIVE_24(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that starts with cooperation, 
    then continues to cooperate if at least m players cooperated previously, 
    otherwise defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev = history.my_actions[prev_round]
        opponent_prev = history.opponent_actions[prev_round]
        total_coop = my_prev + sum(opponent_prev)
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_25(BaseStrategy):
    """
    Strategy for the Collective Risk Dilemma game, promoting cooperation and punishing insufficient cooperation.
    Players start by cooperating, then continue if enough cooperate; otherwise, defect for a set number of rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_active = False
        self.punishment_remaining = 0
        self.p = 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.punishment_active:
            self.punishment_remaining -= 1
            if self.punishment_remaining == 0:
                self.punishment_active = False
            return Action.D
        else:
            prev_round = state.round_number - 1
            my_prev_act = history.my_actions[prev_round]
            opponent_prev = history.opponent_actions[prev_round]
            total_coop = sum(opponent_prev) + (1 if my_prev_act else 0)
            if total_coop < self.game_description.m:
                self.punishment_active = True
                self.punishment_remaining = self.p
                return Action.D
            else:
                return Action.C

class Strategy_COLLECTIVE_25(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game. It encourages cooperation by rewarding it 
    while imposing penalties for insufficient cooperation. The strategy starts with cooperation, 
    continues if enough players cooperate, and defects for a penalty period if cooperation 
    is insufficient.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif self.punishment_remaining > 0:
            action = Action.D
            self.punishment_remaining -= 1
            return action
        else:
            prev_round = state.round_number - 1
            my_coop = history.my_actions[prev_round]
            opponent_coop = history.opponent_actions[prev_round, :]
            total_coop = my_coop + np.sum(opponent_coop)
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                self.punishment_remaining = 1
                return Action.D

class Strategy_COLLECTIVE_26(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that encourages cooperation by monitoring past behavior,
    rewarding sustained cooperation, and temporarily defecting to penalize lack of cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.in_punishment = False
        self.punishment_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if self.in_punishment:
            action = Action.D
            self.punishment_remaining -= 1
            if self.punishment_remaining == 0:
                self.in_punishment = False
            return action
        len_history = len(history.my_actions)
        if len_history == 0:
            return Action.C
        recent_rounds = min(len_history, 3)
        met_count = 0
        for r in range(len_history - recent_rounds, len_history):
            my_action = history.my_actions[r]
            opponent_actions = history.opponent_actions[r]
            total = sum(opponent_actions) + (1 if my_action else 0)
            if total >= self.game_description.m:
                met_count += 1
        required = recent_rounds // 2 + 1
        if met_count >= required:
            return Action.C
        else:
            self.in_punishment = True
            self.punishment_remaining = 2
            return Action.D

class Strategy_COLLECTIVE_27(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma that balances cooperation based on recent success.
    Initially cooperates, then decides based on the success of the last three rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        s_count = min(3, state.round_number)
        start_round = max(0, state.round_number - s_count)
        recent_successes = 0
        for r in range(start_round, state.round_number):
            my_action = history.my_actions[r]
            my_coop = 1 if my_action else 0
            opponent_coop = history.opponent_actions[r, :].sum()
            total_coop = my_coop + opponent_coop
            if total_coop >= self.game_description.m:
                recent_successes += 1
        success_rate = recent_successes / s_count
        if success_rate > 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_26(BaseStrategy):

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.punishment_remaining > 0:
            self.punishment_remaining -= 1
            return Action.D
        last_round = state.round_number - 1
        my_last_coop = history.my_actions[last_round]
        opponent_coops_last = np.sum(history.opponent_actions[last_round, :])
        total_last = my_last_coop + opponent_coops_last
        m = self.game_description.m
        if total_last == m - 1:
            return Action.C
        count = 0
        for r in range(state.round_number):
            my_coop = history.my_actions[r]
            opponent_coops = np.sum(history.opponent_actions[r, :])
            total = my_coop + opponent_coops
            if total >= m:
                count += 1
        total_previous = state.round_number
        if count > total_previous / 2:
            return Action.C
        else:
            self.punishment_remaining = 2
            return Action.D

class Strategy_COLLECTIVE_28(BaseStrategy):
    """
    Grim Trigger Strategy for Collective Risk Dilemma:
    Cooperate initially and continue as long as the minimum number of cooperators is met in all previous rounds.
    If the count of cooperators falls below the threshold in any round, defect permanently in all subsequent rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        for prev_round in range(state.round_number):
            my_action = history.my_actions[prev_round]
            opponent_coops = np.sum(history.opponent_actions[prev_round, :])
            total_cooperators = my_action + opponent_coops
            if total_cooperators < self.game_description.m:
                return Action.D
        return Action.C

class Strategy_COLLECTIVE_27(BaseStrategy):
    """
    An adaptive strategy that cooperates based on the success of the last three rounds.
    It initializes with cooperation and then decides based on the majority success
    of recent rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number
        s = min(3, t)
        start = max(0, t - s)
        recent_successes = 0
        for i in range(start, t):
            my_action = history.my_actions[i]
            opponent_actions = history.opponent_actions[i]
            total_cooperators = (1 if my_action else 0) + sum(opponent_actions)
            if total_cooperators >= self.game_description.m:
                recent_successes += 1
        success_rate = recent_successes / s
        return Action.C if success_rate > 0.5 else Action.D

class Strategy_COLLECTIVE_28(BaseStrategy):
    """
    Grim Trigger strategy for Collective Risk Dilemma. Players cooperate until any round fails to meet the cooperation threshold, after which they permanently defect.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            for t in range(state.round_number):
                my_action = history.my_actions[t]
                opp_actions = history.opponent_actions[t, :]
                total_coop = my_action + opp_actions.sum()
                if total_coop < self.m:
                    return Action.D
            return Action.C

class Strategy_COLLECTIVE_29(BaseStrategy):
    """
    A strategy that encourages sustained cooperation by balancing cooperation and defection based on past outcomes.
    It starts with cooperation, continues if sufficient cooperation is met, defects if not, and recovers by cooperating again.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.force_cooperate_next = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.force_cooperate_next:
            self.force_cooperate_next = False
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_prev_actions = history.opponent_actions[prev_round, :]
        m_prev = (1 if my_prev_action else 0) + np.sum(opponent_prev_actions)
        if m_prev >= self.game_description.m:
            return Action.C
        else:
            self.force_cooperate_next = True
            return Action.D

class Strategy_COLLECTIVE_30(BaseStrategy):
    """
    Implements a strategy that fosters cooperation while punishing insufficient cooperation.
    Cooperates initially and continues if cooperation meets the threshold; otherwise, defects as a punishment.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev_action = history.my_actions[previous_round]
        opponents_actions = history.opponent_actions[previous_round]
        total_coop = int(my_prev_action) + np.sum(opponents_actions)
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_29(BaseStrategy):
    """
    A strategy that balances cooperation and defection based on past outcomes to maximize collective payoff.
    Cooperates initially, continues if enough players cooperate, defects if not, and recovers by re-cooperating.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defected_last_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.defected_last_round:
            self.defected_last_round = False
            return Action.C
        t_prev = state.round_number - 1
        my_prev_action = history.my_actions[t_prev]
        opponents_prev_actions = history.opponent_actions[t_prev, :]
        num_coop_prev = sum(opponents_prev_actions) + (1 if my_prev_action else 0)
        if num_coop_prev < self.game_description.m:
            self.defected_last_round = True
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_30(BaseStrategy):
    """
    A strategy that responds to the level of cooperation in the previous round.
    Cooperates if the number of cooperators meets the threshold m; otherwise, defects once.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t_prev = state.round_number - 1
        my_coop = history.my_actions[t_prev]
        opponents_coop = np.sum(history.opponent_actions[t_prev])
        total_coop = my_coop + opponents_coop
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_31(BaseStrategy):
    """
    An adaptive strategy that balances cooperation and punishment in a Collective Risk Dilemma.
    It uses an initial exploration phase, followed by assessment and punishment phases, and handles edge cases in the final rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        if current_round < 3:
            return Action.C
        elif current_round >= self.game_description.n_rounds - 3:
            count = 0
            for t in range(current_round - 1, max(current_round - 4, -1), -1):
                if t < 0:
                    break
                sum_opponents = history.opponent_actions[t, :].sum()
                my_prev_action = history.my_actions[t]
                total_coop = sum_opponents + my_prev_action
                if total_coop >= self.game_description.m:
                    count += 1
            if count >= 2:
                return Action.C
            else:
                return Action.D
        else:
            previous_round = current_round - 1
            sum_opponents = history.opponent_actions[previous_round, :].sum()
            my_prev_action = history.my_actions[previous_round]
            total_coop = sum_opponents + my_prev_action
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_31(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation (ARC) Strategy.
    Cooperates initially, punishes when cooperation is insufficient, and forgives when cooperation resumes.
    Handles edge cases in final rounds to avoid exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number <= 2:
            return Action.C
        if state.round_number >= self.r - 2:
            count_defect_rounds = 0
            for offset in [1, 2]:
                prev_round = state.round_number - offset
                if prev_round < 0:
                    continue
                my_prev_action = history.my_actions[prev_round]
                opponent_prev_actions = history.opponent_actions[prev_round, :]
                num_coop = my_prev_action + np.sum(opponent_prev_actions)
                if num_coop < self.m:
                    count_defect_rounds += 1
            if count_defect_rounds >= 1:
                return Action.D
            else:
                prev_round = state.round_number - 1
                my_prev_action = history.my_actions[prev_round]
                opponent_prev_actions = history.opponent_actions[prev_round, :]
                num_coop = my_prev_action + np.sum(opponent_prev_actions)
                if num_coop >= self.m:
                    return Action.C
                else:
                    return Action.D
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opponent_prev_actions = history.opponent_actions[prev_round, :]
            num_coop = my_prev_action + np.sum(opponent_prev_actions)
            if num_coop >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_32(BaseStrategy):
    """
    Adaptive Collective Cooperation (ACC) Strategy.
    
    This strategy starts by cooperating and continues to cooperate as long as the number 
    of cooperators meets or exceeds the minimum required threshold. If cooperation falls 
    below this threshold, it defects. If cooperation is insufficient twice in a row, 
    it restarts cooperation to avoid perpetual defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.consecutive_punishments = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        opponent_actions_prev = history.opponent_actions[prev_round, :]
        my_action_prev = history.my_actions[prev_round]
        prev_coop_count = opponent_actions_prev.sum() + (1 if my_action_prev else 0)
        if prev_coop_count >= self.m:
            self.consecutive_punishments = 0
            return Action.C
        else:
            self.consecutive_punishments += 1
            if self.consecutive_punishments >= 2:
                self.consecutive_punishments = 0
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_32(BaseStrategy):
    """Adaptive Collective Cooperation strategy to balance mutual benefits and deter defection."""

    def __init__(self, game_description: CollectiveRiskDescription):
        """Initialize the strategy with game parameters and state variables."""
        self.game_description = game_description
        self.consec_insufficient = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        """Implement the ACC strategy based on the current game state and history."""
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_prev_actions = history.opponent_actions[prev_round, :]
        total_coop = my_prev_action + np.sum(opponents_prev_actions)
        m = self.game_description.m
        if total_coop >= m:
            self.consec_insufficient = 0
            return Action.C
        else:
            self.consec_insufficient += 1
            if self.consec_insufficient >= 2:
                self.consec_insufficient = 0
                return Action.C
            return Action.D

class Strategy_COLLECTIVE_33(BaseStrategy):
    """
    Adaptive Cooperation with Punishment strategy for the Collective Risk Dilemma.
    Cooperates initially, adapts based on previous cooperation success, punishes failure by defecting for two rounds, 
    and defects in the last two rounds to maximize personal gain.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        n_rounds = self.game_description.n_rounds
        action = None
        if current_round > 0:
            remaining_rounds = n_rounds - current_round - 1
            if remaining_rounds <= 1:
                action = Action.D
        if action is None and current_round != 0:
            if self.punishment_counter > 0:
                action = Action.D
                self.punishment_counter -= 1
            else:
                prev_round = current_round - 1
                if history:
                    my_prev_action = history.my_actions[prev_round]
                    opponent_prev_actions = history.opponent_actions[prev_round]
                    sum_coop = int(my_prev_action) + opponent_prev_actions.sum()
                    prev_success = sum_coop >= self.game_description.m
                else:
                    prev_success = False
                if prev_success:
                    action = Action.C
                else:
                    self.punishment_counter = 2
                    action = Action.D
        elif action is None:
            action = Action.C
        return action

class Strategy_COLLECTIVE_33(BaseStrategy):
    """
    Adaptive Cooperation with Punishment Strategy for Collective Risk Dilemma.
    Cooperates initially, punishes for two rounds after a failure, and defects in the last two rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishing = False
        self.punishment_rounds_left = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        n_rounds = self.game_description.n_rounds
        if state.round_number >= n_rounds - 2:
            return Action.D
        if self.punishing:
            action = Action.D
            self.punishment_rounds_left -= 1
            if self.punishment_rounds_left <= 0:
                self.punishing = False
            return action
        else:
            previous_round = state.round_number - 1
            my_prev = history.my_actions[previous_round]
            opponent_prev = history.opponent_actions[previous_round]
            total_coop = my_prev + np.sum(opponent_prev)
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                self.punishing = True
                self.punishment_rounds_left = 2
                return Action.D

class Strategy_COLLECTIVE_34(BaseStrategy):
    """
    Adaptive Cooperation Strategy based on historical performance.
    Cooperates in the first round. For subsequent rounds, including the last,
    cooperates if at least m/n proportion of past rounds met the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n = game_description.n_players
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        successful_rounds = 0
        total_rounds = state.round_number
        for past_round in range(total_rounds):
            my_action = history.my_actions[past_round]
            opponents_actions = history.opponent_actions[past_round]
            total_coop = my_action + np.sum(opponents_actions)
            if total_coop >= self.m:
                successful_rounds += 1
        proportion = successful_rounds / total_rounds if total_rounds != 0 else 0
        threshold = self.m / self.n
        if proportion >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_34(BaseStrategy):
    """
    Adaptive Cooperation Strategy based on Historical Performance.
    Cooperates initially and adapts based on the proportion of successful rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m_threshold = game_description.m
        self.total_rounds = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        successful_rounds = 0
        for round_index in range(len(history.my_actions)):
            own_action = history.my_actions[round_index]
            opponents_actions = history.opponent_actions[round_index, :]
            total_coop = own_action + sum(opponents_actions)
            if total_coop >= self.m_threshold:
                successful_rounds += 1
        total_rounds = len(history.my_actions)
        proportion = successful_rounds / total_rounds
        threshold = self.m_threshold / self.n_players
        if proportion >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_36(BaseStrategy):
    """
    This strategy begins by Cooperating in the first round. For subsequent rounds, 
    it Cooperates if the number of cooperators in the previous round meets or exceeds 
    the threshold m. Otherwise, it Defects. After S consecutive defections, it 
    switches back to Cooperating to potentially recover cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0
        self.s = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        opponent_actions_prev = history.opponent_actions[previous_round]
        my_action_prev = history.my_actions[previous_round]
        sum_cooperators_prev = np.sum(opponent_actions_prev) + my_action_prev
        if sum_cooperators_prev >= self.game_description.m:
            self.consecutive_defections = 0
            return Action.C
        else:
            action = Action.D
            self.consecutive_defections += 1
            if self.consecutive_defections >= self.s:
                action = Action.C
                self.consecutive_defections = 0
            return action

class Strategy_COLLECTIVE_37(BaseStrategy):
    """
    Strategy to encourage cooperation by punishing insufficient cooperation temporarily.
    Cooperates initially, defects once if cooperation threshold isn't met, then resets.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.reset = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.reset:
            self.reset = False
            return Action.C
        prev_round = state.round_number - 1
        opponent_coop_prev = sum(history.opponent_actions[prev_round])
        my_coop_prev = 1 if history.my_actions[prev_round] else 0
        c_prev = opponent_coop_prev + my_coop_prev
        if c_prev >= self.game_description.m:
            return Action.C
        else:
            self.reset = True
            return Action.D

class Strategy_COLLECTIVE_38(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that adapts based on previous cooperation.
    Cooperates initially, punishes when cooperation is too low, then forgives to reset cooperation.
    Always cooperates in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.next_cooperate = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        if self.next_cooperate:
            self.next_cooperate = False
            return Action.C
        t_prev = state.round_number - 1
        my_last_action = history.my_actions[t_prev]
        sum_others_last = np.sum(history.opponent_actions[t_prev, :])
        total_coop = my_last_action + sum_others_last
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            self.next_cooperate = True
            return Action.D

class Strategy_COLLECTIVE_36(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that starts with cooperation, continues if enough players cooperated previously, defects otherwise, and resets cooperation after a set number of consecutive defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0
        self.s = 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.consecutive_defections = 0
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opp_prev_actions = history.opponent_actions[prev_round, :]
        total_coop = sum(opp_prev_actions) + (1 if my_prev_action else 0)
        if total_coop >= self.game_description.m:
            self.consecutive_defections = 0
            return Action.C
        else:
            self.consecutive_defections += 1
            if self.consecutive_defections == self.s:
                self.consecutive_defections = 0
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_39(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that adapts based on the level of cooperation in previous rounds.
    It starts by cooperating, continues if enough players cooperate, and defects for two rounds if cooperation falls below the threshold.
    It always cooperates in the final round to maximize the chance of meeting the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        if self.punishment_remaining > 0:
            self.punishment_remaining -= 1
            return Action.D
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_actions = history.opponent_actions[prev_round]
        total_coop_prev = np.sum(opponent_actions) + my_prev_action
        if total_coop_prev < self.game_description.m:
            self.punishment_remaining = 2
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_37(BaseStrategy):
    """
    A strategy that encourages cooperation by punishing insufficient cooperation 
    and resetting to cooperation after punishment.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.reset_flag = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.reset_flag:
            self.reset_flag = False
            return Action.C
        prev_round = state.round_number - 1
        my_prev = history.my_actions[prev_round]
        opp_prev = history.opponent_actions[prev_round, :]
        c_prev = sum(opp_prev) + my_prev
        if c_prev >= self.game_description.m:
            return Action.C
        else:
            self.reset_flag = True
            return Action.D

class Strategy_COLLECTIVE_40(BaseStrategy):
    """
    A strategy that begins by cooperating and adapts based on the collective cooperation in previous rounds.
    It defects for up to two consecutive rounds if insufficient players cooperate, then resumes cooperation.
    This aims to maintain collective benefits while punishing low cooperation temporarily.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defect_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t_prev = state.round_number - 1
        my_prev = history.my_actions[t_prev]
        opponent_prev = history.opponent_actions[t_prev, :]
        num_coop = (1 if my_prev else 0) + np.sum(opponent_prev)
        if num_coop >= self.game_description.m:
            self.defect_count = 0
            return Action.C
        else:
            self.defect_count += 1
            if self.defect_count <= 2:
                return Action.D
            else:
                self.defect_count = 0
                return Action.C

class Strategy_COLLECTIVE_38(BaseStrategy):
    """
    Implementation of the Collective Strategy for the Collective Risk Dilemma.
    Cooperates initially, reciprocates based on previous actions, defects as punishment,
    and reverts to cooperation to restart collaboration.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        t_prev = state.round_number - 1
        my_prev_action = history.my_actions[t_prev]
        opponent_prev_actions = history.opponent_actions[t_prev]
        sum_opponents = sum(opponent_prev_actions)
        sum_self = 1 if my_prev_action else 0
        cooperators = sum_opponents + sum_self
        if cooperators >= self.game_description.m:
            return Action.C
        elif my_prev_action:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_41(BaseStrategy):
    """
    A strategy that promotes sustained cooperation by cooperating as long as 
    at least m players cooperated in the previous round. Initially cooperates.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_prev_action = history.my_actions[-1]
        opp_prev_actions = history.opponent_actions[-1]
        total_coop = sum(opp_prev_actions) + int(my_prev_action)
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_39(BaseStrategy):
    """
    Adaptive Cooperation with Punishment Strategy for the Collective Risk Dilemma.
    Cooperates initially, punishes for two rounds if cooperation drops below threshold,
    and reverts to cooperation afterwards. Cooperates in the last round to maximize
    the chance of meeting the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        total_rounds = self.game_description.n_rounds
        m = self.game_description.m
        if current_round == 0:
            return Action.C
        if current_round == total_rounds - 1:
            return Action.C
        if self.punishment_remaining > 0:
            self.punishment_remaining -= 1
            return Action.D
        prev_round = current_round - 1
        my_prev = history.my_actions[prev_round]
        opponent_prev = history.opponent_actions[prev_round, :]
        num_coop = int(my_prev) + int(opponent_prev.sum())
        if num_coop < m:
            self.punishment_remaining = 2
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_40(BaseStrategy):
    """
    Adaptive Cooperation with Temporary Punishment strategy for the Collective Risk Dilemma.
    Cooperates initially, punishes defection with up to two consecutive defections,
    then reverts to cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defect_count = 0

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        opponent_actions_prev = history.opponent_actions[prev_round]
        my_prev_action = history.my_actions[prev_round]
        total_coop_prev = sum(opponent_actions_prev) + (1 if my_prev_action else 0)
        if total_coop_prev >= self.game_description.m:
            self.defect_count = 0
            return Action.C
        else:
            self.defect_count += 1
            if self.defect_count <= 2:
                return Action.D
            else:
                self.defect_count = 0
                return Action.C

class Strategy_COLLECTIVE_42(BaseStrategy):
    """
    A strategy designed for the Collective Risk Dilemma game that encourages sustained cooperation through observation 
    and punishment. Players start by cooperating, continue if enough players cooperate, and defect otherwise, but 
    can revert back to cooperation if conditions improve.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n_players = game_description.n_players
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        opp_actions_prev = history.opponent_actions[prev_round, :]
        sum_opp = np.sum(opp_actions_prev)
        my_prev = history.my_actions[prev_round]
        s_prev = sum_opp + (1 if my_prev else 0)
        if s_prev >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_41(BaseStrategy):
    """
    A strategy that promotes sustained cooperation by cooperating as long as 
    the number of cooperators in the previous round meets or exceeds the threshold m.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_last = history.my_actions[-1]
        opponent_last = history.opponent_actions[-1]
        sum_o = np.sum(opponent_last)
        total_coop = sum_o + my_last
        if total_coop >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_43(BaseStrategy):
    """
    A strategy that begins by cooperating, then adapts based on whether a minimum threshold of cooperators is met.
    If the threshold is met, it continues to cooperate. If not, it defects once as a punitive measure,
    then returns to cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.current_state = 'coop'

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.current_state == 'coop':
            t_prev = state.round_number - 1
            my_prev = history.my_actions[t_prev]
            opp_prev = history.opponent_actions[t_prev]
            total_coop_prev = my_prev + np.sum(opp_prev)
            if total_coop_prev >= self.game_description.m:
                return Action.C
            else:
                self.current_state = 'punish'
                return Action.D
        else:
            self.current_state = 'coop'
            return Action.C

class Strategy_COLLECTIVE_44(BaseStrategy):
    """
    A strategy that begins by cooperating and adapts based on the number of cooperators in the previous round.
    Cooperates if the previous round met or exceeded the minimum required cooperators m; otherwise, defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        opponent_coop = sum(history.opponent_actions[last_round])
        my_coop = history.my_actions[last_round]
        total_coop = opponent_coop + my_coop
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_42(BaseStrategy):
    """
    A strategy that promotes cooperation and punishes defection, allowing recovery.
    Cooperates initially, then observes previous cooperation levels to decide actions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev_action = history.my_actions[previous_round]
        opponent_prev_actions = history.opponent_actions[previous_round, :]
        s_prev = my_prev_action + sum(opponent_prev_actions)
        m = self.game_description.m
        if s_prev >= m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_45(BaseStrategy):
    """
    Adaptive Cooperation with Punishment Reset Strategy.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_actions = history.my_actions
        my_last_action = my_actions[-1]
        sum_opponents = sum(history.opponent_actions[-1])
        sum_coop = sum_opponents + (1 if my_last_action else 0)
        if sum_coop >= self.game_description.m:
            self.consecutive_defections = 0
            return Action.C
        else:
            if my_last_action:
                self.consecutive_defections = 0
            else:
                self.consecutive_defections += 1
            if self.consecutive_defections < 2:
                return Action.D
            else:
                self.consecutive_defections = 0
                return Action.C

class Strategy_COLLECTIVE_46(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game where players cooperate 
    initially and continue to cooperate as long as the minimum number of 
    cooperators is met in each round. If the threshold isn't met, they defect.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_prev_actions = history.opponent_actions[prev_round]
        total_coop = my_prev_action + sum(opponent_prev_actions)
        if total_coop >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_47(BaseStrategy):
    """
    This strategy starts by cooperating and then adapts based on previous cooperation levels.
    It uses a forgiveness mechanism to recover from potential cycles of defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cf_counter = 0
        self.coop_phase = False
        self.forgiveness_rounds = None

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number - 1
        prev_my_action = history.my_actions[t]
        prev_opp_actions = history.opponent_actions[t, :]
        total_prev_coop = prev_my_action + sum(prev_opp_actions)
        cooperation_met = total_prev_coop >= self.game_description.m
        if cooperation_met:
            self.cf_counter = 0
            self.coop_phase = False
            return Action.C
        elif self.coop_phase:
            action = Action.C
            self.forgiveness_rounds -= 1
            if self.forgiveness_rounds == 0:
                self.coop_phase = False
                self.forgiveness_rounds = None
            return action
        else:
            action = Action.D
            self.cf_counter += 1
            if self.cf_counter >= 2:
                action = Action.C
                self.coop_phase = True
                self.forgiveness_rounds = 1
            return action

class Strategy_COLLECTIVE_43(BaseStrategy):
    """
    Adaptive Cooperation with Punishment Strategy for Collective Risk Dilemma.
    
    - Cooperate in the first round.
    - Continue cooperating if the cooperation threshold was met in the previous round.
    - Defect if the threshold was not met, then revert to cooperation in the next round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_punished = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.last_punished = False
            return Action.C
        if self.last_punished:
            self.last_punished = False
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_prev_actions = history.opponent_actions[prev_round, :]
        num_coop = int(my_prev_action)
        num_coop += np.sum(opponents_prev_actions)
        if num_coop >= self.game_description.m:
            return Action.C
        else:
            self.last_punished = True
            return Action.D

class Strategy_COLLECTIVE_44(BaseStrategy):
    """
    Adaptive Cooperation Based on Previous Round's Performance.
    
    This strategy initially cooperates to set a cooperative tone. In subsequent rounds,
    it cooperates if the number of cooperators in the previous round met the threshold,
    otherwise it defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            my_last = history.my_actions[-1]
            opponents_last = history.opponent_actions[-1]
            total_coop = my_last + np.sum(opponents_last)
            if total_coop >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_45(BaseStrategy):
    """
    A strategy that adaptively cooperates and punishes based on the collective cooperation levels in previous rounds.
    It starts by cooperating, continues if the threshold is met, defects if not, and resets cooperation after two consecutive defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defects = 0
        self.s = 2

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        my_last_action = history.my_actions[-1]
        opponent_last_round = history.opponent_actions[-1]
        total_coop = int(my_last_action) + np.sum(opponent_last_round)
        if total_coop >= self.game_description.m:
            self.consecutive_defects = 0
            return Action.C
        else:
            if my_last_action == False:
                self.consecutive_defects += 1
            else:
                self.consecutive_defects = 0
            if self.consecutive_defects < self.s:
                return Action.D
            else:
                self.consecutive_defects = 0
                return Action.C

class Strategy_COLLECTIVE_48(BaseStrategy):
    """
    A collective strategy for the Collective Risk Dilemma game. 
    It aims to maximize collective payoff by ensuring at least `m` players cooperate each round, 
    adapting dynamically based on previous round outcomes.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_prev_actions = history.opponent_actions[prev_round]
        c_prev = my_prev_action + np.sum(opponents_prev_actions)
        if c_prev >= self.game_description.m:
            return Action.C
        else:
            p = (self.game_description.m - c_prev) / self.game_description.n_players
            if random.random() < p:
                return Action.D
            else:
                return Action.C

class Strategy_COLLECTIVE_46(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that encourages sustained cooperation.
    Cooperates in the first round and continues to cooperate if the number of cooperators
    in the previous round met the threshold m; otherwise, it defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_opponents = history.opponent_actions[-1, :]
        coop_opponents = sum(prev_opponents)
        my_last_action = history.my_actions[-1]
        total_coop = coop_opponents + my_last_action
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_49(BaseStrategy):
    """
    Cooperative Punishment with Recovery strategy to maintain cooperation
    in a collective risk dilemma. Players start by cooperating, punish by
    defecting once if cooperation falls below the threshold, then revert
    to cooperation to allow recovery.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_punished = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            my_prev_action = history.my_actions[-1]
            opponents_prev_actions = history.opponent_actions[-1, :]
            count_coop_prev = my_prev_action + sum(opponents_prev_actions)
            if count_coop_prev >= self.game_description.m:
                self.last_punished = False
                return Action.C
            elif not self.last_punished:
                self.last_punished = True
                return Action.D
            else:
                self.last_punished = False
                return Action.C

class Strategy_COLLECTIVE_47(BaseStrategy):
    """
    ForgivenessStrategy: Cooperates initially, then responds based on previous rounds.
    Continues to cooperate if the minimum m cooperators were met, defects otherwise.
    After two consecutive defective rounds, it cooperates once to attempt to restart cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.failure_count = 0
        self.cooperate_next = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_last_action = history.my_actions[prev_round]
        opponent_last_actions = history.opponent_actions[prev_round, :]
        total_coop = my_last_action + np.sum(opponent_last_actions)
        if total_coop >= self.game_description.m:
            self.failure_count = 0
            self.cooperate_next = False
            return Action.C
        elif self.cooperate_next:
            self.cooperate_next = False
            self.failure_count = 0
            return Action.C
        else:
            self.failure_count += 1
            if self.failure_count >= 2:
                self.cooperate_next = True
                self.failure_count = 0
            return Action.D

class Strategy_COLLECTIVE_50(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that encourages sustained cooperation
    with mechanisms to recover from consecutive failures.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_failures = 0
        self.s = 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.consecutive_failures = 0
            return Action.C
        prev_my_action = history.my_actions[-1].item()
        prev_opp_actions = history.opponent_actions[-1, :]
        prev_coop_opponents = sum(prev_opp_actions)
        prev_coop = prev_coop_opponents + (1 if prev_my_action else 0)
        if prev_coop >= self.game_description.m:
            self.consecutive_failures = 0
            return Action.C
        else:
            self.consecutive_failures += 1
            if self.consecutive_failures >= self.s:
                self.consecutive_failures = 0
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_48(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that encourages cooperation by'
'
    adapting based on the previous round's cooperation level. It aims to ensure'
'
    the minimum required cooperators while allowing for probabilistic defection'
'
    to avoid exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n_players = game_description.n_players
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t_prev = state.round_number - 1
        my_prev = history.my_actions[t_prev]
        opponent_prev = history.opponent_actions[t_prev, :]
        sum_opponents = np.sum(opponent_prev)
        c_prev = sum_opponents + (1 if my_prev else 0)
        if c_prev >= self.m:
            return Action.C
        else:
            p = (self.m - c_prev) / self.n_players
            if random.random() < p:
                return Action.D
            else:
                return Action.C

class Strategy_COLLECTIVE_51(BaseStrategy):
    """
    A strategy that encourages cooperation among players in a repeated game while allowing recovery after failures.
    - All players cooperate in the first round.
    - If the previous round met the cooperation threshold, continue to cooperate.
    - If the previous round failed, players switch their previous action: cooperators defect, and defectors cooperate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round_number = state.round_number - 1
        prev_my_action = history.my_actions[prev_round_number]
        prev_opponent_actions = history.opponent_actions[prev_round_number, :]
        sum_coops = prev_my_action + np.sum(prev_opponent_actions)
        prev_met = sum_coops >= self.game_description.m
        if prev_met:
            return Action.C
        else:
            return Action.D if prev_my_action else Action.C

class Strategy_COLLECTIVE_35(BaseStrategy):
    """
    Adaptive Collective Cooperation strategy for the Collective Risk Dilemma.
    Initially cooperates, adapts based on previous cooperation rates, and decides
    based on overall trends in final rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number < 2:
            return Action.C
        n_rounds = self.game_description.n_rounds
        m = self.game_description.m
        current_round = state.round_number
        if current_round >= n_rounds - 3:
            total_cooperations = 0.0
            for t in range(current_round):
                my_action = history.my_actions[t]
                opponents_actions = history.opponent_actions[t]
                coops = int(my_action) + np.sum(opponents_actions)
                total_cooperations += coops
            if current_round > 0:
                avg_coops = total_cooperations / current_round
            else:
                avg_coops = 0.0
            if avg_coops >= m:
                return Action.C
            else:
                return Action.D
        else:
            last_round = current_round - 1
            my_action = history.my_actions[last_round]
            opponents_actions = history.opponent_actions[last_round]
            coops_last = int(my_action) + np.sum(opponents_actions)
            if coops_last >= m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_52(BaseStrategy):
    """
    A strategy that initially cooperates and then adapts based on the number of cooperators in the previous round.
    Cooperates if the minimum required cooperators threshold (m) was met; otherwise, defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n = game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_actions_prev = history.opponent_actions[prev_round]
        cooperators = int(my_prev_action) + int(opponent_actions_prev.sum())
        if cooperators >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_53(BaseStrategy):
    """
    Implements the Collective Risk Deterrence strategy to balance cooperation with deterrent measures.
    Uses initial cooperation, reciprocal altruism, gradual escalation, and reset mechanisms.
    Defects in the final round to align with subgame perfect equilibrium.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.ESCLATION_LIMIT = 3
        self.RESET_DURATION = 2
        self.reset_counter = 0
        self.defect_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.n_rounds - 1:
            return Action.D
        if self.reset_counter > 0:
            self.reset_counter -= 1
            return Action.C
        if history is None:
            return Action.C
        opp_actions = history.opponent_actions[-1, :]
        my_prev_action = history.my_actions[-1]
        previous_coop = sum(opp_actions) + (1 if my_prev_action else 0)
        if previous_coop >= self.m:
            self.defect_streak = 0
            return Action.C
        else:
            self.defect_streak += 1
            if self.defect_streak >= self.ESCLATION_LIMIT:
                self.reset_counter = self.RESET_DURATION
                self.defect_streak = 0
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_54(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that adapts based on the proportion of past successful rounds.
    Cooperates in the first round and then uses the historical success rate to decide future actions.
    Success is defined as meeting the required number of cooperators.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        successes = 0
        for r in range(state.round_number):
            my_action = history.my_actions[r]
            opponent_actions = history.opponent_actions[r]
            total_coop = int(my_action) + sum(opponent_actions)
            if total_coop >= self.game_description.m:
                successes += 1
        p = successes / state.round_number
        return Action.C if random.random() < p else Action.D

class Strategy_COLLECTIVE_55(BaseStrategy):
    """
    The Cooperate-and-Monitor strategy encourages sustained cooperation while adapting to collective outcomes.
    Players start by cooperating, then adjust based on whether the cooperation threshold was met in previous rounds.
    If the threshold was met, they continue to cooperate. If not, they may defect but attempt to recover cooperation
    in subsequent rounds if conditions are met.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        prev_coops = history.my_actions[previous_round] + np.sum(history.opponent_actions[previous_round, :])
        m = self.game_description.m
        if prev_coops >= m:
            return Action.C
        else:
            last_action = history.my_actions[previous_round]
            if last_action is False:
                if state.round_number - 2 >= 0:
                    t_minus_2 = state.round_number - 2
                    t2_coops = history.my_actions[t_minus_2] + np.sum(history.opponent_actions[t_minus_2, :])
                    if t2_coops < m:
                        return Action.C
            return Action.D

class Strategy_COLLECTIVE_56(BaseStrategy):
    """
    A strategy designed to sustain cooperation in a Collective Risk Dilemma by 
    initially cooperating, punishing insufficient cooperation, and introducing 
    probabilistic recovery.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.recovering_next_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.recovering_next_round = False
            return Action.C
        if self.recovering_next_round:
            action = Action.C if random.random() < 0.5 else Action.D
            self.recovering_next_round = False
            return action
        prev_round = state.round_number - 1
        my_prev_coop = history.my_actions[prev_round]
        opponent_prev_coop = sum(history.opponent_actions[prev_round, :])
        total_coop_prev = my_prev_coop + opponent_prev_coop
        if total_coop_prev >= self.game_description.m:
            return Action.C
        else:
            if total_coop_prev == 0:
                self.recovering_next_round = True
            return Action.D

class Strategy_COLLECTIVE_57(BaseStrategy):
    """
    A strategy that cooperates on the first round and continues to cooperate as long as at least m players 
    cooperated in the previous round. If fewer than m players cooperated, the strategy switches to defect 
    permanently.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.m_threshold = game_description.m
        self.n_players = game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            my_prev_action = history.my_actions[-1]
            opponent_prev_actions = history.opponent_actions[-1, :]
            sum_opponent_coop = np.sum(opponent_prev_actions)
            sum_prev_coop = sum_opponent_coop + (1 if my_prev_action else 0)
            if sum_prev_coop >= self.m_threshold:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_58(BaseStrategy):
    """
    A strategy designed for the Collective Risk Dilemma game, balancing cooperation with strategic defection.
    Cooperates initially, adapts based on past cooperation levels, and defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            prev_rounds = state.round_number
            my_actions = history.my_actions[:prev_rounds].astype(int)
            opponent_actions = history.opponent_actions[:prev_rounds, :]
            opponent_sum = opponent_actions.sum(axis=1)
            total_per_round = my_actions + opponent_sum
            met_m = total_per_round >= self.game_description.m
            count = met_m.sum()
            if count > prev_rounds / 2:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_59(BaseStrategy):
    """
    A strategy that maintains cooperation if enough players cooperated in the previous round.
    Cooperates initially and adapts based on the number of cooperators in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_prev_action = history.my_actions[-1]
        opponents_prev_actions = history.opponent_actions[-1]
        total_coop = int(my_prev_action) + np.sum(opponents_prev_actions)
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_60(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that encourages sustained cooperation 
    through responsiveness and a reset mechanism after consecutive defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_last_action = history.my_actions[state.round_number - 1]
        opponent_last_actions = history.opponent_actions[state.round_number - 1, :]
        my_coop = int(my_last_action)
        opponent_coop = sum(opponent_last_actions)
        num_coop = my_coop + opponent_coop
        m = self.game_description.m
        if num_coop >= m:
            self.consecutive_defections = 0
            return Action.C
        else:
            self.consecutive_defections += 1
            if self.consecutive_defections >= 2:
                self.consecutive_defections = 0
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_61(BaseStrategy):
    """
    A strategy that begins by cooperating, adapts based on previous round's cooperation levels, 
    and defects in the final round to maximize individual payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            my_coop = 1 if my_prev_action else 0
            opponent_prev_actions = history.opponent_actions[prev_round]
            opponent_coops = np.sum(opponent_prev_actions)
            total_coops = my_coop + opponent_coops
            if total_coops >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_62(BaseStrategy):
    """
    A strategy that cooperates if at least m players cooperated in the previous round, 
    otherwise defects. Always cooperates in the first round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            my_coop = 1 if my_prev_action else 0
            opp_coops = sum(history.opponent_actions[prev_round, :])
            total_coop = my_coop + opp_coops
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_63(BaseStrategy):
    """
    A deterministic strategy promoting sustained cooperation through recovery.

    Players start by Cooperating. In subsequent rounds, they continue Cooperating
    if the previous round met or exceeded the required cooperators (m). If not, 
    they defect unless their previous action was Defection, in which case they 
    Cooperate again to allow potential recovery.

    This approach balances maintaining beneficial outcomes with resilience against
    occasional defections, promoting sustainable cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev_action = history.my_actions[previous_round]
        opponent_prev_actions = history.opponent_actions[previous_round]
        sum_opponent_actions = np.sum(opponent_prev_actions)
        total_coop = my_prev_action + sum_opponent_actions
        if total_coop >= self.game_description.m:
            return Action.C
        elif not my_prev_action:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_64(BaseStrategy):

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            prev_round = state.round_number - 1
            my_last = history.my_actions[prev_round]
            opponents_last = history.opponent_actions[prev_round]
            total_coop = my_last + np.sum(opponents_last)
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_65(BaseStrategy):
    """
    An adaptive strategy that balances cooperation with cautious defection.
    Cooperates initially, continues if cooperation threshold is met, and defects 
    with limited forgiveness when the threshold is not met.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.failure_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opponent_prev_actions = history.opponent_actions[prev_round]
            total_coop_prev = sum(opponent_prev_actions) + my_prev_action
            if total_coop_prev >= self.game_description.m:
                self.failure_counter = 0
                return Action.C
            else:
                self.failure_counter += 1
                return Action.D

class Strategy_COLLECTIVE_66(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that balances cooperation with punishment
    and recovery. It starts by cooperating, punishes insufficient cooperation, then
    resets to cooperation to encourage recovery.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_defected = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        others_prev_actions = history.opponent_actions[prev_round]
        prev_coop = my_prev_action + np.sum(others_prev_actions)
        m = self.game_description.m
        if self.last_defected:
            action = Action.C
            self.last_defected = False
        elif prev_coop >= m:
            action = Action.C
        else:
            action = Action.D
            self.last_defected = True
        return action

class Strategy_COLLECTIVE_68(BaseStrategy):
    """
    A strategy that promotes cooperation based on previous round outcomes.
    Cooperates in the first round. In subsequent rounds, cooperates if at least m players cooperated in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_my_action = history.my_actions[-1]
        prev_opponent_actions = history.opponent_actions[-1]
        my_coop = 1 if prev_my_action else 0
        opponent_coop = np.sum(prev_opponent_actions)
        total_coop = my_coop + opponent_coop
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_69(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that adapts based on the collective cooperation of all players.
    Performs cooperation in the first round, continues if enough players cooperate,
    defects otherwise with a waiting period before attempting cooperation again.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n_players = game_description.n_players
        self.waiting_period = self.m // self.n_players + 1
        self.timer = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.timer = 0
            return Action.C
        previous_round = state.round_number - 1
        my_prev = history.my_actions[previous_round]
        opponent_prev = history.opponent_actions[previous_round]
        total_C = 1 if my_prev else 0
        total_C += sum(opponent_prev)
        if total_C >= self.m:
            self.timer = 0
            return Action.C
        else:
            if self.timer == 0:
                self.timer = self.waiting_period
            self.timer -= 1
            return Action.D

class Strategy_COLLECTIVE_70(BaseStrategy):
    """
    Forgiving Strategy: Cooperates initially and continues if at least one of the last two rounds met the cooperation threshold.
    Defects only after two consecutive rounds below the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        recent_rounds = [state.round_number - 1]
        if state.round_number > 1:
            recent_rounds.append(state.round_number - 2)
        for t in recent_rounds:
            my_coop = history.my_actions[t]
            opp_coop = history.opponent_actions[t, :].sum()
            total_c = (1 if my_coop else 0) + opp_coop
            if total_c >= self.game_description.m:
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_71(BaseStrategy):
    """
    Adaptive Cooperation with Forgiveness Strategy.

    This strategy encourages initial cooperation and adapts based on previous rounds.
    Players cooperate if the previous round met the cooperation threshold; otherwise, they defect.
    After a set number of consecutive defections, players cooperate again to test recovery.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0
        self.x = 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev = history.my_actions[prev_round]
        opp_prev = history.opponent_actions[prev_round]
        total_coop = my_prev + np.sum(opp_prev)
        m = self.game_description.m
        if total_coop >= m:
            self.consecutive_defections = 0
            return Action.C
        else:
            self.consecutive_defections += 1
            if self.consecutive_defections >= self.x:
                self.consecutive_defections = 0
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_72(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that balances cooperation and strategic defection.
    Cooperates in the first round, adapts based on previous cooperation in middle rounds,
    and defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.m = game_description.m
        self.n_rounds = game_description.n_rounds

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.n_rounds - 1:
            return Action.D
        else:
            prev_round = state.round_number - 1
            my_prev = history.my_actions[prev_round]
            opponent_prev = history.opponent_actions[prev_round]
            num_coop = my_prev + opponent_prev.sum()
            return Action.C if num_coop >= self.m else Action.D

class Strategy_COLLECTIVE_73(BaseStrategy):
    """
    A strategy that begins with cooperation and adjusts based on the collective cooperation in previous rounds.
    Cooperates if the minimum required cooperators were met in the previous round, otherwise defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_actions_prev = history.opponent_actions[prev_round]
        total_coop = my_prev_action + np.sum(opponent_actions_prev)
        if total_coop >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_74(BaseStrategy):
    """
    Responsive Cooperation with Immediate Punishment strategy.
    Cooperates initially and continues if the cooperation threshold was met in the previous round; otherwise, defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_last = history.my_actions[prev_round]
        opponent_last = history.opponent_actions[prev_round, :]
        total_coop = my_last + np.sum(opponent_last)
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_75(BaseStrategy):
    """
    Cooperative Punishment with Recovery strategy to maintain cooperation by punishing when the collective threshold isn't met.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.state = 'COOPERATE'

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        if history is None:
            return Action.D
        my_prev = history.my_actions[prev_round]
        opponent_prev = history.opponent_actions[prev_round, :]
        total_coop_prev = my_prev + opponent_prev.sum()
        if self.state == 'COOPERATE':
            if total_coop_prev >= self.game_description.m:
                action = Action.C
                new_state = 'COOPERATE'
            else:
                action = Action.D
                new_state = 'PUNISH'
        else:
            action = Action.C
            new_state = 'COOPERATE'
        self.state = new_state
        return action

class Strategy_COLLECTIVE_76(BaseStrategy):
    """
    Cooperative Restart with Bounded Retaliation strategy.
    Cooperates initially, continues if enough players cooperated, otherwise defects for a limited number of rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.ret_remaining = 0
        self.R = 1

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_prev_actions = history.opponent_actions[prev_round, :]
        n_coop_prev = sum(opponents_prev_actions) + my_prev_action
        if self.ret_remaining > 0:
            action = Action.D
            self.ret_remaining -= 1
        elif n_coop_prev >= self.game_description.m:
            action = Action.C
        else:
            action = Action.D
            self.ret_remaining = self.R
        return action

class Strategy_COLLECTIVE_77(BaseStrategy):
    """
    Adaptive Cooperation strategy with forgiveness for Collective Risk Dilemma.
    Cooperates initially, punishes once if cooperation threshold isn't met, then forgives.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        my_prev = history.my_actions[-1]
        opponent_prev = history.opponent_actions[-1, :]
        m = self.game_description.m
        total_coop = my_prev + opponent_prev.sum()
        if total_coop >= m:
            return Action.C
        elif not my_prev:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_78(BaseStrategy):
    """
    A strategy that begins by cooperating, continues to cooperate if the previous round had enough cooperation,
    otherwise defects as punishment. In the last round, it checks the trend of cooperation in the game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_coop_prev = history.my_actions[prev_round]
        opponent_coop_prev = np.sum(history.opponent_actions[prev_round, :])
        total_coop_prev = my_coop_prev + opponent_coop_prev
        if state.round_number == self.n_rounds - 1:
            total_m_met = 0
            for r in range(state.round_number):
                my_action = history.my_actions[r]
                opponent_actions = np.sum(history.opponent_actions[r, :])
                total_c = my_action + opponent_actions
                if total_c >= self.m:
                    total_m_met += 1
            if total_m_met >= state.round_number / 2:
                return Action.C
            else:
                return Action.D
        elif total_coop_prev >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_80(BaseStrategy):
    """
    A strategy that begins by Cooperating and adapts based on the number of Cooperators 
    in the previous round. If cooperation falls below the threshold for a set number 
    of consecutive rounds, it resets to Cooperate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defection_count = 0
        self.RESET_THRESHOLD = 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_coop = history.my_actions[previous_round]
        opponents_coop = np.sum(history.opponent_actions[previous_round, :])
        total_coop = opponents_coop + (1 if my_coop else 0)
        if total_coop >= self.game_description.m:
            self.consecutive_defection_count = 0
            return Action.C
        elif self.consecutive_defection_count < self.RESET_THRESHOLD:
            self.consecutive_defection_count += 1
            return Action.D
        else:
            self.consecutive_defection_count = 0
            return Action.C

class Strategy_COLLECTIVE_81(BaseStrategy):
    """
    Adaptive Cooperation with Punishment (ACP) Strategy.
    Cooperates initially, then continues if at least m players cooperate in previous round.
    Defects otherwise to enforce cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_prev = history.my_actions[-1]
        opponent_prev = history.opponent_actions[-1]
        sum_opponent = np.count_nonzero(opponent_prev)
        sum_my = 1 if my_prev else 0
        total_C = sum_opponent + sum_my
        if total_C >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_82(BaseStrategy):
    """
    Implements the Cooperate-Punish-Cooperate (CPC) strategy to maintain cooperation
    levels in a Collective Risk Dilemma. Players start by Cooperating, then adjust
    based on the previous round's cooperation, defecting if cooperation was insufficient
    and retrying cooperation thereafter.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_opponent_actions = history.opponent_actions[-1, :]
        opp_coop = sum(prev_opponent_actions)
        my_prev_action = history.my_actions[-1]
        prev_coop = opp_coop + (1 if my_prev_action else 0)
        if prev_coop >= self.game_description.m:
            return Action.C
        elif not my_prev_action:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_83(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that encourages cooperation 
    while penalizing insufficient cooperation and defecting in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_prev_actions = history.opponent_actions[prev_round, :]
        total_cooperators = int(my_prev_action) + sum(opponents_prev_actions)
        if total_cooperators >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_84(BaseStrategy):
    """
    Implements the 'Punish Once, Then Cooperate' strategy for the Collective Risk Dilemma.
    Players cooperate initially, defect once if cooperation previously fell below the threshold, 
    then resume cooperation regardless of subsequent outcomes.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punished = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.punished:
            return Action.C
        prev_my_action = history.my_actions[-1]
        prev_opp_actions = history.opponent_actions[-1]
        total_prev = prev_my_action + sum(prev_opp_actions)
        if total_prev < self.game_description.m:
            self.punished = True
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_85(BaseStrategy):
    """
    A strategy to address the Collective Risk Dilemma through initial cooperation,
    conditional cooperation based on past performance, and informed decision-making
    in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.n_rounds - 1:
            count_met = 0
            for round_num in range(state.round_number):
                opp_actions = history.opponent_actions[round_num]
                opp_coop = sum(opp_actions)
                my_coop = 1 if history.my_actions[round_num] else 0
                total_coop = opp_coop + my_coop
                if total_coop >= self.m:
                    count_met += 1
            if count_met > state.round_number / 2:
                return Action.C
            else:
                return Action.D
        else:
            previous_round = state.round_number - 1
            opp_actions_prev = history.opponent_actions[previous_round]
            opp_coop = sum(opp_actions_prev)
            my_coop_prev = 1 if history.my_actions[previous_round] else 0
            total_coop_prev = opp_coop + my_coop_prev
            if total_coop_prev >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_86(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy.
    Cooperates initially and continues if recent rounds were sufficiently successful.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        m = self.m
        current_round = state.round_number
        start = max(0, current_round - 3)
        recent_rounds = range(start, current_round)
        success_count = 0
        for r in recent_rounds:
            my_coop = history.my_actions[r]
            opponent_coop = np.sum(history.opponent_actions[r, :])
            total_coop = (1 if my_coop else 0) + opponent_coop
            if total_coop >= m:
                success_count += 1
        total_rounds = len(recent_rounds)
        success_rate = success_count / total_rounds if total_rounds > 0 else 0
        if success_rate >= 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_87(BaseStrategy):
    """
    A strategy designed to maintain cooperation while being responsive to failures.
    It initiates cooperation, continues if successful, punishes when cooperation fails,
    and forgives after one round of punishment.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_prev_actions = history.opponent_actions[prev_round, :]
        total_cooperators = my_prev_action + np.sum(opponent_prev_actions)
        success = total_cooperators >= self.game_description.m
        if not my_prev_action:
            return Action.C
        elif not success:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_88(BaseStrategy):
    """
    A strategy that promotes sustained cooperation by following these rules:
    1. Cooperate in the first round.
    2. In subsequent rounds, cooperate if at least `m` players cooperated in the previous round; otherwise, defect.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_actions_prev = history.opponent_actions[-1]
        my_prev_action = history.my_actions[-1]
        total_coop = sum(opponent_actions_prev) + my_prev_action
        if total_coop >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_89(BaseStrategy):
    """
    An adaptive strategy that balances cooperation with responses to collective outcomes.
    Cooperates initially, adapts based on past success, and cooperates in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.n_rounds - 1:
            return Action.C
        s = 0
        for round_idx in range(state.round_number):
            if history is None:
                my_action = False
            else:
                my_action = history.my_actions[round_idx]
            if history is not None:
                opponent_actions = history.opponent_actions[round_idx, :]
                num_coop = int(my_action) + opponent_actions.sum()
                if num_coop >= self.m:
                    s += 1
        ratio = s / state.round_number
        return Action.C if ratio >= 0.5 else Action.D

class Strategy_COLLECTIVE_90(BaseStrategy):
    """
    Adaptive Collective Cooperation strategy. Cooperates initially, adapts based on previous cooperation,
    and decides in the last round based on the average cooperation throughout the game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            total_coop = 0.0
            num_prev_rounds = state.round_number
            for r in range(num_prev_rounds):
                my_action = history.my_actions[r]
                opp_actions = history.opponent_actions[r]
                current_coop = 1 if my_action else 0
                current_coop += np.sum(opp_actions)
                total_coop += current_coop
            average_coop = total_coop / num_prev_rounds
            if average_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opp_prev_actions = history.opponent_actions[prev_round]
            coop_count = 1 if my_prev_action else 0
            coop_count += np.sum(opp_prev_actions)
            if coop_count >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_91(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that encourages sustained cooperation through punishment and forgiveness.
    Cooperates in the first round, continues if the previous round met the cooperation threshold, defects once if not, then 
    reverts to cooperation regardless of the outcome.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.next_must_cooperate = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif self.next_must_cooperate:
            self.next_must_cooperate = False
            return Action.C
        else:
            last_round = state.round_number - 1
            my_action_prev = history.my_actions[last_round]
            opponent_actions_prev = history.opponent_actions[last_round, :]
            cooperators = sum(opponent_actions_prev) + (1 if my_action_prev else 0)
            if cooperators >= self.game_description.m:
                return Action.C
            else:
                self.next_must_cooperate = True
                return Action.D

class Strategy_COLLECTIVE_92(BaseStrategy):
    """
    A strategy that starts with cooperation, then continues or adjusts based on previous cooperation rates.
    It defects when fewer than m players cooperate, planning to cooperate again next round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.next_should_cooperate = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.next_should_cooperate = False
            return Action.C
        if self.next_should_cooperate:
            self.next_should_cooperate = False
            return Action.C
        prev_round = state.round_number - 1
        prev_my_action = history.my_actions[prev_round]
        prev_opponent_actions = history.opponent_actions[prev_round]
        prev_coops = np.sum(prev_opponent_actions) + prev_my_action
        if prev_coops >= self.game_description.m:
            return Action.C
        else:
            self.next_should_cooperate = True
            return Action.D

class Strategy_COLLECTIVE_93(BaseStrategy):

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.current_strategy = Action.C
        self.last_switch_round = -1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        if self.last_switch_round == current_round - 1:
            return self.current_strategy
        total_cooperators = 0
        for r in range(current_round):
            my_action = history.my_actions[r]
            opponent_actions = history.opponent_actions[r, :]
            num_opponents_cooperating = np.sum(opponent_actions)
            total_cooperators += (1 if my_action else 0) + num_opponents_cooperating
        average = total_cooperators / current_round
        if average >= self.m:
            action = Action.C
        else:
            action = Action.D
        if action != self.current_strategy:
            self.current_strategy = action
            self.last_switch_round = current_round
        return action

class Strategy_COLLECTIVE_94(BaseStrategy):
    """
    Cooperative Reciprocity with Punishment Strategy.

    This strategy encourages cooperation by initially cooperating in the first round.
    Subsequent actions depend on the number of cooperators in the previous round.
    If at least m players cooperated, the player continues to cooperate; otherwise, they defect.
    The last round follows the same rule to maintain consistency.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            s_prev = state.round_number - 1
            my_prev = history.my_actions[s_prev]
            opponents_prev = history.opponent_actions[s_prev, :]
            total_coop = int(my_prev) + int(opponents_prev.sum())
            if total_coop >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_95(BaseStrategy):
    """
    Conditional Cooperation Strategy with Punishment and Reset.
    Cooperates if the previous round met the cooperation threshold, otherwise defects once.
    Resets to cooperation after defecting once due to failure.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            my_last = history.my_actions[-1]
            opponent_last = history.opponent_actions[-1]
            c_count = my_last + sum(opponent_last)
            if c_count >= self.m:
                return Action.C
            elif my_last:
                return Action.D
            else:
                return Action.C

class Strategy_COLLECTIVE_96(BaseStrategy):
    """
    This strategy promotes sustained cooperation in a repeated public goods game by leveraging past behavior and probabilistic resetting when necessary.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n = game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_c = 1 if history.my_actions[prev_round] else 0
            others_c = sum(history.opponent_actions[prev_round, :])
            total_c = my_c + others_c
            if total_c >= self.m:
                return Action.C
            else:
                p = self.m / self.n
                if random.random() < p:
                    return Action.C
                else:
                    return Action.D

class Strategy_COLLECTIVE_97(BaseStrategy):
    """
    Adaptive Cooperation with Punishment (ACP) strategy for Collective Risk Dilemma.
    Cooperates initially and in subsequent rounds if the previous round met the cooperation threshold.
    Defects if the threshold was not met in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opp_prev_actions = history.opponent_actions[prev_round, :]
        total_coop_prev = (1 if my_prev_action else 0) + sum(opp_prev_actions)
        m = self.game_description.m
        if total_coop_prev >= m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_98(BaseStrategy):
    """
    Implements the Adaptive Cooperation with Forgiveness strategy for the Collective Risk Dilemma.
    Cooperates initially, adapts based on previous cooperation levels, and allows occasional forgiveness.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        sum_opponent = sum(history.opponent_actions[-1, :])
        my_last_action = history.my_actions[-1]
        total_coop = sum_opponent + (1 if my_last_action else 0)
        if total_coop >= self.m:
            return Action.C
        elif random.random() < 0.1:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_99(BaseStrategy):
    """
    A strategy that starts with cooperation and then adapts based on the previous round's cooperation level.
    - Cooperates in the first round.
    - Cooperates again if the previous action was Defect.
    - Defects if the number of cooperators in the previous round was less than the required threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_my_action = history.my_actions[-1]
        if not last_my_action:
            return Action.C
        prev_me = history.my_actions[-1]
        prev_others = history.opponent_actions[-1, :]
        count_prev = int(prev_me) + np.sum(prev_others)
        if count_prev >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_100(BaseStrategy):
    """
    A strategy that starts with cooperation and continues if the minimum number 
    of cooperators is met; otherwise, it defects in the subsequent round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            my_last_action = history.my_actions[-1]
            opponents_last_actions = history.opponent_actions[-1]
            total_cooperators = my_last_action + sum(opponents_last_actions)
            if total_cooperators >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_101(BaseStrategy):
    """
    Adaptive Cooperation Strategy based on Previous Round's Performance.
    Cooperates in the first round and continues if sufficient players cooperated previously.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            previous_round = state.round_number - 1
            my_prev_action = history.my_actions[previous_round]
            opponent_prev_actions = history.opponent_actions[previous_round]
            count_coop = int(my_prev_action) + np.sum(opponent_prev_actions)
            if count_coop >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_102(BaseStrategy):
    """
    A strategy encouraging sustained cooperation in Collective Risk Dilemma games.
    Cooperates initially and if previous round met the cooperation threshold.
    Adapts to failures by probabilistically deciding to cooperate based on m/n.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_prev_action = history.my_actions[-1]
        opponents_prev_actions = history.opponent_actions[-1, :]
        cooperators_prev = my_prev_action + sum(opponents_prev_actions)
        if cooperators_prev >= self.game_description.m:
            return Action.C
        else:
            p = self.game_description.m / self.game_description.n_players
            if random.random() <= p:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_103(BaseStrategy):
    """
    A strategy that begins by cooperating and adapts based on the number of cooperators in previous rounds.
    If enough players cooperated in the previous round, it continues to cooperate. Otherwise, it defects but resets to cooperation after a patience period.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.patience = 2
        self.defects_in_a_row = 0

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_prev_actions = history.opponent_actions[prev_round, :]
        prev_coops = my_prev_action + np.sum(opponent_prev_actions)
        if prev_coops >= self.m:
            self.defects_in_a_row = 0
            return Action.C
        elif self.defects_in_a_row < self.patience:
            self.defects_in_a_row += 1
            return Action.D
        else:
            self.defects_in_a_row = 0
            return Action.C

class Strategy_COLLECTIVE_104(BaseStrategy):
    """
    Strategy to adapt cooperation based on recent success of meeting the minimum required cooperators.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.w = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opp_prev_actions = history.opponent_actions[prev_round, :]
        c_prev = my_prev_action + opp_prev_actions.sum()
        if c_prev >= self.game_description.m:
            return Action.C
        else:
            start_round = max(0, state.round_number - self.w)
            success_count = 0
            for r in range(start_round, state.round_number):
                my_action = history.my_actions[r]
                opp_actions = history.opponent_actions[r, :]
                c_r = my_action + opp_actions.sum()
                if c_r >= self.game_description.m:
                    success_count += 1
            p = success_count / self.w
            if random.random() < p:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_105(BaseStrategy):
    """
    A strategy that cooperates if the previous round met the cooperation threshold (m), 
    otherwise defects once before attempting to cooperate again.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_prev_actions = history.opponent_actions[prev_round]
        total_cooperators = my_prev_action + np.sum(opponent_prev_actions)
        if total_cooperators >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_106(BaseStrategy):
    """
    Implements the Group-Level Tit-for-Tat strategy for the Collective Risk Dilemma.
    Starts with cooperation and mirrors the group's behavior, cooperating if at least m players cooperated in the previous round, otherwise defecting.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_my_action = history.my_actions[-1]
        prev_opponent_actions = history.opponent_actions[-1, :]
        total_coop = prev_my_action + prev_opponent_actions.sum()
        if total_coop >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_107(BaseStrategy):
    """
    Adaptive Cooperation with Forgiveness (ACF) Strategy.
    Cooperates initially and continues if the cooperation threshold is met.
    Occasionally forgives and cooperates even when the threshold isn't met.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.epsilon = 0.05

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        opponent_coops = sum(history.opponent_actions[last_round, :])
        my_coop = history.my_actions[last_round]
        total_coops = opponent_coops + my_coop
        if total_coops >= self.m:
            return Action.C
        elif random.random() < self.epsilon:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_108(BaseStrategy):
    """
    Adaptive Cooperation with Punishment strategy for Collective Risk Dilemma.
    Cooperates initially and continues if the minimum number of cooperators is met.
    Defects as punishment when the threshold isn't met in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_action = history.my_actions[prev_round]
        opponent_actions_sum = np.sum(history.opponent_actions[prev_round, :])
        total_coop = opponent_actions_sum + (1 if my_action else 0)
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_109(BaseStrategy):
    """
    Adaptive Cooperative Punishment (ACP) strategy for the Collective Risk Dilemma.
    
    This strategy encourages cooperation and punishes non-cooperation adaptively.
    It cooperates initially, continues if cooperation is maintained, defects for a round as punishment if cooperation drops below the threshold,
    and adaptively reengages based on others' cooperation levels.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        n_rounds = self.game_description.n_rounds
        m = self.game_description.m
        if current_round == n_rounds - 1:
            pen_prev_round = current_round - 1
            me_pen_prev = history.my_actions[pen_prev_round]
            others_pen_prev = history.opponent_actions[pen_prev_round].sum()
            total_pen_prev = me_pen_prev + others_pen_prev
            if total_pen_prev >= m:
                return Action.C
            elif others_pen_prev + 1 >= m:
                return Action.C
            else:
                return Action.D
        else:
            prev_round = current_round - 1
            me_prev = history.my_actions[prev_round]
            others_prev = history.opponent_actions[prev_round].sum()
            total_prev = me_prev + others_prev
            if total_prev >= m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_110(BaseStrategy):
    """
    Cooperate if the previous round had at least m cooperators; otherwise, defect.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_my_action = history.my_actions[state.round_number - 1]
        prev_opponent_actions = history.opponent_actions[state.round_number - 1]
        sum_opponents = sum(prev_opponent_actions)
        total_coop = sum_opponents + (1 if prev_my_action else 0)
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_111(BaseStrategy):
    """
    Adaptive strategy for the Collective Risk Dilemma based on moving average success rate.
    Cooperates if recent success rates exceed a threshold; otherwise defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_rounds = game_description.n_rounds
        window_size = self.n_rounds // 2
        if window_size < 1:
            window_size = 1
        self.window_size = window_size
        self.alpha = 2.0 / (self.window_size + 1)
        self.threshold = 0.5
        self.average_success = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_actions_prev = history.opponent_actions[prev_round, :]
        sum_opponent_C = np.sum(opponent_actions_prev)
        my_C = 1 if my_prev_action else 0
        total_c = sum_opponent_C + my_C
        s = 1.0 if total_c >= self.game_description.m else 0.0
        if self.average_success is None:
            self.average_success = s
        else:
            self.average_success = self.alpha * s + (1 - self.alpha) * self.average_success
        if self.average_success > self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_112(BaseStrategy):
    """
    Adaptive Collective Cooperation strategy for the Collective Risk Dilemma.
    Cooperates in the first round, then continues if at least m players cooperated previously.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        else:
            previous_round = state.round_number - 1
            my_prev_action = history.my_actions[previous_round]
            opponents_prev_actions = history.opponent_actions[previous_round]
            total_coop = my_prev_action + np.sum(opponents_prev_actions)
            if total_coop >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_113(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that encourages cooperation
    by cooperating if the previous round met the minimum cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev_action = history.my_actions[previous_round]
        opponent_prev_actions = history.opponent_actions[previous_round, :]
        my_coop = 1 if my_prev_action else 0
        others_coop = np.sum(opponent_prev_actions)
        total_coop = my_coop + others_coop
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_114(BaseStrategy):
    """A strategy to foster sustained cooperation using adaptive punishment and recovery."""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev = history.my_actions[prev_round]
            if not my_prev:
                return Action.C
            else:
                opp_prev = history.opponent_actions[prev_round, :]
                total_coop = my_prev + np.sum(opp_prev)
                if total_coop >= self.game_description.m:
                    return Action.C
                else:
                    return Action.D

class Strategy_COLLECTIVE_115(BaseStrategy):
    """
    Adaptive Cooperate-and-Punish Strategy for Collective Risk Dilemma.

    This strategy encourages initial cooperation and includes a punishment mechanism 
    to enforce cooperation when the threshold is not met. Players cooperate if the 
    threshold is met in the previous round, otherwise they defect once and then 
    return to cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.must_cooperate = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.must_cooperate:
            action = Action.C
            self.must_cooperate = False
        else:
            my_prev = history.my_actions[-1]
            opp_prev = history.opponent_actions[-1, :]
            my_coop = 1 if my_prev else 0
            opp_coop = sum(opp_prev)
            num_coop_prev = my_coop + opp_coop
            if num_coop_prev >= self.game_description.m:
                action = Action.C
            else:
                action = Action.D
                self.must_cooperate = True
        return action

class Strategy_COLLECTIVE_116(BaseStrategy):
    """
    A strategy that attempts to sustain cooperation by punishing only once when the previous round had insufficient cooperation, 
    but then reverting in the next opportunity.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        m = self.game_description.m
        current_round = state.round_number
        prev_round = current_round - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_prev_actions = history.opponent_actions[prev_round]
        count_C_prev = int(my_prev_action) + np.sum(opponent_prev_actions)
        if count_C_prev >= m:
            return Action.C
        if current_round > 1:
            prev_prev_round = current_round - 2
            if prev_prev_round >= 0:
                my_prev_prev_action = history.my_actions[prev_prev_round]
                opponent_prev_prev_actions = history.opponent_actions[prev_prev_round]
                count_C_prev_prev = int(my_prev_prev_action) + np.sum(opponent_prev_prev_actions)
                if count_C_prev_prev >= m:
                    return Action.C
        return Action.D

class Strategy_COLLECTIVE_117(BaseStrategy):
    """
    A strategy that starts with cooperation and adapts based on the previous round's outcome.
    Continues to cooperate if successful, defects once if cooperation failed, and revisits
    cooperation after defecting.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round_idx = state.round_number - 1
        last_action = history.my_actions[last_round_idx]
        opponents_last = history.opponent_actions[last_round_idx, :]
        total_coop = last_action + opponents_last.sum()
        if last_action:
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_118(BaseStrategy):
    """
    A strategy that begins with cooperation, punishes insufficient cooperation,
    but forgives after a limited number of defections to restart cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_prev_actions = history.opponent_actions[prev_round, :]
        total_coop_prev = my_prev_action + np.sum(opponents_prev_actions)
        if total_coop_prev >= self.game_description.m:
            self.consecutive_defections = 0
            return Action.C
        elif self.consecutive_defections < 2:
            self.consecutive_defections += 1
            return Action.D
        else:
            self.consecutive_defections = 0
            return Action.C

class Strategy_COLLECTIVE_119(BaseStrategy):
    """
    Adaptive Collective Cooperation (ACC) strategy to sustain cooperation based on previous rounds.
    Cooperate initially, then continue if enough players cooperated in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev_action = history.my_actions[previous_round]
        sum_opponents = np.sum(history.opponent_actions[previous_round])
        total_coop = my_prev_action + sum_opponents
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_120(BaseStrategy):
    """
    Adaptive Cooperation with Punishment Reset Strategy.
    Cooperates initially, punishes when cooperation is insufficient, 
    then resets cooperation to encourage mutual participation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opponents_prev_actions = history.opponent_actions[prev_round]
            my_coop = 1 if my_prev_action else 0
            opp_coop = np.sum(opponents_prev_actions)
            total_coop = my_coop + opp_coop
            m = self.game_description.m
            if total_coop >= m:
                return Action.C
            elif my_prev_action:
                return Action.D
            else:
                return Action.C

class Strategy_COLLECTIVE_121(BaseStrategy):
    """
    Grim Trigger Strategy for Collective Risk Dilemma.
    
    Cooperates in the first round and continues to cooperate unless any previous round
    had fewer than m cooperators. If such a round exists, defects permanently.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            for t in range(state.round_number):
                my_coop = 1 if history.my_actions[t] else 0
                opp_coop = sum(history.opponent_actions[t, :])
                total_coop = my_coop + opp_coop
                if total_coop < self.m:
                    return Action.D
            return Action.C

class Strategy_COLLECTIVE_122(BaseStrategy):
    """
    A strategy that cooperates in the first round and continues to cooperate 
    if at least m players cooperated in the previous round; otherwise, defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_actions_prev = history.opponent_actions[prev_round, :]
        total_cooperators = my_prev_action + np.sum(opponent_actions_prev)
        if total_cooperators >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_123(BaseStrategy):
    """
    A strategy that combines responsiveness with patience to maintain cooperation
    in collective risk dilemmas. Players cooperate initially and adjust based on
    previous round outcomes, defecting temporarily when cooperation is low but
    restarting cooperation after a patience period.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.s = 2
        self.d = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev = history.my_actions[prev_round]
        opp_prev = history.opponent_actions[prev_round]
        total_coop_prev = int(my_prev) + int(sum(opp_prev))
        if total_coop_prev >= self.m:
            return Action.C
        else:
            self.d += 1
            if self.d >= self.s:
                self.d = 0
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_124(BaseStrategy):
    """
    Adaptive Cooperation with Punishment Strategy.
    Cooperates initially, then punishes once if insufficient cooperation,
    and resets to cooperate next.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_action = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.last_action = Action.C
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opponent_prev_actions = history.opponent_actions[prev_round, :]
            prev_coop = my_prev_action + sum(opponent_prev_actions)
            m = self.game_description.m
            if prev_coop >= m:
                action = Action.C
            elif self.last_action == Action.C:
                action = Action.D
            else:
                action = Action.C
            self.last_action = action
            return action

class Strategy_COLLECTIVE_125(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that adapts cooperation probability based on previous rounds' outcomes.
    Players start with a cooperation probability proportional to the ratio of minimum cooperators needed to total players.
    They adjust this probability by a small delta in response to whether the threshold of cooperation was met in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n_players = game_description.n_players
        self.p = self.m / self.n_players
        self.delta = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            if random.random() <= self.p:
                return Action.C
            else:
                return Action.D
        else:
            last_round = state.round_number - 1
            my_prev_action = history.my_actions[last_round]
            opponent_prev_actions = history.opponent_actions[last_round]
            total_coops = my_prev_action + np.sum(opponent_prev_actions)
            if total_coops < self.m:
                self.p += self.delta
            else:
                self.p -= self.delta
            self.p = np.clip(self.p, 0.0, 1.0)
            if random.random() <= self.p:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_126(BaseStrategy):
    """
    Cooperative Threshold Strategy: Cooperate if the number of cooperators in the previous round meets or exceeds the threshold m.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.m_threshold = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev_action = history.my_actions[previous_round]
        opponents_prev_actions = history.opponent_actions[previous_round]
        my_coop = 1 if my_prev_action else 0
        others_coop = np.sum(opponents_prev_actions)
        total_coop = my_coop + others_coop
        if total_coop >= self.m_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_127(BaseStrategy):
    """
    A strategy that balances punishment for insufficient cooperation with recovery attempts.
    Cooperates initially, continues if successful, defects if not, and attempts recovery after one defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number
        t_prev = t - 1
        my_prev_action = history.my_actions[t_prev]
        opponent_prev_actions = history.opponent_actions[t_prev, :]
        c_prev = 1 if my_prev_action else 0
        c_prev += np.sum(opponent_prev_actions)
        if c_prev >= self.m:
            return Action.C
        elif t_prev >= 1:
            t_prev_prev = t_prev - 1
            my_prev_prev_action = history.my_actions[t_prev_prev]
            opponent_prev_prev_actions = history.opponent_actions[t_prev_prev, :]
            c_prev_prev = 1 if my_prev_prev_action else 0
            c_prev_prev += np.sum(opponent_prev_prev_actions)
            if c_prev_prev < self.m:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_128(BaseStrategy):
    """
    A strategy based on historical success of collective cooperation in the Collective Risk Dilemma.
    The strategy starts with cooperation and adapts based on the success ratio of past rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        success_count = 0
        for t in range(state.round_number):
            my_action = history.my_actions[t]
            opponent_actions = history.opponent_actions[t]
            total_cooperators = my_action + np.sum(opponent_actions)
            if total_cooperators >= self.m:
                success_count += 1
        sr = success_count / state.round_number
        threshold = self.m / self.n_players
        if sr >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_129(BaseStrategy):
    """
    Adaptive Cooperation Strategy based on Historical Success.

    This strategy begins with cooperation and adapts based on the historical success
    of collective efforts. It switches to defection if cooperation proves ineffective.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n_rounds = self.game_description.n_rounds
        m = self.game_description.m
        if state.round_number == 0:
            return Action.C
        count_success = 0
        current_round = state.round_number
        for t in range(current_round):
            if history is not None:
                my_action = history.my_actions[t]
                opponents = history.opponent_actions[t, :]
                sum_c = my_action + np.sum(opponents)
                if sum_c >= m:
                    count_success += 1
        if current_round == n_rounds - 1:
            previous_rounds = current_round
            majority = previous_rounds // 2 + 1
            if count_success >= majority:
                return Action.C
            else:
                return Action.D
        else:
            cooperation_rate = count_success / current_round
            if cooperation_rate >= 0.5:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_130(BaseStrategy):
    """
    A strategy to encourage cooperation in the Collective Risk Dilemma game.
    Cooperates initially and continues if sufficient players cooperated previously,
    defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        n_rounds = self.game_description.n_rounds
        if current_round == n_rounds - 1:
            return Action.D
        previous_round = current_round - 1
        my_prev_action = history.my_actions[previous_round]
        opponent_actions = history.opponent_actions[previous_round, :]
        coop_count = sum(opponent_actions) + (1 if my_prev_action else 0)
        if coop_count >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_131(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that promotes sustained cooperation.
    It cooperates in the first round and continues to cooperate as long as the minimum 
    number of cooperators (m) was met in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            own_action = history.my_actions[prev_round]
            opponent_actions = history.opponent_actions[prev_round, :]
            total_cooperative = own_action + np.sum(opponent_actions)
            if total_cooperative >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_132(BaseStrategy):
    """
    A strategy that balances cooperation with defection and forgiveness to maintain sufficient cooperation levels.
    Cooperates initially and continues if cooperation meets the threshold, defects otherwise but forgives after one defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_defected = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.last_defected = False
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_prev_actions = history.opponent_actions[prev_round, :]
        prev_coop = sum(opponents_prev_actions) + (1 if my_prev_action else 0)
        m = self.game_description.m
        if prev_coop >= m:
            self.last_defected = False
            return Action.C
        elif self.last_defected:
            self.last_defected = False
            return Action.C
        else:
            self.last_defected = True
            return Action.D

class Strategy_COLLECTIVE_134(BaseStrategy):
    """
    An adaptive cooperation strategy that transitions based on the success of recent rounds.
    Cooperates initially and adapts by examining the last three rounds to decide future actions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            t = state.round_number
            w = min(3, t)
            lower = max(0, t - w)
            success_count = 0
            for r in range(lower, t):
                my_coop = history.my_actions[r]
                opp_coops = sum(history.opponent_actions[r])
                total_coop = my_coop + opp_coops
                if total_coop >= self.game_description.m:
                    success_count += 1
            p = success_count / w
            if p > 0.5:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_135(BaseStrategy):
    """
    Cooperative Punishment with Sustained Cooperation Strategy.
    Cooperates in the first round. In subsequent rounds, cooperates if at least m players
    cooperated in the previous round; otherwise, defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            opponent_actions_prev = history.opponent_actions[prev_round, :]
            opponent_coops = np.sum(opponent_actions_prev)
            my_prev_action = history.my_actions[prev_round]
            total_coops = opponent_coops + (1 if my_prev_action else 0)
            if total_coops >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_137(BaseStrategy):
    """
    A reactive strategy that cooperates initially and in subsequent rounds if the number 
    of cooperators in the previous round met the required threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        opponents_last_round = history.opponent_actions[prev_round]
        opponents_coop = np.sum(opponents_last_round)
        my_last = history.my_actions[prev_round]
        total_coop = opponents_coop + my_last
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_138(BaseStrategy):
    """
    Adaptive Cooperation with Forgiveness strategy. 
    Starts by cooperating, then adapts based on the number of cooperators in previous rounds.
    Forgiveness mechanism resets to cooperation after a set number of consecutive defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        super().__init__(game_description)
        self.game_description = game_description
        self.m = game_description.m
        self.consecutive_defects = 0
        self.consecutive_defects_threshold = 1

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if history is None or state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev_action = history.my_actions[previous_round]
        opponent_prev_actions = history.opponent_actions[previous_round]
        coop_prev = my_prev_action + np.sum(opponent_prev_actions)
        if coop_prev >= self.m:
            self.consecutive_defects = 0
            return Action.C
        else:
            self.consecutive_defects += 1
            if self.consecutive_defects >= self.consecutive_defects_threshold:
                self.consecutive_defects = 0
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_139(BaseStrategy):
    """A strategy that promotes cooperation with responsive punishment and forgiveness."""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.post_punish = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.post_punish:
            self.post_punish = False
            return Action.C
        prev_round = state.round_number - 1
        my_prev = history.my_actions[prev_round]
        my_C = 1 if my_prev else 0
        opponents_prev = history.opponent_actions[prev_round, :]
        opponents_C = np.sum(opponents_prev)
        sum_coop_prev = my_C + opponents_C
        if sum_coop_prev < self.game_description.m:
            self.post_punish = True
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_140(BaseStrategy):
    """
    Grim Trigger Strategy for Collective Risk Dilemma.
    Cooperates unless any previous round had fewer than m cooperators.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        for s in range(state.round_number):
            my_act = history.my_actions[s]
            opponent_coop = np.sum(history.opponent_actions[s])
            total = int(my_act) + opponent_coop
            if total < self.m:
                return Action.D
        return Action.C

class Strategy_COLLECTIVE_141(BaseStrategy):
    """
    Adaptive Cooperation with Forgiveness Strategy for Collective Risk Dilemma.

    Cooperates initially, adapts based on previous cooperation levels, punishes
    when cooperation is too low, and sometimes forgives to re-initiate cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.punishment_remaining = 0
        self.forgiveness_prob = 0.1

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.punishment_remaining > 0:
            if random.random() < self.forgiveness_prob:
                self.punishment_remaining = 0
                return Action.C
            else:
                self.punishment_remaining -= 1
                return Action.D
        my_last_action = history.my_actions[-1]
        opponents_last_actions = history.opponent_actions[-1]
        total_coop_last = sum([my_last_action]) + sum(opponents_last_actions)
        if total_coop_last >= self.m:
            return Action.C
        else:
            self.punishment_remaining = 2
            return Action.D

class Strategy_COLLECTIVE_142(BaseStrategy):

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.recent_actions = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == self.game_description.n_rounds - 1:
            if history is None:
                return Action.C
            count = 0
            for prev_round_idx in range(state.round_number):
                my_prev = history.my_actions[prev_round_idx]
                opponent_prev = history.opponent_actions[prev_round_idx]
                prev_coop = my_prev + opponent_prev.sum()
                if prev_coop >= self.game_description.m:
                    count += 1
            total_rounds = state.round_number
            if count >= (total_rounds + 1) / 2:
                return Action.C
            else:
                return Action.D
        elif state.round_number == 0:
            action = Action.C
        else:
            prev_round = state.round_number - 1
            my_prev = history.my_actions[prev_round]
            opponent_prev = history.opponent_actions[prev_round]
            prev_coop = my_prev + opponent_prev.sum()
            if prev_coop >= self.game_description.m:
                action = Action.C
            elif any((a == Action.D for a in self.recent_actions)):
                action = Action.C
            else:
                action = Action.D
        self.recent_actions.append(action)
        if len(self.recent_actions) > 2:
            self.recent_actions = self.recent_actions[-2:]
        return action

class Strategy_COLLECTIVE_143(BaseStrategy):
    """
    Responsive Cooperation with Reset Mechanism:
    Cooperates initially and continues if threshold met. Defects if below, resetting cooperation after one defect.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_successful_round = None
        self.s = 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t_prev = state.round_number - 1
        my_action_prev = history.my_actions[t_prev]
        opponent_actions_prev = history.opponent_actions[t_prev]
        total_coop_prev = my_action_prev + np.sum(opponent_actions_prev)
        if total_coop_prev >= self.game_description.m:
            self.last_successful_round = t_prev
            return Action.C
        else:
            last_success = self.last_successful_round
            if last_success is not None:
                start_round = last_success + 1
                end_round = t_prev
            else:
                start_round = 0
                end_round = t_prev
            action_slice = history.my_actions[start_round:end_round + 1]
            consecutive_defections = np.sum(~action_slice)
            if consecutive_defections >= self.s:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_144(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that:
    - Cooperates in the first and last rounds.
    - Cooperates in subsequent rounds if at least m players cooperated in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        prev_round = state.round_number - 1
        my_coop = history.my_actions[prev_round]
        opponents_coop = sum(history.opponent_actions[prev_round, :])
        total_coop = my_coop + opponents_coop
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_145(BaseStrategy):
    """
    Adaptive Cooperation with Resilience (ACR) strategy for Collective Risk Dilemma.
    Cooperates initially and continues if enough players cooperate; defects for up to
    two consecutive rounds if cooperation threshold isn't met, then attempts to
    cooperate again.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_prev_actions = history.opponent_actions[prev_round, :]
        count_prev = my_prev_action + np.sum(opponents_prev_actions)
        m = self.game_description.m
        if count_prev >= m:
            self.consecutive_defections = 0
            return Action.C
        elif self.consecutive_defections < 2:
            self.consecutive_defections += 1
            return Action.D
        else:
            self.consecutive_defections = 0
            return Action.C

class Strategy_COLLECTIVE_146(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that starts with cooperation and adapts based on previous outcomes.
    It punishes when cooperation levels are too low but forgives after one round of defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_action = history.my_actions[state.round_number - 1]
        if not prev_action:
            return Action.C
        last_round = state.round_number - 1
        opp_actions = history.opponent_actions[last_round]
        s_prev = np.sum(opp_actions) + prev_action
        if s_prev >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_147(BaseStrategy):
    """A strategy designed to enforce cooperation in the Collective Risk Dilemma through reciprocation and punishment."""

    def __init__(self, game_description: CollectiveRiskDescription):
        """Initialize the strategy with the game description and state variables."""
        self.game_description = game_description
        self.last_action_was_punishment = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        """Determine the action based on the game state and history."""
        if state.round_number == 0:
            self.last_action_was_punishment = False
            return Action.C
        elif self.last_action_was_punishment:
            self.last_action_was_punishment = False
            return Action.C
        else:
            prev_t = state.round_number - 1
            my_prev_action = history.my_actions[prev_t]
            opponent_prev_actions = history.opponent_actions[prev_t, :]
            total_coop_prev = sum(opponent_prev_actions) + (1 if my_prev_action else 0)
            if total_coop_prev >= self.game_description.m:
                return Action.C
            else:
                self.last_action_was_punishment = True
                return Action.D

class Strategy_COLLECTIVE_149(BaseStrategy):
    """
    Adaptive Cooperation with Forgiveness Strategy for Collective Risk Dilemma.
    Cooperates initially then adapts based on previous round's cooperation level.
    If previous round met the cooperation threshold, Cooperates again; else Defects.
    Forgiveness allows re-initiating cooperation after temporary defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev = history.my_actions[prev_round]
        opponent_actions = history.opponent_actions[prev_round]
        sum_opponents = np.sum(opponent_actions)
        total_coop = my_prev + sum_opponents
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_150(BaseStrategy):
    """
    A strategy that begins with cooperation and adapts based on the success of previous rounds.
    Cooperates if the previous round met the cooperation threshold; otherwise, alternates actions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        my_last_action = history.my_actions[last_round]
        opponent_actions_last_round = history.opponent_actions[last_round, :]
        n_coop = sum(opponent_actions_last_round) + (1 if my_last_action else 0)
        if n_coop >= self.m:
            return Action.C
        else:
            return Action.D if my_last_action else Action.C

class Strategy_COLLECTIVE_151(BaseStrategy):
    """
    Implements a Win-Stay, Lose-Switch strategy for the Collective Risk Dilemma.
    Players start by cooperating, then adjust based on whether the previous round met the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev = history.my_actions[prev_round]
        opp_prev = history.opponent_actions[prev_round]
        coop_opp = np.sum(opp_prev)
        total_coop = coop_opp + (1 if my_prev else 0)
        m = self.game_description.m
        if total_coop >= m:
            new_action = my_prev
        else:
            new_action = not my_prev
        return Action.C if new_action else Action.D

class Strategy_COLLECTIVE_152(BaseStrategy):
    """
    Conditional Cooperation with Recovery strategy.

    Cooperate initially. In subsequent rounds, cooperate if the previous round had at least m cooperators.
    If not, defect but switch back to cooperating after two consecutive defections to attempt recovery.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0
        self.s = 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_my_action = history.my_actions[state.round_number - 1]
        prev_opp_actions = history.opponent_actions[state.round_number - 1]
        prev_coop = prev_my_action + sum(prev_opp_actions)
        m = self.game_description.m
        if prev_coop >= m:
            self.consecutive_defections = 0
            return Action.C
        elif self.consecutive_defections >= self.s:
            self.consecutive_defections = 0
            return Action.C
        else:
            self.consecutive_defections += 1
            return Action.D

class Strategy_COLLECTIVE_153(BaseStrategy):
    """
    Adaptive Cooperativity Strategy for Collective Risk Dilemma.
    
    - Cooperate in the first round to encourage initial cooperation.
    - Cooperate in subsequent rounds if the previous round met the minimum cooperation threshold.
    - In the last round, cooperate if the majority of previous rounds met the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            sum_coops = 0
            for s in range(state.round_number):
                my_action = history.my_actions[s]
                opponents = history.opponent_actions[s]
                total_coops = my_action + sum(opponents)
                if total_coops >= self.game_description.m:
                    sum_coops += 1
            threshold = state.round_number // 2 + 1
            return Action.C if sum_coops >= threshold else Action.D
        else:
            s = state.round_number - 1
            my_action = history.my_actions[s]
            opponents = history.opponent_actions[s]
            total_coops = my_action + sum(opponents)
            return Action.C if total_coops >= self.game_description.m else Action.D

class Strategy_COLLECTIVE_155(BaseStrategy):
    """
    Adaptive Cooperating with Forgiveness (ACF) strategy for the Collective Risk Dilemma.
    Cooperates initially, then defects for up to two consecutive rounds if cooperation is insufficient,
    and resets cooperation afterward.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.defect_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t_prev = state.round_number - 1
        my_prev_action = history.my_actions[t_prev]
        opponents_prev = history.opponent_actions[t_prev]
        prev_coop = my_prev_action + sum(opponents_prev)
        if prev_coop >= self.m:
            self.defect_streak = 0
            return Action.C
        elif self.defect_streak < 2:
            self.defect_streak += 1
            return Action.D
        else:
            self.defect_streak = 0
            return Action.C

class Strategy_COLLECTIVE_156(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma that encourages sustained cooperation
    while being resilient against various opponent behaviors.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        prev_my_action = history.my_actions[prev_round]
        prev_opponent_actions = history.opponent_actions[prev_round]
        coop_from_others = np.sum(prev_opponent_actions)
        coop_count = coop_from_others + (1 if prev_my_action else 0)
        if coop_count >= self.m:
            return Action.C
        else:
            return Action.D if random.random() < 0.5 else Action.C

class Strategy_COLLECTIVE_157(BaseStrategy):
    """
    Adaptive Cooperate-Punish-Forgive Strategy for Collective Risk Dilemma.

    The strategy starts with cooperation, continues if the cooperation threshold is met,
    defects if not, and resets to cooperation after two consecutive rounds of insufficient cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        last_my_action = history.my_actions[-1]
        last_opponent_actions = history.opponent_actions[-1]
        last_coop = last_my_action + np.sum(last_opponent_actions)
        consecutive_defections = 0
        if len(history.my_actions) >= 2:
            second_last_my_action = history.my_actions[-2]
            second_last_opponent_actions = history.opponent_actions[-2]
            second_last_coop = second_last_my_action + np.sum(second_last_opponent_actions)
            if last_coop < self.game_description.m and second_last_coop < self.game_description.m:
                consecutive_defections = 2
        if last_coop >= self.game_description.m or consecutive_defections >= 2:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_158(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy:
    Cooperates unconditionally in the first round. For subsequent rounds, considers the outcomes of the last 3 rounds,
    cooperating if cooperation met the threshold in at least half (rounded up) of these rounds. Switches back to cooperation
    after 2 consecutive defections to test potential revival of cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.s = 3
        self.d = 2
        self.consecutive_defects = 0

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.consecutive_defects >= self.d:
            action = Action.C
            self.consecutive_defects = 0
        else:
            success_count = 0
            start_round = max(0, state.round_number - self.s)
            end_round = state.round_number - 1
            for r in range(start_round, end_round + 1):
                my_action = history.my_actions[r]
                opponents = history.opponent_actions[r, :]
                total_c = int(my_action) + np.sum(opponents)
                if total_c >= self.game_description.m:
                    success_count += 1
            threshold = math.ceil(self.s / 2)
            if success_count >= threshold:
                action = Action.C
            else:
                action = Action.D
        if action == Action.D:
            self.consecutive_defects += 1
        else:
            self.consecutive_defects = 0
        return action

class Strategy_COLLECTIVE_159(BaseStrategy):
    """
    This strategy implements a cooperative approach in the Collective Risk Dilemma game. 
    Players start by cooperating in the first round. In subsequent rounds, they continue to 
    cooperate if at least m players cooperated in the previous round; otherwise, they defect.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        opponents_coop = sum(history.opponent_actions[prev_round])
        my_coop = 1 if history.my_actions[prev_round] else 0
        total_coop = opponents_coop + my_coop
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_160(BaseStrategy):
    """
    A strategy that encourages cooperation based on the success of previous rounds.
    Cooperates initially and continues if the cooperation threshold is met.
    Defects if the threshold is not met in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            previous_round = state.round_number - 1
            my_prev_action = history.my_actions[previous_round]
            opponents_prev_actions = history.opponent_actions[previous_round, ...]
            total_coop = sum(opponents_prev_actions) + (1 if my_prev_action else 0)
            if total_coop >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_161(BaseStrategy):
    """
    A strategy that encourages cooperation while being resilient to occasional defections.
    It punishes defection by defecting for a set number of rounds and then tries to cooperate again.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.max_consecutive_defects = 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        m = self.m
        max_cons_defects = self.max_consecutive_defects
        r = state.round_number - 1
        my_last_action = history.my_actions[r]
        opponent_last_actions = history.opponent_actions[r]
        c_last = int(my_last_action) + opponent_last_actions.sum()
        if c_last >= m:
            return Action.C
        else:
            defect_count = 0
            i = r - 1
            while defect_count <= max_cons_defects and i >= 0:
                my_act = history.my_actions[i]
                opp_act = history.opponent_actions[i]
                c_current = int(my_act) + opp_act.sum()
                if c_current < m:
                    defect_count += 1
                    if defect_count >= max_cons_defects + 1:
                        break
                else:
                    break
                i -= 1
            if defect_count >= max_cons_defects + 1:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_162(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that balances cooperation and punishment.
    It includes phases for initial cooperation, exploration, monitoring, and final round decisions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.initial_rounds = game_description.n_rounds // 10

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number < self.initial_rounds:
            return Action.C
        if random.random() < 0.1:
            return Action.C
        final_start = self.game_description.n_rounds - self.initial_rounds
        if state.round_number >= final_start:
            total_rounds = state.round_number
            if total_rounds == 0:
                return Action.C
            successful = 0
            for rnd in range(total_rounds):
                n_coop = sum(history.opponent_actions[rnd, :]) + (1 if history.my_actions[rnd] else 0)
                if n_coop >= self.game_description.m:
                    successful += 1
            if successful / total_rounds >= 0.5:
                return Action.C
            else:
                return Action.D
        elif state.round_number == 0:
            return Action.C
        else:
            last_round = state.round_number - 1
            n_coop = sum(history.opponent_actions[last_round, :]) + (1 if history.my_actions[last_round] else 0)
            if n_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_163(BaseStrategy):
    """
    A strategy that adapts based on the number of cooperators in the previous round.
    Cooperates in the first round to establish cooperation. In subsequent rounds,
    cooperates if the number of cooperators in the previous round met or exceeded
    the required threshold m; otherwise, defects. Maintains consistency in the
    last round to uphold cooperation throughout the game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_prev_actions = history.opponent_actions[prev_round, :]
        prev_coop = my_prev_action + opponents_prev_actions.sum()
        if prev_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_164(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that starts with cooperation and adapts based on past success.
    Players cooperate initially and continue if a sufficient proportion of past rounds met the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number
        S = 0
        for r in range(t):
            my_action = history.my_actions[r]
            opponent_actions = history.opponent_actions[r]
            total_coop = my_action + np.sum(opponent_actions)
            if total_coop >= self.m:
                S += 1
        threshold = 0.5
        proportion = S / t
        if proportion >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_165(BaseStrategy):
    """
    Adaptive Cooperative Restart (ACR) Strategy.

    This strategy encourages cooperation by restarting cooperation after a few
    consecutive defections. It starts with cooperation, continues if enough
    players cooperate, and defects otherwise. If defection occurs twice in a
    row, it restarts cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.failure_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_opp_actions = history.opponent_actions[-1]
            sum_opp = np.sum(prev_opp_actions)
            my_prev = history.my_actions[-1]
            total_coop_prev = sum_opp + my_prev
            if total_coop_prev >= self.game_description.m:
                self.failure_counter = 0
                return Action.C
            else:
                self.failure_counter += 1
                if self.failure_counter >= 2:
                    self.failure_counter = 0
                    return Action.C
                else:
                    return Action.D

class Strategy_COLLECTIVE_166(BaseStrategy):
    """
    A strategy that addresses the Collective Risk Dilemma by promoting sustained cooperation
    through adaptive behavior based on previous rounds' outcomes. Cooperates initially and in
    successful rounds, defects as a punishment otherwise.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        prev_opponent_actions = history.opponent_actions[last_round]
        sum_opponents = np.sum(prev_opponent_actions)
        my_last_action = history.my_actions[last_round]
        sum_coops = sum_opponents + my_last_action
        if sum_coops >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_167(BaseStrategy):
    """
    Adaptive Cooperation with Defection Reset (ACDR) Strategy.
    
    The strategy begins by cooperating in the first round. In subsequent rounds, it cooperates if the number of cooperators in the previous round meets or exceeds a threshold (m). If not, it defects but resets to cooperation after three consecutive defections to encourage potential future cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperate = True
        self.consecutive_defects = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_prev_actions = history.opponent_actions[prev_round]
        prev_coop = int(my_prev_action) + np.sum(opponent_prev_actions)
        m = self.game_description.m
        if prev_coop >= m:
            self.consecutive_defects = 0
            self.cooperate = True
            return Action.C
        else:
            if self.cooperate:
                self.consecutive_defects = 1
                self.cooperate = False
            else:
                self.consecutive_defects += 1
                if self.consecutive_defects >= 3:
                    self.cooperate = True
                    self.consecutive_defects = 0
            return Action.D

class Strategy_COLLECTIVE_168(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game. It cooperates in the first round,
    cooperates again if at least m players cooperated in the previous round, and defects
    in the last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n_rounds = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.n_rounds - 1:
            return Action.D
        else:
            last_round = state.round_number - 1
            my_prev_action = history.my_actions[last_round]
            opp_prev_actions = history.opponent_actions[last_round]
            count = my_prev_action + opp_prev_actions.sum()
            if count >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_169(BaseStrategy):
    """
    Cooperate initially; continue cooperating if previous round met quota, else defect.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_my_action = history.my_actions[-1]
        my_coop = 1 if prev_my_action else 0
        opp_coop = np.sum(history.opponent_actions[-1, :])
        total_coop = my_coop + opp_coop
        m = self.game_description.m
        if total_coop >= m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_170(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that promotes cooperation and punishes defection.
    Players cooperate initially and continue if the previous round met the cooperation threshold.
    If not, they defect as punishment. After a punishment round, cooperation resumes.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        opponent_actions_prev = history.opponent_actions[prev_round, :]
        my_prev = history.my_actions[prev_round]
        total_prev = np.sum(opponent_actions_prev) + (1 if my_prev else 0)
        m = self.game_description.m
        if total_prev >= m:
            return Action.C
        elif total_prev == 0:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_171(BaseStrategy):
    """
    A strategy that begins with cooperation and adapts based on previous rounds.
    Cooperates if the previous round met the threshold of minimum cooperators (m), 
    otherwise defects in the current round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_actions_prev = history.opponent_actions[prev_round, :]
        total_coops = 1 if my_prev_action else 0
        total_coops += np.sum(opponent_actions_prev)
        if total_coops >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_172(BaseStrategy):
    """
    Adaptive Cooperation with Recovery Strategy for the Collective Risk Dilemma.
    Cooperates initially and continues if sufficient cooperation was observed; otherwise, cooperates with 50% probability.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            my_coop = 1 if my_prev_action else 0
            opponents_prev = history.opponent_actions[prev_round, :]
            opponents_coop = sum(opponents_prev)
            total_coop = my_coop + opponents_coop
            if total_coop >= self.m:
                return Action.C
            else:
                return Action.C if random.random() < 0.5 else Action.D

class Strategy_COLLECTIVE_173(BaseStrategy):
    """
    A strategy that initially cooperates, continues if previous round's cooperation meets 
    threshold m, otherwise defects until enough others cooperate again.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.is_punishing = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opp_actions_prev = history.opponent_actions[prev_round]
        if self.is_punishing:
            others_coop_prev = sum(opp_actions_prev)
            if others_coop_prev >= self.game_description.m:
                self.is_punishing = False
                return Action.C
            else:
                return Action.D
        else:
            total_coop_prev = sum(opp_actions_prev) + (1 if my_prev_action else 0)
            if total_coop_prev >= self.game_description.m:
                return Action.C
            else:
                self.is_punishing = True
                return Action.D

class Strategy_COLLECTIVE_175(BaseStrategy):
    """
    Adaptive Collective Cooperation (ACC) strategy to encourage sustained cooperation.
    Cooperates initially and adapts based on the number of previous round cooperators.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev_action = history.my_actions[previous_round]
        opponent_actions = history.opponent_actions[previous_round, :]
        num_opponent_coop = sum(opponent_actions)
        total_coop = num_opponent_coop + (1 if my_prev_action else 0)
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_176(BaseStrategy):
    """
    A strategy that cooperates in the first round and continues to cooperate if at least m players 
    cooperated in the previous round; otherwise, it defects. This strategy encourages sustained 
    cooperation when possible while responding to insufficient participation by defecting.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        my_last_action = history.my_actions[last_round]
        opponent_actions_last = history.opponent_actions[last_round]
        total_cooperators = int(my_last_action) + sum(opponent_actions_last)
        if total_cooperators >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_177(BaseStrategy):
    """
    A strategy that begins with cooperation, then cooperates if the previous round met the cooperator threshold. 
    If not, it defects for a fixed number of rounds before resuming cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.x = 2
        self.defect_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        if history is None:
            return Action.C
        my_coop = history.my_actions[prev_round]
        opponent_coop = sum(history.opponent_actions[prev_round])
        total_coop = my_coop + opponent_coop
        if total_coop >= self.m:
            self.defect_counter = 0
            return Action.C
        elif self.defect_counter < self.x:
            self.defect_counter += 1
            return Action.D
        else:
            self.defect_counter = 0
            return Action.C

class Strategy_COLLECTIVE_178(BaseStrategy):
    """
    This strategy starts by cooperating to set a positive tone. In subsequent rounds, 
    it cooperates if at least two of the last three rounds met the cooperation threshold; 
    otherwise, it defects. This adaptivity encourages group success while protecting against exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            current_round = state.round_number
            num_rounds_to_consider = min(3, current_round)
            start_round = max(0, current_round - num_rounds_to_consider)
            met_count = 0
            for r in range(start_round, current_round):
                my_action = history.my_actions[r]
                opponents_actions = history.opponent_actions[r]
                num_coop = 1 if my_action else 0
                num_coop += np.sum(opponents_actions)
                if num_coop >= self.game_description.m:
                    met_count += 1
            if met_count >= 2:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_179(BaseStrategy):
    """
    A strategy designed for the Collective Risk Dilemma game. It encourages sustained cooperation by starting with cooperation, 
    punishing when the collective threshold isn't met, and attempting recovery after defecting once.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_last_action = history.my_actions[previous_round]
        if not my_last_action:
            return Action.C
        my_last_c = int(my_last_action)
        opponent_coops = history.opponent_actions[previous_round, :].sum()
        total_coops = my_last_c + opponent_coops
        if total_coops >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_180(BaseStrategy):
    """
    A strategy that starts with cooperation, punishes when cooperation is insufficient, 
    and forgives to return to cooperation afterwards.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.must_cooperate_next = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.must_cooperate_next = False
            return Action.C
        if self.must_cooperate_next:
            self.must_cooperate_next = False
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_prev_actions = history.opponent_actions[prev_round]
        total_C_prev = int(my_prev_action) + int(opponents_prev_actions.sum())
        if total_C_prev >= self.game_description.m:
            return Action.C
        else:
            self.must_cooperate_next = True
            return Action.D

class Strategy_COLLECTIVE_181(BaseStrategy):
    """
    Responsive Cooperation with Forgiveness Strategy.
    
    This strategy starts by cooperating. In subsequent rounds, it cooperates if the 
    number of cooperators in the previous round met the threshold. If not, it defects 
    but periodically resets to attempt cooperation again after a set number of defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0
        self.forgiveness_threshold = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev = history.my_actions[previous_round]
        opp_prev = history.opponent_actions[previous_round, :]
        coop_count = my_prev + np.sum(opp_prev)
        if coop_count >= self.game_description.m:
            self.consecutive_defections = 0
            return Action.C
        else:
            self.consecutive_defections += 1
            if self.consecutive_defections >= self.forgiveness_threshold:
                self.consecutive_defections = 0
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_182(BaseStrategy):
    """
    Adaptive Collective Cooperation Strategy.

    This strategy starts by cooperating in the first round. In subsequent rounds,
    it decides whether to cooperate or defect based on the historical success rate
    of collective cooperation. If a majority of past rounds were successful (>=60%),
    it continues to cooperate. If not, it defects. After defecting for two consecutive
    rounds, it reverts to cooperation if the recent success rate has improved.
    In the last round, it cooperates if the majority of previous rounds were successful.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        game_params = self.game_description
        if current_round == 0:
            return Action.C
        is_last_round = current_round == game_params.n_rounds - 1
        if is_last_round:
            success_count = 0
            for rd in range(current_round):
                opponent_actions = history.opponent_actions[rd, :]
                sum_opponent = sum(opponent_actions)
                my_action = history.my_actions[rd]
                total_coop = sum_opponent + (1 if my_action else 0)
                if total_coop >= game_params.m:
                    success_count += 1
            success_rate = success_count / current_round if current_round != 0 else 0.0
            if success_rate >= 0.5:
                return Action.C
            else:
                return Action.D
        else:
            success_count = 0
            for rd in range(current_round):
                opponent_actions = history.opponent_actions[rd, :]
                sum_opponent = sum(opponent_actions)
                my_action = history.my_actions[rd]
                total_coop = sum_opponent + (1 if my_action else 0)
                if total_coop >= game_params.m:
                    success_count += 1
            total_rounds = current_round
            if total_rounds == 0:
                success_rate = 0.0
            else:
                success_rate = success_count / total_rounds
            if success_rate >= 0.6:
                return Action.C
            else:
                consecutive_d = 0
                for rd in reversed(range(len(history.my_actions))):
                    if not history.my_actions[rd]:
                        consecutive_d += 1
                    else:
                        break
                if consecutive_d >= 2:
                    recent_success = 0
                    start_round = max(0, len(history.my_actions) - 2)
                    for rd in range(start_round, len(history.my_actions)):
                        opponent_actions_rd = history.opponent_actions[rd, :]
                        sum_opponent_rd = sum(opponent_actions_rd)
                        my_action_rd = history.my_actions[rd]
                        total_coop_rd = sum_opponent_rd + (1 if my_action_rd else 0)
                        if total_coop_rd >= game_params.m:
                            recent_success += 1
                    recent_rounds = len(history.my_actions) - start_round
                    if recent_rounds == 0:
                        recent_success_rate = 0.0
                    else:
                        recent_success_rate = recent_success / recent_rounds
                    if recent_success_rate > success_rate:
                        return Action.C
                    else:
                        return Action.D
                else:
                    return Action.D
        return Action.D

class Strategy_COLLECTIVE_183(BaseStrategy):
    """
    Cooperative Punishment with Forgiveness Strategy.

    This strategy promotes cooperation by rewarding it and briefly punishing defection,
    encouraging sustained collective success while maximizing individual payoffs in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            last_round = state.round_number - 1
            my_prev_action = history.my_actions[last_round]
            my_prev_coop = 1 if my_prev_action else 0
            opponent_actions = history.opponent_actions[last_round]
            opponent_coop = np.sum(opponent_actions)
            total_coop_prev = my_prev_coop + opponent_coop
            if total_coop_prev >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_185(BaseStrategy):
    """
    A strategy that starts with cooperation and uses a punishment mechanism
    to maintain cooperation. If the previous round met the cooperation threshold,
    the player continues to cooperate. Otherwise, they defect and return to
    cooperation in the next round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.next_must_cooperate = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif self.next_must_cooperate:
            self.next_must_cooperate = False
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev = history.my_actions[prev_round]
            opp_prev = history.opponent_actions[prev_round, :]
            total_coop = my_prev + sum(opp_prev)
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                self.next_must_cooperate = True
                return Action.D

class Strategy_COLLECTIVE_186(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that encourages cooperation 
    through initial cooperation, punishment for non-compliance, and reset 
    after punishment rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_my_action = history.my_actions[state.round_number - 1]
        prev_opponent_actions = history.opponent_actions[state.round_number - 1, :]
        prev_coop_count = sum(prev_opponent_actions) + (1 if prev_my_action else 0)
        if prev_coop_count == 0:
            return Action.C
        elif prev_coop_count >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_187(BaseStrategy):
    """
    A strategy designed to maintain cooperation in the Collective Risk Dilemma game.
    It cooperates in the first round, and in subsequent rounds, it cooperates if the previous round met the cooperation threshold,
    otherwise it defects but plans to cooperate again in the next round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.force_cooperate = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.force_cooperate:
            self.force_cooperate = False
            return Action.C
        t_prev = state.round_number - 1
        my_prev_action = history.my_actions[t_prev]
        opponents_prev_actions = history.opponent_actions[t_prev]
        num_cooperators = int(my_prev_action) + sum(opponents_prev_actions)
        if num_cooperators >= self.game_description.m:
            return Action.C
        else:
            self.force_cooperate = True
            return Action.D

class Strategy_COLLECTIVE_188(BaseStrategy):
    """
    Collective Strategy for the Collective Risk Dilemma.
    Cooperates initially and adapts based on average cooperation rate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number
        total_coop = 0.0
        for round_number in range(t):
            my_action = int(history.my_actions[round_number])
            opponents = history.opponent_actions[round_number, :]
            opponents_coop = np.sum(opponents)
            total_coop += my_action + opponents_coop
        avg_coop_rate = total_coop / (self.game_description.n_players * t)
        threshold = self.game_description.m / self.game_description.n_players
        if avg_coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_189(BaseStrategy):
    """
    Cooperate in the first round. For subsequent rounds, cooperate if at least m players cooperated in the previous round; otherwise, defect.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            previous_round = state.round_number - 1
            my_prev_action = history.my_actions[previous_round]
            opponents_prev_actions = history.opponent_actions[previous_round, :]
            count_coop = my_prev_action + opponents_prev_actions.sum()
            if count_coop >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_190(BaseStrategy):
    """
    A strategy where players cooperate by default. If the number of cooperators in the previous round 
    was below the threshold m, they defect once and then revert to cooperation in the subsequent round 
    regardless of the outcome.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_defected = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.last_defected:
            self.last_defected = False
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_actions_prev = history.opponent_actions[prev_round, :]
        n_coop = my_prev_action + opponent_actions_prev.sum()
        threshold = self.game_description.m
        if n_coop < threshold:
            self.last_defected = True
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_191(BaseStrategy):
    """
    A strategy that encourages cooperation and adapts based on previous outcomes.
    Cooperates initially, then adapts based on the previous round's outcome.
    Switches to defecting if cooperation didn't yield the desired reward,
    and returns to cooperation after defecting without receiving the reward.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_action = history.my_actions[-1]
        prev_payoff = history.my_payoffs[-1]
        if prev_action:
            if math.isclose(prev_payoff, self.game_description.k, rel_tol=1e-09):
                return Action.C
            else:
                return Action.D
        else:
            expected_payoff = 1 + self.game_description.k
            if math.isclose(prev_payoff, expected_payoff, rel_tol=1e-09):
                return Action.D
            else:
                return Action.C

class Strategy_COLLECTIVE_193(BaseStrategy):
    """
    Adaptive Collective Cooperation Strategy.
    Cooperates initially, punishes non-cooperation once, and safeguards endgame.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.punished = False
        self.endgame_cutoff = self.n_rounds - math.ceil(0.1 * self.n_rounds)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round >= self.endgame_cutoff:
            return Action.C
        if self.punished:
            self.punished = False
            return Action.C
        sum_coop = 0
        n = self.n_players
        for s in range(current_round):
            my_action = history.my_actions[s]
            opponents = history.opponent_actions[s, :]
            coop = 1 if my_action else 0
            coop += np.sum(opponents)
            sum_coop += coop
        avg_coop = sum_coop / (current_round * n)
        threshold = self.m / self.n_players
        if avg_coop >= threshold:
            return Action.C
        else:
            self.punished = True
            return Action.D

class Strategy_COLLECTIVE_194(BaseStrategy):
    """
    Adaptive Cooperation with Punishment and Re-entry Strategy for Collective Risk Dilemma.
    
    The strategy starts by cooperating. In subsequent rounds, it continues to cooperate if the previous round met the minimum cooperation threshold.
    If the threshold was not met, it defects and considers re-entry based on the average cooperation over the last few rounds.
    In the last round, it cooperates if the majority of previous rounds met the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.t = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if current_round == self.n_rounds - 1:
            met_count = 0
            for r in range(current_round):
                my_action = history.my_actions[r]
                opponents = history.opponent_actions[r]
                total = sum(opponents) + my_action
                if total >= self.m:
                    met_count += 1
            total_prev_rounds = current_round
            if met_count / total_prev_rounds >= 0.5:
                return Action.C
            else:
                return Action.D
        else:
            prev_round = current_round - 1
            my_prev = history.my_actions[prev_round]
            opp_prev = history.opponent_actions[prev_round]
            prev_total = sum(opp_prev) + my_prev
            if prev_total >= self.m:
                return Action.C
            else:
                window_size = min(self.t, current_round)
                window_start = max(0, current_round - window_size)
                total_coop = 0.0
                for r in range(window_start, current_round):
                    my_act = history.my_actions[r]
                    opp_acts = history.opponent_actions[r]
                    total_coop += sum(opp_acts) + my_act
                if window_size == 0:
                    return Action.D
                avg_coop = total_coop / window_size
                if avg_coop >= self.m:
                    return Action.C
                else:
                    return Action.D

class Strategy_COLLECTIVE_195(BaseStrategy):
    """
    A strategy based on Collective Reciprocity, encouraging cooperation while adapting to group behavior.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        my_action = history.my_actions[last_round]
        opponent_actions = history.opponent_actions[last_round]
        total_cooperators = sum(opponent_actions) + (1 if my_action else 0)
        if total_cooperators >= self.game_description.m:
            return Action.C
        elif total_cooperators > 0:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_196(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that promotes cooperation 
    by meeting the minimum threshold in early rounds and defecting briefly 
    when cooperation is insufficient, while ensuring maximum cooperation 
    in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        prev_round = state.round_number - 1
        my_prev = history.my_actions[prev_round]
        opponents_prev = history.opponent_actions[prev_round]
        n_coop = sum(opponents_prev) + (1 if my_prev else 0)
        if n_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_197(BaseStrategy):
    """
    This strategy encourages cooperation in a Collective Risk Dilemma by reciprocating cooperation when a threshold is met,
    punishing failures, and attempting recovery after punishment.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_defected_because_threshold = False

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opp_prev_actions = history.opponent_actions[prev_round]
        my_coop = 1 if my_prev_action else 0
        opp_coop = np.sum(opp_prev_actions)
        total_coop = my_coop + opp_coop
        if self.last_defected_because_threshold:
            self.last_defected_because_threshold = False
            return Action.C
        elif total_coop >= self.game_description.m:
            return Action.C
        else:
            self.last_defected_because_threshold = True
            return Action.D

class Strategy_COLLECTIVE_198(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that begins with cooperation, 
    adapts based on previous round outcomes to encourage sustained cooperation, 
    and defects in the final round to maximize individual payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            t_prev = state.round_number - 1
            my_prev_action = history.my_actions[t_prev]
            opponent_prev_actions = history.opponent_actions[t_prev, :]
            prev_cooperators = my_prev_action + int(sum(opponent_prev_actions))
            if prev_cooperators >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_199(BaseStrategy):
    """
    Adaptive Cooperation Strategy based on historical success.
    Cooperates initially and continues if success rate meets or exceeds 50%.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            success_count = 0
            for t in range(state.round_number):
                opponents_coop = sum(history.opponent_actions[t])
                my_action = history.my_actions[t]
                total_coop = opponents_coop + (1 if my_action else 0)
                if total_coop >= self.game_description.m:
                    success_count += 1
            success_rate = success_count / state.round_number
            return Action.C if success_rate >= 0.5 else Action.D

class Strategy_COLLECTIVE_200(BaseStrategy):
    """
    A strategy to maintain cooperation in a Collective Risk Dilemma by balancing responsiveness with recovery,
    encouraging sustained cooperative behavior through initial cooperation, responsive actions, limited retaliation,
    and recovery attempts.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        my_coop = history.my_actions[last_round]
        opponent_coops = np.sum(history.opponent_actions[last_round])
        total_coop = my_coop + opponent_coops
        if total_coop >= self.game_description.m:
            self.consecutive_defections = 0
            return Action.C
        elif self.consecutive_defections < 2:
            self.consecutive_defections += 1
            return Action.D
        else:
            self.consecutive_defections = 0
            return Action.C

class Strategy_COLLECTIVE_201(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that promotes sustained cooperation.
    Players cooperate initially and continue if enough players cooperated previously. 
    If cooperation drops below the threshold, they defect once then attempt to cooperate again.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_last_action = history.my_actions[-1]
        if not my_last_action:
            return Action.C
        s_me = 1 if my_last_action else 0
        s_others = np.sum(history.opponent_actions[-1, :])
        s_total = s_me + s_others
        if s_total >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_202(BaseStrategy):
    """
    Responsive Cooperation with Punishment (RCP) strategy.
    
    - Cooperate in the first round.
    - In subsequent rounds, cooperate if at least m players cooperated in the previous round, otherwise defect.
    - Reenter cooperation once sufficient players cooperate again.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_prev_actions = history.opponent_actions[prev_round]
        my_coop = 1 if my_prev_action else 0
        opp_coop = np.sum(opponents_prev_actions)
        total_coop = my_coop + opp_coop
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_203(BaseStrategy):
    """A strategy for the Collective Risk Dilemma game that balances cooperation with adaptability.
    
    The strategy starts by Cooperating in the first round. For subsequent rounds, it looks back at the last 
    3 rounds and Cooperates if at least one round met the cooperation threshold (m). Otherwise, it Defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.window = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        start = max(0, current_round - self.window)
        end = current_round - 1
        for r in range(start, end + 1):
            my_coop = history.my_actions[r]
            opponent_coop = np.sum(history.opponent_actions[r])
            total_coop = my_coop + opponent_coop
            if total_coop >= self.game_description.m:
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_204(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that initially cooperates and 
    continues to cooperate if enough players cooperated in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        my_last_action = history.my_actions[last_round]
        opponent_last_actions = history.opponent_actions[last_round]
        total_coops = my_last_action + sum(opponent_last_actions)
        if total_coops >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_205(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that encourages sustained cooperation by defecting once if the 
    previous round's cooperation level was below the threshold, then reverting to cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.in_recovery = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.in_recovery:
            self.in_recovery = False
            return Action.C
        last_round = state.round_number - 1
        my_action = history.my_actions[last_round]
        opp_actions = history.opponent_actions[last_round]
        count = int(my_action) + int(sum(opp_actions))
        if count < self.game_description.m:
            self.in_recovery = True
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_206(BaseStrategy):
    """
    Adaptive strategy to encourage cooperation in the Collective Risk Dilemma.
    Cooperates initially, punishes non-cooperation, and forgives after consecutive defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.x = 3
        self.consecutive_Ds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_prev_action = history.my_actions[-1]
        my_prev = 1 if my_prev_action else 0
        opponent_prev_actions = history.opponent_actions[-1, :]
        sum_opponent_prev = np.sum(opponent_prev_actions)
        S_prev = my_prev + sum_opponent_prev
        if S_prev >= self.m:
            self.consecutive_Ds = 0
            return Action.C
        else:
            self.consecutive_Ds += 1
            if self.consecutive_Ds < self.x:
                return Action.D
            else:
                self.consecutive_Ds = 0
                return Action.C

class Strategy_COLLECTIVE_207(BaseStrategy):
    """
    A reactive strategy for the Collective Risk Dilemma game. Players cooperate in the first round and then base their decision on the number of cooperators in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t_prev = state.round_number - 1
        my_prev_action = history.my_actions[t_prev]
        opponent_prev_actions = history.opponent_actions[t_prev, :]
        sum_others = np.sum(opponent_prev_actions)
        total_coop = sum_others + (1 if my_prev_action else 0)
        if total_coop >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_208(BaseStrategy):
    """
    This strategy starts by Cooperating in the first round. 
    For each subsequent round, it Cooperates if the number of Cooperators 
    in the previous round was at least m; otherwise, it Defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            my_prev = history.my_actions[-1]
            opponent_actions_prev = history.opponent_actions[-1, :]
            sum_opponents = np.sum(opponent_actions_prev)
            total_C = sum_opponents + my_prev
            m = self.game_description.m
            if total_C >= m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_209(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that adapts based on previous cooperation.
    Cooperates in the first round and continues if at least m players cooperated previously.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev_action = bool(history.my_actions[prev_round])
            others_actions = history.opponent_actions[prev_round]
            sum_others = np.sum(others_actions)
            total_coop = int(my_prev_action) + sum_others
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_210(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that balances cooperation with adaptability.
    Cooperates initially, then adapts based on the proportion of successful previous rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        met_threshold = 0
        n_rounds = state.round_number
        for prev_round in range(n_rounds):
            my_action = history.my_actions[prev_round]
            opponent_actions = history.opponent_actions[prev_round, :]
            total_coop = my_action + int(opponent_actions.sum())
            if total_coop >= self.game_description.m:
                met_threshold += 1
        proportion_met = met_threshold / n_rounds
        if proportion_met > 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_211(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma where players cooperate if 
    at least half of previous rounds met the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number
        s_count = 0
        m = self.game_description.m
        for s in range(t):
            opponents_coop = sum(history.opponent_actions[s, :])
            me_coop = int(history.my_actions[s])
            total_coop = opponents_coop + me_coop
            if total_coop >= m:
                s_count += 1
        threshold = t / 2
        if s_count >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_212(BaseStrategy):
    """
    An adaptive strategy that balances cooperation based on the previous round's participation.
    Cooperates initially, continues if sufficient cooperation was met, otherwise defects with high probability
    but retaining a small chance to reseed cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        sum_opponents = sum(history.opponent_actions[prev_round])
        my_prev = 1 if history.my_actions[prev_round] else 0
        total_coop = sum_opponents + my_prev
        m = self.game_description.m
        if total_coop >= m:
            return Action.C
        elif random.random() < 0.1:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_213(BaseStrategy):
    """
    Strategy that cooperates in the first round and in subsequent rounds if at least m players cooperated in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_coop = history.my_actions[prev_round]
            opp_coops = history.opponent_actions[prev_round, :]
            total_coop = my_coop + opp_coops.sum()
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_214(BaseStrategy):
    """
    Adaptive Collective Reciprocity strategy implementation.
    Cooperates initially, adapts based on previous round's cooperation, and evaluates history in the last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.n_rounds - 1:
            previous_rounds = state.round_number
            total_coop_count = 0
            for round_num in range(previous_rounds):
                my_action = history.my_actions[round_num]
                opponents_actions = history.opponent_actions[round_num, :]
                my_coop = 1 if my_action else 0
                opponents_coop = sum(opponents_actions)
                total_coop = my_coop + opponents_coop
                if total_coop >= self.m:
                    total_coop_count += 1
            if total_coop_count * 2 > previous_rounds:
                return Action.C
            else:
                return Action.D
        else:
            prev_round = state.round_number - 1
            my_action_prev = history.my_actions[prev_round]
            opponents_prev_round = history.opponent_actions[prev_round, :]
            my_coop_prev = 1 if my_action_prev else 0
            opponents_coop_prev = sum(opponents_prev_round)
            total_coop_prev = my_coop_prev + opponents_coop_prev
            if total_coop_prev >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_215(BaseStrategy):
    """
    Implements a Conditional Cooperation with Forgiveness strategy. Starts by cooperating, continues if cooperation meets the threshold, defects when it doesn't, but forgives and cooperates again after one defection to allow recovery.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_last_action = history.my_actions[prev_round]
        opponent_actions_prev = history.opponent_actions[prev_round]
        opponent_coop_prev = sum(opponent_actions_prev)
        total_coop_prev = opponent_coop_prev + (1 if my_last_action else 0)
        if total_coop_prev >= self.game_description.m:
            return Action.C
        elif not my_last_action:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_216(BaseStrategy):
    """
    A strategy that encourages initial cooperation and adapts based on the previous round's cooperation level.
    Cooperates if the previous round met the cooperation threshold, else randomly cooperates or defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_last_action = history.my_actions[prev_round]
            opponents_last_actions = history.opponent_actions[prev_round, :]
            opponents_coop = np.sum(opponents_last_actions)
            total_coop = opponents_coop + (1 if my_last_action else 0)
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.C if random.random() < 0.5 else Action.D

class Strategy_COLLECTIVE_217(BaseStrategy):
    """
    A strategy that starts with cooperation, punishes defection for a fixed number of rounds, 
    and then attempts to reset cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defect_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.defect_remaining > 0:
            action = Action.D
            self.defect_remaining -= 1
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opponent_prev_actions = history.opponent_actions[prev_round, :]
            count_C = my_prev_action + sum(opponent_prev_actions)
            if count_C < self.game_description.m:
                self.defect_remaining = 2
                action = Action.D
            else:
                action = Action.C
        return action

class Strategy_COLLECTIVE_218(BaseStrategy):
    """
    Cooperate-Punish-Repeat Strategy: Cooperates initially and in subsequent rounds
    if enough players cooperated in the previous round. Otherwise, it defects
    to encourage cooperation recovery.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            previous_round = state.round_number - 1
            my_action = history.my_actions[previous_round]
            opponent_actions = history.opponent_actions[previous_round]
            total_coop = sum(opponent_actions) + (1 if my_action else 0)
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_219(BaseStrategy):
    """
    Implements the Responsive Cooperation with Punishment (RCP) strategy.
    Cooperates initially and in subsequent rounds based on the success of previous rounds.
    Defects once after a failure to maintain cooperation, then resumes cooperating if subsequent rounds succeed.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev = history.my_actions[prev_round]
        others_prev = np.sum(history.opponent_actions[prev_round, :])
        total_coop_prev = my_prev + others_prev
        if total_coop_prev >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_220(BaseStrategy):
    """
    A strategy designed for the Collective Risk Dilemma game. 
    It encourages cooperation by punishing defectors for a set number of rounds and then retrying cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.s = game_description.m - 1
        self.failure_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        my_last_action = history.my_actions[last_round]
        opponents_last_actions = history.opponent_actions[last_round, :]
        num_coop = int(my_last_action) + opponents_last_actions.sum()
        if num_coop >= self.m:
            self.failure_counter = 0
            return Action.C
        else:
            self.failure_counter += 1
            if self.failure_counter == self.s:
                self.failure_counter = 0
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_224(BaseStrategy):
    """
    A strategy where players cooperate if the minimum number of cooperators was met in the previous round, otherwise defect.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_action_prev = history.my_actions[previous_round]
        opponent_actions_prev = history.opponent_actions[previous_round, :]
        sum_coop = my_action_prev + np.sum(opponent_actions_prev)
        if sum_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_227(BaseStrategy):
    """
    A strategy that begins with cooperation and adapts based on previous round outcomes to encourage meeting the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n = game_description.n_players
        self.m = game_description.m

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        my_prev = history.my_actions[-1]
        opp_prev = history.opponent_actions[-1, :]
        total_coop = my_prev + opp_prev.sum()
        if total_coop >= self.m:
            return Action.C
        else:
            p = self.m / self.n
            if random.random() < p:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_228(BaseStrategy):
    """
    The Adaptive Cooperative Threshold (ACT) strategy for the Collective Risk Dilemma.
    Cooperates in the first round, then reciprocates based on the previous round's cooperation level.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            previous_round = state.round_number - 1
            my_prev = history.my_actions[previous_round]
            opponents_prev = history.opponent_actions[previous_round, :]
            total_coop = my_prev + sum(opponents_prev)
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_229(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that encourages sustained cooperation 
    by conditioning future actions on the number of previous cooperators.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_last_action = history.my_actions[prev_round]
        opponents_last_actions = history.opponent_actions[prev_round, :]
        total_coop = sum(opponents_last_actions)
        if my_last_action:
            total_coop += 1
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_230(BaseStrategy):
    """
    Cooperative Punishment with Recovery Strategy.
    Cooperates initially and responds to cooperation levels,
    entering punishment phases when cooperation is too low,
    but recovering quickly if cooperation resumes.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.is_punishing = False
        self.punishment_remaining = 0
        self.p = 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev_action = history.my_actions[previous_round]
        opponent_prev_actions = history.opponent_actions[previous_round, :]
        total_coop_prev = my_prev_action + np.sum(opponent_prev_actions)
        if self.is_punishing:
            action = Action.D
            self.punishment_remaining -= 1
            if total_coop_prev >= self.game_description.m:
                self.is_punishing = False
                self.punishment_remaining = 0
            elif self.punishment_remaining <= 0:
                self.is_punishing = False
        elif total_coop_prev >= self.game_description.m:
            action = Action.C
        else:
            action = Action.D
            self.is_punishing = True
            self.punishment_remaining = self.p
        return action

class Strategy_COLLECTIVE_231(BaseStrategy):
    """
    A strategy to maintain cooperation with recovery from temporary low cooperation.
    Cooperates initially and continues if enough players cooperated in the previous round.
    Defects temporarily if cooperation falls below the threshold, then reverts.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0
        self.p = 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        others_prev_actions = history.opponent_actions[prev_round]
        total_coops_prev = sum(others_prev_actions) + (1 if my_prev_action else 0)
        if total_coops_prev >= self.game_description.m:
            self.consecutive_defections = 0
            return Action.C
        else:
            self.consecutive_defections += 1
            if self.consecutive_defections >= self.p:
                self.consecutive_defections = 0
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_232(BaseStrategy):
    """
    Adaptive Cooperation with Punishment Strategy for the Collective Risk Dilemma.
    Cooperates initially, defects if cooperation threshold isn't met, then reverts to cooperation.
    Handles end game by considering rounds near the end.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punished_last_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        if self.punished_last_round:
            self.punished_last_round = False
            return Action.C
        prev_round = state.round_number - 1
        prev_my_action = history.my_actions[prev_round]
        prev_opp_actions = history.opponent_actions[prev_round, :]
        total_coops = sum(prev_opp_actions) + (1 if prev_my_action else 0)
        if total_coops >= self.game_description.m:
            return Action.C
        else:
            self.punished_last_round = True
            return Action.D

class Strategy_COLLECTIVE_233(BaseStrategy):
    """
    A strategy that starts with cooperation and adapts based on the number of cooperators in the previous round.
    Cooperates if the previous round had at least m cooperators; otherwise, defects but attempts to cooperate again next round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_prev_actions = history.opponent_actions[prev_round]
        opponent_c = np.sum(opponent_prev_actions)
        total_coop = int(my_prev_action) + opponent_c
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_234(BaseStrategy):
    """
    Promotes sustained cooperation by initially cooperating and adapting based on previous outcomes.
    Cooperates if at least m players cooperated last round, otherwise defects. If defected last round, cooperates next.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            last_round = state.round_number - 1
            my_last = history.my_actions[last_round]
            if not my_last:
                return Action.C
            else:
                coop_count = int(my_last) + np.sum(history.opponent_actions[last_round, :])
                if coop_count >= self.game_description.m:
                    return Action.C
                else:
                    return Action.D

class Strategy_COLLECTIVE_235(BaseStrategy):
    """A strategy balancing cooperation and probabilistic defection based on past outcomes."""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.p = 1.0 / self.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opp_prev_actions = history.opponent_actions[prev_round]
        total_coop_prev = my_prev_action + sum(opp_prev_actions)
        if total_coop_prev >= self.m:
            return Action.C
        elif random.random() < self.p:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_236(BaseStrategy):
    """
    A strategy that starts with cooperation and continues if the previous round met the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n_players = game_description.n_players
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_last_action = history.my_actions[-1]
        last_opponents = history.opponent_actions[-1, :]
        opponent_coops = sum(last_opponents)
        total_coop = opponent_coops + (1 if my_last_action else 0)
        if total_coop >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_237(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that promotes cooperation
    while adapting to previous outcomes, with punishment for defection and
    informed decision-making in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_left = 0

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        n_rounds = self.game_description.n_rounds
        m = self.game_description.m
        if state.round_number == 0:
            return Action.C
        if state.round_number == n_rounds - 1:
            previous_rounds = state.round_number
            successful = 0
            for t in range(previous_rounds):
                sum_o = np.sum(history.opponent_actions[t])
                my_c = history.my_actions[t]
                total_coop = sum_o + (1 if my_c else 0)
                if total_coop >= m:
                    successful += 1
            if successful > previous_rounds / 2:
                return Action.C
            else:
                return Action.D
        elif self.punishment_left > 0:
            self.punishment_left -= 1
            return Action.D
        else:
            t_prev = state.round_number - 1
            sum_o = np.sum(history.opponent_actions[t_prev])
            my_c = history.my_actions[t_prev]
            total_coop = sum_o + (1 if my_c else 0)
            if total_coop >= m:
                return Action.C
            else:
                self.punishment_left = 2
                return Action.D

class Strategy_COLLECTIVE_238(BaseStrategy):
    """
    Strategy to maintain cooperation in a repeated Collective Risk Dilemma by punishing non-cooperation 
    once and then giving cooperation another chance.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t_prev = state.round_number - 1
        my_prev_act = history.my_actions[t_prev]
        opponent_acts = history.opponent_actions[t_prev, :]
        c = my_prev_act + np.sum(opponent_acts)
        if c >= self.game_description.m:
            return Action.C
        elif not my_prev_act:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_239(BaseStrategy):
    """
    Adaptive Collective Cooperation Strategy with Reset.

    This strategy begins by cooperating, then adapts based on previous round outcomes.
    Players cooperate if the previous round met the cooperation threshold; otherwise, they defect.
    After three consecutive defections, players reset and cooperate again.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.reset_threshold = 3
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_action = history.my_actions[prev_round]
            opponent_actions = history.opponent_actions[prev_round, :]
            total_coop_last_round = my_action + sum(opponent_actions)
            if total_coop_last_round >= self.m:
                self.consecutive_defections = 0
                return Action.C
            else:
                self.consecutive_defections += 1
                if self.consecutive_defections >= self.reset_threshold:
                    self.consecutive_defections = 0
                    return Action.C
                else:
                    return Action.D

class Strategy_COLLECTIVE_240(BaseStrategy):
    """
    An adaptive cooperation strategy that punishes once after insufficient cooperation,
    then reverts back to cooperation to encourage collective success.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.force_next_coop = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.force_next_coop = False
            return Action.C
        if self.force_next_coop:
            self.force_next_coop = False
            return Action.C
        my_prev_action = history.my_actions[-1]
        opp_prev_actions = history.opponent_actions[-1, :]
        total_coop_prev = my_prev_action + opp_prev_actions.sum()
        m = self.game_description.m
        if total_coop_prev >= m:
            return Action.C
        else:
            self.force_next_coop = True
            return Action.D

class Strategy_COLLECTIVE_241(BaseStrategy):
    """
    A strategy that cooperates initially and switches to defecting forever if in any round the number of cooperators is below the threshold m.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        for t in range(state.round_number):
            my_coop = 1 if history.my_actions[t] else 0
            opp_coops = history.opponent_actions[t].sum()
            total_coop = my_coop + opp_coops
            if total_coop < self.m:
                return Action.D
        t_last = state.round_number - 1
        my_coop_last = 1 if history.my_actions[t_last] else 0
        opp_coops_last = history.opponent_actions[t_last].sum()
        total_coop_last = my_coop_last + opp_coops_last
        if total_coop_last >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_242(BaseStrategy):
    """
    A deterministic strategy to promote cooperation in a repeated Collective Risk Dilemma.
    Cooperates initially, continues if threshold met, defects if not, and forgives after two failures.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_failures = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_prev_actions = history.opponent_actions[prev_round]
        prev_cooperators = my_prev_action + np.sum(opponent_prev_actions)
        m = self.game_description.m
        last_met = prev_cooperators >= m
        if last_met or self.consecutive_failures >= 2:
            self.consecutive_failures = 0
            return Action.C
        else:
            self.consecutive_failures += 1
            return Action.D

class Strategy_COLLECTIVE_243(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that encourages cooperation by reacting to past outcomes.
    It starts by cooperating, then continues or restarts cooperation based on the collective behavior observed.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.ever_met_threshold = False
        self.will_cooperate_next_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.will_cooperate_next_round:
            self.will_cooperate_next_round = False
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opp_prev_actions = history.opponent_actions[prev_round, :]
        c_prev = int(my_prev_action) + int(np.sum(opp_prev_actions))
        if c_prev >= self.game_description.m:
            self.ever_met_threshold = True
            return Action.C
        elif self.ever_met_threshold:
            self.will_cooperate_next_round = True
            return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_244(BaseStrategy):
    """
    Adaptive Cooperation with Reset (ACR) strategy for Collective Risk Dilemma.
    Cooperates initially, continues if enough players cooperate, otherwise defects
    with a reset mechanism after consecutive defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defect_rounds = 0
        self.s = 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.consecutive_defect_rounds = 0
            return Action.C
        prev_round = state.round_number - 1
        prev_my_c = history.my_actions[prev_round]
        prev_others_c = history.opponent_actions[prev_round].sum()
        total_prev_coop = prev_my_c + prev_others_c
        if total_prev_coop >= self.game_description.m:
            self.consecutive_defect_rounds = 0
            return Action.C
        else:
            self.consecutive_defect_rounds += 1
            if self.consecutive_defect_rounds >= self.s:
                self.consecutive_defect_rounds = 0
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_245(BaseStrategy):
    """
    A strategy promoting cooperation through reciprocity and punishment. 
    It starts by cooperating, then cooperates if a sufficient number 
    of players cooperated in the previous round; otherwise, it defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_my_action = history.my_actions[-1]
        previous_coop = sum(history.opponent_actions[-1])
        total_coop = previous_coop + (1 if previous_my_action else 0)
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_247(BaseStrategy):
    """
    Adaptive Collective Cooperation with Forgiveness (ACCF) Strategy.

    Cooperates initially and in subsequent rounds if the previous round met the cooperation threshold.
    Defects for up to f=3 consecutive rounds when the threshold isn't met, then forgives and Cooperates.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_failures = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        my_prev_action = history.my_actions[-1]
        prev_others_actions = history.opponent_actions[-1, :]
        sum_coop_prev = my_prev_action + prev_others_actions.sum()
        m = self.game_description.m
        f = 3
        if sum_coop_prev >= m:
            self.consecutive_failures = 0
            return Action.C
        else:
            self.consecutive_failures += 1
            if self.consecutive_failures > f:
                self.consecutive_failures = 0
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_248(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that cooperates in the first round, 
    then continues to cooperate if at least m players cooperated in the previous round, 
    otherwise defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round_number = state.round_number - 1
        my_prev_action = history.my_actions[prev_round_number]
        opponent_prev_actions = history.opponent_actions[prev_round_number, :]
        prev_coop = 1 if my_prev_action else 0
        prev_coop += np.sum(opponent_prev_actions)
        if prev_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_249(BaseStrategy):
    """
    Cooperative Adaptation with Punishment (CAP) Strategy.

    This strategy promotes cooperation based on the number of cooperators in the previous round.
    It starts with cooperation and adapts by cooperating if the minimum threshold is met, otherwise defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_my_action = history.my_actions[state.round_number - 1]
        prev_opponent_actions = history.opponent_actions[state.round_number - 1, :]
        c_prev = prev_my_action + np.sum(prev_opponent_actions)
        if c_prev >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_250(BaseStrategy):
    """
    Adaptive Cooperation with Punishment strategy for Collective Risk Dilemma.
    Cooperates initially, punishes once when cooperation is low, then reverts.
    Cooperates in the last round if previous round had sufficient cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        else:
            if state.round_number == self.n_rounds - 1:
                prev_round = self.n_rounds - 2
            else:
                prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opponents_prev_actions = history.opponent_actions[prev_round]
            total_coops = my_prev_action + opponents_prev_actions.sum()
            if state.round_number == self.n_rounds - 1:
                if total_coops >= self.m:
                    return Action.C
                else:
                    return Action.D
            elif total_coops >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_251(BaseStrategy):
    """
    Adaptive Cooperation Based on Historical Performance strategy for the Collective Risk Dilemma.
    Cooperates in the first round, then continues to cooperate if more than half of previous rounds met the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        coop_count = 0
        for r in range(state.round_number):
            my_action = history.my_actions[r]
            opponent_coop = np.sum(history.opponent_actions[r])
            total_coop = int(my_action) + opponent_coop
            if total_coop >= self.m:
                coop_count += 1
        if coop_count / state.round_number > 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_252(BaseStrategy):
    """
    Collective Tit-for-Tat Strategy: Cooperates in the first round and mimics 
    the collective cooperation level of the previous round. If at least m players 
    cooperated previously, it cooperates again; otherwise, it defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opp_prev_actions = history.opponent_actions[prev_round]
        total_coop = my_prev_action + opp_prev_actions.sum()
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_253(BaseStrategy):
    """
    Adaptive Cooperation with Forgiveness strategy for the Collective Risk Dilemma.
    Cooperates initially and continues if enough players cooperated in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_my_action = history.my_actions[-1]
        opponent_actions_last_round = history.opponent_actions[-1, :]
        opponent_coop = sum(opponent_actions_last_round)
        total_coop = opponent_coop + (1 if prev_my_action else 0)
        if total_coop >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_254(BaseStrategy):
    """
    Cooperate If Threshold Met (CITM) strategy. Cooperate initially, then check if the number of cooperators in the previous round met the threshold 'm'. Continue cooperating if the threshold was met; otherwise, defect.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_coop_prev = history.my_actions[prev_round]
        opponent_actions = history.opponent_actions[prev_round, :]
        opp_coop = sum(opponent_actions)
        total_coop = opp_coop + (1 if my_coop_prev else 0)
        if total_coop >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_256(BaseStrategy):
    """
    Strategy: Responsive Cooperation with Forgiveness.
    Cooperates initially, continues if threshold met, defects otherwise, but forgives and cooperates again after defecting once.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.my_last_action = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            action = Action.C
            self.my_last_action = action
            return action
        else:
            prior_round = state.round_number - 1
            my_prev_action = history.my_actions[prior_round]
            op_prev_actions = history.opponent_actions[prior_round, :]
            total_prev_coops = my_prev_action + op_prev_actions.sum()
            previous_met_m = total_prev_coops >= self.game_description.m
            if previous_met_m:
                action = Action.C
            elif self.my_last_action == Action.D and state.round_number > 1:
                action = Action.C
            else:
                action = Action.D
            self.my_last_action = action
            return action

class Strategy_COLLECTIVE_257(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that promotes sustained cooperation.
    Cooperates in the first round. In subsequent rounds, cooperates again if the number
    of cooperators in the previous round meets or exceeds the threshold m; otherwise, defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round_number = state.round_number - 1
        my_prev_action = history.my_actions[prev_round_number]
        opponent_prev_actions = history.opponent_actions[prev_round_number, :]
        num_coop_prev = sum(opponent_prev_actions) + int(my_prev_action)
        if num_coop_prev >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_258(BaseStrategy):
    """
    Cooperative Punishment with Recovery strategy.
    Cooperates initially, punishes when cooperation drops below threshold m,
    but allows recovery by cooperating again after a Defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        my_last_action = history.my_actions[last_round]
        opponent_actions_last_round = history.opponent_actions[last_round]
        prev_C = sum(opponent_actions_last_round) + (1 if my_last_action else 0)
        m = self.game_description.m
        if prev_C >= m or my_last_action is False:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_259(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that adapts based on the number of cooperators in previous rounds.
    It starts by cooperating and adjusts its action by either cooperating or defecting based on the previous round's outcomes.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.next_action_force_coop = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            t_prev = state.round_number - 1
            my_prev_action = history.my_actions[t_prev]
            opponent_prev_actions = history.opponent_actions[t_prev]
            my_contribution = 1 if my_prev_action else 0
            opponents_contribution = sum(opponent_prev_actions)
            x_prev = my_contribution + opponents_contribution
            if x_prev >= self.game_description.m:
                self.next_action_force_coop = False
                return Action.C
            elif self.next_action_force_coop:
                self.next_action_force_coop = False
                return Action.C
            else:
                self.next_action_force_coop = True
                return Action.D

class Strategy_COLLECTIVE_260(BaseStrategy):
    """
    A strategy that cooperates by default, defects if fewer than m players cooperated in the previous round, 
    and reverts to cooperation in the next round regardless of outcomes.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.defected_last_round = False

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            self.defected_last_round = False
            return Action.C
        else:
            if self.defected_last_round:
                action = Action.C
                self.defected_last_round = False
            else:
                prev_round = state.round_number - 1
                my_prev_action = history.my_actions[prev_round]
                my_coop = 1 if my_prev_action else 0
                others_prev_actions = history.opponent_actions[prev_round, :]
                others_coop = np.sum(others_prev_actions)
                total_coop = my_coop + others_coop
                if total_coop < self.m:
                    action = Action.D
                    self.defected_last_round = True
                else:
                    action = Action.C
            return action

class Strategy_COLLECTIVE_261(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma where each player uses an individual threshold
    based on their player index to decide whether to cooperate or defect.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.threshold = 1.0 / self.n * self.m if self.n > 0 else 0.0
        self.history = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            cooperators = sum(history.opponent_actions[-1, :]) + history.my_actions[-1]
            if cooperators >= self.threshold * self.n:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_262(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma encouraging sustained cooperation through reciprocity and adaptation.
    It starts with cooperation, continues if the threshold is met, defects if the threshold is not met, and resets to cooperate after defecting.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        opponent_actions_last = history.opponent_actions[last_round]
        opponent_coop_last = np.sum(opponent_actions_last)
        my_coop_last = history.my_actions[last_round]
        total_coop_last = opponent_coop_last + (1 if my_coop_last else 0)
        if total_coop_last >= self.game_description.m:
            return Action.C
        elif not my_coop_last:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_263(BaseStrategy):
    """
    Implement the Adaptive Collective Cooperation (ACC) strategy.
    
    This strategy encourages cooperation based on the collective behavior in the previous round.
    It cooperates if at least m players cooperated in the previous round, otherwise defects.
    The first round always results in a Cooperate action to establish a cooperative tone.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_my_action = history.my_actions[state.round_number - 1]
        prev_opponent_actions = history.opponent_actions[state.round_number - 1]
        sum_opponent = np.sum(prev_opponent_actions)
        total_coop = int(prev_my_action) + sum_opponent
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_264(BaseStrategy):
    """
    Adaptive Collective Cooperation Strategy:
    - Cooperate in the first round.
    - In subsequent rounds, cooperate if the previous round met the cooperation threshold.
    - If the threshold was not met, defect for one round and then revert to cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.next_must_coop = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.next_must_coop:
            self.next_must_coop = False
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_prev_actions = history.opponent_actions[prev_round, :]
        my_c = 1 if my_prev_action else 0
        others_c = sum(opponents_prev_actions)
        m_prev = my_c + others_c
        if m_prev >= self.game_description.m:
            return Action.C
        else:
            self.next_must_coop = True
            return Action.D

class Strategy_COLLECTIVE_266(BaseStrategy):
    """
    Adaptive Cooperation with Forgiveness strategy for the Collective Risk Dilemma.
    
    The strategy begins by cooperating in the first round to encourage initial cooperation.
    In subsequent rounds, it checks if the minimum number of cooperators (m) was met.
    If not, it defects and enters a forgiveness period of 3 rounds, during which it attempts
    to cooperate again. In the endgame (last 5 rounds), it uses a simpler cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.in_forgiveness = False
        self.forgiveness_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        total_rounds = self.game_description.n_rounds
        endgame_threshold = 5
        if round_num >= total_rounds - endgame_threshold:
            prev_opponent = np.sum(history.opponent_actions[-1, :])
            prev_me = history.my_actions[-1]
            sum_prev = prev_opponent + prev_me
            return Action.C if sum_prev >= self.game_description.m else Action.D
        else:
            prev_opponent = np.sum(history.opponent_actions[-1, :])
            prev_me = history.my_actions[-1]
            sum_prev = prev_opponent + prev_me
            if sum_prev >= self.game_description.m:
                self.in_forgiveness = False
                self.forgiveness_rounds = 0
                return Action.C
            else:
                if self.in_forgiveness:
                    action = Action.C
                    self.forgiveness_rounds -= 1
                    if self.forgiveness_rounds <= 0:
                        self.in_forgiveness = False
                else:
                    action = Action.D
                    self.in_forgiveness = True
                    self.forgiveness_rounds = 3
                return action

class Strategy_COLLECTIVE_267(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game. It encourages cooperation initially
    and continues cooperating if enough players cooperated in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opp_last_actions = history.opponent_actions[-1]
        prev_coops_opponents = sum(opp_last_actions)
        my_last_action = history.my_actions[-1]
        total_prev_coops = prev_coops_opponents + (1 if my_last_action else 0)
        if total_prev_coops >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_270(BaseStrategy):
    """
    Adaptive Cooperate-if-Met (ACM) Strategy.

    This strategy starts by cooperating in the first round. In subsequent rounds, it observes the number of cooperators from the previous round. If the number meets or exceeds the minimum required (m), it continues to cooperate. Otherwise, it defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        opponent_actions = history.opponent_actions[last_round]
        my_last_action = history.my_actions[last_round]
        num_coop = sum(opponent_actions) + (1 if my_last_action else 0)
        if num_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_271(BaseStrategy):
    """
    Adaptive Cooperative Restart (ACR) strategy to encourage sustained cooperation.
    Cooperates initially, defects when cooperation is insufficient, and periodically resets to cooperate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0
        self.threshold = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_my_action = history.my_actions[-1]
        prev_opp_actions = history.opponent_actions[-1]
        prev_coop = prev_my_action + prev_opp_actions.sum()
        if prev_coop >= self.game_description.m:
            self.consecutive_defections = 0
            return Action.C
        else:
            self.consecutive_defections += 1
            if self.consecutive_defections >= self.threshold:
                self.consecutive_defections = 0
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_272(BaseStrategy):
    """A strategy for the Collective Risk Dilemma that promotes cooperation while punishing defection."""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punished_last_round = False

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            my_last_action = history.my_actions[-1]
            opp_last_actions = history.opponent_actions[-1, :]
            prior_coop = int(my_last_action) + sum(opp_last_actions)
            return Action.C if prior_coop >= self.game_description.m else Action.D
        elif self.punished_last_round:
            self.punished_last_round = False
            return Action.C
        else:
            my_last_action = history.my_actions[-1]
            opp_last_actions = history.opponent_actions[-1, :]
            prior_coop = int(my_last_action) + sum(opp_last_actions)
            if prior_coop >= self.game_description.m:
                return Action.C
            else:
                self.punished_last_round = True
                return Action.D

class Strategy_COLLECTIVE_273(BaseStrategy):
    """
    Forgiving Cooperation with Punishment Strategy.
    Cooperates initially. If the cooperation threshold is met, continues to cooperate.
    If the threshold is not met, defects as punishment. After a defection, forgives and
    cooperates again in the next round to restart cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_action = None

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            self.last_action = Action.C
            return Action.C
        prev_my_action = history.my_actions[-1]
        prev_opponent_actions = history.opponent_actions[-1]
        prev_coop = int(prev_my_action) + prev_opponent_actions.sum()
        if prev_coop >= self.game_description.m:
            current_action = Action.C
        elif self.last_action == Action.D:
            current_action = Action.C
        else:
            current_action = Action.D
        self.last_action = current_action
        return current_action

class Strategy_COLLECTIVE_274(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that promotes cooperation by punishing 
    insufficient cooperation while maximizing payoff in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.last_action = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            self.last_action = Action.C
            return Action.C
        if current_round == self.n_rounds - 1:
            self.last_action = Action.D
            return Action.D
        prev_round = current_round - 1
        prev_my_action = history.my_actions[prev_round]
        prev_others = history.opponent_actions[prev_round]
        sum_prev_coop = prev_my_action + prev_others.sum()
        if sum_prev_coop >= self.m:
            action = Action.C
        elif self.last_action == Action.C:
            action = Action.D
        else:
            action = Action.C
        self.last_action = action
        return action

class Strategy_COLLECTIVE_275(BaseStrategy):
    """
    A strategy that cooperates if at least m players cooperated in the previous round.
    Cooperates in the first round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_prev_actions = history.opponent_actions[prev_round, :]
        total_coop = int(my_prev_action) + int(np.sum(opponents_prev_actions))
        if total_coop >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_276(BaseStrategy):
    """
    The "Cooperate and Forgive" strategy for the Collective Risk Dilemma.
    It starts by cooperating, punishes non-cooperation with defection, and 
    includes a forgiveness mechanism to reset cooperation after punishment.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.will_forgive = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.will_forgive:
            self.will_forgive = False
            return Action.C
        previous_round = state.round_number - 1
        my_prev_action = history.my_actions[previous_round]
        opponent_prev_actions = history.opponent_actions[previous_round, :]
        total_C = sum(opponent_prev_actions) + (1 if my_prev_action else 0)
        if total_C >= self.game_description.m:
            return Action.C
        else:
            self.will_forgive = True
            return Action.D

class Strategy_COLLECTIVE_277(BaseStrategy):
    """
    A strategy that starts by Cooperating, then defects for a predetermined number of rounds (d) if the cooperation threshold is not met in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defect_remaining = 0
        self.d = 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.defect_remaining > 0:
            self.defect_remaining -= 1
            return Action.D
        if history is None or len(history.my_actions) == 0 or len(history.opponent_actions) == 0:
            return Action.C
        last_my_action = history.my_actions[-1]
        last_opponent_actions = history.opponent_actions[-1]
        total_C = 0
        if last_my_action:
            total_C += 1
        total_C += np.sum(last_opponent_actions)
        if total_C >= self.game_description.m:
            return Action.C
        else:
            self.defect_remaining = self.d
            return Action.D

class Strategy_COLLECTIVE_278(BaseStrategy):
    """
    Adaptive Cooperation Based on Historical Performance
    Cooperates initially, then continues if enough players cooperated in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        opponents_coop = sum(history.opponent_actions[prev_round])
        my_coop = 1 if history.my_actions[prev_round] else 0
        total_coop = opponents_coop + my_coop
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_279(BaseStrategy):
    """
    Cooperative Reset After One Defection (CRAD) strategy.
    - All players start by Cooperating.
    - Cooperate if previous round met the cooperation threshold.
    - Punish by Defecting if cooperation fell short, but reset after one round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n = game_description.n_players
        self.failure_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_last_action = history.my_actions[-1]
        opponent_actions_last = history.opponent_actions[-1, :]
        my_coop = int(my_last_action)
        opponent_coop = int(opponent_actions_last.sum())
        cooperators = my_coop + opponent_coop
        if cooperators >= self.m:
            self.failure_counter = 0
            return Action.C
        else:
            self.failure_counter += 1
            if self.failure_counter == 1:
                return Action.D
            else:
                self.failure_counter = 0
                return Action.C

class Strategy_COLLECTIVE_280(BaseStrategy):
    """
    A strategy that adapts cooperation based on recent success, encouraging sustained contribution.
    Cooperates in the first round, then decides based on the ratio of successful recent rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.t = 5
        self.s = 0.6

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        num_consider = min(self.t, state.round_number)
        start_round = max(0, state.round_number - num_consider)
        successful = 0
        for r in range(start_round, state.round_number):
            my_coop = history.my_actions[r]
            others_coop = np.sum(history.opponent_actions[r, :])
            total_coop = my_coop + others_coop
            if total_coop >= self.game_description.m:
                successful += 1
        success_ratio = successful / num_consider
        if success_ratio >= self.s:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_282(BaseStrategy):
    """Adaptive cooperation strategy based on historical performance."""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        index = state.round_number - 1
        my_prev_action = history.my_actions[index]
        opponents_prev_actions = history.opponent_actions[index]
        c_prev = my_prev_action + np.sum(opponents_prev_actions)
        if c_prev >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_283(BaseStrategy):
    """
    Grim trigger strategy for Collective Risk Dilemma.
    Cooperate initially; if cooperation level ever drops below threshold, defect forever.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defect_mode = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if self.defect_mode:
            return Action.D
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        else:
            prev_round = current_round - 1
            my_last_action = history.my_actions[prev_round]
            opponent_last_actions = history.opponent_actions[prev_round, :]
            total_coop = int(my_last_action) + int(opponent_last_actions.sum())
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                self.defect_mode = True
                return Action.D

class Strategy_COLLECTIVE_284(BaseStrategy):
    """
    Adaptive Cooperation with Restart Probability (ACRP) strategy for Collective Risk Dilemma.
    Cooperates initially, then adapts based on the previous round's cooperation level.
    If the previous round met the minimum required cooperators (m), continues to Cooperate; otherwise, 
    each player has a 50% probability to attempt restarting cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        opponent_actions_prev = history.opponent_actions[prev_round]
        opponent_coop = sum(opponent_actions_prev)
        my_prev_action = history.my_actions[prev_round]
        total_coop = opponent_coop + (1 if my_prev_action else 0)
        if total_coop >= self.m:
            return Action.C
        elif random.random() < 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_285(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game where players cooperate in the first round 
    and subsequently cooperate if at least m players cooperated in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_prev_actions = history.opponent_actions[prev_round, :]
        my_coop = 1 if my_prev_action else 0
        opponent_coop = np.sum(opponent_prev_actions)
        total_coop = my_coop + opponent_coop
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_286(BaseStrategy):
    """
    A strategy that promotes cooperation by starting with cooperation, 
    defecting once if cooperation threshold isn't met in the previous round, 
    and then resetting to cooperate in the subsequent round.
    Inherits from BaseStrategy and uses the game description parameters.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.next_round_force_cooperate = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.next_round_force_cooperate = False
            return Action.C
        if self.next_round_force_cooperate:
            self.next_round_force_cooperate = False
            return Action.C
        prev_round = state.round_number - 1
        my_prev = history.my_actions[prev_round]
        opp_prev = history.opponent_actions[prev_round]
        prev_coop_count = int(my_prev) + opp_prev.sum()
        if prev_coop_count >= self.game_description.m:
            return Action.C
        else:
            action = Action.D
            self.next_round_force_cooperate = True
            return action

class Strategy_COLLECTIVE_287(BaseStrategy):
    """
    This strategy Cooperates as long as at least m players Cooperated in the previous round; otherwise, it Defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        opponent_actions_prev = history.opponent_actions[prev_round]
        opponent_coops = sum(opponent_actions_prev)
        my_prev = history.my_actions[prev_round]
        total_coops = opponent_coops + (1 if my_prev else 0)
        if total_coops >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_288(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma that encourages cooperation
    while responding to collective outcomes. Cooperates initially, continues if 
    sufficient cooperation is met, otherwise defects with a probability based on 
    the shortfall. Includes endgame handling to defect if cooperation has been 
    consistently low in recent rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.coop_counts = []
        self.s = 2
        self.threshold = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_last_action = history.my_actions[-1]
        opponent_last_actions = history.opponent_actions[-1]
        C_prev = my_last_action + opponent_last_actions.sum()
        self.coop_counts.append(C_prev)
        if state.round_number >= self.r - self.s and (not self.r < self.s):
            recent = self.coop_counts[-self.s:]
            met = sum((1 for c in recent if c >= self.m))
            proportion = met / len(recent) if recent else 0
            if proportion < self.threshold:
                return Action.D
        if C_prev >= self.m:
            return Action.C
        else:
            defect_prob = (self.m - C_prev) / self.n
            if random.random() < defect_prob:
                return Action.D
            else:
                return Action.C

class Strategy_COLLECTIVE_289(BaseStrategy):
    """
    Adaptive Collective Cooperation with Forgiveness Strategy.
    Cooperates initially, punishes lack of cooperation, and forgives when cooperation resumes.
    Cooperates in the final round to maintain trust.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        prior_round = state.round_number - 1
        my_last_action = history.my_actions[prior_round]
        opponent_actions_last_round = history.opponent_actions[prior_round]
        my_coop = 1 if my_last_action else 0
        opp_coops = opponent_actions_last_round.sum()
        total_coop = my_coop + opp_coops
        m = self.game_description.m
        if total_coop >= m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_290(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that balances cooperation and punishment.
    Cooperates initially, then punishes non-cooperation for 3 rounds before forgiving.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.punishing = False
        self.punishment_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.punishing = False
            self.punishment_remaining = 0
            return Action.C
        if self.punishment_remaining > 0:
            self.punishment_remaining -= 1
            return Action.D
        else:
            my_previous_action = history.my_actions[-1]
            opponents_previous_actions = history.opponent_actions[-1]
            total_cooperators = int(my_previous_action) + int(opponents_previous_actions.sum())
            if total_cooperators >= self.m:
                return Action.C
            else:
                self.punishment_remaining = 3
                return Action.D

class Strategy_COLLECTIVE_291(BaseStrategy):
    """
    A deterministic strategy for the Collective Risk Dilemma where players Cooperate if the previous round met the cooperation threshold, otherwise Defect.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round_num = state.round_number - 1
        my_last_action = history.my_actions[last_round_num]
        others_last_actions = history.opponent_actions[last_round_num, :]
        total_coop = my_last_action + np.sum(others_last_actions)
        if total_coop >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_292(BaseStrategy):
    """A strategy that combines reciprocity with forgiveness to sustain cooperation."""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.force_coop = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.force_coop:
            self.force_coop = False
            return Action.C
        my_last_action = history.my_actions[-1]
        opponent_last_actions = history.opponent_actions[-1, :]
        sum_opponents = np.sum(opponent_last_actions)
        total_coops = sum_opponents + (1 if my_last_action else 0)
        if total_coops >= self.game_description.m:
            return Action.C
        else:
            self.force_coop = True
            return Action.D

class Strategy_COLLECTIVE_293(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that promotes cooperation when the threshold is met,
    defects when it is not, and periodically retries cooperation to encourage collective success.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperate = True
        self.retry_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        else:
            my_actions_prev = history.my_actions[round_number - 1]
            opponents_actions_prev = history.opponent_actions[round_number - 1]
            my_c = 1 if my_actions_prev else 0
            opponents_c = sum(opponents_actions_prev)
            s_prev = my_c + opponents_c
            m = self.game_description.m
            if s_prev >= m:
                self.cooperate = True
                self.retry_counter = 0
                return Action.C
            elif self.cooperate:
                self.cooperate = False
                self.retry_counter += 1
                return Action.D
            elif self.retry_counter >= 3:
                self.cooperate = True
                self.retry_counter = 0
                return Action.C
            else:
                self.retry_counter += 1
                return Action.D

class Strategy_COLLECTIVE_294(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma:
    - Starts with cooperation in the first round.
    - Continues cooperating if the previous round met the cooperation threshold.
    - Defects for a limited number of consecutive rounds (t_threshold) if cooperation was insufficient.
    - Resumes cooperation after reaching the defect threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.t_threshold = 2
        self.defect_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        opponents_prev = history.opponent_actions[prev_round, :]
        num_opponents_c = np.sum(opponents_prev)
        my_prev = history.my_actions[prev_round]
        total_c = num_opponents_c + (1 if my_prev else 0)
        if total_c >= self.game_description.m:
            self.defect_counter = 0
            return Action.C
        else:
            self.defect_counter += 1
            if self.defect_counter < self.t_threshold:
                return Action.D
            else:
                self.defect_counter = 0
                return Action.C

class Strategy_COLLECTIVE_295(BaseStrategy):
    """
    A strategy designed to maintain cooperation in a Collective Risk Dilemma game.
    It begins by cooperating, continues if enough players cooperate, defects if not,
    and resets to cooperation after one defection to avoid endless cycles.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.next_must_cooperate = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.next_must_cooperate:
            self.next_must_cooperate = False
            return Action.C
        last_round = state.round_number - 1
        my_last_action = history.my_actions[last_round]
        opponent_actions_last_round = history.opponent_actions[last_round]
        sum_opponents = np.sum(opponent_actions_last_round)
        c_last_round = my_last_action + sum_opponents
        if c_last_round >= self.game_description.m:
            return Action.C
        else:
            self.next_must_cooperate = True
            return Action.D

class Strategy_COLLECTIVE_296(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that balances optimism with measured punishment.
    Cooperates initially, punishes once if cooperation threshold isn't met, and adapts in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        n_rounds = self.n_rounds
        if round_number == n_rounds - 1:
            last_round = round_number - 1
            if last_round < 0:
                return Action.C
            my_action = history.my_actions[last_round]
            opponent_actions = history.opponent_actions[last_round, :]
            total_coop = my_action + np.sum(opponent_actions)
            if total_coop >= self.m:
                return Action.C
            else:
                return Action.D
        else:
            prev_round = round_number - 1
            my_action_prev = history.my_actions[prev_round]
            opponent_actions_prev = history.opponent_actions[prev_round, :]
            total_coop_prev = my_action_prev + np.sum(opponent_actions_prev)
            if total_coop_prev >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_297(BaseStrategy):
    """
    Adaptive Cooperation Based on Recent Successes strategy.
    Cooperates initially, then uses recent success rate to decide actions,
    defecting in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.s = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            n = self.game_description.n_players
            m = self.game_description.m
            s = self.s
            start_round = max(0, state.round_number - s)
            end_round = state.round_number - 1
            total_successes = 0
            for round_idx in range(start_round, end_round + 1):
                my_action = history.my_actions[round_idx]
                opponent_actions = history.opponent_actions[round_idx, :]
                num_coop = 1 if my_action else 0
                num_coop += sum(opponent_actions)
                if num_coop >= m:
                    total_successes += 1
            threshold = math.ceil(m / n * s)
            if total_successes >= threshold:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_298(BaseStrategy):
    """
    Adaptive Cooperative Response (ACR) strategy for the Collective Risk Dilemma game.
    Cooperates if the threshold was met in the previous round; otherwise adapts based on their last action.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t_prev = state.round_number - 1
        me_coop = history.my_actions[t_prev]
        others_coop = sum(history.opponent_actions[t_prev])
        total_coop_prev = me_coop + others_coop
        m = self.game_description.m
        if total_coop_prev >= m:
            return Action.C
        elif not me_coop:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_299(BaseStrategy):
    """
    A collective risk dilemma strategy that encourages cooperation through initial cooperation, 
    adaptive mirroring, threshold consideration, trend analysis, and a forgiveness mechanism.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        n_players = self.game_description.n_players
        m = self.game_description.m
        round_num = state.round_number
        prev_round = round_num - 1
        opponents_prev = history.opponent_actions[prev_round, :]
        my_prev_action = history.my_actions[prev_round]
        total_C_prev = sum(opponents_prev) + (1 if my_prev_action else 0)
        if total_C_prev >= m:
            return Action.C
        if total_C_prev > n_players // 2:
            return Action.C

        def compute_avg_coop(start, end):
            if start > end:
                return 0.0
            total = 0.0
            count = 0
            for r in range(start, end + 1):
                coop_count = sum(history.opponent_actions[r, :]) + (1 if history.my_actions[r] else 0)
                total += coop_count / n_players
                count += 1
            return total / count if count > 0 else 0.0
        window_size = 3
        last_start = max(prev_round - window_size + 1, 0)
        last_end = prev_round
        avg_last = compute_avg_coop(last_start, last_end)
        prev_start = max(last_start - window_size, 0)
        prev_end = last_start - 1
        avg_prev = compute_avg_coop(prev_start, prev_end)
        if avg_last > avg_prev:
            return Action.C
        if random.random() < 0.2:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_300(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that balances cooperation with punishment.
    Cooperates in the first round, follows group cooperation in middle rounds,
    and decides the final round based on majority cooperation in the penultimate round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            round_number = state.round_number
            prev_round = round_number - 1
            my_action = history.my_actions[prev_round]
            opponent_actions = history.opponent_actions[prev_round, :]
            prev_coop_count = my_action + int(opponent_actions.sum())
            if round_number == self.n_rounds - 1:
                if prev_coop_count > self.n_players / 2:
                    return Action.C
                else:
                    return Action.D
            elif prev_coop_count >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_301(BaseStrategy):

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.prev_action = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        """
        Implementation of the Collective Risk Dilemma strategy.

        This strategy promotes cooperation while punishing lack of cooperation
        and forgiving after a single punishment to allow recovery.
        """
        r = self.game_description.n_rounds
        if state.round_number == 0:
            action = Action.C
            self.prev_action = action
            return action
        if state.round_number == r - 1:
            action = Action.C
            self.prev_action = action
            return action
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_prev = history.opponent_actions[prev_round]
        prev_coop = sum(opponents_prev) + (1 if my_prev_action else 0)
        m = self.game_description.m
        if prev_coop >= m:
            action = Action.C
        elif self.prev_action == Action.D and state.round_number < r - 1:
            action = Action.C
        else:
            action = Action.D
        self.prev_action = action
        return action

class Strategy_COLLECTIVE_302(BaseStrategy):
    """
    A strategy to maintain cooperation in a Collective Risk Dilemma game with punishment and recovery phases.
    Cooperates initially, punishes if cooperation falls below threshold, then recovers.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishing = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev_action = history.my_actions[previous_round]
        my_coop = 1 if my_prev_action else 0
        opp_coop = sum(history.opponent_actions[previous_round])
        total_coop = my_coop + opp_coop
        if self.punishing:
            self.punishing = False
            return Action.C
        elif total_coop >= self.game_description.m:
            return Action.C
        else:
            self.punishing = True
            return Action.D

class Strategy_COLLECTIVE_303(BaseStrategy):
    """
   Strategy: Cooperative Punishment with Reset

    This strategy begins by cooperating and continues to do so as long as the number of cooperators meets the threshold.
    If the threshold is not met, it defects once as a punishment and then resets to cooperate in the next round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.strategy_state = 'normal'

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev_action = history.my_actions[previous_round]
        opponents_prev_actions = history.opponent_actions[previous_round, :]
        c_prev = int(my_prev_action) + np.sum(opponents_prev_actions)
        if self.strategy_state == 'normal':
            if c_prev >= self.m:
                return Action.C
            else:
                self.strategy_state = 'reset'
                return Action.D
        else:
            self.strategy_state = 'normal'
            return Action.C

class Strategy_COLLECTIVE_304(BaseStrategy):
    """
    A strategy that promotes sustained cooperation by adapting based on recent history.
    Cooperates initially, continues if enough others cooperate, and defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        gd = self.game_description
        if round_num == 0:
            return Action.C
        elif round_num == gd.n_rounds - 1:
            return Action.D
        else:
            prev_round = round_num - 1
            my_prev_action = history.my_actions[prev_round]
            opponent_actions = history.opponent_actions[prev_round, :]
            prev_coop_count = my_prev_action + np.sum(opponent_actions)
            if prev_coop_count >= gd.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_305(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that promotes cooperation
    while responding to previous round outcomes to sustain cooperation.
    Cooperates in the first and last rounds. Continues cooperating if the
    previous round met the cooperation threshold; otherwise defects,
    except in the last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        else:
            previous_round = state.round_number - 1
            my_prev_action = history.my_actions[previous_round]
            opp_prev_actions = history.opponent_actions[previous_round]
            my_prev = int(my_prev_action)
            opp_prev = [int(a) for a in opp_prev_actions]
            total_coop = my_prev + sum(opp_prev)
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_306(BaseStrategy):
    """
    Adaptive Cooperation with Forgiveness Strategy.
    Cooperates initially and after successful rounds, defects with increasing probability after consecutive failures.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_failures = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        is_last_round = state.round_number == self.game_description.n_rounds - 1
        if is_last_round:
            return Action.C
        previous_round = state.round_number - 1
        sum_my_action = int(history.my_actions[previous_round])
        sum_opponent_actions = history.opponent_actions[previous_round, :].sum()
        n_cooperators = sum_my_action + sum_opponent_actions
        met_threshold = n_cooperators >= self.game_description.m
        if met_threshold:
            self.consecutive_failures = 0
            return Action.C
        else:
            self.consecutive_failures += 1
            p = 0.5 + 0.1 * self.consecutive_failures
            p = min(p, 1.0)
            if random.random() < p:
                return Action.D
            else:
                return Action.C

class Strategy_COLLECTIVE_307(BaseStrategy):
    """
    Adaptive Cooperation with Retaliation Strategy.
    Cooperates initially, adapts based on previous cooperation, and retaliates if necessary.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.in_retaliation = False
        self.retalia_remaining = 0
        self.n_players = game_description.n_players
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opp_prev_actions = history.opponent_actions[prev_round, :]
        prev_coop = my_prev_action + opp_prev_actions.sum()
        prev_def = self.n_players - prev_coop
        if state.round_number == self.game_description.n_rounds - 1:
            if prev_def > self.n_players / 2:
                return Action.D
            else:
                return Action.C
        elif self.in_retaliation:
            action = Action.D
            self.retalia_remaining -= 1
            if self.retalia_remaining == 0:
                self.in_retaliation = False
            return action
        else:
            if prev_coop >= self.m:
                if prev_coop > self.n_players // 2:
                    action = Action.C
                else:
                    action = Action.D
            else:
                action = Action.D
            if prev_def > self.n_players / 2:
                self.in_retaliation = True
                self.retalia_remaining = 1
            return action

class Strategy_COLLECTIVE_308(BaseStrategy):
    """Adaptive Cooperation with Forgiveness strategy for the Collective Risk Dilemma."""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        game_desc = self.game_description
        m = game_desc.m
        round_number = state.round_number
        threshold_met = 0
        total_past_rounds = round_number
        for past_round in range(round_number):
            my_action = history.my_actions[past_round]
            opp_actions = history.opponent_actions[past_round, :]
            coop_count = int(my_action) + opp_actions.sum()
            if coop_count >= m:
                threshold_met += 1
        ratio = threshold_met / total_past_rounds
        if ratio > 0.5:
            return Action.C
        else:
            last_round = round_number - 1
            my_prev_action = history.my_actions[last_round]
            opp_prev_actions = history.opponent_actions[last_round, :]
            prev_coop_count = int(my_prev_action) + opp_prev_actions.sum()
            if prev_coop_count >= m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_309(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that starts with cooperation, 
    continues if enough players cooperate, defects if not, and recovers by 
    re-cooperating after one defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.recovering = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.recovering:
            self.recovering = False
            return Action.C
        previous_round = state.round_number - 1
        my_prev_action = history.my_actions[previous_round]
        opp_prev_actions = history.opponent_actions[previous_round]
        n_cooperators = (1 if my_prev_action else 0) + np.sum(opp_prev_actions)
        if n_cooperators >= self.game_description.m:
            return Action.C
        else:
            self.recovering = True
            return Action.D

class Strategy_COLLECTIVE_310(BaseStrategy):
    """
    A strategy that adapts to the level of cooperation in previous rounds by temporarily defecting 
    when insufficient players cooperate, then reverting to cooperation to promote sustained collaboration.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishing = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.punishing:
            self.punishing = False
            return Action.C
        prev_round = state.round_number - 1
        prev_my_action = history.my_actions[prev_round]
        my_c = 1 if prev_my_action else 0
        opponents_c = np.sum(history.opponent_actions[prev_round])
        total_c = my_c + opponents_c
        m = self.game_description.m
        if total_c >= m:
            return Action.C
        else:
            self.punishing = True
            return Action.D

class Strategy_COLLECTIVE_311(BaseStrategy):
    """
    A strategy that adapts based on the number of cooperators in the previous round.
    Cooperates in the first round. In subsequent rounds, cooperates if at least `m` players 
    cooperated in the previous round; otherwise defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            my_last = history.my_actions[-1]
            opp_last = history.opponent_actions[-1]
            count_c = sum(opp_last) + (1 if my_last else 0)
            m = self.game_description.m
            if count_c >= m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_312(BaseStrategy):
    """
    Adaptive Cooperate-Punish-Forgive Strategy.
    Cooperates initially and if the previous round met the cooperation threshold.
    Defects for up to 3 consecutive rounds if the threshold was not met, then resumes cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.punishment_remaining > 0:
            self.punishment_remaining -= 1
            return Action.D
        else:
            prev_round = state.round_number - 1
            if prev_round < 0:
                previous_met = False
            else:
                my_last_action = history.my_actions[prev_round]
                opponents_last_actions = history.opponent_actions[prev_round, :]
                total_coop = my_last_action + sum(opponents_last_actions)
                previous_met = total_coop >= self.game_description.m
            if previous_met:
                return Action.C
            else:
                self.punishment_remaining = 3
                return Action.D

class Strategy_COLLECTIVE_313(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that encourages cooperation through 
    conditional punishment and retrying cooperation. It balances punishment and 
    forgiveness to maximize collective payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_punished = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            prev_round = state.round_number - 1
            if history is not None and prev_round < history.my_actions.size:
                prev_my_action = history.my_actions[prev_round]
                prev_opponents = history.opponent_actions[prev_round]
                expected_coop = np.sum(prev_opponents)
                if expected_coop + 1 >= self.game_description.m:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D
        elif self.last_punished:
            self.last_punished = False
            return Action.C
        elif history is None or state.round_number - 1 >= history.my_actions.size:
            return Action.D
        else:
            prev_round = state.round_number - 1
            prev_my_action = history.my_actions[prev_round]
            prev_opponents = history.opponent_actions[prev_round]
            coop_count = np.sum(prev_opponents) + (1 if prev_my_action else 0)
            if coop_count >= self.game_description.m:
                return Action.C
            else:
                self.last_punished = True
                return Action.D

class Strategy_COLLECTIVE_314(BaseStrategy):
    """Adaptive Threshold Cooperation with Forgiveness strategy.
    
    This strategy encourages cooperation by initially cooperating and then adapting
    based on the number of cooperators in previous rounds. If cooperation drops
    below a threshold, it defects for a limited number of rounds before reverting
    to cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.s = 3
        self.reset_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        opponent_actions = history.opponent_actions[prev_round]
        sum_opp = np.sum(opponent_actions)
        my_prev_action = history.my_actions[prev_round]
        sum_my = 1 if my_prev_action else 0
        total_coop = sum_opp + sum_my
        if total_coop >= self.cooperation_threshold:
            self.reset_counter = 0
            return Action.C
        elif self.reset_counter < self.s:
            self.reset_counter += 1
            return Action.D
        else:
            self.reset_counter = 0
            return Action.C

class Strategy_COLLECTIVE_315(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that balances cooperation and adaptive responses.
    Cooperates initially and responds to outcomes by either maintaining cooperation or defecting,
    with a recovery mechanism to reset cooperation after a defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.next_round_cooperate = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.next_round_cooperate = False
            return Action.C
        if self.next_round_cooperate:
            self.next_round_cooperate = False
            return Action.C
        previous_round = state.round_number - 1
        my_coop_prev = history.my_actions[previous_round]
        opp_coop_prev = history.opponent_actions[previous_round, :]
        total_coop_prev = my_coop_prev + np.sum(opp_coop_prev)
        if total_coop_prev >= self.game_description.m:
            return Action.C
        else:
            self.next_round_cooperate = True
            return Action.D

class Strategy_COLLECTIVE_316(BaseStrategy):
    """
    This strategy begins by cooperating in the first round. In subsequent rounds, it checks if the number of cooperators 
    in the previous round met the required threshold. If the threshold was met, it continues to cooperate; otherwise, 
    it defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev_action = history.my_actions[previous_round]
        opp_prev_actions = history.opponent_actions[previous_round]
        n_coop = sum(opp_prev_actions)
        if my_prev_action:
            n_coop += 1
        if n_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_317(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that promotes cooperation
    by rewarding meeting the cooperation threshold and punishing when it is not.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            my_prev = history.my_actions[state.round_number - 1]
            opponents_prev = history.opponent_actions[state.round_number - 1]
            total_coop_prev = int(my_prev) + int(np.sum(opponents_prev))
            if total_coop_prev >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_318(BaseStrategy):
    """
    An adaptive strategy for Collective Risk Dilemma to balance cooperation and defection.
    Cooperates initially and after defection bursts, defects otherwise based on previous outcomes.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defects = 0

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        sum_prev_opponents = np.sum(history.opponent_actions[prev_round])
        total_prev_coop = sum_prev_opponents + my_prev_action
        m = self.game_description.m
        if total_prev_coop >= m:
            self.consecutive_defects = 0
            return Action.C
        else:
            self.consecutive_defects += 1
            if self.consecutive_defects >= 2:
                self.consecutive_defects = 0
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_319(BaseStrategy):
    """
    Adaptive Cooperation with Rebound (ACR) strategy for Collective Risk Dilemma.
    Cooperates initially, then adapts based on previous round's cooperation level.
    Defects and waits for a rebound period if the cooperation threshold isn't met.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.rebound_remaining = 0
        self.rebound_duration = 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.rebound_remaining > 0:
            self.rebound_remaining -= 1
            return Action.D
        prev_my_action = history.my_actions[-1]
        prev_opponent_actions = history.opponent_actions[-1, :]
        cooperators = prev_my_action + prev_opponent_actions.sum()
        if cooperators >= self.game_description.m:
            return Action.C
        else:
            self.rebound_remaining = self.rebound_duration
            return Action.D

class Strategy_COLLECTIVE_320(BaseStrategy):
    """
    Adaptive Cooperation with Punishment and Forgiveness (ACPF) strategy 
    for the Collective Risk Dilemma.
    
    The strategy starts with cooperation, then adapts based on the number of 
    cooperators in previous rounds. It punishes by defecting if the threshold 
    isn't met and forgives after a set number of defections. It adjusts behavior 
    in the last round to attempt meeting the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        prev_coop = history.my_actions[prev_round] + sum(history.opponent_actions[prev_round, :])
        if prev_coop >= self.game_description.m:
            self.consecutive_defections = 0
            action = Action.C
        else:
            self.consecutive_defections += 1
            if self.consecutive_defections >= 2:
                self.consecutive_defections = 0
                action = Action.C
            else:
                action = Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            sum_prev_coop = 0
            for t in range(state.round_number):
                my_act = history.my_actions[t]
                opp_act = sum(history.opponent_actions[t, :])
                sum_prev_coop += my_act + opp_act
            required = self.game_description.m * (self.game_description.n_rounds - 1)
            if sum_prev_coop >= required:
                action = Action.C
            elif self.game_description.m - prev_coop <= 0:
                action = Action.C
            else:
                action = Action.D
        return action

class Strategy_COLLECTIVE_321(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that promotes sustained cooperation
    with recovery from temporary defections.
    
    The strategy starts by cooperating (Action.C) in the first round. In subsequent rounds, 
    it continues to cooperate as long as the number of cooperators in the previous round meets 
    or exceeds the threshold (m). If cooperation falls short, the strategy defects for a 
    fixed number of rounds (d=2) before attempting cooperation again.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_prev_actions = history.opponent_actions[prev_round, :]
        coops_prev = 0
        if my_prev_action:
            coops_prev += 1
        coops_prev += np.sum(opponents_prev_actions)
        if coops_prev >= self.game_description.m:
            self.consecutive_defections = 0
            return Action.C
        elif self.consecutive_defections < 2:
            self.consecutive_defections += 1
            return Action.D
        else:
            self.consecutive_defections = 0
            return Action.C

class Strategy_COLLECTIVE_322(BaseStrategy):
    """
    Adaptive Historical Cooperation (AHC) Strategy for the Collective Risk Dilemma.
    Cooperates in the first round and in subsequent rounds based on the historical success rate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        success_count = 0
        for t in range(state.round_number):
            my_c = 1 if history.my_actions[t] else 0
            opp_c = sum(history.opponent_actions[t, :])
            total_coop = my_c + opp_c
            if total_coop >= self.game_description.m:
                success_count += 1
        success_rate = success_count / state.round_number
        if success_rate >= 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_323(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that balances individual gain with collective success.
    Cooperates initially and adjusts based on the necessity of maintaining the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        m = self.game_description.m
        x_prev = sum(history.opponent_actions[-1, :]) + (1 if history.my_actions[-1] else 0)
        if x_prev < m:
            return Action.C
        else:
            c_i_prev = 1 if history.my_actions[-1] else 0
            if x_prev - c_i_prev < m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_324(BaseStrategy):
    """
    Adaptive Collective Cooperation Strategy.
    
    This strategy starts with cooperation in the first round. For subsequent rounds, 
    players cooperate if the number of cooperators in the previous round meets the threshold. 
    If not, they defect with a probability proportional to how far the group fell short of the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n_players = game_description.n_players
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_prev = history.my_actions[state.round_number - 1]
        opp_prev = history.opponent_actions[state.round_number - 1, :]
        x_prev = my_prev + np.sum(opp_prev)
        if x_prev >= self.m:
            return Action.C
        else:
            p = (self.m - x_prev) / self.n_players
            if random.random() < p:
                return Action.D
            else:
                return Action.C

class Strategy_COLLECTIVE_325(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma that encourages cooperation 
    based on the success rate of previous rounds while maintaining bounds to avoid 
    extreme behaviors.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.p_min = 0.2
        self.p_max = 0.8

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number
        success_count = 0
        for round_number in range(t):
            my_act = history.my_actions[round_number]
            opponent_acts = history.opponent_actions[round_number, :]
            my_c = 1 if my_act else 0
            opponent_c = sum(opponent_acts)
            total_c = my_c + opponent_c
            if total_c >= self.game_description.m:
                success_count += 1
        success_rate = success_count / t
        cooperation_prob = success_rate
        cooperation_prob = max(cooperation_prob, self.p_min)
        cooperation_prob = min(cooperation_prob, self.p_max)
        if random.random() < cooperation_prob:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_326(BaseStrategy):
    """
    Forgiving Cooperation with Temporary Punishment strategy.
    
    Players initially cooperate. In subsequent rounds, if the previous round had
    enough cooperators (>=m), they cooperate again. If not, they defect once, then
    cooperate again in the following round to attempt recovery.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.will_cooperate_next = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.will_cooperate_next = False
            return Action.C
        prev_round = state.round_number - 1
        opponents_prev = history.opponent_actions[prev_round]
        sum_opponents_C = np.sum(opponents_prev)
        my_prev_action = history.my_actions[prev_round]
        total_C = sum_opponents_C + (1 if my_prev_action else 0)
        m = self.game_description.m
        if total_C >= m:
            self.will_cooperate_next = False
            return Action.C
        elif self.will_cooperate_next:
            self.will_cooperate_next = False
            return Action.C
        else:
            self.will_cooperate_next = True
            return Action.D

class Strategy_COLLECTIVE_327(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that cooperates initially and 
    adapts based on the number of cooperators in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            opponent_cooperations = np.sum(history.opponent_actions[prev_round])
            my_previous_action = history.my_actions[prev_round]
            total_cooperations = opponent_cooperations + my_previous_action
            if total_cooperations >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_328(BaseStrategy):
    """
    Adaptive Cooperatior with Historical Thresholding strategy for Collective Risk Dilemma.
    Cooperates initially, adapts based on previous round's cooperation, and decides in the last round based on historical cooperation average.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number < self.game_description.n_rounds - 1:
            prev_my_action = history.my_actions[-1]
            prev_opp_actions = history.opponent_actions[-1]
            prev_coop = prev_my_action + prev_opp_actions.sum()
            if prev_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D
        else:
            sum_coops = 0.0
            for t in range(len(history.my_actions)):
                my_action = history.my_actions[t]
                opp_actions = history.opponent_actions[t]
                sum_coops += my_action + opp_actions.sum()
            average = sum_coops / len(history.my_actions)
            if average >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_329(BaseStrategy):
    """
    Index-Based Cooperation Strategy for the Collective Risk Dilemma.
    Each player i Cooperates in round t if (i + t) mod n < m.
    Ensures exactly m Cooperate each round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.index = 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        n = self.game_description.n_players
        m = self.game_description.m
        if (self.index + t) % n < m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_330(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that balances persistence with forgiveness.
    Cooperates initially and continues if successful, defects temporarily after failures,
    then forgives and resumes cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defect_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.defect_remaining > 0:
            self.defect_remaining -= 1
            return Action.D
        prev_coop = sum(history.opponent_actions[-1, :]) + history.my_actions[-1]
        if prev_coop >= self.game_description.m:
            return Action.C
        else:
            self.defect_remaining = 2
            return Action.D

class Strategy_COLLECTIVE_331(BaseStrategy):
    """
    Grim Trigger Strategy for Collective Risk Dilemma:
    Cooperate in all rounds unless any previous round failed to meet the minimum cooperators (m), in which case defect for all subsequent rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        for round_idx in range(state.round_number):
            my_action = history.my_actions[round_idx]
            opponent_coop = history.opponent_actions[round_idx].sum()
            total_coop = my_action + opponent_coop
            if total_coop < self.m:
                return Action.D
        return Action.C

class Strategy_COLLECTIVE_332(BaseStrategy):
    """
    Forgiving Reciprocal Cooperation strategy balances reciprocity with forgiveness 
    to sustain cooperation over repeated rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defected_last_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.defected_last_round:
            self.defected_last_round = False
            return Action.C
        prev_round = state.round_number - 1
        opponent_actions_prev = history.opponent_actions[prev_round]
        num_opponents_coop = np.sum(opponent_actions_prev)
        my_prev_action = history.my_actions[prev_round]
        total_coop = num_opponents_coop + (1 if my_prev_action else 0)
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            self.defected_last_round = True
            return Action.D

class Strategy_COLLECTIVE_333(BaseStrategy):

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opp_prev_actions = history.opponent_actions[prev_round]
        sum_coop = int(my_prev_action) + opp_prev_actions.sum()
        if sum_coop < self.game_description.m:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_334(BaseStrategy):
    """
    Adaptive Cooperation with Punishment (ACP) Strategy.
    - Cooperate in the first round.
    - Cooperate if at least m players cooperated in the previous round.
    - Defect for the next 3 rounds if fewer than m players cooperated.
    - In the last round, cooperate based on the previous round's cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        game = self.game_description
        if round_num == 0:
            return Action.C
        if round_num == game.n_rounds - 1:
            prev_opp_actions = history.opponent_actions[-1, :]
            prev_my_action = history.my_actions[-1]
            prev_coop = sum(prev_opp_actions) + (1 if prev_my_action else 0)
            if prev_coop >= game.m:
                return Action.C
            else:
                return Action.D
        if self.punishment_remaining > 0:
            self.punishment_remaining -= 1
            if self.punishment_remaining < 0:
                self.punishment_remaining = 0
            return Action.D
        else:
            prev_opp_actions = history.opponent_actions[-1, :]
            prev_my_action = history.my_actions[-1]
            prev_coop = sum(prev_opp_actions) + (1 if prev_my_action else 0)
            if prev_coop >= game.m:
                return Action.C
            else:
                self.punishment_remaining = 2
                return Action.D

class Strategy_COLLECTIVE_335(BaseStrategy):
    """
    A strategy that encourages cooperation but punishes non-cooperation by defecting 
    for one round after a failure, then reverting back to cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.next_should_coop = True

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.next_should_coop:
            current_action = Action.C
            self.next_should_coop = False
            return current_action
        else:
            t = state.round_number
            last_round = t - 1
            my_last_action = history.my_actions[last_round]
            opponent_last_actions = history.opponent_actions[last_round]
            sum_coop = my_last_action + np.sum(opponent_last_actions)
            if sum_coop < self.game_description.m:
                current_action = Action.D
                self.next_should_coop = True
            else:
                current_action = Action.C
                self.next_should_coop = False
            return current_action

class Strategy_COLLECTIVE_337(BaseStrategy):
    """
    Adaptive cooperation strategy for the Collective Risk Dilemma game.
    
    This strategy encourages cooperation in the first round. In subsequent rounds, it decides based on the historical success rate of meeting the minimum cooperators needed (m). The player cooperates if the success rate is at least m/n; otherwise, they defect.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n = game_description.n_players
        self.m = game_description.m
        self.round_number = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number
        success_count = 0
        for t_prime in range(t):
            my_action = history.my_actions[t_prime]
            opponent_actions = history.opponent_actions[t_prime]
            total_C = sum(opponent_actions) + (1 if my_action else 0)
            if total_C >= self.m:
                success_count += 1
        success_rate = success_count / t
        threshold = self.m / self.n
        if success_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_338(BaseStrategy):
    """
    A strategy that begins with cooperation, punishes when cooperation falls below the threshold,
    and forgives after one round of punishment to reset cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t_prev = state.round_number - 1
        my_prev_action = history.my_actions[t_prev]
        opponents_prev = sum(history.opponent_actions[t_prev])
        c_prev = my_prev_action + opponents_prev
        if c_prev >= self.m:
            return Action.C
        elif my_prev_action == False:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_339(BaseStrategy):
    """
    Responsive Cooperation with Recovery Strategy.
    
    Players start by cooperating. In subsequent rounds, they cooperate if the previous round met the cooperation threshold. If not, they defect for one round before attempting to cooperate again.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_action = None
        self.consecutive_defects = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.last_action = Action.C
            self.consecutive_defects = 0
            return Action.C
        prev_round = state.round_number - 1
        opponent_actions_prev = history.opponent_actions[prev_round]
        my_action_prev = history.my_actions[prev_round]
        prev_coop_opponents = sum(opponent_actions_prev)
        prev_coop_total = prev_coop_opponents + (1 if my_action_prev else 0)
        m = self.game_description.m
        if prev_coop_total >= m:
            self.consecutive_defects = 0
            self.last_action = Action.C
            return Action.C
        elif self.last_action == Action.D:
            if self.consecutive_defects < 1:
                self.consecutive_defects += 1
                return Action.D
            else:
                self.consecutive_defects = 0
                self.last_action = Action.C
                return Action.C
        else:
            self.consecutive_defects = 1
            self.last_action = Action.D
            return Action.D

class Strategy_COLLECTIVE_340(BaseStrategy):
    """
    A strategy to balance responsiveness and recovery in Collective Risk Dilemma.
    Cooperates initially, continues if threshold met, defects otherwise, and resets after defecting.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_prev_action = history.my_actions[-1]
        if not my_prev_action:
            return Action.C
        opp_coop_prev = sum(history.opponent_actions[-1])
        my_coop_prev = 1 if my_prev_action else 0
        total_coop_prev = opp_coop_prev + my_coop_prev
        m = self.game_description.m
        if total_coop_prev >= m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_341(BaseStrategy):
    """
    A Cooperative Punisher with Forgiveness strategy. Players cooperate initially and maintain cooperation as long as the previous round met the minimum required. Otherwise, they defect once before potentially returning to cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        opp_coops = sum(history.opponent_actions[previous_round, :])
        if history.my_actions[previous_round]:
            total_coops = opp_coops + 1
        else:
            total_coops = opp_coops
        if total_coops >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_342(BaseStrategy):
    """
    Cooperate in the first round. In subsequent rounds, cooperate if at least m players cooperated in the previous round; otherwise, defect.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_last_round = history.my_actions[-1]
        opponents_last_round = history.opponent_actions[-1]
        my_coop = 1 if my_last_round else 0
        opponents_coop = np.sum(opponents_last_round)
        total_coop = my_coop + opponents_coop
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_343(BaseStrategy):
    """
    A strategy that encourages cooperation by punishing defection and resetting after consecutive failures.
    Cooperates initially and continues if enough players cooperate; defects otherwise. Resets to cooperation
    after three consecutive rounds of insufficient cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_failures = 0
        self.reset_threshold = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev_action = history.my_actions[previous_round]
        opponents_prev_actions = history.opponent_actions[previous_round, :]
        total_coop = my_prev_action + np.sum(opponents_prev_actions)
        if total_coop >= self.game_description.m:
            self.consecutive_failures = 0
            return Action.C
        else:
            self.consecutive_failures += 1
            if self.consecutive_failures >= self.reset_threshold:
                self.consecutive_failures = 0
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_344(BaseStrategy):
    """
    This strategy encourages sustained cooperation by penalizing only when necessary 
    and allowing recovery from temporary drops below the threshold.
    It cooperates in the first round and subsequent rounds where the previous round 
    met the cooperation threshold. If the previous round did not meet the threshold, 
    it defects and plans to cooperate in the next round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.next_cooperate = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif self.next_cooperate:
            self.next_cooperate = False
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev = history.my_actions[prev_round]
            opponents_prev = history.opponent_actions[prev_round]
            total_prev = sum(opponents_prev) + (1 if my_prev else 0)
            if total_prev >= self.game_description.m:
                return Action.C
            else:
                self.next_cooperate = True
                return Action.D

class Strategy_COLLECTIVE_345(BaseStrategy):
    """
    Adaptive Cooperation with Forgiveness strategy for the Collective Risk Dilemma.
    Cooperates initially, continues if cooperation threshold is met, defects otherwise,
    and resets cooperation after 3 consecutive rounds of insufficient cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defect_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opp_prev_actions = history.opponent_actions[prev_round, :]
        total_coop_prev = int(my_prev_action) + np.sum(opp_prev_actions)
        if total_coop_prev >= self.game_description.m:
            self.defect_streak = 0
            return Action.C
        else:
            self.defect_streak += 1
            if self.defect_streak >= 3:
                self.defect_streak = 0
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_346(BaseStrategy):
    """
    Collective Risk Threshold Strategy
    Cooperates initially and continues if cooperation meets threshold or shows increasing trend.
    Defects in last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.cooperation_counts = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        if t == 0:
            return Action.C
        elif t == self.n_rounds - 1:
            return Action.D
        else:
            prev_t = t - 1
            my_prev_action = history.my_actions[prev_t]
            my_prev_coop = 1 if my_prev_action else 0
            opponent_prev_actions = history.opponent_actions[prev_t]
            opponent_prev_coop = sum(opponent_prev_actions)
            prev_coop_count = my_prev_coop + opponent_prev_coop
            self.cooperation_counts.append(prev_coop_count)
            if prev_coop_count >= self.m:
                return Action.C
            else:
                trend_up = False
                if len(self.cooperation_counts) >= 2:
                    if self.cooperation_counts[-1] > self.cooperation_counts[-2]:
                        trend_up = True
                if trend_up:
                    return Action.C
                else:
                    return Action.D

class Strategy_COLLECTIVE_347(BaseStrategy):
    """
    Adaptive Cooperation with Forgiveness strategy for Collective Risk Dilemma.
    
    This strategy starts with cooperation and adapts based on previous rounds.
    It ensures cooperation if the minimum threshold is met; otherwise, it defects
    for up to two rounds before reverting to cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.total_rounds = game_description.n_rounds
        self.consecutive_defects = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opp_prev_actions = history.opponent_actions[prev_round, :]
            opp_c = np.sum(opp_prev_actions)
            total_c = my_prev_action + opp_c
            if total_c >= self.m:
                self.consecutive_defects = 0
                return Action.C
            elif self.consecutive_defects < 2:
                self.consecutive_defects += 1
                return Action.D
            else:
                self.consecutive_defects = 0
                return Action.C

class Strategy_COLLECTIVE_348(BaseStrategy):
    """
    A strategy to sustain cooperation in a Collective Risk Dilemma through initial cooperation, 
    responsive punishment, and informed final round decisions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        if state.round_number == self.n_rounds - 1:
            total_coops = 0.0
            for s in range(state.round_number):
                coop_self = history.my_actions[s]
                coop_others = np.sum(history.opponent_actions[s, :])
                total_coops += coop_self + coop_others
            avg_coops = total_coops / state.round_number
            if avg_coops >= self.m:
                return Action.C
            else:
                return Action.D
        else:
            prev_round = state.round_number - 1
            coop_self_prev = history.my_actions[prev_round]
            coop_others_prev = np.sum(history.opponent_actions[prev_round, :])
            total_prev = coop_self_prev + coop_others_prev
            if total_prev >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_349(BaseStrategy):
    """
    This strategy cooperates in the first and last rounds. For the middle rounds, it cooperates if the previous round had enough cooperators (>= m); otherwise, it defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.n_rounds - 1:
            return Action.C
        prev_round = state.round_number - 1
        my_prev = history.my_actions[prev_round]
        opponent_prev = sum(history.opponent_actions[prev_round])
        total_coop = int(my_prev) + opponent_prev
        if total_coop >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_350(BaseStrategy):
    """
    Adaptive Cooperation with Forgiveness (ACF) strategy for the Collective Risk Dilemma.
    
    The strategy starts by cooperating in the first round. In subsequent rounds, it cooperates 
    if the number of cooperators in the previous round met or exceeded the threshold m. If not,
    it defects but will revert to cooperating after one round of defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defect_streak = 0

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_prev_actions = history.opponent_actions[prev_round]
        total_coop = int(my_prev_action) + int(opponents_prev_actions.sum())
        if total_coop >= self.game_description.m:
            self.defect_streak = 0
            return Action.C
        else:
            new_streak = self.defect_streak + 1
            if new_streak > 1:
                return Action.C
            else:
                return Action.D
        if total_coop < self.game_description.m:
            self.defect_streak += 1
            if self.defect_streak > 1:
                self.defect_streak = 0

class Strategy_COLLECTIVE_351(BaseStrategy):

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev = history.my_actions[prev_round]
        opponent_prev = history.opponent_actions[prev_round]
        total_coop = my_prev + opponent_prev.sum()
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_352(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that starts with cooperation and continues if the threshold is met, 
    otherwise defects and retries cooperation in subsequent rounds to maintain cooperation while allowing recovery.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev_action = history.my_actions[previous_round]
        opponent_prev_actions = history.opponent_actions[previous_round, :]
        num_opponent_coop = sum(opponent_prev_actions)
        total_coop = num_opponent_coop + (1 if my_prev_action else 0)
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_354(BaseStrategy):
    """
    A deterministic strategy to ensure sufficient cooperation in a repeated game setting.
    Cooperates in the first round and adjusts based on the previous round's cooperation level.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_actions_last_round = history.opponent_actions[-1, :]
        sum_opponents = np.sum(opponent_actions_last_round)
        my_last_action = history.my_actions[-1]
        total_coop = sum_opponents + (1 if my_last_action else 0)
        if total_coop >= self.m:
            next_action = my_last_action
        else:
            next_action = not my_last_action
        return Action.C if next_action else Action.D

class Strategy_COLLECTIVE_355(BaseStrategy):
    """
    Adaptive Collective Cooperation Strategy.
    Cooperates initially and in subsequent rounds based on whether the previous round met the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            last_round = state.round_number - 1
            my_prev = history.my_actions[last_round]
            opp_prev = history.opponent_actions[last_round, :]
            total_coop = my_prev + np.sum(opp_prev)
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_356(BaseStrategy):
    """
    Adaptive Cooperation with Forgiveness strategy for the Collective Risk Dilemma.
    This strategy promotes sustained cooperation by being responsive to others' actions
    and forgiving past defections if cooperation resumes.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.waiting_for_forgiveness = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        m = self.game_description.m
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        if state.round_number == r - 1:
            count = 0
            for t_prev in range(state.round_number):
                my_prev = history.my_actions[t_prev]
                opp_prev = history.opponent_actions[t_prev, :]
                total = my_prev + opp_prev.sum()
                if total >= m:
                    count += 1
            if count > state.round_number / 2:
                return Action.C
            else:
                return Action.D
        elif self.waiting_for_forgiveness:
            prev_round = state.round_number - 1
            my_prev = history.my_actions[prev_round]
            opp_prev = history.opponent_actions[prev_round, :]
            total = my_prev + opp_prev.sum()
            if total >= m:
                self.waiting_for_forgiveness = False
                return Action.C
            else:
                return Action.D
        else:
            prev_round = state.round_number - 1
            my_prev = history.my_actions[prev_round]
            opp_prev = history.opponent_actions[prev_round, :]
            total = my_prev + opp_prev.sum()
            if total >= m:
                return Action.C
            else:
                self.waiting_for_forgiveness = True
                return Action.D

class Strategy_COLLECTIVE_357(BaseStrategy):
    """
    Implements a strategy where the player Cooperates if at least m players Cooperated in the previous round,
    otherwise Defects. In the first round, the player Defects since there's no prior round to base the decision on.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        else:
            prev_round = state.round_number - 1
            my_action = history.my_actions[prev_round]
            opponents_actions = history.opponent_actions[prev_round]
            total_coop = my_action + sum(opponents_actions)
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_358(BaseStrategy):
    """
    A deterministic strategy for the Collective Risk Dilemma that 
    promotes cooperation, punishes when cooperation falls below a threshold, 
    and allows recovery from breakdowns.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_action_was_punishment = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.last_action_was_punishment = False
            return Action.C
        if self.last_action_was_punishment:
            self.last_action_was_punishment = False
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opponents_prev_actions = history.opponent_actions[prev_round, :]
            sum_opponents = np.sum(opponents_prev_actions)
            total_coop = sum_opponents + (1 if my_prev_action else 0)
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                self.last_action_was_punishment = True
                return Action.D

class Strategy_COLLECTIVE_359(BaseStrategy):
    """
    Adaptive Cooperation Based on Historical Performance strategy for Collective Risk Dilemma.
    Cooperates in the first round and adapts based on the number of cooperators in the previous round.
    Continues to cooperate if at least m players cooperated previously; otherwise, defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_past = history.my_actions[prev_round]
            opponent_actions_prev = history.opponent_actions[prev_round]
            coop_count = (1 if my_past else 0) + opponent_actions_prev.sum()
            if coop_count >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_360(BaseStrategy):
    """
    Adaptive Cooperation with Punishment Strategy.
    Cooperates initially, continues cooperation if the previous round met the threshold,
    defects if not, and always cooperates in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        my_last_action = history.my_actions[state.round_number - 1]
        opp_last_actions = history.opponent_actions[state.round_number - 1, :]
        my_c = 1 if my_last_action else 0
        opp_coop = sum(opp_last_actions)
        total_coop = my_c + opp_coop
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_362(BaseStrategy):
    """
    A strategy that starts with cooperation and continues if the previous round met the cooperation threshold.
    Defects for one round if the threshold was not met, then re-evaluates conditions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev_action = history.my_actions[previous_round]
        opponent_actions = history.opponent_actions[previous_round, :]
        prev_coop = my_prev_action + np.sum(opponent_actions)
        if prev_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_363(BaseStrategy):
    """
    A strategy that starts with cooperation and adapts based on the previous round's cooperation level.
    Cooperates if the previous round met the minimum required cooperators (m), otherwise defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev = history.my_actions[prev_round]
        opp_prev = history.opponent_actions[prev_round]
        total_coop = my_prev + opp_prev.sum()
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_364(BaseStrategy):
    """
    Adaptable cooperation strategy based on group success rate.
    Starts with high cooperation, adjusts based on recent group success.
    Cooperates with probability adjusted dynamically.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.coop_prob = 0.8
        self.min_coop_prob = 0.3
        self.coop_threshold = 0.6
        self.increment = 0.1
        self.decrement = 0.15

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number
        success_count = 0
        for r in range(t):
            my_c = history.my_actions[r].item()
            opponent_actions = history.opponent_actions[r]
            total_coop = int(my_c) + opponent_actions.sum()
            if total_coop >= self.game_description.m:
                success_count += 1
        success_rate = success_count / t
        if success_rate > self.coop_threshold:
            self.coop_prob = min(1.0, self.coop_prob + self.increment)
        elif success_rate < self.coop_threshold:
            self.coop_prob = max(self.min_coop_prob, self.coop_prob - self.decrement)
        if random.random() < self.coop_prob:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_365(BaseStrategy):
    """
    A strategy where all players cooperate in every round to foster sustained cooperation.
    Based on the Collective Risk Dilemma strategy where players continue to cooperate regardless of previous outcomes.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        return Action.C

class Strategy_COLLECTIVE_366(BaseStrategy):
    """
    A strategy that promotes sustained cooperation by rewarding cooperation and
    punishing defection, with a recovery mechanism to restart cooperation after
    isolated failures.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.was_punishing = False

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            self.was_punishing = False
            return Action.C
        if self.was_punishing:
            self.was_punishing = False
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_prev_actions = history.opponent_actions[prev_round]
        count_c = my_prev_action + sum(opponent_prev_actions)
        if count_c >= self.game_description.m:
            return Action.C
        else:
            self.was_punishing = True
            return Action.D

class Strategy_COLLECTIVE_367(BaseStrategy):
    """
    A strategy that starts by cooperating and then adapts based on recent success of cooperation.
    Cooperates if more than half of the last three rounds met the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number
        lookback = min(3, t)
        count_success = 0
        for round_num in range(t - lookback, t):
            my_action = history.my_actions[round_num]
            opponents = history.opponent_actions[round_num]
            total_coop = my_action + np.sum(opponents)
            if total_coop >= self.m:
                count_success += 1
        if count_success > lookback / 2:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_368(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game where players cooperate 
    if the number of cooperators in the previous round was below the threshold m.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t_prev = state.round_number - 1
        my_prev = history.my_actions[t_prev]
        opponents_prev = history.opponent_actions[t_prev, :]
        c_prev = my_prev + sum(opponents_prev)
        if c_prev < self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_369(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that starts with cooperation, 
    continues if enough players cooperate in the previous round, and defects otherwise.
    Resets to cooperation after three consecutive defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_my_action = history.my_actions[state.round_number - 1]
            prev_opponents_actions = history.opponent_actions[state.round_number - 1]
            cooperators_last_round = int(prev_my_action) + sum(prev_opponents_actions)
            if cooperators_last_round >= self.game_description.m:
                self.consecutive_defections = 0
                return Action.C
            else:
                self.consecutive_defections += 1
                if self.consecutive_defections >= 3:
                    self.consecutive_defections = 0
                    return Action.C
                else:
                    return Action.D

class Strategy_COLLECTIVE_370(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that promotes sustained cooperation through adaptive decisions.
    Players initially cooperate to establish trust. In subsequent rounds, cooperation continues if the threshold is met;
    otherwise, a deterministic method based on player IDs ensures a fair distribution of cooperative efforts.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.id = random.randint(1, game_description.n_players)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        c_prev = 0
        if history.my_actions[prev_round]:
            c_prev += 1
        c_prev += history.opponent_actions[prev_round].sum()
        n = self.game_description.n_players
        m = self.game_description.m
        if c_prev >= m:
            return Action.C
        else:
            s = n - c_prev + 1
            target = m - c_prev
            if self.id % s < target:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_371(BaseStrategy):
    """
    Adaptive Cooperation strategy with restart mechanism to address the Collective Risk Dilemma.
    Cooperates initially, continues if quorum met, defects otherwise, and retries cooperation after m consecutive failures.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_failures = 0
        self.s = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_prev_action = history.my_actions[-1]
        opponent_prev_actions = history.opponent_actions[-1, :]
        total_coop_prev = my_prev_action + sum(opponent_prev_actions)
        if total_coop_prev >= self.game_description.m:
            self.consecutive_failures = 0
            return Action.C
        else:
            self.consecutive_failures += 1
            if self.consecutive_failures < self.s:
                return Action.D
            else:
                self.consecutive_failures = 0
                return Action.C

class Strategy_COLLECTIVE_372(BaseStrategy):
    """
    Adaptive Cooperation Based on Past Performance.
    Cooperates initially and continues if past average meets threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m_threshold = game_description.m
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        history_length = len(history.my_actions)
        start = max(0, history_length - 3)
        recent_rounds = range(start, history_length)
        total_cooperators = 0
        for rd in recent_rounds:
            my_contrib = 1 if history.my_actions[rd] else 0
            opponents_contrib = np.sum(history.opponent_actions[rd])
            total_cooperators += my_contrib + opponents_contrib
        avg_cooperators = total_cooperators / (history_length - start)
        if avg_cooperators >= self.m_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_373(BaseStrategy):
    """Adaptive Cooperative Restart (ACR) Strategy.
    
    Cooperates initially, continues if threshold met, defects otherwise, 
    and resets cooperation after two consecutive defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round = current_round - 1
        total_players = self.game_description.n_players
        opponent_actions_last = history.opponent_actions[prev_round, :]
        count_C = sum(opponent_actions_last) + history.my_actions[prev_round]
        if count_C >= self.m:
            return Action.C
        consecutive_defects = 0
        if prev_round >= 0:
            if not history.my_actions[prev_round]:
                consecutive_defects += 1
        prev_prev_round = prev_round - 1
        if prev_prev_round >= 0 and prev_prev_round < len(history.my_actions):
            if not history.my_actions[prev_prev_round]:
                consecutive_defects += 1
        if consecutive_defects >= 2:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_374(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game where players initially cooperate.
    Players punish by defecting if the previous round's cooperation was insufficient and they had cooperated.
    After punishing, they resume cooperation regardless of others' actions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.last_punished = False
        self.my_previous_action = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            action = Action.C
            self.my_previous_action = action
            return action
        if self.last_punished:
            action = Action.C
            self.last_punished = False
        else:
            previous_round = state.round_number - 1
            prev_my_action = history.my_actions[previous_round]
            prev_others_actions = history.opponent_actions[previous_round, :]
            prev_coop_count = np.sum(prev_others_actions) + (1 if prev_my_action else 0)
            if prev_coop_count < self.m:
                if prev_my_action:
                    action = Action.D
                    self.last_punished = True
                else:
                    action = Action.C
            else:
                action = Action.C
        self.my_previous_action = action
        return action

class Strategy_COLLECTIVE_375(BaseStrategy):

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        return Action.C

class Strategy_COLLECTIVE_376(BaseStrategy):
    """
    Adaptive Cooperate-Punish with Reset strategy for Collective Risk Dilemma.
    Cooperates initially, punishes failures, and resets after two consecutive failures.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_failures = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        s = state.round_number - 1
        prev_my_action = history.my_actions[s]
        prev_opponent_actions = history.opponent_actions[s, :]
        prev_cooperators = prev_my_action + np.sum(prev_opponent_actions)
        if prev_cooperators >= self.game_description.m:
            self.consecutive_failures = 0
            return Action.C
        else:
            self.consecutive_failures += 1
            if self.consecutive_failures >= 2:
                self.consecutive_failures = 0
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_377(BaseStrategy):
    """
    Adaptive Cooperation with Endgame Protection Strategy.

    This strategy starts by cooperating to establish a cooperative norm. 
    It then continues to cooperate if the previous round met the cooperation threshold. 
    If the threshold was not met, it defects once and then reverts to cooperation unless it's nearing the endgame. 
    In the final 5% of rounds, it defects to maximize personal payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_desc = game_description
        n_rounds = self.game_desc.n_rounds
        self.cutoff_round = n_rounds - math.ceil(0.05 * n_rounds)
        self.punishment_mode = False

    def __call__(self, state: GameState, history) -> Action:
        if history is None:
            self.punishment_mode = False
            return Action.C
        current_round = state.round_number
        if current_round >= self.cutoff_round:
            return Action.D
        if self.punishment_mode:
            self.punishment_mode = False
            return Action.C
        my_prev_action = history.my_actions[-1]
        opp_prev_actions = history.opponent_actions[-1]
        opp_coop = opp_prev_actions.sum()
        my_coop = my_prev_action
        total_coop = opp_coop + my_coop
        if total_coop >= self.game_desc.m:
            return Action.C
        else:
            action = Action.D
            next_round = current_round + 1
            if next_round < self.cutoff_round:
                self.punishment_mode = True
            return action

class Strategy_COLLECTIVE_378(BaseStrategy):
    """
    A strategy where players cooperate only when necessary based on the previous round's cooperation level.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev_action = history.my_actions[previous_round]
        opponent_prev_actions_sum = history.opponent_actions[previous_round].sum()
        total_coop = my_prev_action + opponent_prev_actions_sum
        if total_coop >= self.game_description.m:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_379(BaseStrategy):
    """
    Adaptive Collective Cooperation Strategy for the Collective Risk Dilemma.
    Cooperates initially, then cooperates if previous round met the threshold,
    else defects, encouraging others to cooperate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev = history.my_actions[prev_round]
        opp_prev = history.opponent_actions[prev_round]
        total_coop = my_prev + opp_prev.sum()
        if total_coop >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_380(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma that balances cooperation with proportionate punishment.
    Cooperates initially and continues if the cooperation threshold is met; otherwise, defects with probability based on the shortfall.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_last = history.my_actions[prev_round]
        opp_last = history.opponent_actions[prev_round, :]
        c_prev = int(my_last) + sum(opp_last)
        if c_prev >= self.m:
            return Action.C
        else:
            p_defect = (self.m - c_prev) / self.n
            if random.random() < p_defect:
                return Action.D
            else:
                return Action.C

class Strategy_COLLECTIVE_381(BaseStrategy):
    """
    A strategy that cooperates in the first round and continues to cooperate if at least m players
    cooperated in the previous round, otherwise defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.m = game_description.m
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opp_prev_actions = history.opponent_actions[prev_round]
        total_coop = opp_prev_actions.sum() + (1 if my_prev_action else 0)
        if total_coop >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_382(BaseStrategy):
    """
    A strategy to maintain cooperation in Collective Risk Dilemma by punishing temporary low cooperation.
    Cooperates initially and continues if enough players cooperate. Defects for a set number of rounds if cooperation drops below the threshold, then attempts to recover.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_length = 2
        self.remaining_punishment = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.remaining_punishment > 0:
            self.remaining_punishment -= 1
            return Action.D
        else:
            my_last_action = history.my_actions[-1]
            opponents_last_actions = history.opponent_actions[-1, :]
            sum_coop = my_last_action + sum(opponents_last_actions)
            if sum_coop < self.game_description.m:
                self.remaining_punishment = self.punishment_length
                return Action.D
            else:
                return Action.C

class Strategy_COLLECTIVE_383(BaseStrategy):
    """
    A strategy that balances cooperation and punishment to maintain the cooperation threshold.
    - Cooperates in the first round.
    - Subsequent rounds: Cooperate if enough players cooperated last round; otherwise, forgive or punish based on last action.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number
        my_prev = history.my_actions[t - 1]
        opp_prev = history.opponent_actions[t - 1, :]
        coop_prev = my_prev + int(np.sum(opp_prev))
        m = self.game_description.m
        if coop_prev >= m:
            return Action.C
        elif my_prev:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_384(BaseStrategy):
    """
    A strategy that balances reciprocity with a cooperation reset mechanism.
    Cooperates initially, reciprocates cooperation, defects if cooperation threshold isn't met,
    and resets to cooperation after two consecutive defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.past_actions = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        n_rounds = self.game_description.n_rounds
        m = self.game_description.m
        if current_round == 0:
            action = Action.C
        elif current_round == n_rounds - 1:
            action = Action.D
        else:
            if history is None:
                action = Action.D
            else:
                previous_round = current_round - 1
                my_prev = history.my_actions[previous_round]
                opponent_actions_last = history.opponent_actions[previous_round, :]
                opponent_coop = np.count_nonzero(opponent_actions_last)
                prev_coop_count = int(my_prev) + opponent_coop
                if prev_coop_count >= m:
                    action = Action.C
                else:
                    action = Action.D
                if len(self.past_actions) >= 2 and self.past_actions[-1] == Action.D and (self.past_actions[-2] == Action.D):
                    action = Action.C
            self.past_actions.append(action)
            if len(self.past_actions) > 2:
                self.past_actions.pop(0)
        return action

class Strategy_COLLECTIVE_385(BaseStrategy):

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_coop = history.my_actions[prev_round]
        opponent_coop = np.sum(history.opponent_actions[prev_round, :])
        total_coop = my_coop + opponent_coop
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_386(BaseStrategy):
    """
    Adaptive Collective Cooperation Strategy.
    Cooperate in the first round. For subsequent rounds, look at the last 5 rounds (or fewer if not enough history).
    Count how many of those rounds met or exceeded the cooperation threshold. Cooperate if more than half met the threshold.
    Defect otherwise.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.n_rounds = game_description.n_rounds

    def __call__(self, state: GameState, history: PlayerHistory):
        if state.round_number == 0:
            return Action.C
        t = min(5, len(history.my_actions))
        start = len(history.my_actions) - t
        successful_coops = 0
        for i in range(start, len(history.my_actions)):
            opp_coop = sum(history.opponent_actions[i, :])
            my_coop = history.my_actions[i]
            total = opp_coop + (1 if my_coop else 0)
            if total >= self.m:
                successful_coops += 1
        proportion = successful_coops / t
        if proportion > 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_387(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that starts with cooperation, 
    defects once if fewer than m players cooperate, and then reverts to cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev_action = history.my_actions[previous_round]
        opponents_prev_actions = history.opponent_actions[previous_round]
        total_coop = my_prev_action + np.sum(opponents_prev_actions)
        if total_coop >= self.game_description.m:
            return Action.C
        elif my_prev_action:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_388(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma where players cooperate initially and continue 
    cooperating if the previous round met the minimum cooperation threshold. After a failure, 
    they retry cooperation periodically.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number
        prev_t = t - 1
        my_prev = history.my_actions[prev_t]
        opponents_prev = history.opponent_actions[prev_t]
        total_prev = my_prev + opponents_prev.sum()
        if total_prev >= self.m:
            return Action.C
        elif t >= 2:
            prev_prev_t = prev_t - 1
            my_prev_prev = history.my_actions[prev_prev_t]
            opponents_prev_prev = history.opponent_actions[prev_prev_t]
            total_prev_prev = my_prev_prev + opponents_prev_prev.sum()
            if total_prev_prev >= self.m:
                return Action.C
            else:
                return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_389(BaseStrategy):
    """
    A strategy for maintaining cooperation in Collective Risk Dilemma games.
    Implements initial cooperation, sustained cooperation when beneficial, and
    recovery mechanisms when cooperation falls below the required threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.recovery_rounds = 0

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.recovery_rounds > 0:
            self.recovery_rounds -= 1
            return Action.D
        else:
            my_prev_action = history.my_actions[-1]
            opponent_prev_actions = history.opponent_actions[-1, :]
            total_coop = my_prev_action + sum(opponent_prev_actions)
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                self.recovery_rounds = 1
                return Action.D

class Strategy_COLLECTIVE_390(BaseStrategy):
    """
    A strategy that starts with cooperation and adapts based on previous round's cooperation level.
    Cooperates again if enough players cooperated last round; otherwise, has a chance to defect.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_last = history.my_actions[prev_round]
        opponents_last = history.opponent_actions[prev_round, :]
        s = my_last + np.sum(opponents_last)
        if s >= self.game_description.m:
            return Action.C
        elif random.random() < 0.2:
            return Action.D
        else:
            return Action.C

@dataclass
class Strategy_COLLECTIVE_391(BaseStrategy):
    """
    A strategy that cooperates if the previous round met the cooperation threshold, 
    otherwise defects. It starts by cooperating in the first round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_t = state.round_number - 1
        my_last_action = history.my_actions[prev_t]
        opponent_last_actions = history.opponent_actions[prev_t]
        sum_coop = my_last_action + np.sum(opponent_last_actions)
        if sum_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_392(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that begins with cooperation and adapts based on the number of cooperators in the previous round.
    Cooperates if the previous round met the minimum required cooperators, otherwise defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev = history.my_actions[previous_round]
        opponents_prev = history.opponent_actions[previous_round, :]
        me_c = 1 if my_prev else 0
        opponent_c = int(opponents_prev.sum())
        count_C = me_c + opponent_c
        if count_C >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_393(BaseStrategy):
    """
    A deterministic strategy that balances punishment and cooperation. 
    Cooperates initially, then cooperates if the threshold was met in the previous round or if it's the last round; otherwise, defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        else:
            prev_round = current_round - 1
            opponent_C_prev = sum(history.opponent_actions[prev_round, :])
            own_C_prev = history.my_actions[prev_round]
            total_C_prev = opponent_C_prev + own_C_prev
            if total_C_prev >= self.m or current_round == self.n_rounds - 1:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_394(BaseStrategy):
    """
    Implements the Collective Risk Strategy to encourage sustained cooperation by adapting based on historical success.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        m = self.game_description.m
        count_success = 0
        for r in range(state.round_number):
            my_c = history.my_actions[r]
            opponents_c = history.opponent_actions[r, :]
            total_c = my_c + np.sum(opponents_c)
            if total_c >= m:
                count_success += 1
        total_rounds = state.round_number
        success_rate = count_success / total_rounds
        if success_rate > 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_395(BaseStrategy):
    """
    Responsive Cooperation with Punishment Strategy.

    Cooperates initially and in subsequent rounds if the minimum number of 
    cooperators was met in the previous round. defects as a punitive measure 
    otherwise, reverting back to cooperation when enough players cooperate again.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.current_round = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        if prev_round >= 0 and history is not None:
            my_last_action = history.my_actions[prev_round]
            opp_last_actions = history.opponent_actions[prev_round]
            coop_count = my_last_action + opp_last_actions.sum()
            if coop_count >= self.game_description.m:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_396(BaseStrategy):
    """
    Cooperate in each round if the number of cooperators in the previous round was at least m; otherwise defect.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opponents_prev_actions = history.opponent_actions[prev_round, :]
            total_coop = (1 if my_prev_action else 0) + opponents_prev_actions.sum()
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_397(BaseStrategy):
    """
    A strategy that promotes cooperation based on the number of cooperators in the previous round.
    Cooperates initially and continues if the minimum number of cooperators is met.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        my_last_action = int(history.my_actions[last_round])
        opponent_last_actions = history.opponent_actions[last_round]
        sum_opponent_last = np.sum(opponent_last_actions)
        total_coop = my_last_action + sum_opponent_last
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_398(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that promotes sustained cooperation.
    Players cooperate in the first round and continue if the minimum cooperators threshold is met.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_last = history.my_actions[prev_round]
        opponents_last = history.opponent_actions[prev_round, :]
        total_last = my_last + sum(opponents_last)
        if total_last >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_399(BaseStrategy):
    """
    A strategy that balances initial cooperation, responsive adaptation to others' actions, and periodic cooperation restarts.
    Initially cooperates, adapts based on past cooperation levels, and restarts cooperation after 3 consecutive defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defects = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.consecutive_defects >= 3:
            self.consecutive_defects = 0
            return Action.C
        opp_actions_last = history.opponent_actions[-1]
        coop_opponents = sum(opp_actions_last)
        my_last = history.my_actions[-1]
        total_C = coop_opponents + (1 if my_last else 0)
        if total_C >= self.game_description.m:
            self.consecutive_defects = 0
            return Action.C
        else:
            self.consecutive_defects += 1
            return Action.D

class Strategy_COLLECTIVE_400(BaseStrategy):
    """
    Strategy to encourage cooperation based on previous round outcomes.
    Cooperates in the first round and continues if the previous round met the minimum cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_action = history.my_actions[prev_round]
        opponent_actions = history.opponent_actions[prev_round]
        opponent_coop = np.sum(opponent_actions)
        total_coop = opponent_coop + (1 if my_action else 0)
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_401(BaseStrategy):
    """
    A reciprocal cooperation strategy based on the collective past performance.
    Cooperates if the previous round met the minimum cooperators threshold; otherwise, defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev_action = history.my_actions[previous_round]
        opponents_prev_actions = history.opponent_actions[previous_round, :]
        count_c_prev = my_prev_action + sum(opponents_prev_actions)
        if count_c_prev >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_402(BaseStrategy):
    """
    Strategy: Adaptive Forgiveness with Final Cooperation.
    Cooperates initially, adapts based on threshold of cooperators,
    and cooperates in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_action = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            action = Action.C
            self.last_action = action
            return action
        if state.round_number == self.game_description.n_rounds - 1:
            action = Action.C
            self.last_action = action
            return action
        prev_round = state.round_number - 1
        my_prev = history.my_actions[prev_round]
        opponents_prev = history.opponent_actions[prev_round, :]
        total_prev_c = np.sum(opponents_prev) + my_prev
        if total_prev_c >= self.game_description.m:
            action = Action.C
            self.last_action = action
        else:
            if self.last_action == Action.C:
                action = Action.D
            else:
                action = Action.C
            self.last_action = action
        return action

class Strategy_COLLECTIVE_403(BaseStrategy):
    """
    A strategy promoting sustained cooperation through adaptive responses to collective outcomes.
    
    - Starts with cooperation.
    - Continues if previous round had sufficient cooperators.
    - Defects during failures, with a recovery attempt after a set number of failures.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.s = 2
        self.counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t_prev = state.round_number - 1
        opponent_actions_prev = history.opponent_actions[t_prev]
        my_action_prev = history.my_actions[t_prev]
        sum_opponents_coop = np.sum(opponent_actions_prev)
        my_coop = 1 if my_action_prev else 0
        total_coop_prev = sum_opponents_coop + my_coop
        previous_met = total_coop_prev >= self.game_description.m
        if previous_met:
            self.counter = 0
            return Action.C
        else:
            self.counter += 1
            if self.counter < self.s:
                return Action.D
            else:
                self.counter = 0
                return Action.C

class Strategy_COLLECTIVE_404(BaseStrategy):
    """
    An adaptive strategy based on historical success of cooperation. Players Cooperate initially and switch based on past outcomes.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        if t == 0:
            return Action.C
        else:
            m = self.game_description.m
            s = 0
            for r in range(t):
                my_coop = history.my_actions[r]
                opponent_coop = np.sum(history.opponent_actions[r])
                total_coop = my_coop + opponent_coop
                if total_coop >= m:
                    s += 1
            p = s / t
            if p > 0.5:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_405(BaseStrategy):
    """
    An adaptive strategy to maintain cooperation in a Collective Risk Dilemma by 
    encouraging sustained cooperation and allowing recovery from temporary lapses.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_action_was_punishment = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            if self.last_action_was_punishment:
                action = Action.C
                self.last_action_was_punishment = False
            else:
                prev_round = state.round_number - 1
                my_prev_action = history.my_actions[prev_round]
                opponent_prev_actions = history.opponent_actions[prev_round]
                coop_opponent = np.sum(opponent_prev_actions)
                total_coop = coop_opponent + (1 if my_prev_action else 0)
                if total_coop >= self.game_description.m:
                    action = Action.C
                else:
                    action = Action.D
                    self.last_action_was_punishment = True
            return action

class Strategy_COLLECTIVE_407(BaseStrategy):
    """
    Cooperative Punishment with Forgiveness Strategy
    - Cooperates in the first and last rounds.
    - In subsequent rounds, cooperates if the previous round had at least m cooperators; otherwise, defects.
    - Forgiveness is implicit by returning to cooperation once the threshold is met again.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        else:
            t_prev = state.round_number - 1
            my_prev = history.my_actions[t_prev]
            opponents_prev = history.opponent_actions[t_prev, :]
            cooperators = my_prev + np.sum(opponents_prev)
            if cooperators >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_409(BaseStrategy):
    """
    Adaptive Cooperation Based on Historical Success
    Cooperates if the ratio of successful rounds exceeds 0.5.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number
        success_count = 0
        m = self.game_description.m
        for s in range(t):
            my_coop = history.my_actions[s]
            opponent_coops = history.opponent_actions[s].sum()
            total_coop = my_coop + opponent_coops
            if total_coop >= m:
                success_count += 1
        if t == 0:
            ratio = 0.0
        else:
            ratio = success_count / t
        if ratio > 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_410(BaseStrategy):
    """
    A deterministic strategy for the Collective Risk Dilemma. Players cooperate 
    in the first round and continue to cooperate if the threshold of cooperators 
    was met in the previous round; otherwise, they defect.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_last_action = history.my_actions[-1]
        my_coop = 1 if my_last_action else 0
        opponent_coops = np.sum(history.opponent_actions[-1, :])
        total_cooperations = my_coop + opponent_coops
        if total_cooperations >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_411(BaseStrategy):
    """
    Adaptive Collective Cooperation strategy.
    Cooperates initially, continues if enough cooperated last round, 
    probabilistically cooperates if not, defects in the last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.r - 1:
            return Action.D
        else:
            t_prev = state.round_number - 1
            my_prev_action = history.my_actions[t_prev]
            opponent_prev_actions = history.opponent_actions[t_prev, :]
            c_prev = (1 if my_prev_action else 0) + sum(opponent_prev_actions)
            if c_prev >= self.m:
                return Action.C
            else:
                p = max(0, (self.m - c_prev) / self.n)
                rand = random.random()
                if rand < p:
                    return Action.C
                else:
                    return Action.D

class Strategy_COLLECTIVE_412(BaseStrategy):
    """
    A strategy that cooperates initially, punishes for one round when cooperation is insufficient, 
    then forgives and returns to cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punished_last_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.punished_last_round:
            self.punished_last_round = False
            return Action.C
        prev_round = state.round_number - 1
        if history is None:
            return Action.C
        prev_my_C = history.my_actions[prev_round]
        prev_opp_C = sum(history.opponent_actions[prev_round])
        prev_coop = prev_my_C + prev_opp_C
        if prev_coop >= self.game_description.m:
            return Action.C
        else:
            self.punished_last_round = True
            return Action.D

class Strategy_COLLECTIVE_413(BaseStrategy):
    """A strategy that cooperates initially, punishes when cooperation is below threshold, then forgives."""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev = history.my_actions[previous_round]
        opponents_prev = history.opponent_actions[previous_round]
        count_C = my_prev + np.sum(opponents_prev)
        if count_C >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_414(BaseStrategy):
    """
    Implement a strategy where the player always defects to maximize their individual payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        return Action.D

class Strategy_COLLECTIVE_415(BaseStrategy):
    """
    A strategy that encourages cooperation by reciprocating cooperation and 
    punishing defection. Players cooperate initially and continue if the 
    minimum threshold is met. In the last round, they cooperate if their 
    action is needed to meet the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m_threshold = game_description.m
        self.k_factor = game_description.k

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            prev_opponents = history.opponent_actions[-1]
            prev_coop_opponents = sum(prev_opponents)
            if prev_coop_opponents + 1 >= self.m_threshold:
                return Action.C
            else:
                return Action.D
        else:
            prev_opponents = history.opponent_actions[-1]
            prev_coop_opponents = sum(prev_opponents)
            my_prev_action = history.my_actions[-1]
            total_prev = prev_coop_opponents + (1 if my_prev_action else 0)
            if total_prev >= self.m_threshold:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_416(BaseStrategy):
    """
    Adaptive Cooperation with Forgiveness strategy for the Collective Risk Dilemma. 
    Cooperates initially, continues if cooperation meets the threshold, defects if not, 
    and resets cooperation after two consecutive insufficient rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_insufficient = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_prev_actions = history.opponent_actions[prev_round]
        prev_coop = (1 if my_prev_action else 0) + opponent_prev_actions.sum()
        if prev_coop >= self.game_description.m:
            self.consecutive_insufficient = 0
            return Action.C
        else:
            self.consecutive_insufficient += 1
            if self.consecutive_insufficient >= 2:
                self.consecutive_insufficient = 0
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_417(BaseStrategy):
    """
    Responsive Cooperation with Reset Mechanism.
    Cooperates if previous round met threshold, otherwise defects but resets to cooperate after 3 consecutive failures.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_failures = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        my_c = 1 if my_prev_action else 0
        opponents_prev = history.opponent_actions[prev_round, :]
        opponents_c = sum(opponents_prev)
        total_c_prev = my_c + opponents_c
        if total_c_prev >= self.game_description.m:
            self.consecutive_failures = 0
            return Action.C
        else:
            self.consecutive_failures += 1
            if self.consecutive_failures >= 3:
                self.consecutive_failures = 0
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_418(BaseStrategy):
    """
    Implements the Adaptive Cooperation with Forgiveness strategy.
    Players start by cooperating. In each subsequent round, they cooperate if the number of cooperators
    in the previous round met or exceeded the threshold m; otherwise, they defect.
    This encourages sustained cooperation while adapting to others' behavior.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opponent_prev_actions = history.opponent_actions[prev_round, :]
            prev_coop = 0
            if my_prev_action:
                prev_coop += 1
            prev_coop += np.sum(opponent_prev_actions)
            if prev_coop >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_419(BaseStrategy):
    """
    A strategy that starts with cooperation and continues if the minimum threshold 
    of cooperators (m) is met in the previous round. If not, it defects but 
    can switch back to cooperation if the threshold is met again in subsequent rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        my_prev_coop = 1 if my_prev_action else 0
        others_prev_actions = history.opponent_actions[prev_round, :]
        others_prev_coop = np.sum(others_prev_actions)
        total_prev_coop = my_prev_coop + others_prev_coop
        m = self.game_description.m
        if total_prev_coop >= m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_420(BaseStrategy):
    """
    Cooperative Punishment with Recovery Strategy.
    Cooperates initially. Subsequently, cooperates if the number of cooperators 
    in the previous round meets or exceeds m, otherwise defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opp_prev_actions = history.opponent_actions[prev_round, :]
            coop_prev_round = sum(opp_prev_actions) + my_prev_action
            if coop_prev_round >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_421(BaseStrategy):
    """
    A strategy that encourages cooperation by responding to the previous round's outcomes,
    with a mechanism to restart cooperation after two consecutive defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defects = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if self.consecutive_defects >= 2:
            self.consecutive_defects = 0
            return Action.C
        prev_round = current_round - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_prev_actions = history.opponent_actions[prev_round]
        total_cooperators = sum(opponent_prev_actions) + (1 if my_prev_action else 0)
        if total_cooperators >= self.game_description.m:
            self.consecutive_defects = 0
            return Action.C
        else:
            self.consecutive_defects += 1
            return Action.D

class Strategy_COLLECTIVE_422(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma where players cooperate in the first round and then base their decisions on the previous round's payoff. They cooperate if their previous payoff was either k or 1 + k, indicating the threshold was met; otherwise, they defect.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_payoff = history.my_payoffs[-1]
        k = self.game_description.k
        tolerance = 1e-09
        if abs(last_payoff - k) < tolerance or abs(last_payoff - (1 + k)) < tolerance:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_423(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that cooperates 
    if enough players cooperated in the previous round, starting with 
    cooperation in the first round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opponent_actions_prev = history.opponent_actions[prev_round, :]
            total_c = sum(opponent_actions_prev) + my_prev_action
            if total_c >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_424(BaseStrategy):
    """
    Adaptive Cooperation with Periodic Re-engagement strategy for Collective Risk Dilemma.
    Starts with cooperation, adapts based on previous cooperation levels, and periodically retests cooperation after consecutive defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self_cooperate = True
        self.defect_count = 0
        self.z = 3

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        sum_opponents = np.sum(history.opponent_actions[prev_round, :])
        own_prev_action = history.my_actions[prev_round]
        total_coop_prev = sum_opponents + own_prev_action
        if total_coop_prev >= self.m:
            self_cooperate = True
            self.defect_count = 0
        else:
            self_cooperate = False
            self.defect_count += 1
            if self.defect_count >= self.z:
                self_cooperate = True
                self.defect_count = 0
        return Action.C if self_cooperate else Action.D

class Strategy_COLLECTIVE_425(BaseStrategy):
    """
    Adaptive Cooperation with Punishment (ACP) strategy for the Collective Risk Dilemma.
    Cooperates initially, punishes once if cooperation fails in subsequent rounds,
    and evaluates overall cooperation history in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            count = 0
            for t in range(state.round_number):
                my_prev = history.my_actions[t]
                others_prev = history.opponent_actions[t, :]
                total_c = my_prev + int(others_prev.sum())
                if total_c >= self.game_description.m:
                    count += 1
            if count * 2 > state.round_number:
                return Action.C
            else:
                return Action.D
        else:
            previous_round = state.round_number - 1
            my_prev = history.my_actions[previous_round]
            others_prev = history.opponent_actions[previous_round, :]
            total_c = my_prev + int(others_prev.sum())
            if total_c >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_426(BaseStrategy):
    """
    A strategy where each player cooperates if their index is less than or equal to the threshold m.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        i = 1
        if i <= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_427(BaseStrategy):
    """
    A strategy to promote sustained cooperation with recovery from failures.
    Cooperates initially and continues if the previous round met the threshold.
    If not, it alternates cooperation based on the number of consecutive failures.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opp_prev_actions = history.opponent_actions[prev_round]
        sum_coop_prev = sum(opp_prev_actions) + (1 if my_prev_action else 0)
        if sum_coop_prev >= self.m:
            return Action.C
        else:
            consecutive_failures = 0
            for t in range(prev_round, -1, -1):
                my_action_t = history.my_actions[t]
                opp_actions_t = history.opponent_actions[t]
                sum_coop_t = sum(opp_actions_t) + (1 if my_action_t else 0)
                if sum_coop_t < self.m:
                    consecutive_failures += 1
                else:
                    break
            return Action.C if consecutive_failures % 2 == 0 else Action.D

class Strategy_COLLECTIVE_428(BaseStrategy):
    """
    A Strategy that begins by cooperating, switches to punishing (defecting) 
    if insufficient cooperation is seen, then returns to cooperation.
    This aims to encourage sustained group cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.state = 'Cooperating'

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        my_prev_action = history.my_actions[-1]
        opponent_prev_actions = history.opponent_actions[-1, ...]
        prev_coop = sum(opponent_prev_actions) + (1 if my_prev_action else 0)
        m = self.game_description.m
        if self.state == 'Cooperating':
            if prev_coop >= m:
                return Action.C
            else:
                self.state = 'Punishing'
                return Action.D
        elif self.state == 'Punishing':
            action = Action.D
            self.state = 'Cooperating'
            return action

class Strategy_COLLECTIVE_429(BaseStrategy):
    """
    Strategy that adapts cooperation based on previous rounds' outcomes, forgiving temporary defections.
    Cooperates initially, continues if threshold met, defects otherwise but resets after two defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        my_prev_action = history.my_actions[-1]
        opponent_prev_actions = history.opponent_actions[-1, :]
        s_prev = int(my_prev_action) + np.sum(opponent_prev_actions)
        if s_prev >= self.game_description.m:
            self.consecutive_defections = 0
            return Action.C
        elif self.consecutive_defections < 2:
            self.consecutive_defections += 1
            return Action.D
        else:
            self.consecutive_defections = 0
            return Action.C

class Strategy_COLLECTIVE_430(BaseStrategy):
    """
    Implements the Adaptive Cooperation with Forgiveness strategy.
    This strategy encourages cooperation while allowing a limited number of 
    defections before attempting to re-establish cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.max_failures_before_retrying = 2
        self.consecutive_failures = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        else:
            my_prev_action = history.my_actions[-1]
            opponent_prev_actions = history.opponent_actions[-1, :]
            coop_prev = sum(opponent_prev_actions) + (1 if my_prev_action else 0)
            if coop_prev >= self.game_description.m:
                self.consecutive_failures = 0
                return Action.C
            else:
                self.consecutive_failures += 1
                if self.consecutive_failures <= self.max_failures_before_retrying:
                    return Action.D
                else:
                    self.consecutive_failures = 0
                    return Action.C

class Strategy_COLLECTIVE_431(BaseStrategy):
    """
    Adaptive Collective Cooperation with Forgiveness Strategy.
    
    This strategy starts with cooperation, then adapts based on the previous
    round's cooperation level. It defects if the previous round's cooperation
    was insufficient and includes a forgiveness mechanism to reset cooperation
    after two consecutive defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev = history.my_actions[previous_round]
        others_prev = history.opponent_actions[previous_round, :]
        total_coop = 1 if my_prev else 0
        total_coop += np.sum(others_prev)
        if total_coop >= self.m:
            base_action = Action.C
        else:
            base_action = Action.D
        if self.consecutive_defections >= 2:
            current_action = Action.C
            self.consecutive_defections = 0
        else:
            current_action = base_action
            if current_action == Action.D:
                self.consecutive_defections += 1
            else:
                self.consecutive_defections = 0
        return current_action

class Strategy_COLLECTIVE_432(BaseStrategy):
    """
    A strategy that initially cooperates and then defects if fewer than m players cooperated in the previous round.
    Cooperates if the previous round met or exceeded the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_last_action = history.my_actions[-1]
        opponent_actions_last = history.opponent_actions[-1, :]
        total_coop = my_last_action + sum(opponent_actions_last)
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_433(BaseStrategy):
    """
    A cooperative strategy for the Collective Risk Dilemma game. Players start by cooperating, 
    adapt based on the success rate of past rounds, and defect in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        n_players = self.game_description.n_players
        n_rounds = self.game_description.n_rounds
        m = self.game_description.m
        if current_round == 0:
            return Action.C
        elif current_round == n_rounds - 1:
            return Action.D
        else:
            success_count = 0
            for r in range(current_round):
                my_action = history.my_actions[r]
                opp_actions = history.opponent_actions[r, :]
                total_c = sum(opp_actions) + (1 if my_action else 0)
                if total_c >= m:
                    success_count += 1
            success_rate = success_count / current_round
            threshold = m / n_players
            if success_rate >= threshold:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_434(BaseStrategy):
    """
    Cooperative Reactivism Strategy:
    - Cooperate in the first round.
    - In subsequent rounds, cooperate if the previous round met the cooperation threshold (m); otherwise, defect.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.m = game_description.m

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            my_prev_action = history.my_actions[-1]
            opponent_actions_prev = history.opponent_actions[-1]
            total_cooperation_last_round = my_prev_action + np.sum(opponent_actions_prev)
            if total_cooperation_last_round >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_435(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that:
    - Cooperates in the first round to encourage mutual cooperation.
    - Cooperates in subsequent rounds if at least m players cooperated previously.
    - Defects in the final round to maximize personal payoff without concern for future repercussions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opp_prev_actions = history.opponent_actions[prev_round]
        total_coop = my_prev_action + np.sum(opp_prev_actions)
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_67(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that starts with cooperation and continues 
    if the majority of past rounds met the cooperation threshold. Defects otherwise.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        count = 0
        for t in range(state.round_number):
            my_c = history.my_actions[t]
            opp_c = np.sum(history.opponent_actions[t, :])
            c_t = my_c + opp_c
            if c_t >= self.m:
                count += 1
        if count > state.round_number / 2:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_79(BaseStrategy):

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        a = self.m - 1
        b = self.n - self.m
        self.C = math.comb(self.n - 1, a)
        self.p = self._find_p()

    def _find_p(self):
        low = 0.0
        high = 1.0
        tolerance = 1e-07
        max_iter = 1000
        for _ in range(max_iter):
            mid = (low + high) / 2
            term = (mid ** self.m - 1) * (1 - mid) ** (self.n - self.m) if mid != 0 and mid != 1 else 0
            val = self.C * self.k * term - 1
            if val < 0:
                low = mid
            else:
                high = mid
            if high - low < tolerance:
                break
        p = (low + high) / 2
        return max(0.0, min(1.0, p))

    def __call__(self, state: GameState, history: PlayerHistory | None):
        if random.random() < self.p:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_133(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that encourages cooperation through initial good faith, 
    monitors and adapts based on others' actions, punishes defectors, and adjusts in the endgame.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.past_coop_counts = []
        self.punishment_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_count = len(self.past_coop_counts)
        for new_round in range(current_count, state.round_number):
            my_action = history.my_actions[new_round]
            opponent_actions = history.opponent_actions[new_round]
            total_coop = my_action + np.sum(opponent_actions)
            self.past_coop_counts.append(total_coop)
        remaining_rounds = self.game_description.n_rounds - state.round_number
        if remaining_rounds <= 5:
            c_payoffs = []
            d_payoffs = []
            for t in range(len(history.my_actions)):
                if history.my_actions[t]:
                    c_payoffs.append(history.my_payoffs[t])
                else:
                    d_payoffs.append(history.my_payoffs[t])
            avg_C = avg_D = 0.0
            if c_payoffs:
                avg_C = sum(c_payoffs) / len(c_payoffs)
            if d_payoffs:
                avg_D = sum(d_payoffs) / len(d_payoffs)
            if avg_C > avg_D:
                return Action.C
            else:
                return Action.D
        elif self.punishment_remaining > 0:
            self.punishment_remaining -= 1
            return Action.D
        else:
            avg_coop = sum(self.past_coop_counts) / len(self.past_coop_counts)
            m = self.game_description.m
            if avg_coop >= m:
                return Action.C
            else:
                self.punishment_remaining = 3
                return Action.D

class Strategy_COLLECTIVE_136(BaseStrategy):
    """
    This strategy starts by cooperating in the first round. In subsequent rounds, it looks back at the last 3 rounds (or fewer if there aren't enough) and cooperates if more than half of those rounds met the cooperation threshold (m). Otherwise, it defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        t = state.round_number
        m = self.game_description.m
        s = min(3, t)
        start = max(0, t - s)
        recent_round_indices = range(start, t)
        count = 0
        for r in recent_round_indices:
            if r >= len(history.my_actions):
                continue
            my_action = history.my_actions[r]
            opponent_actions = history.opponent_actions[r]
            coop = 1 if my_action else 0
            coop += sum(opponent_actions)
            if coop >= m:
                count += 1
        if count > s / 2:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_148(BaseStrategy):
    """
    Adaptive Cooperation with Restart Mechanism.
    Cooperates initially, then adapts based on previous cooperation levels.
    Cooperates again after two rounds of insufficient cooperation to encourage restart.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.s_consec = 0
        self.next_cooperate = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif self.next_cooperate:
            self.next_cooperate = False
            return Action.C
        else:
            prev_my = history.my_actions[-1]
            prev_opp = history.opponent_actions[-1, :]
            c_prev = prev_my + np.sum(prev_opp)
            m = self.game_description.m
            if c_prev >= m:
                self.s_consec = 0
                return Action.C
            else:
                self.s_consec += 1
                if self.s_consec >= 2:
                    self.next_cooperate = True
                    self.s_consec = 0
                    return Action.D
                else:
                    return Action.D

class Strategy_COLLECTIVE_154(BaseStrategy):
    """
    Adaptive Cooperation with Temporary Punishment strategy to address the Collective Risk Dilemma.
    Cooperates initially and in subsequent rounds if the previous round met the cooperation threshold.
    Defects temporarily if the threshold was not met, then resumes cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_pending = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.punishment_pending:
            self.punishment_pending = False
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opp_prev_actions = history.opponent_actions[prev_round]
        total_cooperators = opp_prev_actions.sum() + (1 if my_prev_action else 0)
        if total_cooperators >= self.game_description.m:
            return Action.C
        else:
            self.punishment_pending = True
            return Action.D

class Strategy_COLLECTIVE_174(BaseStrategy):
    """
    Adaptive strategy to encourage sustained cooperation with recovery from defections.
    Cooperates initially, continues if sufficient cooperation, defects if not, and resets cooperation after two defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_prev_actions = history.opponent_actions[prev_round, :]
        sum_cooperators = my_prev_action + np.sum(opponent_prev_actions)
        m = self.game_description.m
        s = 2
        if sum_cooperators >= m:
            self.consecutive_defections = 0
            return Action.C
        else:
            self.consecutive_defections += 1
            if self.consecutive_defections >= s:
                self.consecutive_defections = 0
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_184(BaseStrategy):

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.punishing = False
        self.punish_remaining = 0
        self.reset_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        else:
            in_endgame = current_round >= self.r - 5
            if in_endgame:
                total_coop = 0
                for r in range(current_round):
                    coops = sum(history.opponent_actions[r, :]) + history.my_actions[r]
                    if coops >= self.m:
                        total_coop += 1
                if total_coop / current_round > 0.5:
                    return Action.C
                else:
                    return Action.D
            elif self.reset_counter > 0:
                self.reset_counter -= 1
                return Action.C
            elif self.punishing:
                self.punish_remaining -= 1
                if self.punish_remaining == 0:
                    self.punishing = False
                    self.reset_counter = 2
                return Action.D
            else:
                total_prev = current_round
                count_coop = 0
                for r in range(total_prev):
                    coops = sum(history.opponent_actions[r, :]) + history.my_actions[r]
                    if coops >= self.m:
                        count_coop += 1
                ratio = count_coop / total_prev
                if ratio > 0.5:
                    return Action.C
                else:
                    self.punishing = True
                    self.punish_remaining = 3
                    return Action.D

class Strategy_COLLECTIVE_192(BaseStrategy):
    """
    The Adaptive Collective Cooperation (ACC) strategy. 
    This strategy starts with cooperation and adapts based on the collective behavior,
    using a forgiveness mechanism to reset cooperation after defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        opponent_actions_prev = history.opponent_actions[prev_round]
        my_prev_action = history.my_actions[prev_round]
        sum_opponents_coop = np.sum(opponent_actions_prev)
        sum_total_coop = sum_opponents_coop + (1 if my_prev_action else 0)
        if sum_total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.C if not my_prev_action else Action.D

class Strategy_COLLECTIVE_222(BaseStrategy):
    """
    A strategy that starts with cooperation and responds to the number of cooperators in the previous round.
    If sufficient players cooperated previously, it continues to cooperate; otherwise, it defects but reverts to
    cooperation in the next round. This aims to maintain cooperation while allowing recovery after temporary failures.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.pledged_to_cooperate = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            if self.pledged_to_cooperate:
                action = Action.C
                self.pledged_to_cooperate = False
            else:
                prev_my_action = history.my_actions[-1]
                prev_opp_actions = history.opponent_actions[-1]
                prev_coop = prev_my_action + prev_opp_actions.sum()
                if prev_coop >= self.game_description.m:
                    action = Action.C
                else:
                    action = Action.D
                    self.pledged_to_cooperate = True
            return action

class Strategy_COLLECTIVE_223(BaseStrategy):
    """
    A strategy that maintains cooperation while being responsive to changes in cooperation levels and forgiving occasional shortfalls.
    Cooperates initially, defects if the previous round's cooperation was insufficient, but reverts to cooperation afterward.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.last_defected_for_shortfall = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            self.last_defected_for_shortfall = False
            return Action.C
        prev_my_action = history.my_actions[-1]
        opponent_actions_prev = history.opponent_actions[-1, :]
        prev_C = sum(opponent_actions_prev) + (1 if prev_my_action else 0)
        if prev_C >= self.m:
            self.last_defected_for_shortfall = False
            return Action.C
        elif self.last_defected_for_shortfall:
            self.last_defected_for_shortfall = False
            return Action.C
        else:
            self.last_defected_for_shortfall = True
            return Action.D

class Strategy_COLLECTIVE_225(BaseStrategy):
    """
    Collective Risk Tolerant Tit-for-Tat Strategy.
    Cooperates initially and in the final round, uses tit-for-tat based on a threshold of cooperators,
    with a forgiveness mechanism to avoid perpetual defection cycles.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        r = self.game_description.n_rounds
        m = self.game_description.m
        if t == 0:
            return Action.C
        elif t == r - 1:
            return Action.C
        else:
            my_prev_action = history.my_actions[t - 1]
            opp_prev_actions = history.opponent_actions[t - 1, :]
            total_prev = int(my_prev_action) + opp_prev_actions.sum()
            if total_prev >= m:
                return Action.C
            elif self.game_description.n_rounds < 20:
                if t % 5 == 0:
                    return Action.C
                elif random.random() < 0.2:
                    return Action.C
                else:
                    return Action.D
            elif random.random() < 0.2:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_226(BaseStrategy):
    """
    A strategy that begins with cooperation, temporarily punishes if cooperation 
    thresholds are not met, and then forgives and resumes cooperation. This 
    approach aims to maintain cooperative behavior while allowing recovery 
    from temporary lack of cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.state = 'C'

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_coop = history.my_actions[prev_round]
        opponents_coop = history.opponent_actions[prev_round].sum()
        total_prev_coop = my_coop + opponents_coop
        if self.state == 'C':
            if total_prev_coop >= self.game_description.m:
                self.state = 'C'
                return Action.C
            else:
                self.state = 'P'
                return Action.D
        elif self.state == 'P':
            self.state = 'C'
            return Action.C

class Strategy_COLLECTIVE_246(BaseStrategy):
    """
    Cooperative unless the previous round failed to meet the threshold, then defect once and return to cooperation.
    This strategy promotes sustained cooperation by penalizing non-cooperative behavior temporarily while providing a mechanism to reset and try again.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.force_coop = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.force_coop:
            self.force_coop = False
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_prev_actions = history.opponent_actions[prev_round, :]
        coops = 1 if my_prev_action else 0
        coops += np.sum(opponents_prev_actions)
        if coops >= self.game_description.m:
            return Action.C
        else:
            self.force_coop = True
            return Action.D

class Strategy_COLLECTIVE_255(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that promotes cooperation by punishing 
    rounds with insufficient cooperation but allowing recovery by reverting to cooperation 
    after a single defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            if not my_prev_action:
                return Action.C
            else:
                opponent_actions_prev = history.opponent_actions[prev_round, :]
                my_bool_prev = history.my_actions[prev_round]
                cooperators_count = sum(opponent_actions_prev) + (1 if my_bool_prev else 0)
                if cooperators_count >= self.game_description.m:
                    return Action.C
                else:
                    return Action.D

class Strategy_COLLECTIVE_265(BaseStrategy):
    """
    Adaptive Collective Cooperation (ACC) strategy.
    
    This strategy encourages initial cooperation, adapts based on previous rounds' success, 
    and makes a final decision in the last round to maximize collective payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m_threshold = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        if current_round == self.n_rounds - 1:
            successful_rounds = 0
            len_history = len(history.my_actions)
            for t in range(len_history):
                my_action = history.my_actions[t]
                opp_actions = history.opponent_actions[t]
                coop = (1 if my_action else 0) + sum(opp_actions)
                if coop >= self.m_threshold:
                    successful_rounds += 1
            threshold = len_history / 2
            if successful_rounds > threshold:
                return Action.C
            else:
                return Action.D
        else:
            prev_round = current_round - 1
            prev_my_action = history.my_actions[prev_round]
            prev_opp_actions = history.opponent_actions[prev_round]
            coop = (1 if prev_my_action else 0) + sum(prev_opp_actions)
            if coop >= self.m_threshold:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_268(BaseStrategy):
    """
    Adaptive Threshold Cooperation strategy for the Collective Risk Dilemma.
    Balances cooperation with adaptive adjustments based on previous rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_deficit = 0
        self.defecting = False
        self.consecutive_deficit_threshold = 3

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.defecting:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            prev_my_action = history.my_actions[-1]
            prev_opp_actions = history.opponent_actions[-1, :]
            total_coop_prev = (1 if prev_my_action else 0) + sum(prev_opp_actions)
            if total_coop_prev >= self.game_description.m:
                return Action.C
            else:
                return Action.D
        else:
            prev_my_action = history.my_actions[-1]
            prev_opp_actions = history.opponent_actions[-1, :]
            total_coop_prev = (1 if prev_my_action else 0) + sum(prev_opp_actions)
            if total_coop_prev >= self.game_description.m:
                self.consecutive_deficit = 0
                return Action.C
            else:
                self.consecutive_deficit += 1
                if self.consecutive_deficit >= self.consecutive_deficit_threshold:
                    self.defecting = True
                    return Action.D
                else:
                    probability = max(0.5, float(total_coop_prev) / self.game_description.n_players)
                    random_val = random.random()
                    if random_val < probability:
                        return Action.C
                    else:
                        return Action.D

class Strategy_COLLECTIVE_269(BaseStrategy):
    """
    Cooperative Punisher with Forgiveness Strategy.

    Description: Cooperates initially, continues if collective cooperation met the threshold,
    defects once as punishment if the threshold is not met, and then forgives by cooperating
    again to allow recovery and promote sustained cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_state = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            action = Action.C
            self.cooperation_state = True
            return action
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opponent_prev_actions = history.opponent_actions[prev_round]
            count = my_prev_action + np.sum(opponent_prev_actions)
            m = self.game_description.m
            if self.cooperation_state and count >= m:
                action = Action.C
            else:
                action = Action.D
            if action == Action.D:
                self.cooperation_state = True
            else:
                self.cooperation_state = False
            return action

class Strategy_COLLECTIVE_336(BaseStrategy):
    """
    An adaptive strategy that balances cooperation and punishment based on previous rounds' outcomes.
    Cooperates initially and continues to cooperate if the threshold is met; otherwise, defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_prev_actions = history.opponent_actions[prev_round]
        total_cooperators = int(my_prev_action) + opponents_prev_actions.sum()
        if total_cooperators >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_353(BaseStrategy):
    """
    Adaptive Cooperator with Forgiveness (ACF) strategy.
    Cooperates initially, continues if threshold met in previous round,
    defects otherwise, with forgiveness after consecutive defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0
        self.forgiveness_threshold = 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opponents_prev_actions = history.opponent_actions[prev_round, :]
            num_cooperators = my_prev_action + np.sum(opponents_prev_actions)
            if num_cooperators >= self.game_description.m:
                self.consecutive_defections = 0
                return Action.C
            else:
                self.consecutive_defections += 1
                action = Action.D
                if self.consecutive_defections >= self.forgiveness_threshold:
                    action = Action.C
                    self.consecutive_defections = 0
                return action

class Strategy_COLLECTIVE_361(BaseStrategy):
    """
    Cooperative Reset Strategy.

    Cooperates initially, then continues if collective cooperation meets or exceeds threshold in previous round.
    If not, defects once then resets to cooperate again.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.prev_defected = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            if self.prev_defected:
                action = Action.C
                self.prev_defected = False
            else:
                prev_round = state.round_number - 1
                opponent_actions_prev = history.opponent_actions[prev_round]
                sum_opponents = sum(opponent_actions_prev)
                my_prev = history.my_actions[prev_round]
                s_prev = sum_opponents + (1 if my_prev else 0)
                if s_prev >= self.game_description.m:
                    action = Action.C
                else:
                    action = Action.D
                    self.prev_defected = True
            return action

class Strategy_COLLECTIVE_406(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma based on Adaptive Reciprocity.
    Cooperates initially, continues if cooperation threshold is met, defects as retaliation,
    and resets cooperation after a set number of consecutive failed rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_failures = 0
        self.reset_threshold = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        else:
            if history is None:
                return Action.D
            previous_round_num = state.round_number - 1
            if previous_round_num >= len(history.my_actions) or previous_round_num >= len(history.opponent_actions):
                return Action.D
            my_last_action = history.my_actions[previous_round_num]
            opponent_actions_last = history.opponent_actions[previous_round_num]
            total_coop_last = sum(opponent_actions_last) + (1 if my_last_action else 0)
            if total_coop_last >= self.game_description.m:
                self.consecutive_failures = 0
                return Action.C
            else:
                self.consecutive_failures += 1
                if self.consecutive_failures >= self.reset_threshold:
                    self.consecutive_failures = 0
                    return Action.C
                else:
                    return Action.D

class Strategy_COLLECTIVE_408(BaseStrategy):
    """
    Adaptive Cooperation with Forgiveness (ACF): 
    A strategy for the Collective Risk Dilemma that starts with cooperation, 
    adapts based on the number of cooperators, and includes a forgiveness mechanism 
    to reset cooperation after multiple defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.recent_cooperations = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        my_last_action = history.my_actions[last_round]
        opponents_last_actions = history.opponent_actions[last_round, :]
        c_last = my_last_action + np.sum(opponents_last_actions)
        self.recent_cooperations.append(c_last)
        if len(self.recent_cooperations) > 5:
            self.recent_cooperations = self.recent_cooperations[-5:]
        if len(self.recent_cooperations) >= 3:
            last_three = self.recent_cooperations[-3:]
            if all((c < self.game_description.m for c in last_three)):
                if random.random() < 0.2:
                    return Action.C
                else:
                    return Action.D
        if c_last >= self.game_description.m:
            return Action.C
        else:
            m = self.game_description.m
            n = self.game_description.n_players
            shortfall = m - c_last
            defect_prob = shortfall / n
            defect_prob = max(0.0, min(1.0, defect_prob))
            if random.random() < defect_prob:
                return Action.D
            else:
                return Action.C

class Strategy_COLLECTIVE_436(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that encourages cooperation through punishment.
    Cooperates in the first round, then cooperates again if the previous round met the cooperation threshold, otherwise defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_coop = history.my_actions[prev_round]
            opponent_coop = history.opponent_actions[prev_round].sum()
            total_coop = my_coop + opponent_coop
            if total_coop >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_437(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game where players 
    cooperate if at least m players cooperated in the previous round, 
    otherwise defect.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            my_prev = history.my_actions[-1]
            opponents_prev = history.opponent_actions[-1, :]
            total_coop = my_prev + np.sum(opponents_prev)
            if total_coop >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_438(BaseStrategy):
    """
    A strategy that balances cooperation and defection based on recent outcomes.
    It uses a moving window of recent rounds to decide actions, encouraging cooperation
    when successful and defecting when not, with a mechanism to restart cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.w = 3
        self.t = 2
        self.s = 2
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.consecutive_defections >= self.s:
            self.consecutive_defections = 0
            return Action.C
        start_round = max(0, state.round_number - self.w)
        successes = []
        for t_round in range(start_round, state.round_number):
            my_action = history.my_actions[t_round]
            my_coop = 1 if my_action else 0
            opp_coop = sum(history.opponent_actions[t_round])
            total_coop = my_coop + opp_coop
            successes.append(total_coop >= self.game_description.m)
        successful_count = sum(successes)
        if successful_count >= self.t:
            self.consecutive_defections = 0
            return Action.C
        self.consecutive_defections += 1
        return Action.D

class Strategy_COLLECTIVE_439(BaseStrategy):
    """A strategy that cooperates based on the previous round's cooperation level."""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_coop = history.my_actions[prev_round]
        opponent_coops = sum(history.opponent_actions[prev_round, :])
        total_coop = my_coop + opponent_coops
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_440(BaseStrategy):
    """
    A strategy that cooperates if the number of previous cooperators meets the threshold, 
    otherwise defects. First round always cooperates.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_prev_actions = history.opponent_actions[prev_round]
        total_cooperators = my_prev_action + opponent_prev_actions.sum()
        if total_cooperators >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_441(BaseStrategy):
    """
    This strategy cooperates initially, continues cooperation if the previous round met the threshold,
    defects as punishment if the threshold wasn't met, and resets cooperation if all defected previously.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opponent_prev_actions = history.opponent_actions[prev_round, :]
            coop_total = my_prev_action + np.sum(opponent_prev_actions)
            if coop_total >= self.m:
                return Action.C
            elif coop_total == 0:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_442(BaseStrategy):
    """
    A strategy designed for the Collective Risk Dilemma game. It cooperates in the first round, 
    defects in the last round, and uses the success rate of recent rounds to decide actions in 
    between. The strategy encourages sustained cooperation by punishing lack of cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.success_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        r = self.game_description.n_rounds
        m = self.game_description.m
        if t == 0:
            return Action.C
        elif t == r - 1:
            return Action.D
        else:
            if history is None:
                return Action.D
            for s in range(len(self.success_history), t):
                my_action = history.my_actions[s]
                opponent_actions = history.opponent_actions[s]
                total_coop = my_action + np.sum(opponent_actions)
                if total_coop >= m:
                    self.success_history.append(True)
                else:
                    self.success_history.append(False)
            rounds_to_consider = min(3, len(self.success_history))
            if rounds_to_consider == 0:
                return Action.D
            recent_successes = sum(self.success_history[-rounds_to_consider:])
            success_rate = recent_successes / rounds_to_consider
            if success_rate > 0.5:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_443(BaseStrategy):
    """
    A strategy that adaptively cooperates based on recent collective performance.
    Cooperates in the first round and in subsequent rounds if the number of 
    cooperators in the previous round met or exceeded the threshold m.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_actions = history.opponent_actions[prev_round]
        total_coop = my_prev_action + sum(opponent_actions)
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_444(BaseStrategy):
    """
    A strategy that begins by Cooperating and then Cooperates in each round if at least m players Cooperated in the previous round; otherwise, Defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        my_prev_action = history.my_actions[last_round]
        opp_actions_last_round = history.opponent_actions[last_round]
        coop_opp = sum(opp_actions_last_round)
        total_coop = coop_opp + (1 if my_prev_action else 0)
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_445(BaseStrategy):
    """
    Adaptive Collective Cooperation strategy.
    Cooperates initially, then adapts based on recent cooperation rates.
    Defects temporarily if cooperation is insufficient, then forgives.
    Cooperates in final rounds to maximize payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.n = game_description.n_players
        self.punishment_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number >= self.r - 3:
            return Action.C
        if self.punishment_remaining > 0:
            self.punishment_remaining -= 1
            return Action.D
        recent_rounds = 5
        start = max(0, state.round_number - recent_rounds)
        count_coop_meet = 0
        for t in range(start, state.round_number):
            my_action = history.my_actions[t]
            others_actions = history.opponent_actions[t].sum()
            total_coop = my_action + others_actions
            if total_coop >= self.m:
                count_coop_meet += 1
        total_rounds = state.round_number - start
        proportion = count_coop_meet / total_rounds if total_rounds > 0 else 0.0
        if proportion > 0.5:
            return Action.C
        else:
            self.punishment_remaining = 2
            return Action.D

class Strategy_COLLECTIVE_446(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that promotes cooperation until the minimum threshold is no longer met, after which punishment by defection occurs. Defects in the final round regardless of history.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_active = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        if self.punishment_active:
            return Action.D
        previous_round = state.round_number - 1
        my_action = history.my_actions[previous_round]
        opponent_actions = history.opponent_actions[previous_round, :]
        num_cooperators = np.sum(opponent_actions) + (1 if my_action else 0)
        if num_cooperators < self.game_description.m:
            self.punishment_active = True
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_447(BaseStrategy):
    """
    Reciprocal Cooperation with Limited Forgiveness Strategy.
    
    Promotes sustained cooperation by reciprocating group cooperation and allowing 
    a limited number of defections before attempting to restart cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.x = 2
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        my_actions = history.my_actions
        opponent_actions = history.opponent_actions
        my_last_action = my_actions[last_round]
        opponent_last_actions = opponent_actions[last_round]
        sum_opponent_c = np.sum(opponent_last_actions)
        my_c = int(my_last_action)
        total_c = sum_opponent_c + my_c
        if total_c >= self.game_description.m:
            self.consecutive_defections = 0
            return Action.C
        else:
            self.consecutive_defections += 1
            if self.consecutive_defections >= self.x:
                self.consecutive_defections = 0
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_448(BaseStrategy):
    """
    Responsive Cooperation with Resilience (RCR) Strategy.
    Cooperates initially, continues if recent rounds met threshold, otherwise defects.
    Resets cooperation after z consecutive defections without success.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.w = 3
        self.z = 3
        self.consecutive_defections = 0
        self.reset_scheduled = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.reset_scheduled:
            self.reset_scheduled = False
            self.consecutive_defections = 0
            return Action.C
        found_threshold = False
        window = min(self.w, state.round_number)
        start = max(0, state.round_number - window)
        for r in range(state.round_number - 1, start - 1, -1):
            if r < 0:
                break
            my_action = 1 if history.my_actions[r] else 0
            opp_sum = np.sum(history.opponent_actions[r, :])
            total_c = my_action + opp_sum
            if total_c >= self.game_description.m:
                found_threshold = True
                break
        if found_threshold:
            self.consecutive_defections = 0
            return Action.C
        else:
            self.consecutive_defections += 1
            if self.consecutive_defections >= self.z:
                self.reset_scheduled = True
            return Action.D

class Strategy_COLLECTIVE_449(BaseStrategy):
    """
    Strategy that cooperates in the first round, then continues cooperating if at least m players cooperated in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        others_prev_actions = history.opponent_actions[prev_round]
        coop_count = int(my_prev_action) + others_prev_actions.sum()
        if coop_count >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_450(BaseStrategy):
    """
    Adaptive Collective Cooperation (ACC) strategy for the Collective Risk Dilemma.
    
    The strategy cooperates in the first two rounds, then adapts based on the number
    of cooperators in the previous round. If sufficient players cooperated, it continues
    to cooperate; otherwise, it defects as a punitive measure. After defecting once,
    it returns to cooperating in subsequent rounds to encourage re-establishment of cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n = game_description.n_players
        self.in_punishment = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number <= 1:
            return Action.C
        elif self.in_punishment:
            self.in_punishment = False
            return Action.C
        else:
            previous_round = state.round_number - 1
            my_prev_action = history.my_actions[previous_round]
            opponents_prev_actions = history.opponent_actions[previous_round, :]
            num_coop = int(my_prev_action) + int(opponents_prev_actions.sum())
            if num_coop >= self.m:
                return Action.C
            else:
                self.in_punishment = True
                return Action.D

class Strategy_COLLECTIVE_451(BaseStrategy):
    """
    Implements a strategy that adapts based on previous cooperation levels. Cooperates initially, 
    then continues or starts defecting based on whether enough players cooperated in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defection_streak = 0
        self.s = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_last_action = history.my_actions[prev_round]
        opponent_actions = history.opponent_actions[prev_round]
        total_coop = sum(opponent_actions) + (1 if my_last_action else 0)
        if total_coop >= self.game_description.m:
            self.defection_streak = 0
            return Action.C
        elif self.defection_streak < self.s:
            self.defection_streak += 1
            return Action.D
        else:
            self.defection_streak = 0
            return Action.C

class Strategy_COLLECTIVE_452(BaseStrategy):
    """
    A strategy to maintain cooperation levels sufficient to meet the threshold m in a Collective Risk Dilemma.
    Players cooperate if their index is among the first m when cooperation drops below m.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.rounds = game_description.n_rounds
        self.index = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        prev_coop = sum(history.opponent_actions[prev_round, :]) + (1 if history.my_actions[prev_round] else 0)
        if prev_coop >= self.m:
            return Action.C
        elif self.index <= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_453(BaseStrategy):
    """
    A strategy designed to balance cooperation with strategic defection in a Collective Risk Dilemma.
    Starts with cooperation, continues if the threshold is met, defects if not, and resets to cooperation after two consecutive defection rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defect_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        if history is None:
            return Action.D
        my_prev_action = history.my_actions[previous_round]
        opp_prev_actions = history.opponent_actions[previous_round, :]
        num_coop_opponents = np.sum(opp_prev_actions)
        total_coop = num_coop_opponents + (1 if my_prev_action else 0)
        if total_coop >= self.game_description.m:
            self.defect_count = 0
            return Action.C
        else:
            self.defect_count += 1
            if self.defect_count >= 2:
                self.defect_count = 0
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_454(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma that balances cooperation 
    and punishment based on the outcomes of previous rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t_prev = state.round_number - 1
        my_prev_action = history.my_actions[t_prev]
        opponents_prev_actions = history.opponent_actions[t_prev]
        coop_prev_total = sum(opponents_prev_actions) + (1 if my_prev_action else 0)
        if coop_prev_total >= self.game_description.m:
            return Action.C
        elif my_prev_action:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_455(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy.
    
    This strategy starts by cooperating to encourage initial cooperation. It then adapts based on the number of 
    cooperators in previous rounds. If cooperation meets or exceeds the threshold, it continues to cooperate. 
    If not, it may defect but will give another chance if cooperation shows improvement trends.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        prev_round = state.round_number - 1
        my_action = history.my_actions[prev_round]
        opponent_actions = history.opponent_actions[prev_round]
        previous_cooperation = my_action + int(opponent_actions.sum())
        m = self.game_description.m
        if previous_cooperation >= m:
            return Action.C
        prev_prev_round = prev_round - 1
        if prev_prev_round >= 0:
            prev_prev_my = history.my_actions[prev_prev_round]
            prev_prev_opponents = history.opponent_actions[prev_prev_round]
            prev_prev_coop = prev_prev_my + int(prev_prev_opponents.sum())
            if previous_cooperation > prev_prev_coop:
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_456(BaseStrategy):
    """
    A strategy based on conditional cooperation, forgiveness, and endgame consideration.
    Cooperates initially, continues if cooperation meets threshold, defects otherwise,
    forgives after a set number of consecutive defections, and defects in endgame rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0
        self.forgiveness_threshold = 2
        self.endgame_defect_threshold = 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            previous_round = state.round_number - 1
            my_prev_action = history.my_actions[previous_round]
            opponent_actions_prev_round = history.opponent_actions[previous_round]
            sum_opponent = opponent_actions_prev_round.sum()
            total_coop_prev = sum_opponent + (1 if my_prev_action else 0)
            m = self.game_description.m
            if total_coop_prev >= m:
                intended_action = Action.C
            else:
                intended_action = Action.D
            if not my_prev_action:
                self.consecutive_defections += 1
            else:
                self.consecutive_defections = 0
            if self.consecutive_defections >= self.forgiveness_threshold:
                intended_action = Action.C
                self.consecutive_defections = 0
            remaining_rounds = self.game_description.n_rounds - state.round_number - 1
            if remaining_rounds <= self.endgame_defect_threshold:
                intended_action = Action.D
            return intended_action

class Strategy_COLLECTIVE_457(BaseStrategy):
    """
    A strategy that starts with cooperation and adjusts based on the previous round's outcomes.
    Cooperates if the number of cooperators met/exceeded the threshold (m) in the previous round,
    otherwise defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_prev_actions = history.opponent_actions[prev_round]
        my_coop = int(my_prev_action.item())
        opponent_coop = np.sum(opponent_prev_actions)
        total_coop = my_coop + opponent_coop
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_458(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that promotes sustained cooperation 
    through initial cooperation, monitoring past behavior, and brief punishment when 
    the cooperation threshold isn't met.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_action_was_punishment = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif self.last_action_was_punishment:
            self.last_action_was_punishment = False
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_action = history.my_actions[prev_round]
            my_action_int = int(my_action)
            opp_actions = history.opponent_actions[prev_round]
            opp_coop = np.sum(opp_actions)
            total_coop = my_action_int + opp_coop
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                self.last_action_was_punishment = True
                return Action.D

class Strategy_COLLECTIVE_459(BaseStrategy):
    """
    A strategy where players cooperate if at least m players cooperated in the previous round; otherwise, they defect.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n_players = game_description.n_players
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        prev_my_action = history.my_actions[prev_round]
        prev_opponents = history.opponent_actions[prev_round, :]
        total_coop = int(prev_my_action) + int(np.sum(prev_opponents))
        if total_coop >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_461(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that encourages cooperation by conditioning actions on previous rounds' outcomes.
    Cooperates in the first round, and then continues to cooperate if the minimum required cooperators were met in the previous round.
    Defects otherwise, but reverts to cooperation in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        if history is None:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        sum_opponents_C = np.sum(history.opponent_actions[prev_round, :])
        total_C = my_prev_action + sum_opponents_C
        if total_C >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_462(BaseStrategy):
    """
    A strategy that adapts cooperation based on recent collective success.
    Cooperates if at least 50% of the last 3 rounds were successful.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        payoffs = history.my_payoffs
        successes = (payoffs > 1).astype(int)
        window_size = min(len(successes), 3)
        recent_successes = successes[-window_size:]
        success_rate = np.mean(recent_successes) if recent_successes.size > 0 else 0.0
        if success_rate >= 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_463(BaseStrategy):
    """
    Cooperative Until Failure, Then Permanent Defection strategy.
    Cooperates initially and continues if the minimum cooperators threshold is met in all rounds.
    Defects permanently if the threshold is ever failed.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defected = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if self.defected:
            return Action.D
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        for t in range(current_round):
            my_action = history.my_actions[t]
            opp_actions = history.opponent_actions[t, :]
            total_coop = my_action + np.sum(opp_actions)
            if total_coop < self.game_description.m:
                self.defected = True
                return Action.D
        return Action.C

class Strategy_COLLECTIVE_464(BaseStrategy):
    """
    A strategy that reciprocates cooperation based on previous rounds.
    Cooperates in the first round and continues if the threshold m is met.
    Defects otherwise, promoting cooperation while discouraging exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_prev_action = history.my_actions[-1]
        opponents_prev_actions = history.opponent_actions[-1, :]
        cooperators = sum(opponents_prev_actions) + (1 if my_prev_action else 0)
        if cooperators >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_465(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that promotes cooperation by reciprocating 
    cooperative behavior, punishing defection, and incorporating a forgiveness mechanism.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.window_size = 3

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = state.round_number
        game = self.game_description
        n_rounds = game.n_rounds
        if round_num == 0:
            return Action.C
        if round_num == n_rounds - 1:
            return Action.C
        prev_round = round_num - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_prev = np.sum(history.opponent_actions[prev_round])
        prev_coop = int(my_prev_action) + opponent_prev
        if prev_coop >= game.m:
            return Action.C
        start = max(0, prev_round - (self.window_size - 1))
        total_coop = 0
        count = 0
        for t in range(start, prev_round + 1):
            if t < len(history.my_actions):
                my_action = history.my_actions[t]
                opponent_coop = np.sum(history.opponent_actions[t])
                total_coop += int(my_action) + opponent_coop
                count += 1
        avg_coop = total_coop / count if count > 0 else 0.0
        if avg_coop >= game.m:
            return Action.C
        consecutive_d = 0
        t = prev_round
        while t >= 0 and consecutive_d < self.window_size:
            if not history.my_actions[t]:
                consecutive_d += 1
            else:
                break
            t -= 1
        if consecutive_d >= self.window_size:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_466(BaseStrategy):
    """
    A strategy designed to maintain cooperation in a repeated Collective Risk Dilemma game.
    It promotes sustained cooperation by conditioning actions on previous outcomes, defecting once 
    after insufficient cooperation, and then reverting to cooperation to restart collective success.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        prev_my_action = history.my_actions[prev_round]
        opponent_prev = history.opponent_actions[prev_round]
        sum_me = 1 if prev_my_action else 0
        sum_opp = sum(opponent_prev)
        total_coop = sum_me + sum_opp
        if total_coop >= self.m:
            return Action.C
        elif prev_my_action:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_467(BaseStrategy):
    """
    A strategy that starts with cooperation, continues if enough players cooperate, 
    defects as punishment otherwise, and always cooperates the round after a defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.must_cooperate_next = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif self.must_cooperate_next:
            self.must_cooperate_next = False
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opp_prev_actions = history.opponent_actions[prev_round, :]
            coop_prev = sum(opp_prev_actions) + (1 if my_prev_action else 0)
            if coop_prev >= self.game_description.m:
                return Action.C
            else:
                self.must_cooperate_next = True
                return Action.D

class Strategy_COLLECTIVE_468(BaseStrategy):
    """
    Implementation of the Adaptive Forgiveness strategy for the Collective Risk Dilemma.
    Cooperates initially, then continues if enough players cooperated in the previous round.
    Defects if cooperation was insufficient, but only up to two consecutive times before cooperating again.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        my_prev_action = history.my_actions[last_round]
        opponent_prev_actions = history.opponent_actions[last_round, :]
        total_coop_prev = my_prev_action + np.sum(opponent_prev_actions)
        if total_coop_prev >= self.game_description.m:
            self.consecutive_defections = 0
            return Action.C
        elif self.consecutive_defections < 2:
            self.consecutive_defections += 1
            return Action.D
        else:
            self.consecutive_defections = 0
            return Action.C

class Strategy_COLLECTIVE_469(BaseStrategy):
    """
    A strategy that begins by cooperating in the first round. In subsequent rounds, it cooperates if at least m players cooperated in the previous round; otherwise, it defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round_idx = state.round_number - 1
            opponent_actions_prev = history.opponent_actions[prev_round_idx]
            opponent_coop = np.sum(opponent_actions_prev)
            my_prev_action = history.my_actions[prev_round_idx]
            total_coop_prev = opponent_coop + (1 if my_prev_action else 0)
            if total_coop_prev >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_470(BaseStrategy):
    """
    Adaptive Cooperation with Punishment (ACP):
    Cooperate initially. Continue if threshold met; defect once if not, then revert to cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        my_prev_action = history.my_actions[last_round]
        opponent_actions_last = history.opponent_actions[last_round, :]
        coop_prev = my_prev_action + sum(opponent_actions_last)
        if coop_prev >= self.game_description.m:
            return Action.C
        if my_prev_action:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_471(BaseStrategy):
    """
    This strategy cooperates initially, continues cooperating if the minimum threshold 
    of cooperators is met in the previous round, and defects in the last two rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None:
            return Action.C
        n_rounds = self.game_description.n_rounds
        if state.round_number >= n_rounds - 2:
            return Action.D
        previous_round = state.round_number - 1
        my_last = history.my_actions[previous_round]
        coop_me = 1 if my_last else 0
        opponents_last = history.opponent_actions[previous_round, :]
        coop_opponents = sum(opponents_last)
        total_coops = coop_me + coop_opponents
        if total_coops >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_472(BaseStrategy):
    """
    Adaptive Cooperation strategy based on historical success of rounds.
    Cooperates in the first round, then continues if more than half of previous rounds were successful.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        m = self.game_description.m
        previous_rounds = state.round_number
        total_successes = 0
        for t in range(previous_rounds):
            my_action = history.my_actions[t]
            opponent_actions = history.opponent_actions[t]
            coop_count = 0
            if my_action:
                coop_count += 1
            coop_count += sum(opponent_actions)
            if coop_count >= m:
                total_successes += 1
        success_ratio = total_successes / previous_rounds
        if success_ratio >= 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_473(BaseStrategy):
    """
    A strategy that encourages cooperation by reciprocating based on the previous round's outcome.
    Cooperate initially; continue if the previous round met the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opponent_actions_prev = history.opponent_actions[prev_round, :]
            cooperators = (1 if my_prev_action else 0) + sum(opponent_actions_prev)
            if cooperators >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_474(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that promotes cooperation while handling cases
    where cooperation drops below the required threshold. All players cooperate initially, continue
    if the threshold is met, and defect in the last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            prev_round = state.round_number - 1
            my_prev = history.my_actions[prev_round]
            opp_prev = sum(history.opponent_actions[prev_round, :])
            total_prev = my_prev + opp_prev
            if total_prev >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_475(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that combines initial cooperation with 
    limited punishment for non-cooperation to sustain collective benefits.
    
    The strategy follows these rules:
    1. Cooperate in the first round.
    2. If fewer than m players cooperated in the previous round, defect once as a punishment.
    3. After defecting once, always return to cooperation to allow potential recovery of collective cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.force_cooperate_next = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        else:
            m = self.game_description.m
            previous_round = state.round_number - 1
            opponent_actions_prev = history.opponent_actions[previous_round, :]
            my_action_prev = history.my_actions[previous_round]
            previous_coop = np.sum(opponent_actions_prev) + (1 if my_action_prev else 0)
            if previous_coop < m:
                if not self.force_cooperate_next:
                    self.force_cooperate_next = True
                    return Action.D
                else:
                    self.force_cooperate_next = False
                    return Action.C
            else:
                if self.force_cooperate_next:
                    self.force_cooperate_next = False
                return Action.C

class Strategy_COLLECTIVE_476(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that combines initial cooperation with temporary punishment 
    for defection when a minimum number of cooperators is not met. Players cooperate initially and defect 
    for a fixed number of rounds if the cooperation threshold is not met in any round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_remaining = 0
        self.s = 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None:
            return Action.C
        if self.punishment_remaining > 0:
            self.punishment_remaining -= 1
            return Action.D
        prev_my_action = history.my_actions[-1]
        prev_opponent_actions = history.opponent_actions[-1]
        total_c = prev_my_action + sum(prev_opponent_actions)
        if total_c < self.game_description.m:
            self.punishment_remaining = self.s
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_477(BaseStrategy):
    """
    A strategy that starts with cooperation and responds to the previous round's outcomes.
    Cooperates again if at least m players cooperated in the previous round; otherwise, defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_last = history.my_actions[prev_round]
        opponents_last = history.opponent_actions[prev_round]
        total_coop = (1 if my_last else 0) + sum(opponents_last)
        threshold = self.game_description.m
        if total_coop >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_478(BaseStrategy):
    """
    An adaptive strategy that balances cooperation with forgiveness and ends with defection.
    Cooperates initially, mirrors outcomes with a forgiveness mechanism, and defects in the last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.just_gave_second_chance = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n_rounds = self.game_description.n_rounds
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == n_rounds - 1:
            return Action.D
        last_round = round_number - 1
        if history is None:
            return Action.C
        opponents_last_round = history.opponent_actions[last_round]
        my_last_action = history.my_actions[last_round]
        n_cooperators = np.sum(opponents_last_round) + (1 if my_last_action else 0)
        threshold = self.game_description.m
        previous_success = n_cooperators >= threshold
        if previous_success:
            self.just_gave_second_chance = False
            return Action.C
        elif self.just_gave_second_chance:
            self.just_gave_second_chance = False
            return Action.D
        else:
            self.just_gave_second_chance = True
            return Action.C

class Strategy_COLLECTIVE_479(BaseStrategy):
    """
    Reciprocal Cooperation Based on Past Success Strategy.
    Cooperates initially and reciprocates based on whether the threshold m was met in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opp_prev_actions = history.opponent_actions[prev_round, :]
            total_cooperated = my_prev_action + np.sum(opp_prev_actions)
            if total_cooperated >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_480(BaseStrategy):

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_previous_action = history.my_actions[previous_round]
        opponent_previous_actions = history.opponent_actions[previous_round]
        sum_opponent_coop = np.sum(opponent_previous_actions)
        total_coop = sum_opponent_coop + (1 if my_previous_action else 0)
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_481(BaseStrategy):
    """
    A strategy that promotes sustained cooperation by conditioning actions on past group behavior.
    Cooperates in the first round and continues to cooperate if enough players cooperated previously.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            previous_round = state.round_number - 1
            my_prev = history.my_actions[previous_round]
            opp_prev = history.opponent_actions[previous_round, :]
            opp_coop = np.sum(opp_prev)
            total_coop = my_prev + opp_coop
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_482(BaseStrategy):
    """
    Adaptive Cooperation Based on Success Rate Strategy.
    Cooperates initially and continues based on the success rate of previous rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self._m = game_description.m
        self._n = game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number
        successes = 0
        for round_num in range(t):
            my_action = history.my_actions[round_num]
            opponent_coops = sum(history.opponent_actions[round_num, :])
            total_coops = (1 if my_action else 0) + opponent_coops
            if total_coops >= self._m:
                successes += 1
        success_rate = successes / t
        if success_rate >= 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_483(BaseStrategy):
    """
    This strategy begins by cooperating in the first round. In subsequent rounds, it cooperates if the number 
    of cooperators in the previous round met or exceeded the minimum required (m). Otherwise, it defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            s = state.round_number - 1
            my_prev = history.my_actions[s]
            opp_prev = history.opponent_actions[s]
            total_coop = my_prev + sum(opp_prev)
            if total_coop >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_484(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that encourages cooperation through adaptive behavior.
    Cooperates initially and reciprocates based on the number of cooperators in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev = history.my_actions[prev_round]
            opponent_prev = history.opponent_actions[prev_round]
            total_coop = my_prev + opponent_prev.sum()
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_485(BaseStrategy):
    """
    A strategy that starts with cooperation and continues if the minimum threshold of 
    cooperators is met in the previous round; otherwise, it defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t_prev = state.round_number - 1
        my_prev_action = history.my_actions[t_prev]
        opponent_actions_prev = history.opponent_actions[t_prev, :]
        total_coop = my_prev_action + np.sum(opponent_actions_prev)
        if total_coop >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_486(BaseStrategy):
    """
    Adaptive Collective Cooperation Strategy.

    This strategy aims to maintain cooperation while strategically defecting 
    to encourage others to cooperate, using a success rate over recent rounds 
    to decide actions. It balances collective success with individual incentives.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.x = 10
        self.y = 3
        self.defect_remaining = 0

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        current_round = state.round_number
        n_rounds = self.game_description.n_rounds
        if current_round == 0:
            return Action.C
        elif current_round == n_rounds - 1:
            total_success = 0
            for r in range(current_round):
                my_action = history.my_actions[r]
                opponents_actions = history.opponent_actions[r]
                total_coop = np.sum(opponents_actions) + my_action
                if total_coop >= self.game_description.m:
                    total_success += 1
            if total_success / current_round >= 0.5:
                return Action.C
            else:
                start_round = max(0, current_round - self.x)
                recent_success = 0
                for r in range(start_round, current_round):
                    my_act = history.my_actions[r]
                    opponents_act = history.opponent_actions[r]
                    coop_count = np.sum(opponents_act) + my_act
                    if coop_count >= self.game_description.m:
                        recent_success += 1
                n = current_round - start_round
                if n == 0:
                    recent_rate = 0.0
                else:
                    recent_rate = recent_success / n
                if recent_rate >= 0.5:
                    return Action.C
                else:
                    return Action.D
        elif self.defect_remaining > 0:
            self.defect_remaining -= 1
            return Action.D
        else:
            start_round = max(0, current_round - self.x)
            successful_rounds = 0
            for r in range(start_round, current_round):
                my_act = history.my_actions[r]
                opponents_act = history.opponent_actions[r]
                coop_count = np.sum(opponents_act) + my_act
                if coop_count >= self.game_description.m:
                    successful_rounds += 1
            n = current_round - start_round
            if n == 0:
                success_rate = 0.0
            else:
                success_rate = successful_rounds / n
            if success_rate > 0.7:
                return Action.C
            elif success_rate < 0.5:
                self.defect_remaining = self.y
                return Action.D
            else:
                return Action.C

class Strategy_COLLECTIVE_487(BaseStrategy):
    """
    A strategy where players cooperate if the number of cooperators in the previous round meets or exceeds m, starting with cooperation in the first round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round_index = history.my_actions.size - 1
        my_action_prev = history.my_actions[previous_round_index]
        opponent_actions_prev = history.opponent_actions[previous_round_index, :]
        total_coop_prev = np.sum(opponent_actions_prev) + my_action_prev
        if total_coop_prev >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_488(BaseStrategy):
    """
    A Tit-for-Tat inspired strategy for the Collective Risk Dilemma game.
    - Cooperates in the first round.
    - For subsequent rounds, cooperates if at least m players cooperated in the previous round; otherwise, defects.
    Promotes sustained cooperation while preventing exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        my_last_action = bool(history.my_actions[last_round])
        opponent_last_actions = history.opponent_actions[last_round, :]
        opponents_coop = sum(opponent_last_actions)
        total_coop = opponents_coop + (1 if my_last_action else 0)
        m = self.game_description.m
        if total_coop >= m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_489(BaseStrategy):
    """
    An adaptive strategy that starts with cooperation, punishes when cooperation is below the threshold, 
    and forgives to resume cooperation when beneficial.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.cooperate_next = True

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opp_prev_actions = history.opponent_actions[prev_round]
        coops_prev = my_prev_action + opp_prev_actions.sum()
        if self.cooperate_next:
            if coops_prev >= self.m:
                return Action.C
            else:
                self.cooperate_next = False
                return Action.D
        else:
            action = Action.D
            if coops_prev >= self.m:
                self.cooperate_next = True
            return action

class Strategy_COLLECTIVE_491(BaseStrategy):
    """
    This strategy begins with cooperation, punishes defection adaptively, and forgives after a short period.
    It aims to balance punishment and cooperation to maintain a collective benefit.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.defection_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.r - 1:
            if len(history.my_actions) < self.r - 1:
                return Action.C
            else:
                prev_prev_round = min(state.round_number - 2, len(history.my_actions) - 1)
                prev_prev_coop = np.sum(history.opponent_actions[prev_prev_round, :]) + history.my_actions[prev_prev_round]
                if prev_prev_coop >= self.m:
                    return Action.C
                else:
                    return Action.D
        else:
            prev_round = state.round_number - 1
            if prev_round >= len(history.my_actions):
                self.defection_count = 0
                return Action.C
            prev_coop = np.sum(history.opponent_actions[prev_round, :]) + history.my_actions[prev_round]
            if prev_coop >= self.m:
                self.defection_count = 0
                return Action.C
            elif self.defection_count < 2:
                self.defection_count += 1
                return Action.D
            else:
                self.defection_count = 0
                return Action.C

class Strategy_COLLECTIVE_492(BaseStrategy):
    """
    A strategy to address the collective risk dilemma by encouraging cooperation and resetting after consecutive defections.
    - Cooperate in the first round.
    - Cooperate if the previous round met the cooperation threshold.
    - Defect if the threshold wasn't met.
    - Reset to cooperation after two consecutive defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defects = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_last = history.my_actions[-1]
        if my_last == Action.C:
            self.consecutive_defects = 0
        else:
            self.consecutive_defects += 1
        if self.consecutive_defects >= 2:
            self.consecutive_defects = 0
            return Action.C
        my_coop = int(my_last == Action.C)
        opp_coop = int(np.sum(history.opponent_actions[-1]))
        total_coop = my_coop + opp_coop
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_493(BaseStrategy):
    """
    Implements a strategy for the Collective Risk Dilemma game.
    The strategy starts by cooperating in the first round. In subsequent rounds,
    it cooperates if the number of cooperators in the previous round met the threshold,
    otherwise it defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        opponent_actions_prev = history.opponent_actions[prev_round, :]
        my_prev_action = history.my_actions[prev_round]
        cooperators = sum(opponent_actions_prev) + my_prev_action
        if cooperators >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_494(BaseStrategy):
    """
    Forgiving Cooperation with Punishment Strategy.
    Cooperate initially. Continue if enough cooperated last round.
    If insufficient, defect unless you defected last time, then cooperate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        my_last_action = history.my_actions[last_round]
        opponents_last_actions = history.opponent_actions[last_round]
        total_coops = my_last_action + sum(opponents_last_actions)
        if total_coops >= self.m:
            return Action.C
        elif not my_last_action:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_495(BaseStrategy):
    """
    Adaptive Cooperation with Retaliation and Forgiveness strategy for the Collective Risk Dilemma.
    Cooperates initially, retaliates against defection, and forgives based on recent cooperation trends.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.retaliation_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.retaliation_counter > 0:
            self.retaliation_counter -= 1
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_prev_actions = history.opponent_actions[prev_round, :]
        total_prev_coop = my_prev_action + sum(opponents_prev_actions)
        if total_prev_coop >= self.game_description.m:
            return Action.C
        else:
            self.retaliation_counter = 2
            return Action.D

class Strategy_COLLECTIVE_496(BaseStrategy):
    """
    Implements a strategy to ensure sustained cooperation while allowing recovery from temporary drops below the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_opponents = history.opponent_actions[-1, :]
        prev_my_action = history.my_actions[-1]
        prev_cooperators = sum(prev_opponents) + (1 if prev_my_action else 0)
        m = self.game_description.m
        if prev_cooperators >= m:
            return Action.C
        elif not prev_my_action:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_497(BaseStrategy):
    """
    A strategy that begins with cooperation, punishes when cooperation is below a threshold,
    then forgives after a single punishment, returning to cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        opponent_actions = history.opponent_actions[prev_round]
        my_action = history.my_actions[prev_round]
        coop_opponents = sum(opponent_actions)
        my_coop = my_action
        prev_coop_count = coop_opponents + (1 if my_coop else 0)
        if prev_coop_count >= self.game_description.m:
            return Action.C
        elif not my_coop:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_498(BaseStrategy):
    """
    A strategy that starts with cooperation, punishes when cooperation is below the threshold, 
    then resets to cooperation, aiming to avoid perpetual defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_defection_flag = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            my_coop = 1 if my_prev_action else 0
            opponents_coop = np.sum(history.opponent_actions[prev_round, :])
            prev_total_coops = my_coop + opponents_coop
            m = self.game_description.m
            if prev_total_coops >= m:
                self.last_defection_flag = False
                return Action.C
            elif not self.last_defection_flag:
                self.last_defection_flag = True
                return Action.D
            else:
                self.last_defection_flag = False
                return Action.C

class Strategy_COLLECTIVE_499(BaseStrategy):
    """
    Cooperative Reset with Punishment Strategy.
    
    Players start by cooperating. They continue to cooperate if the number of cooperators
    meets the threshold in the previous round. If not, they defect in the next round as
    punishment and then revert to cooperation in the following round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.force_cooperate_next = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.force_cooperate_next:
            self.force_cooperate_next = False
            return Action.C
        last_round = state.round_number - 1
        my_action = history.my_actions[last_round]
        my_coop = 1 if my_action else 0
        opp_actions = history.opponent_actions[last_round]
        opp_coop = sum(opp_actions)
        total_coop = my_coop + opp_coop
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            self.force_cooperate_next = True
            return Action.D

class Strategy_COLLECTIVE_500(BaseStrategy):
    """
    A strategy that promotes sustained cooperation by defecting when the cooperation threshold is not met but allowing recovery in subsequent rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_was_defection_due_to_failure = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.last_was_defection_due_to_failure = False
            return Action.C
        t_prev = state.round_number - 1
        my_prev_action = history.my_actions[t_prev]
        opponent_prev_actions = history.opponent_actions[t_prev]
        s_prev = 0
        if my_prev_action:
            s_prev += 1
        for a in opponent_prev_actions:
            if a:
                s_prev += 1
        m = self.game_description.m
        if s_prev >= m:
            action = Action.C
            self.last_was_defection_due_to_failure = False
        else:
            if self.last_was_defection_due_to_failure:
                action = Action.C
            else:
                action = Action.D
            self.last_was_defection_due_to_failure = action == Action.D
        return action

class Strategy_COLLECTIVE_501(BaseStrategy):
    """A strategy that starts with cooperation and continues if majority of past 
    rounds were successful in meeting the cooperation threshold."""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        m = self.game_description.m
        t = state.round_number
        count_success = 0
        for round in range(t):
            my_action = history.my_actions[round]
            opponent_actions = history.opponent_actions[round]
            total_coop = int(my_action) + int(opponent_actions.sum())
            if total_coop >= m:
                count_success += 1
        if count_success > t / 2:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_502(BaseStrategy):
    """
    A strategy that promotes sustained cooperation by rewarding successful collective action 
    and punishing non-cooperation through defection in the subsequent round if the cooperation 
    threshold is not met.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t_prev = state.round_number - 1
        opponent_coop = sum(history.opponent_actions[t_prev])
        my_coop = 1 if history.my_actions[t_prev] else 0
        total_coop = opponent_coop + my_coop
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_503(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that begins with initial cooperation, 
    continues cooperating if a minimum threshold is met, and probabilistically 
    cooperates otherwise to balance collective rewards.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        last_my_action = history.my_actions[prev_round]
        opponent_actions = history.opponent_actions[prev_round]
        num_coop_prev = last_my_action + opponent_actions.sum()
        if num_coop_prev >= self.game_description.m:
            return Action.C
        else:
            p = self.game_description.m / self.game_description.n_players
            return Action.C if random.random() < p else Action.D

class Strategy_COLLECTIVE_504(BaseStrategy):
    """
    This strategy balances cooperation with strategic punishment to maintain the minimum number of cooperators.
    It starts with cooperation, punishes if the threshold isn't met in subsequent rounds, and evaluates overall history in the last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if current_round == self.n_rounds - 1:
            total_rounds = len(history.my_actions)
            success_count = 0
            for round_num in range(total_rounds):
                opponent_actions_in_round = history.opponent_actions[round_num]
                num_opponent_C = np.sum(opponent_actions_in_round)
                my_action = history.my_actions[round_num]
                num_C = num_opponent_C + (1 if my_action else 0)
                if num_C >= self.m:
                    success_count += 1
            if success_count > total_rounds / 2:
                return Action.C
            else:
                return Action.D
        else:
            prev_round = current_round - 1
            opponent_actions_prev = history.opponent_actions[prev_round]
            num_opponent_C = np.sum(opponent_actions_prev)
            my_prev_action = history.my_actions[prev_round]
            num_C = num_opponent_C + (1 if my_prev_action else 0)
            if num_C >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_505(BaseStrategy):
    """
    Strategy implementing "Adaptive Reciprocity with Reinitiation" for the Collective Risk Dilemma.
    Cooperates initially, reciprocates based on previous cooperation, reinitiates cooperation after 
    three consecutive defections, and defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            prev_round = state.round_number - 1
            my_prev = history.my_actions[prev_round]
            opp_prev = history.opponent_actions[prev_round]
            total_coop = my_prev + opp_prev.sum()
            prev_met = total_coop >= self.game_description.m
            if prev_met or self.consecutive_defections >= 3:
                self.consecutive_defections = 0
                return Action.C
            else:
                self.consecutive_defections += 1
                return Action.D

class Strategy_COLLECTIVE_506(BaseStrategy):
    """
    Adaptive Collective Cooperation Strategy.

    This strategy starts by cooperating in the first round to encourage cooperation. 
    In subsequent rounds, it calculates the average number of cooperators from previous rounds. 
    If the average meets or exceeds the minimum required cooperators (m), it continues to cooperate. 
    Otherwise, it defects to protect individual payoffs.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_rounds = state.round_number
        total_coop = 0
        for r in range(previous_rounds):
            my_action = history.my_actions[r]
            opponents_coop = np.sum(history.opponent_actions[r, :])
            total_coop += (1 if my_action else 0) + opponents_coop
        average_coop = total_coop / previous_rounds
        if average_coop >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_507(BaseStrategy):
    """
    Adaptive Cooperation with Forgiveness strategy for the Collective Risk Dilemma.
    Cooperates initially, then continues if cooperation meets the threshold, otherwise defects once.
    Forgiveness allows reverting to cooperation if future rounds meet the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_action = history.my_actions[-1]
        self_coop = 1 if my_action else 0
        opponents_coop = history.opponent_actions[-1, :].sum()
        cooperation_prev = self_coop + opponents_coop
        if cooperation_prev >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_508(BaseStrategy):
    """
    A strategy that starts by cooperating and then cooperates again if the previous round met the threshold,
    otherwise it defects to punish and then offers another chance to cooperate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_prev_actions = history.opponent_actions[prev_round, :]
        total_cooperators = 1 if my_prev_action else 0
        total_cooperators += np.sum(opponents_prev_actions)
        if total_cooperators >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_509(BaseStrategy):
    """
    A strategy that combines reciprocal cooperation with limited punishment to sustain cooperation.
    Cooperates initially and continues as long as the minimum number of cooperators (m) is met in the previous round.
    Defects if cooperation falls short, but limits consecutive defections to two rounds before attempting to cooperate again.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consec_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_actions = history.my_actions[prev_round]
        opponent_actions = history.opponent_actions[prev_round]
        num_coop_prev = np.sum(opponent_actions) + (1 if my_actions else 0)
        cooperation_met = num_coop_prev >= self.game_description.m
        if self.consec_defections >= 2:
            self.consec_defections = 0
            return Action.C
        elif cooperation_met:
            self.consec_defections = 0
            return Action.C
        else:
            self.consec_defections += 1
            return Action.D

class Strategy_COLLECTIVE_510(BaseStrategy):
    """
    A strategy that cooperates if the minimum number of players cooperate, 
    otherwise defects and may recover cooperation based on previous rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number
        t_prev = t - 1
        my_prev_action = history.my_actions[t_prev]
        opponent_prev_actions = history.opponent_actions[t_prev, :]
        prev_total_C = my_prev_action + opponent_prev_actions.sum()
        if prev_total_C >= self.game_description.m:
            return Action.C
        elif my_prev_action:
            return Action.D
        elif t_prev == 0:
            return Action.D
        else:
            prev_prev_round = t_prev - 1
            my_pprev_action = history.my_actions[prev_prev_round]
            opponent_pprev_actions = history.opponent_actions[prev_prev_round, :]
            prev_pprev_total_C = my_pprev_action + opponent_pprev_actions.sum()
            if prev_pprev_total_C >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_511(BaseStrategy):
    """
    Adaptive Cooperation with Reset Mechanism strategy for the Collective Risk Dilemma.
    Cooperates initially, then continues if previous cooperation met the threshold, 
    defects otherwise. Resets cooperation after two consecutive defections to avoid cycles.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defects = 0
        self.reset_threshold = 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.consecutive_defects >= self.reset_threshold:
            action = Action.C
            self.consecutive_defects = 0
        else:
            previous_round = state.round_number - 1
            opponent_coop = sum(history.opponent_actions[previous_round, :])
            my_coop = history.my_actions[previous_round]
            total_coop = opponent_coop + (1 if my_coop else 0)
            if total_coop >= self.game_description.m:
                action = Action.C
            else:
                action = Action.D
            if action == Action.D:
                self.consecutive_defects += 1
                if self.consecutive_defects > self.reset_threshold:
                    self.consecutive_defects = self.reset_threshold
            else:
                self.consecutive_defects = 0
        return action

class Strategy_COLLECTIVE_512(BaseStrategy):
    """
    Adaptive Cooperation with Punishment Strategy.
    Cooperates initially, then cooperates if the previous round met the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_prev_actions = history.opponent_actions[prev_round, :]
        sum_opp_prev = np.sum(opponent_prev_actions)
        total_coop_prev = sum_opp_prev + (1 if my_prev_action else 0)
        if total_coop_prev >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_1(BaseStrategy):
    """
    Exploitative Strategy for Collective Risk Dilemma.
    Cooperates initially, adapts based on previous outcomes, defecting when safe.
    Includes recooperation and punishment phases.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.recooperate_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        my_last_action = history.my_actions[last_round]
        opponent_actions_last = history.opponent_actions[last_round, :]
        sum_opponents = np.sum(opponent_actions_last)
        last_coops = sum_opponents + (1 if my_last_action else 0)
        if self.recooperate_remaining > 0:
            self.recooperate_remaining -= 1
            return Action.C
        if last_coops < self.game_description.m:
            self.recooperate_remaining = 3
            self.recooperate_remaining -= 1
            return Action.C
        can_defect = last_coops - (1 if my_last_action else 0) >= self.game_description.m
        if can_defect:
            if np.random.random() < 0.2:
                return Action.C
            else:
                return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_2(BaseStrategy):
    """A strategy that starts by cooperating and then adapts based on the previous round's cooperation.
    Cooperates if at least m players cooperated in the previous round, otherwise defects."""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            sum_opponent = np.sum(history.opponent_actions[prev_round, :])
            prev_coops = my_prev_action + sum_opponent
            if prev_coops >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_3(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma game.
    Cooperates initially and continues based on the trend of cooperation,
    defecting in the final round to maximize immediate payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.n_rounds - 1:
            return Action.D
        elif state.round_number == self.n_rounds - 2:
            coops = []
            for i in range(max(0, state.round_number - 2), state.round_number):
                my_action = int(history.my_actions[i])
                opp_coop = sum(history.opponent_actions[i])
                coops.append(my_action + opp_coop)
            avg_coop = sum(coops) / len(coops) if coops else 0
            if avg_coop >= self.m:
                return Action.C
            else:
                trend_increasing = True
                if len(coops) >= 2:
                    for i in range(1, len(coops)):
                        if coops[i] < coops[i - 1]:
                            trend_increasing = False
                            break
                else:
                    trend_increasing = False
                return Action.C if trend_increasing else Action.D
        else:
            window = min(3, state.round_number)
            coops = []
            for i in range(state.round_number - window, state.round_number):
                my_action = int(history.my_actions[i])
                opp_coop = sum(history.opponent_actions[i])
                coops.append(my_action + opp_coop)
            avg_coop = sum(coops) / window if window else 0
            return Action.C if avg_coop >= self.m else Action.D

class Strategy_EXPLOITATIVE_4(BaseStrategy):
    """
    An adaptive strategy for Collective Risk Dilemma that balances cooperation
    based on past behavior and includes a fail-safe mechanism to prevent
    exploitation if success proportion falls below a threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.has_failed = False
        self.p = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.has_failed:
            return Action.D
        m = self.game_description.m
        n_opponents = self.game_description.n_players - 1
        expected_coop_others = 0.0
        if history is not None and state.round_number > 0:
            t_prev = state.round_number
            opponent_actions = history.opponent_actions
            if opponent_actions is not None:
                opponent_actions_array = opponent_actions[:t_prev, :]
                averages = np.mean(opponent_actions_array, axis=0)
                expected_coop_others = np.sum(averages)
            if expected_coop_others >= m:
                action = Action.D
            else:
                action = Action.C
        else:
            action = Action.C
        S = 0
        t_prev = state.round_number
        if history is not None and t_prev > 0:
            for r in range(t_prev):
                my_action = history.my_actions[r]
                payoff = history.my_payoffs[r]
                k = self.game_description.k
                if my_action:
                    if payoff == k:
                        S += 1
                elif payoff == 1.0 + k:
                    S += 1
            if t_prev > 0:
                proportion = S / t_prev
                if proportion < self.p:
                    self.has_failed = True
        return action

class Strategy_EXPLOITATIVE_5(BaseStrategy):
    """
    A strategy that starts by cooperating and then adapts based on the frequency
    of meeting the cooperation threshold in previous rounds. If more than 50%
    of previous rounds met the threshold, defect; otherwise, cooperate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number
        m = self.game_description.m
        count = 0
        for r in range(t):
            my_action = history.my_actions[r]
            opponents = history.opponent_actions[r, :]
            sum_coop = my_action + np.sum(opponents)
            if sum_coop >= m:
                count += 1
        frequency = count / t
        if frequency > 0.5:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_6(BaseStrategy):
    """
    A strategy that starts with cooperation, adapts based on previous cooperation levels, 
    and defects in the final round to maximize payoffs.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.r - 1:
            return Action.D
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_prev_actions = history.opponent_actions[prev_round]
        sum_opponents = np.sum(opponents_prev_actions)
        total_coop = my_prev_action + sum_opponents
        if total_coop >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_8(BaseStrategy):
    """
    A strategy that adaptively cooperates based on historical behavior, with exploration.
    It starts with cooperation to set a tone, then uses the average of past cooperation,
    defecting below a threshold but occasionally exploring by cooperating.
    Defects in the last round to maximize payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n_rounds = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.n_rounds - 1:
            return Action.D
        count_coop = 0.0
        for previous_round in range(state.round_number):
            my_action = history.my_actions[previous_round]
            opp_actions = history.opponent_actions[previous_round, :]
            current_coop = my_action + np.sum(opp_actions)
            count_coop += current_coop
        avg_coop = count_coop / state.round_number
        if avg_coop >= self.m:
            return Action.C
        elif random.random() < 0.1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_9(BaseStrategy):
    """
    A strategy that starts with cooperation, retaliates temporarily when cooperation levels are low,
    and sustains cooperation in the endgame to maximize collective payoffs.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.is_retaliating = False
        self.retaliate_rounds_left = 0
        self.retaliate_duration = 2

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        round_number = state.round_number
        if history is None:
            return Action.C
        n = self.n_players
        r = self.n_rounds
        if round_number < 2:
            return Action.C
        if round_number >= r - 2:
            return Action.C
        if self.is_retaliating:
            if self.retaliate_rounds_left > 0:
                self.retaliate_rounds_left -= 1
                return Action.D
            else:
                self.is_retaliating = False
        recent_coop_counts = []
        for t in range(max(0, round_number - 3), round_number):
            if t >= 0:
                my_action = history.my_actions[t]
                opp_actions = history.opponent_actions[t]
                coop_count = my_action + np.sum(opp_actions)
                recent_coop_counts.append(coop_count)
        if not recent_coop_counts:
            return Action.C
        else:
            average_coop = np.mean(recent_coop_counts)
            if average_coop >= self.m:
                return Action.C
            else:
                self.is_retaliating = True
                self.retaliate_rounds_left = self.retaliate_duration
                return Action.D

class Strategy_EXPLOITATIVE_10(BaseStrategy):
    """
    Adaptive Exploitation strategy for the Collective Risk Dilemma.

    This strategy starts by cooperating in the first round. In subsequent rounds, 
    it continues to cooperate if at least m players cooperated in the previous round. 
    It defects in all other cases, including the last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            previous_round = state.round_number - 1
            my_prev_action = history.my_actions[previous_round]
            opponent_actions = history.opponent_actions[previous_round, :]
            coop_count = (1 if my_prev_action else 0) + sum(opponent_actions)
            if coop_count >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_11(BaseStrategy):
    """
    Adaptive Cooperation Based on Historical Performance strategy.
    Cooperates initially and adapts based on the number of cooperators in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_my_action = history.my_actions[-1]
            prev_opp_actions = history.opponent_actions[-1]
            total_coop = prev_my_action + np.sum(prev_opp_actions)
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_12(BaseStrategy):
    """
    This strategy cooperates in the first round, defects in the last round, and 
    cooperates in intermediate rounds if the average historical cooperation meets 
    or exceeds the minimum required.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            total_coop = 0
            for t in range(state.round_number):
                my_action = history.my_actions[t]
                opponent_actions = history.opponent_actions[t]
                count = int(my_action) + opponent_actions.sum()
                total_coop += count
            average_coop = total_coop / state.round_number
            if average_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_13(BaseStrategy):
    """
    A strategy that balances exploitation and contribution by cooperating initially and 
    then deciding based on the average cooperation of others in previous rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number
        sum_opponents = np.sum(history.opponent_actions[:t])
        avg_coop = sum_opponents / t
        if avg_coop + 1 >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_14(BaseStrategy):
    """
    This strategy begins by cooperating in the first round to encourage others to cooperate. 
    In subsequent rounds, it adapts based on whether the cooperative threshold was met in the previous round.
    If the threshold was met, it continues to cooperate. If not met, it defects for up to two rounds, 
    then gives cooperation another chance. In the final round, it always defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.count_defects = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        my_prev_payoff = history.my_payoffs[prev_round]
        threshold_met = False
        if my_prev_action:
            threshold_met = my_prev_payoff == self.game_description.k
        else:
            threshold_met = my_prev_payoff == 1 + self.game_description.k
        if threshold_met:
            self.count_defects = 0
            return Action.C
        elif self.count_defects < 2:
            self.count_defects += 1
            return Action.D
        else:
            self.count_defects = 0
            return Action.C

class Strategy_EXPLOITATIVE_15(BaseStrategy):
    """
    An exploitative strategy for the Collective Risk Dilemma game. Cooperates initially, 
    then defects if the number of cooperators in the previous round meets the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opp_prev_actions = history.opponent_actions[prev_round, :]
        total_coop = my_prev_action + np.sum(opp_prev_actions)
        if total_coop >= self.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_16(BaseStrategy):
    """
    Adaptive Punishment with Last-Round Exploitation strategy for Collective Risk Dilemma.
    Cooperates initially, punishes if cooperation is insufficient, then resumes cooperation.
    Defects in the final round to maximize personal payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punish_next = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            if self.punish_next:
                action = Action.D
                self.punish_next = False
            else:
                action = Action.C
            if history is not None:
                prev_round = state.round_number - 1
                my_prev = history.my_actions[prev_round]
                opponents_prev = history.opponent_actions[prev_round, :]
                coop_count = my_prev + np.sum(opponents_prev)
                if coop_count < self.game_description.m:
                    self.punish_next = True
                else:
                    self.punish_next = False
            return action

class Strategy_EXPLOITATIVE_17(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that balances cooperation and defection.
    It starts by cooperating, adapts based on previous outcomes, and periodically tests cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.test_interval = 5
        self.testing_counter = 0
        self.last_coop_met = False
        self.last_action = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        if t == 0:
            action = Action.C
            self.last_action = action
            return action
        else:
            prev_my_action = history.my_actions[-1]
            prev_opponent_actions = history.opponent_actions[-1, :]
            prev_coop_count = sum(prev_opponent_actions) + (1 if prev_my_action else 0)
            self.last_coop_met = prev_coop_count >= self.m
            if state.round_number == self.game_description.n_rounds - 1:
                action = Action.C if self.last_coop_met else Action.D
            else:
                if self.testing_counter >= self.test_interval and self.last_action == Action.D:
                    action = Action.C
                    self.testing_counter = 0
                else:
                    action = Action.C if self.last_coop_met else Action.D
                if action == Action.D:
                    self.testing_counter += 1
                else:
                    self.testing_counter = 0
            self.last_action = action
            return action

class Strategy_EXPLOITATIVE_18(BaseStrategy):
    """
    Adaptive Cooperation Strategy based on previous round's cooperation level.
    Cooperates initially and continues if enough players cooperated previously.
    Defects if cooperation was insufficient in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_action_prev = history.my_actions[prev_round]
        opponents_prev = history.opponent_actions[prev_round]
        total_coop = my_action_prev + sum(opponents_prev)
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_19(BaseStrategy):
    """
    A strategy that initially cooperates and then adapts based on the number of cooperators in the previous round.
    Cooperates if the previous round had fewer than m cooperators, otherwise defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        prev_my_action = history.my_actions[-1]
        prev_opp_actions = history.opponent_actions[-1]
        total_coops = prev_opp_actions.sum()
        if prev_my_action:
            total_coops += 1
        if total_coops >= self.game_description.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_20(BaseStrategy):
    """
    Cooperates initially, then defects if cooperators exceed the threshold,
    continues to cooperate if at the threshold, and defects if below.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        my_last_action = history.my_actions[last_round]
        opponent_last_actions = history.opponent_actions[last_round]
        count_C = my_last_action + sum(opponent_last_actions)
        m = self.game_description.m
        if count_C > m:
            return Action.D
        elif count_C == m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_21(BaseStrategy):
    """
    A strategy that begins with cooperation, adapts based on previous cooperation levels, 
    and defects in the final round to maximize payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.n_rounds - 1:
            return Action.D
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            op_prev_actions = history.opponent_actions[prev_round]
            opponent_coop = np.sum(op_prev_actions)
            total_coop = opponent_coop + (1 if my_prev_action else 0)
            if total_coop >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_22(BaseStrategy):
    """
    This strategy begins with cooperation to encourage reciprocity, adapts based 
    on the proportion of successful rounds, and defects in the final two rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number >= self.n_rounds - 2:
            return Action.D
        count = 0
        t = state.round_number
        n_rounds = self.n_rounds
        for s in range(t):
            my_c = history.my_actions[s]
            opps = history.opponent_actions[s]
            opp_c = np.count_nonzero(opps)
            total_c = int(my_c) + opp_c
            if total_c >= self.m:
                count += 1
        proportion = count / t
        return Action.C if proportion > 0.5 else Action.D

class Strategy_EXPLOITATIVE_23(BaseStrategy):
    """
    Adaptive Cooperation Based on Historical Performance strategy.
    
    This strategy cooperates in the first round and then decides to continue 
    cooperating or switch to defecting based on whether the majority of past 
    rounds met the minimum required cooperators threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        sufficient_cooperations = 0
        total_previous_rounds = state.round_number
        for round_prev in range(total_previous_rounds):
            my_action = history.my_actions[round_prev]
            opponent_actions = history.opponent_actions[round_prev, :]
            total_cooperations = my_action + opponent_actions.sum()
            if total_cooperations >= self.m:
                sufficient_cooperations += 1
        if sufficient_cooperations > total_previous_rounds / 2:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_24(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma game. The strategy 
    starts by Cooperating and then uses the success rate of previous defections 
    to decide subsequent actions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        counts_defects = 0
        counts_success = 0
        m = self.game_description.m
        for r in range(state.round_number):
            if not history.my_actions[r]:
                counts_defects += 1
                opp_coops = np.sum(history.opponent_actions[r, :])
                if opp_coops >= m:
                    counts_success += 1
        if counts_defects == 0:
            return Action.C
        else:
            success_rate = counts_success / counts_defects
            threshold = 0.5
            if success_rate >= threshold:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_25(BaseStrategy):
    """
    Adaptive Exploitation Strategy for Collective Risk Dilemma:
    Cooperates initially, adapts based on recent cooperation levels, and defects 
    strategically in the final round to maximize payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        r = self.game_description.n_rounds
        m = self.game_description.m
        n = self.game_description.n_players
        if current_round == 0:
            return Action.C
        elif current_round == r - 1:
            expected_coop = 0
            for j in range(n - 1):
                coop_count = 0
                start = max(0, current_round - 3)
                for i in range(start, current_round):
                    if history.opponent_actions[i][j]:
                        coop_count += 1
                if coop_count >= 2:
                    expected_coop += 1
            if expected_coop >= m:
                return Action.D
            elif expected_coop + 1 >= m:
                return Action.C
            else:
                return Action.D
        else:
            start = max(0, current_round - 3)
            end = current_round
            count_coops = 0
            for i in range(start, end):
                my_coop = 1 if history.my_actions[i] else 0
                opponent_coop = sum(history.opponent_actions[i])
                total = my_coop + opponent_coop
                count_coops += total
            num_rounds = end - start
            average_coop = count_coops / num_rounds if num_rounds > 0 else 0
            if average_coop >= m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_26(BaseStrategy):
    """
    A strategy that adapts based on others' cooperation, retaliating when insufficient.
    Cooperates initially, then dynamically adjusts based on the level of cooperation observed.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishing = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        prev_round = state.round_number - 1
        prev_my_action = history.my_actions[prev_round]
        prev_others_actions = history.opponent_actions[prev_round, :]
        my_coop = 1 if prev_my_action else 0
        others_coop = np.sum(prev_others_actions)
        total_coop = my_coop + others_coop
        if total_coop >= self.game_description.m:
            if self.punishing:
                self.punishing = False
            return Action.C
        else:
            self.punishing = True
            return Action.D

class Strategy_EXPLOITATIVE_27(BaseStrategy):
    """
    Adaptive Cooperation with Probing strategy for Collective Risk Dilemma.
    Cooperates initially, adapts based on previous cooperation levels, and probes every 5 rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        if current_round % 5 == 4:
            return Action.C
        else:
            prev_round = current_round - 1
            if prev_round % 5 == 4:
                opp_actions = history.opponent_actions[prev_round, :]
                num_coop = sum(opp_actions) + 1
                if num_coop >= self.game_description.m:
                    return Action.C
                else:
                    return Action.D
            else:
                opp_actions = history.opponent_actions[-1, :]
                num_coop = sum(opp_actions) + 1
                if num_coop >= self.game_description.m:
                    return Action.C
                else:
                    return Action.D

class Strategy_EXPLOITATIVE_28(BaseStrategy):
    """
    Adaptive Exploitation Strategy for Collective Risk Dilemma.

    This strategy balances cooperation with strategic exploitation. It starts by cooperating, punishes when the threshold
    isn't met, exploits after sustained cooperation, and adapts based on opponents' defection rates.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.success_streak = 0
        self.punishing = False
        self.adaptation_defection = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        n_players = self.game_description.n_players
        opponents_count = n_players - 1
        if opponents_count == 0:
            self.adaptation_defection = False
        else:
            k = 5
            if history is None:
                avg_defect_rate = 0.0
            else:
                my_actions = history.my_actions
                opponent_actions = history.opponent_actions
                n_rounds = len(my_actions)
                start = max(0, n_rounds - k)
                total_defections = 0
                total_possible = 0
                for i in range(start, n_rounds):
                    count_D = np.sum(1 - opponent_actions[i])
                    total_defections += count_D
                    total_possible += len(opponent_actions[i])
                avg_defect_rate = total_defections / total_possible if total_possible > 0 else 0.0
                self.adaptation_defection = avg_defect_rate > 0.7
        if self.adaptation_defection:
            return Action.D if random.random() < 0.8 else Action.C
        else:
            if history is None:
                last_my_action = False
                last_opponent_actions = np.array([])
            else:
                last_my_action = history.my_actions[-1]
                last_opponent_actions = history.opponent_actions[-1]
            num_coop = 1 if last_my_action else 0
            num_coop += sum(last_opponent_actions)
            last_threshold_met = num_coop >= self.game_description.m
            if last_threshold_met:
                self.success_streak += 1
                if self.success_streak >= 2:
                    self.success_streak = 0
                    return Action.D
                else:
                    return Action.C
            elif self.punishing:
                self.punishing = False
                return Action.C
            else:
                self.punishing = True
                return Action.D

class Strategy_EXPLOITATIVE_29(BaseStrategy):
    """
    Exploitative Strategy for Collective Risk Dilemma.
    Cooperates initially, continues if threshold met, defects otherwise, 
    and resets cooperation after 3 consecutive defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0
        self.patience = 3

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t_prev = state.round_number - 1
        my_coop_prev = history.my_actions[t_prev]
        opponent_actions_prev = history.opponent_actions[t_prev]
        sum_coop_prev = sum(opponent_actions_prev) + my_coop_prev
        m = self.game_description.m
        if sum_coop_prev >= m:
            self.consecutive_defections = 0
            return Action.C
        else:
            self.consecutive_defections += 1
            if self.consecutive_defections >= self.patience:
                self.consecutive_defections = 0
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_30(BaseStrategy):
    """
    Strategy: Adaptive Cooperation with Last Round Defection (ACL)
    Description: Cooperates initially, defects in the last round, and adapts based on past cooperation levels.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            past_rounds_count = state.round_number
            cooperators_count = 0
            for prev_round in range(past_rounds_count):
                my_action = history.my_actions[prev_round]
                opponents_coop = history.opponent_actions[prev_round, :]
                sum_coop = my_action + np.sum(opponents_coop)
                if sum_coop >= self.game_description.m:
                    cooperators_count += 1
            proportion = cooperators_count / past_rounds_count
            if proportion >= 0.5:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_31(BaseStrategy):
    """
    A strategy that starts by Cooperating, then decides to Defect if enough players 
    (specifically, m + 1 or more) Cooperated in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        me_coop = history.my_actions[-1]
        opponent_coop = sum(history.opponent_actions[-1, :])
        total_prev_coop = int(me_coop) + opponent_coop
        if total_prev_coop >= self.m + 1:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_32(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma game.
    Cooperates initially, then adjusts based on the average number of cooperators in previous rounds,
    defecting strategically to maximize individual payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        """
        Initializes the strategy with the game's parameters.
        """
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        """
        Determines the action based on the current state and history.
        """
        round_number = state.round_number
        n_rounds = self.game_description.n_rounds
        m = self.game_description.m
        if round_number == 0:
            return Action.C
        elif round_number == n_rounds - 1:
            return Action.D
        else:
            total_coop = 0
            for r in range(round_number):
                my_coop = 1 if history.my_actions[r] else 0
                opp_coop = np.count_nonzero(history.opponent_actions[r])
                total_coop += my_coop + opp_coop
            average = total_coop / round_number
            if average >= m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_33(BaseStrategy):
    """
    Adaptive Cooperation Threshold (ACT) Strategy.
    - Cooperate in the first round.
    - In subsequent rounds, cooperate if the historical success rate of meeting the cooperation threshold exceeds 50%.
    - Consistently adapts based on past outcomes to maximize personal payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        s = state.round_number
        successes = 0
        m = self.game_description.m
        for t in range(s):
            my_coop = history.my_actions[t]
            opp_coops = np.sum(history.opponent_actions[t])
            total_coop = my_coop + opp_coops
            if total_coop >= m:
                successes += 1
        success_rate = successes / s
        if success_rate > 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_34(BaseStrategy):
    """
    A strategy that adapts based on the cooperation level of previous rounds.
    Cooperates initially, continues if sufficient cooperation, defects otherwise,
    and always defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.n_rounds - 1:
            return Action.D
        else:
            prev_round = state.round_number - 1
            prev_my_action = history.my_actions[prev_round]
            prev_opponent_actions = history.opponent_actions[prev_round, :]
            count_coop = (1 if prev_my_action else 0) + np.sum(prev_opponent_actions)
            if count_coop >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_35(BaseStrategy):
    """
    A strategy that starts by cooperating, then adapts based on the previous round's outcomes.
    Defects if previous cooperation was insufficient or if too many players exploited.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        my_prev_action = history.my_actions[last_round]
        opp_prev_actions = history.opponent_actions[last_round]
        C_last = int(my_prev_action) + sum(opp_prev_actions)
        m = self.game_description.m
        n = self.game_description.n_players
        if C_last < m:
            return Action.D
        else:
            D_last = n - C_last
            threshold = (n - m) / 2.0
            return Action.D if D_last > threshold else Action.C

class Strategy_EXPLOITATIVE_36(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that encourages initial cooperation, 
    adapts based on previous outcomes, and defects in the last round to maximize personal gain.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == self.n_rounds - 1:
            return Action.D
        elif history is None:
            return Action.C
        else:
            prev_round = state.round_number - 1
            opponent_actions_prev = history.opponent_actions[prev_round, :]
            opponent_coop = np.sum(opponent_actions_prev)
            my_prev_action = history.my_actions[prev_round]
            total_coop = opponent_coop + (1 if my_prev_action else 0)
            if total_coop >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_37(BaseStrategy):
    """
    Adaptive Exploitation Strategy for the Collective Risk Dilemma.
    
    This strategy starts by cooperating for the first few rounds to encourage cooperation and gather data.
    After the initial rounds, it adapts based on the average cooperation level in recent rounds,
    defecting if sufficient cooperation is maintained and cooperating otherwise to ensure the collective benefit.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.e = 2
        self.s = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number < self.e:
            return Action.C
        current_t = state.round_number
        m = self.game_description.m
        r = self.game_description.n_rounds
        start = max(0, current_t - self.s)
        end = current_t
        total_coop = 0
        num_rounds = end - start
        if num_rounds == 0:
            return Action.D
        for i in range(start, end):
            my_action = history.my_actions[i]
            opponent_actions = history.opponent_actions[i, :]
            total_coop += int(my_action) + np.sum(opponent_actions)
        avg_coop = total_coop / num_rounds
        if avg_coop >= m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_38(BaseStrategy):
    """
    A conditional cooperation strategy for the Collective Risk Dilemma.
    Cooperates when the player's contribution is pivotal, otherwise defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        m = self.game_description.m
        opp_coop_last = sum(history.opponent_actions[-1, :])
        my_coop_last = history.my_actions[-1]
        total_coop_last = opp_coop_last + (1 if my_coop_last else 0)
        if total_coop_last >= m:
            if total_coop_last - 1 < m:
                return Action.C
            else:
                return Action.D
        elif opp_coop_last + 1 >= m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_39(BaseStrategy):
    """
    A strategy designed for the Collective Risk Dilemma game. It starts with cooperation, 
    then decides whether to continue cooperating or defect based on the average number 
    of past cooperators to maximize personal payoff while encouraging others to 
    meet the cooperation threshold when necessary.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        sum_my_coop = history.my_actions[:state.round_number].sum()
        sum_opp_coop = history.opponent_actions[:state.round_number, :].sum()
        sum_c = sum_my_coop + sum_opp_coop
        average_coop = sum_c / state.round_number
        if average_coop >= self.game_description.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_40(BaseStrategy):
    """
    Implements the Adaptive Cooperation with Punishment strategy.
    Cooperates initially, then bases decisions on previous rounds' cooperation levels.
    In the last round, uses the overall trend of cooperation to decide.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        n_prev_rounds = state.round_number
        if state.round_number == self.n_rounds - 1:
            total_coop = 0.0
            for t_prev in range(n_prev_rounds):
                my_action = history.my_actions[t_prev]
                opp_actions = history.opponent_actions[t_prev]
                num_opp_coop = np.sum(opp_actions)
                total_coop += my_action + num_opp_coop
            avg_coop = total_coop / n_prev_rounds if n_prev_rounds > 0 else 0.0
            if avg_coop >= self.m:
                return Action.C
            else:
                return Action.D
        else:
            t_prev = state.round_number - 1
            my_action = history.my_actions[t_prev]
            opp_actions = history.opponent_actions[t_prev]
            num_opp_coop = np.sum(opp_actions)
            total_coop = my_action + num_opp_coop
            if total_coop >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_41(BaseStrategy):
    """
    A strategy that begins with cooperation and dynamically adjusts based on others' behavior to maximize payoffs.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number
        opponent_actions = history.opponent_actions[0:t, :]
        opponent_count = self.game_description.n_players - 1
        sum_others = 0.0
        for j in range(opponent_count):
            coop_count = np.sum(opponent_actions[:, j])
            rate = coop_count / t
            sum_others += rate
        if sum_others >= self.game_description.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_42(BaseStrategy):
    """
    This strategy starts by cooperating to encourage others and then adapts its cooperation probability
    based on the historical success of meeting the cooperation threshold. In the final round, it defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        r = self.game_description.n_rounds
        m = self.game_description.m
        if t == 0:
            return Action.C
        elif t == r - 1:
            return Action.D
        else:
            successful = 0
            for s in range(t):
                my_action = history.my_actions[s]
                opponent_actions = history.opponent_actions[s]
                total_coop = my_action + sum(opponent_actions)
                if total_coop >= m:
                    successful += 1
            success_ratio = successful / t
            cooperate_prob = 2 * success_ratio - 1
            cooperate_prob = max(0, min(1, cooperate_prob))
            exploit_factor = 1 - t / (r - 1)
            cooperate_prob *= exploit_factor
            if random.random() < cooperate_prob:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_43(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that starts with cooperation and 
    adapts based on the proportion of past rounds where the cooperation threshold was met.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        count = 0
        for t in range(state.round_number):
            my_action = history.my_actions[t]
            opponent_actions_t = history.opponent_actions[t]
            sum_opponent_C = np.sum(opponent_actions_t)
            total_C = my_action + sum_opponent_C
            if total_C >= self.game_description.m:
                count += 1
        past_rounds = state.round_number
        rate = count / past_rounds if past_rounds != 0 else 0.0
        if rate >= 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_44(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma. Cooperates in the first round, 
    then defects if at least m players cooperated in the previous round, otherwise cooperates.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_opponent_actions = history.opponent_actions[-1]
            opponent_c = np.sum(prev_opponent_actions)
            my_prev_action = history.my_actions[-1]
            total_c = opponent_c + (1 if my_prev_action else 0)
            if total_c >= self.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_45(BaseStrategy):
    """
    An exploitative strategy for the Collective Risk Dilemma game. It initially cooperates 
    to encourage group cooperation, then switches to defection if cooperation levels drop 
    below the required threshold and persists in defecting thereafter.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defect_persist = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.defect_persist:
            return Action.D
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_actions = history.opponent_actions[prev_round]
        total_cooperators = sum(opponent_actions) + (1 if my_prev_action else 0)
        if total_cooperators >= self.game_description.m:
            return Action.C
        else:
            self.defect_persist = True
            return Action.D

class Strategy_EXPLOITATIVE_46(BaseStrategy):
    """
    A strategy that cooperates based on whether the previous round met the cooperation threshold.
    Cooperates in the first round, then looks at the number of cooperators in the previous round.
    If >= m, cooperates; else, defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_prev_action = history.my_actions[-1]
        opponents_prev_actions = history.opponent_actions[-1, :]
        count_coop = 0
        if my_prev_action:
            count_coop += 1
        count_coop += sum(opponents_prev_actions)
        if count_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_47(BaseStrategy):
    """
    Responsive Cooperation (RC) Strategy:
    Cooperates in the first round. In subsequent rounds, cooperates if at least m players cooperated in the previous round; otherwise, defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            my_prev_action = history.my_actions[-1]
            opp_prev_actions = history.opponent_actions[-1, :]
            sum_opp_coop = np.sum(opp_prev_actions)
            total_coop = sum_opp_coop + my_prev_action
            if total_coop >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_48(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game based on historical cooperation levels.
    The strategy decides to Cooperate or Defect aiming to maximize individual payoffs while supporting the collective goal.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n_players = game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t_prev = state.round_number - 1
        my_prev_action = history.my_actions[t_prev]
        my_coop = 1 if my_prev_action else 0
        opponent_actions_prev = history.opponent_actions[t_prev]
        opp_coop = np.sum(opponent_actions_prev)
        prev_coops = my_coop + opp_coop
        if prev_coops >= self.m:
            if prev_coops - 1 >= self.m:
                return Action.D
            else:
                return Action.C
        else:
            needed = self.m - prev_coops
            if needed <= 1:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_49(BaseStrategy):
    """
    Cooperative Restart with Patience strategy.
    Cooperates initially, continues if successful, defects otherwise,
    but restarts cooperation after 3 consecutive defections to encourage mutual benefit.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defects = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        opponent_actions_prev = history.opponent_actions[prev_round]
        my_action_prev = history.my_actions[prev_round]
        sum_coops = sum(opponent_actions_prev) + (1 if my_action_prev else 0)
        if sum_coops >= self.game_description.m:
            self.consecutive_defects = 0
            return Action.C
        elif self.consecutive_defects < 3:
            self.consecutive_defects += 1
            return Action.D
        else:
            self.consecutive_defects = 0
            return Action.C

class Strategy_EXPLOITATIVE_50(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that cooperates initially, 
    then defects if enough others are expected to meet the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_actions = history.opponent_actions
        cooperation_rates = np.mean(opponent_actions, axis=0)
        expected_cooperators = np.sum(cooperation_rates)
        if expected_cooperators >= self.game_description.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_51(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game. Cooperates in the first round, 
    then cooperates subsequent rounds if the previous round met the cooperation threshold, 
    otherwise defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_actions_prev = history.opponent_actions[prev_round, :]
        total_cooperators = my_prev_action + opponent_actions_prev.sum()
        if total_cooperators >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_52(BaseStrategy):

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        m = self.game_description.m
        t = state.round_number
        success_count = 0
        for r in range(t):
            my_action = history.my_actions[r]
            opponent_actions = history.opponent_actions[r]
            total_coop = my_action + np.sum(opponent_actions)
            if total_coop >= m:
                success_count += 1
        proportion = success_count / t
        if proportion > 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_53(BaseStrategy):
    """An adaptive strategy that responds to recent cooperative behavior, 
    cooperating if a sufficient threshold of recent rounds met the required number of cooperators."""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.window_size = 3
        self.threshold = 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number
        start_round = max(0, t - self.window_size)
        count = 0
        for r in range(start_round, t):
            my_action = history.my_actions[r]
            opponent_actions = history.opponent_actions[r]
            total_cooperators = my_action + opponent_actions.sum()
            if total_cooperators >= self.game_description.m:
                count += 1
        return Action.C if count >= self.threshold else Action.D

class Strategy_EXPLOITATIVE_54(BaseStrategy):
    """
    Adaptive Cooperation Based on Recent Success.
    
    This strategy begins by cooperating in the first round. For subsequent rounds, it evaluates the success of meeting the minimum cooperators (m) in recent rounds. The strategy adjusts its cooperation threshold based on the reward factor (k), promoting continued cooperation when rewarded sufficiently, while defecting when the threshold isn't met.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.window_size = 3
        self.thresh_adj_per_k = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        num_previous_rounds = state.round_number
        start = max(0, num_previous_rounds - self.window_size)
        considered_rounds = num_previous_rounds - start
        recent_success = 0
        for i in range(start, num_previous_rounds):
            opp_coop = sum(history.opponent_actions[i, :])
            self_coop = 1 if history.my_actions[i] else 0
            total_coop = opp_coop + self_coop
            if total_coop >= self.game_description.m:
                recent_success += 1
        if considered_rounds == 0:
            return Action.D
        success_rate = recent_success / considered_rounds
        base_threshold = 0.5
        k = self.game_description.k
        adjusted_threshold = base_threshold - self.thresh_adj_per_k * (k - 1)
        adjusted_threshold = max(0.0, adjusted_threshold)
        if success_rate > adjusted_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_55(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that balances individual gain with maintaining necessary cooperation.
    It starts by cooperating in the first round and then defects only when the previous round's cooperation exceeds the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            previous_coop_opponents = sum(history.opponent_actions[-1])
            previous_my_coop = history.my_actions[-1]
            previous_c = previous_coop_opponents + previous_my_coop
            if previous_c > self.game_description.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_56(BaseStrategy):
    """Adaptive Threshold Cooperation strategy.
    
    This strategy starts by cooperating in the first round and then
    decides whether to cooperate or defect in subsequent rounds based
    on whether the minimum number of players cooperated in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            previous_round = state.round_number - 1
            my_prev_action = history.my_actions[previous_round]
            opponents_prev_actions = history.opponent_actions[previous_round]
            total_coop = my_prev_action + sum(opponents_prev_actions)
            if total_coop >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_57(BaseStrategy):
    """
    Exploitative Strategy for Collective Risk Dilemma:
    Cooperates initially and in subsequent rounds based on whether the previous round met the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opp_prev_actions = history.opponent_actions[prev_round]
        total_coop = int(my_prev_action) + sum(opp_prev_actions)
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_58(BaseStrategy):
    """
    Exploitative Strategy for Collective Risk Dilemma.
    Cooperates initially and defects when safe based on the previous round's cooperation level.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        opponents_actions = history.opponent_actions[prev_round, :]
        opponents_coop = sum(opponents_actions)
        my_prev_action = history.my_actions[prev_round]
        c_prev = opponents_coop + (1 if my_prev_action else 0)
        m = self.game_description.m
        if c_prev >= m and c_prev - 1 >= m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_59(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that balances cooperation and 
    defection based on recent group performance. Cooperates initially, adapts 
    based on recent success, and defects in the last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory | None):
        current_round = state.round_number
        n_rounds = self.game_description.n_rounds
        m = self.game_description.m
        if current_round == 0:
            return Action.C
        elif current_round == n_rounds - 1:
            return Action.D
        else:
            start_round = max(0, current_round - 3)
            rounds_to_check = range(start_round, current_round)
            met_threshold = 0
            for r in rounds_to_check:
                my_c = 1 if history.my_actions[r] else 0
                opp_actions = history.opponent_actions[r]
                opp_c = np.sum(opp_actions)
                total_c = my_c + opp_c
                if total_c >= m:
                    met_threshold += 1
            if met_threshold >= 2:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_60(BaseStrategy):
    """
    A strategy designed for the Collective Risk Dilemma that begins with cooperation,
    continues to cooperate if the previous round met the cooperation threshold, and defects
    in the final round. If a previous round did not meet the threshold, it defects in all
    subsequent rounds except the last.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.has_defected_before = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.r - 1:
            return Action.D
        elif self.has_defected_before:
            return Action.D
        else:
            prev_round = state.round_number - 1
            my_action = history.my_actions[prev_round]
            opponents = history.opponent_actions[prev_round, :]
            cooperators = my_action + sum(opponents)
            if cooperators >= self.m:
                return Action.C
            else:
                self.has_defected_before = True
                return Action.D

class Strategy_EXPLOITATIVE_61(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma game. 
    The player starts by cooperating, then adapts based on the probabilities 
    of meeting the cooperation threshold when cooperating or defecting.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.count_coop = 0
        self.count_coop_met = 0
        self.count_defect = 0
        self.count_defect_met = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        for t in range(state.round_number):
            my_action = history.my_actions[t]
            opponent_actions_t = history.opponent_actions[t]
            sum_opponent = np.sum(opponent_actions_t)
            my_coop = 1 if my_action else 0
            total_coop = my_coop + sum_opponent
            threshold_met = total_coop >= self.game_description.m
            if my_action:
                self.count_coop += 1
                if threshold_met:
                    self.count_coop_met += 1
            else:
                self.count_defect += 1
                if threshold_met:
                    self.count_defect_met += 1
        p_coop = self.count_coop_met / self.count_coop if self.count_coop > 0 else 0.0
        p_defect = self.count_defect_met / self.count_defect if self.count_defect > 0 else 0.0
        E_coop = p_coop * self.game_description.k
        E_defect = p_defect * (1 + self.game_description.k) + (1 - p_defect) * 1
        if E_coop >= E_defect:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_62(BaseStrategy):
    """
    This strategy starts with cooperation and adapts based on others' past actions.
    It decides to cooperate if the summed cooperation rates of others, plus itself, meets the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        n_players = self.game_description.n_players
        m = self.game_description.m
        t = state.round_number
        sum_rates = 0.0
        for j in range(n_players - 1):
            actions = history.opponent_actions[0:t, j]
            sum_coop = np.sum(actions)
            rate = sum_coop / t
            sum_rates += rate
        if sum_rates + 1 >= m:
            return Action.C
        else:
            return Action.D

@dataclass
class Strategy_EXPLOITATIVE_63(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma that Cooperates initially, 
    continues if enough players Cooperated in the previous round, Defects otherwise, 
    but resets to Cooperate after two consecutive Defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.count_defects = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.count_defects >= 2:
            action = Action.C
            self.count_defects = 0
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opponents_prev_actions = history.opponent_actions[prev_round, :]
            total_coop = my_prev_action + np.sum(opponents_prev_actions)
            if total_coop >= self.game_description.m:
                action = Action.C
                self.count_defects = 0
            else:
                action = Action.D
                self.count_defects += 1
        return action

class Strategy_EXPLOITATIVE_64(BaseStrategy):
    """
    A deterministic strategy for the Collective Risk Dilemma game where the player 
    cooperates initially and then decides whether to continue cooperating or defect 
    based on the number of cooperators in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_prev_actions = history.opponent_actions[prev_round, :]
        total_coop = my_prev_action + np.sum(opponent_prev_actions)
        if total_coop < self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_65(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that balances cooperation and exploitation based on past success.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        m = self.game_description.m
        n_rounds = self.game_description.n_rounds
        successful_rounds = 0
        for t in range(state.round_number):
            my_action = history.my_actions[t]
            opponent_actions = history.opponent_actions[t, :]
            sum_opponents = np.sum(opponent_actions)
            total_c = my_action + sum_opponents
            if total_c >= m:
                successful_rounds += 1
        s = successful_rounds / state.round_number
        is_last_round = state.round_number == n_rounds - 1
        if is_last_round:
            if s > 0.5:
                return Action.D
            else:
                return Action.C
        elif s > 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_66(BaseStrategy):

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        n_rounds = self.game_description.n_rounds
        m = self.game_description.m
        if t == 0:
            return Action.C
        elif t == n_rounds - 1:
            return Action.D
        else:
            count = 0
            start = max(0, t - 3)
            end = t - 1
            n_rounds_considered = end - start + 1
            for s in range(start, end + 1):
                self_action = history.my_actions[s]
                opp_actions = history.opponent_actions[s]
                total_coop = self_action + np.sum(opp_actions)
                if total_coop >= m:
                    count += 1
            if n_rounds_considered == 0:
                proportion = 0.0
            else:
                proportion = count / n_rounds_considered
            if proportion > 0.5:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_67(BaseStrategy):
    """
    Adaptive Exploitation Strategy: Cooperates initially and adjusts based on past rounds.
    Cooperates if less than half of previous rounds met the cooperation threshold, defects otherwise.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number
        s_count = 0
        for s in range(t):
            my_c = history.my_actions[s]
            my_c_int = 1 if my_c else 0
            opponent_c = np.sum(history.opponent_actions[s, :])
            total_c = my_c_int + opponent_c
            if total_c >= self.game_description.m:
                s_count += 1
        half_prev = (t - 1) / 2.0
        if s_count > half_prev:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_68(BaseStrategy):
    """
    Adaptive Exploitation Strategy based on past cooperation success.
    Cooperates if at least half of the previous rounds met the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            m = self.game_description.m
            t = state.round_number
            success_count = 0
            for r in range(t):
                my_action = history.my_actions[r]
                opponent_actions = history.opponent_actions[r, :]
                total_coop = int(my_action) + np.sum(opponent_actions)
                if total_coop >= m:
                    success_count += 1
            success_rate = success_count / t
            if success_rate >= 0.5:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_69(BaseStrategy):
    """
    A strategy that adaptively cooperates based on the historical success of meeting the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            t = state.round_number
            m = self.game_description.m
            successful_rounds = 0
            for r in range(t):
                my_coop = history.my_actions[r]
                opponent_coop = np.sum(history.opponent_actions[r, :])
                total_coop = my_coop + opponent_coop
                if total_coop >= m:
                    successful_rounds += 1
            frequency = successful_rounds / t
            if frequency > 0.5:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_70(BaseStrategy):
    """
    A strategy designed for the Collective Risk Dilemma, balancing cooperation and exploitation.
    Cooperates initially to encourage others, then adapts based on past behavior, and makes strategic decisions in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.initial_phase_rounds = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            total = 0
            for r in range(state.round_number):
                count = sum(history.opponent_actions[r, :])
                total += count
            average = total / state.round_number
            threshold = self.game_description.m - 1
            if average >= threshold:
                return Action.D
            else:
                return Action.C
        elif state.round_number < self.initial_phase_rounds:
            return Action.C
        else:
            total = 0
            for r in range(state.round_number):
                count = sum(history.opponent_actions[r, :])
                total += count
            average = total / state.round_number
            threshold = self.game_description.m - 1
            if average >= threshold:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_71(BaseStrategy):
    """
    A strategy that balances cooperation with strategic defection in the final round.
    Cooperates in the first round and early rounds if enough players cooperated previously,
    then defects in the last round to maximize personal gain.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.n_rounds - 1:
            return Action.D
        else:
            prev_round = state.round_number - 1
            opponent_actions_prev = history.opponent_actions[prev_round]
            opponent_coop = sum(opponent_actions_prev)
            my_coop = history.my_actions[prev_round]
            total_coops = opponent_coop + my_coop
            if total_coops >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_72(BaseStrategy):
    """
    Adaptive Exploitation Based on Historical Performance (AEBHP)
    
    This strategy begins with an initial phase of unconditional cooperation to 
    gather information. After the initial phase, it analyzing recent rounds to 
    decide whether to cooperate or defect based on the proportion of rounds 
    meeting the cooperation threshold. In the endgame rounds, it evaluates the 
    overall cooperation rate from non-initial rounds to decide actions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.initial_coop_rounds = 3
        self.recent_rounds = 5
        self.coop_threshold = 0.7
        self.endgame_rounds = 3
        self.endgame_coop_threshold = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number < self.initial_coop_rounds:
            return Action.C
        near_end = state.round_number >= self.game_description.n_rounds - self.endgame_rounds
        if near_end:
            start_analysis = self.initial_coop_rounds
            end_analysis = state.round_number
            if start_analysis >= end_analysis:
                return Action.D
            coop_count = 0
            for i in range(start_analysis, end_analysis):
                my_action = history.my_actions[i]
                opponents = history.opponent_actions[i]
                my_c = 1 if my_action else 0
                other_c = np.sum(opponents)
                total_c = my_c + other_c
                if total_c >= self.game_description.m:
                    coop_count += 1
            n_rounds = end_analysis - start_analysis
            if n_rounds == 0:
                return Action.D
            overall_rate = coop_count / n_rounds
            if overall_rate >= self.endgame_coop_threshold:
                return Action.C
            else:
                return Action.D
        else:
            start_round = max(0, state.round_number - self.recent_rounds)
            coop_count = 0
            for i in range(start_round, state.round_number):
                my_action = history.my_actions[i]
                opponents = history.opponent_actions[i]
                my_c = 1 if my_action else 0
                other_c = np.sum(opponents)
                total_c = my_c + other_c
                if total_c >= self.game_description.m:
                    coop_count += 1
            n_rounds = state.round_number - start_round
            if n_rounds == 0:
                return Action.D
            recent_rate = coop_count / n_rounds
            if recent_rate >= self.coop_threshold:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_73(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma, balancing cooperation and strategic defection.
    The strategy initially cooperates, then adapts based on previous outcomes, trends, and endgame conditions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history) -> Action:
        t = state.round_number
        if t == 0:
            return Action.C
        coops_per_round = []
        for s in range(t):
            my_coop = history.my_actions[s]
            opp_coop = sum(history.opponent_actions[s, :])
            total_coop = my_coop + opp_coop
            coops_per_round.append(total_coop)
        prev_coops = coops_per_round[-1]
        recent_coops = coops_per_round[-3:]
        count_below_m = sum((1 for coop in recent_coops if coop < self.m))
        if count_below_m >= 2:
            return Action.D
        if t >= self.r - 2:
            opp_actions = history.opponent_actions[t - 1, :]
            n_opponents = len(opp_actions)
            sum_coop = sum(opp_actions)
            n_defectors = n_opponents - sum_coop
            if n_defectors * 2 >= n_opponents:
                return Action.D
        if prev_coops >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_74(BaseStrategy):
    """
    Strategy that always defects to maximize individual payoffs in the Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        return Action.D

class Strategy_EXPLOITATIVE_75(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that adapts based on opponents' historical cooperation rates.
    Cooperates in the first round, then decides to Defect or Cooperate by estimating if enough others will Cooperate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            n_opponents = self.game_description.n_players - 1
            coop_rates = []
            for opponent in range(n_opponents):
                actions = history.opponent_actions[:state.round_number, opponent]
                n_coop = np.sum(actions)
                rate = n_coop / state.round_number
                coop_rates.append(rate)
            expected_cooperators = sum(coop_rates)
            if expected_cooperators >= self.game_description.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_76(BaseStrategy):
    """
    Adaptive strategy for Collective Risk Dilemma. Cooperates initially, 
    defects for a limited number of rounds if cooperation is insufficient, 
    and attempts to reset cooperation. Defects in the last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defects = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            prev_round = state.round_number - 1
            my_prev = history.my_actions[prev_round]
            opponents_prev = history.opponent_actions[prev_round, :]
            total_coop = my_prev + np.sum(opponents_prev)
            if total_coop >= self.game_description.m:
                self.consecutive_defects = 0
                return Action.C
            else:
                self.consecutive_defects += 1
                if self.consecutive_defects <= 2:
                    return Action.D
                else:
                    self.consecutive_defects = 0
                    return Action.C

class Strategy_EXPLOITATIVE_77(BaseStrategy):
    """
    Exploitative cooperation strategy based on historical performance.
    Cooperates in the first round, then defects if enough players cooperated previously.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_actions_prev = history.opponent_actions[prev_round, :]
        my_coop = 1 if my_prev_action else 0
        opponent_coop = opponent_actions_prev.sum()
        total_coop = my_coop + opponent_coop
        if total_coop >= self.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_78(BaseStrategy):
    """
    Exploitative Strategy for Collective Risk Dilemma.

    This strategy begins by cooperating in the first round. In subsequent rounds,
    it cooperates if the number of cooperators in the previous round meets or exceeds m,
    the minimum required. Otherwise, it defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        else:
            prev_opponents_actions = history.opponent_actions[-1]
            sum_opponents = np.sum(prev_opponents_actions)
            sum_self = int(history.my_actions[-1])
            total_cooperators = sum_opponents + sum_self
            if total_cooperators >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_79(BaseStrategy):
    """
    A strategy that begins by cooperating and then adapts based on the previous round's cooperation level.
    Cooperates again if the number of cooperators in the previous round met or exceeded the threshold m.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev_action = history.my_actions[previous_round]
        opponents_prev_actions = history.opponent_actions[previous_round]
        sum_opponent_actions = np.sum(opponents_prev_actions)
        total_cooperators = my_prev_action + sum_opponent_actions
        if total_cooperators >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_80(BaseStrategy):
    """
    A strategy that enforces cooperation by cooperating if the previous round met the minimum cooperators threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            my_last = history.my_actions[-1]
            opponents_last = history.opponent_actions[-1, :]
            sum_coop = int(my_last) + sum(opponents_last)
            if sum_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_81(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that maximizes individual gain while supporting cooperation.
    Cooperates initially and adjusts based on previous round's cooperation level.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev = history.my_actions[prev_round]
        opponents_prev = history.opponent_actions[prev_round]
        c_prev = my_prev + np.sum(opponents_prev)
        m = self.game_description.m
        if c_prev < m:
            return Action.C
        elif c_prev >= m + 1:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_82(BaseStrategy):
    """
    A strategy that balances cooperation and exploitation by adapting based on past outcomes.
    Cooperates with 50% probability in the first 5 rounds, then cooperates if the previous round met
    the cooperation threshold, and defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == self.n_rounds - 1:
            return Action.D
        if state.round_number < 5:
            if random.random() < 0.5:
                return Action.C
            else:
                return Action.D
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opp_prev_actions = history.opponent_actions[prev_round]
            sum_op = np.sum(opp_prev_actions)
            total_c_prev = sum_op + (1 if my_prev_action else 0)
            if total_c_prev >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_83(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma game. 
    Cooperates in the first round and continues to cooperate if at least m players 
    cooperated in the previous round; otherwise, it defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_prev_actions = history.opponent_actions[prev_round]
        total_coop = my_prev_action + sum(opponents_prev_actions)
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_84(BaseStrategy):
    """
    Adaptive Exploitation strategy for the Collective Risk Dilemma.
    Cooperates initially, then adapts based on others' cooperation trends and thresholds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.others_have_met_threshold = False

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        current_round = state.round_number
        r = self.game_description.n_rounds
        m = self.game_description.m
        if current_round == 0:
            return Action.C
        action = None
        if current_round == r - 1:
            if self.others_have_met_threshold:
                action = Action.D
            elif current_round - 1 >= 0:
                prev_opp_actions = history.opponent_actions[current_round - 1, :]
                prev_opp_coop = sum(prev_opp_actions)
                action = Action.D if prev_opp_coop >= m else Action.C
            else:
                action = Action.C
        else:
            prev_round = current_round - 1
            prev_opp_actions = history.opponent_actions[prev_round, :]
            prev_opp_coop = sum(prev_opp_actions)
            if prev_opp_coop >= m:
                action = Action.D
            else:
                prev_prev_round = current_round - 2
                trend_increasing = False
                if prev_prev_round >= 0:
                    prev_prev_opp_actions = history.opponent_actions[prev_prev_round, :]
                    prev_prev_opp_coop = sum(prev_prev_opp_actions)
                    trend_increasing = prev_opp_coop > prev_prev_opp_coop
                if trend_increasing:
                    action = Action.D
                else:
                    action = Action.C
        if current_round > 0 and history is not None and (history.opponent_actions is not None):
            self.others_have_met_threshold = self.others_have_met_threshold or any((sum(history.opponent_actions[t, :]) >= m for t in range(current_round) if t < len(history.opponent_actions)))
        return action

class Strategy_EXPLOITATIVE_85(BaseStrategy):
    """
    Adaptive Cooperation with Exploitation (ACE) strategy for the Collective Risk Dilemma.

    This strategy begins by cooperating in the first three rounds to encourage cooperation.
    Subsequently, it calculates the average number of cooperators and defects if the average
    is sufficiently high. In the final round, it defects only if it won't drop the number of
    cooperators below the required threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number + 1
        current_round = state.round_number
        if t <= 3:
            return Action.C
        elif current_round + 1 == self.n_rounds:
            opp_coop_last = np.sum(history.opponent_actions[-1, :])
            if opp_coop_last >= self.m:
                return Action.D
            else:
                return Action.C
        else:
            sum_me = np.sum(history.my_actions[:current_round])
            sum_opp = np.sum(history.opponent_actions[:current_round, :])
            total_coop = sum_me + sum_opp
            avg_coop = total_coop / current_round
            threshold = self.m + 1
            if avg_coop >= threshold:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_86(BaseStrategy):
    """
    Adaptive cooperation strategy based on historical cooperation rates.
    Cooperates initially, then decides based on past success rate with exploration.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.p = 0.5
        self.epsilon = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        success_count = 0
        for past_round in range(state.round_number):
            opp_actions = history.opponent_actions[past_round]
            opp_coop = np.sum(opp_actions)
            my_coop = 1 if history.my_actions[past_round] else 0
            total_coop = opp_coop + my_coop
            if total_coop >= self.m:
                success_count += 1
        ratio = success_count / state.round_number
        if random.random() < self.epsilon:
            return Action.C
        if ratio >= self.p:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_87(BaseStrategy):
    """
    An exploitative strategy for the Collective Risk Dilemma. It starts by cooperating, 
    then adapts based on previous rounds' cooperation levels, and defects in the last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.n_rounds - 1:
            return Action.D
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opponents_prev_actions = history.opponent_actions[prev_round, :]
            total_coop = (1 if my_prev_action else 0) + sum(opponents_prev_actions)
            if total_coop >= self.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_88(BaseStrategy):
    """
    An adaptive strategy that balances cooperation and exploitation based on past outcomes.
    Cooperates initially, continues if successful, punishes temporarily if cooperation fails, 
    and resets to avoid permanent defection cycles.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.success_counter = 0
        self.punishment_counter = 0
        self.max_punishment_rounds = 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        my_last_action = history.my_actions[last_round]
        opponents_last_actions = history.opponent_actions[last_round]
        total_C = my_last_action + np.sum(opponents_last_actions)
        m = self.game_description.m
        if total_C >= m:
            self.success_counter += 1
            self.punishment_counter = 0
        else:
            self.success_counter = 0
            self.punishment_counter += 1
        if self.success_counter > 0:
            return Action.C
        elif self.punishment_counter < self.max_punishment_rounds:
            return Action.D
        else:
            self.punishment_counter = 0
            return Action.C

class Strategy_EXPLOITATIVE_89(BaseStrategy):
    """
    A strategy that initially Cooperates and adapts based on the success of previous rounds.
    It Cooperates if the majority of past rounds met the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        m = self.game_description.m
        count = 0
        for round in range(state.round_number):
            my_action = history.my_actions[round]
            opponent_actions = history.opponent_actions[round]
            total_coop = int(my_action) + np.sum(opponent_actions)
            if total_coop >= m:
                count += 1
        if count > state.round_number / 2:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_90(BaseStrategy):
    """
    Adaptive Exploitation Strategy for Collective Risk Dilemma:
    Cooperates initially and adapts based on recent cooperation rates.
    Defects when exploitation is beneficial or when cooperation is insufficient.
    Implements punishment by temporarily defecting to encourage cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.punishment_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_actions = history.my_actions
        opponent_actions = history.opponent_actions
        coop_counts = []
        for round in range(len(my_actions)):
            opps_c = np.sum(opponent_actions[round])
            my_c = my_actions[round]
            total = opps_c + (1 if my_c else 0)
            coop_counts.append(total)
        recent_coop = coop_counts[-3:]
        avg_coop = sum(recent_coop) / len(recent_coop) if recent_coop else 0.0
        if avg_coop >= self.m:
            return Action.C
        last_round = len(my_actions) - 1
        my_last_action = my_actions[last_round]
        opponent_last = np.sum(opponent_actions[last_round])
        if my_last_action:
            sum_total_last = opponent_last + 1
            if sum_total_last >= self.m:
                if opponent_last >= self.m:
                    return Action.D
                else:
                    return Action.C
            else:
                return Action.D
        elif opponent_last >= self.m:
            return Action.D
        elif self.punishment_remaining > 0:
            self.punishment_remaining -= 1
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_91(BaseStrategy):
    """
    A strategy that leverages reciprocity to maintain cooperation in the Collective Risk Dilemma.
    Cooperates if the number of cooperators in the previous round meets or exceeds the threshold m.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_coop_prev = history.my_actions[-1]
        opponent_coops_prev = np.sum(history.opponent_actions[-1, :])
        total_coop_prev = my_coop_prev + opponent_coops_prev
        if total_coop_prev >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_92(BaseStrategy):
    """
    Adaptive Cooperation Strategy for Collective Risk Dilemma.
    Cooperates initially, then adapt based on the ratio of successful rounds and end-game assessment.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            my_actions = history.my_actions
            n_prior_rounds = len(my_actions)
            total_c = 0.0
            for s in range(n_prior_rounds):
                c_me = 1 if my_actions[s] else 0
                c_others = np.sum(history.opponent_actions[s, :])
                total_c += c_me + c_others
            average_c = total_c / n_prior_rounds
            m = self.game_description.m
            if average_c >= m - 1:
                return Action.C
            else:
                return Action.D
        else:
            my_actions = history.my_actions
            n_prior_rounds = len(my_actions)
            count = 0
            m = self.game_description.m
            for s in range(n_prior_rounds):
                c_me = 1 if my_actions[s] else 0
                c_others = np.sum(history.opponent_actions[s, :])
                total_c = c_me + c_others
                if total_c >= m:
                    count += 1
            ratio = count / n_prior_rounds
            if ratio > 0.5:
                return Action.C
            else:
                prev_action = my_actions[-1]
                if prev_action:
                    return Action.D
                else:
                    return Action.C

class Strategy_EXPLOITATIVE_93(BaseStrategy):
    """
    Adaptive Cooperation Based on Previous Round Performance
    Cooperates initially, then adapts based on previous round's cooperation level.
    If previous round had enough cooperators (>=m), cooperate; else defect.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_coop = history.my_actions[prev_round]
            opponent_coops = history.opponent_actions[prev_round].sum()
            total_coops = my_coop + opponent_coops
            if total_coops >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_94(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that balances cooperation and defection to maximize personal payoff.
    It cooperates initially, then adapts based on the previous round's cooperation level, defecting if enough cooperated,
    and defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opponent_prev_actions = history.opponent_actions[prev_round]
            total_coops = my_prev_action + opponent_prev_actions.sum()
            if total_coops >= self.game_description.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_95(BaseStrategy):
    """
    Adaptive Cooperation Based on Historical Success (ACBHS)
    
    This strategy starts by cooperating in the first round. In subsequent rounds, it calculates a weighted success rate
    of previous rounds, giving more weight to recent rounds. If the success rate exceeds a threshold, it cooperates;
    otherwise, it defects. After several consecutive defections, it tests cooperation again.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.coop_threshold = 0.5
        self.defects_since_last_C = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            action = Action.C
        else:
            if self.defects_since_last_C >= 3:
                action = Action.C
            else:
                s = state.round_number
                alpha = 0.9
                total_weight = 0.0
                total_success_weight = 0.0
                for j in range(s):
                    my_c = history.my_actions[j]
                    opponents = history.opponent_actions[j]
                    n_coop = int(my_c) + int(opponents.sum())
                    success = 1 if n_coop >= self.game_description.m else 0
                    if j < s:
                        t = s - 1 - j
                        weight = alpha ** t
                        total_weight += weight
                        total_success_weight += success * weight
                if total_weight > 0:
                    success_rate = total_success_weight / total_weight
                else:
                    success_rate = 0.0
                if success_rate > self.coop_threshold:
                    action = Action.C
                else:
                    action = Action.D
            if action == Action.C:
                self.defects_since_last_C = 0
            else:
                self.defects_since_last_C += 1
        return action

class Strategy_EXPLOITATIVE_96(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that balances cooperation and probabilistic defection.
    It initiates with cooperation, continues if the threshold is met, tests others with occasional cooperation
    when the threshold isn't met, and decides the last round based on majority cooperation in previous rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.p = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            count_met = 0
            for r in range(state.round_number):
                my_prev = history.my_actions[r]
                opp_prev = history.opponent_actions[r, :]
                total_coop = my_prev + opp_prev.sum()
                if total_coop >= self.game_description.m:
                    count_met += 1
            if count_met > state.round_number / 2:
                return Action.C
            else:
                return Action.D
        else:
            prev_round = state.round_number - 1
            my_prev = history.my_actions[prev_round]
            opp_prev = history.opponent_actions[prev_round, :]
            total_coop_prev = my_prev + opp_prev.sum()
            if total_coop_prev >= self.game_description.m:
                return Action.C
            elif random.random() < self.p:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_97(BaseStrategy):
    """
    Adaptive Exploitation Based on Historical Cooperation strategy.
    Cooperate in the first round, then adapt based on the estimated cooperation rates of all players.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        t = current_round
        n_players = self.game_description.n_players
        m = self.game_description.m
        sum_rates = 0.0
        for j in range(n_players):
            if j == 0:
                actions = history.my_actions[:t]
            else:
                actions = history.opponent_actions[:t, j - 1]
            rate = np.mean(actions)
            sum_rates += rate
        if sum_rates >= m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_98(BaseStrategy):
    """
    Adaptive Cooperate-Punish (ACP) Strategy for Collective Risk Dilemma.

    This strategy starts by cooperating to encourage initial group cooperation. In subsequent rounds, 
    it monitors the number of cooperators. If cooperation meets the threshold, it continues to 
    cooperate. If not, it defects for one round as a punishment signal, then resumes cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.coop_threshold = game_description.m
        self.just_defected = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_my_action = history.my_actions[-1]
        prev_opponents = history.opponent_actions[-1, :]
        prev_coop = prev_my_action + prev_opponents.sum()
        if prev_coop >= self.coop_threshold:
            self.just_defected = False
            return Action.C
        elif not self.just_defected:
            self.just_defected = True
            return Action.D
        else:
            self.just_defected = False
            return Action.C

class Strategy_EXPLOITATIVE_99(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that balances cooperation and probabilistic defection.
    Cooperates initially and adapts based on the number of cooperators in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_actions_prev = history.opponent_actions[prev_round, :]
        count_prev_C = (1 if my_prev_action else 0) + np.sum(opponent_actions_prev)
        if count_prev_C >= self.m:
            return Action.C
        elif random.random() < 0.2:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_100(BaseStrategy):
    """
    Adaptive Cooperative Enforcement (ACE) Strategy.
    
    The strategy aims to balance cooperation and punishment. It starts by cooperating,
    continues if the previous round met the cooperation threshold, defects if not,
    and adjusts based on the average cooperation over recent rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_coop_prev = 1 if history.my_actions[prev_round] else 0
        opp_coop_prev = sum(history.opponent_actions[prev_round, :])
        total_coop_prev = my_coop_prev + opp_coop_prev
        m = self.game_description.m
        n = self.game_description.n_players
        if total_coop_prev >= m:
            return Action.C
        else:
            max_round = prev_round
            start_round = max(0, max_round - 2)
            coop_counts = []
            for r in range(start_round, max_round + 1):
                my = 1 if history.my_actions[r] else 0
                opp = sum(history.opponent_actions[r, :])
                total = my + opp
                coop_counts.append(total)
            if not coop_counts:
                average_coop = 0.0
            else:
                average_coop = sum(coop_counts) / len(coop_counts)
            if average_coop >= m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_101(BaseStrategy):
    """
    A strategy that adapts based on the number of cooperators in previous rounds.
    Cooperates initially, then continues if the threshold is met, otherwise defects.
    In the last round, cooperates if the majority of previous rounds met the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number
        m = self.game_description.m
        n_rounds = self.game_description.n_rounds
        prev_round = t - 1
        my_prev = history.my_actions[prev_round]
        others_prev = history.opponent_actions[prev_round]
        total_coop_prev = my_prev + others_prev.sum()
        if total_coop_prev >= m:
            return Action.C
        elif t == n_rounds - 1:
            successful_coop = 0
            for round_idx in range(t):
                my_act = history.my_actions[round_idx]
                others_act = history.opponent_actions[round_idx]
                total = my_act + others_act.sum()
                if total >= m:
                    successful_coop += 1
            if successful_coop > t / 2:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_102(BaseStrategy):
    """
    A strategy that encourages cooperation based on the outcomes of previous rounds.
    Cooperates in the first round, and in subsequent rounds if at least m players cooperated previously.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_my_action = history.my_actions[-1]
        prev_opp_actions = history.opponent_actions[-1]
        total_coop = sum(prev_opp_actions) + (1 if prev_my_action else 0)
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_103(BaseStrategy):
    """
    An adaptive strategy that cooperates if the previous round met the cooperation threshold, 
    otherwise defects to punish. Starts by cooperating.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev_action = history.my_actions[previous_round]
        my_coop = 1 if my_prev_action else 0
        opp_actions = history.opponent_actions[previous_round, :]
        opp_coop = np.sum(opp_actions)
        total_coops = my_coop + opp_coop
        if total_coops >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_104(BaseStrategy):
    """
    A strategy that balances cooperation and defection by evaluating the impact of previous actions.
    Cooperates initially, then defects when it's safe to do so without losing benefits, especially in final rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        total_rounds = self.game_description.n_rounds
        threshold = total_rounds * 0.95
        if state.round_number + 1 > threshold:
            return Action.D
        t_prev = state.round_number - 1
        my_prev_action = history.my_actions[t_prev]
        opp_prev_actions = history.opponent_actions[t_prev]
        n_coop_prev = sum(opp_prev_actions) + (1 if my_prev_action else 0)
        c_i = 1 if my_prev_action else 0
        if n_coop_prev - c_i >= self.game_description.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_105(BaseStrategy):
    """
    Exploitative Strategy for Collective Risk Dilemma based on opponents' cooperation history.
    Cooperates in the first round, then decides based on expected cooperation rates of others.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n_players = game_description.n_players
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number
        sum_expected = 0.0
        for opponent in range(self.n_players - 1):
            count_coop = np.sum(history.opponent_actions[0:t, opponent])
            rate = count_coop / t
            sum_expected += rate
        total_expected = sum_expected + 1.0
        if total_expected >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_106(BaseStrategy):
    """
    A strategy that begins by cooperating and then adapts based on the number of cooperators in the previous round.
    Cooperates if at least m players (including self) cooperated in the previous round; otherwise, defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_last_action = history.my_actions[-1]
        opponent_last_actions = history.opponent_actions[-1]
        sum_opponent = np.sum(opponent_last_actions)
        total_coop = my_last_action + sum_opponent
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_107(BaseStrategy):
    """
    This strategy cooperates in the first round and then uses the cooperation rates of other players to decide whether to defect or cooperate in subsequent rounds.
    The AI defects if the expected number of cooperators from other players meets or exceeds the threshold `m`, otherwise it cooperates.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number
        n_players = self.game_description.n_players
        m = self.game_description.m
        opponent_actions = history.opponent_actions
        sum_other_exp = 0.0
        for opp in range(n_players - 1):
            coop_count = np.sum(opponent_actions[:, opp])
            coop_rate = coop_count / t
            sum_other_exp += coop_rate
        if sum_other_exp >= m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_108(BaseStrategy):
    """
    Exploitative Strategy for Collective Risk Dilemma.
    Cooperates initially and defects if average cooperation meets threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        total_coops = 0
        for t in range(state.round_number):
            my_action = history.my_actions[t]
            op_coops = np.sum(history.opponent_actions[t, :])
            total = int(my_action) + op_coops
            total_coops += total
        average = total_coops / state.round_number
        if average >= self.game_description.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_109(BaseStrategy):
    """
    Exploitative Strategy for Collective Risk Dilemma.
    
    Initially cooperates to set a positive tone. Continues cooperating if previous rounds 
    met the minimum required. Defects if not, unless there's an increasing trend towards 
    the required cooperation. Cooperates in the last round only if all prior rounds met 
    the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        total_rounds = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == total_rounds - 1:
            all_prior_met = True
            for prev_round in range(current_round):
                opponent_actions_prev = history.opponent_actions[prev_round]
                my_prev_action = history.my_actions[prev_round]
                c_prev = sum(opponent_actions_prev) + (1 if my_prev_action else 0)
                if c_prev < self.game_description.m:
                    all_prior_met = False
                    break
            return Action.C if all_prior_met else Action.D
        else:
            prev_round = current_round - 1
            opponent_prev = history.opponent_actions[prev_round]
            my_prev = history.my_actions[prev_round]
            c_prev = sum(opponent_prev) + (1 if my_prev else 0)
            m = self.game_description.m
            if c_prev >= m:
                return Action.C
            else:
                if current_round >= 2:
                    pre_prev_round = prev_round - 1
                    opponent_pre_prev = history.opponent_actions[pre_prev_round]
                    my_pre_prev = history.my_actions[pre_prev_round]
                    c_prev_prev = sum(opponent_pre_prev) + (1 if my_pre_prev else 0)
                    if c_prev > c_prev_prev:
                        return Action.C
                return Action.D

class Strategy_EXPLOITATIVE_110(BaseStrategy):
    """
    Exploitative Strategy for Collective Risk Dilemma.
    Cooperates in initial rounds (first 3) and then decides based on opponents' cooperation rates.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        n = self.game_description.n_players
        m = self.game_description.m
        if t == 0:
            return Action.C
        if t <= 2:
            return Action.C
        expected_coops = 0
        n_opponents = n - 1
        for j in range(n_opponents):
            coop_count = history.opponent_actions[:t, j].sum()
            rate = coop_count / t
            if rate >= 0.5:
                expected_coops += 1
        if expected_coops >= m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_111(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that adapts based on previous rounds' outcomes.
    It starts by cooperating, exploits when possible, and makes informed decisions in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            count = 0
            total_prev_rounds = state.round_number
            for t in range(total_prev_rounds):
                my_prev = history.my_actions[t]
                opp_prev = history.opponent_actions[t, :]
                coop_count = my_prev + sum(opp_prev)
                if coop_count >= self.game_description.m:
                    count += 1
            proportion = count / total_prev_rounds
            return Action.D if proportion >= 0.5 else Action.C
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opp_prev_actions = history.opponent_actions[prev_round, :]
            coop_count = my_prev_action + sum(opp_prev_actions)
            return Action.D if coop_count >= self.game_description.m else Action.C

class Strategy_EXPLOITATIVE_112(BaseStrategy):
    """
    Adaptive Exploitation Based on Recent Cooperation and Payoff Trends.
    
    This strategy initially cooperates to encourage group participation, then adapts based on previous cooperation levels and individual payoff averages. It defects in the final round to maximize personal gain.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.n_rounds - 1:
            return Action.D
        previous_round = state.round_number - 1
        my_prev_action = history.my_actions[previous_round]
        opponent_prev_actions = history.opponent_actions[previous_round, :]
        c_prev = my_prev_action + np.sum(opponent_prev_actions)
        my_actions_subset = history.my_actions[:previous_round + 1]
        my_payoffs_subset = history.my_payoffs[:previous_round + 1]
        mask_C = my_actions_subset == True
        mask_D = ~mask_C
        sum_C = np.sum(my_payoffs_subset[mask_C])
        n_C = np.sum(mask_C)
        avg_C = sum_C / n_C if n_C != 0 else 0.0
        sum_D = np.sum(my_payoffs_subset[mask_D])
        n_D = np.sum(mask_D)
        avg_D = sum_D / n_D if n_D != 0 else 0.0
        if c_prev >= self.m and avg_C > avg_D:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_113(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game where the AI adapts based on the average cooperation of all players in previous rounds.
    The AI starts by Cooperating and then switches to Defect if the average cooperation exceeds the required threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        total_coop = 0
        for round in range(state.round_number):
            ai_coop = 1 if history.my_actions[round] else 0
            opponent_coop = np.sum(history.opponent_actions[round])
            total_coop += ai_coop + opponent_coop
        avg_coop = total_coop / state.round_number
        m = self.game_description.m
        if avg_coop > m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_114(BaseStrategy):
    """
    A strategy that begins by cooperating and then adapts based on the number of cooperators in the previous round.
    Cooperates if the previous round's cooperators met the threshold m; otherwise, defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_my_action = history.my_actions[state.round_number - 1]
            opponent_prev_round = history.opponent_actions[state.round_number - 1, :]
            my_integer = 1 if prev_my_action else 0
            opponent_integer = np.sum(opponent_prev_round)
            total_cooperators = my_integer + opponent_integer
            if total_cooperators >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_115(BaseStrategy):
    """
    Exploitative Threshold Cooperative strategy for Collective Risk Dilemma.
    Cooperates initially, then adapts based on previous round's cooperation level,
    and defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            my_prev = history.my_actions[state.round_number - 1]
            others_prev = history.opponent_actions[state.round_number - 1, :]
            sum_others = np.sum(others_prev)
            total = my_prev + sum_others
            if total >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_116(BaseStrategy):
    """
    Forgiving Threshold-based Cooperation strategy. Cooperates initially, continues 
    if cooperation threshold is met, defects if not, and resets cooperation after 
    two defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defects = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        opp_prev_actions = history.opponent_actions[previous_round, :]
        my_prev_action = history.my_actions[previous_round]
        prev_coop = sum(opp_prev_actions) + my_prev_action
        if prev_coop >= self.game_description.m:
            self.consecutive_defects = 0
            return Action.C
        elif self.consecutive_defects < 2:
            self.consecutive_defects += 1
            return Action.D
        else:
            self.consecutive_defects = 0
            return Action.C

class Strategy_EXPLOITATIVE_117(BaseStrategy):
    """
    Implements a strategy that cooperates if fewer than m players cooperated in the previous round,
    otherwise defects based on the collective risk dilemma parameters.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opp_prev_actions = history.opponent_actions[prev_round, :]
        opp_count = np.sum(opp_prev_actions)
        total_coops = my_prev_action + opp_count
        if total_coops >= self.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_118(BaseStrategy):
    """Adaptive Threshold Cooperator (ATC)Strategy: Cooperates initially, adapt based on historical success rate."""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        n_rounds = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == n_rounds - 1:
            successful = 0
            for round_num in range(current_round):
                my_action = history.my_actions[round_num]
                opponent_actions = history.opponent_actions[round_num, :]
                num_coop = my_action + np.sum(opponent_actions)
                if num_coop >= self.game_description.m:
                    successful += 1
            ratio = successful / current_round if current_round != 0 else 0
            return Action.C if ratio >= 0.5 else Action.D
        else:
            successful = 0
            for round_num in range(current_round):
                my_action = history.my_actions[round_num]
                opponent_actions = history.opponent_actions[round_num, :]
                num_coop = my_action + np.sum(opponent_actions)
                if num_coop >= self.game_description.m:
                    successful += 1
            ratio = successful / current_round if current_round != 0 else 0
            return Action.C if ratio >= 0.5 else Action.D

class Strategy_EXPLOITATIVE_119(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma game, which 
    balances individual gain with collective cooperation incentives.
    Cooperates in the first round, defects in the last, and adapts 
    based on previous cooperation levels.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n_rounds = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        if t == 0:
            return Action.C
        elif t == self.n_rounds - 1:
            return Action.D
        else:
            s = t - 1
            my_prev_action = history.my_actions[s]
            opponent_prev_actions = history.opponent_actions[s, :]
            total_coop = my_prev_action + np.sum(opponent_prev_actions)
            if total_coop >= self.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_120(BaseStrategy):
    """
    An exploitative strategy for the Collective Risk Dilemma based on historical success rates and recent outcomes.
    Cooperates initially and adapts based on whether the group meets the cooperation threshold, with special handling for edge cases.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        success_count = 0
        for rn in range(state.round_number):
            my_action = history.my_actions[rn]
            opponent_actions = history.opponent_actions[rn]
            n_coop = sum(opponent_actions) + (1 if my_action else 0)
            if n_coop >= self.game_description.m:
                success_count += 1
        success_rate = success_count / state.round_number
        threshold = 0.5
        if self.game_description.n_players <= 5 or self.game_description.m / self.game_description.n_players > 0.8:
            threshold = 0.3
        last_round = state.round_number - 1
        my_last_action = history.my_actions[last_round]
        opponent_actions_last = history.opponent_actions[last_round]
        n_coop_last = sum(opponent_actions_last) + (1 if my_last_action else 0)
        last_round_success = n_coop_last >= self.game_description.m
        if not last_round_success:
            return Action.D
        elif success_rate > threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_121(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma game. Players start by cooperating,
    then defect if the cooperation threshold has been met in a sufficient proportion of recent rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.s = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        met_history = []
        for t in range(state.round_number):
            my_action = history.my_actions[t]
            opponent_actions = history.opponent_actions[t]
            total_coop = int(my_action) + np.sum(opponent_actions)
            met = total_coop >= self.game_description.m
            met_history.append(met)
        window_size = self.s
        window = met_history[-window_size:]
        recent_met_count = sum(window)
        threshold = 0.7 * window_size
        if recent_met_count >= threshold:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_122(BaseStrategy):
    """
    A strategy that balances cooperation and exploitation based on past collective performance.
    Cooperates initially, then defects if more than 70% of past rounds met the threshold.
    Defects in the last round to maximize immediate payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.n_rounds - 1:
            return Action.D
        else:
            count = 0
            for t in range(state.round_number):
                my_action = history.my_actions[t]
                opp_actions = history.opponent_actions[t, :]
                opp_coops = np.sum(opp_actions)
                total_coops = my_action + opp_coops
                if total_coops >= self.m:
                    count += 1
            num_rounds = state.round_number
            proportion = count / num_rounds
            if proportion > 0.7:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_123(BaseStrategy):
    """
    Adaptive Cooperator strategy with a restart mechanism for the Collective Risk Dilemma.
    Cooperates initially, adapts based on recent cooperation levels, and defects in the endgame.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        n_rounds = self.game_description.n_rounds
        m = self.game_description.m
        if state.round_number >= max(0, n_rounds - 3):
            return Action.D
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_actions_prev = history.opponent_actions[prev_round]
        total_prev_coops = my_prev_action + np.sum(opponent_actions_prev)
        if total_prev_coops >= m:
            return Action.C
        consecutive_defects = 0
        i = prev_round
        while i >= 0:
            my_i = history.my_actions[i]
            opponents_i = history.opponent_actions[i]
            total_i = my_i + np.sum(opponents_i)
            if total_i < m:
                consecutive_defects += 1
                i -= 1
            else:
                break
        if consecutive_defects >= 3:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_124(BaseStrategy):
    """
    Adaptive Exploitation Based on Historical Cooperation Strategy.
    Cooperates initially and then defects if enough players cooperated in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        opp_coop = sum(history.opponent_actions[last_round])
        my_coop = 1 if history.my_actions[last_round] else 0
        total_coop = opp_coop + my_coop
        if total_coop >= self.game_description.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_125(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma game, starting with cooperation, 
    maintaining cooperation if the previous round met the threshold, and defecting in the last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_prev_actions = history.opponent_actions[prev_round]
        total_coop_prev = my_prev_action + sum(opponent_prev_actions)
        if total_coop_prev >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_126(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game where the player cooperates 
    if at least m players cooperated in the previous round; otherwise, defects.
    The strategy starts by cooperating in the first round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            t_prev = state.round_number - 1
            my_prev = history.my_actions[t_prev]
            opponents_prev = history.opponent_actions[t_prev, :]
            total_coop_prev = my_prev + sum(opponents_prev)
            if total_coop_prev >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_127(BaseStrategy):
    """
    Adaptive Cooperation Based on Past Success (ACPS) strategy for Collective Risk Dilemma.
    Cooperates initially and adapts based on whether the minimum cooperation threshold was met in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        my_last_action = history.my_actions[last_round]
        opponent_actions_last = history.opponent_actions[last_round]
        total_coop = int(my_last_action) + sum(opponent_actions_last)
        threshold_met = total_coop >= self.game_description.m
        if threshold_met:
            return Action.C if my_last_action else Action.D
        else:
            return Action.D if my_last_action else Action.C

class Strategy_EXPLOITATIVE_128(BaseStrategy):
    """
    Exploitative strategy for the Collective Risk Dilemma. 
    Cooperates initially, defects when m cooperators are met, and defects in the last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.game_description.n_rounds - 1:
            return Action.D
        prev_coop_count = np.sum(history.opponent_actions[current_round - 1, :])
        if prev_coop_count >= self.game_description.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_129(BaseStrategy):
    """A dynamic strategy that adapts based on previous rounds to maximize individual payoff.
    Cooperates initially and switches to defecting when it's safe, reverting if necessary.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        my_last_action = history.my_actions[last_round]
        if my_last_action:
            others_last_actions = history.opponent_actions[last_round]
            others_coop = sum(others_last_actions)
            m = self.game_description.m
            if others_coop >= m:
                return Action.D
            else:
                return Action.C
        else:
            others_last_actions = history.opponent_actions[last_round]
            others_coop = sum(others_last_actions)
            m = self.game_description.m
            if others_coop >= m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_130(BaseStrategy):
    """
    Adaptive Cooperation with Forgiveness Strategy for the Collective Risk Dilemma.
    Cooperates initially to encourage group success and adapts based on previous cooperation levels,
    defecting once and then reverting to cooperation to recover group benefits.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defect_next_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev_action = history.my_actions[previous_round]
        opponent_actions_prev = history.opponent_actions[previous_round]
        sum_opponents_coop = np.sum(opponent_actions_prev)
        total_coop_prev = sum_opponents_coop + (1 if my_prev_action else 0)
        if total_coop_prev >= self.game_description.m:
            action = Action.C
            self.defect_next_round = False
        elif self.defect_next_round:
            action = Action.C
            self.defect_next_round = False
        else:
            action = Action.D
            self.defect_next_round = True
        return action

class Strategy_EXPLOITATIVE_131(BaseStrategy):
    """
    A strategy that starts with cooperation and adapts based on the collective behavior
    of all players in the previous round. It continues to cooperate if the number of
    cooperators met or exceeded the threshold m in the previous round; otherwise, it defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_my_action = history.my_actions[-1]
        prev_opponent_actions = history.opponent_actions[-1, :]
        cooperators = int(prev_my_action) + np.sum(prev_opponent_actions)
        if cooperators >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_132(BaseStrategy):
    """
    Exploitative Strategy for Collective Risk Dilemma
    Cooperates initially, adapts based on previous cooperation levels, and defects in the last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        total_rounds = self.game_description.n_rounds
        if history is None:
            return Action.C
        if current_round == total_rounds - 1:
            return Action.D
        previous_round = current_round - 1
        my_last = history.my_actions[previous_round]
        opponent_last = history.opponent_actions[previous_round]
        total_coop_last = my_last + sum(opponent_last)
        if total_coop_last >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_133(BaseStrategy):
    """
    Adaptive Exploitation Based on Historical Cooperation Strategy.
    Cooperates initially to encourage collective benefit and adapts based on previous cooperation levels.
    Defects when enough others cooperated to meet the threshold, otherwise continues to cooperate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_rounds = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            t_prev = state.round_number - 1
            my_prev = history.my_actions[t_prev]
            opponent_prev = history.opponent_actions[t_prev]
            c_prev = my_prev + np.sum(opponent_prev)
            if c_prev >= self.game_description.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_134(BaseStrategy):
    """
    A strategy where players Cooperate if the previous round met the minimum 
    cooperators needed (m), otherwise Defect. Starts by Cooperating in the first round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            opponent_coop = sum(history.opponent_actions[prev_round, :])
            my_coop = 1 if history.my_actions[prev_round] else 0
            total_coop = opponent_coop + my_coop
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_135(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma that balances exploration and exploitation.
    Cooperates initially, defects in the last round, and decides based on recent success history otherwise.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.success_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds:
            return Action.D
        else:
            if history is not None:
                current_success_length = len(self.success_history)
                history_len = len(history.my_actions)
                for r in range(history_len):
                    if r >= current_success_length:
                        me = history.my_actions[r]
                        me_int = 1 if me else 0
                        opp = np.sum(history.opponent_actions[r, :])
                        total_coop = me_int + opp
                        success = total_coop >= self.game_description.m
                        self.success_history.append(success)
            recent_successes = self.success_history[-3:]
            sum_success = sum(recent_successes)
            num_analyzed = len(recent_successes)
            threshold = num_analyzed // 2 + 1
            if sum_success >= threshold:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_136(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that balances cooperation and defection based on previous rounds' outcomes.
    It starts by cooperating, adapts based on the previous round's cooperation level, and considers future cooperation trends in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.n_rounds - 1:
            if history is None:
                return Action.C
            total_prev_rounds = state.round_number
            p_numerator = 0
            q_numerator = 0
            for r in range(total_prev_rounds):
                sum_other = sum(history.opponent_actions[r])
                if sum_other >= self.m:
                    p_numerator += 1
                if sum_other >= self.m - 1:
                    q_numerator += 1
            p = p_numerator / total_prev_rounds
            q = q_numerator / total_prev_rounds
            val_defect = 1 + p * self.k
            val_cooperate = q * self.k
            if val_defect > val_cooperate:
                return Action.D
            else:
                return Action.C
        else:
            if history is None:
                return Action.D
            previous_round = state.round_number - 1
            sum_self_prev = history.my_actions[previous_round]
            sum_opponents_prev = sum(history.opponent_actions[previous_round])
            total_coop_prev = sum_self_prev + sum_opponents_prev
            if total_coop_prev >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_137(BaseStrategy):
    """
    Strategy that cooperates first, defects last, and follows a threshold-based cooperation in middle rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        elif round_number == self.n_rounds - 1:
            return Action.D
        else:
            prev_round = round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opponents_prev_actions = history.opponent_actions[prev_round]
            total_coop = my_prev_action + np.sum(opponents_prev_actions)
            if total_coop >= self.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_138(BaseStrategy):
    """
    Cooperate on the first round. In each subsequent round, defect if the number of other cooperators in the previous round was at least m; otherwise, cooperate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_opponent_actions = history.opponent_actions[-1]
        sum_o = np.sum(prev_opponent_actions)
        if sum_o >= self.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_139(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that starts by Cooperating, 
    then adapts based on the success of previous defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        prev_action = history.my_actions[last_round]
        if prev_action is False:
            prev_payoff = history.my_payoffs[last_round]
            if prev_payoff - 1.0 >= 1e-09:
                return Action.D
        return Action.C

class Strategy_EXPLOITATIVE_140(BaseStrategy):
    """
    A strategy designed for the Collective Risk Dilemma game. It cooperates initially, defects in the last round,
    and strategically cooperates or defects in middle rounds based on whether the player's cooperation was necessary.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            prev_round = state.round_number - 1
            num_coop_opponents = sum(history.opponent_actions[prev_round])
            if num_coop_opponents >= self.game_description.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_141(BaseStrategy):
    """
    A reactive strategy that cooperates if the previous round did not meet the cooperation threshold and defects otherwise.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_my = history.my_actions[-1]
            prev_opponents = history.opponent_actions[-1]
            n_coop_opponents = np.sum(prev_opponents)
            total_cooperators = prev_my + n_coop_opponents
            if total_cooperators >= self.game_description.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_142(BaseStrategy):
    """
    A strategy that starts with cooperation, adapts based on previous rounds' cooperation levels,
    and defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        if state.round_number == self.n_rounds - 1:
            return Action.D
        previous_round = state.round_number - 1
        my_action = history.my_actions[previous_round]
        opponents_actions = history.opponent_actions[previous_round, :]
        total_coop = (1 if my_action else 0) + int(np.sum(opponents_actions))
        if total_coop >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_143(BaseStrategy):
    """
    A strategy to maximize payoff by cooperating initially and responding to 
    previous cooperation levels, encouraging others to maintain cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_prev_action = history.my_actions[-1]
        opponent_prev_actions = history.opponent_actions[-1]
        sum_coop_prev = my_prev_action + opponent_prev_actions.sum()
        if sum_coop_prev >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_144(BaseStrategy):
    """
    Adaptive Cooperation Based on Historical Success.
    
    Cooperates initially and continues if historical success ratio is at least 50%.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number
        successful = 0
        for r in range(t):
            my_action = history.my_actions[r]
            my_coop = 1 if my_action else 0
            opponents_coop = sum(history.opponent_actions[r, :])
            total_coop = my_coop + opponents_coop
            if total_coop >= self.m:
                successful += 1
        success_ratio = successful / t
        if success_ratio >= 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_145(BaseStrategy):
    """
    A strategy that exploits collective cooperation by only cooperating when sufficient players did so in the previous round.
    Cooperates in the first round to encourage others, then adapts based on previous round's cooperation level.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev = history.my_actions[prev_round]
        opponent_prev = history.opponent_actions[prev_round, :]
        sum_prev = my_prev + np.sum(opponent_prev)
        m = self.game_description.m
        if sum_prev >= m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_146(BaseStrategy):
    """
    Always Defects, regardless of the game state or history.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        return Action.D

class Strategy_EXPLOITATIVE_147(BaseStrategy):
    """
    This strategy starts by cooperating in the first round. For subsequent rounds, 
    it evaluates the ratio of successful rounds where cooperation met the threshold. 
    It continues to cooperate if the ratio is above 0.5; otherwise, it defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            t = state.round_number
            s = 0
            for r in range(t):
                my_coop = history.my_actions[r]
                opponents_coop = np.sum(history.opponent_actions[r])
                total = my_coop + opponents_coop
                if total >= self.game_description.m:
                    s += 1
            ratio = s / t
            if ratio > 0.5:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_148(BaseStrategy):
    """An adaptive strategy for the Collective Risk Dilemma that begins with cooperation, 
    adapt based on the success of previous rounds, and punishes defection while considering future rounds."""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishing = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if self.punishing:
            self.punishing = False
            return Action.C
        if state.round_number == 0:
            return Action.C
        remaining_rounds = self.game_description.n_rounds - state.round_number
        if remaining_rounds <= 2:
            return Action.C
        last_round = state.round_number - 1
        if history is not None:
            my_prev_action = history.my_actions[last_round]
            opponent_prev_actions = history.opponent_actions[last_round, :]
            sum_coop = my_prev_action + sum(opponent_prev_actions)
        else:
            sum_coop = 0
        if sum_coop >= self.game_description.m:
            if sum_coop > self.game_description.n_players / 2:
                return Action.C
            else:
                return Action.D
        elif sum_coop == self.game_description.m - 1:
            return Action.C
        else:
            self.punishing = True
            return Action.D

class Strategy_EXPLOITATIVE_149(BaseStrategy):
    """
    A strategy that starts with cooperation and adapts based on previous round's cooperation level.
    Cooperates if the number of previous cooperators met the threshold, otherwise defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev = int(history.my_actions[prev_round])
            opponents_prev = sum(history.opponent_actions[prev_round, :])
            total_prev_coop = my_prev + opponents_prev
            if total_prev_coop >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_150(BaseStrategy):
    """
    This strategy cooperates in the first round, defects in the last round, and decides based on the number of cooperators in the previous round for intermediate rounds.
    Cooperates if adding its own cooperation would meet the threshold m; otherwise, defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            prev_round = state.round_number - 1
            prev_actions = history.opponent_actions[prev_round, :]
            x = np.sum(prev_actions)
            if x + 1 >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_151(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma game that encourages cooperation when beneficial.
    Cooperates initially and adaptively responds based on the number of cooperators in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            c_count = 1 if my_prev_action else 0
            opponent_actions_prev = history.opponent_actions[prev_round, :]
            c_count += np.sum(opponent_actions_prev)
            if c_count >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_152(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that starts with cooperation 
    and adapts based on the number of previous cooperators relative to a threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_prev_actions = history.opponent_actions[prev_round]
        n_coop = int(my_prev_action) + sum(opponent_prev_actions)
        m = self.game_description.m
        if n_coop > m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_153(BaseStrategy):
    """
    Forgiving Tit-for-Tat Strategy for Collective Risk Dilemma.
    Cooperates initially, defects if cooperation threshold isn't met,
    and forgives after a set number of defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0
        self.forgiveness_threshold = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_coop_count = sum(history.opponent_actions[-1, :])
        if prev_coop_count < self.game_description.m:
            self.consecutive_defections += 1
            if self.consecutive_defections >= self.forgiveness_threshold:
                self.consecutive_defections = 0
                return Action.C
            else:
                return Action.D
        else:
            self.consecutive_defections = 0
            return Action.C

class Strategy_EXPLOITATIVE_154(BaseStrategy):
    """
    A strategy that balances personal gain with contributions to the collective good.
    It decides to cooperate or defect based on the necessity of contribution in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_last_action = history.my_actions[-1]
        opponent_actions_last = history.opponent_actions[-1]
        total_coop_last_round = sum(opponent_actions_last) + (1 if my_last_action else 0)
        if my_last_action:
            adjusted_coop = total_coop_last_round - 1
        else:
            adjusted_coop = total_coop_last_round
        m = self.game_description.m
        if adjusted_coop >= m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_155(BaseStrategy):

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.success_history = []
        self.punishment_remaining = 0
        self.cooperation_threshold = 0.5
        self.punishment_duration = 2
        self.endgame_threshold = max(0, self.r - 3)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            current_length = len(self.success_history)
            for s in range(current_length, history.my_actions.shape[0]):
                my_action = history.my_actions[s]
                opponent_actions = history.opponent_actions[s]
                n_coop = sum(opponent_actions) + my_action
                success = n_coop >= self.m
                self.success_history.append(success)
        if self.punishment_remaining > 0:
            self.punishment_remaining -= 1
            return Action.D
        elif state.round_number >= self.endgame_threshold:
            recent_rounds = min(3, len(self.success_history))
            if recent_rounds == 0:
                return Action.C
            recent_successes = sum(self.success_history[-recent_rounds:])
            recent_avg = recent_successes / recent_rounds
            endgame_threshold = 0.5 / (1 + self.k)
            if recent_avg >= endgame_threshold:
                return Action.C
            elif self.k > 2:
                return Action.C
            else:
                return Action.D
        else:
            if not self.success_history:
                return Action.C
            success_avg = sum(self.success_history) / len(self.success_history)
            if success_avg >= self.cooperation_threshold:
                return Action.C
            else:
                self.punishment_remaining = self.punishment_duration
                return Action.D

class Strategy_EXPLOITATIVE_156(BaseStrategy):
    """
    A strategy that adapts based on historical cooperation rates, defecting when safe and cooperating otherwise.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            m = self.game_description.m
            n_rounds = self.game_description.n_rounds
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            my_prev_coop = 1 if my_prev_action else 0
            opp_prev_actions = history.opponent_actions[prev_round, :]
            opp_prev_coop = sum(opp_prev_actions)
            prev_total = my_prev_coop + opp_prev_coop
            if state.round_number == n_rounds - 1:
                new_coop = prev_total - my_prev_coop
                if new_coop >= m:
                    return Action.D
                else:
                    return Action.C
            elif prev_total < m:
                return Action.C
            elif prev_total >= m + 1:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_157(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma game. 
    The player starts by Cooperating and then uses the average number of Cooperators 
    in the last few rounds to decide the next action.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.w = 5

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            counts = np.sum(history.opponent_actions, axis=1)
            window_size = min(self.w, len(counts))
            recent_counts = counts[-window_size:]
            avg = np.mean(recent_counts)
            if avg >= self.m:
                return Action.D
            elif avg + 1 >= self.m:
                return Action.C
            else:
                return Action.D

@dataclass
class Strategy_EXPLOITATIVE_158(BaseStrategy):
    """
    Adaptive Cooperation with Final Round Exploitation (ACFRE) Strategy.
    Cooperates initially, adapts based on past collective success, and defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            success_count = 0
            for previous_round in range(state.round_number):
                my_action = history.my_actions[previous_round]
                opponent_actions = history.opponent_actions[previous_round, :]
                total_coop = int(my_action) + int(opponent_actions.sum())
                if total_coop >= self.game_description.m:
                    success_count += 1
            num_past_rounds = state.round_number
            success_rate = success_count / num_past_rounds
            if success_rate >= 0.5:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_159(BaseStrategy):
    """
    Exploitative Strategy for Collective Risk Dilemma.
    Cooperates initially, then adapts based on success rate of collective cooperation.
    Defects for a period if cooperation success rate is below a threshold,
    then tests cooperation again if necessary.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defect_counter = 0
        self.testing_cooperation = False

    def compute_success_rate(self, history: PlayerHistory) -> float:
        if history is None or len(history.my_actions) == 0:
            return 0.0
        successful_rounds = 0
        for r in range(len(history.my_actions)):
            my_action = history.my_actions[r]
            opponent_actions = history.opponent_actions[r]
            total_cooperations = my_action + sum(opponent_actions)
            if total_cooperations >= self.game_description.m:
                successful_rounds += 1
        return successful_rounds / len(history.my_actions)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        is_last_round = state.round_number == self.game_description.n_rounds - 1
        if is_last_round:
            success_rate = self.compute_success_rate(history)
            return Action.C if success_rate >= 0.7 else Action.D
        success_rate = self.compute_success_rate(history)
        if success_rate >= 0.7:
            self.defect_counter = 0
            self.testing_cooperation = False
            return Action.C
        elif self.testing_cooperation:
            self.testing_cooperation = False
            return Action.C
        elif self.defect_counter > 0:
            self.defect_counter -= 1
            return Action.D
        else:
            current_success_rate = self.compute_success_rate(history)
            if current_success_rate < 0.7:
                self.testing_cooperation = True
                return Action.C
            else:
                self.defect_counter = 0
                self.testing_cooperation = False
                return Action.C

class Strategy_EXPLOITATIVE_160(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that balances cooperation and defection.
    Cooperates initially, then adapts based on the average number of cooperators in previous rounds,
    and defects in the last round to maximize immediate payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            total_cooperators = 0.0
            for round_num in range(state.round_number):
                my_action = history.my_actions[round_num]
                my_coop = 1 if my_action else 0
                opponent_coop = np.count_nonzero(history.opponent_actions[round_num])
                total_cooperators += my_coop + opponent_coop
            average_cooperators = total_cooperators / state.round_number
            if average_cooperators >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_161(BaseStrategy):
    """
    Adaptive Cooperation Based on Past Success Strategy.

    This strategy starts by cooperating in the first round to encourage initial group success. 
    In subsequent rounds, it cooperates if the number of cooperators in the previous round meets 
    or exceeds the required threshold (m), otherwise it defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        sum_opponent_actions = np.sum(history.opponent_actions[prev_round, :])
        my_prev_action = history.my_actions[prev_round]
        total_cooperators = sum_opponent_actions + (1 if my_prev_action else 0)
        if total_cooperators >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_162(BaseStrategy):
    """
    Adaptive Cooperation Based on Historical Performance Strategy.

    The strategy begins by cooperating in the first round to test others' willingness to cooperate. 
    In subsequent rounds, it cooperates if the number of cooperators in the previous round meets or exceeds the threshold m-1, 
    otherwise it defects to maximize its own payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_action = history.my_actions[prev_round]
            my_coop = int(my_action)
            opponent_coop = history.opponent_actions[prev_round, ...].sum()
            total_coop = my_coop + opponent_coop
            threshold = self.game_description.m - 1
            if total_coop >= threshold:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_163(BaseStrategy):

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.sum_prev_coops = 0
        self.coop_prob = 0.8
        self.prev_coop_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        prev_round = current_round - 1
        my_prev_action = history.my_actions[prev_round]
        opp_prev_actions = history.opponent_actions[prev_round, :]
        num_coop_prev = my_prev_action + np.sum(opp_prev_actions)
        self.sum_prev_coops += num_coop_prev
        if current_round < self.r - 1:
            if num_coop_prev >= self.m:
                self.coop_prob = min(1.0, self.coop_prob + 0.2)
            else:
                self.coop_prob = max(0.2, self.coop_prob - 0.2)
            if random.random() < self.coop_prob:
                action = Action.C
            else:
                action = Action.D
        else:
            avg_coop_ratio = self.sum_prev_coops / current_round
            threshold = self.m / self.n
            if avg_coop_ratio >= threshold:
                action = Action.C
            else:
                action = Action.D
        self.prev_coop_count = num_coop_prev
        return action

class Strategy_EXPLOITATIVE_164(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma game. Cooperates initially, 
    then adapts based on the number of previous rounds meeting the cooperation threshold.
    Defects in the final round to maximize personal gain.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        s = 0
        for prev_round in range(state.round_number):
            my_action = history.my_actions[prev_round]
            opponent_actions_round = history.opponent_actions[prev_round, :]
            total_coop = (1 if my_action else 0) + sum(opponent_actions_round)
            if total_coop >= self.game_description.m:
                s += 1
        threshold = 0.5 * state.round_number
        return Action.C if s >= threshold else Action.D

class Strategy_EXPLOITATIVE_165(BaseStrategy):
    """
    Adaptive Cooperation Based on Historical Success.
    Cooperates initially, then decides based on whether past rounds met the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        total_success = 0
        for t in range(state.round_number):
            my_action = history.my_actions[t]
            opponent_actions = history.opponent_actions[t, :] if t < history.opponent_actions.shape[0] else []
            total_coop = sum(opponent_actions) + (1 if my_action else 0)
            if total_coop >= self.game_description.m:
                total_success += 1
        if 2 * total_success > state.round_number:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_166(BaseStrategy):
    """
    A strategy that adapts based on the historical success of group cooperation.
    Cooperates initially, then defects if the success ratio exceeds a threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.count_success = 0
        self.threshold = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        if t == 0:
            return Action.C
        prev_round = t - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_prev_actions = history.opponent_actions[prev_round, :]
        num_coop = int(my_prev_action) + np.sum(opponent_prev_actions)
        if num_coop >= self.game_description.m:
            self.count_success += 1
        total_rounds_so_far = t
        success_ratio = self.count_success / total_rounds_so_far if total_rounds_so_far > 0 else 0.0
        if success_ratio > self.threshold:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_167(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma game. 
    Cooperates initially and then adapts based on whether the cooperation threshold 
    was met without the player's contribution in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_actions_prev = history.opponent_actions[prev_round]
        others_coop_prev = sum(opponent_actions_prev)
        total_coop_prev = my_prev_action + others_coop_prev
        m = self.game_description.m
        if total_coop_prev >= m:
            if others_coop_prev >= m:
                return Action.D
            else:
                return Action.C
        else:
            return Action.C

class Strategy_EXPLOITATIVE_168(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma where players cooperate in the first round.
    In subsequent rounds, players defect if at least m players cooperated in the previous round;
    otherwise, they cooperate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            my_c = 1 if my_prev_action else 0
            opponent_actions_prev = history.opponent_actions[prev_round, :]
            opp_c = sum(opponent_actions_prev)
            total_c = my_c + opp_c
            if total_c >= self.game_description.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_169(BaseStrategy):
    """
    Adaptive Exploitation Based on Expected Contributions (AEBEC) strategy.
    Cooperates to meet the threshold if expected contributions from others are insufficient.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number
        n = self.game_description.n_players
        m = self.game_description.m
        E = 0.0
        for i in range(n - 1):
            count = np.sum(history.opponent_actions[:t, i])
            rate = count / t
            E += rate
        if E >= m - 1e-09:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_170(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that starts by cooperating, continues 
    if enough players cooperate, defects otherwise, and resets cooperation after 
    a set number of consecutive defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defects = 0
        self.defect_threshold = 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        opponent_actions_last = history.opponent_actions[last_round]
        my_last_action = history.my_actions[last_round]
        n_coop = np.sum(opponent_actions_last) + (1 if my_last_action else 0)
        m = self.game_description.m
        if n_coop >= m:
            self.consecutive_defects = 0
            return Action.C
        elif self.consecutive_defects >= self.defect_threshold:
            self.consecutive_defects = 0
            return Action.C
        else:
            self.consecutive_defects += 1
            return Action.D

class Strategy_EXPLOITATIVE_171(BaseStrategy):
    """
    Cooperate in the first round; thereafter, cooperate if at least m players cooperated in the previous round, otherwise defect.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_actions_prev = history.opponent_actions[prev_round, :]
        my_coop = my_prev_action
        opponent_coop = np.sum(opponent_actions_prev)
        total_coop = my_coop + opponent_coop
        if total_coop >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_172(BaseStrategy):
    """
    A strategy that adapts based on previous cooperation levels.
    Cooperates initially, then reciprocates previous round's total cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            my_prev = int(history.my_actions[-1])
            opp_actions = history.opponent_actions[-1, :]
            total = my_prev + sum(opp_actions)
            if total >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_173(BaseStrategy):
    """
    Adaptive Threshold Exploitation strategy for Collective Risk Dilemma.
    Balances cooperation and exploitation based on historical behavior of others.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        m = self.game_description.m
        target = m / n
        is_last_round = state.round_number == self.game_description.n_rounds - 1
        if state.round_number == 0:
            return Action.C
        sum_C = 0.0
        sum_D = 0.0
        count_C = 0
        count_D = 0
        for round in range(state.round_number):
            my_action = history.my_actions[round]
            opp_actions = history.opponent_actions[round]
            if my_action:
                count_C += 1
                total_C = sum(opp_actions) + 1
                sum_C += total_C
            else:
                count_D += 1
                total_C = sum(opp_actions)
                sum_D += total_C
        C_Rate = sum_C / (count_C * n) if count_C > 0 else 0.0
        D_Rate = sum_D / (count_D * n) if count_D > 0 else 0.0
        if C_Rate >= target:
            action = Action.C
        elif D_Rate >= target:
            action = Action.D
        else:
            action = Action.C
        if is_last_round:
            past_coop = [sum(history.opponent_actions[round]) + int(history.my_actions[round]) for round in range(state.round_number)]
            recent_coop = past_coop[-3:]
            if len(recent_coop) < 3:
                recent_coop = past_coop
            trend = sum(recent_coop) / len(recent_coop) < m
            if trend:
                action = Action.D
        return action

class Strategy_EXPLOITATIVE_174(BaseStrategy):
    """
    This strategy cooperates initially to encourage cooperation. In subsequent rounds, it continues 
    to cooperate if the previous round met the cooperation threshold. If not, it alternates between 
    cooperating and defecting. In the last round, it defects if the previous round's cooperation 
    was insufficient.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            my_prev_prev = history.my_actions[-1]
            sum_opp_prev = np.sum(history.opponent_actions[-1])
            total_prev_prev_coop = my_prev_prev + sum_opp_prev
            if total_prev_prev_coop < self.game_description.m:
                return Action.D
            else:
                return Action.C
        else:
            my_prev = history.my_actions[-1]
            sum_opp_prev = np.sum(history.opponent_actions[-1])
            total_coop_prev = my_prev + sum_opp_prev
            if total_coop_prev >= self.game_description.m:
                return Action.C
            elif my_prev:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_175(BaseStrategy):
    """
    A strategy that adapts based on prior cooperation, defecting in the last round.
    Cooperates initially, continues if enough cooperated previously, defects otherwise.
    Defects unconditionally in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            prev_round = state.round_number - 1
            my_prev = history.my_actions[prev_round]
            opponents_prev = history.opponent_actions[prev_round, :]
            num_opponent_c = np.sum(opponents_prev)
            total_c = num_opponent_c + (1 if my_prev else 0)
            if total_c >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_176(BaseStrategy):
    """
    Adaptive Cooperative Punisher (ACP) Strategy.

    This strategy starts by cooperating, then adapts based on the outcomes of previous rounds.
    It uses a failure counter to determine when to switch to defecting as a punitive measure.
    In the last round, it decides based on the majority outcome of recent previous rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.failure_counter = 0
        self.punishing = False
        self.punishment_remaining = 0
        self.failure_limit = 2
        self.threshold_met_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        is_final_round = state.round_number == self.game_description.n_rounds - 1
        if state.round_number == 0:
            return Action.C
        if is_final_round:
            if len(self.threshold_met_history) == 0:
                return Action.D
            else:
                look_back = min(3, len(self.threshold_met_history))
                recent_history = self.threshold_met_history[-look_back:]
                count = sum(recent_history)
                required = look_back // 2 + 1
                if count >= required:
                    return Action.C
                else:
                    return Action.D
        elif self.punishing:
            action = Action.D
            self.punishment_remaining -= 1
            if self.punishment_remaining == 0:
                self.punishing = False
            return action
        else:
            my_last_action = history.my_actions[-1]
            opponent_last_actions = history.opponent_actions[-1, :]
            sum_coop_prev = my_last_action + sum(opponent_last_actions)
            threshold_met = sum_coop_prev >= self.game_description.m
            self.threshold_met_history.append(threshold_met)
            if threshold_met:
                self.failure_counter = 0
                return Action.C
            else:
                self.failure_counter += 1
                if self.failure_counter >= self.failure_limit:
                    self.punishing = True
                    self.punishment_remaining = 2
                    return Action.D
                else:
                    return Action.C

class Strategy_EXPLOITATIVE_177(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that adapts based on previous cooperation levels.
    Cooperates initially to encourage cooperation, then defects if enough others cooperated previously.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif history is not None:
            prev_round = state.round_number - 1
            opponent_actions_prev = history.opponent_actions[prev_round]
            sum_others = np.sum(opponent_actions_prev)
            if sum_others >= self.game_description.m:
                return Action.D
            else:
                return Action.C
        else:
            return Action.C

class Strategy_EXPLOITATIVE_178(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that balances personal payoff maximization with maintaining sufficient cooperation.
    It cooperates initially, defects when safe, and reverts to cooperation if defection causes cooperation to drop below the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_t = state.round_number - 1
        my_prev_action = history.my_actions[prev_t]
        sum_others_prev = history.opponent_actions[prev_t].sum()
        C_prev = sum_others_prev + my_prev_action
        if not my_prev_action:
            if C_prev < self.game_description.m:
                return Action.C
        if C_prev >= self.game_description.m:
            if sum_others_prev >= self.game_description.m:
                return Action.D
            else:
                return Action.C
        else:
            return Action.C

class Strategy_EXPLOITATIVE_179(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that balances initial cooperation with 
    strategic defection to encourage future cooperation and exploit final-round opportunities.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        n_rounds = self.game_description.n_rounds
        m = self.game_description.m
        if round_num == 0:
            return Action.C
        elif round_num == n_rounds - 1:
            return Action.D
        else:
            prev_round = round_num - 1
            my_prev_action = history.my_actions[prev_round]
            opp_prev_actions = history.opponent_actions[prev_round, :]
            total_coop = sum(opp_prev_actions) + (1 if my_prev_action else 0)
            if total_coop >= m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_180(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that encourages cooperation and adapts based on previous rounds.
    Cooperates initially and continues if the threshold is met, otherwise adapts by sometimes defecting to recover cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            if history is None:
                return Action.D
            my_prev_action = history.my_actions[prev_round]
            opponent_actions_prev = history.opponent_actions[prev_round, :]
            prev_coop_count = sum(opponent_actions_prev) + (1 if my_prev_action else 0)
            if prev_coop_count >= self.game_description.m:
                return Action.C
            elif not my_prev_action:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_181(BaseStrategy):
    """
    Adaptive exploitation strategy for the Collective Risk Dilemma.
    Cooperates initially and adapts based on historical cooperation levels to maximize payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_my_action = history.my_actions[-1]
        prev_opponent_actions = history.opponent_actions[-1]
        sum_o_prev_round = np.sum(prev_opponent_actions)
        T_prev = prev_my_action + sum_o_prev_round
        if T_prev < self.m:
            return Action.C
        else:
            sum_o_prev = T_prev - prev_my_action
            if sum_o_prev >= self.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_182(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that balances cooperation with self-interest.
    It Cooperates initially and adapts based on previous outcomes to maximize personal payoff
    while ensuring the group meets the cooperation threshold when possible.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        opponents_last_actions = history.opponent_actions[last_round, :]
        num_opponent_coop = np.sum(opponents_last_actions)
        my_last_action = history.my_actions[last_round]
        total_coop_last = num_opponent_coop + (1 if my_last_action else 0)
        if total_coop_last < self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_183(BaseStrategy):
    """
    Adaptive Cooperation with Exploitation (ACE) strategy.
    Cooperates initially, then adapts based on recent cooperation trends.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.coop_counts = []
        self.window_size = 3

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        for r in range(len(self.coop_counts), current_round):
            if r >= len(history.my_actions) or r >= history.opponent_actions.shape[0]:
                total_coop = 0
            else:
                my_action = history.my_actions[r]
                opp_actions = history.opponent_actions[r, :]
                my_coop = 1 if my_action else 0
                opp_coop = np.sum(opp_actions)
                total_coop = my_coop + opp_coop
            self.coop_counts.append(total_coop)
        n_prev_rounds = len(self.coop_counts)
        if n_prev_rounds == 0:
            return Action.D
        w = self.window_size
        start = max(0, n_prev_rounds - w)
        recent_coops = self.coop_counts[start:n_prev_rounds]
        avg_coop = np.mean(recent_coops)
        if avg_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_184(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game. It starts by cooperating in the first round, 
    then decides based on the historical success rate of meeting the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        success_count = 0
        m = self.game_description.m
        for s in range(state.round_number):
            my_action = history.my_actions[s]
            opponent_actions = history.opponent_actions[s, :]
            total_coop = (1 if my_action else 0) + np.sum(opponent_actions)
            if total_coop >= m:
                success_count += 1
        total_past_rounds = state.round_number
        success_rate = success_count / total_past_rounds
        return Action.C if success_rate >= 0.5 else Action.D

class Strategy_EXPLOITATIVE_185(BaseStrategy):
    """
    A strategy that Cooperates in the first round and continues to Cooperate in subsequent rounds 
    if at least m players Cooperated in the previous round; otherwise, it Defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev_action = history.my_actions[previous_round]
        opponent_prev_actions = history.opponent_actions[previous_round, :]
        total_cooperators = my_prev_action + np.sum(opponent_prev_actions)
        if total_cooperators >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_186(BaseStrategy):
    """
    Cooperates initially, then defects if enough players cooperated previously; 
    otherwise continues to cooperate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_opp_actions = history.opponent_actions[-1]
            sum_opp = sum(prev_opp_actions)
            my_last = history.my_actions[-1]
            total_c = sum_opp + (1 if my_last else 0)
            if total_c >= self.game_description.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_187(BaseStrategy):
    """
    A strategy to maximize personal payoff while contributing to group success in a Collective Risk Dilemma.
    The strategy involves initial cooperation, testing phases, and adaptive adjustments based on test outcomes.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.pending_tests = []
        self.successful_tests = 0
        self.total_tests = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if history is not None:
            for test_round in list(self.pending_tests):
                if test_round < current_round:
                    other_cooperations = sum(history.opponent_actions[test_round, :])
                    if other_cooperations >= self.m:
                        self.successful_tests += 1
                    self.total_tests += 1
                    self.pending_tests.remove(test_round)
        if current_round == self.n_rounds - 1:
            if self.total_tests > 0:
                success_rate = self.successful_tests / self.total_tests
                if success_rate > 0.8:
                    return Action.D
                else:
                    return Action.C
            else:
                return Action.C
        if current_round < 3:
            return Action.C
        offset = current_round - 3
        if offset >= 0 and offset % 2 == 0:
            action = Action.D
            self.pending_tests.append(current_round)
            return action
        else:
            if self.total_tests > 0:
                success_rate = self.successful_tests / self.total_tests
            else:
                success_rate = 0.0
            if success_rate > 0.8 and self.total_tests >= 5:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_188(BaseStrategy):
    """
    Cooperative exploit strategy for the Collective Risk Dilemma. Cooperates in the first round, then alternates based on whether the previous round met the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_prev_actions = history.opponent_actions[prev_round, :]
        total_cooperators = sum(opponent_prev_actions) + (1 if my_prev_action else 0)
        if total_cooperators >= self.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_189(BaseStrategy):
    """
    Cooperate in the first round. For subsequent rounds, defect if at least m other players cooperated in the previous round; otherwise, cooperate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round_actions = history.opponent_actions[-1]
        num_cooperators = sum(previous_round_actions)
        m = self.game_description.m
        if num_cooperators >= m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_190(BaseStrategy):
    """
    A strategy that begins with cooperation, continues if sufficient players cooperated previously,
    defects otherwise, andforgives after a set number of defections to restart cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defects = 0
        self.s = 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        my_last_action = history.my_actions[last_round]
        opponent_last_actions = history.opponent_actions[last_round, :]
        sum_opponents = sum(opponent_last_actions)
        total_coop_last = my_last_action + sum_opponents
        if total_coop_last >= self.game_description.m:
            self.consecutive_defects = 0
            return Action.C
        else:
            self.consecutive_defects += 1
            if self.consecutive_defects >= self.s:
                self.consecutive_defects = 0
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_191(BaseStrategy):
    """
    Adaptive Cooperation with Forgiveness strategy for Collective Risk Dilemma.
    Cooperates initially, then responds based on previous round's cooperation level.
    Forgives and retries cooperation after two consecutive rounds below the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_t = state.round_number - 1
        prev_my_action = history.my_actions[prev_t]
        prev_their_actions = history.opponent_actions[prev_t, :]
        prev_total_coop = prev_my_action + np.sum(prev_their_actions)
        if prev_total_coop >= self.game_description.m:
            self.consecutive_defections = 0
            return Action.C
        else:
            self.consecutive_defections += 1
            if self.consecutive_defections >= 2:
                self.consecutive_defections = 0
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_192(BaseStrategy):
    """
    A strategy that begins by cooperating and then adapts based on the number of cooperators.
    It cooperates if the number of cooperators in the previous round meets the threshold; otherwise, it defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            my_prev = history.my_actions[state.round_number - 1]
            opp_prev = history.opponent_actions[state.round_number - 1, :]
            c_prev = np.sum(opp_prev) + (1 if my_prev else 0)
            if c_prev >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_193(BaseStrategy):

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            t_prev = state.round_number - 1
            my_prev_action = history.my_actions[t_prev]
            opponents_prev = history.opponent_actions[t_prev, :]
            total_coop_prev = int(my_prev_action) + np.sum(opponents_prev)
            if total_coop_prev >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_194(BaseStrategy):

    def __init__(self, game_description: CollectiveRiskDescription):
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            my_prev_action = history.my_actions[-1]
            opponents_prev_actions = history.opponent_actions[-1, :]
            total_coop = my_prev_action + np.sum(opponents_prev_actions)
            if total_coop >= self.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_195(BaseStrategy):
    """
    Exploitative Strategy for Collective Risk Dilemma.
    Cooperates initially, then adapts based on a weighted average of past cooperation meeting the threshold.
    Leans towards defection in the last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        sum_met = 0.0
        sum_weights = 0.0
        m = self.game_description.m
        current_round = state.round_number
        for t in range(current_round):
            opp_actions = history.opponent_actions[t]
            opp_coop = np.sum(opp_actions)
            my_action = history.my_actions[t]
            total_coop = opp_coop + (1 if my_action else 0)
            met = 1 if total_coop >= m else 0
            age = current_round - 1 - t
            weight = 1.0 / (age + 1)
            sum_met += met * weight
            sum_weights += weight
        proportion = sum_met / sum_weights if sum_weights > 0 else 0.0
        if current_round == self.game_description.n_rounds - 1:
            threshold = 0.7
        else:
            threshold = 0.5
        return Action.C if proportion > threshold else Action.D

class Strategy_EXPLOITATIVE_196(BaseStrategy):
    """
    A strategy that starts with cooperation, adapts based on previous cooperation levels,
    and defects in the final round to maximize individual payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            t_prev = state.round_number - 1
            my_prev_action = history.my_actions[t_prev]
            opponent_prev_actions = history.opponent_actions[t_prev]
            total_coop_prev = my_prev_action + opponent_prev_actions.sum()
            if total_coop_prev >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_197(BaseStrategy):
    """
    A strategy that initially cooperates, adapts based on the previous round's cooperation threshold,
    and attempts to recover cooperation after consecutive defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round_number = state.round_number - 1
        my_prev_action = history.my_actions[previous_round_number]
        opponent_prev_actions = history.opponent_actions[previous_round_number, :]
        prev_total_c = my_prev_action + np.sum(opponent_prev_actions)
        previous_met = prev_total_c >= self.game_description.m
        if previous_met:
            self.consecutive_defections = 0
            return Action.C
        else:
            self.consecutive_defections += 1
            if self.consecutive_defections >= 2:
                self.consecutive_defections = 0
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_198(BaseStrategy):
    """
    Reactive Cooperator Strategy: Cooperates initially and continues if the previous round met the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev_action = history.my_actions[previous_round]
        my_coop = 1 if my_prev_action else 0
        opponent_coops = history.opponent_actions[previous_round]
        sum_coop = my_coop + opponent_coops.sum()
        if sum_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_199(BaseStrategy):
    """
    Strategy that always chooses to defect to maximize individual payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        return Action.D

class Strategy_EXPLOITATIVE_200(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game. The strategy is deterministic and based on the number of cooperators in the previous round.
    Cooperates in the first round to encourage cooperation, then cooperates if the previous round met or was just below the threshold,
    otherwise defects to maximize individual payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_last_action = history.my_actions[previous_round]
        opponent_actions_last = history.opponent_actions[previous_round, :]
        opp_coop_last = np.sum(opponent_actions_last)
        my_coop_last = 1 if my_last_action else 0
        total_coop_last = my_coop_last + opp_coop_last
        m = self.game_description.m
        if total_coop_last >= m:
            return Action.C
        elif total_coop_last + 1 >= m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_201(BaseStrategy):
    """
    A strategy that balances cooperation and exploitation based on observed outcomes.
    Initially cooperates, defects in the last round, and adapts in middle rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        t = state.round_number
        m = self.game_description.m
        count = 0
        for s in range(t):
            my_c = history.my_actions[s]
            opponent_actions = history.opponent_actions[s]
            opponent_coop = np.sum(opponent_actions)
            total_coop = my_c + opponent_coop
            if total_coop >= m:
                count += 1
        p = count / t
        if p > 0.5:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_202(BaseStrategy):
    """
    Implements the Adaptive Exploitation Based on Cooperation Trends strategy.
    Cooperates initially, then uses moving average of cooperation over last three rounds.
    Defects if cooperation is below threshold m for two consecutive rounds.
    Makes strategic decisions in the final round based on recent cooperation trends.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == 1:
            return Action.C
        coop_counts = []
        for round in range(state.round_number):
            my_action = history.my_actions[round]
            opponent_actions = history.opponent_actions[round, :]
            my_coop = 1 if my_action else 0
            opp_coop = np.sum(opponent_actions)
            total_coop = my_coop + opp_coop
            coop_counts.append(total_coop)
        if state.round_number == self.n_rounds - 1:
            if len(coop_counts) >= 3:
                recent = coop_counts[-3:]
            else:
                recent = coop_counts
            avg = sum(recent) / len(recent)
            if avg >= self.m:
                return Action.C
            else:
                return Action.D
        else:
            last_two = coop_counts[-2:]
            if all((c < self.m for c in last_two)):
                return Action.D
            else:
                take = min(3, len(coop_counts))
                recent = coop_counts[-take:]
                avg = sum(recent) / len(recent)
                if avg >= self.m:
                    return Action.C
                else:
                    return Action.D

class Strategy_EXPLOITATIVE_203(BaseStrategy):
    """
    Adaptive Exploitation Based on Recent History strategy for Collective Risk Dilemma.
    Cooperates initially and adapts based on recent rounds' outcomes to balance cooperation and exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        start = max(0, state.round_number - 3)
        recent_rounds = range(start, state.round_number)
        n_players = self.game_description.n_players
        m = self.game_description.m
        count = 0
        for x in recent_rounds:
            my_action = history.my_actions[x]
            opp_actions = history.opponent_actions[x, :]
            total_coop = int(my_action) + sum(opp_actions)
            if total_coop >= m:
                count += 1
        T = len(recent_rounds)
        if m > n_players / 2:
            threshold = 0.75
        else:
            threshold = 0.5
        if count / T >= threshold:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_204(BaseStrategy):
    """
    Adaptive Cooperation with Exploitation (ACE) Strategy.
    Cooperates initially and adapts based on the number of cooperators in the previous round.
    Defects if the previous round met or exceeded the cooperation threshold, otherwise continues to cooperate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opp_prev_actions = history.opponent_actions[prev_round, :]
        my_coop = int(my_prev_action)
        opp_coops = opp_prev_actions.sum()
        total_coop = my_coop + opp_coops
        if total_coop >= self.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_205(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that balances cooperation with self-interest by adapting based on previous rounds' outcomes.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            previous_round = state.round_number - 1
            my_prev_action = history.my_actions[previous_round]
            opp_prev_actions = history.opponent_actions[previous_round]
            my_coop = 1 if my_prev_action else 0
            opp_coop = sum(opp_prev_actions)
            total_coop = my_coop + opp_coop
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_206(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that starts with cooperation, 
    adapts based on previous round's cooperation levels, and retries cooperation 
    after a defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_action = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.last_action = Action.C
            return Action.C
        elif self.last_action == Action.D:
            self.last_action = Action.C
            return Action.C
        else:
            previous_round = state.round_number - 1
            own_prev = history.my_actions[previous_round]
            opp_prev = sum(history.opponent_actions[previous_round, :])
            total_coop = int(own_prev) + opp_prev
            if total_coop >= self.game_description.m:
                self.last_action = Action.C
                return Action.C
            else:
                self.last_action = Action.D
                return Action.D

class Strategy_EXPLOITATIVE_207(BaseStrategy):
    """
    This strategy initially cooperates and then adapts based on others' cooperation.
    It uses the number of previous cooperators to decide its next action, 
    encouraging continued group success while avoiding exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        others_coop = history.opponent_actions[prev_round, :].sum()
        threshold = self.m - 1
        if others_coop >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_209(BaseStrategy):
    """
    A reactive strategy for the Collective Risk Dilemma game where players 
    Cooperate if the cooperation threshold was met in the previous round and 
    Defect otherwise, starting with Cooperation in the first round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        prev_round = state.round_number - 1
        my_last_action = history.my_actions[prev_round]
        opponent_last_actions = history.opponent_actions[prev_round, :]
        coop_count = sum(opponent_last_actions)
        if my_last_action:
            coop_count += 1
        if coop_count >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_210(BaseStrategy):
    """
    A strategy that begins by cooperating to encourage group cooperation, 
    defects when enough players have cooperated to exploit the situation, 
    and defects in the final round to maximize personal gain.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        prev_round = state.round_number - 1
        prev_opponent_actions = history.opponent_actions[prev_round, :]
        prev_my_action = history.my_actions[prev_round]
        total_coop_prev = sum(prev_opponent_actions) + (1 if prev_my_action else 0)
        if total_coop_prev >= self.game_description.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_211(BaseStrategy):
    """
    Adaptive Exploitation Strategy:
    Cooperate in the first round. In subsequent rounds before the last, defect if the previous round met the cooperation threshold, otherwise cooperate. Always defect in the last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opponents_prev_actions = history.opponent_actions[prev_round]
            total_coop = int(my_prev_action) + int(opponents_prev_actions.sum())
            threshold_met = total_coop >= self.game_description.m
            return Action.D if threshold_met else Action.C

class Strategy_EXPLOITATIVE_212(BaseStrategy):
    """
    Adaptive Cooperation Based on Moving Average strategy for Collective Risk Dilemma.
    Cooperates initially and continues if the moving average of past cooperators meets the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        m = self.game_description.m
        cooperator_counts = []
        for t in range(state.round_number):
            my_action = history.my_actions[t]
            opp_actions = history.opponent_actions[t]
            my_c = int(my_action)
            opp_c = np.sum(opp_actions)
            total = my_c + opp_c
            cooperator_counts.append(total)
        window_length = min(5, len(cooperator_counts))
        window = cooperator_counts[-window_length:] if window_length > 0 else []
        if not window:
            return Action.D
        avg = np.mean(window)
        if avg >= m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_213(BaseStrategy):
    """
    Exploitative Cooperation Based on Past Performance strategy.
    Cooperates initially, then defects if previous round met the cooperation threshold, otherwise continues to cooperate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_action_prev = history.my_actions[prev_round]
            opponents_prev = history.opponent_actions[prev_round]
            total_coops = my_action_prev + np.sum(opponents_prev)
            if total_coops >= self.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_214(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma that balances cooperation and exploitation.
    Cooperates initially, then monitors recent cooperation rates to decide actions, defecting briefly when cooperation is low.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.defect_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round < 3:
            return Action.C
        if current_round == self.r - 1:
            return Action.C
        if history is None:
            return Action.C
        if self.defect_remaining > 0:
            self.defect_remaining -= 1
            return Action.D
        my_actions = history.my_actions
        opponent_actions = history.opponent_actions
        end = len(my_actions)
        if end == 0:
            return Action.C
        start = max(0, end - 5)
        sum_coop = 0
        for i in range(start, end):
            my_action = my_actions[i]
            opp_actions = opponent_actions[i]
            count = sum(opp_actions)
            if my_action:
                count += 1
            sum_coop += count
        total_player_rounds = (end - start) * self.n
        if total_player_rounds == 0:
            cooperation_rate = 0.0
        else:
            cooperation_rate = sum_coop / total_player_rounds
        if cooperation_rate >= 0.5:
            return Action.C
        else:
            self.defect_remaining = 2
            return Action.D

class Strategy_EXPLOITATIVE_215(BaseStrategy):
    """
    A strategy that adapts based on the historical effectiveness of defections.
    Cooperates initially and then defects if past defections were successful more than half the time.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_actions = history.my_actions
        rounds_defected = np.where(my_actions == False)[0]
        total_defections = len(rounds_defected)
        if total_defections == 0:
            return Action.C
        successful = 0
        m = self.game_description.m
        for t in rounds_defected:
            others_c = np.sum(history.opponent_actions[t, :])
            if others_c >= m:
                successful += 1
        success_rate = successful / total_defections
        if success_rate > 0.5:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_216(BaseStrategy):
    """
    Adaptive Cooperator with Punishment and Reward (ACPR) strategy.
    Cooperates initially, punishes for two rounds if cooperation threshold isn't met,
    then continues or alternates based on subsequent cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_remaining = 0
        self.alternate = False
        self.last_action = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.last_action = Action.C
            return Action.C
        if self.alternate:
            if self.last_action == Action.C:
                action = Action.D
            else:
                action = Action.C
            self.last_action = action
        else:
            if self.punishment_remaining > 0:
                action = Action.D
                self.punishment_remaining -= 1
            else:
                action = Action.C
            self.last_action = action
        if history is not None:
            prev_round = state.round_number - 1
            if prev_round >= 0 and prev_round < len(history.my_actions):
                total_coop = sum(history.opponent_actions[prev_round])
                if history.my_actions[prev_round]:
                    total_coop += 1
                if total_coop < self.game_description.m:
                    if not self.alternate:
                        if self.punishment_remaining == 0:
                            self.alternate = True
                        else:
                            self.punishment_remaining = 2
        return action

class Strategy_EXPLOITATIVE_217(BaseStrategy):
    """
    Exploitative Strategy for Collective Risk Dilemma balancing cooperation and punishment.

    The strategy encourages cooperation while punishing insufficient contributions to the collective good.
    It adapts based on the history of cooperation, extending punishments when cooperation is inconsistent.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_remaining = 0
        self.cooperation_misses = 0
        self.cooperation_history = []
        self.max_history_length = 5

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.punishment_remaining > 0:
            self.punishment_remaining -= 1
            return Action.D
        last_round = state.round_number - 1
        if history is None:
            return Action.C
        my_last = history.my_actions[last_round]
        their_last = history.opponent_actions[last_round, :]
        num_coop = my_last + their_last.sum()
        meet_threshold = num_coop >= self.game_description.m
        self.cooperation_history.append(int(meet_threshold))
        if len(self.cooperation_history) > self.max_history_length:
            self.cooperation_history.pop(0)
        if meet_threshold:
            return Action.C
        avg_coop = sum(self.cooperation_history) / len(self.cooperation_history) if self.cooperation_history else 0.0
        base_duration = 2
        if avg_coop < 0.3:
            punishment_duration = base_duration + 2
        elif avg_coop < 0.6:
            punishment_duration = base_duration + 1
        else:
            punishment_duration = base_duration
        self.cooperation_misses += 1
        self.punishment_remaining = min(punishment_duration, 5)
        return Action.D

class Strategy_EXPLOITATIVE_218(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that balances cooperation and defection based on observed behavior and game parameters.
    
    The strategy follows these rules:
    1. Cooperate in the first round.
    2. In intermediate rounds, cooperate if at least m players cooperated in the previous round; otherwise, defect.
    3. Defect in the last round to maximize immediate payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        elif current_round == self.n_rounds - 1:
            return Action.D
        else:
            previous_round = current_round - 1
            my_prev_action = history.my_actions[previous_round]
            opponent_prev_actions = history.opponent_actions[previous_round, :]
            total_coop = my_prev_action + opponent_prev_actions.sum()
            return Action.C if total_coop >= self.m else Action.D

class Strategy_EXPLOITATIVE_219(BaseStrategy):
    """
    A strategy that starts by Cooperating, then adapts based on recent cooperation rates.
    If recent rounds met the cooperation threshold more than half the time, Cooperate;
    otherwise, Defect. The last round also follows this logic based on trends.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        today_round = state.round_number
        recent_round_indices = range(max(0, today_round - 3), today_round)
        count = 0
        total_rounds = len(recent_round_indices)
        if total_rounds == 0:
            return Action.C
        for r in recent_round_indices:
            my_c = history.my_actions[r]
            opp_actions = history.opponent_actions[r, :]
            total_c = my_c + np.sum(opp_actions)
            if total_c >= self.game_description.m:
                count += 1
        if count / total_rounds > 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_220(BaseStrategy):
    """
    A reactive strategy that starts by Defecting in the first round and then cooperates in subsequent rounds 
    if at least m players cooperated in the previous round, based on the Collective Risk Dilemma parameters.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        others_prev_actions = history.opponent_actions[prev_round, :]
        total_coop = sum(others_prev_actions) + (1 if my_prev_action else 0)
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_221(BaseStrategy):
    """
    Adaptive Cooperation with Punishment and Learning (ACPL) strategy.
    Cooperates initially, continues if enough cooperated last round, defects to punish otherwise.
    Limits excessive defection to avoid being exploited.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        game_desc = self.game_description
        m = game_desc.m
        r = game_desc.n_rounds
        prev_round = current_round - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_prev_actions = history.opponent_actions[prev_round]
        sum_opponent = sum(opponent_prev_actions)
        total_coop_last = sum_opponent + (1 if my_prev_action else 0)
        if total_coop_last >= m:
            return Action.C
        if current_round == r - 1:
            return Action.C
        if len(history.my_actions) >= 2:
            recent_actions = history.my_actions[-2:]
        else:
            recent_actions = history.my_actions[-1:]
        defect_count = len(recent_actions) - sum(recent_actions)
        if defect_count <= 1:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_222(BaseStrategy):
    """
    Adaptive strategy based on historical performance.
    First alternates C and D for the first five rounds, then calculates expected payoffs.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        if state.round_number < 5:
            if state.round_number % 2 == 0:
                return Action.C
            else:
                return Action.D
        count_C_success = 0
        count_D_success = 0
        total_C = 0
        total_D = 0
        n_prev_rounds = history.my_actions.shape[0]
        for r in range(n_prev_rounds):
            my_action_bool = history.my_actions[r]
            action = Action.C if my_action_bool else Action.D
            opponent_actions = history.opponent_actions[r, :]
            total_coop = sum(opponent_actions) + (1 if my_action_bool else 0)
            threshold_met = total_coop >= self.game_description.m
            if action == Action.C:
                total_C += 1
                if threshold_met:
                    count_C_success += 1
            else:
                total_D += 1
                if threshold_met:
                    count_D_success += 1
        p_C = count_C_success / total_C if total_C != 0 else 0.0
        p_D = count_D_success / total_D if total_D != 0 else 0.0
        k = self.game_description.k
        E_C = p_C * k
        E_D = p_D * (1 + k) + (1 - p_D)
        if E_C > E_D:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_223(BaseStrategy):
    """
    Exploitative Strategy for Collective Risk Dilemma.
    Cooperates in the first round. Subsequently, defects if the number of cooperators
    in the previous round was at least m, otherwise continues to cooperate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_last_action = history.my_actions[-1]
        opp_last_actions = history.opponent_actions[-1, :]
        opp_cooperations = sum(opp_last_actions)
        total_cooperations = my_last_action + opp_cooperations
        if total_cooperations >= self.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_224(BaseStrategy):
    """
    Always defects in every round, as it provides a higher or equal payoff than cooperating.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        return Action.D

class Strategy_EXPLOITATIVE_225(BaseStrategy):
    """
    A strategy that cooperates in the first round and then continues to cooperate as long as 
    at least m players cooperated in the previous round; otherwise, it defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.m = game_description.m
        self.n_players = game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_prev_actions = history.opponent_actions[prev_round]
        total_coops = my_prev_action + np.sum(opponents_prev_actions)
        if total_coops >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_226(BaseStrategy):
    """
    Adaptive Exploitation strategy for the Collective Risk Dilemma.
    Cooperates in the first round, continues cooperating if sufficient players 
    cooperated in the previous round until the final round, where it defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        n_rounds = self.game_description.n_rounds
        m = self.game_description.m
        if current_round == 0:
            return Action.C
        elif current_round == n_rounds - 1:
            return Action.D
        else:
            previous_round = current_round - 1
            my_prev_action = history.my_actions[previous_round]
            opponents_prev_actions = history.opponent_actions[previous_round]
            total_cooperators = my_prev_action.item() + int(opponents_prev_actions.sum())
            if total_cooperators >= m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_227(BaseStrategy):
    """
    A strategy that adapts based on the average cooperation of other players.
    Cooperates initially and then defects if the average cooperation meets the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            total_coop = 0
            for round_num in range(state.round_number):
                coop_in_round = history.opponent_actions[round_num].sum()
                total_coop += coop_in_round
            avg_coop = total_coop / state.round_number
            if avg_coop >= self.game_description.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_228(BaseStrategy):
    """
    Exploitative Adaptation Strategy for Collective Risk Dilemma.

    The strategy cooperates in the first round. For subsequent rounds, it uses the cooperation history
    to decide whether to defect or cooperate, aiming to maximize individual payoff while ensuring
    the reward threshold is met.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        m = self.game_description.m
        list_of_coop_counts = []
        start = max(0, state.round_number - 3)
        for r in range(start, state.round_number):
            my_action_bool = history.my_actions[r]
            opponent_actions_in_round = history.opponent_actions[r]
            coop_count = my_action_bool + np.sum(opponent_actions_in_round)
            list_of_coop_counts.append(coop_count)
        num_meeting = sum((1 for count in list_of_coop_counts if count >= m))
        total_rounds = len(list_of_coop_counts)
        majority = False
        if total_rounds > 0:
            majority_prop = num_meeting / total_rounds
            majority = majority_prop > 0.5
        last_coop = list_of_coop_counts[-1] if list_of_coop_counts else 0
        safe_defection = last_coop - 1 >= m if list_of_coop_counts else False
        if majority and safe_defection:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_229(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game. The AI starts by Cooperating 
    and then reacts based on the number of Cooperators in the previous round.
    If at least m players Cooperated previously, the AI will Defect; otherwise, it Cooperates.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opp_prev_actions = history.opponent_actions[prev_round]
            total_coop = my_prev_action + np.sum(opp_prev_actions)
            if total_coop >= self.game_description.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_230(BaseStrategy):
    """
    A strategy designed for the Collective Risk Dilemma that balances cooperation and exploitation.
    Cooperates initially, adapts based on previous cooperation levels, and defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.n_rounds - 1:
            return Action.D
        else:
            previous_round = state.round_number - 1
            opponent_coop = np.sum(history.opponent_actions[previous_round])
            self_coop = 1 if history.my_actions[previous_round] else 0
            total_coop = opponent_coop + self_coop
            if total_coop >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_231(BaseStrategy):
    """
    Adaptive Cooperation with Periodic Testing strategy for Collective Risk Dilemma.
    The strategy starts by cooperating, continues if enough others cooperate, 
    otherwise defects but periodically tests cooperation after 4 defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0
        self.test_cooperate_next = False
        self.x = 4

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev_action = history.my_actions[previous_round]
        opponent_prev_actions = history.opponent_actions[previous_round, :]
        c_prev = int(my_prev_action) + np.sum(opponent_prev_actions)
        if self.test_cooperate_next:
            action = Action.C
            self.test_cooperate_next = False
            self.consecutive_defections = 0
        elif c_prev >= self.game_description.m:
            action = Action.C
            self.consecutive_defections = 0
        else:
            action = Action.D
            self.consecutive_defections += 1
            if self.consecutive_defections >= self.x:
                self.test_cooperate_next = True
        return action

class Strategy_EXPLOITATIVE_232(BaseStrategy):
    """
    An adaptive strategy that promotes cooperation based on previous rounds' outcomes.
    Cooperates in the first round, then adapts by rewarding sustained cooperation and defecting upon insufficient cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        n_rounds = self.game_description.n_rounds
        m = self.game_description.m
        if current_round == n_rounds - 1:
            prev_round = current_round - 1
        else:
            prev_round = current_round - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_actions_prev = history.opponent_actions[prev_round]
        total_coop = my_prev_action + np.sum(opponent_actions_prev)
        if total_coop >= m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_234(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy.
    Cooperates initially and continues if previous round met the threshold of cooperators.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_prev_actions = history.opponent_actions[prev_round]
        sum_others = np.sum(opponents_prev_actions)
        total_coop = sum_others + (1 if my_prev_action else 0)
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_235(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma game. The strategy 
    starts by Cooperating and then decides to Cooperate or Defect in subsequent 
    rounds based on the ratio of successful outcomes where cooperation met the 
    minimum required threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        success_count = 0
        for t in range(state.round_number):
            my_coop = int(history.my_actions[t])
            opponent_coop = history.opponent_actions[t, :].sum()
            total_coop = my_coop + opponent_coop
            if total_coop >= self.m:
                success_count += 1
        ratio = success_count / state.round_number
        if ratio > 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_236(BaseStrategy):
    """
    A strategy that starts with cooperation and then reciprocates based on whether the minimum number of cooperators was met in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev_coop = history.my_actions[previous_round]
        opponents_prev_actions = history.opponent_actions[previous_round, :]
        coop_count = int(my_prev_coop) + np.sum(opponents_prev_actions)
        if coop_count >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_237(BaseStrategy):
    """
    Adaptive Cooperation with Punishment and Reset Strategy.
    
    This strategy starts by cooperating. In subsequent rounds, it continues to
    cooperate if the previous round met the minimum cooperators needed (m). If
    not, it defects and tracks consecutive failures. After 3 consecutive failures,
    it resets by cooperating again to attempt restarting cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_failures = 0
        self.reset_threshold = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_prev_actions = history.opponent_actions[prev_round, :]
        total_coop_prev = my_prev_action + np.sum(opponents_prev_actions)
        if total_coop_prev >= self.game_description.m:
            self.consecutive_failures = 0
            return Action.C
        else:
            self.consecutive_failures += 1
            if self.consecutive_failures >= self.reset_threshold:
                self.consecutive_failures = 0
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_238(BaseStrategy):
    """
    An adaptive and exploitative strategy for the Collective Risk Dilemma. 
    Starts by cooperating, then reciprocates based on the number of previous cooperators. 
    In the last round, uses the trend of the last five rounds to decide.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        if t == 0:
            return Action.C
        elif t == self.n_rounds - 1:
            recent_coops = []
            start = max(0, t - 5)
            for s in range(start, t):
                my_action = history.my_actions[s]
                opp_actions = history.opponent_actions[s]
                total_coop = (1 if my_action else 0) + sum(opp_actions)
                recent_coops.append(total_coop >= self.m)
            num_success = sum(recent_coops)
            total = len(recent_coops)
            if num_success / total > 0.5:
                return Action.C
            else:
                return Action.D
        else:
            s = t - 1
            my_action = history.my_actions[s]
            opp_actions = history.opponent_actions[s]
            total_coop = (1 if my_action else 0) + sum(opp_actions)
            if total_coop >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_239(BaseStrategy):
    """
    This strategy starts by cooperating in the first round. In subsequent rounds,
    it cooperates if at least m players cooperated in the previous round, otherwise it defects.
    In the final round, it always defects to maximize personal payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            prev_round = state.round_number - 1
            my_coop = int(history.my_actions[prev_round])
            opponents_coop = sum(history.opponent_actions[prev_round, :])
            total_coop = my_coop + opponents_coop
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_240(BaseStrategy):
    """
    Adaptive strategy based on cooperation history and game phase to optimize personal payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.exploration_rounds = max(1, int(0.1 * self.n_rounds))
        self.endgame_rounds = max(1, int(0.05 * self.n_rounds))
        self.endgame_start_round = self.n_rounds - self.endgame_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number < self.exploration_rounds:
            return Action.C
        if state.round_number >= self.endgame_start_round:
            return Action.D
        past_coops_meet_count = 0
        for s in range(state.round_number):
            my_c = history.my_actions[s]
            opponents = history.opponent_actions[s]
            n_coops = (1 if my_c else 0) + np.sum(opponents)
            if n_coops >= self.m:
                past_coops_meet_count += 1
        fraction = past_coops_meet_count / state.round_number
        return Action.D if fraction > 0.5 else Action.C

class Strategy_EXPLOITATIVE_241(BaseStrategy):
    """
    Cooperate if at least `m` players cooperated in the last round; otherwise, defect.
    Starts by cooperating in the first round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev = history.my_actions[prev_round]
        opponents_prev = history.opponent_actions[prev_round, :]
        total_coop = int(my_prev) + np.sum(opponents_prev)
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_242(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that balances individual payoff maximization with the necessity of collective action.
    The strategy is based on the average cooperation of other players in previous rounds and adapts its decision accordingly.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if self.n < self.m:
            return Action.D
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.r - 1:
            total_coop = 0
            num_rounds = state.round_number
            for t in range(num_rounds):
                coop = sum(history.opponent_actions[t, :])
                total_coop += coop
            avg_coop = total_coop / num_rounds if num_rounds != 0 else 0
            if avg_coop + 1 >= self.m:
                return Action.C
            else:
                return Action.D
        else:
            total_coop = 0
            num_rounds = state.round_number
            for t in range(num_rounds):
                coop = sum(history.opponent_actions[t, :])
                total_coop += coop
            avg_coop = total_coop / num_rounds if num_rounds != 0 else 0
            if avg_coop >= self.m - 1:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_243(BaseStrategy):
    """
    Exploitative Strategy for Collective Risk Dilemma.
    Cooperates initially, continues if threshold met, otherwise defects.
    Adapts based on observed trends and handles edge cases.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        m = self.game_description.m
        k = self.game_description.k
        last_few_rounds = 2
        if state.round_number >= r - last_few_rounds:
            return Action.D
        if m >= n - 2:
            if history:
                prev_my_action = history.my_actions[-1]
                prev_opp_actions = history.opponent_actions[-1, :]
                prev_coops = prev_my_action + sum(prev_opp_actions)
                if prev_coops >= m:
                    return Action.D
        if history:
            prev_my_action = history.my_actions[-1]
            prev_opp_actions = history.opponent_actions[-1, :]
            prev_coops = prev_my_action + sum(prev_opp_actions)
        else:
            prev_coops = 0
        if prev_coops >= m:
            return Action.C
        else:
            coops_over_time = []
            for t in range(len(history.my_actions)):
                my_coop = history.my_actions[t]
                opp_coop = sum(history.opponent_actions[t, :])
                coops_over_time.append(my_coop + opp_coop)
            if len(coops_over_time) >= 2 and coops_over_time[-1] > coops_over_time[-2]:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_244(BaseStrategy):
    """
    Adaptive Cooperation Based on Recent Performance strategy.
    Cooperates initially and continues if the previous round met the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_prev = history.opponent_actions[prev_round]
        total_coop = my_prev_action + sum(opponents_prev)
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_245(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy for Collective Risk Dilemma.
    Cooperates initially, defects in endgame, and adapts based on historical cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        if t < 5:
            return Action.C
        elif t >= self.game_description.n_rounds - 5:
            return Action.D
        else:
            n_players = self.game_description.n_players
            m = self.game_description.m
            total = 0.0
            for s in range(t):
                my_coop = 1 if history.my_actions[s] else 0
                opponent_coops = np.sum(history.opponent_actions[s, :])
                rate = (my_coop + opponent_coops) / n_players
                total += rate
            avg_coop = total / t
            threshold = m / n_players + 0.1
            if threshold > 1.0:
                threshold = 1.0
            if avg_coop >= threshold:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_246(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma game.
    Uses historical performance to decide actions by comparing expected values of cooperation and defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        q = state.round_number
        p = 0
        for t_prev in range(q):
            other_coop = sum(history.opponent_actions[t_prev, :])
            my_coop = 1 if history.my_actions[t_prev] else 0
            total_coop = other_coop + my_coop
            if total_coop >= self.game_description.m:
                p += 1
        m = self.game_description.m
        k = self.game_description.k
        if q == 0:
            E_coop = 0.0
            E_defect = 0.0
        else:
            probability = p / q
            E_coop = probability * k
            E_defect = probability * (1 + k) + (q - p) / q * 1
        if E_coop > E_defect:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_247(BaseStrategy):
    """
    Exploitative Strategy for Collective Risk Dilemma:
    Cooperate in the first round, then adapt based on the number of cooperators in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            my_c = 1 if my_prev_action else 0
            opponent_prev_actions = history.opponent_actions[prev_round, :]
            opponent_cooperators = np.sum(opponent_prev_actions)
            total_cooperators = my_c + opponent_cooperators
            return Action.C if total_cooperators >= self.m else Action.D

class Strategy_EXPLOITATIVE_248(BaseStrategy):
    """
    Adaptive Cooperation with Last-Round Exploitation Strategy.

    Cooperates in the first round, then adapts based on the number of cooperators in the previous round.
    Continues to cooperate if the threshold m is met; otherwise, defects. Always defects in the last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        previous_round = state.round_number - 1
        my_action = history.my_actions[previous_round]
        opponent_actions = history.opponent_actions[previous_round, :]
        total_coop = sum([my_action]) + sum(opponent_actions)
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_249(BaseStrategy):
    """
    An adaptive strategy that starts by cooperating, then adapts based on the level of cooperation in previous rounds.
    It defects in the last round to maximize personal gain without fear of retaliation, with some randomness added.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        last_round = state.round_number - 1
        opponent_actions_last = history.opponent_actions[last_round]
        sum_opponents_C = np.sum(opponent_actions_last)
        my_last_C = history.my_actions[last_round]
        prev_coop_count = sum_opponents_C + (1 if my_last_C else 0)
        m = self.game_description.m
        if prev_coop_count >= m:
            return Action.C
        elif random.random() < 0.9:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_250(BaseStrategy):
    """
    Adaptive Exploitation Based on Historical Success strategy for Collective Risk Dilemma.
    Cooperates initially, then uses historical success rates to decide actions, with special handling for the last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if t == r - 1:
            window_size = max(1, t // 2)
            start = max(0, t - window_size)
            s_count = 0
            for s in range(start, t):
                cooperators = history.my_actions[s] + np.sum(history.opponent_actions[s])
                if cooperators >= m:
                    s_count += 1
            success_rate = s_count / window_size
        else:
            s_count = 0
            for s in range(t):
                cooperators = history.my_actions[s] + np.sum(history.opponent_actions[s])
                if cooperators >= m:
                    s_count += 1
            success_rate = s_count / t
        threshold = m / n
        if success_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_251(BaseStrategy):
    """
    Adaptive Exploitation Based on Historical Cooperation strategy.
    Cooperates in the first round, then defects if the previous round met or exceeded the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_my_action = history.my_actions[state.round_number - 1]
        prev_opponent_actions = history.opponent_actions[state.round_number - 1, :]
        prev_coop_count = (1 if prev_my_action else 0) + sum(prev_opponent_actions)
        if prev_coop_count >= self.game_description.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_252(BaseStrategy):
    """
    A strategy that balances cooperation and defection based on recent game history.
    Starts with cooperation, adapts based on recent success, and periodically explores.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.past_actions = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        start_round = max(0, state.round_number - 5)
        count_success = 0
        total_rounds = 0
        for t in range(start_round, state.round_number):
            my_act = history.my_actions[t]
            opp_acts = history.opponent_actions[t]
            total_coop = my_act + np.sum(opp_acts)
            if total_coop >= self.game_description.m:
                count_success += 1
            total_rounds += 1
        q = count_success / total_rounds if total_rounds > 0 else 0.0
        default_action = Action.C if q >= 0.5 else Action.D
        if len(history.my_actions) >= 3:
            last_three_my = history.my_actions[-3:]
            all_defected = all((acted == False for acted in last_three_my))
            if all_defected:
                all_below_threshold = True
                for t in range(state.round_number - 3, state.round_number):
                    if t < 0:
                        continue
                    my_act = history.my_actions[t]
                    opp_acts = history.opponent_actions[t]
                    total_coop = my_act + np.sum(opp_acts)
                    if total_coop >= self.game_description.m:
                        all_below_threshold = False
                        break
                if all_below_threshold:
                    return Action.C
        return default_action

class Strategy_EXPLOITATIVE_253(BaseStrategy):
    """A strategy that adapts based on historical cooperation levels, defecting when safe to maximize payoff."""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            previous_round = state.round_number - 1
            opponent_actions_prev = history.opponent_actions[previous_round]
            sum_opponent_prev = np.sum(opponent_actions_prev)
            if sum_opponent_prev >= self.game_description.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_254(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma game.
    Cooperates initially and adjusts based on previous rounds' outcomes to maximize payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defect_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        my_prev_action = history.my_actions[-1]
        opponents_prev_actions = history.opponent_actions[-1]
        sum_opponent_c = np.sum(opponents_prev_actions)
        total_c = my_prev_action + sum_opponent_c
        if total_c >= self.game_description.m:
            self.defect_counter = 0
            return Action.C
        else:
            self.defect_counter += 1
            if self.defect_counter >= 2:
                self.defect_counter = 0
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_255(BaseStrategy):
    """An adaptive strategy for the Collective Risk Dilemma game that balances cooperation and exploitation.
    
    The strategy starts by cooperating in the first round, then tests whether cooperation is necessary by defecting
    in subsequent rounds. It adapts based on whether the threshold of cooperators is met and defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperated_last = False
        self.received_reward_last = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            action = Action.C
            self.cooperated_last = True
            return action
        else:
            if state.round_number == self.game_description.n_rounds - 1:
                action = Action.D
            else:
                if history is not None:
                    prev_action = history.my_actions[-1]
                    last_payoff = history.my_payoffs[-1]
                    if prev_action:
                        self.received_reward_last = last_payoff >= self.game_description.k
                    else:
                        self.received_reward_last = last_payoff >= 1 + self.game_description.k
                else:
                    self.received_reward_last = False
                if self.cooperated_last and self.received_reward_last:
                    action = Action.D
                elif not self.cooperated_last and self.received_reward_last:
                    action = Action.D
                else:
                    action = Action.C
            self.cooperated_last = action == Action.C
            return action

class Strategy_EXPLOITATIVE_256(BaseStrategy):
    """
    An adaptive strategy that starts by defecting and continues if effective.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        defect_count = 0
        successful_defects = 0
        for round in range(state.round_number):
            if not history.my_actions[round]:
                defect_count += 1
                opponents_c = sum(history.opponent_actions[round, :])
                if opponents_c >= self.m:
                    successful_defects += 1
        if defect_count == 0:
            success_rate = 0.5
        else:
            success_rate = successful_defects / defect_count
        if success_rate > 0.5:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_257(BaseStrategy):
    """
    Cooperates initially and in subsequent rounds if enough players met the cooperation threshold m.
    Defects when the previous round did not meet the threshold, then resumes cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishing = False
        self.punishment_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.punishing:
            self.punishment_remaining -= 1
            action = Action.D
            if self.punishment_remaining == 0:
                self.punishing = False
            return action
        else:
            previous_round = state.round_number - 1
            my_coop = history.my_actions[previous_round]
            opponent_coop = np.sum(history.opponent_actions[previous_round])
            total_coop = my_coop + opponent_coop
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                self.punishing = True
                self.punishment_remaining = 1
                return Action.D

class Strategy_EXPLOITATIVE_258(BaseStrategy):
    """
    Adaptive Cooperation Strategy based on past group performance.
    Cooperates in the first round, then continues to Cooperate if at least m players Cooperated previously, else Defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_coop = sum(history.opponent_actions[-1, :])
        my_coop = 1 if history.my_actions[-1] else 0
        total_coop = opponent_coop + my_coop
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_259(BaseStrategy):
    """
    Adaptive Cooperation with Punishment strategy.
    Cooperate if at least m players cooperated in the previous round.
    Cooperate in the first round, last round based on previous.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev = history.my_actions[prev_round]
        opp_prev = history.opponent_actions[prev_round]
        count = (1 if my_prev else 0) + np.sum(opp_prev)
        if count >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_260(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that balances individual and collective gains.
    Cooperates initially, then defects only when enough others cooperated previously.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t_prev = state.round_number - 1
        opponents_prev = history.opponent_actions[t_prev, :]
        my_prev = history.my_actions[t_prev]
        C_count = np.sum(opponents_prev) + my_prev
        m_plus_1 = self.game_description.m + 1
        if C_count >= m_plus_1:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_261(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game where the player
    cooperates initially and adapts based on the number of previous cooperators.
    Cooperates in the first round. In subsequent rounds, defects if the previous
    round met or exceeded the minimum cooperators needed, otherwise continues
    to cooperate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            previous_round = state.round_number - 1
            sum_opponents = np.sum(history.opponent_actions[previous_round])
            my_prev_action = history.my_actions[previous_round]
            total_coops = sum_opponents + (1 if my_prev_action else 0)
            if total_coops >= self.game_description.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_262(BaseStrategy):
    """
    A strategy designed to balance cooperation and exploitation in the Collective Risk Dilemma game.
    It starts by cooperating, continues if enough players cooperate, and defects in the last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.n_rounds - 1:
            return Action.D
        else:
            previous_round = state.round_number - 1
            my_previous_action = history.my_actions[previous_round]
            opponents_previous_actions = history.opponent_actions[previous_round]
            sum_coop = 1 if my_previous_action else 0
            sum_coop += np.sum(opponents_previous_actions)
            if sum_coop >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_263(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that starts with cooperation and adapts based on previous round outcomes.
    Cooperates if the previous round met the cooperation threshold, otherwise defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_actions_prev = history.opponent_actions[prev_round, :]
        total_coop = my_prev_action + sum(opponent_actions_prev)
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_264(BaseStrategy):
    """
    An adaptive strategy that balances cooperation and exploitation based on historical outcomes.
    Cooperates when previous rounds met the minimum cooperators threshold, and uses majority vote for the last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        n_rounds = self.game_description.n_rounds
        m = self.game_description.m
        if state.round_number == n_rounds - 1:
            count_success = 0
            for prev_round in range(state.round_number):
                my_action = history.my_actions[prev_round]
                opponent_actions = history.opponent_actions[prev_round, :]
                total_coop = my_action + sum(opponent_actions)
                if total_coop >= m:
                    count_success += 1
            majority_threshold = (n_rounds - 1) / 2
            if count_success > majority_threshold:
                return Action.C
            else:
                return Action.D
        else:
            prev_round = state.round_number - 1
            my_action = history.my_actions[prev_round]
            opponent_actions = history.opponent_actions[prev_round, :]
            total_coop = my_action + sum(opponent_actions)
            if total_coop >= m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_265(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that starts by Cooperating, 
    adapts based on the success of past rounds, and Defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        successful_rounds = 0
        for round in range(state.round_number):
            my_action = history.my_actions[round]
            opp_actions = history.opponent_actions[round]
            coop_count = int(my_action) + np.sum(opp_actions)
            if coop_count >= self.game_description.m:
                successful_rounds += 1
        proportion = successful_rounds / state.round_number
        if proportion > 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_266(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that balances cooperation and defection.
    It starts by cooperating, then adapts based on previous outcomes to maximize payoffs.
    Includes a recovery mechanism to attempt restarting cooperation after consecutive defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0
        self.max_defections = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev = history.my_actions[prev_round]
            others_prev = history.opponent_actions[prev_round]
            total_coop = sum(others_prev) + (1 if my_prev else 0)
            m = self.game_description.m
            if total_coop >= m:
                self.consecutive_defections = 0
                return Action.C
            else:
                self.consecutive_defections += 1
                if self.consecutive_defections >= self.max_defections:
                    self.consecutive_defections = 0
                    return Action.C
                else:
                    return Action.D

class Strategy_EXPLOITATIVE_267(BaseStrategy):

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            previous_opponent_actions = history.opponent_actions[-1]
            others_c = np.sum(previous_opponent_actions)
            if others_c >= self.game_description.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_268(BaseStrategy):
    """
    Adaptive Cooperation with Final Round Defection strategy for the Collective Risk Dilemma.
    Cooperates initially, adapts based on previous cooperation levels, and defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        """Initializes the strategy with the game description."""
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        """Determines the action based on the current state and history."""
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            t_prev = state.round_number - 1
            my_prev_action = history.my_actions[t_prev]
            opponent_actions_prev = history.opponent_actions[t_prev]
            sum_op_prev = np.sum(opponent_actions_prev)
            total_coop_prev = my_prev_action + sum_op_prev
            if total_coop_prev >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_269(BaseStrategy):
    """
    Strategy that adapts cooperation based on recent collective success.
    Cooperates if previous round met the minimum cooperators needed (m).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev_action = history.my_actions[previous_round]
        others_prev_actions = history.opponent_actions[previous_round]
        coop_count = my_prev_action + np.sum(others_prev_actions)
        if coop_count >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_270(BaseStrategy):
    """
    Strategy: Adaptive Cooperation Based on Historical Performance

    This strategy begins by cooperating in the first round to test others' behavior.
    In subsequent rounds, it cooperates if a majority of previous rounds met the 
    cooperation threshold (m), otherwise it defects. In the last round, it uses 
    the same logic to decide based on historical trends.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        n = self.game_description.n_players
        m = self.m
        count = 0
        prev_rounds = state.round_number
        for pr in range(prev_rounds):
            my_action = history.my_actions[pr]
            opponents_actions = history.opponent_actions[pr, :]
            total_coop = my_action + opponents_actions.sum()
            if total_coop >= m:
                count += 1
        if count * 2 >= prev_rounds:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_271(BaseStrategy):
    """
    Historical Average-Based Cooperation Strategy.

    Cooperates in the first round. In subsequent rounds, cooperates only if adding 
    one's cooperation to the historical average of cooperators meets or exceeds the threshold m.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        total_coops = 0.0
        for t in range(state.round_number):
            my_action = history.my_actions[t]
            opp_coop = sum(history.opponent_actions[t, :])
            coops = (1 if my_action else 0) + opp_coop
            total_coops += coops
        avg_coops = total_coops / state.round_number
        expected_total = avg_coops + 1
        if expected_total >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_272(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma that balances cooperation and defection based on historical outcomes.
    Cooperates in the first round, considers recent success in subsequent rounds, and evaluates overall history in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        n_rounds_total = self.game_description.n_rounds
        m = self.game_description.m
        if current_round == n_rounds_total - 1:
            all_rounds = range(current_round)
            coop_counts = []
            for r in all_rounds:
                opp_actions = history.opponent_actions[r]
                opponent_coop = sum(opp_actions)
                self_coop = 1 if history.my_actions[r] else 0
                total = opponent_coop + self_coop
                coop_counts.append(total)
            success_count = sum((1 for count in coop_counts if count >= m))
            total = len(coop_counts)
            if success_count / total > 0.5:
                return Action.C
            else:
                return Action.D
        else:
            h = 3
            n_prev_rounds = current_round
            start = max(0, n_prev_rounds - h)
            end = n_prev_rounds
            relevant_rounds = range(start, end)
            coop_counts = []
            for r in relevant_rounds:
                opp_actions = history.opponent_actions[r]
                opponent_coop = sum(opp_actions)
                self_coop = 1 if history.my_actions[r] else 0
                total = opponent_coop + self_coop
                coop_counts.append(total)
            success_count = sum((1 for count in coop_counts if count >= m))
            total = len(coop_counts)
            if total == 0:
                return Action.D
            if success_count / total > 0.5:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_273(BaseStrategy):
    """
    Implementation of the Adaptive Punisher with Proportional Cooperation strategy.
    This strategy starts by cooperating, punishes lack of cooperation, and adjusts
    its behavior based on the history of play to maximize payoff while encouraging
    others to cooperate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.n_rounds = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        s = state.round_number
        if s == 0:
            return Action.C
        if s == self.n_rounds - 1:
            prev_s = s - 1
            my_prev = history.my_actions[prev_s]
            opponent_prev = history.opponent_actions[prev_s, :]
            prev_coop = int(my_prev) + int(opponent_prev.sum())
            return Action.C if prev_coop >= self.m else Action.D
        else:
            prev_s = s - 1
            my_prev = history.my_actions[prev_s]
            opponent_prev = history.opponent_actions[prev_s, :]
            prev_coop = int(my_prev) + int(opponent_prev.sum())
            if prev_coop >= self.m:
                return Action.C
            else:
                action = Action.D
                if s >= 2:
                    prev_prev_s = s - 2
                    my_prev_prev = history.my_actions[prev_prev_s]
                    opponent_prev_prev = history.opponent_actions[prev_prev_s, :]
                    prev_prev_coop = int(my_prev_prev) + int(opponent_prev_prev.sum())
                    if prev_prev_coop < self.m and prev_coop < self.m:
                        p = prev_coop / self.n
                        if random.random() < p:
                            action = Action.C
                return action

class Strategy_EXPLOITATIVE_274(BaseStrategy):
    """
    Adaptive cooperation strategy that decides actions based on recent cooperation thresholds.
    Cooperates if more than half of the last three rounds met the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        """
        Initializes the strategy with the game description.
        """
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        """
        Determines the action based on the current state and history.
        """
        if state.round_number == 0:
            return Action.C
        m = self.game_description.m
        met_thresholds = []
        for r in range(state.round_number):
            my_action = history.my_actions[r]
            opponent_actions = history.opponent_actions[r]
            total_coop = my_action + sum(opponent_actions)
            met_thresholds.append(total_coop >= m)
        window_size = 3
        start_index = max(0, len(met_thresholds) - window_size)
        recent_met = met_thresholds[start_index:]
        sum_met = sum(recent_met)
        len_recent = len(recent_met)
        if 2 * sum_met > len_recent:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_275(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that balances cooperation with self-interest.
    Cooperates initially, adapts based on previous cooperation levels, and defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        elif round_number == self.n_rounds - 1:
            return Action.D
        else:
            prev_round = round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opp_prev_actions = history.opponent_actions[prev_round, :]
            total_coop = my_prev_action + sum(opp_prev_actions)
            if total_coop >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_276(BaseStrategy):
    """
    A strategy that starts by Cooperating and then adapts based on the previous round's cooperation level.
    If in the previous round, at least m players Cooperate, the player Cooperates again; otherwise, Defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev = history.my_actions[prev_round]
            opponent_prev = history.opponent_actions[prev_round]
            prev_coop = sum(opponent_prev)
            if my_prev:
                prev_coop += 1
            if prev_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_277(BaseStrategy):
    """
    Adaptive Cooperation with Exploitation (ACE) strategy for the Collective Risk Dilemma.
    Cooperates initially, then adapts based on the proportion of previous rounds meeting the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t_previous = state.round_number
        successful_rounds = 0
        for r in range(t_previous):
            my_action = history.my_actions[r]
            my_coop = 1 if my_action else 0
            opp_coop = np.sum(history.opponent_actions[r])
            total_coop = my_coop + opp_coop
            if total_coop >= self.game_description.m:
                successful_rounds += 1
        p = successful_rounds / t_previous
        if p >= 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_278(BaseStrategy):
    """
    A strategy to balance cooperation and defection in a Collective Risk Dilemma.
    Cooperates initially, defects when possible, and decides the last round based on historical cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        m = self.game_description.m
        if state.round_number == r - 1:
            count = 0
            num_rounds = state.round_number
            for T in range(num_rounds):
                my_action = history.my_actions[T]
                opponents = history.opponent_actions[T, :]
                sum_opponents = np.sum(opponents)
                if my_action + sum_opponents >= m:
                    count += 1
            if count / num_rounds >= 0.5:
                return Action.C
            return Action.D
        else:
            prev_round = state.round_number - 1
            opponents_prev = history.opponent_actions[prev_round, :]
            sum_opponents_prev = np.sum(opponents_prev)
            if sum_opponents_prev >= m:
                return Action.D
            return Action.C

class Strategy_EXPLOITATIVE_279(BaseStrategy):
    """
    A strategy that begins by Cooperating to encourage others and then Adaptively Exploits by Defecting 
    if the historical cooperation rate of others meets the threshold, thus maximizing personal gain.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        sum_coop = np.sum(history.opponent_actions[:state.round_number])
        average_coop = sum_coop / state.round_number
        if average_coop >= self.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_280(BaseStrategy):
    """
    Adaptive Exploitative Strategy (AES)

    This strategy starts by cooperating in the first round to encourage initial cooperation. 
    In subsequent rounds, it calculates the success rate of prior rounds (where the cooperation 
    threshold was met) and decides to cooperate if the success rate is 50% or higher; otherwise, 
    it defects. In the last round, it defects to maximize immediate payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            success_count = 0
            for t in range(state.round_number):
                my_coop = history.my_actions[t]
                opp_coops = np.sum(history.opponent_actions[t, :])
                total_coop = (1 if my_coop else 0) + opp_coops
                if total_coop >= self.game_description.m:
                    success_count += 1
            success_rate = success_count / state.round_number
            return Action.C if success_rate >= 0.5 else Action.D

class Strategy_EXPLOITATIVE_281(BaseStrategy):
    """
    A strategy that cooperates if the number of cooperators in the previous round met the threshold m.
    Cooperates in the first round, then checks the previous round's cooperation level.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_desc = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_last_action = history.my_actions[prev_round]
        opponent_actions = history.opponent_actions[prev_round, :]
        opponent_coop = np.count_nonzero(opponent_actions)
        my_coop = 1 if my_last_action else 0
        total_coop = my_coop + opponent_coop
        if total_coop >= self.game_desc.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_282(BaseStrategy):
    """
    Adaptive Cooperation Based on Past Success (ACPS) strategy.
    Cooperates in the first round, then adapts based on the previous round's cooperation level.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_actions_prev = history.opponent_actions[-1]
        opponent_coop_count = np.sum(opponent_actions_prev)
        my_prev_action = history.my_actions[-1]
        my_coop = 1 if my_prev_action else 0
        total_cooperators = opponent_coop_count + my_coop
        if total_cooperators >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_283(BaseStrategy):
    """
    Adaptive Probe and Cooperate Strategy (APC)
    Balances cooperation and defection based on past success in meeting the minimum cooperators needed.
    Probes periodically to reassess the environment and adapts accordingly to maximize payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.t = 5
        self.s = 3
        self.threshold = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        round_num = state.round_number
        if history is None:
            return Action.C
        t = self.t
        s = self.s
        m = self.game_description.m
        threshold = self.threshold
        probe_round = (round_num - 1) % s == 0 and round_num >= t
        if probe_round:
            return Action.C
        if round_num <= t:
            return Action.C
        else:
            start = max(0, round_num - 1 - t + 1)
            end = round_num - 1
            successes = 0
            for i in range(start, end + 1):
                my_coop = history.my_actions[i]
                opponent_coops = np.sum(history.opponent_actions[i])
                total_coop = my_coop + opponent_coops
                if total_coop >= m:
                    successes += 1
            success_rate = successes / t
            if success_rate >= threshold:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_284(BaseStrategy):
    """
    Reciprocal Cooperation with Forgiveness strategy. Cooperates initially, 
    then cooperates if previous round met the minimum cooperation threshold; 
    otherwise, defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_action = history.my_actions[previous_round]
        my_coop = int(my_action)
        opponent_coops = np.sum(history.opponent_actions[previous_round])
        total_coop = my_coop + opponent_coops
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_285(BaseStrategy):
    """
    A strategy that starts by Cooperating, then adapts based on others' cooperation rates, 
    and defects in the last round to maximize payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        n_players = game_description.n_players
        self.cooperation_counts = [0] * (n_players - 1)
        self.last_processed_round = -1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        s = state.round_number
        n_rounds = self.game_description.n_rounds
        if s == 0:
            return Action.C
        if s == n_rounds - 1:
            return Action.D
        if history is not None:
            if self.last_processed_round < s - 1:
                start_round = self.last_processed_round + 1
                end_round = s - 1
                for round_num in range(start_round, end_round + 1):
                    for player_idx in range(len(self.cooperation_counts)):
                        if history.opponent_actions[round_num, player_idx]:
                            self.cooperation_counts[player_idx] += 1
                self.last_processed_round = end_round
        s_so_far = s
        m = self.game_description.m
        sum_expected = 0.0
        for coop in self.cooperation_counts:
            sum_expected += coop / s_so_far
        if sum_expected >= m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_286(BaseStrategy):
    """
    Adaptive Exploitation Strategy for Collective Risk Dilemma.
    Cooperates initially, defects if cooperation threshold is not met, and re-enters cooperation after a calculated period.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.current_phase = 'coop'
        self.defect_countdown = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            t = state.round_number
            prev_round = t - 1
            my_prev = history.my_actions[prev_round]
            opponent_prev = history.opponent_actions[prev_round]
            sum_opponent_c = np.sum(opponent_prev)
            cooperators = my_prev + sum_opponent_c
            m = self.game_description.m
            n_rounds = self.game_description.n_rounds
            if self.current_phase == 'coop':
                if cooperators >= m:
                    action = Action.C
                else:
                    self.current_phase = 'defect'
                    remaining_rounds = n_rounds - t
                    self.defect_countdown = remaining_rounds // m
                    action = Action.D
            elif self.current_phase == 'defect':
                if self.defect_countdown > 0:
                    action = Action.D
                    self.defect_countdown -= 1
                else:
                    self.current_phase = 'coop'
                    action = Action.C
            return action

class Strategy_EXPLOITATIVE_287(BaseStrategy):
    """
    Adaptive Cooperative Reset (ACR) Strategy for addressing the Collective Risk Dilemma.
    This strategy encourages sustained cooperation by resetting cooperation after a set number of defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_my_action = history.my_actions[-1]
        prev_opponent_actions = history.opponent_actions[-1, :]
        my_contribution = 1 if prev_my_action else 0
        opponent_contribution = sum(prev_opponent_actions)
        total_prev_coop = my_contribution + opponent_contribution
        m = self.game_description.m
        if total_prev_coop >= m:
            self.consecutive_defections = 0
            return Action.C
        else:
            self.consecutive_defections += 1
            if self.consecutive_defections < 2:
                return Action.D
            else:
                self.consecutive_defections = 0
                return Action.C

class Strategy_EXPLOITATIVE_288(BaseStrategy):
    """
    Adaptive Cooperation Based on Historical Success strategy.

    Cooperates in the first round, defects in the last, and adapts based on the success of previous rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            total_prev_rounds = state.round_number
            successful_coops = 0
            for s in range(state.round_number):
                my_action = history.my_actions[s]
                opponent_actions = history.opponent_actions[s, :]
                opp_coop = np.sum(opponent_actions)
                my_coop = 1 if my_action else 0
                total = opp_coop + my_coop
                if total >= self.game_description.m:
                    successful_coops += 1
            success_ratio = successful_coops / total_prev_rounds
            if success_ratio > 0.5:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_289(BaseStrategy):
    """
    A strategy that starts by cooperating and adapts based on the level of cooperation in previous rounds.
    Cooperates if at least m players cooperated in the previous round; otherwise, defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_prev_actions = history.opponent_actions[prev_round, :]
        total_coop = int(my_prev_action) + sum(opponent_prev_actions)
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_290(BaseStrategy):

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.game_description.n_rounds - 1:
            return Action.D
        prev_my_action = history.my_actions[-1]
        prev_others_actions = history.opponent_actions[-1]
        total_coops = prev_my_action + prev_others_actions.sum()
        if total_coops >= self.game_description.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_291(BaseStrategy):
    """
    Adaptive Exploitation Based on Historical Performance strategy.
    Cooperates initially and then adaptively decides to Cooperate or Defect based on historical cooperation rates.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            s = state.round_number
            prev_my_actions = history.my_actions[:s]
            prev_opp_actions = history.opponent_actions[:s, :]
            my_coop = prev_my_actions.astype(int)
            opp_coop = np.sum(prev_opp_actions, axis=1)
            total_coop = my_coop + opp_coop
            E = np.mean(total_coop)
            m = self.game_description.m
            if E >= m:
                return Action.D
            elif E + 1 >= m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_292(BaseStrategy):
    """
    A strategy that starts with cooperation, punishes defection, and includes forgiveness.
    Cooperates initially, punishes if recent cooperation is insufficient, and defects in the last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.window_size = 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        n_rounds = self.game_description.n_rounds
        m = self.game_description.m
        if current_round == 0:
            return Action.C
        if current_round == n_rounds - 1:
            return Action.D
        window_start = max(0, current_round - self.window_size)
        window = range(window_start, current_round)
        enough_coop = False
        for s in window:
            my_action = history.my_actions[s]
            opponent_actions = history.opponent_actions[s]
            coop_count = (1 if my_action else 0) + sum(opponent_actions)
            if coop_count >= m:
                enough_coop = True
                break
        return Action.C if enough_coop else Action.D

class Strategy_EXPLOITATIVE_293(BaseStrategy):
    """
    A strategy that adapts based on the previous round's cooperation level.
    Cooperates in the first round and continues if the minimum cooperators threshold was met.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opp_prev_actions = history.opponent_actions[prev_round]
        total_coop = np.sum(opp_prev_actions) + my_prev_action
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_294(BaseStrategy):
    """
    A strategy that starts with cooperation, adapts based on past successes, 
    and defects in the last round to maximize individual payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            current_round = state.round_number
            successes = 0
            for h in range(current_round):
                my_action = history.my_actions[h]
                opp_actions = history.opponent_actions[h]
                total_coop = int(my_action) + opp_actions.sum()
                if total_coop >= self.game_description.m:
                    successes += 1
            success_ratio = successes / current_round
            if success_ratio > 0.5:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_295(BaseStrategy):
    """
    Cooperate in the first round, then defect if the number of cooperators in the previous round exceeded m; otherwise, continue to cooperate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_prev_actions = history.opponent_actions[prev_round, :]
        prev_cooperators = my_prev_action + sum(opponents_prev_actions)
        m = self.game_description.m
        if prev_cooperators > m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_296(BaseStrategy):
    """
    A strategy that decides whether to cooperate or defect based on the historical success of cooperation.
    Cooperates initially, then continues if at least half of previous rounds successfully met the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        s = 0
        for i in range(state.round_number):
            my_action = history.my_actions[i]
            opponent_actions = history.opponent_actions[i]
            sum_opponent = np.sum(opponent_actions)
            coops = (1 if my_action else 0) + sum_opponent
            if coops >= self.game_description.m:
                s += 1
        success_rate = s / state.round_number
        if success_rate >= 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_297(BaseStrategy):
    """
    An exploitative strategy for the Collective Risk Dilemma game that adapts based on cooperation trends.
    Cooperates initially and switches to defecting if cooperation levels drop below a threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        opponent_actions_prev = history.opponent_actions[last_round]
        my_action_prev = history.my_actions[last_round]
        coop_prev = np.sum(opponent_actions_prev) + (1 if my_action_prev else 0)
        if coop_prev < self.m:
            return Action.D
        x = 3
        rounds_to_check = range(max(0, last_round - (x - 1)), last_round + 1)
        for r in rounds_to_check:
            if r < 0 or r >= len(history.my_actions):
                continue
            opponent_actions_r = history.opponent_actions[r]
            my_action_r = history.my_actions[r]
            coop_r = np.sum(opponent_actions_r) + (1 if my_action_r else 0)
            if coop_r < self.m:
                return Action.D
        return Action.C

class Strategy_EXPLOITATIVE_298(BaseStrategy):
    """
    Exploitative Strategy for Collective Risk Dilemma:
    Cooperates in the first round, defects in the last round, and decides based on the average cooperation rate in previous rounds otherwise.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n_rounds = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        elif current_round == self.n_rounds - 1:
            return Action.D
        else:
            sum_coop = 0.0
            n_prev_rounds = current_round
            for prev_round in range(n_prev_rounds):
                my_action = history.my_actions[prev_round]
                opponents_actions = history.opponent_actions[prev_round]
                opponents_coop = np.sum(opponents_actions)
                sum_coop += my_action + opponents_coop
            if n_prev_rounds == 0:
                avg_coop = 0.0
            else:
                avg_coop = sum_coop / n_prev_rounds
                if avg_coop >= self.m:
                    return Action.D
                else:
                    return Action.C
            return Action.D

class Strategy_EXPLOITATIVE_299(BaseStrategy):
    """
    Cooperates in the first round and in rounds where the previous round's cooperators 
    were not above the threshold; defects otherwise.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_actions_prev = history.opponent_actions[prev_round]
        prev_coop_count = int(my_prev_action) + np.sum(opponent_actions_prev)
        if prev_coop_count > self.game_description.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_300(BaseStrategy):
    """
    An adaptive strategy that responds to the cooperation level of other players,
    defecting when insufficient cooperation is observed, and testing cooperation
    again after a brief defecting period. It also adapts near the game's end to 
    exploit others' actions if they defect more frequently.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defect_remaining = 0
        self.test_coop_next_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.test_coop_next_round:
            self.test_coop_next_round = False
            action_chosen = Action.C
        elif self.defect_remaining > 0:
            action_chosen = Action.D
            self.defect_remaining -= 1
            if self.defect_remaining == 0:
                self.test_coop_next_round = True
        elif history is None:
            action_chosen = Action.D
        else:
            len_my_actions = len(history.my_actions)
            start = max(0, len_my_actions - 3)
            count = 0
            for t in range(start, len_my_actions):
                my_action = history.my_actions[t]
                opp_actions = history.opponent_actions[t]
                total = my_action + np.sum(opp_actions)
                if total >= self.game_description.m:
                    count += 1
            total_rounds = len_my_actions - start
            majority = total_rounds // 2 + 1
            if count >= majority:
                action_chosen = Action.C
            else:
                self.defect_remaining = 2
                action_chosen = Action.D
        if history is not None:
            len_my_actions = len(history.my_actions)
            n = self.game_description.n_players
            if state.round_number >= self.game_description.n_rounds - 3:
                start = max(0, len_my_actions - 3)
                if start < len_my_actions:
                    opp_actions_recent = history.opponent_actions[start:]
                    opp_coop_per_round = np.sum(opp_actions_recent, axis=1)
                    opp_defect_per_round = n - 1 - opp_coop_per_round
                    avg_opp_defect = np.mean(opp_defect_per_round)
                    if avg_opp_defect >= (n - 1) / 2:
                        action_chosen = Action.D
        return action_chosen

class Strategy_EXPLOITATIVE_301(BaseStrategy):
    """
    Adaptive Exploitation strategy for Collective Risk Dilemma. 
    Cooperates initially, punishes defection, adapts exploitation probability based on outcomes,
    and applies endgame tactics in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defect_prob = 0.2

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev_action = history.my_actions[previous_round]
        opponent_coop_prev = history.opponent_actions[previous_round, :].sum()
        total_coop_prev = my_prev_action + opponent_coop_prev
        if my_prev_action == 0:
            if total_coop_prev >= self.game_description.m:
                self.defect_prob = min(1.0, self.defect_prob + 0.05)
            else:
                self.defect_prob = max(0.0, self.defect_prob - 0.05)
        if total_coop_prev < self.game_description.m:
            current_action = Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            n_opponents = self.game_description.n_players - 1
            if n_opponents == 0:
                current_action = Action.D
            else:
                start = max(0, previous_round - 2)
                opponent_acts = history.opponent_actions[start:]
                opponent_coop_rates = []
                for opp in range(n_opponents):
                    opp_actions = opponent_acts[:, opp].astype(float)
                    mean = opp_actions.mean()
                    opponent_coop_rates.append(mean)
                others_expected = sum(opponent_coop_rates)
                if others_expected >= self.game_description.m:
                    current_action = Action.D
                elif others_expected + 1 >= self.game_description.m:
                    current_action = Action.C
                else:
                    current_action = Action.D
        elif random.random() < self.defect_prob:
            current_action = Action.D
        else:
            current_action = Action.C
        return current_action

class Strategy_EXPLOITATIVE_302(BaseStrategy):

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        t_prev = state.round_number - 1
        sum_opponent = np.sum(history.opponent_actions[t_prev])
        my_prev = history.my_actions[t_prev]
        coopers_prev = sum_opponent + my_prev
        m = self.game_description.m
        if coopers_prev >= m:
            if coopers_prev - 1 >= m:
                return Action.D
            else:
                return Action.C
        else:
            return Action.C

class Strategy_EXPLOITATIVE_303(BaseStrategy):
    """
    A strategy that cooperates in the first round and continues to cooperate if a majority 
    of previous rounds met the cooperation threshold, otherwise defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        m = self.game_description.m
        t = state.round_number
        s = 0
        for tau in range(t):
            my_action = history.my_actions[tau]
            my_c = 1 if my_action else 0
            opp_actions = history.opponent_actions[tau]
            opp_c = sum(opp_actions)
            total_c = my_c + opp_c
            if total_c >= m:
                s += 1
        threshold = 0.5 * t
        if s > threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_304(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma where the player Cooperates initially and 
    then uses the average number of Cooperators in past defecting rounds to decide future actions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_actions = history.my_actions
        defects = [r for r in range(len(my_actions)) if not my_actions[r]]
        if not defects:
            return Action.C
        total_coop = 0.0
        for r in defects:
            opp_actions = history.opponent_actions[r, :]
            coop_count = np.sum(opp_actions)
            total_coop += coop_count
        average_coop = total_coop / len(defects)
        if average_coop >= self.game_description.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_305(BaseStrategy):
    """
    Strategy for the Collective Risk Dilemma game. The strategy starts by Cooperating to encourage others, 
    adapts based on whether the minimum cooperation threshold was met in previous rounds, and ends by 
    Cooperating in the final round to maintain a positive contribution.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n_rounds = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.n_rounds - 1:
            return Action.C
        previous_round = state.round_number - 1
        my_prev_action = history.my_actions[previous_round]
        opponent_actions = history.opponent_actions[previous_round]
        prev_coop_count = my_prev_action + sum(opponent_actions)
        same = prev_coop_count >= self.m
        action = my_prev_action if same else not my_prev_action
        return Action.C if action else Action.D

class Strategy_EXPLOITATIVE_306(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma game. It starts by cooperating,
    periodically defects to explore outcomes, and adapts based on the success of previous defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.S = 0
        self.F = 0
        self.exploration_prob = 0.2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and len(history.my_actions) > 0:
            previous_round = len(history.my_actions) - 1
            my_prev_action = history.my_actions[previous_round]
            if my_prev_action == False:
                opponent_actions_prev = history.opponent_actions[previous_round, :]
                sum_coop = np.sum(opponent_actions_prev)
                if sum_coop >= self.game_description.m:
                    self.S += 1
                else:
                    self.F += 1
        if random.random() < self.exploration_prob:
            return Action.D
        elif self.S > self.F:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_307(BaseStrategy):
    """
    Cooperate if at least m players cooperated in the previous round; otherwise, defect.
    This strategy encourages maintaining sufficient cooperation levels while protecting against exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev = history.my_actions[prev_round]
            opponents_prev = history.opponent_actions[prev_round, :]
            total_coop = opponents_prev.sum() + (1 if my_prev else 0)
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_308(BaseStrategy):
    """
    An adaptive strategy that balances cooperation and exploitation based on past success.
    Cooperates initially, continues if past success exceeds a threshold, and defects in final rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number
        if t >= self.r - 2:
            return Action.D
        n = self.n
        m = self.m
        success_count = 0
        for s in range(t):
            my_action = history.my_actions[s]
            opponent_actions = history.opponent_actions[s, :]
            my_coop = 1 if my_action else 0
            opponent_coop = np.sum(opponent_actions)
            total = my_coop + opponent_coop
            if total >= m:
                success_count += 1
        proportion = success_count / t
        threshold = m / n
        if proportion > threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_309(BaseStrategy):
    """
    Adaptive Cooperation with Punishment strategy for Collective Risk Dilemma.
    Cooperates initially, then defects if cooperation drops below threshold. 
    After several defecting rounds, experiments with cooperation to check if others are cooperating.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.is_defecting = False
        self.consecutive_defections = 0
        self.experiment_pending = False
        self.experiment_threshold = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        opp_actions = history.opponent_actions[prev_round, :]
        prev_opponent_C = opp_actions.sum()
        prev_self_C = history.my_actions[prev_round]
        prev_total_C = prev_opponent_C + prev_self_C
        m = self.game_description.m
        if prev_total_C >= m:
            self.is_defecting = False
            self.consecutive_defections = 0
            self.experiment_pending = False
            return Action.C
        elif not self.is_defecting:
            self.is_defecting = True
            self.consecutive_defections = 1
            self.experiment_pending = False
            return Action.D
        elif self.experiment_pending:
            if prev_total_C >= m:
                self.is_defecting = False
                self.consecutive_defections = 0
                self.experiment_pending = False
                return Action.C
            else:
                self.is_defecting = True
                self.consecutive_defections = 1
                self.experiment_pending = False
                return Action.D
        else:
            self.consecutive_defections += 1
            if self.consecutive_defections >= self.experiment_threshold:
                self.experiment_pending = True
                self.consecutive_defections = 0
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_310(BaseStrategy):
    """
    A responsive and adaptive strategy for the Collective Risk Dilemma. 
    Cooperates initially and then bases decisions on the outcomes of the last three rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            start_round = max(0, state.round_number - 3)
            end_round = state.round_number - 1
            cooperation_count = 0
            for r in range(start_round, end_round + 1):
                my_action = history.my_actions[r]
                opponent_actions = history.opponent_actions[r, :]
                my_c = 1 if my_action else 0
                opponent_coop = np.sum(opponent_actions)
                total_coop = my_c + opponent_coop
                if total_coop >= self.game_description.m:
                    cooperation_count += 1
            if cooperation_count >= 2:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_311(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma based on game outcomes.
    Cooperates initially, then adapts based on whether the threshold was met,
    defecting after failures and testing again after consecutive defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defects = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_action_prev = history.my_actions[previous_round]
        opponents_prev = history.opponent_actions[previous_round, :]
        sum_prev = my_action_prev + np.sum(opponents_prev)
        threshold = self.game_description.m
        threshold_met = sum_prev >= threshold
        if threshold_met:
            self.consecutive_defects = 0
            return Action.C
        elif my_action_prev:
            self.consecutive_defects += 1
            return Action.D
        else:
            self.consecutive_defects += 1
            if self.consecutive_defects >= 2:
                self.consecutive_defects = 0
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_312(BaseStrategy):
    """
    Adaptive Collective Exploitation (ACE) strategy for Collective Risk Dilemma.
    
    This strategy balances initial cooperation with adaptive responses based on opponents' behavior,
    ensuring exploitation when possible while protecting against consistent defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_coop_count = 0
        self.opponent_total_actions = 0

    def _get_previous_cooperators(self, history: PlayerHistory) -> int:
        my_prev_action = history.my_actions[-1]
        opponent_prev_actions = history.opponent_actions[-1]
        my_coop = 1 if my_prev_action else 0
        opp_coop = sum(opponent_prev_actions)
        return my_coop + opp_coop

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_opponent_actions = history.opponent_actions[-1]
        count = sum(prev_opponent_actions)
        self.opponent_coop_count += count
        self.opponent_total_actions += len(prev_opponent_actions)
        r = self.game_description.n_rounds
        endgame_threshold = int(r * 0.95)
        if state.round_number >= endgame_threshold:
            prev_coop = self._get_previous_cooperators(history)
            if prev_coop < self.game_description.m:
                return Action.D
        prev_coop = self._get_previous_cooperators(history)
        if prev_coop >= self.game_description.m:
            return Action.C
        if self.opponent_total_actions == 0:
            avg_coop = 0.0
        else:
            avg_coop = self.opponent_coop_count / self.opponent_total_actions
        if avg_coop < 0.3:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_313(BaseStrategy):
    """
    This strategy aims to balance cooperation and exploitation in a Collective Risk Dilemma.
    It cooperates initially to encourage cooperation, adjusts based on past cooperation rates,
    and defects in the final round to maximize immediate payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            prev_round = state.round_number - 1
            prev_my_action = history.my_actions[prev_round]
            prev_opponent_actions = history.opponent_actions[prev_round]
            total_cooperators = prev_my_action + np.sum(prev_opponent_actions)
            if total_cooperators >= self.game_description.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_314(BaseStrategy):
    """
    This strategy begins by cooperating, then adapts based on previous cooperation levels,
    defecting if the threshold isn't met while periodically testing cooperation to encourage others.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        my_coop = 1 if my_prev_action else 0
        opp_actions = history.opponent_actions[prev_round, :]
        opp_coop = np.sum(opp_actions)
        total_coop = my_coop + opp_coop
        if total_coop >= self.m:
            return Action.C
        if (state.round_number + 1) % 3 == 0:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_315(BaseStrategy):
    """
    Exploitative Strategy for Collective Risk Dilemma.
    Cooperate in the first round. In subsequent rounds, continue cooperating if at least m players cooperated in the previous round; otherwise, defect.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev = history.my_actions[prev_round]
            opp_prev = history.opponent_actions[prev_round, :]
            total_coop = my_prev + np.sum(opp_prev)
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_316(BaseStrategy):
    """
    A strategy that cooperates initially and adapts based on the success ratio of past rounds.
    Cooperates if the ratio of successful rounds is below 50%; otherwise, defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        success_count = 0
        for round_num in range(state.round_number):
            my_action = history.my_actions[round_num]
            opponent_actions = history.opponent_actions[round_num]
            total_cooperators = int(my_action) + np.sum(opponent_actions)
            if total_cooperators >= self.m:
                success_count += 1
        success_ratio = success_count / state.round_number
        if success_ratio > 0.5:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_317(BaseStrategy):
    """
    A strategy that adapts cooperation based on historical success.
    Cooperates in the first round. In subsequent rounds, cooperates if the ratio of historically successful rounds meets a threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        successful_rounds = 0
        for s in range(state.round_number):
            my_action = history.my_actions[s]
            opponents_actions = history.opponent_actions[s, :]
            num_cooperators = my_action + sum(opponents_actions)
            if num_cooperators >= m:
                successful_rounds += 1
        ratio = successful_rounds / state.round_number
        threshold = m / n
        if ratio >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_318(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that balances individual incentives 
    with collective outcomes by alternating cooperation based on the previous round's 
    cooperation level.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t_prev = state.round_number - 1
        if t_prev < 0:
            return Action.C
        opponent_actions_prev = history.opponent_actions[t_prev, :]
        opponent_coop = sum(opponent_actions_prev)
        my_coop = history.my_actions[t_prev]
        total_coop = opponent_coop + (1 if my_coop else 0)
        if total_coop >= self.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_319(BaseStrategy):
    """
    A strategy that balances cooperation and defection based on historical cooperation levels.
    Cooperates initially and in rounds where the average of other cooperators is below m; defects otherwise.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        n_previous_rounds = len(history.my_actions)
        sum_C_others = 0.0
        for s in range(n_previous_rounds):
            my_action = history.my_actions[s]
            opp_actions = history.opponent_actions[s, :]
            total_coop = sum(opp_actions) + (1 if my_action else 0)
            if my_action:
                c_others = total_coop - 1
            else:
                c_others = total_coop
            sum_C_others += c_others
        average = sum_C_others / n_previous_rounds
        if average >= self.game_description.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_320(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma that balances cooperation based on recent outcomes. 
    Commences with initial cooperation, continues if the previous round met the cooperation threshold, 
    and periodically probes for renewed cooperation after consecutive failures.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_non_met = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            my_prev = history.my_actions[state.round_number - 1]
            opponent_prev = history.opponent_actions[state.round_number - 1, :]
            total_coop = int(my_prev) + opponent_prev.sum()
            if total_coop >= self.game_description.m:
                self.consecutive_non_met = 0
                return Action.C
            else:
                self.consecutive_non_met += 1
                if self.consecutive_non_met % 3 == 0:
                    return Action.C
                else:
                    return Action.D

class Strategy_EXPLOITATIVE_321(BaseStrategy):
    """
    This strategy uses the Adaptive Cooperation Threshold approach. It Cooperates in the first round. 
    For subsequent rounds, it calculates the ratio of previous rounds where at least m players Cooperated. 
    If this ratio is 50% or higher, it continues to Cooperate; otherwise, it Defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number
        S = 0
        for s in range(t):
            my_c = 1 if history.my_actions[s] else 0
            opponent_c = sum(history.opponent_actions[s])
            total_c = my_c + opponent_c
            if total_c >= self.game_description.m:
                S += 1
        ratio = S / t
        if ratio >= 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_322(BaseStrategy):
    """
    Recent Threshold Cooperator strategy. Cooperates in the first round. In subsequent rounds, cooperates if at least m players cooperated in the previous round; otherwise, defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            previous_round = state.round_number - 1
            my_prev_action = history.my_actions[previous_round]
            opponent_prev_actions = history.opponent_actions[previous_round]
            total_coop = my_prev_action + np.sum(opponent_prev_actions)
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_323(BaseStrategy):
    """
    A strategy that cooperates in the first round, then defects if enough others cooperated in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_opponent_actions = history.opponent_actions[-1, :]
        num_coop_last = np.sum(prev_opponent_actions)
        if num_coop_last >= self.game_description.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_324(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game where players adapt based on others' cooperation history.
    Cooperates in the first round, then calculates expected values to decide actions in subsequent rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        n_opponents = self.n_players - 1
        sum_others = 0.0
        rounds = state.round_number
        for opponent in range(n_opponents):
            coop_actions = history.opponent_actions[:rounds, opponent]
            count_coop = np.count_nonzero(coop_actions)
            rate = count_coop / rounds
            sum_others += rate
        e_c = sum_others + 1.0
        e_d = sum_others
        if e_c >= self.m:
            return Action.C
        elif e_d >= self.m:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_325(BaseStrategy):
    """
    A strategy that balances cooperation and defection based on previous round outcomes.
    Cooperates if continuing cooperation would meet the threshold m.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        s_prev = state.round_number - 1
        other_coop_prev = sum(history.opponent_actions[s_prev])
        if other_coop_prev + 1 >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_326(BaseStrategy):
    """
    A strategy designed for the Collective Risk Dilemma. It initially cooperates, 
    then defects if the previous round met the cooperation threshold, and always 
    defects in the last round to maximize personal gain.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        elif current_round == self.game_description.n_rounds - 1:
            return Action.D
        else:
            last_payoff = history.my_payoffs[-1]
            if last_payoff > 1:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_327(BaseStrategy):
    """
    Adaptive Cooperation Threshold Strategy
    
    This strategy begins with cooperation to test collective cooperation potential.
    It then adapts based on the historical success of cooperation, defecting if 
    cooperation isn't yielding sufficient benefits. In the last round, it defects
    to maximize immediate payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            m = self.game_description.m
            success_count = 0
            for r in range(state.round_number):
                my_action = history.my_actions[r]
                opponents = history.opponent_actions[r, :]
                total_coop = my_action + sum(opponents)
                if total_coop >= m:
                    success_count += 1
            success_ratio = success_count / state.round_number
            return Action.C if success_ratio > 0.5 else Action.D

class Strategy_EXPLOITATIVE_328(BaseStrategy):
    """
    Adaptive Exploitation Based on Historical Cooperation Strategy.
    Cooperates initially, adapts based on previous cooperation levels,
    and defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_action_prev = history.my_actions[prev_round]
            opponent_actions_prev = history.opponent_actions[prev_round, :]
            n_coop = int(my_action_prev) + np.sum(opponent_actions_prev)
            m = self.game_description.m
            if n_coop >= m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_329(BaseStrategy):

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_prev_actions = history.opponent_actions[prev_round]
        my_coop = 1 if my_prev_action else 0
        opponents_coop = sum(opponents_prev_actions)
        total_coop = my_coop + opponents_coop
        m = self.game_description.m
        if total_coop >= m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_331(BaseStrategy):
    """
    A strategy that cooperates in the first round, then defects if the cooperation 
    threshold was met in the previous round, and cooperates otherwise.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        prev_my_action = history.my_actions[last_round]
        opp_actions = history.opponent_actions[last_round]
        opp_coop = np.sum(opp_actions)
        total_coop = opp_coop + (1 if prev_my_action else 0)
        if total_coop >= self.game_description.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_332(BaseStrategy):
    """
    Exploitative strategy for the Collective Risk Dilemma that cooperates initially and adapts based on the necessity of contribution to meet the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_last_action = history.my_actions[prev_round]
        opponents_last = history.opponent_actions[prev_round, :]
        total_C_last = my_last_action + sum(opponents_last)
        if my_last_action:
            threshold_without_me = total_C_last - 1
        else:
            threshold_without_me = total_C_last
        if threshold_without_me >= self.game_description.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_333(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma that balances cooperation and exploitation.
    Cooperates initially, then dynamically adjusts based on past success rates.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.recent_success_rate = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        t = state.round_number
        if t == 0:
            return Action.C
        n = self.game_description.n_players
        m = self.game_description.m
        count_success = 0
        for s in range(t):
            my_action = history.my_actions[s]
            opp_actions = history.opponent_actions[s, :]
            total_C = 1 if my_action else 0
            for opp_act in opp_actions:
                if opp_act:
                    total_C += 1
            if total_C >= m:
                count_success += 1
        success_rate = count_success / t
        s_last = t - 1
        my_act_last = history.my_actions[s_last]
        opp_acts_last = history.opponent_actions[s_last, :]
        total_C_last = 1 if my_act_last else 0
        for opp in opp_acts_last:
            if opp:
                total_C_last += 1
        last_round_success = total_C_last >= m
        is_endgame = (t + 1) / self.game_description.n_rounds > 0.95
        if is_endgame:
            if success_rate >= 0.5:
                return Action.C
            else:
                return Action.D
        else:
            self.recent_success_rate = 0.5 * self.recent_success_rate + 0.5 * success_rate
            if success_rate >= self.recent_success_rate and last_round_success:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_334(BaseStrategy):
    """
    Adaptive Exploitation Strategy for Collective Risk Dilemma:
    - Cooperates initially to set a cooperative tone.
    - Adapts based on historical cooperation levels.
    - Defects in the last round to maximize immediate payoff.
    - Monitors and adapts to avoid being exploited by others.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        n_rounds = self.game_description.n_rounds
        m = self.game_description.m
        n_players = self.game_description.n_players
        if state.round_number == n_rounds - 1:
            return Action.D
        t = state.round_number
        count_cooperators = 0
        for r in range(t):
            my_act = history.my_actions[r]
            opp_acts = history.opponent_actions[r]
            c = 1 if my_act else 0
            c += sum(opp_acts)
            count_cooperators += c
        average_coop = count_cooperators / t
        if average_coop < m:
            return Action.D
        else:
            exploited = False
            exploiting_rounds = []
            for r in range(t):
                if history.my_actions[r]:
                    my_act = 1
                    opp_acts = history.opponent_actions[r]
                    c_total = my_act + sum(opp_acts)
                    if c_total >= m:
                        n_others = len(opp_acts)
                        n_D = n_others - sum(opp_acts)
                        exploiting_rounds.append(n_D)
            if len(exploiting_rounds) > 0:
                avg_D = np.mean(exploiting_rounds)
                avg_exploit_threshold = (n_players - 1) / 2
                if avg_D > avg_exploit_threshold:
                    exploited = True
            if exploited:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_335(BaseStrategy):
    """
    Adaptive Exploitative Strategy for Collective Risk Dilemma.
    Initially cooperates, adapts based on previous rounds' outcomes, and defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            previous_round = state.round_number - 1
            my_prev_action = history.my_actions[previous_round]
            opponent_prev_actions = history.opponent_actions[previous_round]
            sum_opponent_C = np.sum(opponent_prev_actions)
            sum_my_C = 1 if my_prev_action else 0
            total_prev_C = sum_opponent_C + sum_my_C
            if total_prev_C >= self.game_description.m:
                self.consecutive_defections = 0
                return Action.C
            else:
                self.consecutive_defections += 1
                if self.consecutive_defections <= 2:
                    return Action.D
                else:
                    self.consecutive_defections = 0
                    return Action.C

class Strategy_EXPLOITATIVE_336(BaseStrategy):
    """
    An adaptive strategy that cooperates if a majority of recent rounds met the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        successful_rounds = 0
        total_examined = 0
        t = state.round_number
        start = max(0, t - 5)
        for round_number in range(t - 1, start - 1, -1):
            if round_number < 0:
                continue
            my_action = history.my_actions[round_number]
            opponent_actions = history.opponent_actions[round_number]
            coops = 1 if my_action else 0
            coops += np.sum(opponent_actions)
            if coops >= self.game_description.m:
                successful_rounds += 1
            total_examined += 1
        if total_examined == 0:
            return Action.C
        proportion = successful_rounds / total_examined
        if proportion > 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_337(BaseStrategy):
    """
    Exploitative Strategy for Collective Risk Dilemma.
    
    The strategy starts by Cooperating in the first round, then observes the 
    number of cooperators. In subsequent rounds, it Cooperates if at least m players 
    cooperated in the previous round, otherwise Defects. In the last round, it always 
    Defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.r - 1:
            return Action.D
        else:
            prev_round = state.round_number - 1
            opp_coop = np.sum(history.opponent_actions[prev_round])
            my_coop = history.my_actions[prev_round]
            total_coop = opp_coop + my_coop
            if total_coop >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_338(BaseStrategy):
    """
    Exploitative Strategy for Collective Risk Dilemma:
    - Cooperate in the first round.
    - Adapt based on historical success of cooperation.
    - Defect in the last round if historical cooperation success is below 50%.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            total_success = 0
            total_attempts = 0
            for s in range(history.my_actions.size):
                if history.my_actions[s]:
                    opponent_actions = history.opponent_actions[s]
                    sum_opponent = np.sum(opponent_actions)
                    total_coop = 1 + sum_opponent
                    if total_coop >= self.game_description.m:
                        total_success += 1
                    total_attempts += 1
            if total_attempts == 0:
                return Action.D
            success_rate = total_success / total_attempts
            return Action.C if success_rate >= 0.5 else Action.D
        else:
            total_success = 0
            total_attempts = 0
            for s in range(state.round_number):
                if history.my_actions[s]:
                    opponent_actions = history.opponent_actions[s]
                    sum_opponent = np.sum(opponent_actions)
                    total_coop = 1 + sum_opponent
                    if total_coop >= self.game_description.m:
                        total_success += 1
                    total_attempts += 1
            success_rate = total_success / total_attempts if total_attempts > 0 else 0
            return Action.C if success_rate >= 0.5 else Action.D

class Strategy_EXPLOITATIVE_339(BaseStrategy):
    """
    Adaptive cooperation strategy for the Collective Risk Dilemma.
    Cooperates initially and in rounds where recent cooperation has been sufficiently successful,
    defects otherwise, and always defects in the final round to maximize immediate payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        total_coop_rounds = 0
        num_prev_rounds = history.my_actions.shape[0]
        for prev_round in range(num_prev_rounds):
            my_action = history.my_actions[prev_round]
            opponent_actions = history.opponent_actions[prev_round, :]
            total_coop = my_action + np.sum(opponent_actions)
            if total_coop >= self.game_description.m:
                total_coop_rounds += 1
        recent_success = total_coop_rounds / num_prev_rounds
        threshold = 0.5
        if recent_success > threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_340(BaseStrategy):
    """
    Adaptive Cooperate-Punish Strategy.

    The strategy starts by cooperating, monitors cooperation levels, and adapts by either continuing to cooperate or defecting
    for a set number of rounds if cooperation drops below the threshold. It also adjusts behavior in the final rounds based on
    past cooperation rates.

    Attributes:
        n (int): Number of players.
        r (int): Number of rounds.
        m (int): Minimum cooperators needed.
        defecting (bool): Whether the strategy is currently in a defecting phase.
        defect_remaining (int): Number of rounds remaining in the current defecting phase.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.defecting = False
        self.defect_remaining = 0
        self.forgiveness_period = 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        m = self.game_description.m
        if state.round_number >= max(0, r - 3) and state.round_number > 0:
            if history is not None:
                last_round = state.round_number - 1
                if last_round < 0:
                    return Action.C
                else:
                    total_opp_coop = 0
                    total_rounds = 0
                    for rd in range(0, last_round + 1):
                        opp_actions = history.opponent_actions[rd]
                        opp_coop = sum(opp_actions)
                        total_opp_coop += opp_coop
                        total_rounds += 1
                    avg_opp_coop = total_opp_coop / (total_rounds * (n - 1)) if total_rounds > 0 else 0.0
                    if avg_opp_coop > 0.5:
                        return Action.C
                    else:
                        return Action.D
            else:
                return Action.C
        elif self.defecting:
            action = Action.D
            self.defect_remaining -= 1
            if self.defect_remaining <= 0:
                self.defecting = False
            return action
        else:
            last_round = state.round_number - 1
            my_prev_action = history.my_actions[last_round]
            opp_prev_actions = history.opponent_actions[last_round]
            sum_coop = my_prev_action + sum(opp_prev_actions)
            if sum_coop >= m:
                return Action.C
            else:
                self.defecting = True
                self.defect_remaining = self.forgiveness_period
                return Action.D

class Strategy_EXPLOITATIVE_341(BaseStrategy):
    """
    A strategy that balances individual payoff maximization with cooperation based on previous round outcomes.
    Cooperates initially and adapts based on the number of cooperators in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opp_prev_actions = history.opponent_actions[prev_round]
        total_prev_coop = sum(opp_prev_actions) + (1 if my_prev_action else 0)
        if total_prev_coop >= self.game_description.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_342(BaseStrategy):
    """
    This strategy balances cooperation and defection in a repeated Collective Risk Dilemma.
    It cooperates initially, continues cooperating if enough others do, and defects in the last two rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number + 1
        if t > self.game_description.n_rounds - 2:
            return Action.D
        prev_my = history.my_actions[state.round_number - 1]
        prev_opponents = history.opponent_actions[state.round_number - 1]
        my_coop = 1 if prev_my else 0
        others_coop = np.sum(prev_opponents)
        total_coop = my_coop + others_coop
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_343(BaseStrategy):
    """
    A strategy that balances cooperation and defection to maximize individual payoff
    in the Collective Risk Dilemma. Cooperates initially and continues if the 
    cooperation threshold is met, otherwise defects but periodically attempts to 
    reset cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.prev_action = None
        self.coop_after_defect = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            action = Action.C
            self.prev_action = Action.C
            self.coop_after_defect = False
            return action
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opponent_actions_prev = history.opponent_actions[prev_round]
            c_prev = my_prev_action + sum(opponent_actions_prev)
            if c_prev >= self.game_description.m:
                action = Action.C
                self.prev_action = Action.C
                self.coop_after_defect = False
            elif self.prev_action == Action.D and self.coop_after_defect:
                action = Action.C
                self.prev_action = Action.C
                self.coop_after_defect = False
            else:
                action = Action.D
                self.prev_action = Action.D
                self.coop_after_defect = True
            return action

class Strategy_EXPLOITATIVE_344(BaseStrategy):
    """
    Adaptive Exploitation in Collective Risk Dilemma strategy.
    Cooperates in the first round, then decides based on average past cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        sum_coop = 0.0
        for rnd in range(state.round_number):
            my_action = 1 if history.my_actions[rnd] else 0
            opp_actions = history.opponent_actions[rnd, :]
            opp_coop = np.sum(opp_actions)
            sum_coop += my_action + opp_coop
        avg_coop = sum_coop / state.round_number
        if avg_coop >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_345(BaseStrategy):
    """
    This strategy Cooperates in the first round and switches based on the number of Cooperators in the previous round.
    It Cooperates again if at least m players Cooperated previously; otherwise, it Defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.m = game_description.m

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev = history.my_actions[prev_round]
            opp_prev = history.opponent_actions[prev_round, :]
            total_coop = my_prev + opp_prev.sum()
            if total_coop >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_346(BaseStrategy):
    """
    Adaptive Cooperation Threshold (ACT) Strategy for Collective Risk Dilemma.
    Cooperates initially and adapts based on the number of cooperators in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        predecessor_round = state.round_number - 1
        my_prev_action = history.my_actions[predecessor_round]
        opponent_actions = history.opponent_actions[predecessor_round, :]
        count_coop = sum(opponent_actions)
        if my_prev_action:
            count_coop += 1
        if count_coop >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_347(BaseStrategy):
    """
    This strategy starts with cooperation to gauge others' willingness.
    Subsequent decisions adapt based on the average past cooperation,
    cooperating if the average meets or exceeds the threshold m.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number
        total_coops = 0
        for round_num in range(t):
            my_action = history.my_actions[round_num]
            opponent_actions = history.opponent_actions[round_num, :]
            total_coops += my_action + opponent_actions.sum()
        avg_coop = total_coops / t
        if avg_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_348(BaseStrategy):
    """
    This strategy begins by cooperating in the first round. In subsequent rounds, it estimates the likelihood of each opponent cooperating based on their past actions. It uses these estimates to decide whether to cooperate or defect, aiming to maximize its own payoff by contributing only when necessary and exploiting when possible.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_actions = history.opponent_actions
        n_opponents = self.game_description.n_players - 1
        e_defect = 0.0
        for j in range(n_opponents):
            coop_prob = opponent_actions[:, j].astype(float).mean()
            e_defect += coop_prob
        e_coop = e_defect + 1.0
        m = self.game_description.m
        if e_coop >= m:
            if e_defect < m:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_349(BaseStrategy):
    """
    An adaptive strategy that maintains cooperation when beneficial and attempts 
    to restart it after periods of insufficient participation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.s = 3
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        my_prev_action = history.my_actions[last_round]
        opponent_prev_actions = history.opponent_actions[last_round]
        total_coop_last = sum(opponent_prev_actions) + (1 if my_prev_action else 0)
        if total_coop_last >= self.m:
            self.consecutive_defections = 0
            return Action.C
        else:
            self.consecutive_defections += 1
            if self.consecutive_defections >= self.s:
                self.consecutive_defections = 0
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_350(BaseStrategy):
    """
    An exploitative strategy for the Collective Risk Dilemma that balances
    maximizing individual gain with maintaining sufficient cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.buffer = 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        if prev_round < 0:
            prev_round = 0
        if history is None:
            return Action.C
        if prev_round >= 0:
            my_prev_action = history.my_actions[prev_round]
            opponent_prev_actions = history.opponent_actions[prev_round]
            if my_prev_action == Action.D:
                total_cooperators = (1 if my_prev_action == Action.C else 0) + np.sum(opponent_prev_actions)
                if total_cooperators < self.game_description.m:
                    return Action.C
        my_prev_action = history.my_actions[prev_round] if history is not None else None
        if my_prev_action is None:
            return Action.C
        total_cooperators = (1 if my_prev_action == Action.C else 0) + np.sum(history.opponent_actions[prev_round])
        if total_cooperators >= self.game_description.m + self.buffer:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_351(BaseStrategy):
    """
    An exploitative strategy for the Collective Risk Dilemma that cooperates initially and adapts based on others' behavior.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        n_players = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        round_number = state.round_number
        is_last_round = round_number == r - 1
        if is_last_round:
            adjusted_threshold = m - n_players // 10
            cooperation_threshold = adjusted_threshold
        else:
            cooperation_threshold = m
        expected_cooperators = 0
        if history is None:
            return Action.D
        opponent_actions = history.opponent_actions
        num_prev_rounds = round_number
        for opponent_idx in range(opponent_actions.shape[1]):
            actions = opponent_actions[:, opponent_idx]
            coop_count = np.sum(actions).item()
            if num_prev_rounds == 0:
                coop_rate = 0.0
            else:
                coop_rate = coop_count / num_prev_rounds
            if coop_rate > 0.5:
                expected_cooperators += 1
        if expected_cooperators + 1 >= cooperation_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_352(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that balances cooperation and defection based on past behavior.
    Cooperates in the first round, defects in the last round, and decides based on the success rate of previous rounds otherwise.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        r = self.game_description.n_rounds
        m = self.game_description.m
        if t == 0:
            return Action.C
        elif t == r - 1:
            return Action.D
        else:
            if history is None:
                return Action.C
            success_count = 0
            for x in range(t):
                my_action = history.my_actions[x]
                opp_actions = history.opponent_actions[x]
                total_C = my_action + opp_actions.sum()
                if total_C >= m:
                    success_count += 1
            threshold = t / 2
            if success_count > threshold:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_353(BaseStrategy):
    """
    Exploitative Cooperation Based on Historical Rates strategy for the Collective Risk Dilemma.
    Cooperates initially to establish trust, then uses others' historical cooperation rates to decide actions.
    Defects when the expected number of cooperators from others meets or exceeds the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n_players = game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        num_rounds = state.round_number
        opponent_actions = history.opponent_actions
        num_opponents = opponent_actions.shape[1]
        expected_coop = 0.0
        for opp in range(num_opponents):
            coop_count = np.sum(opponent_actions[:, opp])
            rate = coop_count / num_rounds
            expected_coop += rate
        if expected_coop >= self.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_354(BaseStrategy):
    """Exploitative Strategy for Collective Risk Dilemma.
    
    This strategy starts by Cooperating in the first round. In subsequent rounds, 
    it Defects if the number of Cooperators in the previous round was at least m, 
    otherwise Cooperates.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            s_prev = state.round_number - 1
            my_prev = history.my_actions[s_prev]
            opponents_prev = history.opponent_actions[s_prev, :]
            count = int(my_prev) + int(opponents_prev.sum())
            if count >= self.game_description.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_355(BaseStrategy):
    """
    Adaptive Threshold Exploitation strategy for the Collective Risk Dilemma.
    
    This strategy begins by cooperating in the first round to test others' willingness to cooperate.
    In subsequent rounds, it calculates the cooperation rate of other players and decides to cooperate or defect based on predefined thresholds.
    It defects in the final round to maximize immediate payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        elif round_number == self.r - 1:
            return Action.D
        else:
            if history is None:
                return Action.D
            prev_rounds = round_number
            last_round_actions = history.opponent_actions[round_number - 1]
            c_prev = np.sum(last_round_actions)
            sum_coops = np.sum(history.opponent_actions)
            n_opponents = self.n - 1
            avg_c = sum_coops / (prev_rounds * n_opponents) if prev_rounds * n_opponents != 0 else 0.0
            threshold = self.m / self.n
            if c_prev >= self.m:
                return Action.C
            elif avg_c > threshold:
                if threshold == 0:
                    p = 1.0
                else:
                    x = avg_c / threshold
                    p = x
                    p = max(0.0, min(1.0, p))
                if random.random() < p:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D

class Strategy_EXPLOITATIVE_356(BaseStrategy):
    """
    An adaptive strategy that starts with cooperation and adapts based on whether the cooperation threshold was met in the previous round.
    Cooperates if last action was C and threshold was met, otherwise defects or vice versa.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        last_action = history.my_actions[prev_round]
        opponent_actions_last = history.opponent_actions[prev_round, :]
        my_coop = 1 if last_action else 0
        opponent_coop = opponent_actions_last.sum()
        coop_count = my_coop + opponent_coop
        met_threshold = coop_count >= self.game_description.m
        if last_action:
            return Action.C if met_threshold else Action.D
        else:
            return Action.D if met_threshold else Action.C

class Strategy_EXPLOITATIVE_357(BaseStrategy):
    """A strategy that balances individual payoff maximization with collective cooperation to meet reward thresholds."""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_prev_action = history.my_actions[-1]
        opponent_prev_actions = history.opponent_actions[-1, :]
        sum_opponent_C = np.sum(opponent_prev_actions)
        x_prev = sum_opponent_C + (1 if my_prev_action else 0)
        m = self.game_description.m
        if x_prev >= m + 1:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_359(BaseStrategy):
    """
    Implement the Exploitative Strategy for Collective Risk Dilemma.
    Cooperates initially, then adapts based on previous rounds, and defects in the end if uncertain.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        game = self.game_description
        if t < 3:
            return Action.C
        elif t == game.n_rounds - 1:
            meet_count = 0
            for i in range(len(history.my_actions)):
                my_action = history.my_actions[i]
                opp_actions = history.opponent_actions[i, :]
                cooperators = sum(opp_actions) + (1 if my_action else 0)
                if cooperators >= game.m:
                    meet_count += 1
            total_rounds = len(history.my_actions)
            if meet_count / total_rounds >= 0.5:
                return Action.C
            else:
                return Action.D
        else:
            prev_round = len(history.my_actions) - 1
            my_prev_action = history.my_actions[prev_round]
            opp_prev_actions = history.opponent_actions[prev_round, :]
            cooperators_prev = sum(opp_prev_actions) + (1 if my_prev_action else 0)
            if cooperators_prev >= game.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_360(BaseStrategy):
    """
    A Collective Tit-for-Tat strategy for the Collective Risk Dilemma game.
    Cooperates in the first round, then cooperates if at least m players cooperated in the previous round, otherwise defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opponents_prev_actions = history.opponent_actions[prev_round, :]
            total_cooperators = my_prev_action + sum(opponents_prev_actions)
            return Action.C if total_cooperators >= self.m else Action.D

class Strategy_EXPLOITATIVE_361(BaseStrategy):
    """
    Implements the Adaptive Cooperation with Periodic Testing (ACPT) strategy.
    This strategy starts with cooperation, continues if the cooperation threshold
    is met, defects if not for up to three rounds, then tests cooperation again.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        t_prev = state.round_number - 1
        my_prev_action = history.my_actions[t_prev]
        opp_prev_actions = history.opponent_actions[t_prev]
        sum_coop_prev = my_prev_action + np.sum(opp_prev_actions)
        met_prev = sum_coop_prev >= self.game_description.m
        if met_prev:
            self.consecutive_defections = 0
            return Action.C
        elif self.consecutive_defections < 3:
            self.consecutive_defections += 1
            return Action.D
        else:
            self.consecutive_defections = 0
            return Action.C

class Strategy_EXPLOITATIVE_362(BaseStrategy):
    """
    Adaptive Cooperate-and-Punish with Periodic Forgiveness strategy.
    Cooperates initially and in every 3 rounds. Punishes by defecting if previous round had insufficient cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number % 3 == 0 and state.round_number != 0:
            return Action.C
        previous_round = state.round_number - 1
        opponents_last_actions = history.opponent_actions[previous_round, :]
        my_last_action = history.my_actions[previous_round]
        n_coop_opponents = sum(opponents_last_actions)
        my_coop = 1 if my_last_action else 0
        total_coop = n_coop_opponents + my_coop
        m = self.game_description.m
        if total_coop >= m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_363(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that balances cooperation and strategic defection.
    It starts with initial cooperation, adapts based on recent outcomes, punishes non-cooperation,
    and defects in the final rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number >= self.game_description.n_rounds - 2:
            return Action.D
        if history is not None:
            prev_round = state.round_number - 1
            if not history.my_actions[prev_round]:
                my_prev_action = history.my_actions[prev_round]
                opponent_actions_prev = history.opponent_actions[prev_round]
                total_coop_prev = my_prev_action + sum(opponent_actions_prev)
                if total_coop_prev < self.game_description.m:
                    return Action.C
        considered_rounds = range(max(0, state.round_number - 3), state.round_number)
        count_threshold = 0
        for r in considered_rounds:
            my_action = history.my_actions[r]
            opponent_actions = history.opponent_actions[r]
            total_coop = my_action + sum(opponent_actions)
            if total_coop >= self.game_description.m:
                count_threshold += 1
        total_considered = len(considered_rounds)
        if total_considered == 0:
            return Action.C
        if count_threshold > total_considered / 2:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_364(BaseStrategy):
    """
    Strategy that cooperates only when the average number of cooperators in previous rounds is exactly m-1; otherwise, defects if the average is >=m, or defects otherwise.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_actions = history.opponent_actions
        prev_cooperations = np.sum(opponent_actions, axis=1)
        expected_st = np.mean(prev_cooperations)
        m = self.game_description.m
        if expected_st >= m:
            return Action.D
        elif expected_st == m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_365(BaseStrategy):
    """
    Cooperates in the first round, then defects if at least m players cooperated in the previous round, otherwise continues to cooperate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_actions_prev = history.opponent_actions[prev_round, :]
        total_coop = int(my_prev_action) + opponents_actions_prev.sum()
        if total_coop >= self.game_description.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_366(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma game that balances cooperation and exploitation.
    The strategy is designed to encourage cooperation while allowing for strategic defection to maximize payoffs.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_successes = 0
        self.force_cooperate_next = False
        self.endgame_start_round = game_description.n_rounds - 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or state.round_number >= self.endgame_start_round:
            return Action.C
        if self.force_cooperate_next:
            self.force_cooperate_next = False
            return Action.C
        last_round = state.round_number - 1
        if history is None:
            last_round_met = False
        else:
            my_last_action = history.my_actions[last_round]
            opp_last_actions = history.opponent_actions[last_round, :]
            total_coop = my_last_action + opp_last_actions.sum()
            last_round_met = total_coop >= self.game_description.m
        if last_round_met:
            self.consecutive_successes += 1
            if self.consecutive_successes >= 3:
                base_prob = 0.1
                steps = self.consecutive_successes - 3
                defect_prob = base_prob + 0.05 * steps
                defect_prob = min(defect_prob, 0.5)
                if random.random() < defect_prob:
                    return Action.D
                else:
                    return Action.C
            else:
                return Action.C
        else:
            self.consecutive_successes = 0
            self.force_cooperate_next = True
            return Action.C

class Strategy_EXPLOITATIVE_367(BaseStrategy):
    """
    Cooperate If Trending Towards Threshold (CITT) Strategy.

    This strategy cooperates in the first round, defects in the last round, and 
    cooperates in middle rounds if the average number of cooperators in previous 
    rounds is at least the minimum required. Otherwise, it defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        n_rounds = state.round_number
        if n_rounds == 0:
            return Action.C
        previous_coop_counts = []
        for t_round in range(n_rounds):
            if t_round >= history.my_actions.size:
                break
            my_coop = history.my_actions[t_round]
            opponent_coop = np.sum(history.opponent_actions[t_round, :])
            total_coop = my_coop + opponent_coop
            previous_coop_counts.append(total_coop)
        if not previous_coop_counts:
            return Action.C
        avg_coop = sum(previous_coop_counts) / len(previous_coop_counts)
        if avg_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_368(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game. Cooperates in the first round, 
    cooperates in middle rounds if at least m players cooperated previously, and defects 
    in the last round and when insufficient players cooperate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            prev_round = state.round_number - 1
            my_prev = history.my_actions[prev_round]
            opponent_actions_prev = history.opponent_actions[prev_round]
            my_coop = 1 if my_prev else 0
            opponent_coop = np.sum(opponent_actions_prev)
            total_prev_coop = my_coop + opponent_coop
            if total_prev_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_369(BaseStrategy):
    """
    An adaptive strategy balancing cooperation and self-interest in the Collective Risk Dilemma.
    Cooperates initially, continues if enough others cooperate, and defects otherwise.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            n_prev_rounds = state.round_number
            met_rounds = 0
            for r in range(n_prev_rounds):
                my_action = history.my_actions[r]
                opp_actions = history.opponent_actions[r, :]
                total_c = my_action + np.sum(opp_actions)
                if total_c >= self.game_description.m:
                    met_rounds += 1
            if met_rounds > n_prev_rounds / 2:
                return Action.C
            else:
                return Action.D
        else:
            my_prev_action = history.my_actions[-1]
            opp_prev_actions = history.opponent_actions[-1, :]
            total_c_prev = my_prev_action + np.sum(opp_prev_actions)
            if total_c_prev >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_370(BaseStrategy):
    """
    A strategy that begins by cooperating, then cooperates or defects based on the previous round's cooperation level,
    and defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        n_rounds = self.game_description.n_rounds
        if current_round == 0:
            return Action.C
        if current_round == n_rounds - 1:
            return Action.D
        prev_round = current_round - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_actions_prev = history.opponent_actions[prev_round, :]
        cooperators = (1 if my_prev_action else 0) + np.sum(opponent_actions_prev)
        if cooperators >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_371(BaseStrategy):
    """
    Exploitative strategy for the Collective Risk Dilemma.
    It starts with cooperation and then defects if the cooperation rate is sufficiently high.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number
        T = 0
        for r in range(t):
            my_action = history.my_actions[r]
            opponent_actions = history.opponent_actions[r, :]
            sum_coop = my_action + np.sum(opponent_actions)
            if sum_coop >= self.m:
                T += 1
        average_coop = T / t
        threshold = 0.8
        if average_coop >= threshold:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_372(BaseStrategy):
    """
    A strategy that starts by cooperating, defects in the final round, and adapts based on previous cooperation levels.
    Cooperates if the previous round did not meet the cooperation threshold, otherwise defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            my_last = history.my_actions[-1]
            opponent_last = history.opponent_actions[-1]
            sum_coop = 1 if my_last else 0
            sum_coop += np.sum(opponent_last)
            if sum_coop >= self.game_description.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_373(BaseStrategy):
    """
    A strategy that cooperates based on the estimated likelihood of other players' cooperation.
    It uses historical data to determine if the current cooperation is necessary to meet the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n_players = game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number
        if t == 0:
            return Action.C
        opponent_actions = history.opponent_actions
        sum_coop = np.sum(opponent_actions[:t], axis=0)
        rates = sum_coop / t
        expected = np.sum(rates)
        if expected >= self.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_374(BaseStrategy):
    """
    Adaptive Exploitation with Threshold Response strategy for Collective Risk Dilemma.
    Cooperates initially, adapts based on previous round's cooperation, and defects in the last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.n_rounds - 1:
            return Action.D
        prev_round = state.round_number - 1
        my_actions = history.my_actions[prev_round]
        opponents_actions = history.opponent_actions[prev_round]
        total_coop = my_actions + opponents_actions.sum()
        if total_coop >= self.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_375(BaseStrategy):
    """
    A strategy that starts with cooperation and adapts based on the number of cooperators in the previous round.
    It continues to cooperate if at least m players cooperated in the previous round; otherwise, it defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            my_prev = history.my_actions[-1]
            opponent_prev = history.opponent_actions[-1]
            self_coop = 1 if my_prev else 0
            opponent_coop = opponent_prev.sum()
            total_coop = self_coop + opponent_coop
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_376(BaseStrategy):
    """
    Adaptive Exploitation Strategy for Collective Risk Dilemma.
    Cooperates initially, then uses the outcome of the last round to decide actions.
    Defects if the threshold isn't met, then forces cooperation in the next round.
    Defects in the last round to maximize personal payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.force_next_coop = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        if self.force_next_coop:
            action = Action.C
            self.force_next_coop = False
            return action
        last_round = state.round_number - 1
        my_prev_action = history.my_actions[last_round]
        others_prev_actions = history.opponent_actions[last_round]
        total_coop_prev_round = (1 if my_prev_action else 0) + sum(others_prev_actions)
        threshold = self.game_description.m
        threshold_met = total_coop_prev_round >= threshold
        if threshold_met:
            action = Action.C
        else:
            action = Action.D
            self.force_next_coop = True
        return action

class Strategy_EXPLOITATIVE_377(BaseStrategy):
    """
    A strategy that balances cooperation and defection based on the necessity of cooperation in the past rounds.
    Cooperates initially, then adapts based on the frequency of necessary contributions and recent outcomes.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history.my_actions[-1]:
            t_round = len(history.my_actions) - 1
            sum_others = sum(history.opponent_actions[t_round])
            total_coop = sum_others
            if total_coop < self.game_description.m:
                return Action.C
        max_round = len(history.my_actions)
        window_start = max(0, max_round - 5)
        count = 0
        num_rounds = 0
        for t_round in range(window_start, max_round):
            num_rounds += 1
            if history.my_actions[t_round]:
                sum_others = sum(history.opponent_actions[t_round])
                if sum_others < self.game_description.m:
                    count += 1
        if num_rounds == 0:
            necessary_rate = 0.0
        else:
            necessary_rate = count / num_rounds
        if necessary_rate < 0.3:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_378(BaseStrategy):
    """
    A strategy that cooperates if at least 50% of previous rounds met the minimum cooperators threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        num_past_rounds = current_round
        success_count = 0
        for past_round in range(num_past_rounds):
            my_action = history.my_actions[past_round]
            opponent_coops = np.sum(history.opponent_actions[past_round, :])
            total_coops = my_action + opponent_coops
            if total_coops >= self.game_description.m:
                success_count += 1
        threshold = 0.5
        success_rate = success_count / num_past_rounds
        return Action.C if success_rate >= threshold else Action.D

class Strategy_EXPLOITATIVE_379(BaseStrategy):
    """
    A strategy that begins by Cooperating and then decides to Cooperate or Defect based on historical cooperation levels.
    The decision is made by checking if more than half of the previous rounds met the minimum cooperators threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        m = self.game_description.m
        count_coop = 0
        total_rounds = state.round_number
        for t in range(total_rounds):
            my_action = history.my_actions[t]
            opponent_coop = sum(history.opponent_actions[t])
            total = int(my_action) + opponent_coop
            if total >= m:
                count_coop += 1
        if count_coop > total_rounds / 2:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_380(BaseStrategy):
    """
    Strategy to maximize individual payoff by cooperating when the previous round's 
    cooperators met the threshold, and defecting otherwise.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_action = history.my_actions[-1]
        opponents_actions = history.opponent_actions[-1]
        own_coop = 1 if my_action else 0
        others_coop = sum(opponents_actions)
        total_coop = own_coop + others_coop
        m = self.game_description.m
        if total_coop >= m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_381(BaseStrategy):
    """
    History-Based Cooperation with Threshold Strategy for Collective Risk Dilemma.

    This strategy cooperates in the first round and then checks the number of players who cooperated in the previous round. 
    If the number of cooperators meets or exceeds the threshold m, the player continues to cooperate. Otherwise, the player defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round_idx = state.round_number - 1
        my_prev_action = history.my_actions[last_round_idx]
        others_prev_actions = history.opponent_actions[last_round_idx, :]
        count_cooperators = int(my_prev_action) + np.sum(others_prev_actions)
        if count_cooperators >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_221(BaseStrategy):
    """
    Adaptive strategy to ensure maximum payoffs by maintaining the cooperation threshold.
    The strategy starts with all players Cooperating. If cooperation in any round 
    drops below the threshold, the players with the lowest indices will Cooperate 
    in the next round to meet the threshold again.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.index = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_coop = 0
        if history is not None:
            prev_my_action = history.my_actions[-1]
            prev_others_actions = history.opponent_actions[-1]
            prev_coop = sum(prev_others_actions) + (1 if prev_my_action else 0)
        if prev_coop >= self.m:
            return Action.C
        elif self.index <= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_281(BaseStrategy):

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.is_punishing = False
        self.punishment_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opponents_prev = history.opponent_actions[prev_round]
            count_prev = (1 if my_prev_action else 0) + np.sum(opponents_prev)
            m = self.game_description.m
            if count_prev >= m:
                return Action.C
            else:
                return Action.D
        elif self.is_punishing:
            self.punishment_remaining -= 1
            if self.punishment_remaining <= 0:
                self.is_punishing = False
            return Action.D
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opponents_prev = history.opponent_actions[prev_round]
            count_prev = (1 if my_prev_action else 0) + np.sum(opponents_prev)
            m = self.game_description.m
            if count_prev >= m:
                return Action.C
            else:
                r = self.game_description.n_rounds
                m_val = self.game_description.m
                T = 2.0 * r / m_val
                T_ceil = math.ceil(T)
                remaining_rounds = r - state.round_number
                T_use = min(T_ceil, remaining_rounds)
                if T_use < 1:
                    T_use = 1
                self.is_punishing = True
                self.punishment_remaining = T_use
                return Action.D

class Strategy_COLLECTIVE_460(BaseStrategy):
    """
    Adaptive Cooperation with Forgiveness strategy for the Collective Risk Dilemma game.
    Cooperates initially, and continues if enough players cooperate. Defects for a period if cooperation is insufficient, then forgives and tries again.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.f = game_description.m - 1
        self.defect_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.defect_remaining > 0:
            action = Action.D
            self.defect_remaining -= 1
        else:
            previous_round = state.round_number - 1
            my_prev_action = history.my_actions[previous_round]
            opponent_actions = history.opponent_actions[previous_round, :]
            total_coop = my_prev_action + opponent_actions.sum()
            if total_coop >= self.game_description.m:
                action = Action.C
            else:
                action = Action.D
                self.defect_remaining = self.f
        return action

class Strategy_COLLECTIVE_490(BaseStrategy):
    """
    An adaptive strategy that balances cooperation and self-interest across different game phases.
    It transitions through initial cooperation, recent history evaluation, and endgame optimization.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m_threshold = game_description.m
        self.k_reward = game_description.k
        self.h_initial = min(game_description.n_rounds // 4, 1)
        self.w_recent = 3
        self.s_threshold = 0.8
        self.history = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if history is None:
            return Action.D
        if current_round < self.h_initial:
            return Action.C
        if current_round >= self.n_rounds - self.w_recent:
            self.endgame_phase(history, current_round)
        else:
            self.recent_history_phase(history)
        return Action.C

    def endgame_phase(self, history: PlayerHistory, current_round: int) -> Action:
        recent_rounds = min(len(history.my_actions), self.w_recent)
        start = max(0, len(history.my_actions) - recent_rounds)
        recent_my = sum(history.my_actions[start:])
        opponent_actions = history.opponent_actions[start:]
        recent_opponent = np.sum(opponent_actions)
        total_coop = recent_my + recent_opponent
        w_used = recent_rounds
        if w_used == 0:
            return Action.D
        average_coop = total_coop / w_used
        if average_coop + 1 >= self.m_threshold:
            return Action.C
        else:
            return Action.D

    def recent_history_phase(self, history: PlayerHistory) -> Action:
        recent_rounds = min(len(history.my_actions), self.w_recent)
        start = max(0, len(history.my_actions) - recent_rounds)
        recent_my = sum(history.my_actions[start:])
        opponent_actions = history.opponent_actions[start:]
        recent_opponent = np.sum(opponent_actions)
        total_coop = recent_my + recent_opponent
        w_used = recent_rounds
        if w_used == 0:
            return Action.D
        average_coop = total_coop / (w_used * self.n_players)
        if average_coop >= self.s_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_7(BaseStrategy):
    """
    Adaptive Exploitation with Forgiveness Strategy for Collective Risk Dilemma.
    Cooperates initially, then defects if average cooperation meets threshold.
    Forgiveness mechanism helps re-cooperate if cooperation drops.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.consecutive_below_m = 0

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        total_coop = 0.0
        for r in range(state.round_number):
            my_coop = 1 if history.my_actions[r] else 0
            opp_coop = sum(history.opponent_actions[r, :])
            total_coop += my_coop + opp_coop
        avg_coop = total_coop / state.round_number
        is_last_round = state.round_number == self.r - 1
        self.consecutive_below_m = 0 if avg_coop >= self.m else self.consecutive_below_m + 1
        if self.consecutive_below_m >= 3:
            return Action.C
        if is_last_round:
            if avg_coop >= self.m:
                return Action.D
            else:
                return Action.C
        if avg_coop >= self.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_208(BaseStrategy):
    """
    Adaptive Cooperation Based on Historical Performance strategy.
    Cooperates initially, then decides based on historical success ratio.
    Switches to Defect in the endgame (last 10% of rounds).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        cutoff = self.n_rounds - math.ceil(0.1 * self.n_rounds)
        if state.round_number >= cutoff:
            return Action.D
        s = 0
        for t in range(state.round_number):
            my_action = history.my_actions[t]
            opponent_actions = history.opponent_actions[t]
            num_coop = my_action + np.sum(opponent_actions)
            if num_coop >= self.m:
                s += 1
        ratio = s / state.round_number
        if ratio >= 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_233(BaseStrategy):
    """
    Adaptive Threshold Cooperation with Exploration strategy for the Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history_met = []
        self.processed_rounds = -1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        if history is not None and current_round > self.processed_rounds + 1:
            for r in range(self.processed_rounds + 1, current_round):
                opponent_actions_in_round = history.opponent_actions[r]
                my_action_in_round = history.my_actions[r]
                opp_coop = np.sum(opponent_actions_in_round)
                my_coop = 1 if my_action_in_round else 0
                total_coop = opp_coop + my_coop
                if total_coop >= self.game_description.m:
                    self.history_met.append(1)
                else:
                    self.history_met.append(0)
            self.processed_rounds = current_round - 1
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        window_size = 3
        relevant_history = self.history_met[-window_size:]
        if relevant_history:
            proportion_met = sum(relevant_history) / len(relevant_history)
        else:
            proportion_met = 0.0
        if proportion_met >= 0.5:
            action = Action.C
        else:
            action = Action.D
        if random.random() < 0.1:
            action = Action.D if action == Action.C else Action.C
        return action

class Strategy_EXPLOITATIVE_330(BaseStrategy):
    """
    Adaptive Threshold Punishment Strategy for the Collective Risk Dilemma.
    
    This strategy aims to promote cooperation by initially cooperating, punishing 
    when cooperation is insufficient, and adapting based on opponents' behavior.
    It transitions through phases: initial cooperation, cooperation with 
    punishment for non-compliance, detection of exploitation, and final rounds 
    of defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.initial_cutoff = max(1, math.ceil(0.1 * self.n_rounds))
        self.final_cutoff = self.n_rounds - self.initial_cutoff
        self.in_punishment = False
        self.in_exploitation = False
        self.exploitation_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number < self.initial_cutoff:
            return Action.C
        elif state.round_number >= self.final_cutoff:
            return Action.D
        elif self.in_exploitation:
            return Action.D
        elif self.in_punishment:
            previous_coop = self._get_previous_coop(history)
            if previous_coop >= self.m:
                self.in_punishment = False
                return Action.C
            else:
                return Action.D
        else:
            previous_coop = self._get_previous_coop(history)
            if previous_coop >= self.m:
                return Action.C
            else:
                self.in_punishment = True
                self.exploitation_count += 1
                if self.exploitation_count >= 3:
                    self.in_exploitation = True
                return Action.D

    def _get_previous_coop(self, history: PlayerHistory) -> int:
        if history is None:
            return 0
        my_prev_action = history.my_actions[-1]
        opp_prev_actions = history.opponent_actions[-1, :]
        opp_coop = sum(opp_prev_actions)
        total_coop = opp_coop + (1 if my_prev_action else 0)
        return total_coop

class Strategy_EXPLOITATIVE_358(BaseStrategy):
    """
    Adaptive strategy for Collective Risk Dilemma based on reciprocal cooperation and endgame maximization.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            opp_actions_last = history.opponent_actions[-1]
            my_last_action = history.my_actions[-1]
            cooperators_prev = sum(opp_actions_last) + int(my_last_action)
        else:
            return Action.D
        m = self.game_description.m
        n_rounds = self.game_description.n_rounds
        current_round = state.round_number
        if cooperators_prev >= m:
            rounds_remaining = n_rounds - (current_round + 1)
            if rounds_remaining > 2:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_382(BaseStrategy):
    """
    A strategy that cooperates in the first round, defects in the last round, 
    and adapts based on the previous round's cooperation level to balance 
    encouraging others and maximizing personal gain.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        elif current_round == self.n_rounds - 1:
            return Action.D
        else:
            previous_round = current_round - 1
            my_action_prev = history.my_actions[previous_round]
            opponent_actions_prev = history.opponent_actions[previous_round]
            cooperators = my_action_prev + np.sum(opponent_actions_prev)
            if cooperators >= self.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_383(BaseStrategy):
    """
    This strategy cooperates in the first round and then decides based on the previous round's cooperation level.
    If fewer than m players cooperated previously, it cooperates; otherwise, it defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev = history.my_actions[prev_round]
            opp_prev = history.opponent_actions[prev_round, :]
            sum_opp = opp_prev.sum()
            total_coop_prev = sum_opp + my_prev
            if total_coop_prev < self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_384(BaseStrategy):
    """
    Exploitative Strategy for Collective Risk Dilemma. 
    Cooperates in the first round, defects in the last round, and uses the average cooperation rate from past rounds to decide actions in between.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        n_rounds = self.game_description.n_rounds
        if t == 0:
            return Action.C
        elif t == n_rounds - 1:
            return Action.D
        else:
            total_coop = 0.0
            for r in range(t):
                my_coop = history.my_actions[r]
                opponent_coop = np.sum(history.opponent_actions[r, :])
                coop_count = my_coop + opponent_coop
                total_coop += coop_count
            average_coop = total_coop / t
            m = self.game_description.m
            return Action.D if average_coop >= m else Action.C

class Strategy_EXPLOITATIVE_385(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma. Cooperates when 
    necessary to meet the cooperation threshold, defects otherwise.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.always_cooperate = self.n_players - 1 < self.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if self.always_cooperate:
            return Action.C
        if state.round_number == 0:
            return Action.C
        previous_rounds = state.round_number
        opponent_actions = history.opponent_actions[:previous_rounds, :]
        cooperation_counts = np.sum(opponent_actions, axis=0)
        cooperation_rates = cooperation_counts / previous_rounds
        E = np.sum(cooperation_rates)
        if E >= self.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_386(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that defects if the expected number of 
    cooperators from others meets or exceeds a threshold, otherwise cooperates.
    Initial move is always Cooperate. Subsequent moves estimate cooperation rates 
    from other players' past actions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number
        m = self.game_description.m
        opponent_actions = history.opponent_actions
        n_opponents = opponent_actions.shape[1]
        sum_rates = 0.0
        for j in range(n_opponents):
            cooperation_count = np.sum(opponent_actions[:, j])
            rate = cooperation_count / t
            sum_rates += rate
        if sum_rates >= m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_387(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma game where the player starts cooperating, 
    tests defection, and then adapts based on past outcomes to decide future actions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.success_count = 0
        self.failure_count = 0
        self.last_action_was_defect = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            action = Action.C
        elif state.round_number == 1:
            action = Action.D
        else:
            if self.last_action_was_defect:
                t = state.round_number - 1
                my_action_t = history.my_actions[t]
                opp_actions_t = history.opponent_actions[t]
                opp_coop = sum(opp_actions_t)
                my_contribution = 1 if my_action_t else 0
                total_coop = opp_coop + my_contribution
                if total_coop >= self.game_description.m:
                    self.success_count += 1
                else:
                    self.failure_count += 1
                self.last_action_was_defect = False
            if self.success_count > self.failure_count:
                action = Action.D
            else:
                action = Action.C
        self.last_action_was_defect = action == Action.D
        return action

class Strategy_EXPLOITATIVE_388(BaseStrategy):
    """
    A strategy that always cooperates in the Collective Risk Dilemma game.
    This deterministic strategy consistently chooses to cooperate in every round, 
    regardless of previous outcomes or opponents' actions, based on the analysis that 
    cooperation yields higher overall payoffs compared to other strategies.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        return Action.C

class Strategy_EXPLOITATIVE_389(BaseStrategy):
    """
    This strategy is designed to maximize individual payoff while contributing 
    to meeting the cooperation threshold when necessary. It starts by cooperating 
    in the first round to encourage others, defects in middle rounds if past 
    cooperation was sufficient, and uses the average cooperation in the last round 
    to decide.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        is_last_round = state.round_number == self.game_description.n_rounds - 1
        if is_last_round:
            sum_coop = 0
            for round_num in range(state.round_number):
                my_action = history.my_actions[round_num]
                my_coop = 1 if my_action else 0
                opp_actions = history.opponent_actions[round_num]
                opp_coop = np.sum(opp_actions)
                sum_coop += my_coop + opp_coop
            avg = sum_coop / state.round_number
            if avg >= self.game_description.m:
                return Action.D
            else:
                return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opp_prev_actions = history.opponent_actions[prev_round]
            my_coop = 1 if my_prev_action else 0
            opp_coop = np.sum(opp_prev_actions)
            total_prev_coop = my_coop + opp_coop
            if total_prev_coop >= self.game_description.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_390(BaseStrategy):
    """
    A strategy designed for the Collective Risk Dilemma game. It encourages initial cooperation and 
    adapts based on the number of cooperators in previous rounds, punishing non-cooperation while allowing 
    for recovery by periodically reverting to cooperation after defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.must_cooperate_next = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.must_cooperate_next:
            self.must_cooperate_next = False
            return Action.C
        last_round_num = state.round_number - 1
        my_last_action = history.my_actions[last_round_num]
        opp_last_actions = history.opponent_actions[last_round_num, :]
        count_c = int(my_last_action) + np.sum(opp_last_actions)
        if count_c >= self.game_description.m:
            return Action.C
        else:
            self.must_cooperate_next = True
            return Action.D

class Strategy_EXPLOITATIVE_391(BaseStrategy):
    """
    Adaptive Cooperation strategy with threshold tracking. Cooperates initially,
    repeats the previous action if the threshold was met, switches otherwise,
    and defects in the last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        prev_payoff = history.my_payoffs[-1]
        last_action = history.my_actions[-1]
        threshold_met = prev_payoff > 1.0
        if threshold_met:
            return Action.C if last_action else Action.D
        else:
            return Action.D if last_action else Action.C

class Strategy_EXPLOITATIVE_392(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game. The strategy cooperates in the first round and then
    adapts based on the cooperation of other players in the previous round. It defects if enough others
    cooperated to meet the threshold, otherwise it cooperates.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.m = game_description.m

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        others_prev_coop = sum(history.opponent_actions[-1, :])
        if others_prev_coop >= self.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_393(BaseStrategy):
    """
    A strategy designed for the Collective Risk Dilemma game. It starts by cooperating 
    to set a positive precedent, continues cooperating if the threshold is met, defects 
    otherwise, and periodically retries cooperation every three defections. In the 
    last round, it cooperates if the previous round met the threshold, otherwise defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.failing_rounds_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round_num = self.game_description.n_rounds - 1
        if state.round_number == last_round_num:
            t_prev = state.round_number - 1
            if t_prev < 0:
                return Action.C
            my_prev = history.my_actions[t_prev]
            opponent_prev = history.opponent_actions[t_prev, :]
            num_coop_prev = sum(opponent_prev) + (1 if my_prev else 0)
            if num_coop_prev >= self.game_description.m:
                return Action.C
            else:
                return Action.D
        else:
            t_prev = state.round_number - 1
            my_prev = history.my_actions[t_prev]
            opponent_prev = history.opponent_actions[t_prev, :]
            num_coop_prev = sum(opponent_prev) + (1 if my_prev else 0)
            if num_coop_prev >= self.game_description.m:
                self.failing_rounds_counter = 0
                return Action.C
            elif self.failing_rounds_counter >= 3:
                self.failing_rounds_counter = 0
                return Action.C
            else:
                self.failing_rounds_counter += 1
                return Action.D

class Strategy_EXPLOITATIVE_394(BaseStrategy):
    """
    This strategy starts with cooperation and adapts based on the collective outcome of previous rounds.
    It balances individual self-interest with collective success by defecting when safe and cooperating when necessary.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_my_action = history.my_actions[-1]
        prev_opponents_actions = history.opponent_actions[-1]
        total_C_last_round = prev_my_action + sum(prev_opponents_actions)
        m = self.game_description.m
        if prev_my_action:
            if total_C_last_round - 1 >= m:
                return Action.D
            else:
                return Action.C
        elif total_C_last_round >= m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_395(BaseStrategy):
    """
    This strategy determines cooperation based on the necessity of the player's contribution in the previous round.
    It defects when the threshold is met without their contribution and cooperates otherwise.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        prev_my_action = history.my_actions[previous_round]
        prev_opponents = history.opponent_actions[previous_round]
        opp_coops = sum(prev_opponents)
        my_coop = 1 if prev_my_action else 0
        total_prev = opp_coops + my_coop
        if prev_my_action:
            effective_prev = total_prev - 1
        else:
            effective_prev = total_prev
        if effective_prev >= self.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_396(BaseStrategy):
    """
    Responsive Cooperative Punisher strategy for the Collective Risk Dilemma.
    Cooperates initially, punishes when cooperation is insufficient, forgives after two defections, 
    and defects in endgame rounds to maximize payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defects = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number >= self.game_description.n_rounds - 3:
            return Action.D
        previous_round = state.round_number - 1
        prev_my_action = history.my_actions[previous_round].item()
        sum_opp = sum(history.opponent_actions[previous_round])
        coops_in_prev = sum_opp + prev_my_action
        if coops_in_prev >= self.game_description.m:
            self.consecutive_defects = 0
            return Action.C
        elif self.consecutive_defects == 2:
            self.consecutive_defects = 0
            return Action.C
        else:
            self.consecutive_defects += 1
            return Action.D

class Strategy_EXPLOITATIVE_397(BaseStrategy):
    """
    Exploitative Strategy for Collective Risk Dilemma:
    Cooperates initially, continues if threshold met, and assesses cooperation in last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        n_rounds = self.game_description.n_rounds
        m = self.game_description.m
        if round_number == 0:
            return Action.C
        elif round_number == n_rounds - 1:
            sum_coop = 0.0
            for t in range(round_number):
                my_coop = history.my_actions[t]
                opponent_coop = history.opponent_actions[t].sum()
                sum_coop += my_coop + opponent_coop
            avg_coop = sum_coop / round_number
            if avg_coop >= m:
                return Action.C
            else:
                return Action.D
        else:
            prev_round = round_number - 1
            my_coop = history.my_actions[prev_round]
            opponent_coop = history.opponent_actions[prev_round].sum()
            total_coop = my_coop + opponent_coop
            if total_coop >= m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_398(BaseStrategy):
    """
    A dynamic strategy for the Collective Risk Dilemma that balances cooperation
    and defection based on observed behavior to maximize individual payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.n_rounds - 1:
            return Action.D
        prev_round = state.round_number - 1
        opponent_actions_prev = history.opponent_actions[prev_round]
        sum_others = np.sum(opponent_actions_prev)
        my_prev_action = history.my_actions[prev_round]
        total_coop = sum_others + my_prev_action
        if total_coop >= self.m + 1:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_399(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma game that encourages 
    initial cooperation, adapts based on recent success rates, and defects in endgame.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.initial_phase = int(0.1 * game_description.n_rounds)
        self.endgame_cutoff = int(0.8 * game_description.n_rounds)

    def __call__(self, state: GameState, history) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number < self.initial_phase:
            return Action.C
        if state.round_number >= self.endgame_cutoff:
            return Action.D
        last_round = state.round_number - 1
        opponents = history.opponent_actions[last_round, :]
        opp_coop = np.sum(opponents)
        self_coop = history.my_actions[last_round]
        total_coop_last = opp_coop + self_coop
        if total_coop_last >= self.game_description.m:
            return Action.C
        else:
            recent_success = 0
            recent_total = 0
            r_max = last_round
            r_min = max(r_max - 4, 0)
            for r in range(r_max, r_min - 1, -1):
                opp_actions = history.opponent_actions[r, :]
                opp_c = np.sum(opp_actions)
                self_c = history.my_actions[r]
                total = opp_c + self_c
                if total >= self.game_description.m:
                    recent_success += 1
                recent_total += 1
            if recent_total == 0:
                return Action.D
            else:
                success_rate = recent_success / recent_total
                if success_rate > 0.5:
                    return Action.C
                else:
                    return Action.D

class Strategy_EXPLOITATIVE_400(BaseStrategy):
    """
    Strategy: Adaptive Cooperation with Forgiveness.
    - Cooperates in the first round.
    - Adjusts based on previous round's cooperation level, defecting for up to 3 rounds if cooperation is insufficient.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defect_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_last = history.my_actions[-1]
        oppo_last = history.opponent_actions[-1]
        coop_prev = my_last + oppo_last.sum()
        m = self.game_description.m
        if coop_prev >= m:
            self.defect_count = 0
            return Action.C
        else:
            self.defect_count += 1
            if self.defect_count <= 3:
                return Action.D
            else:
                self.defect_count = 0
                return Action.C

class Strategy_EXPLOITATIVE_401(BaseStrategy):
    """
    This strategy begins by cooperating in the first round. For subsequent rounds, it continues to cooperate only if the previous round met or exceeded the required number of cooperators (m). It defects in all cases during the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        elif history is not None:
            my_prev = history.my_actions[state.round_number - 1]
            opponent_actions = history.opponent_actions[state.round_number - 1]
            prev_coop_count = (1 if my_prev else 0) + sum(opponent_actions)
            if prev_coop_count >= self.game_description.m:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_402(BaseStrategy):
    """
    Strategy for Collective Risk Dilemma:
    1. Cooperate in the first round.
    2. In intermediate rounds, cooperate if at least m players cooperated in the previous round.
    3. Defect in the last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.r - 1:
            return Action.D
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opponents_prev_actions = history.opponent_actions[prev_round]
            total_coop = my_prev_action + sum(opponents_prev_actions)
            if total_coop >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_403(BaseStrategy):
    """
    An adaptive strategy that decides to Cooperate or Defect based on past observations of others' cooperation.
    Cooperates initially and then adapts based on whether the threshold was met without its own contribution.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        c_safe = 0
        total_considered = 0
        for t in range(state.round_number):
            if history.my_actions[t]:
                opp_coop = history.opponent_actions[t].sum()
                if opp_coop >= self.m:
                    c_safe += 1
                total_considered += 1
        if total_considered == 0:
            return Action.C
        proportion = c_safe / total_considered
        return Action.D if proportion > 0.5 else Action.C

class Strategy_EXPLOITATIVE_404(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that starts with cooperation, 
    mirrors past cooperation, punishes defection, and adjusts in the endgame.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        current_round = state.round_number
        game_desc = self.game_description
        if current_round == 0:
            return Action.C
        n_rounds = game_desc.n_rounds
        if current_round == n_rounds - 1:
            count_coop = 0
            for r in range(current_round):
                my_action = history.my_actions[r]
                opp_actions = history.opponent_actions[r, :]
                total_coop = sum(opp_actions) + (1 if my_action else 0)
                if total_coop >= game_desc.m:
                    count_coop += 1
            total_rounds = current_round
            if count_coop > total_rounds / 2:
                return Action.C
            else:
                return Action.D
        elif current_round == n_rounds - 2:
            count_coop = 0
            for r in range(current_round):
                my_action = history.my_actions[r]
                opp_actions = history.opponent_actions[r, :]
                total_coop = sum(opp_actions) + (1 if my_action else 0)
                if total_coop >= game_desc.m:
                    count_coop += 1
            total_rounds = current_round
            if count_coop > total_rounds / 2:
                return Action.C
            else:
                return Action.D
        else:
            previous_round = current_round - 1
            my_prev_action = history.my_actions[previous_round]
            opp_prev_actions = history.opponent_actions[previous_round, :]
            total_coop = sum(opp_prev_actions) + (1 if my_prev_action else 0)
            if total_coop >= game_desc.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_405(BaseStrategy):
    """
    An exploitative strategy for the Collective Risk Dilemma game. Cooperates initially and defects if the previous round's cooperation meets or exceeds the threshold m.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        m = self.game_description.m
        prev_round = state.round_number - 1
        opponent_coop = sum(history.opponent_actions[prev_round])
        my_coop = history.my_actions[prev_round]
        total_coop = opponent_coop + my_coop
        if total_coop >= m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_406(BaseStrategy):
    """
    A strategy that promotes cooperation unless in the final round, adapting based on previous cooperation levels.
    Cooperates initially, continues if enough players cooperated previously, and defects in the last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            previous_round_index = state.round_number - 1
            my_prev_action = history.my_actions[previous_round_index]
            others_prev_actions = history.opponent_actions[previous_round_index]
            others_coop_sum = np.sum(others_prev_actions)
            total_coop = my_prev_action + others_coop_sum
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_407(BaseStrategy):
    """
    Adaptive Cooperation Based on Historical Performance strategy.
    Cooperates initially and continues if enough players cooperated previously; otherwise defects, with recovery after consecutive defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defects = 0
        self.recovery_threshold = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_my_c = history.my_actions[-1]
        prev_opponent_actions = history.opponent_actions[-1]
        count_coop_prev = (1 if prev_my_c else 0) + np.sum(prev_opponent_actions)
        if count_coop_prev >= self.game_description.m:
            self.consecutive_defects = 0
            return Action.C
        elif self.consecutive_defects >= self.recovery_threshold:
            self.consecutive_defects = 0
            return Action.C
        else:
            self.consecutive_defects += 1
            return Action.D

class Strategy_EXPLOITATIVE_408(BaseStrategy):
    """
    Adaptive Cooperation Based on Previous Round's Outcome.
    Cooperates initially, then adapts based on the number of cooperators in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_prev_actions = history.opponent_actions[prev_round, :]
        num_opponent_coops = np.count_nonzero(opponent_prev_actions)
        total_coops = num_opponent_coops + (1 if my_prev_action else 0)
        if total_coops >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_409(BaseStrategy):
    """
    A strategy that starts with cooperation, then responds based on previous round's cooperation level.
    Cooperates again if threshold met; otherwise punishes or switches based on own last action.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        opponent_actions_prev = history.opponent_actions[previous_round, :]
        my_last_action = history.my_actions[previous_round]
        total_coop = opponent_actions_prev.sum() + my_last_action
        if total_coop >= self.game_description.m:
            return Action.C
        elif my_last_action == Action.D:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_410(BaseStrategy):
    """
    Adaptive Cooperation with Late-Game Defection strategy.
    Cooperates initially, then evaluates mid-game success to decide continued cooperation,
    and defects in the final phase.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_rounds = game_description.n_rounds
        self.initial_phase_length = int(0.2 * self.n_rounds)
        self.last_phase_length = int(0.1 * self.n_rounds)
        self.mid_phase_decision = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round < self.initial_phase_length:
            return Action.C
        last_phase_start = self.n_rounds - self.last_phase_length
        if current_round >= last_phase_start:
            return Action.D
        if self.mid_phase_decision is None:
            if self.initial_phase_length == 0:
                self.mid_phase_decision = Action.D
            else:
                count = 0
                m = self.game_description.m
                for t in range(self.initial_phase_length):
                    opponents = history.opponent_actions[t, :] if history else []
                    cooperators = sum(opponents) + 1
                    if cooperators >= m:
                        count += 1
                total_initial = self.initial_phase_length
                if total_initial == 0:
                    percent = 0.0
                else:
                    percent = count / total_initial * 100
                if percent > 50:
                    self.mid_phase_decision = Action.C
                else:
                    self.mid_phase_decision = Action.D
        return self.mid_phase_decision

class Strategy_EXPLOITATIVE_411(BaseStrategy):
    """
    A strategy designed for the Collective Risk Dilemma that balances cooperation 
    and exploitation based on observed behavior and expected outcomes.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        elif round_num == self.game_description.n_rounds - 1:
            prev_actions = history.opponent_actions[-1, :]
            sum_coop = np.sum(prev_actions)
            m = self.game_description.m
            k = self.game_description.k
            if sum_coop >= m:
                D_pay = 1 + k
            else:
                D_pay = 1
            total_c = sum_coop + 1
            if total_c >= m:
                C_pay = k
            else:
                C_pay = 0
            return Action.D if D_pay > C_pay else Action.C
        else:
            prev_actions = history.opponent_actions[-1, :]
            sum_coop = np.sum(prev_actions)
            if sum_coop >= self.game_description.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_412(BaseStrategy):
    """
    An adaptive strategy that cooperates based on the historical success of collective cooperation.
    Cooperates if at least half of the previous rounds met the cooperation threshold m.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        m = self.game_description.m
        total_rounds = state.round_number
        success_count = 0
        for t in range(total_rounds):
            my_action = history.my_actions[t]
            opponent_actions = history.opponent_actions[t]
            others_coop = np.sum(opponent_actions)
            total_coop = my_action + others_coop
            if total_coop >= m:
                success_count += 1
        success_rate = success_count / total_rounds
        if success_rate >= 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_413(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that cooperates initially and defects 
    only when the previous round's cooperation is sufficient to maintain the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            my_last = history.my_actions[-1]
            opponent_last = history.opponent_actions[-1, :]
            c_prev = int(my_last) + np.sum(opponent_last)
            m = self.game_description.m
            if c_prev >= m + 1:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_414(BaseStrategy):
    """
    A strategy that starts with cooperation and punishes defection by defecting 
    for a set number of rounds before reverting to cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n_players = game_description.n_players
        self.p_defect = 2
        self.state = 'coop'
        self.defect_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_last_action = history.my_actions[prev_round]
        opponent_last_actions = history.opponent_actions[prev_round]
        total_coop = my_last_action + np.sum(opponent_last_actions)
        if self.state == 'coop':
            if total_coop >= self.m:
                return Action.C
            else:
                self.state = 'defect'
                self.defect_counter = 1
                return Action.D
        else:
            action = Action.D
            self.defect_counter += 1
            if self.defect_counter >= self.p_defect:
                self.state = 'coop'
                self.defect_counter = 0
            return action

class Strategy_EXPLOITATIVE_415(BaseStrategy):
    """
    Cooperates in the first round, then adapts based on the previous round's cooperation count. 
    If the number of Cooperators meets or exceeds m, continue Cooperating; else Defect.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            my_prev = history.my_actions[-1]
            opponents_prev = history.opponent_actions[-1]
            coop_count = my_prev + sum(opponents_prev)
            if coop_count >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_416(BaseStrategy):
    """
    Implements a strategy that balances cooperation and defection in the Collective Risk Dilemma.
    Cooperates initially, adapts based on the previous round's cooperation level,
    and defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        elif round_number == self.n_rounds - 1:
            return Action.D
        else:
            previous_round = round_number - 1
            my_prev_action = history.my_actions[previous_round]
            opponents_prev_actions = history.opponent_actions[previous_round]
            total_coop = 1 if my_prev_action else 0
            total_coop += opponents_prev_actions.sum()
            if total_coop >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_417(BaseStrategy):
    """
    A strategy that adapts based on the cooperation history in the Collective Risk Dilemma.
    Cooperates in the first round, then defects if enough players cooperated previously,
    otherwise continues cooperating.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev_action = history.my_actions[previous_round]
        opponent_actions_prev = history.opponent_actions[previous_round]
        total_coop = my_prev_action + np.sum(opponent_actions_prev)
        if total_coop >= self.game_description.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_418(BaseStrategy):
    """
    Adaptive Exploitation Strategy for Collective Risk Dilemma.
    
    This strategy begins by cooperating in the first round to set a cooperative tone.
    It switches to defecting if the average cooperation rate of previous rounds
    falls below the threshold of m/n. Additionally, in the last five rounds,
    it defects to maximize personal gains.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        round_num = state.round_number
        if round_num >= self.n_rounds - 5:
            return Action.D
        sum_c_list = []
        for r in range(round_num):
            my_c = history.my_actions[r]
            opponents = history.opponent_actions[r, :]
            sum_c = my_c + np.sum(opponents)
            sum_c_list.append(sum_c)
        cooperation_rates = [c / self.n_players for c in sum_c_list]
        average_rate = np.mean(cooperation_rates)
        threshold = self.m / self.n_players
        if average_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_419(BaseStrategy):
    """
    Adaptive Cooperation with Periodic Testing strategy for the Collective Risk Dilemma.
    Cooperates initially, continues if enough cooperated in the previous round, and tests cooperation periodically.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_actions_prev = history.opponent_actions[prev_round, :]
        s_prev = int(my_prev_action) + np.sum(opponent_actions_prev)
        if s_prev >= self.game_description.m:
            self.consecutive_defections = 0
            return Action.C
        elif self.consecutive_defections >= 3:
            self.consecutive_defections = 0
            return Action.C
        else:
            self.consecutive_defections += 1
            return Action.D

class Strategy_EXPLOITATIVE_420(BaseStrategy):
    """
    Cooperative strategy that sustains cooperation if enough players cooperate.
    Cooperates in the first round, then cooperates if at least m players cooperated in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_prev_actions = history.opponent_actions[prev_round]
        total_coop = int(my_prev_action) + np.sum(opponents_prev_actions)
        if total_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_421(BaseStrategy):
    """
    Adaptive Exploitation with Threshold Maintenance Strategy.
    
    This strategy starts by cooperating in the first round to encourage initial cooperation.
    In intermediate rounds, it checks the previous round's cooperation level and defects if
    maintaining the threshold is possible by doing so. In the final round, it defects to maximize payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        prev_round = current_round - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_prev_actions = history.opponent_actions[prev_round, :]
        last_C = my_prev_action + opponents_prev_actions.sum()
        if last_C >= self.m:
            if last_C - 1 >= self.m:
                return Action.D
            else:
                return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_422(BaseStrategy):
    """
    A strategy balancing cooperation and defection based on past success of cooperative actions.
    Initializes by cooperating, then adapts based on the success rate of achieving the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_actions = history.my_actions
        m = self.game_description.m
        total_cooperations = 0
        successful_cooperations = 0
        for t in range(len(my_actions)):
            if my_actions[t]:
                opponent_coop = np.sum(history.opponent_actions[t, :])
                total_coop = opponent_coop + 1
                if total_coop >= m:
                    successful_cooperations += 1
                total_cooperations += 1
        if total_cooperations == 0:
            success_rate = 0.0
        else:
            success_rate = successful_cooperations / total_cooperations
        if success_rate > 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_423(BaseStrategy):
    """
    An adaptive strategy that estimates others' cooperation probability and chooses actions to maximize expected payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.my_actions = []
        self.coop_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.my_actions.append(1)
            return Action.C
        if history is not None:
            for i in range(len(history.my_actions)):
                if i >= len(self.coop_history):
                    my_act = 1 if history.my_actions[i] else 0
                    opponents_in_round = history.opponent_actions[i]
                    others_act = sum(opponents_in_round)
                    total_coop = my_act + others_act
                    self.coop_history.append(total_coop)
        t = state.round_number
        n = self.game_description.n_players
        m = self.game_description.m
        k = self.game_description.k
        sum_coop_others = 0.0
        for i in range(t):
            if i < len(self.coop_history) and i < len(self.my_actions):
                total_coop_in_i = self.coop_history[i]
                my_act = self.my_actions[i]
                others_coop_in_i = total_coop_in_i - my_act
                sum_coop_others += others_coop_in_i
        if t == 0:
            p = 0.5
        else:
            p = sum_coop_others / ((n - 1) * t) if n > 1 else 0.5
        prob_c = 0.0
        for s in range(m - 1, n):
            if s > n - 1:
                break
            comb = math.comb(n - 1, s)
            prob = comb * p ** s * (1 - p) ** (n - 1 - s)
            prob_c += prob
        e_coop = k * prob_c
        prob_d = 0.0
        for s in range(m, n):
            if s > n - 1:
                break
            comb = math.comb(n - 1, s)
            prob = comb * p ** s * (1 - p) ** (n - 1 - s)
            prob_d += prob
        e_defect = 1.0 + k * prob_d
        if e_coop > e_defect:
            chosen_action = Action.C
        else:
            chosen_action = Action.D
        self.my_actions.append(1 if chosen_action == Action.C else 0)
        return chosen_action

class Strategy_EXPLOITATIVE_424(BaseStrategy):
    """
    Adaptive Exploitation with Final Round Defection (AEFRD) strategy for the Collective Risk Dilemma.

    - Cooperate in the first round.
    - For intermediate rounds, cooperate if the average number of cooperators across previous rounds meets or exceeds m; otherwise, defect.
    - Always defect in the final round to maximize immediate payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            t = state.round_number
            sum_coops = 0.0
            for round_idx in range(t):
                my_action = history.my_actions[round_idx]
                sum_coops += 1 if my_action else 0
                opp_actions = history.opponent_actions[round_idx, :]
                sum_coops += np.sum(opp_actions)
            avg_coop = sum_coops / t
            if avg_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_425(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that adapts based on cooperation trends.
    Cooperates initially, defects in the last round, and adapts in intermediate rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        n_rounds = self.n_rounds
        m = self.m
        if current_round == 0:
            return Action.C
        elif current_round == n_rounds - 1:
            return Action.D
        else:
            coops = []
            start = max(0, current_round - 3)
            for r in range(start, current_round):
                my_coop = history.my_actions[r]
                opponent_coop = np.sum(history.opponent_actions[r])
                total = my_coop + opponent_coop
                coops.append(total)
            if not coops:
                avg_coop = 0.0
            else:
                avg_coop = np.mean(coops)
            if avg_coop >= m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_426(BaseStrategy):
    """
    A strategy that adapts cooperation based on historical player behavior and group success.
    Starts by cooperating, then uses historical data to decide actions, with adaptive feedback 
    to promote group cooperation when necessary.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.boost_mode = False
        self.boost_rounds_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number
        n = self.n_players
        m = self.m
        if self.boost_mode:
            if self.boost_rounds_remaining > 0:
                self.boost_rounds_remaining -= 1
                return Action.C
            else:
                self.boost_mode = False
        opponent_actions = history.opponent_actions
        total_C_others = 0
        for r in range(t):
            sum_r = sum(opponent_actions[r, :])
            total_C_others += sum_r
        if n > 1 and t > 0:
            sum_c = total_C_others / (t * (n - 1))
        else:
            sum_c = 0.0
        threshold = m - 0.5
        action = Action.D if sum_c >= threshold else Action.C
        z = 5
        w = 2
        start = max(0, t - z)
        success_count = 0
        for r in range(start, t):
            my_action = history.my_actions[r]
            opp_actions = history.opponent_actions[r, :]
            total_C = my_action + sum(opp_actions)
            if total_C >= m:
                success_count += 1
        if success_count < w:
            action = Action.C
            self.boost_mode = True
            self.boost_rounds_remaining = 3
        return action

class Strategy_EXPLOITATIVE_427(BaseStrategy):
    """
    Exploitative strategy for Collective Risk Dilemma:
    - Cooperate in the first round.
    - Defect in the last round.
    - In middle rounds, defect if others' cooperation in the previous round meets the threshold, else cooperate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            previous_round = state.round_number - 1
            others_last = sum(history.opponent_actions[previous_round, :])
            if others_last >= self.game_description.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_428(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma game. It starts by cooperating, 
    punishes when the threshold isn't met, and re-evaluates cooperation based on others' actions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_prev_action = history.my_actions[-1]
        prev_opponent_actions = history.opponent_actions[-1, :]
        if my_prev_action:
            total_coop = 1 + np.sum(prev_opponent_actions)
            if total_coop >= self.m:
                return Action.C
            else:
                return Action.D
        else:
            others_coop = np.sum(prev_opponent_actions)
            if others_coop >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_429(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma where the player cooperates if exactly m-1 other players cooperated in the previous round, otherwise defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round_actions = history.opponent_actions[-1]
        num_cooperators = np.sum(last_round_actions)
        if num_cooperators == self.m - 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_430(BaseStrategy):
    """
    Adaptive Exploitation in Collective Risk Dilemma Strategy.
    Cooperates initially, defects in the last round, and follows the previous round's cooperation trend.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_prev = history.opponent_actions[prev_round, :]
        total_coop_prev = sum(opponents_prev) + int(my_prev_action)
        if total_coop_prev >= self.game_description.m:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_431(BaseStrategy):
    """
    A strategy that cooperates in the first round and then cooperates if more than half of previous rounds met the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        count = 0
        for round_idx in range(state.round_number):
            my_action = history.my_actions[round_idx]
            opponent_actions = history.opponent_actions[round_idx, :]
            total_C = my_action + np.sum(opponent_actions)
            if total_C >= self.m:
                count += 1
        threshold = state.round_number / 2
        if count > threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_432(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma.
    
    This strategy starts by cooperating in the first round. It then adapts based on the success rate of past cooperations, 
    defining success as meeting the minimum required contributors. It defects in the final round to ensure a safe payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        n_rounds = self.game_description.n_rounds
        m = self.game_description.m
        if current_round == 0:
            return Action.C
        elif current_round == n_rounds - 1:
            return Action.D
        else:
            success_count = 0
            coop_count = 0
            for i in range(current_round):
                if history.my_actions[i]:
                    opponent_actions_in_round = history.opponent_actions[i]
                    opponent_coop = np.sum(opponent_actions_in_round)
                    total_coop = 1 + opponent_coop
                    if total_coop >= m:
                        success_count += 1
                    coop_count += 1
            if coop_count == 0:
                success_rate = 0.0
            else:
                success_rate = success_count / coop_count
            if success_rate >= 0.5:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_433(BaseStrategy):
    """
    A strategy to maximize individual payoff in the Collective Risk Dilemma game by cooperating initially,
    defecting in the last round, and strategically choosing actions in intermediate rounds based on others' cooperation rates.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n_rounds = self.game_description.n_rounds
        n = self.game_description.n_players
        m = self.game_description.m
        if state.round_number == 0:
            return Action.C
        if state.round_number == n_rounds - 1:
            return Action.D
        s = state.round_number
        my_actions_prev = history.my_actions[0:s]
        my_count = sum(my_actions_prev)
        counts = [my_count]
        for opp in range(n - 1):
            opp_actions = history.opponent_actions[0:s, opp]
            opp_count = sum(opp_actions)
            counts.append(opp_count)
        total_coop = sum(counts)
        avg_coop = total_coop / (s * n)
        if (n - 1) * avg_coop >= m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_434(BaseStrategy):
    """
    A strategy that begins by cooperating and then adapts based on whether the cooperation threshold was met in the previous round. 
    If the threshold is met, it continues to cooperate. If not, it defects for two rounds before reverting to cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defect_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.defect_remaining = 0
            return Action.C
        if self.defect_remaining > 0:
            self.defect_remaining -= 1
            return Action.D
        else:
            prev_round = state.round_number - 1
            my_previous_action = history.my_actions[prev_round]
            opponent_previous_actions = history.opponent_actions[prev_round]
            my_C = my_previous_action
            opponent_C = opponent_previous_actions.sum()
            total_coop_prev = my_C + opponent_C
            if total_coop_prev >= self.game_description.m:
                return Action.C
            else:
                self.defect_remaining = 2
                return Action.D

class Strategy_EXPLOITATIVE_435(BaseStrategy):
    """
    Adaptive Cooperate-Punish Strategy for Collective Risk Dilemma.

    The strategy cooperates in the first round. In subsequent rounds, it continues 
    to cooperate if at least m players cooperated in the previous round; otherwise, 
    it defects. In the last round, it always defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            prev_round = state.round_number - 1
            cooperators = np.sum(history.opponent_actions[prev_round]) + history.my_actions[prev_round]
            if cooperators >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_436(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that balances cooperation and defection based on game dynamics and opponent behavior.
    Cooperates initially, continues if beneficial, and shifts towards defection in the endgame.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_few_rounds = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        if t == 0:
            return Action.C
        remaining_rounds = self.game_description.n_rounds - t
        if remaining_rounds <= self.last_few_rounds:
            return Action.D
        prev_t = t - 1
        my_prev_action = history.my_actions[prev_t]
        opp_prev_actions = history.opponent_actions[prev_t, :]
        opp_coop_count = np.sum(opp_prev_actions)
        total_coop_last = opp_coop_count + (1 if my_prev_action else 0)
        m = self.game_description.m
        n_opp = self.game_description.n_players - 1
        if total_coop_last >= m:
            opp_coop_counts = [np.sum(history.opponent_actions[:prev_t + 1, opp]) for opp in range(n_opp)]
            rounds_processed = prev_t + 1
            rates = [count / rounds_processed for count in opp_coop_counts]
            consistent = sum((1 for rate in rates if rate > 0.5))
            threshold = n_opp // 2 + 1
            if consistent >= threshold:
                if random.random() < 0.2:
                    return Action.D
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_437(BaseStrategy):

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        elif current_round >= self.r - 2:
            return Action.D
        else:
            prev_round = current_round - 1
            opponent_coop = sum(history.opponent_actions[prev_round, :])
            threshold = self.m - 1
            if opponent_coop >= threshold:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_438(BaseStrategy):
    """
    A strategy that cooperates in the first round, defects in the last, and 
    cooperates in middle rounds if more than half of the previous rounds met 
    the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        successful_rounds = 0
        for t in range(current_round):
            my_coop = history.my_actions[t]
            opp_coop = history.opponent_actions[t].sum()
            total_coop = my_coop + opp_coop
            if total_coop >= self.m:
                successful_rounds += 1
        total_previous_rounds = current_round
        if successful_rounds / total_previous_rounds > 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_441(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that starts with cooperation, 
    continues if successful, defects upon failure, and resets cooperation 
    after a set number of consecutive failures.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_failures = 0
        self.consecutive_failure_threshold = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_my_action = history.my_actions[-1]
        prev_opponent_actions = history.opponent_actions[-1, :]
        prev_total_coop = prev_my_action + sum(prev_opponent_actions)
        if prev_total_coop >= self.game_description.m:
            self.consecutive_failures = 0
            return Action.C
        else:
            self.consecutive_failures += 1
            if self.consecutive_failures >= self.consecutive_failure_threshold:
                self.consecutive_failures = 0
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_443(BaseStrategy):
    """
    A strategy to address the Collective Risk Dilemma by encouraging sustained cooperation
    through reciprocal altruism and forgiveness. It starts with cooperation, punishes non-cooperation,
    and allows for restarting cooperation after punishment.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.next_round_coop = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.next_round_coop:
            self.next_round_coop = False
            return Action.C
        prev_round = state.round_number - 1
        prev_my_action = history.my_actions[prev_round]
        prev_others_actions = history.opponent_actions[prev_round, :]
        coops = prev_my_action + np.sum(prev_others_actions)
        if coops >= self.game_description.m:
            return Action.C
        else:
            self.next_round_coop = True
            return Action.D

class Strategy_EXPLOITATIVE_444(BaseStrategy):
    """
    An exploitative strategy for the Collective Risk Dilemma game. 
    Cooperates initially, adapts based on the proportion of cooperators, 
    and defects in the last round to maximize payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.n_rounds - 1:
            return Action.D
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opponent_actions_prev = history.opponent_actions[prev_round]
            count_coop = int(my_prev_action) + np.sum(opponent_actions_prev)
            if count_coop >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_445(BaseStrategy):
    """
    Adaptive Cooperation Based on Previous Outcomes strategy for Collective Risk Dilemma.
    Cooperates initially, then adapts based on previous round outcomes and majority in last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            prev_meet = 0
            prev_round_count = state.round_number
            for t in range(prev_round_count):
                my_coop = history.my_actions[t]
                opponent_coops = np.sum(history.opponent_actions[t, :])
                total = my_coop + opponent_coops
                if total >= self.game_description.m:
                    prev_meet += 1
            if prev_meet > prev_round_count / 2:
                return Action.C
            else:
                return Action.D
        else:
            prev_round = state.round_number - 1
            my_coop_prev = history.my_actions[prev_round]
            opponent_coops_prev = np.sum(history.opponent_actions[prev_round, :])
            total_coop_prev = my_coop_prev + opponent_coops_prev
            if total_coop_prev >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_446(BaseStrategy):
    """
    Reactive Cooperation with Last-Round Defection strategy.
    Cooperates initially, reacts based on previous cooperation levels, and defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n_rounds = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.n_rounds - 1:
            return Action.D
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opponent_prev_actions = history.opponent_actions[prev_round, :]
            sum_opponents = np.sum(opponent_prev_actions)
            total_coop = sum_opponents + (1 if my_prev_action else 0)
            if total_coop >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_447(BaseStrategy):
    """
    Responsive Cooperation with Reset Mechanism Strategy.
    Cooperates initially, then adapts based on previous round's cooperation levels.
    Includes a reset mechanism to re-establish cooperation after consecutive defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.threshold_reset = 3
        self.consecutive_defection = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            last_round = state.round_number - 1
            my_last_action = history.my_actions[last_round]
            opponent_last_actions = history.opponent_actions[last_round, :]
            count_c_prev = my_last_action + np.sum(opponent_last_actions)
            if count_c_prev >= self.m:
                self.consecutive_defection = 0
                return Action.C
            else:
                self.consecutive_defection += 1
                if self.consecutive_defection > self.threshold_reset:
                    self.consecutive_defection = 0
                    return Action.C
                else:
                    return Action.D

class Strategy_EXPLOITATIVE_449(BaseStrategy):
    """
    Implements the Reactive Exploitation with Forgiveness strategy.
    Cooperates on the first round; in subsequent rounds, defects if the number of cooperators
    in the previous round meets or exceeds the threshold m, otherwise cooperates.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            my_prev_action = history.my_actions[-1]
            opp_prev_actions = history.opponent_actions[-1, :]
            c_prev = (1 if my_prev_action else 0) + np.sum(opp_prev_actions)
            if c_prev >= self.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_450(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that adapts based on the number of previous cooperators.
    Cooperates initially, defects in the last round, and adapts based on previous cooperation levels.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.n_rounds - 1:
            return Action.D
        else:
            previous_round = state.round_number - 1
            my_previous = history.my_actions[previous_round]
            opponent_actions = history.opponent_actions[previous_round, ...]
            opponent_coop = np.sum(opponent_actions)
            total_coop = opponent_coop + (1 if my_previous else 0)
            if total_coop >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_451(BaseStrategy):
    """
    Adaptive Cooperation Based on Historical Success strategy for Collective Risk Dilemma.

    This strategy begins by Cooperating in the first round and then adapts based on the number
    of Cooperators in the previous round. If at least m players Cooperated previously, it
    continues to Cooperate; otherwise, it Defects to protect its interests.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_prev_action = history.my_actions[state.round_number - 1]
        prev_opponents_actions = history.opponent_actions[state.round_number - 1, :]
        total_coop = my_prev_action + sum(prev_opponents_actions)
        if total_coop >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_452(BaseStrategy):
    """
    A strategy that cooperates if the previous round's cooperation didn't meet the threshold,
    defects otherwise after the first round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            my_coop = 1 if my_prev_action else 0
            opp_actions = history.opponent_actions[prev_round, :]
            opp_coop = np.sum(opp_actions)
            total_coop = my_coop + opp_coop
            if total_coop >= self.game_description.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_453(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that balances cooperation and defection based on the number of Cooperators in previous rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            my_prev = history.my_actions[-1]
            opponent_prev = history.opponent_actions[-1, :]
            sum_coops = my_prev + np.sum(opponent_prev)
            if sum_coops >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_455(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma game that balances cooperation and defection.
    It starts with cooperation, then adapts based on the number of cooperators in previous rounds,
    includes a forgiveness mechanism, and handles the last round specially.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        n = self.game_description.n_players
        m = self.game_description.m
        r = self.game_description.n_rounds
        if t == 0:
            return Action.C
        elif t == r - 1:
            if history is None:
                return Action.C
            total_coops = 0
            for s in range(len(history.my_actions)):
                prev_me = history.my_actions[s]
                prev_opp = history.opponent_actions[s]
                coop_count = sum(prev_opp) + (1 if prev_me else 0)
                total_coops += coop_count
            avg_coops = total_coops / len(history.my_actions)
            if avg_coops >= m:
                return Action.C
            else:
                return Action.D
        else:
            prev_action = history.my_actions[-1] if history else False
            if not prev_action:
                return Action.C
            prev_me = history.my_actions[-1]
            prev_opp = history.opponent_actions[-1]
            coop_count = sum(prev_opp) + (1 if prev_me else 0)
            if coop_count >= m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_456(BaseStrategy):
    """
    A strategy to balance personal gain with collective cooperation by defecting when safe and cooperating otherwise.
    Cooperates in the first round, then defects if the previous round had enough cooperators to exceed the threshold,
    ensuring the collective goal is met while maximizing personal payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opp_prev_actions = history.opponent_actions[prev_round, :]
        num_coop_prev = (1 if my_prev_action else 0) + sum(opp_prev_actions)
        if num_coop_prev >= self.game_description.m + 1:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_457(BaseStrategy):
    """
    Adaptive Cooperation with Last Round Defection strategy.
    Cooperates initially and continues if enough players cooperate in the previous round.
    Defects in the last round to maximize immediate payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        t_prev = state.round_number - 1
        prev_coop = history.my_actions[t_prev] + np.sum(history.opponent_actions[t_prev])
        if prev_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_458(BaseStrategy):
    """
    A strategy based on historical cooperation levels in the Collective Risk Dilemma.
    Cooperates initially, continues if average cooperation meets the threshold, and defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        t = state.round_number
        sum_coop = 0
        for r in range(t):
            my_action = history.my_actions[r]
            opponent_actions_r = history.opponent_actions[r]
            num_coop = (1 if my_action else 0) + np.sum(opponent_actions_r)
            sum_coop += num_coop
        avg_coop = sum_coop / t
        if avg_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_460(BaseStrategy):
    """
    An adaptive strategy that cooperates based on historical success of meeting the cooperation threshold.
    Cooperates in the first round, then cooperates in subsequent rounds if the ratio of successful rounds 
    (meeting the threshold) is at least 50%.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_actions = history.my_actions
        opponent_actions = history.opponent_actions
        total_rounds = my_actions.size
        success_count = 0
        for round_number in range(total_rounds):
            my_C = my_actions[round_number]
            opponents_C = opponent_actions[round_number].sum()
            total_C = int(my_C) + int(opponents_C)
            if total_C >= self.game_description.m:
                success_count += 1
        success_ratio = success_count / total_rounds
        if success_ratio >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_461(BaseStrategy):
    """
    A strategy designed for the Collective Risk Dilemma, encouraging initial cooperation, 
    adapting based on previous rounds' outcomes, and adjusting for endgame scenarios.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        endgame_rounds = math.ceil(0.1 * self.r)
        endgame_start = self.r - endgame_rounds
        if state.round_number >= endgame_start:
            return Action.D
        last_round = state.round_number - 1
        my_prev_action = history.my_actions[last_round]
        prev_opponent_actions = history.opponent_actions[last_round, :]
        sum_prev_opponents = np.sum(prev_opponent_actions)
        total_coop = my_prev_action + sum_prev_opponents
        if total_coop >= self.m:
            return Action.C
        elif self.m / self.n >= 0.75:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_462(BaseStrategy):
    """
    Adaptive Exploitation Based on Past Cooperation strategy for the Collective Risk Dilemma.

    This strategy encourages cooperation by starting with a cooperative action, then adapts based on the number of previous cooperators.
    In the last round, it defects to maximize immediate payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opponents_prev_actions = history.opponent_actions[prev_round]
            prev_coop = my_prev_action + sum(opponents_prev_actions)
            if prev_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_463(BaseStrategy):

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            t_prev = state.round_number - 1
            me_action = history.my_actions[t_prev]
            opponent_actions = history.opponent_actions[t_prev]
            c_prev = int(me_action) + opponent_actions.sum()
            if c_prev >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_464(BaseStrategy):
    """
    Adaptive Exploitation Strategy (AES) for the Collective Risk Dilemma.
    Cooperates initially, then defects if previous round's cooperation exceeded threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n_players = game_description.n_players

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opp_prev_actions = history.opponent_actions[prev_round]
        prev_coop_count = (1 if my_prev_action else 0) + opp_prev_actions.sum()
        if prev_coop_count > self.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_465(BaseStrategy):
    """
    A strategy to optimize payoffs in a Collective Risk Dilemma by cooperating initially and defecting when safe.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        previous_round = current_round - 1
        my_prev_action = history.my_actions[previous_round]
        opponents_prev_actions = history.opponent_actions[previous_round]
        sum_coop = int(my_prev_action) + opponents_prev_actions.sum()
        if sum_coop > self.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_466(BaseStrategy):
    """
    Cooperate in the first round. In subsequent rounds, cooperate if at least m players cooperated in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev_action = history.my_actions[previous_round]
        opponent_actions = history.opponent_actions[previous_round]
        total_coop = int(my_prev_action) + np.sum(opponent_actions)
        threshold = self.game_description.m
        if total_coop >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_467(BaseStrategy):
    """
    An adaptive strategy that initially cooperates, then responds to the collective cooperation history,
    defecting when cooperation is insufficient and resetting cooperation attempts after three consecutive failures.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_fail = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_action = history.my_actions[previous_round]
        opponent_actions = history.opponent_actions[previous_round]
        cooperative_count = my_action + opponent_actions.sum()
        if cooperative_count >= self.game_description.m:
            self.consecutive_fail = 0
            return Action.C
        else:
            self.consecutive_fail += 1
            if self.consecutive_fail >= 3:
                self.consecutive_fail = 0
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_468(BaseStrategy):
    """
    This strategy begins by Cooperating in the first round. In subsequent rounds, 
    it Cooperates again if at least m players Cooperated in the previous round; 
    otherwise, it Defects. This encourages sustained cooperation when beneficial.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        opponents_last_round_actions = history.opponent_actions[prev_round]
        my_last_action = history.my_actions[prev_round]
        total_coop_last_round = sum(opponents_last_round_actions) + my_last_action
        if total_coop_last_round >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_469(BaseStrategy):
    """
    Adaptive Cooperation Strategy based on historical performance.
    Cooperates initially and adapts based on the proportion of successful rounds.
    Defects if recent cooperation rates are insufficient, especially near the end.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        m = self.game_description.m
        r = self.game_description.n_rounds
        T_met = 0
        for t_round in range(current_round):
            my_coop = history.my_actions[t_round]
            opponent_coop = sum(history.opponent_actions[t_round, :])
            total_coop = my_coop + opponent_coop
            if total_coop >= m:
                T_met += 1
        total_previous = current_round
        cooperation_rate = T_met / total_previous if total_previous != 0 else 0.0
        if cooperation_rate > 0.5:
            action = Action.C
        else:
            action = Action.D
        if current_round >= r - 3:
            lookback = 5
            start_round = max(0, current_round - lookback)
            recent_T_met = 0
            for t_round in range(start_round, current_round):
                my_coop = history.my_actions[t_round]
                opponent_coop = sum(history.opponent_actions[t_round, :])
                total_coop = my_coop + opponent_coop
                if total_coop >= m:
                    recent_T_met += 1
            recent_rounds = current_round - start_round
            if recent_rounds == 0:
                recent_rate = 0.0
            else:
                recent_rate = recent_T_met / recent_rounds
            if recent_rate <= 0.5:
                action = Action.D
        return action

class Strategy_EXPLOITATIVE_470(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game. 
    Cooperates in the first round. In subsequent rounds, defects if the previous round met 
    or exceeded the cooperation threshold (m); otherwise, cooperates.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            my_last = history.my_actions[-1]
            opponent_last = history.opponent_actions[-1]
            my_contribution = 1 if my_last else 0
            opponent_contribution = sum(opponent_last)
            total = my_contribution + opponent_contribution
            if total >= self.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_471(BaseStrategy):
    """
    Adaptive Cooperation with Periodic Reengagement strategy for Collective Risk Dilemma.
    Cooperates initially, then adapts based on previous cooperation levels.
    Reengages cooperation once after two consecutive rounds below the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def count_coop(self, history: PlayerHistory, round_number: int) -> int:
        my_action = history.my_actions[round_number]
        opponent_actions = history.opponent_actions[round_number]
        count = 0
        if my_action:
            count += 1
        for action in opponent_actions:
            if action:
                count += 1
        return count

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        m = self.game_description.m
        n = state.round_number
        last_round = n - 1
        if n >= 2:
            previous_round = last_round - 1
            if previous_round >= 0:
                count_n2 = self.count_coop(history, previous_round)
                count_n1 = self.count_coop(history, last_round)
                if count_n2 < m and count_n1 < m:
                    return Action.C
        count_last = self.count_coop(history, last_round)
        if count_last >= m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_472(BaseStrategy):
    """
    An adaptive strategy based on opponents' historical cooperation rates.
    Cooperates in the first round, then decides based on expected contributions from others.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number
        n_opponents = self.game_description.n_players - 1
        cooperation_counts = np.sum(history.opponent_actions[0:t, :], axis=0)
        avg_coop_rates = cooperation_counts / t
        sum_e = np.sum(avg_coop_rates)
        m = self.game_description.m
        if sum_e >= m:
            return Action.D
        elif sum_e + 1 >= m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_473(BaseStrategy):
    """
    This strategy cooperates in the first round, continues if the threshold is met, 
    and defects in the last round to maximize payoff while encouraging cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.n_rounds - 1:
            return Action.D
        else:
            prev_my_action = history.my_actions[-1]
            prev_others_actions = history.opponent_actions[-1]
            total_coop = int(prev_my_action) + prev_others_actions.sum()
            if total_coop >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_474(BaseStrategy):
    """
    A strategy that adaptively decides between Cooperate (C) and Defect (D) based on historical game outcomes.
    It starts with cooperation, defects if the minimum number of cooperators isn't met, and reevaluates after a set period.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_coop_round = -1
        self.is_defecting = False
        self.defect_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        t = state.round_number
        my_actions = history.my_actions
        opponent_actions = history.opponent_actions
        prev_round = t - 1
        sum_self = 1 if my_actions[prev_round] else 0
        sum_others = sum(opponent_actions[prev_round, :])
        prev_coop_count = sum_self + sum_others
        if prev_coop_count >= self.game_description.m:
            self.last_coop_round = prev_round
            self.is_defecting = False
            self.defect_remaining = 0
            return Action.C
        elif not self.is_defecting:
            self.is_defecting = True
            self.defect_remaining = 3
            return Action.D
        else:
            self.defect_remaining -= 1
            if self.defect_remaining > 0:
                return Action.D
            else:
                sum_self_prev = 1 if my_actions[prev_round] else 0
                sum_others_prev = sum(opponent_actions[prev_round, :])
                new_prev_coop = sum_self_prev + sum_others_prev
                if new_prev_coop >= self.game_description.m:
                    self.is_defecting = False
                    self.defect_remaining = 0
                    return Action.C
                else:
                    self.is_defecting = True
                    self.defect_remaining = 3
                    return Action.D

class Strategy_EXPLOITATIVE_475(BaseStrategy):
    """
    A strategy that Cooperates in the first round and then adapts based on the historical cooperation rates of other players.
    It defects if the expected number of cooperators (excluding itself) meets or exceeds the threshold, otherwise Cooperates.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        n_players = self.game_description.n_players
        m = self.game_description.m
        current_round = state.round_number
        opponent_actions = history.opponent_actions
        sum_p = 0.0
        for j in range(n_players - 1):
            coop_count = np.sum(opponent_actions[:current_round, j])
            rate = coop_count / current_round
            sum_p += rate
        if sum_p >= m - 1e-09:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_476(BaseStrategy):
    """
    This strategy aims to maximize individual payoff while ensuring the collective benefit by maintaining the cooperation threshold.
    It starts by cooperating, then adjusts based on the previous round's cooperation level.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        sum_opponents = sum(history.opponent_actions[prev_round, :])
        my_last = history.my_actions[prev_round]
        m_prev = sum_opponents + (1 if my_last else 0)
        game = self.game_description
        if m_prev > game.m:
            return Action.D
        elif m_prev == game.m:
            if my_last:
                return Action.C
            else:
                return Action.C
        else:
            return Action.C

class Strategy_EXPLOITATIVE_477(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that adapts based on the cooperation level of previous rounds.
    Cooperates initially and continues if enough players cooperated previously.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_prev_actions = history.opponent_actions[prev_round]
        total_coop = my_prev_action + opponent_prev_actions.sum()
        if total_coop >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_478(BaseStrategy):
    """Exploitative strategy based on historical cooperation rates."""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        game_history = []
        for t in range(round_number):
            my_action = history.my_actions[t]
            my_coop = 1 if my_action else 0
            opponent_coops = np.sum(history.opponent_actions[t, :])
            total_coop = my_coop + opponent_coops
            game_history.append(total_coop)
        met_m_count = sum((1 for coop in game_history if coop >= self.game_description.m))
        total_rounds = len(game_history)
        if total_rounds == 0:
            return Action.C
        fraction_met = met_m_count / total_rounds
        if fraction_met > 0.5:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_479(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that balances cooperation and defection.
    Cooperates initially, continues if threshold is met, and defects in the last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        t_prev = state.round_number - 1
        my_prev_action = history.my_actions[t_prev]
        opponents_prev_actions = history.opponent_actions[t_prev, :]
        n_coop_prev = int(my_prev_action) + np.sum(opponents_prev_actions)
        if n_coop_prev >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_480(BaseStrategy):

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        m = self.game_description.m
        total_rounds = self.game_description.n_rounds
        if state.round_number == total_rounds - 1:
            t_prev_rounds = history.my_actions.size
            sum_opponent_per_round = np.sum(history.opponent_actions, axis=1)
            sum_coop_per_round = history.my_actions + sum_opponent_per_round
            successful_rounds = np.sum(sum_coop_per_round >= m)
            if successful_rounds > t_prev_rounds / 2:
                return Action.C
            else:
                return Action.D
        else:
            sum_opponent_per_round = np.sum(history.opponent_actions, axis=1)
            sum_coop_per_round = history.my_actions + sum_opponent_per_round
            successful_rounds = np.sum(sum_coop_per_round >= m)
            success_rate = successful_rounds / state.round_number
            if success_rate > 0.5:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_481(BaseStrategy):
    """Adaptive Cooperation with Reciprocity strategy.
    
    Cooperates initially to encourage mutual cooperation, defects in the final round, 
    adapts based on previous rounds' outcomes, and periodically tests cooperation after 
    a series of defections to encourage collective benefit.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0
        self.test_period = 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        last_round = state.round_number - 1
        my_last_action = history.my_actions[last_round]
        opponents_last_actions = history.opponent_actions[last_round, :]
        total_coops = int(my_last_action) + sum(opponents_last_actions)
        if total_coops >= self.game_description.m:
            self.consecutive_defections = 0
            return Action.C
        else:
            self.consecutive_defections += 1
            if self.consecutive_defections >= self.test_period:
                self.consecutive_defections = 0
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_482(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma game. 
    Initially Cooperates, then defects if the previous round met the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            last_opponent_actions = history.opponent_actions[-1]
            sum_opponents = sum(last_opponent_actions)
            my_last = history.my_actions[-1]
            total_coop = sum_opponents + (1 if my_last else 0)
            if total_coop >= self.game_description.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_483(BaseStrategy):
    """
    Adaptive Probe Cooperation strategy to address the Collective Risk Dilemma.
    Cooperates if previous cooperation succeeded, otherwise defects until a probe is sent.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0
        self.probe_sent = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev = history.my_actions[prev_round]
        opp_prev = history.opponent_actions[prev_round]
        sum_opp = np.sum(opp_prev)
        total_prev = my_prev + sum_opp
        if total_prev >= self.game_description.m:
            self.consecutive_defections = 0
            self.probe_sent = False
            return Action.C
        elif self.probe_sent:
            if total_prev >= self.game_description.m:
                self.consecutive_defections = 0
                self.probe_sent = False
                return Action.C
            else:
                self.consecutive_defections = 1
                self.probe_sent = False
                return Action.D
        elif self.consecutive_defections >= 3:
            self.probe_sent = True
            self.consecutive_defections = 0
            return Action.C
        else:
            self.consecutive_defections += 1
            return Action.D

class Strategy_EXPLOITATIVE_484(BaseStrategy):
    """
    An exploitative strategy for the Collective Risk Dilemma. 
    It starts by cooperating and then adapts based on the number of cooperators in the previous round.
    If at least m players cooperated, it continues to cooperate; otherwise, it defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev_action = history.my_actions[previous_round]
        opponent_prev_actions = history.opponent_actions[previous_round, :]
        total_cooperators = sum(opponent_prev_actions) + (1 if my_prev_action else 0)
        if total_cooperators >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_485(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that begins by cooperating, 
    then adapts based on prior cooperation levels, and decides in the final 
    round based on historical trends.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            count_coop = 0
            for round in range(state.round_number):
                total_coop = history.my_actions[round] + sum(history.opponent_actions[round, :])
                if total_coop >= self.game_description.m:
                    count_coop += 1
            proportion_coop = count_coop / state.round_number
            if proportion_coop >= 0.5:
                return Action.C
            else:
                return Action.D
        else:
            previous_round = state.round_number - 1
            total_coop = history.my_actions[previous_round] + sum(history.opponent_actions[previous_round, :])
            if total_coop >= self.game_description.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_486(BaseStrategy):
    """
    Adaptive Exploitation Strategy in Collective Risk Dilemma:
    Cooperates initially, continues if cooperation is sufficient, defects for a period, 
    then tests cooperation again. In the last round, chooses action to maximize immediate payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.defect_phase = False
        self.defect_count = 0
        self.p = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.n_rounds - 1:
            if history is None:
                return Action.D
            previous_round = round_number - 1
            sum_opp = np.sum(history.opponent_actions[previous_round, :])
            if sum_opp >= self.m - 1:
                return Action.C
            else:
                return Action.D
        elif not self.defect_phase:
            previous_round = round_number - 1
            if history is None:
                return Action.C
            prev_my_action = history.my_actions[previous_round]
            prev_opp_actions = history.opponent_actions[previous_round, :]
            prev_coop = prev_my_action + np.sum(prev_opp_actions)
            if prev_coop >= self.m:
                return Action.C
            else:
                self.defect_phase = True
                self.defect_count = 0
                return Action.D
        else:
            self.defect_count += 1
            if self.defect_count < self.p:
                return Action.D
            else:
                self.defect_phase = False
                self.defect_count = 0
                return Action.C

class Strategy_EXPLOITATIVE_487(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game. Cooperates in the first round, then defects if the number of cooperators in the previous round exceeded m; otherwise, continues to cooperate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_prev = history.my_actions[prev_round]
            sum_others = np.sum(history.opponent_actions[prev_round])
            total_coops = int(my_prev) + sum_others
            if total_coops > self.game_description.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_488(BaseStrategy):
    """
    Exploitative strategy for the Collective Risk Dilemma.
    Cooperates initially, then cooperates if enough others did previously, 
    otherwise defects. Resets to cooperate after 3 consecutive defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_d_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_opponent_actions = history.opponent_actions[-1]
        prev_my_action = history.my_actions[-1]
        prev_coop = sum(prev_opponent_actions) + (1 if prev_my_action else 0)
        m = self.game_description.m
        if prev_coop >= m:
            default_action = Action.C
        else:
            default_action = Action.D
        if self.consecutive_d_count >= 3:
            action = Action.C
            self.consecutive_d_count = 0
        else:
            action = default_action
            if action == Action.D:
                self.consecutive_d_count += 1
            else:
                self.consecutive_d_count = 0
        return action

class Strategy_EXPLOITATIVE_489(BaseStrategy):
    """
    An exploitative strategy for the Collective Risk Dilemma game. It starts by cooperating, 
    then dynamically adjusts its behavior based on the level of cooperation observed in previous rounds.
    The strategy uses a moving threshold to decide whether to cooperate or defect, adjusting the threshold 
    each round based on the previous round's cooperation rate. It defects in the last round to avoid exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = float(game_description.m)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_actions_prev = history.opponent_actions[prev_round]
        n_coop_prev = sum(opponent_actions_prev) + (1 if my_prev_action else 0)
        current_threshold = self.threshold
        if n_coop_prev >= current_threshold:
            action = Action.C
            self.threshold = min(current_threshold + 0.1, self.game_description.n_players)
        else:
            action = Action.D
            self.threshold = max(current_threshold - 0.1, 0.0)
        return action

class Strategy_EXPLOITATIVE_490(BaseStrategy):
    """
    Adaptive strategy for the Collective Risk Dilemma balancing cooperation and defection.
    Cooperates initially, continues if enough players cooperate previously, and defects in the last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.n_rounds - 1:
            return Action.D
        prev_round = state.round_number - 1
        my_prev_coop = history.my_actions[prev_round]
        opponent_prev_coops = sum(history.opponent_actions[prev_round, :])
        total_prev_coops = (1 if my_prev_coop else 0) + opponent_prev_coops
        if total_prev_coops >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_491(BaseStrategy):
    """
    Exploitative Strategy for Collective Risk Dilemma. Cooperate first, then defect if past cooperation meets threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            t = state.round_number
            sum_coop = 0
            for round in range(t):
                my_action = history.my_actions[round]
                opponent_actions = history.opponent_actions[round]
                total = my_action + opponent_actions.sum()
                sum_coop += total
            average = sum_coop / t
            if average >= self.game_description.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_492(BaseStrategy):
    """
    An exploitative strategy for the Collective Risk Dilemma that balances cooperation with opportunistic defection.
    Cooperates initially, defects when cooperation thresholds are met in subsequent rounds, and always defects in the final round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            prev_round = state.round_number - 1
            my_prev = history.my_actions[prev_round]
            opponents_prev = history.opponent_actions[prev_round]
            sum_opponents = np.sum(opponents_prev)
            total_coop = my_prev + sum_opponents
            if total_coop >= self.game_description.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_493(BaseStrategy):
    """
    Adaptive Cooperation Strategy based on recent history of cooperation levels.
    Cooperates if at least m players cooperated in the previous round, otherwise defects.
    Cooperates in the first round to encourage initial cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_my_action = history.my_actions[state.round_number - 1]
        prev_opponent_actions = history.opponent_actions[state.round_number - 1, :]
        sum_opponents = np.sum(prev_opponent_actions)
        total_coop = prev_my_action + sum_opponents
        if total_coop >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_494(BaseStrategy):
    """
    History-Based Conditional Cooperation (HBCC) strategy for the Collective Risk Dilemma.
    Cooperates in the first round and adapts based on the number of cooperators in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_my_action = history.my_actions[state.round_number - 1]
        prev_opponent_actions = history.opponent_actions[state.round_number - 1, :]
        total_coop = int(prev_my_action) + np.sum(prev_opponent_actions)
        if total_coop >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_495(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that Cooperates initially, 
    continues Cooperating if threshold is met, and Defects in the last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.n_rounds - 1:
            return Action.D
        else:
            prev_round = state.round_number - 1
            my_prev_action = history.my_actions[prev_round]
            opponent_prev_actions = history.opponent_actions[prev_round, :]
            total_coop = my_prev_action + np.sum(opponent_prev_actions)
            if total_coop >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_496(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that adaptively cooperates or defects based on previous rounds.
    Cooperates initially, then responds to the number of cooperators in the previous round.
    Resets to cooperation after two consecutive defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = state.round_number - 1
        opponent_actions = history.opponent_actions[last_round]
        opponent_coop = sum(opponent_actions)
        my_last_action = history.my_actions[last_round]
        my_c = 1 if my_last_action else 0
        total_coop_prev = opponent_coop + my_c
        if total_coop_prev >= self.game_description.m:
            return Action.C
        else:
            if state.round_number >= 2:
                two_rounds_back = last_round - 1
                if two_rounds_back >= 0:
                    my_two_ago = history.my_actions[two_rounds_back]
                    my_last = history.my_actions[last_round]
                    if not my_two_ago and (not my_last):
                        return Action.C
            return Action.D

class Strategy_EXPLOITATIVE_497(BaseStrategy):

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            opp_actions_prev = history.opponent_actions[prev_round]
            c_opp_prev = sum(opp_actions_prev)
            my_prev = history.my_actions[prev_round]
            c_total_prev = c_opp_prev + (1 if my_prev else 0)
            m = self.game_description.m
            if c_total_prev >= m:
                return Action.C
            elif c_total_prev + 1 >= m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_498(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that balances cooperation and exploitation.
    It starts with cooperation, adapts based on the number of cooperators, and uses
    payoff comparisons to adjust its behavior over time.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.wait_until = None
        self.defect_start = 0
        self.coop_payoffs = []
        self.defect_payoffs = []
        self.last_processed = 0

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if history is not None:
            new_rounds = len(history.my_actions)
            for t in range(self.last_processed, new_rounds):
                if history.my_actions[t]:
                    self.coop_payoffs.append(history.my_payoffs[t])
                else:
                    self.defect_payoffs.append(history.my_payoffs[t])
            self.last_processed = new_rounds
        if state.round_number == 0:
            return Action.C
        if self.wait_until is not None and state.round_number < self.wait_until:
            return Action.D
        if history is None or len(history.my_actions) < 1:
            return Action.C
        t_minus_1 = state.round_number - 1
        my_prev_action = history.my_actions[t_minus_1]
        opp_prev_actions = history.opponent_actions[t_minus_1]
        total_coop_prev = my_prev_action + sum(opp_prev_actions)
        if total_coop_prev >= self.game_description.m:
            return Action.C
        else:
            current_round = state.round_number
            s = min(self.game_description.n_rounds - current_round, self.game_description.m)
            self.wait_until = current_round + s
            self.defect_start = current_round
            return Action.D
        if state.round_number == self.wait_until:
            current_round = state.round_number
            s = self.wait_until - self.defect_start
            defect_payoffs_during = self.defect_payoffs[-s:] if len(self.defect_payoffs) >= s else self.defect_payoffs
            coop_payoffs_before = self.coop_payoffs[-s:] if len(self.coop_payoffs) >= s else self.coop_payoffs
            if len(defect_payoffs_during) == 0:
                avg_defect = 0.0
            else:
                avg_defect = sum(defect_payoffs_during) / len(defect_payoffs_during)
            if len(coop_payoffs_before) == 0:
                avg_coop = 0.0
            else:
                avg_coop = sum(coop_payoffs_before) / len(coop_payoffs_before)
            if avg_defect > avg_coop:
                new_s = min(self.game_description.n_rounds - current_round, self.game_description.m)
                self.wait_until = current_round + new_s
                self.defect_start = current_round
                return Action.D
            else:
                self.wait_until = None
                return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C

class Strategy_EXPLOITATIVE_499(BaseStrategy):
    """
    Exploitative Cooperation Based on Past Performance Strategy.

    This strategy starts by cooperating in the first round to encourage cooperation.
    In subsequent rounds, it defects if at least m players cooperated in the previous round,
    otherwise it continues to cooperate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev = history.my_actions[prev_round]
        opp_actions = history.opponent_actions[prev_round, :]
        total_coop_prev = my_prev + np.sum(opp_actions)
        if total_coop_prev >= self.game_description.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_500(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game that balances individual payoff with collective cooperation.
    Cooperates initially and defects only when safe to maintain the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_actions_prev = history.opponent_actions[prev_round, :]
        sum_opponents = np.sum(opponent_actions_prev)
        c_last = my_prev_action + sum_opponents
        if c_last >= self.game_description.m + 1:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_501(BaseStrategy):
    """
    Cooperate in the first round. In subsequent rounds, Cooperate if at least m players Cooperated in the previous round; otherwise, Defect.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponents_prev_actions = history.opponent_actions[prev_round]
        total_coop = my_prev_action + np.sum(opponents_prev_actions)
        if total_coop >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_502(BaseStrategy):
    """
    A strategy that begins with cooperation and adapts based on the average number 
    of cooperators in previous rounds. It switches to defection if the average 
    cooperation falls below the required threshold and resumes cooperation if 
    the average improves.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        sum_coop = 0
        num_rounds = state.round_number
        for r in range(num_rounds):
            my_action = history.my_actions[r]
            my_c = 1 if my_action else 0
            opponent_actions_r = history.opponent_actions[r, :]
            opponents_c = sum(opponent_actions_r)
            sum_coop += my_c + opponents_c
        average_coop = sum_coop / num_rounds
        if average_coop >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_503(BaseStrategy):
    """
    A strategy that adaptively responds to previous rounds' outcomes, 
    encouraging cooperation when beneficial and defecting otherwise.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t_prev = state.round_number - 1
        my_prev_action = history.my_actions[t_prev]
        opponents_prev_actions = history.opponent_actions[t_prev, :]
        coop_count = int(my_prev_action) + np.sum(opponents_prev_actions)
        if coop_count >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_504(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that maximizes individual payoff 
    while helping meet the cooperation threshold. Cooperates initially, then defects
    if the prior round had enough cooperators (>= m+1) to make defection safe.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            prev_round = state.round_number - 1
            my_coop = history.my_actions[prev_round]
            opponent_coop = sum(history.opponent_actions[prev_round, :])
            total_coop = my_coop + opponent_coop
            if total_coop >= self.game_description.m + 1:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_505(BaseStrategy):
    """
    An exploitative strategy for the Collective Risk Dilemma that adapts based on previous rounds.
    Cooperates initially and in subsequent rounds only if necessary to meet the cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            t_prev = state.round_number - 1
            my_prev_action = history.my_actions[t_prev]
            opponent_actions = history.opponent_actions[t_prev]
            s_prev = my_prev_action + opponent_actions.sum()
            if s_prev - my_prev_action >= self.game_description.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_507(BaseStrategy):
    """
    Reactive Cooperation Strategy:
    Cooperate if at least m players cooperated in the previous round.
    Always cooperate in the first round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m_threshold = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opp_prev_actions = history.opponent_actions[prev_round, :]
        my_c = 1 if my_prev_action else 0
        opp_c = sum(opp_prev_actions)
        total_c = my_c + opp_c
        if total_c >= self.m_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_508(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game. It starts by cooperating, 
    then decides based on the historical success rate of cooperation meeting the required threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        count_successful = 0
        for round in range(state.round_number):
            my_action = history.my_actions[round]
            opponent_actions_in_round = history.opponent_actions[round, :]
            coop_opponents = np.sum(opponent_actions_in_round)
            total_coop = 1 if my_action else 0
            total_coop += coop_opponents
            if total_coop >= self.m:
                count_successful += 1
        if state.round_number == 0:
            return Action.C
        success_rate = count_successful / state.round_number
        threshold = self.m / self.n_players
        if success_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_509(BaseStrategy):
    """
    This strategy starts by cooperating in the first round to encourage others.
    In subsequent rounds, it cooperates if the number of cooperators in the previous round met or exceeded m.
    Otherwise, it defects to avoid exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_prev_actions = history.opponent_actions[prev_round, :]
        total_cooperators = my_prev_action + sum(opponent_prev_actions)
        if total_cooperators >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_510(BaseStrategy):
    """
    An adaptive strategy for the Collective Risk Dilemma. Cooperates initially and continues if the historical success rate meets the threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        game = self.game_description
        m = game.m
        n = game.n_players
        target_proportion = m / n
        total_rounds = state.round_number
        success_count = 0
        for r in range(total_rounds):
            my_action = history.my_actions[r]
            my_contribution = 1 if my_action else 0
            opponent_contributions = np.sum(history.opponent_actions[r, :])
            total_cooperators = my_contribution + opponent_contributions
            if total_cooperators >= m:
                success_count += 1
        proportion = success_count / total_rounds
        if proportion >= target_proportion:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_511(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma game. It cooperates initially, then 
    adapts based on the number of cooperators in the previous round. If the number 
    meets or exceeds the threshold m, the player defects; otherwise, continues to 
    cooperate. This balances exploitation with necessary contributions to maximize 
    individual payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_last_action = history.my_actions[prev_round]
        my_coop = 1 if my_last_action else 0
        opponent_coops = np.sum(history.opponent_actions[prev_round, :])
        total_coop = my_coop + opponent_coops
        if total_coop >= self.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_512(BaseStrategy):
    """
    Enhanced Exploitative Adaptive Strategy (EEAS) for the Collective Risk Dilemma game.
    Dynamically adjusts cooperation based on recent history and calculated thresholds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        initial_threshold = self.m / self.n_players * 1.2
        self.initial_threshold = min(initial_threshold, 1.0)
        self.threshold = self.initial_threshold
        self.defect_until = -1
        self.all_cooperation = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        if t == 0:
            return Action.C
        if history is None:
            history = PlayerHistory(my_actions=np.array([], dtype=bool), my_payoffs=np.array([], dtype=np.float64), opponent_actions=np.array([], dtype=bool), opponent_payoffs=np.array([], dtype=np.float64))
        if self.defect_until > t:
            self._update_cooperation(history, t - 1)
            return Action.D
        if t == self.n_rounds - 1:
            if len(self.all_cooperation) == 0:
                return Action.C
            overall_avg = np.mean(self.all_cooperation)
            if overall_avg >= self.initial_threshold:
                return Action.C
            else:
                return Action.D
        self._update_cooperation(history, t - 1)
        window = range(max(0, t - 5), t)
        coop_rates = []
        for r in window:
            if r >= len(history.my_actions):
                my_prev = False
            else:
                my_prev = history.my_actions[r]
            if r >= history.opponent_actions.shape[0]:
                opponent_sum = 0
            else:
                opponent_sum = history.opponent_actions[r].sum()
            rate = (my_prev + opponent_sum) / self.n_players
            coop_rates.append(rate)
        if not coop_rates:
            avg_coop = 0.0
        else:
            avg_coop = np.mean(coop_rates)
        self.threshold = 0.9 * self.threshold + 0.1 * avg_coop
        if avg_coop >= self.threshold:
            return Action.C
        else:
            shortfall = self.threshold - avg_coop
            if shortfall <= 0:
                defect_rounds = 1
            else:
                defect_rounds = max(1, int(round(shortfall / 0.1)))
                defect_rounds = min(defect_rounds, self.n_rounds - t)
            self.defect_until = t + defect_rounds - 1
            if self.defect_until >= self.n_rounds:
                self.defect_until = self.n_rounds - 1
            return Action.D

    def _update_cooperation(self, history: PlayerHistory, r: int) -> None:
        if r >= 0 and r < len(history.my_actions):
            my_prev = history.my_actions[r]
            opponent_sum = 0
            if r < history.opponent_actions.shape[0]:
                opponent_sum = history.opponent_actions[r].sum()
            rate = (my_prev + opponent_sum) / self.n_players
            self.all_cooperation.append(rate)

class Strategy_EXPLOITATIVE_439(BaseStrategy):
    """
    Adaptive Cooperation with Punishment (ACP) strategy.
    Cooperates initially, punishes lack of sufficient cooperation,
    and adapts based on payoff trends.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.is_punishing = False
        self.punishment_remaining = 0
        self.punishment_duration = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            my_payoffs = history.my_payoffs
            n = len(my_payoffs)
            mid = n // 2
            sum_first_half = my_payoffs[:mid].sum() if mid > 0 else 0
            sum_second_half = my_payoffs[mid:].sum()
            if sum_second_half > sum_first_half:
                return Action.C
            else:
                return Action.D
        if self.is_punishing:
            my_last_action = history.my_actions[-1]
            opponent_last_actions = history.opponent_actions[-1, :]
            last_coop = int(my_last_action) + int(opponent_last_actions.sum())
            if last_coop >= self.game_description.m:
                self.is_punishing = False
                self.punishment_remaining = 0
            elif self.punishment_remaining > 0:
                self.punishment_remaining -= 1
                return Action.D
            else:
                self.is_punishing = False
                self.punishment_remaining = 0
        my_last_action = history.my_actions[-1]
        opponent_last_actions = history.opponent_actions[-1, :]
        last_coop = int(my_last_action) + int(opponent_last_actions.sum())
        payoffs = history.my_payoffs
        trend_positive = False
        if len(payoffs) >= 2:
            sum_last_two = payoffs[-2:].sum()
            sum_first_two = payoffs[:2].sum()
            trend_positive = sum_last_two > sum_first_two
        if last_coop >= self.game_description.m and trend_positive:
            return Action.C
        else:
            self.is_punishing = True
            self.punishment_remaining = self.punishment_duration
            return Action.D

class Strategy_EXPLOITATIVE_440(BaseStrategy):
    """
    A strategy that begins by cooperating and adapts based on the success of previous rounds.
    It defects if insufficient players cooperate, but periodically tests cooperation again.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consec_defections = 0
        self.s = self.game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = state.round_number - 1
        my_prev_action = history.my_actions[prev_round]
        opponent_actions_prev = history.opponent_actions[prev_round, :]
        sum_opponent_C = np.sum(opponent_actions_prev)
        my_C = 1 if my_prev_action else 0
        total_C = sum_opponent_C + my_C
        if total_C >= self.game_description.m:
            self.consec_defections = 0
            return Action.C
        else:
            self.consec_defections += 1
            if self.consec_defections >= self.s:
                self.consec_defections = 0
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_448(BaseStrategy):
    """
    Adaptive Cooperation with Probing (ACAP) strategy for the Collective Risk Dilemma.
    Cooperates initially, defects if cooperation isn't sufficient, and periodically probes cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.current_mode = 'cooperate'
        self.defect_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1
        my_prev_action = history.my_actions[previous_round]
        my_contribution = 1 if my_prev_action else 0
        others_prev_actions = history.opponent_actions[previous_round]
        prev_coop_count = my_contribution + sum(others_prev_actions)
        if self.current_mode == 'cooperate':
            if prev_coop_count >= self.game_description.m:
                return Action.C
            else:
                self.current_mode = 'defect'
                self.defect_counter = 0
                return Action.D
        elif self.current_mode == 'defect':
            if self.defect_counter < 3:
                self.defect_counter += 1
                return Action.D
            else:
                self.current_mode = 'probe'
                self.defect_counter = 0
                return Action.C
        elif self.current_mode == 'probe':
            if prev_coop_count >= self.game_description.m:
                self.current_mode = 'cooperate'
                return Action.C
            else:
                self.current_mode = 'defect'
                self.defect_counter = 0
                return Action.D

class Strategy_EXPLOITATIVE_454(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that starts with cooperation, 
    adapts based on the number of cooperators, tracks trends, forgives after 
    defection, and handles the last round specially.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.coop_counts = []
        self.last_action = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            action = Action.C
            self.last_action = action
            return action
        else:
            prev_round = state.round_number - 1
            my_last_action = history.my_actions[prev_round]
            opponents_last_actions = history.opponent_actions[prev_round]
            total_c_last_round = my_last_action + sum(opponents_last_actions)
            self.coop_counts.append(total_c_last_round)
            m = self.game_description.m
            if total_c_last_round >= m:
                action = Action.C
            else:
                trend_positive = False
                if len(self.coop_counts) >= 2:
                    trend_positive = self.coop_counts[-1] > self.coop_counts[-2]
                if trend_positive:
                    action = Action.C
                else:
                    action = Action.D
                if self.last_action == Action.D and trend_positive:
                    action = Action.C
                if state.round_number == self.game_description.n_rounds - 1:
                    if not trend_positive:
                        action = Action.D
            self.last_action = action
            return action

class Strategy_EXPLOITATIVE_459(BaseStrategy):
    """
    Adaptive Exploitation Strategy for the Collective Risk Dilemma.
    Cooperates initially and adapts based on past cooperation levels, defecting when safe to maximize payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        game = self.game_description
        m = game.m
        n_rounds = game.n_rounds
        if t == 0:
            return Action.C
        else:
            past_coops = []
            for i in range(t):
                my_action = history.my_actions[i]
                opponent_actions_i = history.opponent_actions[i]
                coop = int(my_action) + np.sum(opponent_actions_i)
                past_coops.append(coop)
            if t == n_rounds - 1:
                if not past_coops:
                    return Action.D
                avg = sum(past_coops) / len(past_coops)
                if avg >= m:
                    return Action.D
                else:
                    return Action.C
            else:
                last_coop = past_coops[-1]
                if last_coop >= m:
                    n_last = min(3, len(past_coops))
                    avg_last_3 = sum(past_coops[-n_last:]) / n_last
                    if avg_last_3 >= m * 1.1:
                        return Action.D
                    else:
                        return Action.C
                else:
                    return Action.C

class Strategy_EXPLOITATIVE_506(BaseStrategy):
    """
    This strategy starts by cooperating in the first round and then uses the historical average of cooperators
    to decide actions in subsequent rounds. It cooperates if adding its cooperation would bring the average
    to meet or exceed the threshold `m`.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        sum_S = 0
        for r in range(state.round_number):
            opp_actions = history.opponent_actions[r]
            opp_coop = np.sum(opp_actions)
            my_coop = 1 if history.my_actions[r] else 0
            S_r = opp_coop + my_coop
            sum_S += S_r
        num_rounds = state.round_number
        average_S = sum_S / num_rounds
        if average_S + 1 >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_442(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma that starts with cooperation, then 
    adapts based on whether enough players cooperated in the previous round, and 
    defects in the final 20% of rounds to avoid exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        r = self.game_description.n_rounds
        if current_round / r >= 0.8:
            return Action.D
        else:
            prev_round = current_round - 1
            my_coop_prev = history.my_actions[prev_round]
            opp_coop = sum(history.opponent_actions[prev_round, :])
            total_coop_prev = my_coop_prev + opp_coop
            if total_coop_prev >= self.game_description.m:
                return Action.C
            else:
                return Action.D