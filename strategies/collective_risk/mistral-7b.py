"""
Generated LLM strategies for social dilemma games.

This file contains strategy classes generated by LLMs for game theory experiments.
Each strategy is a callable class that implements a specific approach to the game.

Generated with:
- Provider: Client
- Model: mistral:latest
- Game: collective_risk
"""

from dataclasses import dataclass
from enum import Enum
import math
import numpy as np
from numpy.typing import NDArray
import random

from emergent_llm.players import BaseStrategy
from emergent_llm.games import PublicGoodsDescription, CollectiveRiskDescription, CommonPoolDescription, CommonPoolState
from emergent_llm.common import Action, C, D, PlayerHistory, GameState




class Strategy_COLLECTIVE_3(BaseStrategy):
    """Adaptive Tit-for-Tat strategy for the Collective Risk Dilemma game."""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_players = max(1, math.ceil(game_description.n_players * 0.5))
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds, dtype=np.float64), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros((game_description.n_rounds, game_description.n_players), dtype=np.float64))

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if state.round_number == 0:
            self.history.my_actions[0] = True
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.min_players and history.my_payoffs[-1] != 1 + (self.game_description.k - 1):
            self.history.my_actions[-1] = True
            return Action.C
        self.history.my_actions[-1] = False
        return Action.D

class Strategy_COLLECTIVE_6(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation (TFT-AC)

    This strategy mirrors opponent behavior while maintaining adaptability to different player strategies. It starts cooperatively, encourages others to follow suit, and punishes defection through the adaptation mechanism.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.p = 0.8
        self.q = 0.5
        self.s = 10
        self.h = 0.7
        self.strategy = Action.C

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and (not history):
            return Action.C
        payoffs = np.zeros(self.game_description.n_players)
        cooperators = np.zeros(self.game_description.n_rounds, dtype=int)
        if history:
            for t in range(1, state.round_number + 1):
                cooperated = history.opponent_actions[t - 1].tolist()
                cooperators[t] = sum(cooperated)
                if cooperators[t] >= self.game_description.n_players * (self.game_description.m / self.game_description.n_players):
                    payoffs[history.my_actions[t - 1].astype(int)] += self.game_description.k
                payoffs[history.my_actions[t - 1].astype(int)] += 1
        if state.round_number < self.s:
            return self.strategy
        count_defectors = np.mean(history.opponent_actions[:, :self.game_description.n_players - 1].astype(int) > 0) * self.game_description.n_rounds
        if count_defectors > self.p * self.game_description.n_players:
            self.strategy = Action.D
        count_cooperators = np.mean(history.opponent_actions[:, :self.game_description.n_players - 1].astype(int) == 1) * self.game_description.n_rounds
        if count_cooperators > self.q * self.game_description.n_players:
            self.strategy = Action.C
        if state.round_number == self.game_description.n_rounds - 1 and np.mean(payoffs) > self.h:
            self.strategy = Action.C
        return self.strategy

class Strategy_COLLECTIVE_9(BaseStrategy):
    """
    A Tit-for-Tat with Adaptive Cooperation (TFT-AC) strategy for the Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.forgiveness = game_description.n_rounds // 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            history = PlayerHistory(my_actions=np.array([[Action.C]], dtype=bool), my_payoffs=np.array([]), opponent_actions=np.zeros((state.round_number, self.game_description.n_players), dtype=bool), opponent_payoffs=np.zeros(state.round_number))
        history.my_actions = np.append(history.my_actions, [Action.C] if state.round_number > self.forgiveness else history.my_actions[-1])
        history.my_payoffs = np.append(history.my_payoffs, np.zeros(1))
        opponent_cooperators = np.sum(history.opponent_actions[:, -1], axis=0)
        if opponent_cooperators < self.game_description.n_players // self.game_description.m:
            history.my_payoffs[-1] += 1
            return Action.D
        else:
            history.my_payoffs[-1] += 1 + self.game_description.k
            return Action.C

class Strategy_COLLECTIVE_10(BaseStrategy):
    """
    Implementation of Tit-for-Tat with Adaptive Threshold (TFT-AT) strategy.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.num_players = game_description.n_players
        self.min_cooperators = game_description.m
        self.num_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.min_cooperators
        self.average_cooperation = 0.0
        self.history_length = self.num_rounds if self.num_rounds > 0 else 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        self.average_cooperation = np.mean(history.my_actions[:state.round_number])
        self.threshold = self.min_cooperators + (self.threshold - self.min_cooperators) * math.exp(-state.round_number / self.num_rounds) * (len(history.my_actions[history.my_actions > 0]) / self.history_length - self.average_cooperation)
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.threshold:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_11(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m
        self.s = math.ceil(self.game_description.n_players * self.game_description.n_rounds / self.m)
        self.avg_cooperators = np.zeros(self.game_description.n_rounds + 1)
        self.consecutive_cooperation_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and len(history.my_actions) < self.s):
            return Action.C
        cooperators = sum(history.opponent_actions[-self.s:, :] if history else np.zeros((self.s, self.game_description.n_players)).flatten())
        avg_cooperators = self.avg_cooperation_rate(cooperators, self.consecutive_cooperation_count)
        return Action.C if avg_cooperators >= self.m else Action.D

    def average_counter_reset(self):
        self.avg_cooperators[:self.consecutive_cooperation_count] = 0
        self.consecutive_cooperation_count = 0

    def consecutive_cooperation_increment(self):
        self.consecutive_cooperation_count += 1

    def average_counter_increment(self, cooperators: int) -> float:
        self.consecutive_cooperation_increment()
        self.avg_cooperators[self.consecutive_cooperation_count] = cooperators
        return np.mean(self.avg_cooperators[-self.s:])

    def average_cooperation_rate(self, cooperators: int, consecutive_cooperation_count: int) -> float:
        if consecutive_cooperation_count == 0:
            return cooperators / self.m if self.m else 0.5
        else:
            self.average_counter_reset()
            return self.average_counter_increment(cooperators)

class Strategy_COLLECTIVE_12(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) Strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.minimum_cooperators = math.ceil(self.game_description.m - 1)
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and np.all(history.my_actions == 0)):
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.minimum_cooperators:
            self.consecutive_defections = 0
            return Action.C
        else:
            if np.all(history.my_actions == 0) and history is not None and (history.opponent_actions.shape[0] > 1):
                self.consecutive_defections += 1
                if self.consecutive_defections < self.minimum_cooperators:
                    return Action.C
            return Action.D

class Strategy_COLLECTIVE_13(BaseStrategy):
    """
    A Tit-for-Tat Adaptive Cooperative Strategy (TFTAC) for the Collective Risk Dilemma game.
    The strategy prioritizes cooperation when possible, aiming to meet or exceed the minimum threshold needed for collective success.
    It also encourages a collaborative environment where players reward each other for cooperative actions and forgiveness is shown to defecting opponents.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = np.zeros((1, 2), dtype=bool)
        self.my_payoffs = np.zeros(self.game_description.n_rounds, dtype=np.float64)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and history.my_actions[-1].any():
            return Action.C
        opponent_cooperators = history.opponent_actions[-1].sum()
        threshold_reached = opponent_cooperators >= self.game_description.n_players // 2
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C if threshold_reached else Action.D
        response_to_opponent = self.opponent_history[-1][0] and (not history.my_actions[-1]) or (not self.opponent_history[-1][0] and history.my_actions[-1])
        if response_to_opponent:
            return Action.D
        if threshold_reached:
            self.opponent_history = np.vstack((self.opponent_history, history.opponent_actions[-1]))
        else:
            self.opponent_history = np.vstack((self.opponent_history, np.full(len(history.opponent_actions), False)))
        return Action.C if threshold_reached else Action.D

class Strategy_COLLECTIVE_14(BaseStrategy):
    """Adaptive Tit-for-Tat strategy for Collective Risk Dilemma"""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = [Action.C]

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperators = np.count_nonzero(history.opponent_actions[-1])
        if cooperators >= self.game_description.m and history.my_actions[-1] == Action.C:
            return Action.C
        elif cooperators < self.game_description.m or history.my_actions[-1] != Action.C:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C if history.my_actions[-2] == Action.C else Action.D

class Strategy_COLLECTIVE_16(BaseStrategy):
    """
    The Titan Strategy for Collective Risk Dilemma (TRC)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.total_payoff = 0
        self.round_history = []

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if len(self.round_history) == self.game_description.n_rounds:
            self._update_total_payoff()
            if self.total_payoff > self.game_description.k * (self.game_description.n_players - self.game_description.m):
                return Action.C
            else:
                return Action.D
        cooperators = sum(history.opponent_actions[-1, :])
        p_coop = cooperators / self.game_description.n_players
        if p_coop >= self.game_description.m / self.game_description.n_players:
            return Action.C
        return Action.D

    def _update_total_payoff(self):
        payoffs = np.array([history.my_payoffs[-1] for history in self.round_history])
        self.total_payoff += payoffs.sum()
        self.round_history.append(None)

class Strategy_COLLECTIVE_17(BaseStrategy):
    """
    Tit-for-Tat Adaptive Cooperation (TFTAC) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.accumulated_reward = 0
        self.strategy = Action.C

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            partner_actions = history.opponent_actions[-1]
            self.accumulated_reward += np.sum(history.my_payoffs)
            if self.game_description.m <= partner_actions.sum() + 1 and self.accumulated_reward > self.game_description.m - 1:
                self.strategy = Action.C
            else:
                self.strategy = Action.D
        return self.strategy

class Strategy_COLLECTIVE_19(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) Strategy for the Collective Risk Dilemma Game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = []

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if history is None and state.round_number == 0:
            return Action.C
        self.opponent_history.append(np.mean(history.opponent_actions[-1]))
        opponent_cooperation = sum([1 for action in self.opponent_history[-self.game_description.n_players:] if action > 0.5])
        if opponent_cooperation > self.game_description.n_players - self.game_description.m:
            return Action.D
        elif np.all(history.opponent_actions[-1] == 0) or opponent_cooperation == 0:
            return Action.D
        else:
            return Action.C
        if state.round_number == self.game_description.n_rounds:
            return Action.C

class Strategy_COLLECTIVE_21(BaseStrategy):
    """
    A strategy that cooperates initially and adapts cooperation threshold based on previous round's cooperators count.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m_t = (game_description.n_players + 1) // 2 if game_description.n_players % 2 else game_description.n_players // 2
        self.last_round_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        self.last_round_cooperators = cooperators
        if cooperators < self.m_t and self.m_t > 1:
            self.m_t -= 1
        return Action.C if cooperators >= self.game_description.m or self.m_t == 1 else Action.D

    def last_round(self) -> int:
        """
        Returns the number of cooperators in the most recent round.
        """
        return self.last_round_cooperators

class Strategy_COLLECTIVE_22(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Threshold Adaptation (TTTA)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = (game_description.m + 1) // 2 if game_description.m % 2 == 1 else game_description.m // game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif history is not None:
            cooperators = np.sum(history.opponent_actions[-1])
            if cooperators / self.game_description.n_players >= self.threshold:
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_23(BaseStrategy):
    """
    A Tit-for-Tat strategy for the Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m
        self.last_round_threshold_met = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if self.last_round_threshold_met and cooperators < self.min_cooperators:
            return Action.D
        elif cooperators >= self.min_cooperators:
            self.last_round_threshold_met = True
            return Action.C
        else:
            self.last_round_threshold_met = False
        return Action.D

class Strategy_COLLECTIVE_24(BaseStrategy):
    """Adaptive Tit-for-Tat Strategy for Collective Risk Dilemma"""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if not history:
            return Action.C
        player_index = state.round_number - 1
        last_round = len(history.opponent_actions) - 1
        if state.round_number == last_round + 1:
            cooperators = sum(history.opponent_actions[last_round])
            if cooperators >= self.m:
                return Action.C
            return Action.D
        return Action.C if history.opponent_actions[last_round][player_index] == Action.C.value else Action.D

class Strategy_COLLECTIVE_25(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Cooperative Bias (ATTCB) strategy for the Collective Risk Dilemma game.
    The strategy promotes cooperation by rewarding cooperation and punishing defection when necessary while maintaining a peaceful and forgiving stance.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.probability_p = 0.2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperation_level = sum(history.opponent_actions[-1]) if history else 0
        if cooperation_level >= self.game_description.m and history:
            return Action.C
        elif cooperation_level < self.game_description.n_players - self.game_description.m or state.round_number == self.game_description.n_rounds:
            return Action.D
        else:
            action = random.choice([Action.C, Action.D]) if random.random() < self.probability_p else Action.C
        return action

class Strategy_COLLECTIVE_26(BaseStrategy):
    """Adaptive Tit-for-Tat (ATFT) strategy for Collective Risk Dilemma"""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m
        self.last_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if not history or state.round_number == 0:
            return Action.C
        self.last_round = state.round_number == self.game_description.n_rounds
        cooperators = sum(history.opponent_actions[-1, :]) if history else 0
        if cooperators >= self.min_cooperators or self.last_round:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_27(BaseStrategy):
    """
    Adaptive Tit-for-Tat Strategy for Collective Risk Dilemma.
    Reciprocates cooperation and punishes defection to promote a collective mindset.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros((game_description.n_rounds, game_description.n_players)))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is not None:
            self.history = history
        cooperators = sum(self.history.opponent_actions[-1, :])
        if cooperators >= self.game_description.m:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_28(BaseStrategy):
    """Adaptive Tit-for-Tat strategy for Collective Risk Dilemma"""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or not self.opponent_history:
            return Action.C
        opponent_action = self.opponent_history[-1]
        if opponent_action == Action.C:
            return Action.C
        elif opponent_action == Action.D and len(self.opponent_history) < state.round_number - 1:
            return Action.C
        else:
            return Action.D
        self.opponent_history.append(opponent_action)

class Strategy_COLLECTIVE_29(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptation (TFT-A)

    Strategy Description: ... (You can include a brief summary of the strategy here)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold_cooperators = game_description.n_players // 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_history = history.opponent_actions if history else np.zeros((1, self.game_description.n_players), dtype=np.bool_)
        cooperators_count = sum(opponent_history[-self.game_description.n_rounds:, -1])
        if cooperators_count >= self.threshold_cooperators * len(opponent_history):
            return Action.C
        if history and history.my_actions[-1]:
            return Action.C
        for i in range(len(opponent_history) - 1, -1, -1):
            if opponent_history[i, -1] == Action.C:
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_30(BaseStrategy):
    """
    Tit-for-Tat Adaptive (TfTA) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[state.round_number - 1, :])
        if cooperators >= self.m or not history:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_31(BaseStrategy):
    """
    A Tit-for-Tat Adaptive Strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.toleranceLevel = 1.0
        self.history = PlayerHistory(my_actions=np.empty((game_description.n_rounds,), dtype=bool), my_payoffs=np.empty((game_description.n_rounds,), dtype=float), opponent_actions=np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), opponent_payoffs=np.zeros((game_description.n_rounds, game_description.n_players), dtype=float))

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if history is not None:
            self.history = history
        if state.round_number == 0 or (history and history.my_actions[-1]):
            action = Action.C
        else:
            action = Action.C if self.history.opponent_actions[-1, state.round_number % len(self.game_description.n_players)] else Action.D
        if self.game_description.m <= np.count_nonzero(self.history.opponent_actions[-1]):
            self.toleranceLevel *= self.game_description.k
        elif not action == self.history.my_actions[-1]:
            self.toleranceLevel /= self.game_description.k
        if state.round_number == self.game_description.n_rounds:
            self.toleranceLevel = 1.0
        return action

class Strategy_COLLECTIVE_32(BaseStrategy):
    """
    The Tit-for-Tat Adaptive (TfTA) strategy in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or self.history is None:
            return Action.C
        if history.my_actions[-1] is None:
            self.history = np.zeros(self.game_description.n_players, dtype=bool)
            cooperators = 0
        else:
            cooperators = sum(history.opponent_actions[-1])
        if cooperators >= self.game_description.m and self.history[-1] is True:
            self.history = np.append(self.history, [True])
            return Action.C
        elif cooperators < self.game_description.m and self.history[-1] is False:
            self.history = np.append(self.history, [False])
            return Action.D
        else:
            self.history = np.append(self.history, [True])
            return Action.C

class Strategy_COLLECTIVE_33(BaseStrategy):
    """
    Adaptive Tit-for-Tat strategy for Collective Risk Dilemma game.
    Prioritizes reciprocity and fairness, encouraging both cooperation and collective success.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.my_actions = np.zeros(game_description.n_rounds, dtype=int)
        self.total_payoff = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number < len(self.my_actions):
            last_opponent_action = history.opponent_actions[state.round_number - 1, :].sum() >= self.game_description.n_players // 2
        else:
            self.total_payoff += np.mean(history.my_payoffs[-self.game_description.n_rounds:]) * (history.opponent_actions[state.round_number - self.game_description.n_rounds:, :].sum(axis=0) >= self.game_description.n_players // 2)
            if np.mean(self.my_actions[:-1]) > self.game_description.n_players - self.game_description.n_players // self.game_description.m:
                last_opponent_action = False
            else:
                last_opponent_action = history.opponent_actions[state.round_number - 1, :].sum() >= self.game_description.n_players // 2
        return Action(last_opponent_action)

class Strategy_COLLECTIVE_34(BaseStrategy):
    """
    An implementation of the Adaptive Tit-for-Tat strategy in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_rounds = game_description.n_players // 2
        self.cooperative_period = game_description.n_rounds - self.punishment_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and history.opponent_actions[-1].all() == [False]):
            return Action.D
        elif history is not None and np.all(history.opponent_actions[:-self.punishment_rounds, -1] == [True]) and np.any(history.opponent_actions[-self.punishment_rounds:-1, -1] == [False]):
            return Action.D
        elif history is not None and (np.all(history.opponent_actions[-self.cooperative_period:, -1] == [True]) or np.any(history.opponent_actions[-self.punishment_rounds:-1, -1] == [False])):
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_35(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = math.floor(self.game_description.m * (self.game_description.n_players / self.game_description.n_rounds))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        elif state.round_number < self.game_description.n_rounds:
            cooperators = sum(history.opponent_actions[state.round_number - 1, :]) if history else 0
            return Action.C if cooperators >= self.cooperation_threshold else Action.D
        elif state.round_number == self.game_description.n_rounds:
            penultimate_cooperators = sum(history.opponent_actions[state.round_number - 1, :]) if history else 0
            return Action.C if penultimate_cooperators >= self.cooperation_threshold else Action.D

class Strategy_COLLECTIVE_36(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.trust_threshold = math.ceil(game_description.n_players * 0.5)
        self.history = PlayerHistory(my_actions=np.zeros(game_description.n_rounds, dtype=bool), my_payoffs=np.zeros(game_description.n_rounds), opponent_actions=np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), opponent_payoffs=np.zeros((game_description.n_rounds, game_description.n_players)))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.history = PlayerHistory(my_actions=np.zeros(self.game_description.n_rounds, dtype=bool), my_payoffs=np.zeros(self.game_description.n_rounds), opponent_actions=np.zeros((self.game_description.n_rounds, self.game_description.n_players), dtype=bool), opponent_payoffs=np.zeros((self.game_description.n_rounds, self.game_description.n_players)))
        if state.round_number == 0:
            return Action.C
        else:
            cooperators = sum(history.opponent_actions[-1])
            if cooperators >= self.trust_threshold:
                self.history.my_actions[-1] = True
                self.history.my_payoffs[-1] = self.game_description.k - 1 if cooperators >= self.game_description.m else 1
            else:
                self.history.my_actions[-1] = False
                self.history.my_payoffs[-1] = 1
        return Action(self.history.my_actions[-1])

class Strategy_COLLECTIVE_37(BaseStrategy):
    """
    A Tit-for-Tat (TFT) strategy with an adaptive cooperation threshold (AC-TFT) for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.payoff = np.zeros(game_description.n_rounds)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None:
            n_c = 0
        else:
            n_c = sum(history.opponent_actions[-1, :])
        if n_c >= self.cooperation_threshold:
            self.payoff[state.round_number - 1] = 1 - Action.D.value + self.game_description.k
            return Action.C
        else:
            self.payoff[state.round_number - 1] = 1 - Action.C.value
            return Action.D
        if state.round_number == self.game_description.n_rounds:
            if self.cooperation_threshold > self.game_description.m:
                return Action.D
            else:
                return Action.C

class Strategy_COLLECTIVE_40(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.ct = 0
        self.sliding_window_size = math.ceil(self.game_description.n_rounds * 0.1)
        self.cooperation_success_rate = np.zeros(int(self.sliding_window_size))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            cooperators = sum(history.opponent_actions[-self.sliding_window_size:, :].sum(axis=0))
            self.cooperation_success_rate = np.roll(self.cooperation_success_rate, -1)
            self.cooperation_success_rate[int(self.sliding_window_size) - 1] = cooperators >= self.m
            if state.round_number == self.game_description.n_rounds - 1:
                if self.cooperation_success_rate[-1]:
                    return Action.C
            if self.ct < self.game_description.n_players - self.m + 1:
                if cooperators >= (self.m - 1) * (self.n_players + 1) // (2 * self.m):
                    self.ct += 1
            elif self.ct > 0:
                if cooperators < (self.m - self.ct - 1) * (self.n_players + 1) // (2 * self.m):
                    self.ct -= 1
            action = Action.D
            if self.cooperation_success_rate[-1] >= self.ct:
                action = Action.C
        return action

class Strategy_COLLECTIVE_41(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)

    Strategy that follows a tit-for-tat approach and adapts the cooperation threshold based on historical performance.
    Promotes collective cooperation while being robust to various opponent behaviors in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.m_adjustment = 0.01 * (self.cooperation_threshold - 1)
        self.payoff = 0
        self.last_round_action = None
        self.average_opponent_payoff = 0

    def __call__(self, state: GameState, history: PlayerHistory):
        action = Action.D
        if state.round_number == 0 or not history:
            action = Action.C
        elif state.round_number == self.game_description.n_rounds and self.payoff > self.average_opponent_payoff:
            action = Action.C
        else:
            n_c = sum(history.opponent_actions[state.round_number - 1])
            if n_c >= self.cooperation_threshold:
                action = Action.C
            elif n_c < self.cooperation_threshold - self.m_adjustment:
                self.cooperation_threshold -= self.m_adjustment
            elif self.payoff >= np.mean(history.my_payoffs[:-1]):
                self.cooperation_threshold += self.m_adjustment
            elif self.last_round_action is not None and self.last_round_action == Action.C:
                action = Action.C
            if action == Action.C and self.payoff >= self.average_opponent_payoff:
                self.payoff += 1
            else:
                self.payoff -= np.mean(history.my_payoffs[:-1]) * self.game_description.k if history else 0
        if state.round_number != 0 and (not history):
            history = PlayerHistory(np.array([[self.last_round_action == Action.C]]), np.array([self.payoff]))
        self.average_opponent_payoff = np.mean(history.opponent_payoffs[:-1]) if history else 0
        self.last_round_action = action
        return action

class Strategy_COLLECTIVE_42(BaseStrategy):
    """
    An implementation of the Adaptive Tit-for-Tat strategy in Collective Risk Dilemma game.
    The strategy cooperates initially and adjusts its actions based on opponents' previous behaviors to encourage cooperation while not being exploited.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(my_actions=np.zeros(self.game_description.n_rounds), my_payoffs=np.zeros(self.game_description.n_rounds), opponent_actions=np.zeros((self.game_description.n_rounds, self.game_description.n_players)), opponent_payoffs=np.zeros((self.game_description.n_rounds, self.game_description.n_players)))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.history = PlayerHistory(my_actions=np.zeros(self.game_description.n_rounds), my_payoffs=np.zeros(self.game_description.n_rounds), opponent_actions=np.zeros((self.game_description.n_rounds, self.game_description.n_players)), opponent_payoffs=np.zeros((self.game_description.n_rounds, self.game_description.n_players)))
        if state.round_number == 0:
            self.history.my_actions[state.round_number] = True
        else:
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators >= self.game_description.n_players // 2:
                self.history.my_actions[state.round_number] = True
            else:
                self.history.my_actions[state.round_number] = False
        return Action(self.history.my_actions[state.round_number])

class Strategy_COLLECTIVE_43(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT)

    This strategy employs a Tit-for-Tat approach, adjusting the cooperation threshold based on the majority of cooperators in the previous round.
    If more than half of the players cooperated, it chooses to cooperate; otherwise, it defects. In the first and last rounds, it randomly chooses between cooperation and defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = math.ceil(game_description.n_players / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return random.choice([Action.C, Action.D])
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.threshold:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_44(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Rational Cooperation (TFT-ARC) Strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = []
        self.rational_cooperator = False
        self.punished_irrational = False

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        self.update_opponent_behavior(cooperators)
        if self.punished_irrational and state.round_number != self.game_description.n_rounds - 1:
            return Action.D
        if cooperators >= self.game_description.m:
            return Action.C
        return Action.D

    def update_opponent_behavior(self, cooperators: int) -> None:
        if len(self.opponent_history) == 0:
            self.rational_cooperator = cooperators >= self.game_description.m
            return
        last_round = len(self.opponent_history) - 1
        last_cooperators = self.opponent_history[-1]['my_actions'][-1]
        if cooperators < self.game_description.m and (not self.rational_cooperator):
            self.punished_irrational = True
        elif cooperators >= self.game_description.m and self.rational_cooperator:
            self.punished_irrational = False
        self.opponent_history.append({'my_actions': self.opponent_history[-1]['my_actions'] + [cooperators >= self.game_description.m], 'my_payoffs': self.opponent_history[-1]['my_payoffs'] + [0] if cooperators < self.game_description.m else self.opponent_history[-1]['my_payoffs'] + [self.game_description.k]})

class Strategy_COLLECTIVE_45(BaseStrategy):
    """
    Implementation of Adaptive Tit-for-Tat strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.strategy = [Action.C] * (game_description.n_players + 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1] if history is not None else [0] * self.game_description.n_players)
        if cooperators >= self.game_description.m and self.strategy[-1] == Action.C:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_46(BaseStrategy):
    """
    A strategy inspired by Tit-for-Tat with an adaptive cooperation feature that encourages players to cooperate more frequently when it benefits the collective.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.p = game_description.k - 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        min_cooperators = self.game_description.m - 1 if state.round_number > self.game_description.m else 0
        adaptation_condition = cooperators >= min_cooperators or (random.random() < self.p and cooperators >= min_cooperators - 1)
        return Action(history.my_actions[-1] if history else False) if state.round_number > 0 else Action.C

class Strategy_COLLECTIVE_47(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) Strategy for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is not None:
            cooperators = sum(history.opponent_actions[-1])
            if cooperators < self.min_cooperators:
                return Action.D
            else:
                return Action.C

class Strategy_COLLECTIVE_49(BaseStrategy):
    """
    Tit-for-Tat Adaptive (TFT-A) for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.my_last_action = None
        self.min_cooperators = math.ceil(game_description.m * 0.5)
        self.min_coop_switch = self.min_cooperators - 1
        self.current_round_coop = 0

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if not history and state.round_number == 0:
            return Action.C
        if state.round_number == 1 or self.my_last_action is None:
            self.my_last_action = Action.C
            return self.my_last_action
        coop_count = sum(history.opponent_actions[-1])
        if state.round_number < self.game_description.n_rounds and coop_count >= self.min_cooperators:
            action = Action.C
            self.my_last_action = action
        elif state.round_number == self.game_description.n_rounds and coop_count >= self.min_cooperators:
            action = Action.C
        else:
            action = Action.D
            if coop_count + 1 >= self.min_coop_switch and self.my_last_action == Action.D:
                self.current_round_coop += 1
                self.my_last_action = Action.C
                if self.current_round_coop >= self.min_cooperators:
                    self.current_round_coop = 0
            else:
                self.my_last_action = action
        return self.my_last_action

class Strategy_COLLECTIVE_50(BaseStrategy):
    """
    A strategy that follows the Tit-for-Tat Adaptive (TFTA) rule in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.probability_cooperate = 1.0
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=np.bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players - 1), dtype=np.bool), np.zeros((game_description.n_rounds, game_description.n_players - 1)))

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if history is None:
            return Action.C
        self.history = history
        cooperators_prev = sum(history.opponent_actions[-1])
        self.probability_cooperate = 1.0 if state.round_number == 1 else self.probability_cooperate
        if cooperators_prev >= self.game_description.m:
            return Action.C
        elif random.random() < self.probability_cooperate:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_51(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperative Threshold (TT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(game_description.n_rounds), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players)), np.zeros((game_description.n_rounds, game_description.n_players)))
        self.adaptive_threshold = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[state.round_number - 1, :])
        self.update_adaptive_threshold(cooperators, history)
        if cooperators >= self.adaptive_threshold:
            return Action.C
        return Action.D

    def update_adaptive_threshold(self, cooperators, history):
        total_players = self.game_description.n_players
        if cooperators > total_players - cooperators:
            self.adaptive_threshold = self.game_description.m
        else:
            last_five_rounds = np.array(list(reversed(history.opponent_actions))[-5:])
            average_cooperators = np.mean(last_five_rounds.sum(axis=0)) + 1
            self.adaptive_threshold = self.game_description.m * (average_cooperators / total_players)

class Strategy_COLLECTIVE_52(BaseStrategy):
    """
    Adaptive Tit-for-Tat Strategy for Collective Risk Dilemma Game
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.max_retaliation = math.ceil(self.game_description.n_players / 2)
        self.state = Action.C
        self.deviation_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None and state.round_number == 0:
            return Action.C
        if state.round_number < self.max_retaliation or history.my_actions[-1] == self.state:
            cooperators = sum(history.opponent_actions[-1])
            if cooperators >= self.game_description.m:
                self.state = Action.C
            else:
                self.state = Action.D
        else:
            self.deviation_count = 0
            self.state = Action.C if history.my_payoffs[-1] >= self.game_description.k else Action.D
        if history is not None and state.round_number != 0 and (history.my_actions[-1] != self.state):
            self.deviation_count += 1
        return self.state

class Strategy_COLLECTIVE_53(BaseStrategy):
    """
    A strategy inspired by the Tit-for-Tat game theory concept, which encourages cooperation among players in the Collective Risk Dilemma game.
    The Adaptive version of this strategy implements a forgiveness mechanism, allowing for return to cooperation after a deviation from it.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(my_actions=np.zeros(self.game_description.n_rounds, dtype=bool), my_payoffs=np.zeros(self.game_description.n_rounds), opponent_actions=np.zeros((self.game_description.n_rounds, self.game_description.n_players), dtype=bool), opponent_payoffs=np.zeros((self.game_description.n_rounds, self.game_description.n_players)))

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if not history:
            return Action.C
        opponent_cooperators = sum(history.opponent_actions[state.round_number - 1, :])
        cooperate = opponent_cooperators >= self.game_description.n_players // self.game_description.m
        if state.round_number == 0 or (state.round_number > 0 and (not self.history.my_actions[state.round_number - 1])):
            cooperate = True
        if state.round_number > 0 and self.history.my_actions[state.round_number - 1]:
            cooperate &= cooperate
        self.history.my_actions[state.round_number] = cooperate
        if state.round_number > 0 and (not cooperate) and self.history.my_actions[state.round_number - 1]:
            self.history.my_payoffs[state.round_number - 1] += (self.game_description.k - 1) * (self.game_description.n_players - 1 - opponent_cooperators)
        return Action(int(cooperate)) if cooperate else Action.D

class Strategy_COLLECTIVE_54(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.first_round = True
        self.history = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        self.history = history
        cooperators = sum(history.opponent_actions[-1])
        threshold_met = cooperators >= self.game_description.m
        if state.round_number == self.game_description.n_rounds - 1 or (self.first_round and threshold_met):
            return Action.C
        elif not threshold_met:
            return Action.D
        self.first_round = False
        return Action.C if threshold_met else Action.D

class Strategy_COLLECTIVE_55(BaseStrategy):
    """
    Adaptive Tit-for-Tat strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_first = True
        self.last_round_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is not None:
            self.last_round_cooperators = sum(history.opponent_actions[-1, :])
        if state.round_number == len(history.my_payoffs) - 1 and self.cooperation_first and (self.last_round_cooperators >= self.game_description.n_players - (self.game_description.m - 1)):
            return Action.C
        elif state.round_number == len(history.my_payoffs) - 1:
            return Action.D
        if self.last_round_cooperators >= self.game_description.n_players - (self.game_description.m - 1):
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_56(BaseStrategy):
    """
    Implementation of the Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = math.ceil(game_description.m)
        self.adaptation_rate = 0.1
        self.history = PlayerHistory(np.zeros(self.game_description.n_rounds, dtype=bool), np.zeros(self.game_description.n_rounds), np.zeros((self.game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros(self.game_description.n_rounds))

    def __call__(self, state: GameState, history: None | PlayerHistory):
        self.history = history or self.history
        if state.round_number == 0:
            action = Action.D
        else:
            cooperators = sum(self.history.opponent_actions[-state.round_number:, -1])
            action = Action.C if cooperators >= self.cooperation_threshold else Action.D
        self.history.my_actions[state.round_number - 1] = action == Action.C
        if state.round_number < self.game_description.n_rounds:
            self.cooperation_threshold += (self.history.my_actions[-1] * self.adaptation_rate - (not self.history.my_actions[-1]) * self.adaptation_rate) / (state.round_number - 1)
        return action

class Strategy_COLLECTIVE_58(BaseStrategy):
    """
    Implementation of the Adaptive Tit-for-Tat strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(self.game_description.n_rounds, dtype=bool), np.zeros(self.game_description.n_rounds), np.zeros((self.game_description.n_rounds, self.game_description.n_players), dtype=bool), np.zeros((self.game_description.n_rounds, self.game_description.n_players)))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is None:
            self.history = history
        last_round = self.history.my_actions[-1]
        all_cooperated = np.sum(self.history.opponent_actions[-1, :]) >= self.game_description.m - 1
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        elif all_cooperated and last_round:
            return Action.C
        elif not all_cooperated or not last_round:
            return Action.D
        else:
            return self.__class__.ACTIONS[0]

class Strategy_COLLECTIVE_59(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat Adaptive Cooperation (TFT-AC)
    Strategy Description: A simple yet effective approach that encourages mutual cooperation while being robust against opportunistic behavior.
                           Includes a forgiveness factor for past mistakes, and adjusts according to the number of cooperators in the group.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.forgiveness = 0
        self.opponent_cooperations = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        action = Action.C if state.round_number == 0 else Action.D
        if history is not None:
            self.forgiveness = min(self.game_description.n_players // 2, self.forgiveness + 1)
            if state.round_number < self.game_description.n_rounds and (history.opponent_actions[-1][-1] == Action.D.value and self.forgiveness > self.opponent_cooperations):
                action = Action.D
            elif state.round_number < self.game_description.n_rounds:
                cooperators = sum(history.opponent_actions[-1])
                if cooperators >= self.game_description.m and cooperators >= self.opponent_cooperations + 1 or state.round_number == self.game_description.n_rounds - 1:
                    action = Action.C
            self.opponent_cooperations = sum(history.opponent_actions[-1]) if history is not None else 0
        return action

class Strategy_COLLECTIVE_60(BaseStrategy):
    """
    A strategy based on Tit-for-Tat with an adaptive cooperation threshold for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.adaptation_threshold = self.game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-1] if history else [False])
        if cooperators < self.adaptation_threshold:
            self.adaptation_threshold -= 0.1
            self.adaptation_threshold = max(self.adaptation_threshold, self.game_description.m - self.game_description.n_players + 1)
        return Action.C if self.adaptation_threshold >= self.game_description.m else Action.D

class Strategy_COLLECTIVE_61(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.current_round = 0
        self.cooperation_threshold = int((game_description.m + game_description.n_players - 1) / 2)
        self.history = []
        self.min_CT = math.ceil(self.cooperation_threshold)
        self.max_CT = math.floor(self.cooperation_threshold)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is not None:
            self.history = history.opponent_actions
            self.current_round = len(self.history)
        if state.round_number == 0:
            return Action.C
        else:
            cooperators = np.sum(self.history[-1])
            if cooperators >= self.cooperation_threshold:
                self.cooperation_threshold += 1
            elif cooperators >= self.cooperation_threshold - 1:
                pass
            else:
                self.cooperation_threshold -= 1
            if self.cooperation_threshold < self.min_CT:
                self.cooperation_threshold = self.min_CT
            elif self.cooperation_threshold > self.max_CT:
                self.cooperation_threshold = self.max_CT
        return Action.C if cooperators >= self.cooperation_threshold else Action.D

class Strategy_COLLECTIVE_62(BaseStrategy):
    """
    Titan Strategy for Collective Risk Dilemma (TRD)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = self.game_description.n_players
        self.n_rounds = self.game_description.n_rounds
        self.m = self.game_description.m
        self.k = self.game_description.k
        self.cooperation_threshold = self.m // 2
        self.momentum_factor = 0.5
        self.history = None
        self.player_tally = [0] * self.n_players

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if not history:
            return Action.C if random.random() < self.cooperation_threshold else Action.D
        self.history = history
        self.update_tally(state)
        self.calculate_round_cooperators(state)
        self.adjust_cooperation_threshold()
        return Action.C if self.round_cooperators >= self.cooperation_threshold else Action.D

    def update_tally(self, state: GameState):
        """Update the tally for each player in this round."""
        for i, player_action in enumerate(self.history.opponent_actions[-1]):
            if player_action:
                self.player_tally[i] += 1

    def calculate_round_cooperators(self, state: GameState):
        """Calculate the number of cooperators in this round."""
        self.round_cooperators = sum(self.player_tally)

    def adjust_cooperation_threshold(self):
        """Adjust cooperation threshold based on past outcomes."""
        cooperation_rate = self.round_cooperators / self.n_players
        self.cooperation_threshold = min(max(cooperation_rate, self.m // self.n_players), self.m) * (1 + self.momentum_factor * (self.game_description.n_rounds - self.history.my_payoffs.size))

class Strategy_COLLECTIVE_63(BaseStrategy):
    """
    Strategy for the Collective Risk Dilemma game implementing the Adaptive Tit-for-Tat strategy.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.first_round = True
        self.opponent_history = np.zeros(shape=(1, self.game_description.n_players), dtype=np.bool_)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        action = Action.D
        if state.round_number == 0:
            self.first_round = True
            action = Action.C
        elif not self.first_round and len(history) > 0:
            opponent_coop_count = np.sum(history.opponent_actions[-1, :])
            if opponent_coop_count >= self.game_description.n_players // self.game_description.m:
                action = Action.C
            elif np.any(self.opponent_history[-1, :]):
                action = Action.D
            self.first_round = False
        else:
            self.opponent_history = history.opponent_actions
        if state.round_number == self.game_description.n_rounds:
            self.first_round = True
        return action

class Strategy_COLLECTIVE_64(BaseStrategy):
    """
    Implementation of the Adaptive Tit-for-Tat (ATfT) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and (not history):
            return Action.C
        if history:
            cooperators = sum(history.opponent_actions[-1])
            if cooperators >= self.min_cooperators:
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_65(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Cooperative Bias (ATFCB) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.past_repeated_defection_count = 0
        self.first_round = True

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            self.first_round = True
            return Action.C
        elif state.round_number == 0 and history is not None:
            self.first_round = False
        cooperation_count = np.sum(history.opponent_actions[-1])
        if self.first_round or cooperation_count >= self.cooperation_threshold:
            return Action.C
        if len(history) > self.game_description.k and np.all(history.opponent_actions[:, self.__class__] == Action.D):
            self.past_repeated_defection_count += 1
            if self.past_repeated_defection_count >= self.game_description.k:
                return Action.D
        else:
            self.past_repeated_defection_count = max(0, self.past_repeated_defection_count - 1)
        return Action.D

class Strategy_COLLECTIVE_66(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATFT) for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = self.game_description.n_players // 2
        self.forgiveness_period = math.ceil(self.game_description.n_rounds / 10)
        self.tolerance_multiplier = self.forgiveness_period / self.threshold
        self.tolerance_decay_rate = 1 / self.forgiveness_period
        self.tolerance_level = self.threshold
        self.history = PlayerHistory(np.zeros(self.game_description.n_rounds, dtype=bool), np.zeros(self.game_description.n_rounds), np.zeros((self.game_description.n_rounds, self.game_description.n_players), dtype=bool), np.zeros(self.game_description.n_rounds))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None and state.round_number == 0:
            return Action.C
        if state.round_number > self.forgiveness_period:
            self.tolerance_level = max(self.threshold - int(self.tolerance_decay_rate * self.tolerance_multiplier), 1)
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.tolerance_level:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_67(BaseStrategy):
    """
    Tit-for-Tat Cooperation with Adaptive Risk Aversion (TFTC-ARA) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.k = self.game_description.k
        self.alpha = 0.01
        self.prev_opponent_cooperators = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.prev_opponent_cooperators is None:
            self.prev_opponent_cooperators = sum(history.opponent_actions[0])
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.game_description.m:
            k_adjusted = self.k * (1 + self.alpha if self.prev_opponent_cooperators >= self.game_description.m else 1 - self.alpha)
            return Action(int(k_adjusted > random.random()))
        return Action.D

class Strategy_COLLECTIVE_69(BaseStrategy):
    """
    Implementation of Tit-for-Tat Adaptive Cooperative (TFTAC) strategy for Collective Risk Dilemma game.
    This strategy demonstrates goodwill and encourages reciprocation, retaliating against defection while being forgiving towards initial mistakes or temporary deviations from cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros(game_description.n_rounds))
        self.own_actions = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.history.my_actions[0] = True
            self.own_actions += 1
            return Action.C
        state_round = min(state.round_number, len(self.history.my_payoffs) - 1)
        history_round = min(len(self.history.my_payoffs), history.opponent_actions.shape[0])
        if state.round_number == history_round:
            majority = math.ceil(self.game_description.n_players / 2)
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators > majority:
                return Action.C
            else:
                return Action.D
        self.history.my_payoffs[state_round] = (1 - self.own_actions) * self.game_description.k if sum(self.history.opponent_actions[state_round, :]) >= self.game_description.m else 1 - self.own_actions
        self.history.my_actions[state_round] = self.own_action(history_round)
        self.own_actions += int(self.history.my_actions[-1])
        if state_round == history_round - 1:
            if sum(self.history.opponent_actions[state_round, :]) == self.own_actions:
                return self.history.opponent_actions[state_round, -1]
        majority = int((len(self.history.opponent_actions[state_round, :]) + 1) / 2)
        if self.own_actions < self.game_description.m - 1 or self.own_actions >= self.game_description.n - (self.game_description.m - 1):
            return Action.D
        if sum(self.history.opponent_actions[state_round, :]) == len(self.history.opponent_actions[state_round, :]):
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_70(BaseStrategy):
    """
    Strategy name: Adaptive Tit-for-Tat (ATFT) for Collective Risk Dilemma
    Strategy summary: ATFT cooperates when at least m players cooperated in the previous round and defects otherwise.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_coop_threshold = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        if history.my_actions[-1]:
            cooperators = sum(history.opponent_actions[-1])
            if cooperators >= self.min_coop_threshold:
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_71(BaseStrategy):
    """
    Tit-for-Tat Adaptive (TFT-A) Strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_action_history = np.zeros(self.game_description.n_players, dtype=np.bool_)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        elif state.round_number == 0 and history is not None:
            self.opponent_action_history = history.opponent_actions[0]
            return self.opponent_action_history
        opponent_cooperators = np.sum(history.opponent_actions[-1])
        if opponent_cooperators >= len(self.opponent_action_history) // self.game_description.m:
            self.opponent_action_history = history.opponent_actions[-1]
            return Action.C
        else:
            self.opponent_action_history = np.logical_not(history.opponent_actions[-1])
            return Action.D

class Strategy_COLLECTIVE_72(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation (TFT-AC) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = int(math.ceil(game_description.n_rounds * 0.8))
        self.increment = 0.01
        self.likelihood_of_cooperation = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and len(history.my_actions) == 0):
            return Action.C
        if history is None or state.round_number - self.threshold >= 0:
            cooperators = sum([elem for sublist in history.opponent_actions[:state.round_number, :] for elem in sublist])
            if cooperators >= self.game_description.m and cooperators / self.game_description.n_players >= 0.5:
                return Action.C
            elif cooperators < self.game_description.m and state.round_number - self.threshold >= 0:
                self.likelihood_of_cooperation += self.increment
                return Action(random.choice([Action.C, Action.D]) if random.random() <= self.likelihood_of_cooperation else Action.D)
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_75(BaseStrategy):
    """
    A Tit-for-Tat with Adaptive Cooperation (TFT-AC) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_window = 3
        self.revenge_window = 2
        self.grace_period = 2
        self.current_state = 'cooperate'
        self.current_punishment_counter = 0
        self.current_grace_counter = 0
        self.opponent_history = []

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        action = Action.D
        round_actions = history.opponent_actions[-1] if history is not None else np.zeros(self.game_description.n_players)
        if sum(round_actions) >= self.game_description.m:
            if sum(history.my_actions[:-1]) < self.punishment_window:
                action = Action.C
            elif sum(history.my_actions[-self.grace_period - 1:-1]) == self.grace_period and action != Action.C:
                action = Action.C
        elif sum(history.my_actions[:-1]) >= self.punishment_window:
            action = Action.D
            if action not in self.opponent_history[-self.revenge_window - 1:-1]:
                self.current_state = 'revenge'
        elif sum(history.my_actions[-self.grace_period - 1:-1]) == self.grace_period and action != Action.C:
            action = Action.C
            self.current_state = 'copy'
        self.opponent_history.append(action)
        return action

class Strategy_COLLECTIVE_76(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.act_threshold = game_description.m - 1
        self.last_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if state.round_number == 0 or history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        self.last_cooperators = cooperators
        if cooperators >= self.game_description.m:
            return Action.C
        elif cooperators < self.act_threshold:
            return Action.D
        else:
            self.update_act_threshold(cooperators, self.act_threshold)
            if self.last_cooperators >= self.act_threshold:
                return Action.C
            else:
                return Action.D

    def update_act_threshold(self, current_cooperators, act_threshold):
        if current_cooperators > self.act_threshold + 1:
            for _ in range(min(current_cooperators - self.act_threshold - 1, 5)):
                self.act_threshold += 1
        elif current_cooperators < self.act_threshold - 1:
            for _ in range(min(self.act_threshold - current_cooperators - 1, 5)):
                self.act_threshold -= 1

class Strategy_COLLECTIVE_77(BaseStrategy):
    """
    A strategy that cooperates if the majority of players cooperated in the previous round, and defects otherwise.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.minimum_cooperators = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or state.round_number >= self.game_description.n_rounds - 1:
            return Action.C
        if history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.minimum_cooperators:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_78(BaseStrategy):
    """
    A strategy that implements the Tit-for-Tat Adaptive (TFT-A) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_round_majority = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round_actions = np.array([action for round_, actions in zip(range(state.round_number), history.opponent_actions.T) for action in actions])
        current_majority = sum(current_round_actions >= self.game_description.n_players // 2) >= self.game_description.m
        if not self.last_round_majority or (self.last_round_majority and (not current_majority)):
            return Action.D
        if self.last_round_majority and current_majority:
            self.last_round_majority = True
            return Action.C
        self.last_round_majority = False
        return Action.C if self.last_round_majority else Action.D

class Strategy_COLLECTIVE_79(BaseStrategy):
    """
    Adaptive Tit-for-Tat strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = math.ceil(self.game_description.m - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        last_action = history.my_actions[-1] if history is not None else False
        if cooperators >= self.min_cooperators and last_action or (not last_action and cooperators < self.min_cooperators):
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_80(BaseStrategy):
    """
    The Tit-for-Tat with Adaptive Cooperation Threshold (TTFTC) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.forgiveness_limit = int(self.game_description.n_players * 0.5)
        self.consecutive_defections_counter = {i: 0 for i in range(1, self.game_description.n_players + 1)}

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        action = Action.D
        if state.round_number == 0:
            action = Action.C
        else:
            opponents_cooperated_count = sum(history.opponent_actions[state.round_number - 1])
            if opponents_cooperated_count >= self.forgiveness_limit:
                action = Action.C
            elif opponents_cooperated_count < self.forgiveness_limit:
                action = Action.D
            else:
                opponents_cooperated_indices = [i for i, x in enumerate(history.opponent_actions[state.round_number - 1]) if x == True]
                chosen_player = random.choice(opponents_cooperated_indices)
                if self.consecutive_defections_counter[chosen_player] > self.forgiveness_limit:
                    action = Action.C
        self.consecutive_defections_counter[state.round_number % self.game_description.n_players + 1] += 1
        if state.round_number > self.forgiveness_limit and self.consecutive_defections_counter[state.round_number % self.game_description.n_players + 1] > self.forgiveness_limit:
            action = Action.C
        return action

class Strategy_COLLECTIVE_81(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation (TFTA) strategy for Collective Risk Dilemma games.
    Encourages cooperation and penalizes defection, prioritizing collective interest.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperators_threshold = game_description.m
        self.rounds_cooperated = 0
        self.last_opponent_action = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_actions = history.opponent_actions[-1]
        cooperation_count = sum(opponent_actions)
        if self.last_opponent_action is None or cooperation_count != self.last_opponent_action.sum():
            self.rounds_cooperated = 0
            self.last_opponent_action = np.where(opponent_actions, 1, 0).sum()
        if cooperation_count >= self.cooperators_threshold:
            self.rounds_cooperated += 1
            if state.round_number == self.game_description.n_rounds:
                return Action.C
        else:
            self.rounds_cooperated = 0
        return Action(self.last_opponent_action != 0)

class Strategy_COLLECTIVE_82(BaseStrategy):
    """
    Strategy name: Adaptive Cooperative Tit-for-Tat (ACT) for Collective Risk Dilemma Game

    This strategy cooperates initially and in rounds where more than half of the players cooperated in the previous round.
    In all other cases, it defects. The strategy also offers forgiveness for repeated defection by switching to cooperation after three consecutive defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defection_counter = 0
        self.last_cooperators = 0

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        action = Action.D if cooperators < self.game_description.m // 2 else Action.C
        if self.defection_counter >= 3 and history:
            if np.all(history.my_actions[-3:] == [False, False, False]):
                action = Action.C
        self.defection_counter = 0 if action == Action.C else self.defection_counter + 1
        self.last_cooperators = cooperators
        return action

class Strategy_COLLECTIVE_83(BaseStrategy):
    """
    Tit-for-Tat Strategy for Collective Risk Dilemma Game
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_last_action = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not self.opponent_last_action:
            self.opponent_last_action = history.opponent_actions[state.round_number - 1, 0]
        action = Action.C if self.opponent_last_action else Action.D
        self.opponent_last_action = history.opponent_actions[state.round_number - 1, 0]
        return action

class Strategy_COLLECTIVE_84(BaseStrategy):
    """
    Adaptive Cooperative Tit-for-Tat (ACTFT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_round_cooperators = 0
        self.opponent_defected_count = 0
        self.num_opponents = game_description.n_players - 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :]) if history is not None else 0
        self.last_round_cooperators = cooperators
        if cooperators < self.game_description.m and state.round_number > self.game_description.n_rounds // 2:
            self.opponent_defected_count += 1
        if self.opponent_defected_count > self.num_opponents // 2:
            return Action.D
        elif cooperators < self.game_description.m:
            return Action.D
        return Action.C

class Strategy_COLLECTIVE_85(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation (TFT-AC) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(my_actions=np.zeros(game_description.n_rounds, dtype=bool), my_payoffs=np.zeros(game_description.n_rounds, dtype=float), opponent_actions=np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), opponent_payoffs=np.zeros((game_description.n_rounds, game_description.n_players), dtype=float))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None or state.round_number == 0:
            self.history.my_actions[state.round_number] = True
        else:
            num_cooperators = sum(history.opponent_actions[-1, :])
            cooperators_threshold = self.game_description.n_players * (self.game_description.m / 100)
            cooperate = False if num_cooperators < cooperators_threshold else True
            self.history.my_actions[state.round_number] = cooperate
        return Action(int(self.history.my_actions[-1]))

class Strategy_COLLECTIVE_86(BaseStrategy):
    """
    Tit-for-Tat Adaptive (TFT-A) for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.own_actions = np.zeros(game_description.n_rounds, dtype=bool)
        self.own_payoffs = np.zeros(game_description.n_rounds)
        self.m_1 = math.floor((game_description.m - 1) / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and history.my_actions[-1]:
            cooperators = sum(history.opponent_actions[-1])
            if cooperators >= self.m_1:
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_88(BaseStrategy):
    """
    An implementation of the Adaptive Tit-for-Tat strategy for Collective Risk Dilemma game.
    The strategy aims to foster cooperation and punish defection among players, promoting collective success.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = []

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_action = history.opponent_actions[-1, 0]
        self.opponent_history.append(opponent_action)
        if len(self.opponent_history) == state.round_number:
            self.opponent_history = self.opponent_history[-self.game_description.n_players:]
        cooperators = sum([1 for action in self.opponent_history if action])
        if cooperators >= len(self.opponent_history) // 2 and opponent_action:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_89(BaseStrategy):
    """
    A Tit-for-Tat with Adaptive Cooperative Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m / game_description.n_players
        self.memory = []
        self.t = 10

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if not history:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-self.t:])
        cooperation_rate = cooperators / self.t
        average_cooperation_rate = cooperation_rate if len(self.memory) >= self.t else 0
        if state.round_number == len(history.my_actions):
            average_cooperation_rate = average_cooperation_rate
        else:
            average_cooperation_rate = np.mean([cooperation_rate] + self.memory)
        if average_cooperation_rate >= self.cooperation_threshold and len(self.memory) or (history.my_actions[-1] == Action.C and average_cooperation_rate >= self.cooperation_threshold - (self.game_description.m - 1) / self.game_description.n_players):
            action = Action.C
        else:
            action = Action.D
        self.memory.append(history.my_actions[-1])
        return action

class Strategy_COLLECTIVE_90(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATFT) for Collective Risk Dilemma
    Strategy Description: Follows a consistent cooperative behavior in response to similar behaviors from others. Encourages long-term cooperation and mutual benefit among players, fostering a "collective" approach that aligns with the goal of maximizing overall group success.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_length = int(math.ceil(game_description.n_players / 2)) if game_description.n_players % 2 else int(math.ceil(game_description.n_players / 2) + 1)

    def __call__(self, state: GameState, history: PlayerHistory):
        action = Action.D
        if state.round_number == 0 and history is None:
            action = Action.C
        elif state.round_number > 0 and history is not None:
            last_round = len(history.opponent_actions) - 1
            if last_round >= self.punishment_length:
                if np.count_nonzero(history.opponent_actions[-1]) < self.game_description.n_players // 2:
                    action = Action.C
                else:
                    action = Action.D
            elif history.my_actions[last_round] == Action.C:
                action = Action.C
            else:
                action = Action.D
        return action

class Strategy_COLLECTIVE_92(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATFT) for Collective Risk Dilemma

    An adaptive strategy that promotes cooperation by reciprocating the actions of other players while maintaining the ability to punish defection. It demonstrates adaptability and fairness over time while aligning with the collective mindset of fostering long-term cooperative relationships within the game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.players = [0] * self.game_description.n_players
        self.history = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        self.history = history
        if state.round_number == 0:
            return Action.C
        prev_coop = sum(self.players[-self.game_description.m:])
        last_round = self.history.my_actions[-1]
        if state.round_number == len(self.history.my_payoffs):
            return Action.C
        if last_round == Action.C and prev_coop >= self.game_description.m:
            return Action.C
        if prev_coop < self.game_description.m or last_round == Action.D:
            return Action.D
        if prev_coop > self.game_description.m and last_round == Action.C:
            return 1 - last_round

class Strategy_COLLECTIVE_94(BaseStrategy):
    """
    Strategy Name: Adaptive Cooperative-Defect (ACD) Strategy
    Strategy adjusts its cooperation probability based on observed minimum cooperation levels, total reward gained so far, and the number of remaining rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.total_reward = 0
        self.rounds_played = 0
        self.min_cooperation_level = float('inf')

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.min_cooperation_level = min(history.opponent_actions[0]) if history else 1
            return Action.C if random.random() <= self.min_cooperation_level else Action.D
        self.rounds_played += 1
        total_reward_so_far = self.total_reward + np.sum(history.my_payoffs[-1])
        cooperators = sum(history.opponent_actions[-1])
        min_cooperation_level_observed = min(cooperators, self.min_cooperation_level)
        if state.round_number == self.game_description.n_rounds:
            cooperate_probability = 0.99
        else:
            cooperate_probability = min_cooperation_level_observed + (total_reward_so_far / (self.game_description.n_rounds - self.rounds_played) * self.game_description.k - min_cooperation_level_observed)
        if random.random() <= cooperate_probability:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_96(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation (TFTA)
    Strategy Description: This strategy cooperates initially and mimics the opponent's previous action for subsequent rounds. It temporarily increases cooperation probability if a majority of opponents cooperate, and decreases it if they defect.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_probability = 1.0
        self.last_opponent_action = None
        self.boost_threshold = math.ceil(game_description.n_players * 0.5)

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if not history:
            return Action.C
        self.last_opponent_action = np.mean(history.opponent_actions[-1])
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.boost_threshold:
            self.cooperation_probability += 0.2
            self.cooperation_probability = min(self.cooperation_probability, 1.0)
        elif cooperators < self.boost_threshold and self.last_opponent_action:
            self.cooperation_probability -= 0.2
            self.cooperation_probability = max(self.cooperation_probability, 0.2)
        action = np.random.choice([Action.C, Action.D], p=[self.cooperation_probability, 1 - self.cooperation_probability])
        if state.round_number == self.game_description.n_rounds - 1:
            return action
        return action

class Strategy_COLLECTIVE_97(BaseStrategy):
    """
    Tit-for-Tat Adaptive Cooperation (TFTAC) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.transition_round = min(self.game_description.n_rounds, 3) + 1
        self.threshold = math.ceil((self.game_description.n_players - 1) * 0.5)
        self.last_round = self.game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number < self.transition_round and sum(history.opponent_actions[state.round_number - 1]) > self.threshold:
            return Action.C
        else:
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators >= self.game_description.m and cooperators - len(np.where(history.opponent_actions[-1, :] == 1)[0]) >= self.game_description.m - 1:
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_99(BaseStrategy):
    """
    Adaptive Cooperative Tit-for-Tat (ACTFT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.average_cooperation = np.zeros(self.game_description.n_rounds)

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.average_cooperation[state.round_number] = np.mean(history.my_actions[:state.round_number + 1])
        cooperators_needed = math.ceil(self.game_description.m / self.game_description.n_players * (state.round_number + 1))
        if self.average_cooperation[-1] >= cooperators_needed:
            return Action.C
        elif self.average_cooperation[-1] < (cooperators_needed - 1) / (self.game_description.n_players - 1):
            return Action.D
        else:
            return random.choice([Action.C, Action.D])

    def last_round(self) -> bool:
        """Checks if the current state is in the last round"""
        return self.game_description.n_rounds - 1 == self.average_cooperation.shape[0] - 1

    def total_payoff(self, payoffs: NDArray[np.float64]) -> float:
        """Calculates the total payoff for this strategy"""
        return np.sum(payoffs)

class Strategy_COLLECTIVE_100(BaseStrategy):
    """
    A strategy inspired by the Tit-for-Tat game theory strategy, with adaptive learning and forgiveness mechanisms.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.long_term_avg_cooperate_payoff = np.zeros(self.game_description.n_rounds)
        self.long_term_avg_defect_payoff = np.zeros(self.game_description.n_rounds)
        self.forgiveness_threshold = self.game_description.n_players // 2

    def __call__(self, state: GameState, history: PlayerHistory):
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators < self.game_description.m:
            payoff_cooperate = np.mean([history.my_payoffs[round] for round in range(state.round_number)])
            payoff_defect = np.mean([history.my_payoffs[round] for round in range(state.round_number) if history.my_actions[round] == Action.D])
            if payoff_cooperate > payoff_defect:
                self.long_term_avg_cooperate_payoff = np.roll(self.long_term_avg_cooperate_payoff, -1)
                self.long_term_avg_cooperate_payoff[0] = payoff_cooperate
                self.long_term_avg_defect_payoff = np.roll(self.long_term_avg_defect_payoff, -1)
                self.long_term_avg_defect_payoff[0] = payoff_defect
                return Action.C
            else:
                self.long_term_avg_cooperate_payoff = np.roll(self.long_term_avg_cooperate_payoff, -1)
                self.long_term_avg_cooperate_payoff[0] = payoff_cooperate
                self.long_term_avg_defect_payoff = np.roll(self.long_term_avg_defect_payoff, -1)
                self.long_term_avg_defect_payoff[0] = payoff_defect
                return Action.D
        elif cooperators >= self.game_description.n_players - self.forgiveness_threshold:
            return Action.C
        elif sum(history.opponent_actions[-2:, :][0]) == self.game_description.n_players - 1 and history.opponent_actions[-1] != history.opponent_actions[-2]:
            return Action.C
        elif history.my_actions[-2] == Action.C and history.opponent_actions[-1] == Action.D:
            return Action.D
        else:
            return history.my_actions[-1]

class Strategy_COLLECTIVE_101(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperative Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.past_avg_coop = np.zeros(game_description.n_rounds)
        self.m = game_description.m
        self.t = math.ceil(game_description.n_players * 0.6)
        self.b = math.floor(game_description.n_players * 0.4)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and len(history.my_actions) > 0:
            cooperators = sum(history.opponent_actions[-1, :])
            self.past_avg_coop[-1] = (cooperators + self.past_avg_coop[-2]) / 2 if len(self.past_avg_coop) > 1 else cooperators
            if cooperators >= self.m:
                action = Action.C
                if np.mean(history.my_actions[-self.game_description.n_rounds // 3:]) > self.t:
                    self.m += 1
                elif np.mean(history.my_actions[-self.game_description.n_rounds // 3:]) < self.b:
                    self.m -= 1
            else:
                action = Action.D
        else:
            action = Action.C
        return action

class Strategy_COLLECTIVE_102(BaseStrategy):
    """
    An adaptive Tit-for-Tat strategy for the Collective Risk Dilemma game.
    It starts by cooperating in the first round and then responds to other players' cooperation levels in subsequent rounds.
    If more than half of the players cooperated in the previous round, it continues cooperating. Otherwise, it defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.round = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None or state.round_number == 0:
            self.round += 1
            return Action.C
        cooperation_level = sum(history.opponent_actions[-1])
        cooperators = min(cooperation_level, self.game_description.n_players // 2)
        if cooperators >= self.game_description.m:
            return Action.C
        elif cooperation_level < self.game_description.n_players:
            self.round += 1
        else:
            self.round = state.round_number + 1
        return Action.D

class Strategy_COLLECTIVE_103(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Risk Aversion (TFT-ARA) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.reward = game_description.k
        self.decay_rate = 0.9
        self.total_cooperators = 0
        self.threshold = int(self.game_description.m * self.game_description.n_players // 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        action = Action.D
        if history is not None and len(history.opponent_actions) > 0:
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators >= self.game_description.m:
                self.reward *= self.decay_rate
                action = Action.C
            if state.round_number == self.game_description.n_rounds and cooperators > self.threshold:
                action = Action.C
        return action

class Strategy_COLLECTIVE_104(BaseStrategy):
    """
    A strategy that encourages cooperation within the group by reciprocating good actions and punishing defection to maintain trust among players over time.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.previous_player_cooperation = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        if self.previous_player_cooperation is None:
            self.previous_player_cooperation = np.zeros(self.game_description.n_players, dtype=bool)
        self.previous_player_cooperation[:] = history.my_actions[-1] if history is not None else [False] * self.game_description.n_players
        cooperation_threshold = math.ceil(self.game_description.n_players * (self.m / 100))
        player_cooperated = np.sum(history.my_actions[-1]) >= cooperation_threshold
        if player_cooperated:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_105(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Cooperative Threshold (ATTC) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = math.ceil(game_description.n_players * game_description.m / 100)
        self.state = Action.C

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or not history:
            return self.state
        n_cooperators = sum(history.opponent_actions[-1, :])
        if n_cooperators < self.threshold and state.round_number != self.game_description.n_rounds:
            self.state = Action.D
        elif n_cooperators >= self.threshold or state.round_number == self.game_description.n_rounds:
            self.state = Action.C
        return self.state

class Strategy_COLLECTIVE_106(BaseStrategy):
    """
    Strategy name: Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)

    This strategy cooperates in the first round to foster a cooperative environment.
    For subsequent rounds, it maintains past cooperation if all previous opponents also cooperated (Tit-for-Tat).
    However, it adapts its cooperation by comparing the ratio of cooperators vs defectors in the recent past (n_recent) to the minimum required for success (m).
    If more than m players have cooperated recently, TFT-ACT continues to cooperate. Otherwise, it defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_recent = 5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = np.sum(history.opponent_actions[:self.n_recent, :]) >= self.game_description.m
        return Action.C if cooperators or state.round_number == self.game_description.n_rounds - 1 else Action.D

class Strategy_COLLECTIVE_107(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)
    Strategy Description: Adapts behavior based on the number of cooperators in the previous round, lowering the cooperation threshold if fewer than m players cooperate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.n_players // 2
        self.adaptation_factor = 0.9

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.game_description.m:
            self.cooperation_threshold = min(self.game_description.n_players, max(self.cooperation_threshold, self.cooperation_threshold * self.adaptation_factor))
        return Action(int(self.cooperation_threshold >= cooperators))

class Strategy_COLLECTIVE_108(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.alpha = game_description.m + (game_description.m - 1) * (game_description.n_rounds - 1) / game_description.n_rounds
        self.beta = 0.01

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :]) if history is not None else 0
        new_alpha = self.alpha * (1 - self.beta) if state.round_number < self.game_description.n_rounds else self.alpha
        return Action.C if cooperators >= max(new_alpha, self.game_description.m) else Action.D

class Strategy_COLLECTIVE_109(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation (TFT-AC)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperativity_threshold = 0
        self.num_defections = 0
        self.current_round = 0

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            self.cooperativity_threshold = 1
            self.num_defections = 0
            return Action.C
        self.current_round = state.round_number
        opponent_history = history.opponent_actions[self.current_round - 1, :]
        num_cooperators = sum(opponent_history)
        cooperativity_level = (self.current_round - self.num_defections) / self.game_description.n_rounds
        if cooperativity_level > self.cooperativity_threshold * random.random():
            return Action.C
        else:
            self.num_defections += 1
            return Action.D
        if self.current_round == self.game_description.n_rounds and num_cooperators < self.game_description.m:
            return Action.D

class Strategy_COLLECTIVE_110(BaseStrategy):
    """
    An implementation of the Adaptive Tit-for-Tat strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.minority_threshold = int(game_description.n_players * 0.5)
        self.cooperated_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_cooperators = sum(history.opponent_actions[-1]) if history else self.minority_threshold
        self.cooperated_rounds += 1 if opponent_cooperators >= self.game_description.m else 0
        return Action.C if self.cooperated_rounds >= self.game_description.n_players // 2 else Action.D

class Strategy_COLLECTIVE_111(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation (TFT-AC)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros(game_description.n_rounds))

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[state.round_number - 1, :])
        forgiveness_threshold = math.ceil(self.game_description.n_players / 2) - self.game_description.m + 1
        if cooperators >= self.game_description.m or (history and len(history.opponent_actions) > 1 and (cooperators == forgiveness_threshold)):
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_112(BaseStrategy):
    """
    The Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.t = int(math.ceil(game_description.n_players / 2))
        self.m = game_description.m
        self.n = game_description.n_players
        self.p = int(math.ceil(self.t / 2))
        self.ct = self.m
        self.cooperation_rate = np.zeros(self.t + 1)

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if len(history.my_actions) > self.t + 1:
            self.cooperation_rate = np.mean(history.my_actions[-self.t:])
            self.ct = self.m + (self.n - self.m) * self.cooperation_rate
        cooperators = sum(history.opponent_actions[state.round_number - 1, :])
        if state.round_number < self.game_description.n_rounds:
            if cooperators >= self.ct:
                return Action.C
            else:
                return Action.D
        elif cooperators >= self.m:
            return Action.C
        else:
            if cooperators > 0 and state.round_number - self.p < 1:
                return Action.D
            self.ct = max(self.m, self.ct - (self.ct - self.m) * (self.cooperation_rate < 1))
            return Action.C

class Strategy_COLLECTIVE_113(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation (TFT-AC) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-1])
        if cooperators >= self.m and state.round_number < self.game_description.n_rounds:
            return Action.C
        elif state.round_number == self.game_description.n_rounds:
            total_cooperation = np.sum(history.my_actions) + np.sum(np.where(history.opponent_payoffs > 1, history.opponent_actions, 0))
            if total_cooperation >= self.m * self.game_description.n_rounds:
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_114(BaseStrategy):
    """
    Tit-for-Tat Adaptive with Foresight (TA-TFT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = self.game_description.n_players
        self.m = self.game_description.m
        self.last_round_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and state.round_number > 1:
            cooperators = sum(history.opponent_actions[state.round_number - 1, :])
            if cooperators >= self.n_players // 2:
                return Action.C
            if self.last_round_cooperators > self.n_players - self.m:
                self.last_round_cooperators = cooperators
                return Action.C
            if cooperators < self.n_players - self.m and self.last_round_cooperators >= self.m:
                self.last_round_cooperators = cooperators
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_115(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATFT) for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.history = PlayerHistory(my_actions=np.zeros(game_description.n_players * game_description.n_rounds, dtype=bool), my_payoffs=np.zeros(game_description.n_rounds), opponent_actions=np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), opponent_payoffs=np.zeros((game_description.n_rounds, game_description.n_players)))

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if state.round_number == 0:
            return Action.C
        if history is None:
            history = self.history
        current_round = state.round_number - 1
        cooperators = sum(history.opponent_actions[current_round, :])
        if cooperators >= self.m and history.my_actions[-1]:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_117(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation (TFT-AC)
    A cooperative strategy that adapts to the number of co-operators in previous rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.historic_cooperation_counts = np.zeros(game_description.n_rounds)
        self.ever_cooperated = False

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 and (not history):
            return Action.C
        action = Action.D
        self.historic_cooperation_counts[state.round_number] = sum(history.opponent_actions[-1, :])
        if self.historic_cooperation_counts[-1] > 0:
            self.ever_cooperated = True
        cooperation_count = self.historic_cooperation_counts[state.round_number]
        if cooperation_count >= self.game_description.m:
            action = Action.C
        elif cooperation_count > 0 and cooperation_count < self.game_description.m and self.ever_cooperated:
            action = Action.D
        elif not self.ever_cooperated or (state.round_number != self.game_description.n_rounds and self.historic_cooperation_counts[-2] >= self.game_description.m):
            action = Action.C
        return action

class Strategy_COLLECTIVE_119(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) Strategy
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.average_cooperators = np.zeros(game_description.n_rounds + 1)
        self.current_cooperators = 0
        self.self_defected = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is None:
            self.current_cooperators = 1
            self.self_defected = False
        else:
            self.average_cooperators[state.round_number] = self.average_cooperators[state.round_number - 1] + (history.my_actions[-1] - self.current_cooperators) / state.round_number
            self.current_cooperators = np.sum(history.my_actions)
            if self.current_cooperators < self.game_description.m and (not self.self_defected):
                return Action.C
            elif self.current_cooperators >= self.game_description.m or (self.current_cooperators < self.game_description.m and self.self_defected):
                self.self_defected = False
                return Action.C
            else:
                self.self_defected = True
                return Action.D

class Strategy_COLLECTIVE_121(BaseStrategy):
    """Tit-for-Tat with Adaptive Threshold (TFT-AT) strategy for Collective Risk Dilemma"""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.m
        self.remaining_rounds = game_description.n_rounds
        self.recent_cooperation = np.zeros(3)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        action = Action.D
        if state.round_number == 0:
            action = Action.C
        elif self.remaining_rounds <= self.game_description.n_rounds // 3:
            self.threshold = self.game_description.m
        if history is not None:
            cooperation = history.opponent_actions[-1, :].sum()
            if cooperation >= self.threshold:
                action = Action.C
                self.recent_cooperation[0] = cooperation
            else:
                self.recent_cooperation[0] = cooperation
                self.recent_cooperation[1] = self.recent_cooperation[0]
            if self.recent_cooperation[2] == 0:
                self.threshold += 1
            elif self.recent_cooperation[:2].sum() >= self.game_description.n_players * self.game_description.m // 3:
                self.threshold += 1
        return action

class Strategy_COLLECTIVE_122(BaseStrategy):
    """
    Tit-for-Tat Adaptive (TFT-A) strategy in the Collective Risk Dilemma game.
    Cooperation when others are also cooperating and defensive stance when they are not.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m
        self.n = self.game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        elif len(history.opponent_actions) > state.round_number - 1 and np.sum(history.opponent_actions[-state.round_number + 1]) < self.m:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_124(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperative Threshold (TFT-ACT)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.current_threshold = math.ceil(game_description.n_players * 0.5)
        self.min_cooperators = game_description.m
        self.max_players = game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1] if history else [0])
        if cooperators >= self.min_cooperators and state.round_number < self.game_description.n_rounds:
            if cooperators < self.current_threshold:
                self.current_threshold = min(self.max_players, self.current_threshold + 1)
            elif cooperators >= self.current_threshold:
                self.current_threshold = max(self.min_cooperators, self.current_threshold - 1)
        return Action.C if cooperators >= self.current_threshold else Action.D

class Strategy_COLLECTIVE_125(BaseStrategy):
    """
    A strategy that implements the Tit-for-Tat with Threshold (TFT-Threshold) strategy in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = self.game_description.m
        self.punishment_steps = math.ceil((self.game_description.n_players - self.threshold) / 2)
        self.history = PlayerHistory(my_actions=np.zeros(self.game_description.n_rounds, dtype=bool), my_payoffs=np.zeros(self.game_description.n_rounds, dtype=float), opponent_actions=np.zeros((self.game_description.n_rounds, self.game_description.n_players), dtype=bool), opponent_payoffs=np.zeros((self.game_description.n_rounds, self.game_description.n_players), dtype=float))

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if state.round_number == 0:
            self.history.my_actions[0] = True
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            cooperators = np.sum(self.history.opponent_actions[-1, :])
            if cooperators >= self.threshold:
                self.history.my_actions[-1] = True
                return Action.C
        cooperators = np.sum(self.history.opponent_actions[-1, :])
        self.history.my_actions[state.round_number - 1] = cooperators >= self.threshold
        if not self.history.my_actions[state.round_number - 1] and state.round_number > self.punishment_steps:
            self.history.my_actions[state.round_number - 1] = True
        return Action(self.history.my_actions[state.round_number - 1])

class Strategy_COLLECTIVE_126(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATfT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.minimum_cooperators = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-1])
        if cooperators < self.minimum_cooperators:
            return Action.D
        return Action.C

class Strategy_COLLECTIVE_127(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT)
    Strategy Description: This strategy cooperates in the first round and subsequently adapts its cooperation based on the proportion of cooperators in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m / game_description.n_players
        self.history = PlayerHistory(my_actions=np.zeros(game_description.n_rounds, dtype=bool), my_payoffs=np.zeros(game_description.n_rounds), opponent_actions=np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), opponent_payoffs=np.zeros((game_description.n_rounds, game_description.n_players)))

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            self.history.my_actions[0] = True
        else:
            opponents_cooperated = np.sum(history.opponent_actions[-1, :])
            cooperation_probability = opponents_cooperated / self.game_description.n_players
            if cooperation_probability >= self.cooperation_threshold and history.my_actions[-1] != True:
                self.cooperation_threshold += (self.game_description.n_rounds - state.round_number) * 0.01
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_128(BaseStrategy):
    """
    A collective risk dilemma strategy that cooperates when a sufficient number of players have cooperated in the past rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history_length = game_description.n_rounds
        self.min_cooperators_threshold = int(math.ceil(game_description.m * (game_description.n_players - 1) / game_description.n_rounds))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and len(history.my_actions) < self.history_length):
            return Action.D
        cooperators = np.sum(history.my_actions[-self.history_length:])
        if cooperators >= self.min_cooperators_threshold:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_129(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation (TFT-AC) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_period = game_description.n_players // 2
        self.average_cooperation_rate = np.zeros(self.punishment_period)
        self.current_round = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            history = PlayerHistory(np.zeros(1), np.zeros(1), np.zeros((self.game_description.n_players, 1)), np.zeros(1))
        self.current_round += 1
        opponent_cooperated = sum(history.opponent_actions[self.current_round - 1]) > 0
        if self.current_round >= self.punishment_period:
            average_cooperation_rate = np.mean(self.average_cooperation_rate)
            self.average_cooperation_rate[:] = 0
            self.average_cooperation_rate[-1] = average_cooperation_rate
            if self.current_round == self.punishment_period and (not opponent_cooperated):
                return Action.C
        return Action(int(opponent_cooperated))

class Strategy_COLLECTIVE_130(BaseStrategy):
    """
    Adaptive Tit-for-Tat Strategy for Collective Risk Dilemma.
    Implements the ATFT strategy as described in the given problem statement.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.n_players // game_description.m
        self.forgiveness_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.cooperation_threshold:
            return Action.C
        else:
            self.forgiveness_counter = max(self.forgiveness_counter - 1, 0)
            if self.forgiveness_counter == 0 and history is not None:
                forgiven = False
                for i in range(len(history.opponent_actions) - 1, -1, -1):
                    if sum(history.opponent_actions[i, :]) >= self.cooperation_threshold:
                        forgiven = True
                        break
                self.forgiveness_counter = forgiven and len(history.opponent_actions) - i
            return Action.D

class Strategy_COLLECTIVE_133(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.d = 0.1
        self.i = 0.1
        self.max_p = 1.0
        self.min_p = 0.2
        self.history = []
        self.cooperation_probability = 1.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if not history:
            return Action.C
        round_history = history.opponent_actions[-1]
        coop_count = sum(round_history)
        if state.round_number == 0 or coop_count >= self.m:
            self.cooperation_probability = min(self.cooperation_probability + self.i, self.max_p)
        else:
            self.cooperation_probability = max(self.cooperation_probability - self.d, self.min_p)
        if state.round_number < self.r - 1:
            action = Action.C if coop_count >= self.m else Action.D
        elif coop_count >= self.history[-1] + (self.m - self.history[-1]) * 2:
            action = Action.C
        else:
            action = Action.D
        self.history.append(coop_count)
        return action

class Strategy_COLLECTIVE_134(BaseStrategy):
    """
    A Tit-for-Tat Cooperation (TFTC) strategy for Collective Risk Dilemma games.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not self.opponent_history:
            self.opponent_history.append(bool(history and history.opponent_actions[-1].sum()))
        current_opponent_action = bool(self.opponent_history[-1])
        self.opponent_history.append(current_opponent_action)
        return Action(int(current_opponent_action) ^ int(state.round_number > 0))

class Strategy_COLLECTIVE_135(BaseStrategy):
    """
    Adaptive Tit-for-Tat Strategy for the Collective Risk Dilemma Game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif len(self.cooperation_history) < state.round_number:
            return Action.D
        else:
            num_cooperators = sum(self.cooperation_history[-self.game_description.n_players:])
            if num_cooperators >= self.m:
                cooperation_action = Action.C
            else:
                cooperation_action = Action.D
            self.cooperation_history.append(cooperation_action == Action.C)
            return cooperation_action

class Strategy_COLLECTIVE_136(BaseStrategy):
    """
    Tit-for-Tat Adaptive (TFT-A) Strategy for Collective Risk Dilemma
    This strategy emulates a cooperative environment by adapting to other players' actions.
    It encourages reciprocity and fosters long-term cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(game_description.n_rounds), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players)), np.zeros((game_description.n_rounds, game_description.n_players)))
        self.num_cooperators_last = 0
        self.num_cooperators_prev = 0
        self.min_threshold_met = False
        self.last_round = False
        self.odd_number = game_description.n_players % 2 != 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        self.history = history
        self.last_round = state.round_number == self.history.my_actions.shape[0] - 1
        cooperators = sum(self.history.opponent_actions[-1, :])
        if self.last_round:
            if cooperators >= self.game_description.m and (not self.min_threshold_met) or (not self.min_threshold_met and cooperators > 0):
                return Action.C
            elif self.min_threshold_met and cooperators == 0:
                return Action.D
        elif cooperators >= (self.odd_number and self.game_description.n_players + 1) // 2 or (not self.odd_number and cooperators >= (self.game_description.n_players - 1) // 2):
            self.num_cooperators_prev = cooperators
            return Action.C
        elif cooperators == self.num_cooperators_last:
            if cooperators < self.game_description.m:
                self.min_threshold_met = False
                return Action.D
            else:
                self.min_threshold_met = True
        else:
            self.num_cooperators_last = cooperators
            if cooperators >= self.game_description.m:
                self.min_threshold_met = True
            else:
                self.min_threshold_met = False
        return Action.D

class Strategy_COLLECTIVE_137(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.n_players // 3
        self.delta = 0.1
        self.past_outcomes = []

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1] if history else [0])
        ratio_cooperators = cooperators / self.game_description.m if cooperators >= self.game_description.m else 0
        payoff = np.mean(history.my_payoffs if history else [0]) if history else 0
        if ratio_cooperators < self.cooperation_threshold:
            self.cooperation_threshold += self.delta * (1 - payoff)
            return Action.D
        self.cooperation_threshold = max(self.cooperation_threshold - self.delta, 0)
        self.past_outcomes.append(payoff)
        if len(self.past_outcomes) > self.game_description.n_rounds // 10:
            self.past_outcomes.pop(0)
        return Action.C

class Strategy_COLLECTIVE_139(BaseStrategy):
    """
    The Adaptive Tit-for-Tat (ATFT) Strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.r = self.game_description.n_rounds
        self.m = self.game_description.m
        self.k = self.game_description.k
        self.forgiveness_phase_threshold = math.floor(self.r / 3)
        self.cumulative_cooperation_threshold = math.floor(2 * self.forgiveness_phase_threshold / self.r)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        elif state.round_number == self.r and history is not None:
            return Action.C
        else:
            opponent_cooperators = sum(history.opponent_actions[state.round_number - 1, :])
            my_cumulative_cooperation = np.sum(history.my_actions[:state.round_number])
            if state.round_number > self.forgiveness_phase_threshold and my_cumulative_cooperation < self.cumulative_cooperation_threshold:
                return Action.C
            elif opponent_cooperators >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_140(BaseStrategy):
    """
    A strategy that mimics the Tit-for-Tat Adaptive behavior in Collective Risk Dilemma games.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m
        self.threshold_met = np.zeros(game_description.n_rounds)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        self.threshold_met[-1] = cooperators >= self.min_cooperators
        if state.round_number < self.game_description.n_rounds - 1:
            return Action(self.threshold_met[-1]) if self.threshold_met[-1] else Action.D
        last_round = history.opponent_actions[-2, :].sum() >= self.min_cooperators
        return Action(last_round) if last_round else Action.D

class Strategy_COLLECTIVE_141(BaseStrategy):
    """
    The Tit-for-Tat Adaptive Cooperation (TTAC) strategy.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m
        self.forgiveness_factor = 0.5
        self.cooperators_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or state.round_number == self.game_description.n_rounds:
            return Action.C
        if history is None:
            self.cooperators_count = 0
            return Action.C
        if state.round_number < self.m or self.cooperators_count < self.m:
            return Action.D
        self.cooperators_count = sum(history.opponent_actions[-1, :])
        if self.cooperators_count >= self.m and history.my_actions[-1] == Action.D:
            forgiveness = min(self.forgiveness_factor, self.cooperators_count / (state.round_number - 1))
            forgiveness *= self.forgiveness_factor
            if forgiveness > 0:
                return Action.C
            else:
                return Action.D
        return Action.C

# class Strategy_COLLECTIVE_142(BaseStrategy):
#     """
#     Tit-for-Tat Adaptive Strategy for the Collective Risk Dilemma game.
#     This strategy fosters cooperation when others do so, but also punishes defection to ensure fairness.
#     It adapts to opponent behavior by switching to a punishing strategy if necessary.
#     """

#     def __init__(self, game_description: CollectiveRiskDescription):
#         self.game_description = game_description
#         self.n_consecutive_defects = self.game_description.n_players // 2
#         self.punishing_duration = self.game_description.n_players // 4
#         self.current_state = Action.C
#         self.punishing_mode = False

#     def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
#         if state.round_number == 0 and history is None:
#             return self.current_state
#         cooperators = sum(history.opponent_actions[-1, :])
#         if cooperators >= self.game_description.m:
#             self.current_state = Action.C
#         else:
#             self.current_state = Action.D
#         if not self.punishing_mode and cooperators < self.game_description.m - self.n_consecutive_defects:
#             self.punishing_mode = True
#         elif self.punishing_mode and history.my_actions[-self.punishing_duration - 1, :].sum() >= self.n_consecutive_defects:
#             self.punishing_mode = False
#         return self.current_state

class Strategy_COLLECTIVE_143(BaseStrategy):
    """
    Tit-for-Tat Cooperation (TFTC) strategy for Collective Risk Dilemma.
    This strategy initiates cooperation in the first round and responds to opponents' actions from the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or not history:
            return Action.C
        opponent_actions = history.opponent_actions if history else np.zeros((state.round_number, self.game_description.n_players), dtype=bool)
        self.opponent_history.append(opponent_actions[-1])
        action = self.opponent_history[-1][-1] if self.opponent_history else Action.D
        cooperators = sum(history.opponent_actions[-1, :]) if history else np.sum(self.opponent_history[-1])
        reward = 1 if cooperators < self.game_description.m else 1 + self.game_description.k
        return action if action == Action.C and cooperators >= self.game_description.m or action == Action.D else Action.D

class Strategy_COLLECTIVE_144(BaseStrategy):
    """
    A Tit-for-Tat with Threshold Adaptation (TFTA) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.m
        self.n_players = game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[state.round_number - 1, :])
        my_action = Action.C if cooperators >= self.threshold else Action.D
        if history is not None and state.round_number > 0:
            last_my_action = history.my_actions[state.round_number - 1]
            if last_my_action == my_action:
                return my_action
            if cooperators >= self.n_players // 2:
                return Action.C
        return my_action

class Strategy_COLLECTIVE_145(BaseStrategy):
    """
    The Adaptive Tit-for-Tat (ATFT) Strategy for the Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.minimum_cooperators = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if not history:
            return Action.C if random.random() < 0.5 else Action.D
        if state.round_number == 1:
            num_cooperators = np.sum(history.opponent_actions[0])
            if num_cooperators >= self.minimum_cooperators:
                return Action.C
            return Action.D
        num_cooperators = np.sum(history.opponent_actions[-1])
        if num_cooperators >= self.minimum_cooperators:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_146(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATfT) strategy for the Collective Risk Dilemma.
    Encourages reciprocity and forgiveness among players to promote cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.player_index = 0
        self.history = PlayerHistory(my_actions=np.empty((1,), dtype=bool), my_payoffs=np.empty((1,), dtype=float), opponent_actions=np.empty((1, game_description.n_players), dtype=bool), opponent_payoffs=np.empty((1, game_description.n_players), dtype=float))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is not None and state.round_number > 0:
            self.history = history
        if state.round_number == 0:
            return Action.C
        else:
            cooperators = sum(self.history.opponent_actions[state.round_number - 2, :])
            if cooperators >= self.game_description.n_players // self.game_description.m:
                return Action.C
            return Action.D

class Strategy_COLLECTIVE_147(BaseStrategy):
    """
    A strategy inspired by the classic Tit-for-Tat strategy, with an adaptive cooperation element to adjust to the game progress.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.t_cooldown = game_description.n_players // 2
        self.last_action = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        prev_round_cooperation = np.all(history.opponent_actions[-1])
        last_defection = self.last_action != Action.C if self.last_action is not None else False
        action = Action.D if last_defection and (not prev_round_cooperation) else Action.C
        self.last_action = action
        remaining_rounds = state.round_number + 1 - self.game_description.n_rounds
        if remaining_rounds <= 3:
            self.t_cooldown *= 0.85
        return action

class Strategy_COLLECTIVE_148(BaseStrategy):
    """
    Tit-for-Tat Cooperation (T4TC) strategy in Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or len(self.opponent_history) == 0:
            return Action.C
        opponent_action = self.opponent_history[-1]
        if opponent_action == Action.C:
            return Action.C
        else:
            self.opponent_history.append(opponent_action)
            return Action.D

    def update_with_opponent_action(self, action: Action):
        """
        Update opponent's action history in the T4TC strategy class.
        """
        self.opponent_history.append(action)

class Strategy_COLLECTIVE_149(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Threshold (TFT-AT) Strategy for Collective Risk Dilemma Game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.m
        self.last_round = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == len(history.opponent_actions):
            return self.play_round((history.my_actions[-1] if history else np.zeros(1, dtype=bool)).sum(), self.threshold, self.game_description.k)
        else:
            return self.play_round((history.opponent_actions[-2].sum() if history else np.zeros((state.round_number - 1, 1), dtype=bool)).sum(), self.threshold, self.game_description.k)

    def play_round(self, cooperators: int, threshold: int, k: float) -> Action:
        return Action.C if cooperators >= threshold else Action.D

class Strategy_COLLECTIVE_150(BaseStrategy):
    """
    A Tit-For-Tat Adaptive Cooperation (TTAC) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.initial_rounds = 5
        self.cooperation_rate = np.zeros(self.initial_rounds)
        self.history_len = self.initial_rounds + 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history and len(history.my_actions) >= self.history_len:
            self.cooperation_rate = np.roll(self.cooperation_rate, -1)
            self.cooperation_rate[-1] = sum(history.my_actions[-self.initial_rounds:]) / self.initial_rounds
        cooperators = sum(history.opponent_actions[-1, :]) if history else 0
        cooperation_rate = cooperators / (self.game_description.n_players - (self.game_description.m - 1))
        if state.round_number == self.game_description.n_rounds or cooperation_rate < 1 / (self.game_description.n_players - self.game_description.m + 1):
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_151(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) Strategy for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = self.game_description.m / self.game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            cooperators = 0
        else:
            cooperators = sum(history.opponent_actions[-1]) / self.game_description.n_players
        if state.round_number != self.game_description.n_rounds - 1 and cooperators < self.cooperation_threshold:
            return Action.D
        return Action.C

class Strategy_COLLECTIVE_152(BaseStrategy):
    """
    The Adaptive Tit-for-Tat (ATfT) strategy for Collective Risk Dilemma game.
    This strategy cooperates when the number of cooperators in the previous round is greater than or equal to m, otherwise it defects.
    In the first round, it cooperates since there's no history to reference.
    In the final round, it adopts a forgiving approach by cooperating regardless of previous actions taken by opponents.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.n_players // game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or not history:
            return Action.C
        cooperators = sum(history.opponent_actions[-1])
        if state.round_number == self.game_description.n_rounds - 1 or cooperators >= self.threshold:
            return Action.C
        return Action.D if cooperators < self.threshold else Action.C

class Strategy_COLLECTIVE_153(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)
    Strategy Description: Initiates cooperation in the first round, and adaptively chooses between cooperation and defection based on the percentage of cooperators in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m_threshold = game_description.m / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        cooperators = np.sum(history.opponent_actions[state.round_number - 1, :])
        percentage_cooperators = cooperators / self.game_description.n_players if cooperators > 0 else 0
        return Action.C if percentage_cooperators >= self.m_threshold else Action.D

class Strategy_COLLECTIVE_154(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATFT) for Collective Risk Dilemma
    Strategy Description: Follows tit-for-tat behavior, encouraging reciprocation and building long-term relationships.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.first_round = True
        self.history = PlayerHistory(my_actions=np.array([], dtype=bool), my_payoffs=np.array([]), opponent_actions=np.zeros((1, game_description.n_players), dtype=bool), opponent_payoffs=np.zeros(1))

    def __call__(self, state: GameState, history: PlayerHistory):
        if self.first_round and history is None:
            self.history = PlayerHistory(my_actions=np.array([True], dtype=bool), my_payoffs=np.array([0]), opponent_actions=np.zeros((1, self.game_description.n_players), dtype=bool), opponent_payoffs=np.zeros(1))
            self.first_round = False
        elif state.round_number == 0:
            self.history = history
            return Action.C
        last_round = self.history.opponent_actions[-1]
        my_action = np.mean(last_round) >= self.game_description.n_players / 2
        self.history = PlayerHistory(my_actions=np.append(self.history.my_actions, [my_action]), my_payoffs=np.append(self.history.my_payoffs, np.nan), opponent_actions=np.vstack([self.history.opponent_actions, last_round]), opponent_payoffs=np.append(self.history.opponent_payoffs, np.nan))
        if my_action:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_155(BaseStrategy):
    """
    A Tit-for-Tat with Adaptation strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_defections = 0
        self.cooperative_threshold = int(math.ceil(game_description.n_players / 2))
        self.punishment_threshold = 3
        self.forgiveness_threshold = 2
        self.current_state = Action.C

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif not history:
            return Action.C
        else:
            opponent_last_action = history.opponent_actions[-1, 0]
            if opponent_last_action != self.current_state:
                if opponent_last_action == Action.D:
                    self.opponent_defections += 1
                    if self.opponent_defections >= self.punishment_threshold:
                        self.current_state = Action.D
                    elif self.opponent_defections > 0:
                        self.cooperative_threshold = min(self.game_description.n_players, self.cooperative_threshold + 1)
                else:
                    self.opponent_defections = 0
                    if self.opponent_defections <= 0 and len(history.my_actions) >= self.forgiveness_threshold:
                        self.current_state = Action.C
                        self.cooperative_threshold = max(1, self.cooperative_threshold - 1)
            return self.current_state

class Strategy_COLLECTIVE_156(BaseStrategy):
    """
    A strategy that adopts an adaptive Tit-for-Tat behavior in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is None or len(history.opponent_actions) < state.round_number + 1:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            majority = self._count_majority(history.opponent_actions[state.round_number - 1])
            if self._has_switched(history, state.round_number - 2):
                return Action.C
            return self._opposite(majority)
        cooperators = self._count_cooperators(history.opponent_actions[state.round_number - 1])
        if cooperators >= (self.n + 1) // 2:
            return Action.C
        return self._opposite(majority)

    def _count_cooperators(self, actions: NDArray[np.bool_]) -> int:
        return sum(actions)

    def _count_majority(self, actions: NDArray[np.bool_]) -> int:
        cooperators = self._count_cooperators(actions)
        return min(self.n - cooperators, cooperators)

    def _has_switched(self, history: PlayerHistory, round_number: int) -> bool:
        if round_number == 0:
            return False
        previous_majority = self._count_majority(history.opponent_actions[round_number - 1])
        previous_but_one_majority = self._count_majority(history.opponent_actions[round_number - 2])
        return previous_majority != previous_but_one_majority

    def _opposite(self, majority: int) -> Action:
        if majority >= self.m:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_157(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Risk Aversion (TfTARA)
    Strategy Summary: Cooperates initially, then adapts to opponents' behavior and adjusts the k factor based on average number of cooperators.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.k = game_description.k
        self.avg_coopers = 0.0
        self.rounds_played = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        action = Action.C
        if state.round_number == 0:
            return Action.C
        self.rounds_played += 1
        if history is not None:
            cooperators = sum(history.opponent_actions[-1, :])
            self.avg_coopers = np.mean([self.avg_coopers * (self.rounds_played - 1) + cooperators, cooperators]) if self.rounds_played > 1 else cooperators
            if cooperators >= self.game_description.m:
                action = Action.C
            elif cooperators < self.game_description.m - 1:
                action = Action.D
            elif self.avg_coopers >= self.game_description.m and self.k < self.game_description.k + 0.2:
                self.k += 0.1
            elif self.avg_coopers <= self.game_description.m - 2 and self.k > self.game_description.k - 0.2:
                self.k -= 0.1
        return action

class Strategy_COLLECTIVE_158(BaseStrategy):
    """
    A strategy based on Titan, a cooperative approach that adapts to the current situation and past performances.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.alpha = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            if np.random.random() < self._calculate_threshold(history):
                return Action.C
            return Action.D
        cooperators = self._count_cooperators(history)
        threshold = self._calculate_threshold(history)
        if cooperators / self.game_description.n_players >= threshold:
            return Action.C
        return Action.D

    def _calculate_threshold(self, history: PlayerHistory) -> float:
        cooperators = self._count_cooperators(history)
        if self.game_description.n_players % 2 == 1:
            return self.game_description.m / self.game_description.n_players + self.alpha
        return (self.game_description.m + 1) / self.game_description.n_players + self.alpha

    def _count_cooperators(self, history: PlayerHistory) -> int:
        if history is None or len(history.my_actions) == 0:
            return 0
        return np.sum(history.my_actions[-self.game_description.n_rounds:])

class Strategy_COLLECTIVE_159(BaseStrategy):
    """
    Adaptive Tit-for-Tat Strategy in Collective Risk Dilemma.
    Cooperation occurs when more than half of opponents cooperated last round.
    Otherwise, defects as a punishment for non-cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.min_cooperators:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_160(BaseStrategy):
    """
    A strategy that implements the Adaptive Tit-for-Tat strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m
        self.k = self.game_description.k
        self.n = self.game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if not history:
            return Action.C
        if state.round_number == self.game_description.n_rounds:
            cooperators = sum(history.opponent_actions[-1])
            payoff_maximization = cooperators >= self.m
            return Action.C if payoff_maximization else Action.D
        round_number = state.round_number - 1
        my_action = history.my_actions[round_number]
        opponent_cooperated = sum(history.opponent_actions[round_number]) >= self.n // 2 and my_action or not my_action
        return Action.C if opponent_cooperated else Action.D

    def update_state(self, state: GameState, action: Action, history: PlayerHistory) -> None:
        opponents = np.where(history.my_actions != action)[0]
        cooperators = sum(history.opponent_actions[:, opponents])
        if cooperators > self.m or state.round_number == self.game_description.n_rounds:
            history.my_actions[-1] = Action.C
        else:
            history.my_actions[-1] = Action.D
        history.opponent_actions[state.round_number, self.__class__.__name__] = action

class Strategy_COLLECTIVE_162(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Threshold Adaptation (TFTA)
    Strategy Description: Cooperates if more than half of players cooperated in the previous round. Otherwise, defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = math.ceil(game_description.n_players / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return random.choice([Action.C, Action.D])
        if not history:
            return random.choice([Action.C, Action.D])
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.m:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_163(BaseStrategy):
    """Adaptive Tit-for-Tat strategy for Collective Risk Dilemma."""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_three_rounds = [0] * 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        action = Action.D
        if state.round_number - 3 < self.last_three_rounds[-1]:
            if history and self.last_three_rounds[-1] == state.round_number - 4:
                action = Action.C if history.my_actions[-4] == Action.D else action
        if state.round_number - 2 < self.last_three_rounds[-2]:
            if history and self.last_three_rounds[-2] == state.round_number - 3:
                action = Action.C if history.my_actions[-3] == Action.D and history.my_actions[-4] == Action.D else action
        if state.round_number - 1 < self.last_three_rounds[-3]:
            if history and self.last_three_rounds[-3] == state.round_number - 2:
                action = Action.C if history.my_actions[-2] == Action.D and history.my_actions[-3] == Action.D and (history.my_actions[-4] == Action.D) else action
        if history:
            cooperators = sum(history.opponent_actions[state.round_number - 1])
            if state.round_number > self.last_three_rounds[-3] + 1 and cooperators >= self.game_description.m:
                action = Action.C if history.my_actions[state.round_number - 1] == Action.C else Action.D
            else:
                action = Action.D
        self.last_three_rounds[2], self.last_three_rounds[1], self.last_three_rounds[0] = (state.round_number, self.last_three_rounds[1], self.last_three_rounds[0])
        return action

class Strategy_COLLECTIVE_164(BaseStrategy):
    """
    Tit-for-Tat (with a twist) strategy for the Collective Risk Dilemma game.
    Cooperates in the first round to demonstrate good faith, and cooperates if at least m players cooperated in the previous round, otherwise defects.
    Switches to purely cooperative behavior for the next r/2 rounds if the number of players drops below n/2.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n_players = game_description.n_players
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        cooperative_phase = min(self.r // 2, int(self.n_players / 2) - cooperators + 1)
        if history and state.round_number > cooperative_phase:
            return Action.C if cooperators >= self.m else Action.D
        return Action.C

class Strategy_COLLECTIVE_166(BaseStrategy):
    """
    Tit-for-Tat Adaptive (TFT-A) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.f_counter = self.game_description.n_players - 1 if self.game_description.n_players < self.game_description.n_rounds else self.game_description.n_rounds - 1
        self.max_cooperators = game_description.n_players // game_description.m
        self.last_opponent_action = None
        self.last_opponent_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_actions = history.opponent_actions if history else np.zeros((1, self.game_description.n_players), dtype=bool)
        current_cooperators = sum(opponent_actions[-1, :])
        if current_cooperators < self.max_cooperators:
            return Action.D
        forgiveness_check = current_cooperators >= self.max_cooperators or (state.round_number > self.f_counter and self.last_opponent_action == Action.C and (current_cooperators > self.last_opponent_cooperators))
        self.last_opponent_cooperators = current_cooperators
        self.last_opponent_action = Action.C if forgiveness_check else Action.D
        return Action.C if forgiveness_check else Action.D

class Strategy_COLLECTIVE_167(BaseStrategy):
    """
    TFT-AC Strategy for Collective Risk Dilemma.
    This strategy follows Tit-for-Tat with adaptive cooperation based on the collective actions of opponents.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.propensity = 0.5
        self.cooperators_threshold = 0.6

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        total_players = len(history.opponent_actions[0, :])
        if cooperators >= self.game_description.m:
            cooperation_rate = cooperators / total_players
            if cooperation_rate > self.cooperators_threshold:
                self.propensity += 0.05
            elif cooperation_rate < self.cooperators_threshold - 0.1:
                self.propensity -= 0.05
        action = Action.D if random.random() > self.propensity else Action.C
        return action

class Strategy_COLLECTIVE_168(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Cooperative Adaptation (TFT-CA)
    A strategy that initially cooperates and mimics others' cooperation or defection. The adaptive component allows players to adjust their actions based on the majority's behavior, fostering a more collective approach that encourages stability and long-term cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = int(game_description.n_players * 0.5)
        self.my_cooperation_level = None
        self.last_round_cooperators = None

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is not None:
            self.update_cooperation_level(history)
        current_round_cooperators = sum(history.opponent_actions[state.round_number - 1, :])
        action = Action.D
        if current_round_cooperators >= self.threshold:
            action = Action.C
        return action

    def update_cooperation_level(self, history: PlayerHistory):
        cooperators_this_round = sum(history.opponent_actions[len(history.my_actions) - 1, :])
        if self.last_round_cooperators is not None and abs(self.last_round_cooperators - cooperators_this_round) > 1:
            self.my_cooperation_level = (cooperators_this_round + self.last_round_cooperators) // 2
        else:
            self.my_cooperation_level = cooperators_this_round > self.threshold
        self.last_round_cooperators = cooperators_this_round

class Strategy_COLLECTIVE_170(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperative Threshold (TFTC) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.payoff_history = []
        self.rounds_without_defection = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None or state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1])
        self.rounds_without_defection += 1 if cooperators >= self.cooperation_threshold else 0
        if cooperators >= self.cooperation_threshold and state.round_number > 1:
            increment = int(math.ceil(self.game_description.n_players * (self.rounds_without_defection / state.round_number)))
            self.cooperation_threshold += max(increment - self.cooperation_threshold, 0)
        return Action.C if cooperators >= self.cooperation_threshold else Action.D

class Strategy_COLLECTIVE_171(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Cooperative Threshold Strategy for Collective Risk Dilemma.
    Encourages cooperation when a majority of players have also chosen to collaborate.
    Punishes freeriders by defecting when necessary to maintain a minimum level of cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n = game_description.n_players
        self.history = []

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or len(self.history) == 0:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-1])
        collaborations = np.sum(np.where(history.my_actions != history.opponent_actions, 1, 0))
        if cooperators >= self.m:
            return Action.C
        elif collaborations < self.n - self.m + 1 and cooperators < self.m:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_172(BaseStrategy):
    """
    Adaptive Tit-for-Tat strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.opponent_history.append(history.opponent_actions[-1]) if history else None
        last_round_opponent_action = np.mean(self.opponent_history) if self.opponent_history else Action.C
        return Action.C if last_round_opponent_action == Action.C else Action.D

class Strategy_COLLECTIVE_173(BaseStrategy):
    """
    A Tit-for-Tat Adaptive Cooperation Strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.smooth_factor = 0.1

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.m - 1 and state.round_number > 1:
            return Action.C
        return Action.D

    def adjust_strategy(self, state: GameState, history: PlayerHistory):
        """
        Adjust the strategy based on the game's performance.
        This method is not part of the original requirement but added for flexibility.
        """
        if state.round_number == self.game_description.n_rounds:
            if sum(history.my_actions[:, 0]) > self.game_description.n_rounds * self.m // 2:
                return Action.C
        else:
            my_cooperators = sum(history.my_actions[:, :self.game_description.n_rounds - state.round_number])
            if my_cooperators > state.round_number * self.m // 2:
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_174(BaseStrategy):
    """
    Tit-for-Tat Strategy with Adaptive Cooperation Threshold for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.initial_threshold = game_description.m + (game_description.n_players - game_description.m) // game_description.n_rounds
        self.learning_rate = 0.01
        self.cooperators_last_round = 0
        self.act = self.initial_threshold

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :]) if history is not None else 0
        self.cooperators_last_round = cooperators
        self.act = self.initial_threshold * (1 + self.learning_rate * (cooperators - self.game_description.m))
        return Action.C if cooperators >= math.ceil(self.game_description.n_players * self.act / 100) else Action.D

class Strategy_COLLECTIVE_175(BaseStrategy):
    """
    The Tit-for-Tat Adaptive (TFT-A) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if not history or state.round_number == 0:
            return Action.C
        past_actions = history.opponent_actions[-2] if state.round_number > 1 else np.zeros(self.game_description.n_players)
        cooperators = sum(past_actions >= self.m)
        if cooperators == self.game_description.n_players:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_176(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Risk Aversion (ATfTRA) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.forgiveness_counter = 10
        self.last_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if not history or state.round_number == 0:
            return Action.C
        if state.round_number < self.game_description.n_rounds:
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators >= self.m - 1 or self.forgiveness_counter > 0:
                return Action.C
            else:
                self.forgiveness_counter -= 1
                return Action.D
        if self.forgiveness_counter == 0 and cooperators < self.m:
            self.last_cooperators = cooperators
            return Action.D
        if self.forgiveness_counter > 0 and cooperators >= self.m:
            self.forgiveness_counter = 10
            return Action.C
        if state.round_number == self.game_description.n_rounds:
            if cooperators >= self.last_cooperators or self.last_cooperators >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_177(BaseStrategy):
    """
    Strategy name: Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)
    Summary: A strategy that cooperates in the initial round and adjusts its cooperation threshold dynamically based on the number of cooperators in recent rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = math.floor((game_description.n_players + 1) / 2)
        self.r_c = min(int(game_description.n_rounds * 0.5), 3)
        self.r_d = self.r_c

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_cooperators = sum(history.opponent_actions[-self.r_c:, :].sum(axis=0))
        past_cooperators = sum(history.opponent_actions[-self.r_d:, :].sum(axis=0))
        if state.round_number == history.opponent_payoffs.size - 1 or current_cooperators >= self.cooperation_threshold:
            self.cooperation_threshold = max(1, min(self.cooperation_threshold + 1, self.game_description.n_players))
        elif past_cooperators < self.cooperation_threshold and current_cooperators > 0:
            self.cooperation_threshold -= 1
        return Action.C if current_cooperators >= self.cooperation_threshold else Action.D

class Strategy_COLLECTIVE_179(BaseStrategy):
    """
    A strategy that encourages cooperation, reciprocating when others cooperate and defecting if they have previously defected.
    In the Collective Risk Dilemma, this strategy adopts a reciprocal behavior that encourages cooperation when at least `m` players cooperated in the previous round and defects if fewer than `m` players cooperated.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.minimum_cooperators = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.minimum_cooperators:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_180(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Threshold (TFT-AT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.rounds_played = 0
        self.min_cooperators = self.game_description.m
        self.penalty_length = math.ceil(self.game_description.n_players / 2)
        self.history = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            self.history = history
            self.rounds_played += 1
            cooperators = sum(self.history.opponent_actions[-1, :])
            if self.rounds_played == self.game_description.n_rounds:
                if cooperators >= self.min_cooperators:
                    return Action.C
                elif cooperators < self.min_cooperators - self.penalty_length:
                    self.min_cooperators = cooperators + 1
                    self.penalty_length += 2
            if cooperators >= self.min_cooperators:
                return Action.C
            elif self.rounds_played > self.game_description.n_rounds - self.penalty_length:
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_181(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperative Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.initial_threshold = math.ceil(game_description.n_players * 0.5)
        self.adaptation_period = int(game_description.n_rounds * 0.8)
        self.smoothing_factor = 0.5
        self.current_threshold = self.initial_threshold
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and len(history.my_actions) < self.adaptation_period):
            return Action.D
        cooperators = np.sum(history.opponent_actions[-1, :]) if history is not None else 0
        if cooperators >= self.current_threshold:
            return Action.C
        return Action.D

    def update_cooperative_threshold(self):
        average_cooperation = np.mean([h[0] for h in self.cooperation_history])
        new_threshold = int((1 - self.smoothing_factor) * average_cooperation + self.smoothing_factor * self.current_threshold)
        if new_threshold < self.game_description.m:
            new_threshold = self.game_description.m
        elif new_threshold > self.game_description.n - 1:
            new_threshold = self.game_description.n - 1
        self.current_threshold = new_threshold
        self.cooperation_history.append([len(self.cooperation_history) == self.adaptation_period and cooperators >= self.current_threshold for cooperators in history.my_actions if history is not None])

class Strategy_COLLECTIVE_182(BaseStrategy):
    """
    Strategy name: Adaptive Tit-for-Tat (ATFT) for Collective Risk Dilemma
    Strategy description: Cooperates initially and imitates opponents' actions in subsequent rounds if at least m players cooperated; otherwise, defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m
        self.n = self.game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1])
        if cooperators >= self.m:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_183(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATfT) for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.t = math.ceil(game_description.n_rounds * 0.8)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        else:
            if state.round_number == 1:
                return Action.C
            last_round = len(history.opponent_actions) - 1
            cooperators = sum(history.opponent_actions[last_round, :])
            if last_round < self.t or (cooperators >= self.game_description.m and last_round == self.t):
                return Action.C
            return Action.D

class Strategy_COLLECTIVE_184(BaseStrategy):
    """
    The Tit-for-Tat (TFT) strategy with Adaptation for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.tolerance = math.floor((game_description.m - 1) / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None or len(history.opponent_actions) == 0:
            return Action.D
        last_round = len(history.opponent_actions) - 1
        cooperators = sum(history.opponent_actions[last_round, :])
        if cooperators >= self.game_description.m or (cooperators < self.tolerance and history.opponent_actions[-1, -1] == Action.C):
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_185(BaseStrategy):
    """
    A strategy that follows the Tit-for-Tat Adaptive (TFT-A) approach in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.strategy = [Action.C] * self.game_description.n_rounds + [None] * (self.game_description.n_rounds - 1)

    def __call__(self, state: GameState, history: PlayerHistory):
        if state.round_number == 0 or history is None:
            return self.strategy[state.round_number]
        last_round = len(self.strategy) - 1
        strategy_last_round = self.strategy[last_round]
        if strategy_last_round == Action.C and history.opponent_actions[-1, state.player_index] == Action.D:
            self.strategy[last_round] = Action.D
        elif strategy_last_round == Action.D and history.opponent_actions[-1, state.player_index] == Action.C:
            if last_round > 1 and self.strategy[last_round - 1] == Action.D:
                self.strategy[last_round] = Action.C
            else:
                self.strategy[last_round] = strategy_last_round
        return self.strategy[state.round_number]

class Strategy_COLLECTIVE_186(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat with Risk Aversion (ATfTRA)
    Strategy Description: A strategy that encourages reciprocity while also considering the collective goal of meeting the cooperation threshold and risk aversion.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.endowment = 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return random.choice([Action.C, Action.D])
        elif history is not None:
            self.endowment = np.mean(history.my_payoffs[:state.round_number])
            own_past_action = history.my_actions[-1]
            num_cooperators_last_round = sum(history.opponent_actions[-1, :])
            if own_past_action and num_cooperators_last_round >= self.game_description.m:
                if self.endowment * self.game_description.k > self.endowment * self.game_description.k / 1.5:
                    return Action.C
            if not own_past_action and num_cooperators_last_round >= self.game_description.m:
                if self.endowment * self.game_description.k > self.endowment * self.game_description.k / 1.5:
                    return Action.C
        return Action.D

class Strategy_COLLECTIVE_187(BaseStrategy):
    """
    Titan Strategy for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            threshold = math.ceil(self.game_description.m * state.round_number / self.game_description.n_players + 1)
        else:
            previous_cooperators = np.sum(history.my_actions[:state.round_number])
            threshold = math.ceil((previous_cooperators + self.game_description.m * state.round_number) / self.game_description.n_players + 1 if previous_cooperators >= self.threshold else self.game_description.m * state.round_number / self.game_description.n_players + 1)
        cooperators = np.sum(history.opponent_actions[state.round_number - 1, :]) if history is not None else 0
        if cooperators >= threshold:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_188(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperative_threshold = game_description.m
        self.history = PlayerHistory(my_actions=np.zeros(game_description.n_rounds, dtype=bool), my_payoffs=np.zeros(game_description.n_rounds), opponent_actions=np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), opponent_payoffs=np.zeros((game_description.n_rounds, game_description.n_players)))

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.cooperative_threshold:
            self.cooperative_threshold += (self.cooperative_threshold - self.game_description.m) * 0.01 if state.round_number % (self.game_description.n_rounds // 2) == 0 and cooperators < self.game_description.m else self.cooperative_threshold - (self.cooperative_threshold - self.game_description.m) * 0.01 if state.round_number % (self.game_description.n_rounds // 2) == 0 and cooperators > self.game_description.m else self.cooperative_threshold
        return Action.C if cooperators >= self.cooperative_threshold else Action.D

class Strategy_COLLECTIVE_189(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Risk Aversion (ATfTra) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m
        self.bias = 0.5

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return np.random.choice([Action.C, Action.D], p=[self.bias, 1 - self.bias])
        else:
            n_cooperators = int(np.sum(history.opponent_actions[-1]))
            if n_cooperators >= self.m and state.round_number > 1:
                return Action.C
            elif n_cooperators < self.m and state.round_number > 1:
                return Action.D
        return Action.C

class Strategy_COLLECTIVE_190(BaseStrategy):
    """
    Tit-for-Tat Adaptive Cooperation Strategy for Collective Risk Dilemma.
    Mimics reciprocal behavior and encourages cooperation while still ensuring personal gain.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :]) if history is not None else 0
        if cooperators < self.m:
            return Action.D
        return Action.C

class Strategy_COLLECTIVE_191(BaseStrategy):
    """Tit-for-Tat with Adaptive Cooperation (TFTA) strategy for the Collective Risk Dilemma game"""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.p = 0.6
        self.q = 0.5
        self.r = 0.5
        self.increment = 0.1
        self.x = int(game_description.n_rounds * 0.7)
        self.y = int(game_description.n_rounds * 0.3)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_cooperators = sum(history.opponent_actions[-self.x:-1]) if history else 0
        my_recent_cooperation = sum(history.my_actions[-self.x:] if history else [0]) if history else 0
        recent_opponent_cooperative_rounds = sum(history.opponent_actions[:-self.y, -1] if history else [0]) if history else 0
        self.q += self.increment if my_recent_cooperation > self.p * self.n else 0
        self.r += self.increment if recent_opponent_cooperative_rounds > 0 else 0
        action = Action.C if random.random() < self.q * self.r else Action.D
        return action

class Strategy_COLLECTIVE_192(BaseStrategy):
    """
    Tit-for-Tat Strategy for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m
        self.n_players = game_description.n_players
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-1])
        if cooperators >= self.min_cooperators:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_193(BaseStrategy):
    """Adaptive Tit-for-Tat strategy for Collective Risk Dilemma"""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self._last_cooperation = False
        self._opponent_history = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None:
            self._opponent_history = np.zeros((1, self.game_description.n_players), dtype=np.bool_)
        else:
            self._opponent_history = history.opponent_actions
        if len(self._opponent_history) == self.game_description.n_rounds:
            return Action.C
        round_number = state.round_number - 1
        opponent_action = self._opponent_history[round_number, :]
        last_cooperation = self._last_cooperation if round_number > 0 else False
        if opponent_action.sum() >= self.game_description.n_players - self.game_description.m:
            return Action.C
            self._last_cooperation = True
        elif opponent_action.sum() < self.game_description.m and last_cooperation:
            self._last_cooperation = False
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_195(BaseStrategy):
    """
    Adaptive Tit-for-Tat Strategy for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.state = {'cooperative': True, 'consecutiveCooperationCount': 0, 'threshold': math.ceil(game_description.n_players * 0.75), 'last_round': False}

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if not history:
            return self.state['cooperative'] and Action.C or Action.D
        round_number = state.round_number
        if round_number == 0:
            self.state['cooperative'] = True
            self.state['consecutiveCooperationCount'] = 0
            return Action.C
        opponent_cooperators = sum(history.opponent_actions[-1, :])
        cooperated_last_round = history.my_actions[-1]
        if round_number > self.game_description.n_players - self.state['threshold']:
            self.state['last_round'] = True
        if self.state['last_round']:
            cooperative_decision = self.state['cooperative']
        else:
            cooperative_decision = opponent_cooperators >= self.game_description.m and cooperated_last_round or not cooperated_last_round
        if cooperative_decision:
            self.state['consecutiveCooperationCount'] += 1
            if self.state['consecutiveCooperationCount'] > self.state['threshold']:
                for _ in range(min(self.game_description.n_players, round_number + 3) - round_number):
                    self.state['consecutiveCooperationCount'] -= 1
                    self.state['cooperative'] = True
        else:
            self.state['consecutiveCooperationCount'] = 0
            self.state['cooperative'] = False
        return cooperative_decision and Action.C or Action.D

class Strategy_COLLECTIVE_197(BaseStrategy):
    """
    The Tit-for-Tat with Adaptive Cooperation (TFT-AC) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.adaptation = 0.01
        self.cooperation_threshold = game_description.m - 1
        self.last_round_adjustment = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if not history and state.round_number == 0:
            return Action.C
        players_cooperated = sum(history.opponent_actions[-1, :]) if history else 0
        if state.round_number == self.game_description.n_rounds - 1:
            if players_cooperated < self.game_description.m * 0.7:
                self.last_round_adjustment = True
                return Action.D
        excess_cooperators = max(players_cooperated - (self.cooperation_threshold + int(self.adaptation)), 0)
        new_adaptation = min(0.9, self.adaptation + excess_cooperators * self.adaptation)
        if state.round_number > 1:
            if history and history.my_actions[-2] == Action.C and (history.opponent_actions[-1, -self.game_description.n_players + 1] == Action.D):
                self.last_round_adjustment = True
            else:
                self.last_round_adjustment = False
        if self.last_round_adjustment:
            cooperation_threshold = self.cooperation_threshold
        else:
            cooperation_threshold = self.cooperation_threshold + int(new_adaptation)
        self.adaptation = new_adaptation
        self.cooperation_threshold = cooperation_threshold
        return Action.C if history and history.opponent_actions[-1, -self.game_description.n_players + 1] == Action.C else Action.D

class Strategy_COLLECTIVE_198(BaseStrategy):
    """
    Implementation of the Adaptive Tit-for-Tat (ATFT) strategy for the Collective Risk Dilemma game.
    The ATFT strategy attempts to balance cooperation and defection based on observed behaviors in the community.
    By cooperating when others do, it aligns with a collective mindset and encourages mutual benefits when possible.
    At the same time, it punishes those who do not cooperate in order to discourage free-riding and preserve individual interests.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = self.game_description.m
        self.k_factor = self.game_description.k

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0 and (not history):
            return Action.C
        cooperators = 0
        previous_cooperators = 0 if not history else sum(history.opponent_actions[-1])
        if history:
            cooperators = previous_cooperators >= self.threshold
        if not cooperators:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_200(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperative Threshold (TFT-ACT) Strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.c_thresh = game_description.m // 2
        self.total_coop_reward = 0
        self.total_defect_reward = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        cooperate = len(history.opponent_actions[-1][:cooperators]) > self.c_thresh if len(history.opponent_actions) else True
        if cooperate:
            reward = k_factor = self.game_description.k * (self.game_description.m - cooperators) + sum(history.opponent_payoffs[-1][:cooperators])
            total_reward = self.total_coop_reward + reward
            if total_reward > self.total_defect_reward:
                self.c_thresh += 0.01
        else:
            reward = k_factor = sum(history.opponent_payoffs[-1][cooperators:])
            total_reward = self.total_defect_reward + reward
            if total_reward > self.total_coop_reward:
                self.c_thresh -= 0.01
        return Action.C if total_reward + k_factor > self.total_defect_reward else Action.D

class Strategy_COLLECTIVE_201(BaseStrategy):
    """Adaptive Tit-for-Tat with Risk Aversion (ATfT-RA) strategy for the Collective Risk Dilemma game."""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.k = game_description.k
        self.history_cooperation = np.zeros(self.game_description.n_rounds)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            self.history_cooperation[-1] = sum(history.opponent_actions[-1]) / self.game_description.n_players
        if history and state.round_number > 1 and (history.my_actions[-1] != Action.C):
            risk_threshold = self.m * (self.k - 1) / self.k
            if self.history_cooperation[-1] >= risk_threshold:
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_203(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Risk Aversion (ATfTA-RA) strategy for Collective Risk Dilemma game.
    The strategy cooperates when more than half of opponents have cooperated in the previous round,
    and defects otherwise, or with a probability based on the number of cooperators minus the minimum required.
    The risk aversion aspect allows for flexibility in response to various opponent behaviors.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.p = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        n_players = self.game_description.n_players
        cooperators = sum(history.opponent_actions[-1, :]) if history else 0
        m = self.game_description.m
        k = self.game_description.k
        if cooperators >= m:
            if k > 2:
                self.p = min(1, max(0, (m - cooperators) / (n_players - m)))
                return Action.C if random.random() < self.p else Action.D
            else:
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_204(BaseStrategy):
    """
    Adaptive Tit-for-Tat strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.epsilon = 0.2
        self.m = game_description.n_players // self.game_description.m
        self.total_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.total_cooperators += sum(history.my_actions) if history else 0
        cooperators = sum(history.opponent_actions[-1, :]) if history else 0
        if cooperators >= self.m and self.total_cooperators >= self.game_description.n_players * (1 - self.epsilon):
            return Action.C
        elif cooperators < self.m:
            return Action.D if random.random() > 1 - self.epsilon else Action.C
        return Action.C

class Strategy_COLLECTIVE_205(BaseStrategy):
    """
    The Adaptive Tit-for-Tat (ATFT) strategy for the Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.total_payoff = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        self.total_payoff = np.sum(history.my_payoffs[:state.round_number])
        cooperators = sum(history.opponent_actions[state.round_number - 1, :])
        if cooperators >= self.game_description.n_players // 2:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_206(BaseStrategy):
    """
    Adaptive Tit-for-Tat strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_cooperators = 0
        self.last_defectors = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :]) if history else 0
        self.last_cooperators = cooperators if cooperators >= self.game_description.m else 0
        self.last_defectors = self.game_description.n_players - cooperators
        if state.round_number == self.game_description.n_rounds or (history and self.last_defectors >= self.last_cooperators):
            return Action.C
        return Action.D if self.last_defectors > self.last_cooperators else Action.C

class Strategy_COLLECTIVE_208(BaseStrategy):
    """
    A collective risk dilemma strategy that cooperates initially and adapts its actions based on the majority of other players' cooperation in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m
        self.n = self.game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        majority = math.ceil((self.n + 1) * self.m / 2)
        if len(np.unique(history.opponent_actions[-1])) >= majority:
            if cooperators == self.n - (majority - 1):
                return Action.D
            elif cooperators < self.n - majority:
                return Action.C
            else:
                random_choice = random.random()
                if random_choice > 0.5:
                    return Action.C
                else:
                    return Action.D
        elif random.random() > 0.6:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_209(BaseStrategy):
    """
    Implementation of the Adaptive Tit-for-Tat strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.minimum_cooperators = self.game_description.m
        self.k = self.game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :]) if history is not None else 0
        return Action.C if cooperators >= self.minimum_cooperators else Action.D
        if state.round_number == self.game_description.n_rounds:
            return (cooperators >= self.minimum_cooperators) * Action.C + (Action.D - (cooperators >= self.minimum_cooperators))

class Strategy_COLLECTIVE_210(BaseStrategy):
    """
    Adaptive Tit-for-Tat Strategy for the Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.average_cooperators = 0
        self.rounds_count = 0
        self.periodic_threshold = math.ceil(game_description.n_players * game_description.n_rounds / self.game_description.k)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            self.update_average(history)
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators >= self.game_description.n_players * self.game_description.m / self.game_description.n_players:
                return Action.C
        return Action.D

    def update_average(self, history):
        self.rounds_count += 1
        if self.rounds_count % self.periodic_threshold == 0 or self.rounds_count == 1:
            self.average_cooperators = (self.average_cooperators * (self.rounds_count - 1) + history.opponent_actions[-1].sum()) / self.rounds_count

class Strategy_COLLECTIVE_212(BaseStrategy):
    """
    Tit-for-Tat with adaptations for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_coop = math.ceil(game_description.n_players * game_description.m / 100)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponents = history.opponent_actions if history else np.zeros((1, self.game_description.n_players), dtype=bool)
        coop_threshold = self.min_coop if np.sum(np.sum(opponents[-1], axis=0)) < self.min_coop else self.game_description.n_players // 2
        cooperators = sum(opponents[-1] > coop_threshold - 1)
        if cooperators >= coop_threshold:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_217(BaseStrategy):
    """
    Implementation of the Adaptive Tit-for-Tat (ATfT) strategy for the Collective Risk Dilemma.
    This strategy promotes cooperation by cooperating initially, and then adopting the behavior of the majority of cooperators in subsequent rounds.
    If more than m players cooperated in the previous round, it continues to cooperate; otherwise, it defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and len(history.opponent_actions) == 0):
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.m:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_218(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperative Threshold (TFT-ACT)
    Strategy Description: Follows cooperative or defective actions based on majority behavior of other players in recent past.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = math.ceil(game_description.n_players // 2)
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players - 1), dtype=bool), np.zeros((game_description.n_rounds, game_description.n_players - 1)))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.history.my_actions[0] = True
            return Action.C
        cooperators = np.sum(history.opponent_actions[-self.m:, :]) >= (self.game_description.n_players - 1) // 2
        if cooperators:
            self.history.my_actions[-1] = True
            return Action.C
        self.history.my_actions[-1] = False
        return Action.D

class Strategy_COLLECTIVE_219(BaseStrategy):
    """
    An adaptive Tit-for-Tat strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = np.zeros((self.game_description.n_rounds, 1), dtype=bool)
        self.total_payoff = 0.0

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        opponent_cooperators = sum(history.opponent_actions[-1, :])
        self.opponent_history[-1] = opponent_cooperators >= self.game_description.n_players // 2
        if self.opponent_history[-1]:
            return Action.C
        return Action.D

    def get_total_payoff(self) -> float:
        """
        Returns the total payoff for this strategy over all rounds.
        """
        return self.total_payoff

class Strategy_COLLECTIVE_220(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation (TFT-AC) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.p_init = self.game_description.m / self.game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and len(history.opponent_actions) > 0:
            cooperators = sum(history.opponent_actions[-1, :])
            p_coop = (self.game_description.n_players - (self.game_description.m - state.round_number)) / (self.game_description.n_players - self.game_description.m + 1) if state.round_number >= self.game_description.m else state.round_number / self.game_description.m
            random_choice = random.random()
            return Action(int(random_choice < p_coop))
        else:
            return Action(int(random.random() < self.p_init))

class Strategy_COLLECTIVE_221(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.my_actions = np.zeros(game_description.n_rounds, dtype=int)
        self.my_payoffs = np.zeros(game_description.n_rounds, dtype=float)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            self.my_actions[0] = 1
            return Action.C
        elif state.round_number > 0:
            previous_action = self.my_actions[-1] if len(self.my_actions) > 0 else 0
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators >= self.game_description.n_players // 2:
                self.my_payoffs[-1] = previous_action + (cooperators * self.game_description.k - len(self.my_actions))
            else:
                self.my_payoffs[-1] = previous_action
            return Action((previous_action + 1) % 2)

class Strategy_COLLECTIVE_222(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation (TFT-AC)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.p = 0.5
        self.epsilon = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :]) if history else 0
        adaptability_factor = self.epsilon * ((cooperators - self.p * self.n) / self.n)
        opponent_cooperated_last_round = bool(history and np.any(history.opponent_actions[-1]))
        cooperate = Action.C if opponent_cooperated_last_round + adaptability_factor > 0.5 else Action.D
        return cooperate

class Strategy_COLLECTIVE_223(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATfT) for Collective Risk Dilemma

    This strategy starts by cooperating in the first round and when history is not available. In each subsequent round, ATfT continues to cooperate if a majority of players cooperated in the previous round; otherwise, it defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.minority = math.floor(self.game_description.n_players / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperation_count = sum(history.opponent_actions[-1])
        if cooperation_count >= self.minority:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_225(BaseStrategy):
    """
    Tit-for-Tat Adaptive Cooperation (TFT-AC) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperator_threshold = int(math.ceil(game_description.n_players * game_description.m / 100))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :]) if history else 0
        if cooperators >= self.cooperator_threshold or state.round_number == self.game_description.n_rounds:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_227(BaseStrategy):
    """
    Tit-for-Tat Cooperation (TFTC) with Adaptive Threshold (A-TFTC) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n = game_description.n_players
        self.k = game_description.k
        self.threshold = math.ceil(self.m)
        self.best_payoff = 0.0
        self.cooperated_last_round = False
        self.history = PlayerHistory(np.zeros((1, self.game_description.n_rounds), dtype=bool), np.zeros(self.game_description.n_rounds), np.zeros((self.game_description.n_rounds, self.game_description.n_players), dtype=bool), np.zeros(self.game_description.n_rounds))

    def __call__(self, state: GameState, history: PlayerHistory):
        self.history = history
        if state.round_number == 0:
            return Action.C
        coop_this_round = False
        current_payoff = 0.0
        opponents_cooperated = sum(history.opponent_actions[state.round_number - 1, :])
        if opponents_cooperated >= self.threshold:
            if np.sum(history.my_payoffs[state.round_number - 1]) > np.sum(history.my_payoffs[state.round_number - 1] * self.game_description.k):
                self.threshold += 1
            else:
                self.threshold -= 1
            coop_this_round = True
        elif opponents_cooperated == 0 and self.threshold > 1:
            coop_this_round = False
        else:
            pass
        self.cooperated_last_round = coop_this_round
        payoff = np.mean(history.my_payoffs)
        if payoff > self.best_payoff:
            coop_this_round = False
            self.best_payoff = payoff
        if coop_this_round:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_228(BaseStrategy):
    """
    A Tit-for-Tat strategy with adaptive cooperation threshold for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.total_players = game_description.n_players
        self.cooperators_count = np.zeros(self.game_description.n_rounds, dtype=np.int32)
        self.min_cooperators = math.ceil(self.total_players / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        action = Action.D
        if history:
            opponents_cooperators = sum(history.opponent_actions[-1, :])
            self.cooperators_count[state.round_number] += opponents_cooperators
            if opponents_cooperators >= self.min_cooperators and state.round_number > 1:
                action = Action.C
            if opponents_cooperators < self.total_players - self.cooperation_threshold and state.round_number > 1:
                self.adjust_threshold(opponents_cooperators)
        return action

    def adjust_threshold(self, cooperators: int):
        """
        Adjust the cooperation threshold based on the observed behavior of opponents.
        """
        new_threshold = cooperators + 1 if cooperators >= self.min_cooperators else cooperators
        self.cooperation_threshold = max(new_threshold, self.game_description.m - 1)
        self.min_cooperators = math.ceil((self.total_players + self.cooperation_threshold) / 2)

class Strategy_COLLECTIVE_229(BaseStrategy):
    """
    Implementation of TFT-ACT strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = 1
        self.previous_payoff = float('-inf')

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and history.my_actions[-1].all():
            cooperators = sum(history.opponent_actions[-1])
            if cooperators >= self.game_description.m:
                current_payoff = np.mean(history.my_payoffs)
                if current_payoff > self.previous_payoff and self.cooperation_threshold < self.game_description.n_players:
                    self.cooperation_threshold += 1
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_230(BaseStrategy):
    """
    Tit-for-Tat Cooperation strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            if state.round_number == 0:
                return Action.C
            else:
                self.history = PlayerHistory(np.zeros(state.round_number, dtype=bool), np.zeros(state.round_number), np.zeros((state.round_number, self.game_description.n_players), dtype=bool), np.zeros(state.round_number))
                return Action.C
        else:
            self.history = history
            cooperators = sum((1 for action in self.history.opponent_actions[-state.round_number:, :] if np.all(action == True)))
            if state.round_number == 1 or cooperators >= self.game_description.m:
                return Action.C
            if state.round_number > 1 and (self.history.my_actions[-2] == Action.C and self.history.my_actions[-1] != Action.C):
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_231(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_round_cooperators = 0
        self.last_action = Action.D

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            self.last_round_cooperators = sum(history.opponent_actions[-1])
            self.last_action = history.my_actions[-1]
        if self.last_action == Action.C and self.game_description.m <= self.last_round_cooperators + 1:
            return Action.C
        elif self.last_action == Action.D and self.game_description.m > self.last_round_cooperators + 1:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            if self.last_round_cooperators < self.game_description.m - 1:
                return Action.D
            elif self.last_round_cooperators >= self.game_description.m:
                return Action.C
        elif self.last_round_cooperators == self.game_description.m - 1:
            if random.random() < 0.5:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_233(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.past_action = Action.C

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return self.past_action
        past_opponent_action = history.opponent_actions[state.round_number - 1, 0]
        if past_opponent_action == self.past_action.value:
            return self.past_action
        else:
            self.past_action = Action(int(not self.past_action.value))
            return self.past_action

class Strategy_COLLECTIVE_234(BaseStrategy):
    """
    A Tit-for-Tat with Adaptive Cooperative Threshold (TFTAT) Strategy.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperators_in_previous_round = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or self.cooperators_in_previous_round is None:
            return Action.C
        self.cooperators_in_previous_round = sum(history.opponent_actions[state.round_number - 1])
        if self.cooperators_in_previous_round >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_235(BaseStrategy):
    """
    A simple adaptive strategy inspired by the Tit-for-Tat strategy in the Prisoner's Dilemma game, but tailored for the Collective Risk Dilemma.
    This strategy cooperates initially and adapts to the behavior of other players throughout the game. It cooperates when enough other players have cooperated in the previous round (m or more), while defecting when fewer than m players cooperate to protect its own resources.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m
        self.last_round = game_description.n_rounds - 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators < self.min_cooperators:
            return Action.D
        elif state.round_number == self.last_round:
            return Action.C
        else:
            return Action.C

class Strategy_COLLECTIVE_236(BaseStrategy):
    """
    Tit-for-Tat Adaptive Cooperation (TFTAC) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.trust_window = int(math.ceil(game_description.n_players / 2))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            return Action.C
        recent_opponent_actions = history.opponent_actions[-self.trust_window:, -1]
        opponent_cooperators = sum(recent_opponent_actions)
        if opponent_cooperators >= self.trust_window:
            return Action.C
        return Action.D

    def last_round_behavior(self, history: PlayerHistory) -> Action:
        if sum(history.opponent_actions[-self.trust_window:, -1]) >= self.trust_window:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_237(BaseStrategy):
    """
    Adaptive Tit-for-Tat Strategy for Collective Risk Dilemma Game
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.num_players = game_description.n_players
        self.min_cooperators = math.ceil(self.num_players * game_description.m / 3)
        self.early_punishment_threshold = math.ceil(self.num_players * game_description.m / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            if history is None:
                return Action.D
            cooperators = sum(history.opponent_actions[-1])
            if cooperators >= self.min_cooperators and state.round_number > 1:
                return Action.C
            elif state.round_number <= math.ceil(self.num_players / 3) and history.my_actions[-1] == Action.D:
                return Action.D
            else:
                return Action.C

class Strategy_COLLECTIVE_238(BaseStrategy):
    """
    Implementation of the Tit-for-Tat-Adaptive (TfT-A) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_increases = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None or state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        majority = self.game_description.n_players // 2
        if cooperators >= majority:
            self.consecutive_increases = max(0, self.consecutive_increases + 1)
            return Action.C
        elif cooperators >= self.game_description.m > majority - 1 and self.consecutive_increases >= 2:
            return Action.C
        elif cooperators >= self.game_description.m > majority - 1 and self.consecutive_increases < 2:
            return Action.D
        else:
            self.consecutive_increases = 0 if self.consecutive_increases > 0 else self.consecutive_increases
            return Action.D

class Strategy_COLLECTIVE_239(BaseStrategy):
    """
    This strategy implements the Tit-for-Tat Adaptive Cooperation (TFTAC) in the Collective Risk Dilemma game.
    It cooperates in the first round to demonstrate goodwill and encourages reciprocity, and then cooperates if the majority of players cooperated in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = int(math.ceil((game_description.n_players - 1) / 2))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and np.all(history.my_actions == [False])):
            return Action.C
        elif history is not None and np.count_nonzero(history.opponent_actions[-1]) >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_240(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.delta = 0.1
        self.last_round_cooperators = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.cooperation_threshold = self.game_description.n_players
            return Action.C
        if history is not None and self.last_round_cooperators is not None:
            current_round_cooperators = sum(history.opponent_actions[-1, :])
            self.cooperation_threshold += (current_round_cooperators >= self.game_description.m) * self.delta - (current_round_cooperators < self.game_description.m) * self.delta
        self.last_round_cooperators = sum(history.opponent_actions[-1, :]) if history is not None else 0
        cooperators = sum(history.opponent_actions[-1, :]) if history is not None else 0
        return Action.C if cooperators >= self.cooperation_threshold else Action.D

class Strategy_COLLECTIVE_241(BaseStrategy):
    """
    Implementation of Tit-for-Tat Adaptive (TFT-A) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.coop_counter = 0
        self.opponent_action_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is None or history.my_actions is None or len(history.my_actions) < self.game_description.n_rounds:
            return Action.C
        if state.round_number == self.game_description.n_rounds:
            return Action.C
        coop_last = sum(history.my_actions[-1])
        self.coop_counter += 1 if history.my_actions[-1][0] else 0
        if coop_last >= self.game_description.m and self.coop_counter >= self.game_description.m:
            return Action.C
        elif coop_last < self.game_description.m and history.my_actions[-1][0] and (self.opponent_action_history[-1] == 1):
            action = 1
        elif coop_last < self.game_description.m and (not history.my_actions[-1][0]) and (self.opponent_action_history[-1] == 0):
            action = 0
        else:
            action = self.opponent_action_history[-1]
        self.opponent_action_history.append(action)
        return Action(action)

class Strategy_COLLECTIVE_242(BaseStrategy):
    """
    Tit-for-Tat Adaptive Strategy for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.history = PlayerHistory(np.zeros(self.game_description.n_rounds, dtype=bool), np.zeros(self.game_description.n_rounds), np.zeros((self.game_description.n_rounds, self.n_players), dtype=bool), np.zeros((self.game_description.n_rounds, self.n_players)))

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is None:
            history = self.history
        total_cooperators = sum(history.opponent_actions[-1, :])
        if total_cooperators < self.m:
            return Action.D
        else:
            return Action.C
        payoff = 0 if total_cooperators < self.m else 1 + self.k
        my_action = int(self.__class__.__name__[9]) if state.round_number == self.game_description.n_rounds - 1 and total_cooperators >= self.m else int(history.my_actions[-1])
        self.history.my_actions[-1] = my_action
        self.history.my_payoffs[-1] = payoff

class Strategy_COLLECTIVE_243(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT) strategy in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.m
        self.history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if not history:
            return Action.C
        self.history += [np.mean(history.opponent_actions[-1]) > self.game_description.n_players - self.threshold]
        cooperation_level = np.mean(history.opponent_actions[-1]) if len(self.history) > 1 else False
        threshold_change = 1 if cooperation_level < self.threshold else -1
        self.threshold += threshold_change
        self.threshold = max(self.threshold, self.game_description.m)
        return Action.C if cooperation_level >= self.threshold else Action.D

class Strategy_COLLECTIVE_244(BaseStrategy):
    """
    Adaptive Tit-for-Tat Strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(my_actions=np.empty((1,), dtype=bool), my_payoffs=np.empty((1,), dtype=float), opponent_actions=np.empty((1, game_description.n_players), dtype=bool), opponent_payoffs=np.empty((1, game_description.n_players), dtype=float))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None or state.round_number == 0:
            self.history = PlayerHistory(my_actions=np.array([[True]]), my_payoffs=np.array([[0.0]]), opponent_actions=np.zeros((1, self.game_description.n_players)), opponent_payoffs=np.zeros((1, self.game_description.n_players)))
            return Action.C
        else:
            cooperators = sum(history.opponent_actions[-1])
            if cooperators >= self.game_description.m and cooperators > (self.game_description.n_players - self.game_description.m) // 2:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_245(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation (TFT-AC)

    A cooperative strategy that encourages cooperation by mimicking other players' actions and fostering a reciprocal relationship.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self._t_w = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if not history:
            return Action.C
        current_round = state.round_number - 1
        if self._t_w is None:
            self._set_t_w()
        players_cooperated = sum(history.opponent_actions[current_round])
        action = Action.C if players_cooperated >= (self.n + self._t_w - 1) // 2 else Action.D
        if current_round == len(history.my_actions) - 1 and history.my_payoffs[-1] < np.mean(history.my_payoffs):
            action = Action.D
        return action

    def _set_t_w(self):
        self._t_w = int(self.m / 2 if self.n < 10 or self.k <= 2.5 else math.ceil(self.n // 4))

class Strategy_COLLECTIVE_246(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Threshold (TFT-AT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperators = 0
        self.p_t = 1.0
        self.payoff = 0
        self.threshold = game_description.m / (game_description.n_players - 1)

    def __call__(self, state: GameState, history: PlayerHistory):
        if state.round_number == 0 and history is None:
            return Action.C
        cooperation_count = sum(history.opponent_actions[-1])
        p_t_1 = cooperation_count / self.game_description.n_players
        if cooperation_count >= self.threshold:
            action = Action.C
        elif p_t_1 < self.threshold and p_t_1 - 0.05 <= self.threshold:
            action = Action.D
        else:
            if history.my_actions[-1]:
                if cooperation_count < self.threshold:
                    self.p_t -= 0.05
            elif cooperation_count >= self.threshold:
                self.p_t += 0.05
            action = Action(int(self.p_t * (self.game_description.n_players - 1) >= self.threshold))
        if action == Action.C:
            self.cooperators += 1
            self.payoff += 1 - action.value + self.game_description.k * (self.threshold ** state.round_number if self.cooperators >= self.game_description.m else 0)
        return action

class Strategy_COLLECTIVE_248(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATfT) for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_cooperation_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None or state.round_number == 0:
            return Action.C
        cooperation_count = sum(history.opponent_actions[state.round_number - 1])
        self.last_cooperation_count += int(cooperation_count >= self.game_description.m)
        action = Action.C if self.last_cooperation_count >= self.game_description.m else Action.D
        if state.round_number == self.game_description.n_rounds and self.last_cooperation_count >= self.game_description.m:
            action = Action.C
        return action

class Strategy_COLLECTIVE_249(BaseStrategy):
    """
    A strategy that follows Tit-for-Tat with Adaptation (TfTA).
    This strategy cooperates initially, then adopts a tit-for-tat approach and includes an adaptation mechanism.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.forgiveness_window = int(math.ceil(self.n_players / 2))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_cooperators = sum(history.opponent_actions[state.round_number - 1, :]) if history is not None else 0
        if opponent_cooperators >= self.m and state.round_number > self.forgiveness_window:
            return Action.C
        elif opponent_cooperators < self.m and state.round_number <= self.forgiveness_window:
            return Action.C
        else:
            if history is not None and len(history.opponent_actions) > self.forgiveness_window + 1:
                self.forgiveness_window += 1 if history.opponent_actions[-self.forgiveness_window - 1, 0] == Action.D else 0
            return Action.D

class Strategy_COLLECTIVE_251(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation (TFTA) Strategy for the Collective Risk Dilemma Game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.average_cooperation_history = np.zeros(game_description.n_rounds - 1)
        self.threshold = min(self.game_description.n_players, 4)

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        past_actions = history.opponent_actions[:state.round_number] if history else None
        decision = self.tfta_decision(past_actions, self.m)
        edge_case = self.handle_edge_cases(state, history)
        return edge_case if state.round_number == self.game_description.n_rounds else decision

    def tfta_decision(self, past_actions, m):
        frequent_cooperators = self.find_top_m_cooperators(past_actions)
        cooperation_threshold = min(len(frequent_cooperators), m)
        cooperation_count = np.sum([action == Action.C for player in frequent_cooperators[:cooperation_threshold]])
        average_cooperation = cooperation_count / cooperation_threshold
        return Action.C if cooperation_count >= m else Action.C if average_cooperation > 0.5 else Action.D

    def handle_edge_cases(self, state, history):
        if state.round_number == self.game_description.n_rounds:
            frequent_cooperators = self.find_top_m_cooperators(history.opponent_actions[-2:])
            cooperation_threshold = min(len(frequent_cooperators), m)
            cooperation_count = np.sum([action == Action.C for player in frequent_cooperators[:cooperation_threshold]])
            average_cooperation = cooperation_count / cooperation_threshold
            return Action.C if cooperation_count >= m else Action.C if average_cooperation > 0.5 else random.choice([Action.C, Action.D])
        return self.tfta_decision(history.opponent_actions[:state.round_number], self.m)

    def find_top_m_cooperators(self, actions):
        cooperators = np.argwhere(actions == Action.C).reshape(-1)
        if len(cooperators) < self.threshold:
            return []
        return cooperators[:self.threshold]

class Strategy_COLLECTIVE_252(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_round_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        self.last_round_cooperators = sum(history.opponent_actions[-1])
        if all([h for h in history.opponent_actions[:, -1] if h]):
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_253(BaseStrategy):
    """
    Implementation of the Tit-for-Tat-Adaptive (TfTA) strategy in Collective Risk Dilemma games.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_opponent_action = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None or len(history.opponent_actions) == 0:
            self.last_opponent_action = None
        else:
            self.last_opponent_action = history.opponent_actions[-1, 0]
        return Action.C if self.last_opponent_action else Action.D

class Strategy_COLLECTIVE_257(BaseStrategy):
    """
    Implementation of the Adaptive Tit-for-Tat (ATFT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_coopers = game_description.m
        self.k_factor = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_opponent_cooperated = False
        min_cooperators_in_prev_round = self.min_coopers
        if history:
            last_round = len(history.opponent_actions) - 1
            min_cooperators_in_prev_round = sum(history.opponent_actions[last_round, :])
            last_opponent_cooperated = history.opponent_actions[last_round, 0]
        if min_cooperators_in_prev_round < self.min_coopers:
            if last_opponent_cooperated:
                return Action.C
            else:
                return Action.D
        elif last_opponent_cooperated:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_258(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-1] if history else np.zeros(self.game_description.n_players, dtype=bool))
        if cooperators < self.m:
            return Action.D
        return Action.C

class Strategy_COLLECTIVE_259(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_history = min(len(str(self.game_description.n_players)), 5)
        self.act = np.zeros(self.n_history)

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if history is not None and state.round_number != 0:
            cooperators = sum(history.opponent_actions[-1])
            self.act = np.roll(self.act, -1)
            self.act[-1] = cooperators
        if state.round_number == 0:
            return Action.C
        m_t = sum(history.opponent_actions[-1])
        act_avg = np.mean(self.act)
        if m_t >= self.game_description.m and act_avg >= self.game_description.m:
            return Action.C
        elif m_t < self.game_description.m and act_avg < self.game_description.m:
            return Action.D
        elif m_t >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_262(BaseStrategy):
    """
    Strategy that cooperates initially and mimics the majority's actions in subsequent rounds, encouraging reciprocity.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and (not history):
            return Action.C
        my_action = Action.C if history else Action.D
        cooperation_count = np.sum(history.opponent_actions[-1, :]) if history else 0
        if cooperation_count >= self.m:
            self.history.append(my_action)
            return my_action
        elif my_action == Action.C and cooperation_count < self.n_players - self.n_players % self.m:
            return Action.D
        else:
            return Action.D
        if state.round_number >= self.game_description.n_rounds - 1:
            if my_action == Action.C and cooperation_count < self.m:
                return Action.D
            else:
                return Action.C

class Strategy_COLLECTIVE_263(BaseStrategy):
    """
    A Tit-for-Tat Adaptive (TFT-A) strategy that cooperates initially and reciprocates opponents' actions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.initial_cooperative_rounds = math.ceil(game_description.m * 0.5)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if not history:
            return Action.C
        opp_actions = history.opponent_actions[-1]
        cooperators = sum(opp_actions)
        if state.round_number <= self.initial_cooperative_rounds:
            return Action.C
        elif cooperators >= self.game_description.m and state.round_number > self.initial_cooperative_rounds:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_264(BaseStrategy):
    """
    Tit-for-Tat Adaptive Strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.threshold = math.ceil((self.n + 1) * (self.m - 1) / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C if self.n < self.threshold else Action.D
        cooperators = sum(history.opponent_actions[-1])
        if cooperators >= self.m:
            return Action.C
        elif cooperators > self.threshold:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_266(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) strategy for the Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players - 1), dtype=bool), np.zeros(game_description.n_rounds))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None and state.round_number == 0:
            return Action.C
        elif history is not None:
            if state.round_number < len(history.my_actions):
                self.history = history
            cooperators = sum(self.history.opponent_actions[-1, :])
            if cooperators >= self.game_description.m - 1:
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_267(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation (TFT-AC) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.round_number = 0
        self.num_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        self.round_number = state.round_number
        if history is None or self.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        my_action = Action.C if cooperators >= self.n_players // 2 else Action.D
        if self.round_number == state.round_number - 1:
            self.num_cooperators += int(my_action == Action.C)
            reward_threshold = math.ceil(self.m * self.game_description.k)
            cooperators_threshold = min(self.num_cooperators, self.n_players)
            if cooperators_threshold >= reward_threshold:
                return Action.C
        return my_action

class Strategy_COLLECTIVE_269(BaseStrategy):
    """
    A Tit-for-Tat Adaptive Cooperative Strategy that promotes cooperation by starting cooperatively and mirroring the opponent's actions in the hopes that they will reciprocate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_round_opponent_action = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            self.last_round_opponent_action = None
            return Action.C
        if state.round_number == self.game_description.n_rounds:
            self.last_round_opponent_action = None
            return Action.D
        self.last_round_opponent_action = history.opponent_actions[-1][-1]
        if self.last_round_opponent_action == Action.C:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_271(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.minimum_cooperators = game_description.m
        self.last_round = game_description.n_rounds - 1
        self.current_round = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        self.current_round = state.round_number
        if not history or state.round_number == 0:
            return Action.C
        last_history = history.opponent_actions[-1]
        num_cooperators = sum(last_history)
        if num_cooperators >= self.minimum_cooperators:
            response = Action.C
        elif num_cooperators < self.minimum_cooperators - 1:
            response = Action.D
        elif self.current_round == self.last_round or last_history[-1] == Action.C:
            response = Action.C
        else:
            response = Action.D
        return response

class Strategy_COLLECTIVE_273(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Threshold (TFTA) strategy for the Collective Risk Dilemma game.
    Encourages cooperation when it benefits the majority and punishes defection, while allowing for forgiveness as a gesture of goodwill.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.p = 0.5
        self.min_coop_in_last_half = math.ceil(game_description.n_players / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1 if history is not None else 0
        previous_state = history.opponent_actions[previous_round] if history is not None else np.zeros(self.game_description.n_players, dtype=bool)
        cooperators = sum(previous_state)
        if cooperators >= self.game_description.m:
            return Action.C
        elif cooperators > 0 and cooperators / len(previous_state) > self.p or self.game_description.n_players - cooperators < self.min_coop_in_last_half:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_274(BaseStrategy):
    """
    Titan Strategy for Collective Risk Dilemma.
    Prioritizes collective interests and adapts over time based on opponent behaviors.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = math.ceil(game_description.m * 0.7)
        self.total_cooperators = 0
        self.total_rewards = 0
        self.opponents_defected = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C if self.game_description.m <= np.count_nonzero(np.array([1 for _ in range(self.game_description.n_players)])) else Action.D
        action = None
        if history is not None:
            cooperators = np.count_nonzero(history.opponent_actions[-1, :])
            self.total_cooperators += cooperators
            self.total_rewards += np.sum(history.my_payoffs)
            if self.threshold < self.game_description.n_players // 2:
                action = Action.C if cooperators >= self.threshold or cooperators >= self.game_description.m else Action.D
                self.threshold += int(math.ceil(self.total_cooperators / (state.round_number + 1) * 0.3))
            else:
                action = Action.C if cooperators >= self.game_description.m else Action.D
        return action

class Strategy_COLLECTIVE_275(BaseStrategy):
    """
    A strategy that mimics Tit-for-Tat with adaptive cooperation based on a minimum cooperation requirement.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.minimum_cooperators = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None or state.round_number == 0:
            return Action.C
        recent_history = history.opponent_actions[-1]
        cooperators = np.sum(recent_history >= 1)
        if cooperators < self.minimum_cooperators:
            return Action.D
        else:
            return Action.C

    def last_round(self, state: GameState) -> bool:
        return state.round_number == self.game_description.n_rounds - 1

class Strategy_COLLECTIVE_276(BaseStrategy):
    """
    Tit-for-Tat Adaptive (TFT-A) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = self.game_description.n_players
        self.m = self.game_description.m
        self.last_round_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and history.my_actions[-1] and (not self.last_round_cooperators >= self.m):
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.m:
            self.last_round_cooperators = max(self.last_round_cooperators, cooperators)
            return Action.C
        self.last_round_cooperators = 0
        return Action.D

class Strategy_COLLECTIVE_277(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = math.floor(game_description.m - 1)
        self.rounds_above_threshold = 0
        self.rounds_below_threshold = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :]) if history is not None else 0
        payoffs = history.my_payoffs if history is not None else np.zeros(self.game_description.n_rounds)
        if cooperators < self.threshold + 1:
            self.rounds_below_threshold += 1
            if self.rounds_below_threshold == 3:
                self.threshold -= 1
                self.rounds_below_threshold = 0
        elif cooperators >= self.threshold - 1:
            self.rounds_above_threshold += 1
            if self.rounds_above_threshold == 3:
                self.threshold += 1
                self.rounds_above_threshold = 0
        if cooperators >= self.threshold:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_279(BaseStrategy):
    """
    A Tit-for-Tat Adaptive (TfTA) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.opponent_history.append(history.opponent_actions[-1]) if history is not None else None
        cooperators = sum(self.opponent_history[-1])
        opponent_cooperated = cooperators >= self.game_description.n_players // 2
        return Action.C if opponent_cooperated and self.opponent_history else Action.D

class Strategy_COLLECTIVE_280(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Cooperative Ramp-Up (ATFTCR) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.ramp_up_rounds = math.ceil(self.game_description.n_rounds / 2)
        self.current_round = 0
        self.history = None

    def __call__(self, state: GameState, history: PlayerHistory):
        self.history = history if self.history is None else history
        self.current_round = state.round_number
        if self.current_round == 0 or (self.current_round > self.ramp_up_rounds and self.min_cooperators(self.history) < self.game_description.m):
            return Action.D
        if self.current_round <= self.ramp_up_rounds or self.min_cooperators(self.history) >= self.game_description.m:
            return Action.C
        if self.current_round == self.game_description.n_rounds - 1:
            return Action.C
        if self.min_cooperators(self.history) == 0 and self.current_round > self.ramp_up_rounds:
            return Action.D

    def min_cooperators(self, history):
        return int(np.sum(history.my_actions))

class Strategy_COLLECTIVE_281(BaseStrategy):
    """
    Tit-for-Tat (with modification) for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros(game_description.n_rounds))

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            self.history.my_actions[0] = True
            return Action.C
        elif state.round_number < len(history.my_payoffs):
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators < self.game_description.m and history.my_actions[-1] == False:
                self.history.my_actions[state.round_number] = True
                return Action.C
            elif cooperators >= self.game_description.m:
                self.history.my_actions[state.round_number] = history.opponent_actions[-1, self.__class__.__len__([0]) - 1]
                return self.history.opponent_actions[-1, self.__class__.__len__([0]) - 1]
        else:
            self.history.my_actions[state.round_number] = True
            return Action.C

class Strategy_COLLECTIVE_282(BaseStrategy):
    """
    A strategy based on the Adaptive Tit-for-Tat approach for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.threshold = self.n_players // (2 * self.m - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None:
            return Action.D
        recent_opponents = history.opponent_actions[-1]
        cooperators = np.sum(recent_opponents)
        num_defectors = self.n_players - cooperators
        if cooperators >= self.m and num_defectors < self.threshold:
            return Action.C
        elif num_defectors >= self.threshold:
            return Action.D
        my_action = history.my_actions[-1]
        opponent_action = recent_opponents[self.__class__.__name__.lower().replace(' ', '_')]
        if my_action == opponent_action:
            return my_action
        if opponent_action == Action.D and num_defectors >= self.threshold:
            return Action.D
        return Action.C

class Strategy_COLLECTIVE_283(BaseStrategy):
    """
    Titan Strategy for Collective Risk Dilemma (TRD) using Cooperate-Reciprocate-Gradient (CRG) approach.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.n_players // 2
        self.t = self.game_description.m / self.game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C if np.sum(np.array([1 for _ in range(self.threshold + 1)]).reshape(-1)) > random.randint(1, self.game_description.n_players) else Action.D
        cooperator_count = np.sum(history.my_actions[-1])
        if cooperator_count / self.game_description.n_players >= self.t:
            return Action.C
        if history.my_actions[-1] and np.sum(np.where(history.opponent_actions[-1, :] == True, self.game_description.n_players - 1, 0).reshape(-1) > self.game_description.n_players - self.game_description.m + 1):
            return Action.C
        action_rewards = np.array([np.sum(history.my_payoffs[:state.round_number]) for action in [Action.C, Action.D]])
        return Action.C if action_rewards[0] >= action_rewards[1] else Action.D

class Strategy_COLLECTIVE_284(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation (TFT-AC)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = []
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = len(self.history) - 1 if history else state.round_number
        cooperators = np.sum(history.opponent_actions[current_round, :]) if history else 0
        if current_round == self.game_description.n_rounds - 1:
            return Action.C
        if current_round == 0:
            return Action.C
        elif self.consecutive_defections >= 3 and history is not None:
            self.consecutive_defections = 0
            return Action.C
        elif cooperators < self.game_description.m:
            if current_round > 3 and history is not None and (self.history[-1] == Action.D):
                self.consecutive_defections += 1
            else:
                self.consecutive_defections = 0
            return Action.D
        else:
            if current_round > 3 and history is not None and (self.history[-1] == Action.C):
                self.consecutive_defections = 0
            else:
                self.consecutive_defections = 0
            return Action.C
        self.history.append(Action.D if history is not None else None)

class Strategy_COLLECTIVE_285(BaseStrategy):
    """
    Implementation of the Tit-for-Tat strategy in Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperative_threshold = game_description.m
        self.previous_round_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is not None:
            self.previous_round_cooperators = sum(history.opponent_actions[-1])
        if state.round_number == 0:
            return Action.C
        elif self.previous_round_cooperators >= self.game_description.m:
            return Action.C
        else:
            return Action.D

    def update_threshold(self, cooperators: int):
        if cooperators < self.game_description.m:
            adjustment = (self.game_description.k - 1) / self.game_description.n_players
            self.cooperative_threshold += adjustment
        else:
            self.cooperative_threshold -= 1

class Strategy_COLLECTIVE_286(BaseStrategy):
    """
    Strategy name: Adaptive Tit-for-Tat with Risk-Aversion (ATfT-RA)
    Strategy summary: Promotes cooperation by reciprocating it but also includes a risk-aversion element to protect itself from repeated defections and maximize rewards when possible.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperators_prev_round = np.zeros(game_description.n_players)
        self.c_i_prev = np.zeros(game_description.n_players, dtype=bool)

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if state.round_number == 0 or history is None:
            self.c_i_prev[:] = np.full(self.game_description.n_players, False)
            self.cooperators_prev_round[:] = 0
            return Action.C
        round = state.round_number - 1
        self.cooperators_prev_round = history.my_actions[round]
        self.c_i_prev[:] = history.my_actions[round].astype(bool)
        cooperators = np.sum(history.opponent_actions[round, :])
        if self.c_i_prev[-1] and cooperators >= self.game_description.m or round == self.game_description.n_rounds - 1:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_287(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat Adaptive Cooperation (TTAC)
    Strategy Description: A strategy that cooperates initially and copies the most frequent action of the last 'w' rounds from all players.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history_window = math.ceil(game_description.n_players * 0.15)

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        last_w_actions = history.my_actions[-self.history_window:]
        majority_action = np.mean(last_w_actions)
        if np.greater_equal(np.count_nonzero(last_w_actions - majority_action), len(last_w_actions) // 2):
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_290(BaseStrategy):
    """
    Tit-for-Tat Adaptive Cooperation (TFTAC) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.current_round = 0
        self.cooperative_streak = 0
        self.defecting_streak = 0
        self.last_cooperation = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.current_round = state.round_number
        if history is not None:
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators >= self.game_description.m and self.cooperative_streak > 0:
                return Action.C
            elif cooperators < self.game_description.m - 1:
                return Action.D
            elif history.my_actions[-1] == Action.C:
                self.cooperative_streak += 1
                if self.last_cooperation is not None and self.last_cooperation + 1 < self.current_round:
                    self.defecting_streak = min(self.defecting_streak, self.current_round - self.last_cooperation)
            elif self.defecting_streak > 0 and self.cooperative_streak == 0:
                self.last_cooperation = self.current_round - self.defecting_streak + 1
                self.cooperative_streak += 1
        return Action.C if self.cooperative_streak > 0 else Action.D

class Strategy_COLLECTIVE_291(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TTAT-CT)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.p = int(math.ceil(game_description.n_players / 2))
        self.epsilon = 0.1
        self.average_cooperation_ratio = 0.0
        self.cooperate_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and state.round_number - self.p >= 1:
            self.average_cooperation_ratio = (self.average_cooperation_ratio * (self.p - 1) + self.cooperate_count / self.p) / state.round_number
            if self.average_cooperation_ratio >= self.adaptive_threshold():
                return Action.C
            elif self.average_cooperation_ratio <= self.adaptive_threshold() - self.epsilon:
                return Action.D
            else:
                return np.random.choice([Action.C, Action.D], p=[self.epsilon, 1 - self.epsilon])
        else:
            return np.random.choice([Action.C, Action.D], p=[self.epsilon, 1 - self.epsilon])

    def adaptive_threshold(self) -> float:
        numerator = self.game_description.m
        denominator = math.ceil((self.game_description.m + (self.game_description.n_players - self.game_description.m)) / self.p)
        if denominator == 0:
            return float('inf')
        return numerator / denominator

class Strategy_COLLECTIVE_292(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATFT) for Collective Risk Dilemma

    The strategy emphasizes mutual cooperation when beneficial for the group while retaliating against individual defection. It promotes a long-term collective interest by rewarding consistent cooperation and punishing defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and len(np.where(history.opponent_actions[-1])[0]) >= self.min_cooperators):
            return Action.C
        for player in range(self.game_description.n_players):
            if history is not None and history.opponent_actions[-1, player] == 0:
                return Action.D
        return Action.C

class Strategy_COLLECTIVE_294(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Risk Aversion (ATfTA-RA) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.threshold_reached = False
        self.punishment_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            self.threshold_reached = False
            self.punishment_counter = 0
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators < self.m:
            self.punishment_counter += 1
            if self.punishment_counter >= self.game_description.n_players - self.m:
                self.threshold_reached = False
            return Action.D
        elif cooperators == self.m:
            if not self.threshold_reached:
                self.punishment_counter = 0
                self.threshold_reached = True
            return Action.C
        else:
            if self.threshold_reached:
                self.threshold_reached = False
            return Action.D

class Strategy_COLLECTIVE_295(BaseStrategy):
    """
    A Tit-for-Tat with Adaptive Cooperation Threshold strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m
        self.p_init = random.uniform(0, 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C if self.p_init > random.random() else Action.D
        if history is None or len(history.my_actions) < self.game_description.n_rounds - 1:
            return Action.D
        previous_cooperators = sum(history.my_actions[-2:])
        return Action.C if previous_cooperators >= self.m - 1 else Action.D

class Strategy_COLLECTIVE_296(BaseStrategy):
    """
    Tit-for-Tat-Adaptive (TfTA) Strategy for Collective Risk Dilemma Game
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.d = 0.5
        self.history = PlayerHistory(np.zeros((self.n_rounds,), dtype=bool), np.zeros((self.n_rounds,)), np.zeros((self.n_rounds + 1, self.n_players), dtype=bool), np.zeros((self.n_rounds + 1, self.n_players)))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        self.history = history
        round_number = state.round_number
        my_action = self.history.my_actions[round_number - 1]
        opponent_cooperators = sum(self.history.opponent_actions[-1, :])
        if round_number == self.n_rounds:
            return Action.C
        if my_action and opponent_cooperators >= self.m:
            reward = 1 - self.history.my_payoffs[round_number - 1] + self.k
            if round_number > self.d * self.n_rounds:
                if opponent_cooperators < self.m - 1:
                    return Action.D
        elif round_number > self.d * self.n_rounds:
            if opponent_cooperators >= self.m - 1:
                return Action.C
        return Action(1 if my_action else 0)

class Strategy_COLLECTIVE_297(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat Adaptive Cooperation (TFT-A)
    This strategy cooperates initially and mimics the opponent's action from the previous round.
    If an opponent has previously defected but then starts cooperating again, TFT-A will also switch to cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_defection_round = -1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_action = history.opponent_actions[state.round_number - 1, :] if history else np.zeros(self.game_description.n_players)
        action = Action.C if opponent_action.sum() > self.game_description.m - 1 else Action.D
        self.last_defection_round = state.round_number if action == Action.D and opponent_action.sum() < self.game_description.m - 1 else self.last_defection_round
        return action

class Strategy_COLLECTIVE_299(BaseStrategy):
    """
    Implementation of Tit-for-Tat-Adaptive (TfTA) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(self.game_description.n_rounds, dtype=bool), np.zeros(self.game_description.n_rounds), np.zeros((self.game_description.n_rounds, self.game_description.n_players), dtype=bool), np.zeros((self.game_description.n_rounds, self.game_description.n_players)))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is not None and state.round_number > 0 and (len(history.my_actions) > 0):
            last_action = history.my_actions[-1]
        else:
            last_action = False
        if state.round_number == 0 or (state.round_number > 0 and history.opponent_actions[-1, -1] != last_action):
            action = Action.D
        else:
            action = Action.C
        self.history.my_actions[-1] = action == Action.C
        if action == Action.C:
            self.history.my_payoffs[-1] = 0 if len(history.opponent_actions[-1]) < self.game_description.m else 0 + self.game_description.k
        else:
            self.history.my_payoffs[-1] = 1
        self.history.opponent_actions[-1, -1] = last_action
        if len(self.history.opponent_actions) < state.round_number + 1:
            self.history.opponent_payoffs[state.round_number, -1] = 1 + 0 if last_action else 1 + self.game_description.k
        elif last_action:
            self.history.opponent_payoffs[state.round_number, -1] = 1 + 0
        else:
            self.history.opponent_payoffs[state.round_number, -1] = 1 + self.game_description.k
        return action

class Strategy_COLLECTIVE_300(BaseStrategy):
    """
    The Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma games.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_coop = min(game_description.n_players - 1, game_description.m)
        self.round_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.min_coop:
            return Action.C
        elif state.round_number == len(self.round_history) + 1:
            return Action.D
        else:
            self.min_coop += (state.round_number - len(self.round_history) - 1) % 2 + 1
            self.round_history.append(state.round_number)
            return Action.D

class Strategy_COLLECTIVE_302(BaseStrategy):
    """
    Implements the Adaptive Tit-for-Tat strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(self.game_description.n_rounds, dtype=bool), np.zeros(self.game_description.n_rounds), np.zeros((self.game_description.n_rounds, self.game_description.n_players), dtype=bool), np.zeros(self.game_description.n_rounds))
        self.cooperation_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if state.round_number == 0:
            return Action.D
        if history is None:
            history = PlayerHistory(np.zeros(self.game_description.n_rounds, dtype=bool), np.zeros(self.game_description.n_rounds), np.zeros((self.game_description.n_rounds, self.game_description.n_players), dtype=bool), np.zeros(self.game_description.n_rounds))
        self.history = history
        if state.round_number == 1:
            cooperators = sum(self.history.opponent_actions[-1, :])
            if cooperators >= self.game_description.m:
                self.cooperation_count += 1
            else:
                self.cooperation_count = 0
        current_cooperation = sum(self.history.opponent_actions[-1, :])
        if current_cooperation >= self.game_description.m:
            action = Action.C
            self.cooperation_count += 1
        elif self.cooperation_count > 0 and self.cooperation_count < self.game_description.n_players:
            action = Action.C
            self.cooperation_count -= 1
        else:
            action = Action.D
            self.cooperation_count = 0
        self.history.my_actions[state.round_number - 1] = action == Action.C
        self.history.opponent_actions[state.round_number - 1, :] = history.opponent_actions[-1, :] if state.round_number > 1 else None
        return action

class Strategy_COLLECTIVE_303(BaseStrategy):
    """
    The Tit-for-Tat Adaptive Strategy (TFTA) for Collective Risk Dilemma.
    Balances cooperation and defection while encouraging reciprocity with opponents.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_cooperated = [False]
        self.strategy_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        strategy_history = self.strategy_history if len(self.strategy_history) > 0 else [Action.C]
        opponent_cooperated = self.opponent_cooperated[-len(strategy_history):]
        opponent_actions = history.opponent_actions if history is not None else np.zeros((1, state.round_number))
        cooperators = sum(opponent_actions[-1, :])
        if cooperators >= self.game_description.m:
            if len(strategy_history) > 0 and strategy_history[-1] == Action.D:
                self.opponent_cooperated[-1] = False
                return Action.C
            elif len(strategy_history) == 0 or strategy_history[-1] == Action.C:
                self.opponent_cooperated[-1] = True
                return Action.C
        elif len(strategy_history) > 0 and strategy_history[-1] == Action.C:
            self.opponent_cooperated[-1] = False
            return Action.D
        if strategy_history[-1] == Action.C and history.opponent_actions[state.round_number - 1, 0] == Action.D:
            self.payoff -= self.game_description.k
        elif strategy_history[-1] == Action.D and history.opponent_actions[state.round_number - 1, 0] == Action.C:
            self.payoff += self.game_description.k
        self.strategy_history.append(strategy_history[-1])
        return strategy_history[-1]

class Strategy_COLLECTIVE_304(BaseStrategy):
    """
    Strategy: Tit-for-Tat with Adaptive Cooperation (TFT-AC)
    Strategy description: https://www.gameoflife.xyz/strategy-tft-ac/
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros((game_description.n_rounds, game_description.n_players)))
        self.h = 5
        self.p = (1 - game_description.k) / self.h
        self.player_index = 0

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if history is not None:
            self.history = history
        if state.round_number == 0:
            return Action.C
        else:
            m_avg = np.mean(self.history.my_actions[-self.h:])
            action = Action.C if m_avg >= self.game_description.m else Action.D
            if state.round_number == self.game_description.n_rounds or (action == Action.D and self.history.my_actions[state.round_number - 1] == True):
                m_avg = np.mean(self.history.my_actions[-self.h:])
                if m_avg >= self.game_description.m:
                    action = Action.C
            self.player_index = (self.player_index + 1) % self.game_description.n_players
            return action

class Strategy_COLLECTIVE_305(BaseStrategy):
    """
    Adaptive Cooperative Tit-for-Tat (ACTFT) Strategy in Collective Risk Dilemma Game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.total_cooperation = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        action = Action.C if state.round_number == 0 else Action.D
        if history is not None and state.round_number > 0:
            self.total_cooperation += np.sum(history.my_actions[-1])
            cooperation_in_last_round = np.sum(history.opponent_actions[-1, :])
            if cooperation_in_last_round < self.game_description.m:
                action = Action.D
            elif state.round_number == self.game_description.n_rounds and self.total_cooperation < self.game_description.m * self.game_description.n_rounds:
                action = Action.D
            elif state.round_number < self.game_description.n_rounds and cooperation_in_last_round >= self.game_description.m:
                action = Action.C
        return action

class Strategy_COLLECTIVE_306(BaseStrategy):
    """
    Strategy name: Tit-for-Tat with Adaptive Threshold (TFT-AT)
    Strategy summary: Cooperates in the first round, subsequently cooperates if at least m players cooperated in the previous round, and defects otherwise.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m
        self.n_players = self.game_description.n_players

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[state.round_number - 1])
        return Action.C if cooperators >= self.m else Action.D

class Strategy_COLLECTIVE_309(BaseStrategy):
    """
    The Tit-for-Tat-Adaptive (TfTA) strategy mimics an initial cooperative strategy while retaliating against defection to encourage future cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = math.ceil(game_description.n_players * game_description.m / 100)
        self.last_round_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and history.opponent_actions is not None:
            self.last_round_cooperators = sum(history.opponent_actions[-1])
            cooperators = max(self.min_cooperators, self.last_round_cooperators) if state.round_number > 1 else self.min_cooperators
            if cooperators <= self.last_round_cooperators:
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_310(BaseStrategy):
    """
    Tit-for-Tat Adaptive (TFT-A) for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.m
        self.n_players = game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-1], axis=0)
        m_prime = np.count_nonzero(cooperators >= self.threshold)
        my_action = Action.C if m_prime >= self.threshold else Action.D
        return my_action

class Strategy_COLLECTIVE_311(BaseStrategy):
    """
    A Tit-for-Tat Adaptive (TFT-A) strategy that cooperates initially and reciprocates cooperation or defection in subsequent rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_opponent_action = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_actions = history.opponent_actions if history else np.zeros((state.round_number + 1, self.game_description.n_players), dtype=bool)
        last_opponent_action = opponent_actions[-1, self.get_opponent()] if state.round_number > 0 else None
        self.last_opponent_action = last_opponent_action
        return Action(int(self.last_opponent_action == Action.C)) if last_opponent_action is not None else Action.C

    def get_opponent(self) -> int:
        """
        Returns the index of the opponent player in the game (assuming this strategy is used by only one player).
        """
        return 1 if self.__class__ == self.game_description.n_players - 1 else 0

class Strategy_COLLECTIVE_312(BaseStrategy):
    """
    Adaptive Tit-for-Tat Strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.maintainers = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1 and self.maintainers < self.game_description.m:
            return Action.D
        cooperators = sum(history.opponent_actions[state.round_number - 1, :])
        if cooperators >= self.game_description.m:
            self.maintainers += 1
            return Action.C
        else:
            self.maintainers = max(0, self.maintainers - 1)
            return Action.D

class Strategy_COLLECTIVE_313(BaseStrategy):
    """
    A Tit-for-Tat strategy with adaptive cooperation threshold for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self._history = [{'cooperators': 0, 'majority_cooperated': False} for _ in range(game_description.n_rounds + 1)]

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum([h['cooperators'] for h in self._history[1:]])
        majority_cooperated = math.ceil(cooperators / self.game_description.n_players) >= 0.5
        if history is None:
            self._history[state.round_number] = {'cooperators': self.game_description.n_players - len([h['majority_cooperated'] for h in self._history[-2::-1]]) > 0, 'majority_cooperated': majority_cooperated}
            return Action(majority_cooperated)
        else:
            self._history[state.round_number] = {'cooperators': history.my_actions[-1].sum(), 'majority_cooperated': majority_cooperated}
            return Action(history.my_actions[-1].sum() > self.game_description.n_players // 2)

class Strategy_COLLECTIVE_314(BaseStrategy):
    """
    The TFT-AC strategy encourages cooperation at the start of the game and gradually builds trust with opponents based on their previous actions.
    By responding similarly to how opponents acted in the previous round, it exhibits a sense of fairness and reciprocity.
    The adaptive component allows for flexibility in cooperation levels depending on the number of cooperators needed and the specific game conditions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.round = 0
        self.counter = 0
        self.strategy = [Action.D] * self.game_description.n_rounds

    def cooperate_probability(self, round_number, counter):
        return min(max(counter / (round_number + 1), 0), 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        self.round = state.round_number
        if self.round == 0 and history is None:
            return Action.C
        if history is None:
            return self.strategy[-1]
        opponent_cooperated = int(history.opponent_actions[self.round - 1, 0])
        self.counter += 1 if opponent_cooperated else self.counter - 1 if self.counter > 0 else self.counter
        strategy = self.strategy[-1]
        cooperate_probability = self.cooperate_probability(self.round, self.counter)
        if opponent_cooperated and cooperate_probability > 0.5:
            strategy = Action.C
        elif not opponent_cooperated and 1 - cooperate_probability > 0.5:
            strategy = Action.D
        self.strategy.append(strategy)
        return strategy

class Strategy_COLLECTIVE_316(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation (TFT-AC) Strategy for Collective Risk Dilemma Game
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.total_cooperation = 0
        self.cooperation_in_last_round = False
        self.c_history = np.zeros(game_description.n_players, dtype=bool)

    def __call__(self, state: GameState, history: PlayerHistory):
        action = Action.D
        if history is None or state.round_number == 0:
            self.c_history.fill(False)
            action = Action.C
            self.total_cooperation += 1
        else:
            round_num = state.round_number - 1
            if len(self.c_history) <= round_num:
                self.c_history = np.roll(self.c_history, -1)
            cooperators = np.sum(history.opponent_actions[round_num, :])
            if cooperators >= self.game_description.n_players // self.game_description.m:
                action = Action.C
                self.total_cooperation += 1
        if state.round_number == self.game_description.n_rounds and self.total_cooperation < self.game_description.n_players * self.game_description.m // self.game_description.n_players:
            self.cooperation_in_last_round = False
        else:
            self.cooperation_in_last_round = True
        self.c_history[-1] = action == Action.C
        return action

class Strategy_COLLECTIVE_317(BaseStrategy):
    """
    The Adaptive Tit-for-Tat (ATFT) strategy for the Collective Risk Dilemma game.
    This strategy cooperates initially and then mimics the average cooperative behavior of opponents in previous rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.total_cooperators = 0
        self.total_opponents = 0
        self.rounds_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            self.total_cooperators += np.sum(history.my_actions)
            self.total_opponents += len(history.opponent_payoffs)
            self.rounds_count += 1
        cooperation_average = self.total_cooperators / (self.rounds_count * self.game_description.n_players) if self.rounds_count > 0 else 1
        return Action.C if cooperation_average >= (self.game_description.n_players - self.game_description.m) / self.game_description.n_players else Action.D

class Strategy_COLLECTIVE_319(BaseStrategy):
    """
    A Tit-for-Tat with Adaptive Cooperative Threshold (TT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history_window = 1
        self.defection_threshold = 1
        self.current_round = 0

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        self.current_round = state.round_number
        if self.current_round == 0:
            return Action.C
        cooperation_history = np.full(self.cooperation_history_window, False)
        defection_count = 0
        for i in range(min(len(history.my_actions), self.cooperation_history_window)):
            if history.my_actions[i] == Action.C:
                cooperation_history[i] = True
            else:
                defection_count += 1
        if len(cooperation_history) < self.cooperation_history_window + self.defection_threshold:
            cooperation_history = np.concatenate((cooperation_history, np.zeros(self.cooperation_history_window + self.defection_threshold - len(cooperation_history))))
        if sum(cooperation_history[-self.cooperation_history_window:]) < self.game_description.m:
            if defection_count >= self.defection_threshold or self.current_round == self.game_description.n_rounds:
                self.defection_threshold += 1
                self.cooperation_history_window *= 2
                return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_320(BaseStrategy):
    """
    Tit-for-Tat with Adaptation (TfT-A) strategy.
    Cooperates on first move and mimics majority behavior of previous round.
    Includes a probability threshold for deviations when the majority cooperated or defected in the last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.p = 0.2
        self.q = 0.2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        majority_cooperated = cooperators >= self.game_description.n_players // 2
        if majority_cooperated:
            action = random.choice([Action.C, Action.D])
            if np.random.rand() < self.p:
                action = Action.C
            else:
                action = Action.D
        else:
            action = random.choice([Action.C, Action.D])
            if np.random.rand() < self.q:
                action = Action.D
            else:
                action = Action.C
        return action

class Strategy_COLLECTIVE_321(BaseStrategy):
    """
    Implementation of Adaptive Tit-for-Tat strategy in Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if not history:
            return Action.C
        if state.round_number == history.my_actions.size - 1:
            cooperators = sum(history.opponent_actions[:, self.__class__].flatten())
            if cooperators >= self.game_description.n_players * (self.m / self.game_description.n_players):
                return Action.C
        else:
            cooperators = history.opponent_actions[state.round_number - 1, :].sum()
            if cooperators < self.m:
                return Action.D
        return Action.C

class Strategy_COLLECTIVE_322(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation (TFT-AC) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = self.game_description.n_players
        self.n_rounds = self.game_description.n_rounds
        self.m = self.game_description.m
        self.k = self.game_description.k
        self.N = math.ceil(self.n_rounds / 10)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_actions = np.array([history.my_actions[0] if history else [False]]) if history else None
        opponent_actions = history.opponent_actions if history else np.zeros((self.n_rounds, self.n_players), dtype=bool)
        average_cooperators = np.mean(opponent_actions[:, -self.N:].sum(axis=1))
        probability_to_cooperate = math.floor(self.m + (average_cooperators - self.m) * (self.n_players - 1) / (self.n_players - self.m)) / self.n_players
        if state.round_number == self.n_rounds - 1:
            probability_to_cooperate = max(min(probability_to_cooperate, 1), 0)
        cooperate_probability = random.uniform(0, 1)
        return Action.C if cooperate_probability <= probability_to_cooperate else Action.D

class Strategy_COLLECTIVE_323(BaseStrategy):
    """
    Adaptive Tit-for-Tat Strategy for the Collective Risk Dilemma.
    A simple strategy that demonstrates goodwill and fosters trust,
    reciprocating cooperation while punishing defection, and forgiving past errors.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(my_actions=np.empty((1,), dtype=bool), my_payoffs=np.empty((1,)), opponent_actions=np.zeros((1, game_description.n_players), dtype=bool), opponent_payoffs=np.zeros((1, game_description.n_players)))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        elif state.round_number == 0 and history:
            self.history = history
            return Action.C
        my_action = self.history.my_actions[-1]
        opponent_cooperators = sum(self.history.opponent_actions[-1, :])
        if opponent_cooperators >= self.game_description.n_players // 2:
            return Action.C
        elif my_action and opponent_cooperators < self.game_description.n_players // 2:
            self.history.my_payoffs[-1] = 1 - self.history.my_actions[0]
        return Action.D

class Strategy_COLLECTIVE_324(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TTAT-ACT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.delta = 0.1
        self.patience = 5
        self.act_history = np.zeros(self.game_description.n_rounds)
        self.current_act = self.m
        self.last_cooperators = 0

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if not history or state.round_number == 0:
            return Action.C
        round_number = state.round_number
        cooperators = np.sum(history.opponent_actions[round_number - self.patience:round_number, :])
        if round_number <= self.n_players + self.patience:
            self.last_cooperators = cooperators
            return Action.C
        if round_number == self.game_description.n_rounds:
            if cooperators >= self.last_cooperators and self.current_act >= self.m:
                return Action.C
            else:
                return Action.D
        if round_number - self.patience < self.game_description.n_rounds and round_number > self.n_players + self.patience:
            if cooperators >= self.m:
                self.current_act = self.m
            elif self.current_act <= self.m - 1:
                self.current_act -= self.delta
        if cooperators >= self.current_act:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_325(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation (TFT-AC) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m
        self.n = self.game_description.n_players

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators_prev = sum([1 for action in history.opponent_actions[-1] if action])
        if cooperators_prev >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_326(BaseStrategy):
    """
    A simple adaptation of the Tit-for-Tat strategy for the Collective Risk Dilemma game.
    The strategy cooperates initially and subsequently cooperates if at least half of the players cooperated in the previous round, otherwise defects.
    If a player defects after a history of cooperation, it returns to cooperating in the next round to give the opponent another chance to cooperate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperators_threshold = int(self.game_description.n_players / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        if history is not None and state.round_number > 0:
            cooperators = sum(history.opponent_actions[-1, :])
            return Action(int(cooperators >= self.cooperators_threshold))

class Strategy_COLLECTIVE_327(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n = game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-self.m:].sum(axis=0))
        if cooperators >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_328(BaseStrategy):
    """
    Implementation of the Adaptive Tit-for-Tat (ATFT) strategy for the Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_threshold = int(self.game_description.n_players * 0.75)
        self.last_cooperators = np.zeros(self.game_description.n_players, dtype=int)
        self.punishment_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperation_level = sum(history.opponent_actions[-1, :])
        cooperators = int(np.maximum(cooperation_level - self.punishment_counter, 0))
        self.last_cooperators[:cooperators] = 1
        self.last_cooperators[cooperators:] = 0
        self.punishment_counter = 0 if cooperators >= self.game_description.m else self.punishment_counter + 1
        if state.round_number == self.game_description.n_rounds - 1:
            my_cooperation = int(history.my_actions[-1])
            return Action.C if my_cooperation or cooperators >= self.game_description.m else Action.D
        elif self.punishment_counter == 3 and cooperation_level >= self.game_description.m:
            return Action.D
        return Action(int(self.last_cooperators[-1]))

class Strategy_COLLECTIVE_329(BaseStrategy):
    """
    A strategy that mimics positive behavior while being cautious about potential free-riders. It encourages players to cooperate when others do, and punishes defection moderately through tactical delay.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.tactical_delay = math.ceil(game_description.n_players / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None or state.round_number == 0:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-1])
        if cooperators >= self.game_description.m:
            return Action.C
        else:
            for t in range(1, min(self.tactical_delay + 1, state.round_number)):
                if np.sum(history.opponent_actions[-t - 1]) < self.game_description.m:
                    continue
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_330(BaseStrategy):
    """
    A Tit-for-Tat strategy with adaptive cooperation threshold, designed to encourage mutual cooperation by reciprocating cooperative actions and punishing defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_counter = {}
        self.uncooperative_counter = {}

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or not history:
            return Action.C
        action = Action.D
        player_index = self.__class__.__name__ + str(state.round_number)
        if player_index in self.cooperation_counter:
            cooperation_count, uncooperative_count = (self.cooperation_counter[player_index], self.uncooperative_counter[player_index])
            coopPlayers = sum(history.opponent_actions[-1, :]) if history else 0
            if coopPlayers >= self.game_description.m - 1 and cooperation_count < self.game_description.m:
                action = Action.C
                cooperation_count += 1
            elif uncooperative_count >= 3 and cooperation_count > 0:
                action = Action.D
                cooperation_count -= 1
        if action == Action.C:
            self.cooperation_counter[player_index] = cooperation_count + 1 if player_index in self.cooperation_counter else 1
        elif action == Action.D:
            self.uncooperative_counter[player_index] = uncooperative_count + 1 if player_index in self.uncooperative_counter else 1
        return action

class Strategy_COLLECTIVE_331(BaseStrategy):
    """
    Strategy name: Adaptive Tit-for-Tat (ATfT) for Collective Risk Dilemma
    Strategy description: Initiate with cooperation, respond to opponent's actions, and forgive defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        self.opponent_history += [bool(history.opponent_actions[-1, 0])]
        if len(self.opponent_history) == state.round_number + 1:
            last_round = state.round_number
            if last_round == len(self.opponent_history) - 1 and self.opponent_history[-1]:
                return Action.C
        opponent_action = self.opponent_history[-1]
        if opponent_action:
            return Action.C
        elif state.round_number > 1 and (not opponent_action):
            return Action.D
        return Action.D

class Strategy_COLLECTIVE_332(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation (TFT-AC) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.base_Pc = 1 - self.game_description.m / self.game_description.n_players
        self.slope = (self.base_Pc - 0.3) / 0.2
        self.current_cooperation_rate = 0
        self.total_payoff = 0
        self.last_round = False

    def __call__(self, state: GameState, history: PlayerHistory):
        action = Action.D
        if state.round_number == 0:
            action = Action.C
            self.total_payoff = 0
        elif state.round_number == self.game_description.n_rounds:
            self.last_round = True
        else:
            cooperators = sum(history.opponent_actions[state.round_number - 1, :])
            self.total_payoff += history.my_payoffs[state.round_number - 1]
            if cooperators >= self.game_description.m:
                payoff = history.my_payoffs[state.round_number - 1].mean() + self.game_description.k
            else:
                payoff = history.my_payoffs[state.round_number - 1].mean()
            self.current_cooperation_rate = cooperators / self.game_description.n_players
            if self.current_cooperation_rate < 0.3:
                self.base_Pc *= 1 + self.slope * (1 - self.current_cooperation_rate)
            elif self.current_cooperation_rate > 0.5:
                self.base_Pc = 1 - self.game_description.m / self.game_description.n_players
            if self.total_payoff < self.game_description.n_rounds * (self.game_description.k * 0.7):
                action = Action.D
        if random.random() > self.base_Pc:
            action = Action.C
        return action

class Strategy_COLLECTIVE_333(BaseStrategy):
    """
    A Tit-for-Tat Adaptive (TFT-A) strategy for the Collective Risk Dilemma game.
    Cooperation is encouraged in the initial round and subsequent rounds mimic the majority's action from the previous round.
    If more than the minimum cooperators needed cooperated in the last round, a tit-for-tat approach is employed when k > 2.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_round_cooperators = 0
        self.tit_for_tat_count = 0
        self.tit_for_tat_threshold = math.ceil(self.game_description.m * 3)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :]) if history else 0
        if self.tit_for_tat_count < self.tit_for_tat_threshold and cooperators >= self.game_description.m:
            action = Action.C if self.last_round_cooperators >= self.game_description.m else Action.D
            self.last_round_cooperators = int(action == Action.C)
            self.tit_for_tat_count += 1
        elif cooperators >= self.game_description.n_players // 2:
            action = Action.C
        else:
            action = Action.D
        self.last_round_cooperators = int(action == Action.C)
        return action

class Strategy_COLLECTIVE_334(BaseStrategy):
    """
    A Tit-for-Tat adaptive (TfTA) strategy for the Collective Risk Dilemma (CRD) game.
    This strategy initially cooperates in the first round, then mimics the collective behavior of the last r rounds.
    If more than m players cooperated in the past r rounds, it continues cooperating; otherwise, it defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.r = self.game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if not history and state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-self.r:].sum(axis=0))
        return Action(cooperators >= self.game_description.m)

class Strategy_COLLECTIVE_335(BaseStrategy):
    """
    A-TFT Strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.d_wait = math.floor(game_description.n_rounds / 10)
        self.cooperation_threshold_met = False
        self.first_encounter = True

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        action = Action.D
        if self.first_encounter:
            self.first_encounter = False
            action = Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            self.cooperation_threshold_met = any(history.opponent_actions[-1]) >= self.m
        if (self.cooperation_threshold_met or self.first_encounter) and any(history.opponent_actions[-1]):
            action = Action.C
        if history is not None:
            round_number = state.round_number - 1
            if round_number >= self.d_wait:
                self.d_wait = math.floor((state.round_number + 1) / 10)
        return action

class Strategy_COLLECTIVE_336(BaseStrategy):
    """
    Tit-for-Tat Adaptive (TFT-A) for Collective Risk Dilemma strategy, which cooperates in the first round and adapts based on the previous round's cooperation level from other players.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.majority = game_description.n_players // 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators >= self.majority:
                return Action.C
            return Action.D

class Strategy_COLLECTIVE_338(BaseStrategy):
    """
    Tit-for-Tat Adaptive (TFT-A) strategy for Collective Risk Dilemma.
    Promotes cooperation and stability through reciprocity, maintaining a balance between self-interest and collective interest.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperate_count = 0
        self.opponent_history = {}

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None or len(history.my_actions) < self.game_description.n_rounds:
            return Action.D
        action = Action.D
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.game_description.m and history is not None:
            self.cooperate_count += 1
            action = Action.C
        elif cooperators < self.game_description.m and self.cooperate_count > len(history.my_actions) // 2:
            self.cooperate_count -= 1
            action = Action.D
        elif history is not None and len(self.opponent_history) < 2:
            self.opponent_history[history.opponent_actions[-2, :].tolist()] = self.cooperate_count
        if history is not None and len(self.opponent_history) == 2:
            if sum([cooperator for cooperator in self.opponent_history.values()]) > len(self.opponent_history) // 2:
                action = Action.C
            elif self.game_description.n_players % 2 == 0 and sum([cooperator for cooperator in self.opponent_history.values()]) == len(self.opponent_history) // 2:
                action = np.random.choice([Action.C, Action.D])
        self.update_opponent_history(history)
        return action

    def update_opponent_history(self, history):
        if history is not None:
            current_round = len(history.my_actions) - 1
            self.opponent_history[history.opponent_actions[current_round, :].tolist()] = self.cooperate_count

class Strategy_COLLECTIVE_339(BaseStrategy):
    """
    Tit-for-Tat Adaptive (TFT-A) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.previous_round_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None or state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.game_description.m > self.previous_round_cooperators:
            return Action.C
        elif cooperators < self.game_description.m and (self.previous_round_cooperators == 0 or history.my_actions[-2] != Action.D):
            return Action.D
        else:
            self.previous_round_cooperators = cooperators
            return history.my_actions[-1]

class Strategy_COLLECTIVE_340(BaseStrategy):
    """
    Implementation of the Tit-for-Tat Adaptive (TFT-A) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m
        self.k = game_description.k
        self.history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if not history and state.round_number == 0:
            return Action.C
        self.history.append(history) if history else self.history.append([[Action.D] * self.game_description.n_players])
        if state.round_number > 1 and len(self.history) > state.round_number:
            coop_count = np.sum(np.array(self.history[-state.round_number])[:, self.min_cooperators - 1])
            return Action.C if coop_count >= self.min_cooperators else Action.D
        if state.round_number == 0:
            return Action.C
        elif len(self.history) > state.round_number and np.sum(history.opponent_actions[-1]) < self.min_cooperators:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_342(BaseStrategy):
    """
    A Titan Strategy implementation for the Collective Risk Dilemma game.
    The Titan strategy is an adaptive and robust strategy that balances risk-taking with cooperation, aiming to maximize long-term payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.num_initial_rounds = math.ceil(game_description.n_players / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            cooperation_probability = random.random() > 0.5
            return Action(cooperation_probability) if cooperation_probability else Action.D
        cooperators = sum(history.opponent_actions[-1, :])
        cooperation_probability = max(cooperators / self.game_description.n_players, 0)
        return Action(state.round_number <= self.num_initial_rounds or random.random() > cooperation_probability) if Action.C else Action.D

class Strategy_COLLECTIVE_343(BaseStrategy):
    """
    Strategy name: Tit-for-Tat Adaptive Cooperation (TFTAC)
    Strategy summary: Balances cooperation and defection while being responsive to the actions of other players.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.initial_rounds = 3
        self.cooperation_threshold = math.ceil((self.game_description.n_players + 1) / 2) - 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number <= self.initial_rounds:
            return Action.C
        if not history:
            return Action.C
        players_cooperated = sum(history.opponent_actions[-1])
        if players_cooperated >= self.cooperation_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_344(BaseStrategy):
    """Adaptive Tit-for-Tat strategy for the Collective Risk Dilemma game."""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self._last_round_opponent_action = None
        self._first_encounter_with_defector = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_actions = history.opponent_actions if history is not None else np.zeros((1, self.game_description.n_players), dtype=bool)
        last_round_opponent_action = opponent_actions[-1, 0]
        if self._first_encounter_with_defector is None:
            self._first_encounter_with_defector = state.round_number == 1 or last_round_opponent_action
        if self._first_encounter_with_defector and (not last_round_opponent_action):
            return Action.D
        elif last_round_opponent_action:
            return Action.C
        else:
            return Action.D if state.round_number == self._first_encounter_with_defector + 1 else Action.C

class Strategy_COLLECTIVE_345(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATfT) for Collective Risk Dilemma

    This strategy follows the Adaptive Tit-for-Tat approach in the Collective Risk Dilemma game. It starts by cooperating in the first round, and subsequently bases its actions on the previous opponents' behavior. If an opponent cooperates, it reciprocates with cooperation; if an opponent defects, it defects in the next round as a punishment, then reverts to cooperating if the opponent cooperates in the following round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(my_actions=np.array([False]), my_payoffs=np.array([0.0]), opponent_actions=np.array([]), opponent_payoffs=np.array([]))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is not None:
            self.history = history
        if state.round_number == 0:
            return Action.C
        cooperation_ratio = self.calculate_cooperation_ratio()
        if state.round_number == self.game_description.n_rounds - 1:
            if cooperation_ratio < self.game_description.m / (self.game_description.n_players - 1):
                return Action.D
            else:
                return Action.C
        elif state.round_number == self.game_description.n_rounds - 2:
            if cooperation_ratio < self.game_description.m / (self.game_description.n_players - 2):
                return Action.D
            else:
                return Action.C
        elif self.history.opponent_actions[-1][-1] == Action.C.value:
            return Action.C
        else:
            return Action.D

    def calculate_cooperation_ratio(self) -> float:
        cooperation = np.sum(self.history.my_actions)
        total = len(self.history.my_actions)
        if total == 0:
            return 0
        else:
            return cooperation / total

class Strategy_COLLECTIVE_346(BaseStrategy):
    """
    A Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperative_threshold = math.ceil(game_description.m / (2 * game_description.n_players))
        self.cooperation_rate = self.cooperative_threshold
        self.most_cooperative_player = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is not None:
            if state.round_number == 0:
                return Action.C
            else:
                cooperators = sum(history.opponent_actions[state.round_number - 1])
                if cooperators >= self.cooperative_threshold:
                    self.update_cooperation_rate(cooperators)
                    return Action.C
                else:
                    return Action.D
        elif state.round_number == 0:
            return Action.C
        else:
            if self.most_cooperative_player is None:
                self.find_most_cooperative_player(history)
            action = self.most_cooperative_player.my_actions[state.round_number - 1]
            return action

    def update_cooperation_rate(self, cooperation_count: int):
        new_cooperation_rate = (cooperation_count + self.cooperation_rate) / 2
        if new_cooperation_rate > self.game_description.m / self.game_description.n_players:
            new_cooperation_rate = self.game_description.m / self.game_description.n_players
        elif new_cooperation_rate < self.cooperative_threshold:
            new_cooperation_rate = self.cooperative_threshold
        self.cooperation_rate = new_cooperation_rate

    def find_most_cooperative_player(self, history: PlayerHistory):
        total_rewards = np.sum(history.my_payoffs)
        most_reward = -math.inf
        for player in range(len(history.opponent_actions)):
            player_rewards = np.sum(history.opponent_payoffs[:, player])
            if player_rewards > most_reward:
                self.most_cooperative_player = PlayerHistory(my_actions=history.opponent_actions[:, player], my_payoffs=history.opponent_payoffs[:, player])
                most_reward = player_rewards
        if self.most_cooperative_player is None:
            self.most_cooperative_player = PlayerHistory(my_actions=np.zeros((history.my_payoffs.size,), dtype=bool), my_payoffs=np.zeros(history.my_payoffs.size, dtype=float))

class Strategy_COLLECTIVE_347(BaseStrategy):
    """
    Implementation of Tit-for-Tat Plus (TFT+) strategy.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperation_count = sum(history.opponent_actions[-1]) if history else 0
        if cooperation_count >= self.m:
            return Action.C
        else:
            previous_cooperation_count = cooperation_count if history else 0
            return Action.D if previous_cooperation_count == 0 and cooperation_count > 0 else Action.C

class Strategy_COLLECTIVE_348(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.m - 1
        self.last_reward_vs_defect = float('-inf')
        self.last_cooperator_count = 0
        self.last_majority_cooperated = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        action = Action.D
        if history:
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators > self.threshold or (cooperators == self.game_description.m and random.random() < 0.5):
                action = Action.C
            if action == Action.C:
                if cooperators >= self.threshold + 1 and history.my_payoffs[-1] > history.my_payoffs[-1] * (1 - self.game_description.k):
                    self.threshold += 1
                elif cooperators < self.threshold - 1 and history.my_payoffs[-1] >= history.my_payoffs[0]:
                    self.threshold -= 1
            self.last_cooperator_count = cooperators
            self.last_majority_cooperated = action == Action.C and cooperators >= self.game_description.m
            self.last_reward_vs_defect = history.my_payoffs[-1]
        return action

class Strategy_COLLECTIVE_349(BaseStrategy):
    """
    The Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.sliding_window_size = math.floor(game_description.n_rounds * 0.1)
        self.average_cooperators = 0
        self.current_round = 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or not history:
            return Action.C
        cooperators = sum(history.opponent_actions[-self.sliding_window_size:, -1]) / self.sliding_window_size
        if state.round_number != self.game_description.n_rounds or cooperators >= self.cooperation_threshold:
            return Action.C
        return Action.D

    def update_state(self, average_cooperators: float):
        self.average_cooperators = average_cooperators
        if average_cooperators > self.cooperation_threshold:
            self.cooperation_threshold -= 0.01
        elif average_cooperators < self.cooperation_threshold:
            self.cooperation_threshold += 0.01

class Strategy_COLLECTIVE_350(BaseStrategy):
    """
    Implementation of the Tit-for-Tat Adaptive Cooperation (TFTAC) strategy.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m_current = math.ceil(self.game_description.m * 0.8)
        self.cooperation_counts = np.zeros(5, dtype=np.int32)

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_cooperated = sum(history.opponent_actions[-1]) >= self.game_description.n_players // 2
        if opponent_cooperated:
            self.cooperation_counts[4] = self.cooperation_counts[3]
            self.cooperation_counts[3] = self.cooperation_counts[2]
            self.cooperation_counts[2] = self.cooperation_counts[1]
            self.cooperation_counts[1] = self.cooperation_counts[0] + (1 if history.my_actions[-1] else 0)
            self.m_current = max(self.game_description.m, math.ceil(self.cooperation_counts[-5:].sum() / 5 + 1))
            return Action.C
        else:
            self.cooperation_counts[4] = self.cooperation_counts[3]
            self.cooperation_counts[3] = self.cooperation_counts[2]
            self.cooperation_counts[2] = self.cooperation_counts[1]
            self.cooperation_counts[1] = self.cooperation_counts[0] + (1 if history.my_actions[-1] else 0)
            return Action.D

class Strategy_COLLECTIVE_351(BaseStrategy):
    """
    A strategy that cooperates in the first round and then adapts to its opponent's actions, encouraging mutual cooperation.
    Forgives defections after three consecutive rounds of cooperation from the opponent.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.forgiveness_counter = 0
        self.last_opponent_action = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        current_round = len(history.opponent_actions) - 1
        last_round = current_round - 1 if current_round > 0 else None
        self.forgiveness_counter = max(self.forgiveness_counter - 1, 0)
        if last_round is not None and self.last_opponent_action == Action.C and history.opponent_actions[last_round][-1].all():
            self.forgiveness_counter = 3
        cooperators = sum(history.opponent_actions[current_round])
        if self.forgiveness_counter > 0 and cooperators >= self.game_description.n_players // self.forgiveness_counter:
            return Action.C
        self.last_opponent_action = history.opponent_actions[current_round][-1] if current_round >= 0 else None
        return Action(int(self.last_opponent_action))

class Strategy_COLLECTIVE_352(BaseStrategy):
    """
    Strategy name: Tit-for-Tat-Adaptive (TFT-A)
    Balances individual self-interest and collective welfare by promoting mutual cooperation while also punishing defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_cooperators = 0
        self.first_round = True
        self.defection_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        action = Action.C
        if state.round_number == 0:
            self.first_round = True
            return Action.C
        elif state.round_number == self.game_description.n_rounds:
            action = Action.C
        elif history and (not history.my_actions[-1]):
            self.defection_counter += 1
            if self.defection_counter == 1:
                action = Action.D
            else:
                self.defection_counter = 0
                action = Action.C
        else:
            self.last_cooperators = sum(history.opponent_actions[-1])
            if self.last_cooperators >= self.game_description.n_players // 2:
                action = Action.C
            else:
                action = Action.D
        if history and self.first_round:
            self.last_cooperators += sum(history.opponent_actions[0])
            self.first_round = False
        return action

class Strategy_COLLECTIVE_353(BaseStrategy):
    """
    A Tit-for-Tat strategy with adaptive cooperation threshold (TFTAT) for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.p_init = 0.9
        self.p_decay = 0.01
        self.p_min = 0.2
        self.endowment = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            self.p = self.p_init
            self.endowment = 1
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators < self.m:
            payoff = 1 - self.endowment
            if self.p > self.p_min:
                self.p -= self.p_decay
            if self.p < self.p_min:
                self.p = self.p_min
        else:
            payoff = 1 - self.endowment + self.k * self.m / cooperators
            self.p += self.p_decay
        if payoff > self.endowment:
            self.endowment *= payoff / self.endowment
        return Action.C if payoff > self.endowment else Action.D

class Strategy_COLLECTIVE_354(BaseStrategy):
    """
    Adaptive Tit-for-Tat Strategy for Collective Risk Dilemma Game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :]) if history is not None else 0
        if cooperators < self.m or state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_355(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat Adaptive (TFT-A) for Collective Risk Dilemma
    Strategy Description: When exactly do you cooperate vs defect? In each round i, if the number of cooperators in the previous round (i-1) is less than m, player will defect (D). If the number of cooperators in the previous round (i-1) equals or exceeds m, player will cooperate (C).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(my_actions=np.zeros(game_description.n_rounds), my_payoffs=np.zeros(game_description.n_rounds), opponent_actions=np.zeros((game_description.n_rounds, game_description.n_players)), opponent_payoffs=np.zeros((game_description.n_rounds, game_description.n_players)))

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if history is not None and state.round_number > 0:
            self.history = history
        if state.round_number == 0:
            return Action.C
        coop_count = np.sum(self.history.opponent_actions[-1])
        if coop_count >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_356(BaseStrategy):
    """
    A Tit-for-Tat strategy with cooperation threshold for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_opponent_action = None
        self.number_of_cooperative_rounds = 0
        self.some_threshold = int(self.game_description.n_players / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if state.round_number == 0:
            return Action.C
        if history is not None:
            self.last_opponent_action = history.opponent_actions[-1][0]
            cooperators = sum(history.opponent_actions[-1])
            self.number_of_cooperative_rounds += 1 if cooperators >= self.game_description.m else 0
        action = Action.C if state.round_number > 1 and cooperators >= self.game_description.m else Action.D
        if history is not None and state.round_number > 1:
            if self.last_opponent_action == Action.C and action == Action.D:
                action = Action.D
            elif self.last_opponent_action != Action.C and action == Action.C:
                action = Action.C
        if state.round_number == self.game_description.n_rounds:
            cooperative_payoff = sum(history.my_payoffs) if action == Action.C else history.my_payoffs[-1][-1] + self.game_description.k * (cooperators - self.game_description.m)
            defection_payoff = history.my_payoffs[-1][-1]
            action = Action.C if cooperative_payoff > defection_payoff else Action.D
        return action

class Strategy_COLLECTIVE_358(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation (TFT-AC) Strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_period = int(math.ceil(game_description.n_players / 2))
        self.current_round = 0
        self.consecutive_defections = 0
        self.peace_offering = True

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        self.current_round = state.round_number
        if not history:
            return Action.C
        if self.current_round == 1:
            return Action.C
        opponent_action = history.opponent_actions[-1][0] if self.current_round == 1 else history.opponent_actions[-1, -1]
        if opponent_action:
            return Action.C
        elif self.peace_offering and self.consecutive_defections >= self.cooperation_period:
            self.peace_offering = False
            return Action.C
        else:
            self.consecutive_defections += 1
        if self.current_round == self.game_description.n_rounds - 1:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_359(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATFT) for Collective Risk Dilemma

    A cooperative strategy that initially cooperates to promote cooperation, and subsequently defects if fewer than the minimum required number of players cooperated in the previous round. In the last round, always cooperate to maximize payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = math.ceil(game_description.n_players * game_description.m / 100)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.min_cooperators:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_360(BaseStrategy):
    """
    A strategy that reciprocates cooperation and punishes defection in the Collective Risk Dilemma game.
    It adapts to the collective behavior of other players by cooperating if a majority cooperated in the previous round,
    otherwise defecting to encourage future cooperation. If the number of cooperators in the last round equals m, it will cooperate again in the final round to ensure achieving the minimum cooperation threshold for maximum payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if not history:
            return Action.C
        current_round = state.round_number - 1
        current_cooperators = sum(history.opponent_actions[current_round, :])
        if current_round == self.game_description.n_rounds - 1:
            return Action.C if current_cooperators >= self.m else Action.D
        if current_cooperators > (self.n - 1) // 2:
            return Action.C
        elif current_cooperators == (self.n - 1) // 2:
            return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_362(BaseStrategy):
    """
    The Tit-for-Tat with Adaptive Cooperation (TFT-AC) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_last_action = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None and state.round_number == 0:
            return Action.C
        if history is None:
            self.opponent_last_action = None
            return Action.C
        if state.round_number == 1:
            self.opponent_last_action = history.opponent_actions[-1]
            return Action.C
        if state.round_number == len(history.opponent_actions) and self.opponent_last_action is not None:
            self.opponent_last_action = history.opponent_actions[-1]
            return Action.C
        last_round = len(history.opponent_actions) - 1
        self.opponent_last_action = history.opponent_actions[last_round]
        if history.opponent_actions[last_round, :].mean() >= self.game_description.m / self.game_description.n_players:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_363(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATFT) for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None and state.round_number == 0:
            return Action.C
        elif state.round_number == 0:
            self.history = np.zeros((1,), dtype=bool)
            self.history[0] = True
            return Action.C
        else:
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators >= self.game_description.m:
                self.history = np.append(self.history, [True])
            else:
                self.history = np.append(self.history, [False])
            return Action(int(self.history[-1]))

class Strategy_COLLECTIVE_364(BaseStrategy):
    """
    Tit-for-Tat with Adaptation (TFT-A) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_cooperators_count = [0] * self.game_description.n_players
        self.last_round_action = Action.D

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_actions = history.opponent_actions if history is not None else np.zeros((1, self.game_description.n_players), dtype=bool)
        opponent_cooperators = sum(opponent_actions[-1, :])
        most_frequent_cooperator = max(set(self.opponent_cooperators_count))
        if opponent_cooperators >= self.game_description.m and opponent_actions[-1, most_frequent_cooperator] == 1:
            return Action.C
        if opponent_cooperators < self.game_description.m or opponent_actions[-1, most_frequent_cooperator] == 0:
            return Action.D
        self.opponent_cooperators_count[most_frequent_cooperator] += opponent_actions[-1, most_frequent_cooperator] - self.last_round_action
        self.last_round_action = opponent_actions[-1, most_frequent_cooperator]
        return Action.D

class Strategy_COLLECTIVE_365(BaseStrategy):
    """
    Tit-for-Tat Adaptive Strategy for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.alpha = int(math.ceil(game_description.n_players / 2))
        self.beta = 10

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if not history:
            return Action.C
        if state.round_number >= self.game_description.n_rounds - self.beta:
            return Action.C
        opponent_actions = history.opponent_actions[-1]
        cooperators = np.sum(opponent_actions)
        if cooperators < self.game_description.m or (cooperators >= self.alpha and state.round_number > self.alpha):
            return Action.D
        return Action.C

class Strategy_COLLECTIVE_367(BaseStrategy):
    """
    A Tit-for-Tat strategy with threshold adaptation for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.minimum_cooperators = self.game_description.m
        self.k = self.game_description.k
        self.last_opponent_cooperation = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or not history:
            return Action.C
        self.last_opponent_cooperation = sum(history.opponent_actions[-1])
        if self.last_opponent_cooperation >= self.minimum_cooperators:
            return Action.C
        if history.my_actions[-1] and self.last_opponent_cooperation < self.minimum_cooperators:
            return Action.D
        return Action.C

class Strategy_COLLECTIVE_368(BaseStrategy):
    """
    A strategy that mimics the Tit-for-Tat with Cooperative Adjustment (TTCA).
    It cooperates initially, and adjusts its action based on the number of cooporators in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_strategy_change_round = None

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is not None:
            self.last_strategy_change_round = history.my_actions[-1]
        pastCooperators = sum(history.opponent_actions[-1, :])
        if pastCooperators >= self.game_description.m:
            return Action.C
        else:
            return Action.D
        if state.round_number > self.last_strategy_change_round + 1:
            self.last_strategy_change_round = None
            return Action.C

class Strategy_COLLECTIVE_369(BaseStrategy):
    """ Tit-for-Tat with Adaptive Cooperation (TFT-AC) for Collective Risk Dilemma game. """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.memory = np.zeros((self.game_description.n_players, self.game_description.n_rounds), dtype=np.bool_)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and history.my_actions[-1] == Action.D):
            return Action.C
        cooperators = np.sum(history.opponent_actions[-1, :]) if history is not None else 0
        if cooperators >= self.game_description.n_players // 2:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_370(BaseStrategy):
    """
    The Adaptive Tit-for-Tat (ATFT) strategy in Collective Risk Dilemma.
    ATFT encourages cooperation when partners also cooperate but retaliates against defection while maintaining the possibility of forgiveness for future rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None or len(history.opponent_actions) < self.game_description.n_rounds:
            return Action.D
        partner_cooperated_t = sum(history.opponent_actions[state.round_number - 1]) >= self.m
        partner_cooperated_t_1 = history.opponent_actions[state.round_number - 2] if state.round_number > 1 else False
        return Action(int(partner_cooperated_t and partner_cooperated_t_1 or not partner_cooperated_t_1))

    def last_round(self, history: PlayerHistory):
        if len(history.opponent_actions) < self.game_description.n_rounds:
            return None
        partner_cooperated_r = sum(history.opponent_actions[-1]) >= self.m
        return Action(int(partner_cooperated_r)) if history.opponent_actions else None

class Strategy_COLLECTIVE_371(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperative Threshold (TFT-ACT) Strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.m
        self.consecutive_successes = 0
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is not None:
            player_cooperators = np.sum(history.opponent_actions[-1]) - 1
            if player_cooperators >= self.threshold:
                self.consecutive_defections = 0
                self.consecutive_successes += 1
                if self.consecutive_successes > self.game_description.n_players // 2:
                    self.threshold += 1
                return Action.C
            else:
                self.consecutive_successes = 0
                self.consecutive_defections += 1
                if self.consecutive_defections >= self.game_description.n_players // 2:
                    self.threshold -= 1
        return Action.D

class Strategy_COLLECTIVE_372(BaseStrategy):
    """
    The Tit-for-Tat Adaptive (TFT-A) strategy for the Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.tolerance_level = math.floor((game_description.n_players - game_description.m) / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        cooperators = np.sum(history.opponent_actions[state.round_number - 1])
        if state.round_number == self.game_description.n_rounds or history.my_payoffs[-1] is None:
            return self.__call__(GameState(state.round_number + 1), history)
        elif cooperators < self.game_description.m or math.isclose(cooperators - self.game_description.m, self.tolerance_level):
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_373(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Threshold (TFTA) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.threshold = self.n_players
        self.init_threshold = self.n_players
        self.rounds_passed = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            self.rounds_passed = 1
            return Action.C
        self.rounds_passed += 1
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.m:
            return Action.C
        if cooperators < self.m and self.rounds_passed > self.game_description.n_rounds // 2:
            self.threshold = max(self.threshold - self.game_description.n_players // self.game_description.n_rounds, 1)
        elif cooperators >= self.m * 2 // 3 and self.rounds_passed < self.game_description.n_rounds // 2:
            self.threshold = min(self.threshold + self.game_description.n_players // self.game_description.n_rounds, self.init_threshold)
        return Action.D if cooperators < self.threshold else Action.C

class Strategy_COLLECTIVE_374(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat Adaptive Cooperation (TFTAC)
    The strategy cooperates in the first round and then mimics the previous action of each opponent for subsequent rounds. If a player switches from cooperation to defection, TFTAC will also switch to defection in response. If an opponent defects, TFTAC will continue to defect until the opponent returns to cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_actions_history = []
        self.opponent_payoffs_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is not None:
            self.opponent_actions_history.append(history.opponent_actions[-1])
            self.opponent_payoffs_history.append(history.opponent_payoffs[-1])
        last_action = self.opponent_actions_history[-1][-1] if len(self.opponent_actions_history) > 0 else None
        if last_action is None:
            return Action.C
        elif last_action:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_375(BaseStrategy):
    """
    A strategy based on the Tit-for-Tat Adaptive (TFT-A) in Collective Risk Dilemma games.
    Cooperates on the first round to signal goodwill and promotes cooperation, copies others' actions in subsequent rounds,
    punishes those who did not cooperate, rewards frequent cooperators, and adopts the most recent opponent behavior in the last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros(game_description.n_rounds))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.history.opponent_actions[0] = np.full(self.game_description.n_players, False)
            return Action.C
        if state.round_number == 0:
            return Action.C
        opponent_moves = history.opponent_actions[-1]
        nb_coop = sum(opponent_moves)
        if nb_coop >= self.game_description.m or (nb_ties := sum([1 for moves in history.opponent_actions if sum(moves) == nb_coop])) > 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return history.opponent_actions[-2][self.__class__.__name__]
        max_coops = -1
        max_player = None
        for i in range(self.game_description.n_players):
            coop_count = sum([1 for moves in history.opponent_actions if moves[i] == Action.C])
            if coop_count > max_coops:
                max_coops, max_player = (coop_count, i)
        return history.opponent_actions[-1][max_player]

class Strategy_COLLECTIVE_377(BaseStrategy):
    """
    A strategy that cooperates initially and adapts its cooperation threshold based on the average percentage of cooperators in past rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.m / game_description.n_players
        self.history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or len(self.history) == 0:
            return Action.C
        cooperators_percentage = np.mean([hist[round] for hist in self.history[-self.game_description.n_rounds:]]) * 100
        if cooperators_percentage > self.game_description.n_players * 0.6 or cooperators_percentage < self.game_description.n_players * 0.4:
            self.threshold += math.copysign(cooperators_percentage - self.game_description.n_players * 0.4, cooperators_percentage - self.game_description.n_players * 0.6) / self.game_description.n_players
        self.history.append([round < state.round_number for round in history.my_actions if round is not None])
        return Action.C if cooperators_percentage >= self.threshold else Action.D

class Strategy_COLLECTIVE_378(BaseStrategy):
    """
    Adaptive Tit-for-Tat strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.round = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is not None and self.round != 0:
            cooperators = sum(history.opponent_actions[-1])
            if cooperators >= self.game_description.m:
                return Action.C
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds:
            return Action.C
        self.round += 1
        return Action.D

class Strategy_COLLECTIVE_380(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (ACT) for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = math.ceil(game_description.n_players - 1)
        self.prev_cooperators = 0
        self.total_payoff = 0

    def __call__(self, state: GameState, history: None | PlayerHistory):
        action = Action.D
        if state.round_number == 0:
            action = Action.C
        else:
            cooperators = sum(history.opponent_actions[state.round_number - 1, :])
            self.prev_cooperators = cooperators
            payoff = self.total_payoff + history.my_payoffs[-1] if history is not None else 0
            if cooperators >= self.game_description.m:
                action = Action.C
                self.threshold = max(self.threshold - 1, 0)
                self.total_payoff += payoff
            elif payoff >= self.threshold:
                self.threshold = min(self.threshold + 1, self.game_description.n_players - 1)
                self.total_payoff += payoff
        return action

class Strategy_COLLECTIVE_382(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.round_counter = 0
        self.forgiveness_cycle = 3
        self.current_state = Action.C
        self.opponent_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is not None:
            self.opponent_history.append(np.array(history.opponent_actions[-1]))
            self.round_counter += 1
        if state.round_number == 0 or len(self.opponent_history) < self.forgiveness_cycle:
            return self.current_state
        last_three = self.opponent_history[-self.forgiveness_cycle:-1]
        if np.all(last_three == [Action.D, Action.D, Action.D]):
            self.current_state = Action.C
        opponent_cooperators = np.sum(self.opponent_history[-1])
        if opponent_cooperators < self.game_description.m:
            return Action.D
        return self.current_state

class Strategy_COLLECTIVE_383(BaseStrategy):
    """
    Adaptive Tit-for-Tat strategy for the Collective Risk Dilemma game.
    Strategy Name: Adaptive Tit-for-Tat (ATFT)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.average_cooperators = 0.0
        self.fraction_threshold = 0.0
        self.rounds_played = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if state.round_number == self.game_description.n_rounds:
            return Action.C
        self.rounds_played += 1
        if self.rounds_played > self.game_description.n_rounds:
            self.average_cooperators = self.average_cooperators * (self.rounds_played - 1) / self.rounds_played
            self.fraction_threshold = self.average_cooperators * (self.game_description.k > 2)
        else:
            cooperators = sum(history.opponent_actions[-1, :]) if history is not None else 0
            self.average_cooperators = self.average_cooperators + (cooperators / self.rounds_played if self.rounds_played > 0 else cooperators)
        num_cooperators = math.ceil(self.fraction_threshold * self.game_description.n_players)
        if history is not None and cooperators >= num_cooperators:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_384(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) Strategy
    This strategy cooperates to initiate a cooperative relationship and adjusts the cooperation threshold based on the average cooperation rate of other players.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = None
        self.average_cooperators = 0.0

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        self.average_cooperators = (self.average_cooperators * (state.round_number - 1) + cooperators) / state.round_number
        if self.cooperation_threshold is None:
            self.cooperation_threshold = self.game_description.n_players // 2
        if self.average_cooperators >= self.cooperation_threshold:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_385(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation (TFT-AC) Strategy for the Collective Risk Dilemma game.
    This strategy cooperates in the first round and adapts its cooperation based on the partner's history.
    It mimics the partner's behavior and only punishes defectors if they consistently fail to cooperate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(my_actions=np.array([[False]], dtype=bool), my_payoffs=np.array([]), opponent_actions=np.zeros((1, game_description.n_players), dtype=bool), opponent_payoffs=np.zeros(game_description.n_players))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is not None and state.round_number > 0:
            self.history = history
        if state.round_number == 0:
            return Action.C
        last_opponent_action = self.history.opponent_actions[-1, -1]
        current_round = self.history.my_actions.shape[0]
        initial_cooperation_phase = current_round <= self.game_description.m + 1
        endgame = current_round >= state.round_number - (self.game_description.n_players - self.game_description.m)
        if initial_cooperation_phase or endgame:
            return Action.C
        if last_opponent_action:
            if current_round > self.game_description.m + 1 and np.count_nonzero(self.history.opponent_actions[:, -1]) < self.game_description.m:
                return self.history.my_actions[-1]
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_386(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATFT) for Collective Risk Dilemma

    This strategy cooperates with others when they have been consistently cooperative,
    but defects if others have been non-cooperative. The strategy encourages cooperation
    by following past actions and strives for a balance between self-interest (defecting)
    and group interest (cooperating).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.past_action = None
        self.total_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return random.choice([Action.C, Action.D])
        self.past_action = history.my_actions[-1] if history else random.choice([True, False]) if state.round_number == 1 else self.past_action
        self.total_cooperators += self.past_action
        cooperators = sum(history.opponent_actions[-1, :]) if history else 0
        if cooperators >= self.game_description.m and state.round_number < self.game_description.n_rounds:
            return Action.C
        elif cooperators >= self.game_description.m * (self.game_description.n_rounds - 1) and state.round_number == self.game_description.n_rounds:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_387(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Risk Aversion (ATfTra) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history_length = game_description.n_rounds - 1 if game_description.n_rounds > 0 else 0
        self.adjusted_ratio = np.zeros(self.history_length)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        ratio = cooperators / self.game_description.m
        if ratio < 0.5:
            return Action.D
        adjusted_ratio = ratio * self.game_description.k
        if adjusted_ratio > 1:
            return Action.C
        return Action.D

    def update_adjusted_ratio(self, history: PlayerHistory):
        if len(history) < self.history_length + 1:
            return
        cooperators = sum(history.opponent_actions[-(self.history_length + 1):])
        self.adjusted_ratio[-1] = cooperators / self.game_description.m * self.game_description.k

class Strategy_COLLECTIVE_388(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATFT) for Collective Risk Dilemma
    Strategy Description: ATFT starts by cooperating in the first round and then mimics the cooperative spirit of the game. If a player has been cooperated with in the previous round, it returns the favor. If a player has defected, the strategy defects as well ("punishment"). However, to allow for forgiveness, if five consecutive defections occur from an opponent, the strategy will revert to cooperating again.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is not None:
            action = Action.D
            if history.opponent_actions[-1][-1] == Action.C:
                action = Action.C
                self.consecutive_defections = 0
            else:
                self.consecutive_defections += 1
                if self.consecutive_defections >= 5:
                    action = Action.C
                    self.consecutive_defections = 0
            return action

class Strategy_COLLECTIVE_389(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Threshold (ATT) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m
        self.previous_state = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or self.previous_state is None:
            return Action.D
        cooperator_count = sum(history.opponent_actions[-1])
        if cooperator_count >= self.min_cooperators:
            cooperated_last_round = history.my_actions[-1]
            return Action(int(cooperator_count >= self.min_cooperators + 1) or (cooperator_count == self.min_cooperators and cooperated_last_round))
        return Action.D

class Strategy_COLLECTIVE_390(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold Strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperators_threshold = int(game_description.n_players * 0.5 + 1)
        self.threshold_adjustment_rounds = math.ceil(game_description.n_rounds / 10)
        self.cooperation_rate = np.zeros(self.threshold_adjustment_rounds)
        self.current_cooperators_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and state.round_number > self.threshold_adjustment_rounds:
            self.cooperation_rate = np.roll(self.cooperation_rate, -1)
            self.cooperation_rate[-1] = self.current_cooperators_count / self.threshold_adjustment_rounds * (self.game_description.n_players - 1) + 1
            self.current_cooperators_count = 0
        cooperators = sum(history.opponent_actions[-1, :]) if history is not None else 0
        self.current_cooperators_count += cooperators
        return Action.C if cooperators >= self.cooperators_threshold else Action.D

class Strategy_COLLECTIVE_391(BaseStrategy):
    """
    A Tit-for-Tat-Adaptive (TfTA) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_cooperated_last = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        self.opponent_cooperated_last = bool(history.opponent_actions[-1, -1])
        if self.opponent_cooperated_last:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_392(BaseStrategy):
    """
    A strategy that cooperates in the first round, then reciprocates an opponent's previous action,
    while also considering a threshold for consecutive cooperative moves by opponents to avoid unilateral cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.n_players // 2
        self.history_length = game_description.n_players * game_description.n_rounds
        self.history = np.zeros(self.history_length, dtype=bool)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        elif history is None:
            self.history = np.zeros(self.history_length, dtype=bool)
        state_index = state.round_number - 1 if history else state.round_number * self.game_description.n_players - 1
        opponent_actions = history.opponent_actions[state_index, :] if history else self.history[(state.round_number - 1) * self.game_description.n_players:]
        last_cooperators = sum(opponent_actions)
        if last_cooperators >= self.threshold:
            return Action.C
        elif state.round_number < self.game_description.n_rounds and sum(opponent_actions[:-1]) > self.threshold:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_394(BaseStrategy):
    """
    A Tit-for-Tat with Adaptive Cooperation (TFT-AC) strategy for the Collective Risk Dilemma game.

    Cooperates in the first round, then cooperates if at least m players cooperated in the previous round.
    If fewer than m players cooperated, defects to punish those who did not comply with the emerging cooperative norm.
    After the last m-1 defections from a player, considers this as a sign of uncooperative behavior and switches to permanent defection towards that player while still cooperating with other players.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_m1_defections = {opponent: 0 for opponent in range(1, game_description.n_players + 1)}

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        opponent_cooperators = sum(history.opponent_actions[state.round_number - 1])
        self.last_m1_defections[self.__class__] = 0
        if opponent_cooperators >= self.game_description.m:
            return Action.C
        else:
            for opponent in history.opponent_actions[-1]:
                if opponent and self.last_m1_defections[opponent] < self.game_description.m - 1:
                    self.last_m1_defections[opponent] += 1
            return Action.D

class Strategy_COLLECTIVE_395(BaseStrategy):
    """
    Tit-for-Tat Adaptive Cooperation (TFTAC) Strategy in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.game_params = game_description.__dict__
        self.first_round = True
        self.forgiveness_counter = 0
        self.last_opponent_action = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-1, :])
        m = self.game_params['m']
        if self.first_round:
            self.first_round = False
            return Action.C
        if cooperators >= m and self.last_opponent_action is not None and (self.last_opponent_action == Action.C):
            return Action.C
        if self.last_opponent_action is None or self.last_opponent_action == Action.D:
            return Action.D if cooperators < m else Action.C
        if self.forgiveness_counter >= 1 and cooperators > m + 1:
            self.forgiveness_counter = 0
            self.last_opponent_action = None
            return Action.C
        self.forgiveness_counter += 1
        self.last_opponent_action = history.opponent_actions[-1, -1]
        return Action.D if cooperators < m + 1 else Action.C

class Strategy_COLLECTIVE_396(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation (TFT-AC) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.g = 0.8
        self.r_factor = 1.2
        self.p_factor = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and history.opponent_actions is None):
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            g = self.r_factor
        else:
            g = self.g
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.game_description.m:
            g *= 1 + self.r_factor
        elif state.round_number < self.game_description.m:
            g *= self.p_factor
        else:
            g *= 1 - self.p_factor
        self.g = g
        if history is not None and state.round_number > 0:
            last_action = history.my_actions[-1]
            if last_action == Action.C and history.opponent_actions[-1, -1] == last_action:
                return Action.C
            elif last_action == Action.D and history.opponent_actions[-1, -1] == Action.C:
                return Action.D
        return Action.C

class Strategy_COLLECTIVE_397(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat Plus (TFT+)
    Description: Cooperate if at least m-1 players cooperated in the previous round, otherwise defect.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1])
        if cooperators >= self.m - 1:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_399(BaseStrategy):
    """
    Tit-for-Tat with Adaptation (TFT-A) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is not None:
            self.opponent_history = history.opponent_actions.flatten().tolist()
        cooperate = Action.C if self.opponent_history[-1] == Action.C else Action.D
        return cooperate

    def update(self, state: GameState, payoff: float) -> None:
        """
        Update the opponent history with the latest opponent action and store the payoff.
        """
        self.opponent_history.append(state.round_number > 0 and self.opponent_history[-1] != Action(state.action).value)

    def end_game(self, final_payoffs: NDArray[np.float64]) -> float:
        """
        Return the total game payoff for this strategy instance.
        """
        return np.sum(final_payoffs[0]) if self.opponent_history[-1] == Action.C else np.sum(final_payoffs[1])

class Strategy_COLLECTIVE_401(BaseStrategy):
    """
    Adaptive Tit-for-Tat strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.my_cooperation_history = np.zeros(game_description.n_rounds)
        self.m = game_description.m

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_opponent_cooperated = np.any(history.opponent_actions[state.round_number - 1])
        current_cooperation = Action.C if previous_opponent_cooperated else Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            total_cooperation = np.sum(history.my_actions)
            return Action.C if total_cooperation >= self.m else Action.D
        self.my_cooperation_history[state.round_number] = current_cooperation == Action.C
        return current_cooperation

class Strategy_COLLECTIVE_402(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TTFT) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.t = 10
        self.alpha = 0.01
        self.avg_cooperation = 0.5
        self.CT = math.ceil(self.m * 0.5)

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if state.round_number == 0 and history is None:
            return Action.C
        CR_prev = np.mean(history.opponent_actions[:, -self.t:])
        if state.round_number == self.r - 1:
            if CR_prev >= self.m:
                action = Action.C
            else:
                action = Action.D
        elif CR_prev >= self.CT:
            action = Action.C
        else:
            action = Action.D
        self.avg_cooperation = (self.avg_cooperation * (self.t - 1) + CR_prev) / self.t
        self.CT = math.ceil((self.m + self.avg_cooperation) * 0.5)
        return action

class Strategy_COLLECTIVE_403(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma games.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.past_actions = np.zeros((1, game_description.n_players), dtype=bool)
        self.current_round = 0
        self.n_defect = math.ceil(game_description.n_players / 2)
        self.punishment_duration = game_description.n_players

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        actions = self.past_actions[-1, :]
        cooperators = np.sum(actions)
        if all(actions) and cooperators >= self.cooperation_threshold:
            return Action.C
        elif any(~actions):
            if self.current_round <= self.n_defect:
                self.punishment()
            elif cooperators > self.cooperation_threshold:
                self.reset_threshold()
            return Action.D
        else:
            self.reset_threshold()
            return Action.C

    def punishment(self):
        self.current_round += 1

    def reset_threshold(self):
        if self.cooperation_threshold < self.game_description.n_players:
            self.cooperation_threshold += 1
        self.current_round = min(self.current_round + self.punishment_duration, self.game_description.n_rounds)

class Strategy_COLLECTIVE_404(BaseStrategy):
    """
    Implementation of the Tit-for-Tat Adaptive Cooperation (TFTAC) strategy.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.tolerance = min(math.floor((game_description.n_players - 1) * 0.2), int((game_description.n_players - 1) / 2))
        self.endowment = 0

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if not history:
            return Action.C
        cooperation_count = sum(history.my_actions)
        if cooperation_count >= self.game_description.m:
            action = Action.C
        elif abs(cooperation_count - (self.game_description.m - 1)) <= self.tolerance:
            action = Action.C
        else:
            action = Action.D
        if state.round_number == len(history.my_payoffs):
            self.tolerance *= 2
        return action

class Strategy_COLLECTIVE_405(BaseStrategy):
    """
    Implementation of Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = math.ceil(game_description.n_players / 2)
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is not None:
            self.consecutive_defections = 0
            num_cooperators = sum(history.opponent_actions[-1])
            if num_cooperators >= self.cooperation_threshold:
                return Action.C
            else:
                self.cooperation_threshold += math.ceil((self.game_description.n_players - self.cooperation_threshold) * (len(history.opponent_actions) / self.game_description.n_rounds))
                if self.cooperation_threshold > self.game_description.n_players:
                    self.cooperation_threshold = self.game_description.n_players
                if num_cooperators < self.cooperation_threshold - 1:
                    self.consecutive_defections += 1
            if len(history.opponent_actions) == self.game_description.n_rounds and self.consecutive_defections >= self.game_description.n_players:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_406(BaseStrategy):
    """
    A strategy implementing Tit-for-Tat Adaptive Cooperation (TFT-AC) in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1] if history else [True] * self.game_description.n_players)
        if cooperators >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_407(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TTAT-ACT)

    This strategy follows a Tit-for-Tat approach with an adaptive cooperation threshold. It promotes cooperation by following the majority's lead while punishing non-cooperation when necessary.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.num_players = game_description.n_players
        self.majority_threshold = math.ceil(self.num_players / 2) if self.num_players % 2 else self.num_players // 2

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if state.round_number == 0:
            return Action.C
        if history is None:
            return Action.C
        last_round = len(history.opponent_actions) - 1
        cooperators = sum(history.opponent_actions[last_round, :])
        return Action.C if cooperators >= self.majority_threshold else Action.D

class Strategy_COLLECTIVE_408(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_c_history = np.zeros(game_description.n_rounds)
        self.w = math.ceil(game_description.n_rounds * 0.1)
        self.ACT = game_description.m / game_description.n_players * 100

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        self.n_c_history = np.roll(self.n_c_history, -1)
        self.n_c_history[-1] = sum(history.opponent_actions[state.round_number - 1])
        if len(self.n_c_history) > self.w:
            self.n_c_history = np.delete(self.n_c_history, 0)
            self.ACT = self.game_description.m / self.game_description.n_players * np.mean(self.n_c_history)
        n_c = sum(history.opponent_actions[state.round_number - 1])
        return Action.C if n_c >= self.ACT else Action.D

class Strategy_COLLECTIVE_409(BaseStrategy):
    """
    A strategy that follows the Adaptive Tit-for-Tat (ATFT) approach in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = np.sum(history.opponent_actions[state.round_number - 1])
        my_action = Action.C if cooperators >= self.min_cooperators else Action.D
        if state.round_number == history.my_actions.size - 1 or (history.my_actions[-1] == Action.D and my_action == Action.C):
            return my_action
        return my_action

class Strategy_COLLECTIVE_410(BaseStrategy):
    """
    A Tit-for-Tat Adaptive Cooperation strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = [Action.C]

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or not history:
            return self.cooperation_history[-1]
        cooperators = sum(history.opponent_actions[-1])
        if cooperators >= self.game_description.m:
            self.cooperation_history.append(Action.C)
        elif self.cooperation_history[-1] == Action.D and cooperators >= self.game_description.n - (self.game_description.m - 1):
            self.cooperation_history.append(Action.C)
        elif self.cooperation_history[-1] == Action.D:
            self.cooperation_history.append(cooperators >= self.game_description.m)
        elif self.cooperation_history[-1] == Action.C and history.opponent_actions[-1][-1] == Action.D:
            self.cooperation_history.append(Action.C)
        else:
            self.cooperation_history.append(self.cooperation_history[-1])
        return self.cooperation_history[-1]

class Strategy_COLLECTIVE_411(BaseStrategy):
    """
    Adaptive Tit-for-Tat strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.player_history = PlayerHistory(my_actions=np.empty((self.game_description.n_rounds,), dtype=bool), my_payoffs=np.empty((self.game_description.n_rounds,), dtype=float), opponent_actions=np.empty((self.game_description.n_rounds, self.game_description.n_players), dtype=bool), opponent_payoffs=np.empty((self.game_description.n_rounds, self.game_description.n_players), dtype=float))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = self.player_history.my_actions.shape[0]
        last_round = min(current_round, self.game_description.n_rounds - 1)
        last_cooperators = np.sum(self.player_history.opponent_actions[-last_round:])
        if state.round_number == current_round:
            if last_cooperators >= self.game_description.n_players - 1:
                return Action.C
        player_index = (state.round_number - 1) % self.game_description.n_players + 1
        last_opponent_action = self.player_history.opponent_actions[-last_round:, player_index - 1][0]
        if state.round_number == current_round - 1 and history is not None:
            if last_cooperators >= self.game_description.m:
                return Action.C
        return Action(int(last_opponent_action)) if history is not None else Action.C

class Strategy_COLLECTIVE_413(BaseStrategy):
    """Adaptive Tit-for-Tat Strategy for Collective Risk Dilemma"""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = None
        self.cooperators_threshold = self.game_description.m
        self.n_players = self.game_description.n_players

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if history is None:
            return Action.C
        if state.round_number == len(history.my_actions):
            cooperators = sum(history.opponent_actions[-1])
            return Action(cooperators >= self.cooperators_threshold)
        cooperators = sum(history.opponent_actions[-2])
        return Action(cooperators >= self.cooperators_threshold)

class Strategy_COLLECTIVE_414(BaseStrategy):
    """
    Adaptive Tit-for-Tat Strategy for Collective Risk Dilemma.
    Promotes cooperation among players while remaining robust against a wide range of opponent behaviors.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = np.zeros(game_description.n_rounds - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        if state.round_number == 0 or len(history.opponent_actions) < state.round_number - 1:
            return Action.C
        opponent_last_action = history.opponent_actions[-1][-1]
        cooperators = np.sum(history.opponent_actions[-1])
        if cooperators < self.game_description.n_players // self.game_description.m and opponent_last_action == Action.C:
            return Action.C
        elif opponent_last_action == Action.D:
            self.opponent_history[-1] = opponent_last_action
            return Action.D
        else:
            self.opponent_history[-1] = opponent_last_action
            return Action.C

# class Strategy_COLLECTIVE_415(BaseStrategy):
#     """
#     A strategy based on Tit-for-Tat Adaptive Cooperative (TFTAC). The strategy cooperates if at least m players cooperated in the previous round, and defects otherwise.
#     If more than n-m+1 players cooperated in the previous round, it temporarily raises the threshold to encourage reciprocity by requiring m+1 players to cooperate.
#     If less than m players cooperated in the previous round, it waits for m players to defect before returning to cooperation again.
#     In the last round, it always cooperates regardless of previous actions to maximize potential payoff.
#     """

#     def __init__(self, game_description: CollectiveRiskDescription):
#         self.game_description = game_description
#         self.threshold = None
#         self.m = min(game_description.n_players - 1, game_description.m)

#     def __call__(self, state: GameState, history: PlayerHistory) -> Action:
#         if state.round_number == 0 or history is None:
#             return Action.C
#         cooperation_count = sum(history.opponent_actions[-1])
#         if cooperation_count >= self.m and cooperation_count <= self.game_description.n_players - self.m + 1:
#             action = Action.C
#         elif cooperation_count < self.m and cooperation_count < len(history.opponent_actions) - self.m + 1:
#             action = Action.C
#         else:
#             if self.threshold is None or self.threshold > self.game_description.n_players // (self.m + 1):
#                 self.threshold = math.ceil(self.game_description.n_players / (self.m + 1))
#             elif self.threshold <= self.game_description.n_players // (self.m + 1):
#                 self.threshold = None
#             action = Action.D if cooperation_count < self.threshold else Action.C
#         if state.round_number == self.game_description.n_rounds - 1:
#             return Action.C
#         return action

class Strategy_COLLECTIVE_416(BaseStrategy):
    """
    Implementation of the Tit-for-Tat Adaptive strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(my_actions=np.zeros(game_description.n_rounds, dtype=bool), my_payoffs=np.zeros(game_description.n_rounds), opponent_actions=np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), opponent_payoffs=np.zeros((game_description.n_rounds, game_description.n_players)))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.history.my_actions[0] = True
        elif state.round_number == 0:
            self.history.my_actions[0] = True
        elif self.history.opponent_actions[-1, (self.game_description.n_players - 1) // 2:(self.game_description.n_players + 1) // 2].mean() >= self.game_description.n_players // self.game_description.m:
            self.history.my_actions[state.round_number] = True
        else:
            self.history.my_actions[state.round_number] = False
        return Action(self.history.my_actions[state.round_number])

class Strategy_COLLECTIVE_417(BaseStrategy):
    """
    Strategy name: Tit-for-Tat with Adaptive Threshold (TFTA)
    This strategy balances cooperation with self-interest while maintaining a collective approach.
    It encourages a stable community by retaliating against defection but also rewarding consistent cooperation.
    The adaptive nature of the strategy allows it to be effective against a wide range of opponent behaviors.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_coop = math.ceil(game_description.n_players * game_description.m / 100)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators < self.min_coop and state.round_number != self.game_description.n_rounds:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_419(BaseStrategy):
    """
    Tit-for-Tat-Adaptive (TfTA) Strategy for the Collective Risk Dilemma Game.
    This strategy cooperates initially and adapts its actions based on majority cooperation in the previous round.
    It fosters a cooperative environment while being cautious of exploitation by non-cooperators.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.num_players = self.game_description.n_players
        self.m = self.game_description.m
        self.n_minors = math.ceil((self.num_players - self.m) / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None or len(history.opponent_actions) < self.game_description.n_rounds:
            return Action.D
        cooperators = sum(history.opponent_actions[-1])
        if cooperators >= self.num_players // 2:
            return Action.C
        elif cooperators < self.n_minors:
            return Action.D
        else:
            return random.choice([Action.C, Action.D])

class Strategy_COLLECTIVE_420(BaseStrategy):
    """
    Adaptive Tit-for-Tat strategy for the Collective Risk Dilemma game. Encourages cooperation when others cooperate and retaliates against defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m
        self.num_players = game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return random.choice([Action.C, Action.D])
        cooperators = np.sum(history.opponent_actions[-1]) if history is not None else 0
        return Action.C if cooperators >= self.min_cooperators else Action.D

class Strategy_COLLECTIVE_421(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFt-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.initial_round = 0
        self.cooperation_threshold = game_description.m
        self.p = 0.5
        self.active_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == self.initial_round:
            return Action.C
        action = Action.D
        if history is not None:
            if history.my_actions[-1] and state.round_number >= self.initial_round + 1:
                self.active_cooperators += 1
                cooperators = min(self.game_description.n_players, self.cooperation_threshold + math.ceil(self.p * (self.game_description.n_players - self.cooperation_threshold) / self.game_description.n_rounds * history.my_actions.size))
                if cooperators > self.game_description.n_players:
                    cooperators = self.cooperation_threshold
                self.cooperation_threshold = cooperators
            else:
                self.active_cooperators -= 1
            if history.my_actions[-1] and self.active_cooperators >= self.game_description.n_players // 2:
                action = Action.C
        if state.round_number == self.game_description.n_rounds:
            if self.cooperation_threshold >= self.game_description.n_players - self.game_description.n_rounds + 1:
                action = Action.C
        return action

class Strategy_COLLECTIVE_423(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) Strategy for Collective Risk Dilemma Game.
    Aligns with a collective mindset by prioritizing mutual cooperation when it is beneficial for the group, while also punishing non-cooperative behavior to deter potential free riders.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_rounds = int(math.ceil(self.game_description.m * self.game_description.n_players / (self.game_description.n_players - 1)))
        self.last_round_cooperated = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and len(history.opponent_actions) == 0):
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        should_cooperate = cooperators >= self.game_description.m if state.round_number > self.min_rounds else False
        if state.round_number == self.game_description.n_rounds or (history is not None and len(history.opponent_actions) < self.min_rounds):
            should_cooperate = False
        return Action.C if should_cooperate else Action.D

class Strategy_COLLECTIVE_425(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold Strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = []
        self.cooperation_threshold = math.ceil(game_description.n_players * (game_description.m / 100))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or not history:
            return Action.C
        self.history = history.my_actions.tolist() if history else []
        n_cooperators = sum(history.opponent_actions[-1, :])
        if n_cooperators >= self.cooperation_threshold and len(self.history) > self.game_description.n_rounds - self.game_description.m + 1:
            return Action.C
        return Action.D

    def update_state(self, state: GameState, history: PlayerHistory):
        self.history = history.my_actions.tolist()
        n_cooperators = sum(history.opponent_actions[-1, :])
        if n_cooperators >= self.cooperation_threshold:
            self.cooperation_threshold += math.ceil((self.game_description.n_players - self.cooperation_threshold) * 0.05)
        elif len(self.history) <= self.game_description.n_rounds - self.game_description.m + 1:
            self.cooperation_threshold = math.ceil(self.game_description.n_players * (self.game_description.m / 100))

class Strategy_COLLECTIVE_426(BaseStrategy):
    """Adaptive Tit-for-Tat with Threshold (ATFT) strategy for Collective Risk Dilemma"""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.states = [Action.C] * self.game_description.n_players
        self.history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or not history:
            return self.states[0]
        my_cooperators = sum(history.opponent_actions[state.round_number - 1])
        if my_cooperators >= self.game_description.n_players - self.game_description.m + 1:
            self.states[-1] = Action.C
            return Action.C
        elif my_cooperators < self.game_description.m - 1:
            self.states[-1] = Action.D
            return Action.D
        else:
            opponent = np.argwhere(history.opponent_actions[state.round_number - 1, :])[0][0]
            if history.opponent_actions[state.round_number - 1, opponent] == Action.C:
                self.states[-1] = Action.C
                return Action.C
            else:
                self.states[-1] = Action.D
                return Action.D

class Strategy_COLLECTIVE_427(BaseStrategy):
    """
    A Tit-for-Tat Adaptive Cooperation (TTFC) Strategy for Collective Risk Dilemma Game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = [{'round': 0, 'majority': False}]

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None or state.round_number == 0:
            majority = self.game_description.n_players % 2 != 0 and len(self.history) >= 2 and (sum(map(lambda x: x['majority'], self.history[-2:])) > self.game_description.m)
            return Action.C if majority else Action.D
        if len(self.history) == state.round_number:
            majority = self.count_majority()
        else:
            majority = self.calculate_majority(self.history[-1]['majority'], self.history[-2]['majority'])
        action = Action.C if majority else Action.D
        self.history.append({'round': state.round_number, 'majority': majority, 'action': action})
        return action

    def count_majority(self) -> bool:
        majority = False
        if len(self.history) > 1 and self.game_description.n_players % 2 == 1:
            majority = sum(map(lambda x: x['majority'], self.history[-2:])) > self.game_description.m
        else:
            majority = sum(map(lambda x: x['majority'], self.history)) >= self.game_description.m * len(self.history) // 2
        return majority

    def calculate_majority(self, prev_maj, current_maj):
        if self.game_description.n_players % 2 == 1:
            majority = prev_maj + current_maj > self.game_description.m
        else:
            majority = prev_maj + current_maj >= self.game_description.m
        return majority

class Strategy_COLLECTIVE_428(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperative Threshold (ACT) strategy in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.n_players
        self.history = PlayerHistory(np.zeros((1, 2), dtype=bool), np.zeros(1), np.zeros((1, self.game_description.n_players), dtype=bool), np.zeros(1))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        self.history = history
        action = Action.D
        cooperators = sum(self.history.opponent_actions[-1, :])
        if state.round_number == self.history.my_payoffs.size:
            action = Action.C
        elif cooperators >= self.m - 1 and self.m > 1:
            action = Action.C
        self.history = history or PlayerHistory(self.history.my_actions, self.history.my_payoffs, self.history.opponent_actions, self.history.opponent_payoffs)
        if cooperators >= self.m:
            self.m = max(self.m - 1, 1)
        return action

class Strategy_COLLECTIVE_429(BaseStrategy):
    """
    A strategy that mimics the majority of players' actions from the previous round, promoting reciprocity and fostering trust within the group.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1] if history else np.zeros(self.n - 1))
        majority_cooperated = cooperators >= (self.n - 1) // 2
        if state.round_number == self.game_description.n_rounds:
            return Action.C if majority_cooperated else Action.D
        return Action(majority_cooperated)

class Strategy_COLLECTIVE_430(BaseStrategy):
    """
    The Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT) strategy for Collective Risk Dilemma games.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = None
        self.history = []

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if not self.history and state.round_number == 0:
            return Action.D
        if not self.history:
            self.history = [[Action.D]]
        current_cooperators = sum(history.opponent_actions[-1])
        cooperation_percentage = current_cooperators / (state.round_number * self.game_description.n_players)
        if state.round_number == len(self.history):
            self.adjust_CT(cooperation_percentage, len(self.history))
            action = Action.C if cooperation_percentage >= self.cooperation_threshold else Action.D
        else:
            action = Action.C if cooperation_percentage >= self.cooperation_threshold else Action.D
        self.update_history(history)
        return action

    def initial_CT(self, n: int, m: int):
        if self.history:
            return (n - m + 1) / (n - 1)
        return math.ceil((n - m + 1) / (n - 1))

    def calculate_percentage(self, history: PlayerHistory):
        current_cooperators = sum(history.opponent_actions[-1])
        total_players = len(history) * self.game_description.n_players
        return current_cooperators / total_players

    def adjust_CT(self, percentage: float, round_number: int):
        adaptation_factor = 0.95 ** (round_number - len(self.history))
        self.cooperation_threshold = self.initial_CT(self.game_description.n_players, self.game_description.m) * adaptation_factor

    def update_history(self, history: PlayerHistory):
        self.history.append([history.my_actions[-1]])

class Strategy_COLLECTIVE_431(BaseStrategy):
    """
    Adaptive Tit-for-Tat Strategy in Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperators_count = 0
        self.history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is not None:
            self.history = self.history + [history.my_actions[-1]]
        cooperators_count = sum(self.history[-self.game_description.m:])
        if cooperators_count >= self.game_description.m:
            action = Action.C
        else:
            action = Action.D
            if cooperators_count > 0:
                self.cooperators_count -= 1
        return action

class Strategy_COLLECTIVE_432(BaseStrategy):
    """
    Strategy implementing Tit-for-Tat Adaptive Cooperation (TFT-AC).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            sum_cooperation = 0
        else:
            sum_cooperation = np.sum(history.opponent_actions[-1])
        if sum_cooperation >= self.min_cooperators:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_434(BaseStrategy):
    """
    A Collective Risk Dilemma strategy implementing Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.act = math.ceil(game_description.m - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            cooperators = 0
            for _ in range(state.round_number):
                cooperators += sum(history.opponent_actions[_, :].tolist())
            self.act = math.ceil(self.game_description.m - 1) if cooperators >= self.game_description.n_players - (self.game_description.n_players - self.game_description.m) else self.act - 1
        cooperators = sum(history.opponent_actions[state.round_number - 1, :])
        if cooperators >= self.act:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_435(BaseStrategy):
    """
    The Tit for Tat Adaptive (TfTA) strategy demonstrates goodwill by cooperating initially and then cooperating with opponents if at least m-1 players also cooperated in the previous round. TfTA adapts to opponent behavior by imitating their actions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.k = game_description.k
        self.adaptation_rounds = math.ceil(game_description.n_players / 2)
        self.opponent_recent_action = None
        self.current_history = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is not None:
            self.current_history = history
        if state.round_number == 0:
            return Action.C
        else:
            cooperators = sum(self.current_history.opponent_actions[-1, :])
            if cooperators >= self.m - 1 or (cooperators < self.m - 1 and self.opponent_recent_action == Action.D):
                return Action.C
            elif cooperators < self.m - 1 and self.opponent_recent_action == Action.C:
                if state.round_number <= self.adaptation_rounds:
                    return self.opponent_recent_action
                else:
                    self.opponent_recent_action = None
            else:
                self.opponent_recent_action = self.current_history.opponent_actions[-1, np.argmax(self.current_history.opponent_payoffs[-1])]
        return Action.D

class Strategy_COLLECTIVE_436(BaseStrategy):
    """
    Strategy that follows the Tit-for-Tat Adaptive (TfTA) approach in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None or len(history.my_actions) < self.game_description.n_rounds - 1:
            return Action.D
        majority_cooperated = np.count_nonzero(history.opponent_actions[-1]) >= self.n_players - (self.m - 1)
        i_cooperated = history.my_actions[-1] == Action.C
        if majority_cooperated and i_cooperated:
            return Action.C
        elif majority_cooperated or np.count_nonzero(history.my_actions[-1]) < self.m:
            return Action.D
        return Action.D

class Strategy_COLLECTIVE_438(BaseStrategy):
    """
    Tit-for-Tat strategy with Adaptive Cooperation Threshold for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = math.ceil(game_description.n_players * 0.5)
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros(game_description.n_rounds))
        self.p = 0.65
        self.q = 0.35

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[state.round_number - 1, :])
        self.history.my_actions[state.round_number - 1] = cooperators >= self.threshold
        if state.round_number == self.game_description.n_rounds:
            return self.decide_last_round(cooperators)
        self.history.my_payoffs[state.round_number - 1] = 1 - self.history.my_actions[state.round_number - 1] if cooperators < self.threshold else 1 - self.history.my_actions[state.round_number - 1] + self.game_description.k
        self.adjust_threshold(cooperators)
        return Action.C if self.history.my_actions[state.round_number - 1] else Action.D

    def decide_last_round(self, cooperators):
        if cooperators >= self.threshold * (1 + self.q) or cooperators <= self.threshold * (1 - self.p):
            return Action.C
        return Action.D

    def adjust_threshold(self, cooperators):
        if cooperators / self.game_description.n_players < self.p:
            self.threshold += 1
        elif cooperators / self.game_description.n_players > self.q:
            self.threshold -= 1

class Strategy_COLLECTIVE_439(BaseStrategy):
    """
    Adaptive Tit-for-Tat strategy for Collective Risk Dilemma game.
    Strategy encourages reciprocity and collective success by rewarding cooperation when a sufficient number of players cooperate, and punishing defection in the previous round with defect.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators < self.m or cooperators >= self.game_description.n_players - (self.m - 1):
            return Action.D
        return Action.C

class Strategy_COLLECTIVE_440(BaseStrategy):
    """
    A strategy inspired by Tit-for-Tat, with an adaptive cooperation threshold for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = min(game_description.n_players, game_description.m)
        self.history = PlayerHistory(my_actions=np.zeros(shape=(1, 2), dtype=bool), my_payoffs=np.zeros(shape=1, dtype=float), opponent_actions=np.zeros(shape=(1, game_description.n_players), dtype=bool), opponent_payoffs=np.zeros(shape=1, dtype=float))

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if history is not None and state.round_number != 0:
            self.history = history
        cooperation = Action.C
        defection = Action.D
        if state.round_number == 0:
            return cooperation
        cooperators = sum(self.history.opponent_actions[-1, :])
        if cooperators < self.cooperation_threshold:
            return defection
        reward_factor = math.floor((cooperators - (self.cooperation_threshold - 1)) / (self.game_description.n_players - self.cooperation_threshold + 1) * (self.game_description.k - 1) + 1)
        self.cooperation_threshold = min(self.game_description.m + reward_factor, self.game_description.n_players)
        return cooperation

class Strategy_COLLECTIVE_441(BaseStrategy):
    """
    A strategy for the Collective Risk Dilemma based on Tit-for-Tat, which cooperates in the initial round and responds to opponents' cooperation in subsequent rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_defected_in_first_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if state.round_number == 1:
            self.opponent_defected_in_first_round = history.opponent_actions[0, 0] == Action.D
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.game_description.m and (not self.opponent_defected_in_first_round) or state.round_number == self.game_description.n_rounds:
            return Action.C
        if cooperators < self.game_description.m:
            if self.opponent_defected_in_first_round:
                self.opponent_defected_in_first_round = False
                return Action.C
            else:
                self.opponent_defected_in_first_round = True
        return Action.D

class Strategy_COLLECTIVE_442(BaseStrategy):
    """
    Adaptive Tit-for-Tat strategy for the Collective Risk Dilemma game.
    Encourages cooperation through an initial forgiveness phase and reciprocating other players' actions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.initial_forgiveness = math.ceil(game_description.n_rounds / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number < self.initial_forgiveness:
            return Action.C
        elif history is not None:
            previous_round = len(history.opponent_actions) - 1
            cooperators = sum(history.opponent_actions[previous_round])
            if cooperators < self.game_description.m or (cooperators >= self.game_description.n_players // 2 and random.random() > 0.5):
                return Action.D
        return Action.C

class Strategy_COLLECTIVE_443(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) Strategy for the Collective Risk Dilemma Game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = math.ceil(game_description.n_players / 2)
        self.threshold_increase = math.floor((game_description.n_players - 1) / 4)
        self.adaptive_m = self.m
        self.cooperation_streak = 0
        self.last_round_threshold = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.adaptive_m and self.cooperation_streak >= self.threshold_increase:
            self.adaptive_m = max(self.adaptive_m - self.threshold_increase, self.m)
            self.cooperation_streak = 0
        elif cooperators >= self.m:
            self.cooperation_streak += 1
        else:
            self.cooperation_streak = 0
        if self.adaptive_m > self.game_description.n_players - 1:
            self.adaptive_m = self.m
        elif state.round_number >= math.floor(self.game_description.n_rounds / 4) and cooperators < math.ceil((self.game_description.n_players + 1) / 2):
            self.adaptive_m += self.threshold_increase
            if self.adaptive_m > self.game_description.n_players - 1:
                self.adaptive_m = self.m
        if state.round_number == self.game_description.n_rounds - 1:
            self.last_round_threshold = self.adaptive_m
        return Action.C if cooperators >= self.adaptive_m else Action.D

    def get_current_cooperation_threshold(self) -> int:
        return self.adaptive_m if self.last_round_threshold is not None else self.m

class Strategy_COLLECTIVE_444(BaseStrategy):
    """
    Adaptive Tit-for-Tat strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None or state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators < self.min_cooperators:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_445(BaseStrategy):
    """
    Tit-for-Tat with Adaptation (TFT-A) Strategy for the Collective Risk Dilemma Game
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_round_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and len(history.opponent_actions) > 0:
            self.last_round_cooperators = sum(history.opponent_actions[-1, :])
            if self.last_round_cooperators >= self.game_description.n_players * (self.game_description.m / self.game_description.n_players):
                return Action.C
            else:
                return Action.D
        if state.round_number == self.game_description.n_rounds - 1 and self.last_round_cooperators < self.game_description.n_players * (self.game_description.m / self.game_description.n_players):
            return Action.D
        return Action.C

class Strategy_COLLECTIVE_446(BaseStrategy):
    """
    Strategy name: Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)
    A strategy that fosters mutual cooperation while being resilient against potential defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.cooperative_threshold = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            self.cooperative_threshold = self.m + math.floor((self.n_players - self.m) / 2)
            return Action.C
        elif state.round_number == self.r:
            cooperators = sum(history.opponent_actions[state.round_number - 1, :])
            if cooperators >= self.m:
                return Action.C
            else:
                return Action.D
        elif state.round_number < self.r / 2:
            self.cooperative_threshold -= (self.m - math.floor(self.r / 2)) / self.r / 2
        elif state.round_number > self.r / 2 and state.round_number < self.r:
            self.cooperative_threshold += (self.r - state.round_number) / (self.r / 2) * (self.m - self.cooperative_threshold)
        cooperators = sum(history.opponent_actions[state.round_number - 1, :])
        if cooperators >= self.cooperative_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_447(BaseStrategy):
    """
    TFT-ACT is a strategy in Collective Risk Dilemma games that promotes cooperation and punishes defection. It seeks a balance between selfish behavior and altruism.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros(game_description.n_rounds))
        self.m = game_description.m
        self.action = Action.C

    def update_history(self, round_number, cooperation_level):
        self.history.my_actions[round_number - 1] = self.action == Action.C
        self.history.my_payoffs[round_number - 1] = cooperation_level * (self.action != Action.C) + (1 - cooperation_level) * (self.action == Action.C)
        self.history.opponent_actions[round_number - 1, :] = cooperation_level

    def decide_action(self, current_round):
        if current_round == 0:
            return Action.C
        cooperation_prev_round = self.history.opponent_actions[-1].mean()
        if cooperation_prev_round >= self.m / self.game_description.n_players:
            return Action.C
        elif cooperation_prev_round < self.m / self.game_description.n_players and self.action == Action.D:
            return Action.D
        else:
            return self.action

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if history is None:
            self.update_history(1, 0)
            return self.decide_action(1)
        else:
            self.history = history
            return self.decide_action(state.round_number + 1)

class Strategy_COLLECTIVE_448(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATfT) for Collective Risk Dilemma
    This strategy maintains trust and reciprocity, promoting collective collaboration while also retaliating against defections to deter long-term exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.strategy = [Action.C] * self.game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and state.round_number > 0:
            last_round = state.round_number - 1
            self.strategy[last_round] = history.opponent_actions[last_round, -1]
        return self.strategy[state.round_number]

class Strategy_COLLECTIVE_449(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATfT) for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_action_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if len(self.opponent_action_history) < state.round_number:
            self.opponent_action_history += [None] * (state.round_number - len(self.opponent_action_history))
        if history is not None and self.opponent_action_history[-1] is not None:
            opponent_last_action = self.opponent_action_history[-1][state.round_number - 1]
        else:
            opponent_last_action = None
        if opponent_last_action is None:
            return Action.C
        elif opponent_last_action:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_450(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = math.ceil(game_description.n_players * 0.5)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_452(BaseStrategy):
    """
    A Tit-for-Tat adaptive strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.previous_action = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.previous_action = Action.C
            return self.previous_action
        action = self.previous_action
        cooperators = np.sum(history.opponent_actions[-1, :])
        if cooperators >= self.game_description.m and action == Action.C:
            self.previous_action = Action.C
        elif cooperators < self.game_description.m and action == Action.C:
            self.previous_action = Action.D
        elif cooperators >= self.game_description.m and action == Action.D:
            self.previous_action = Action.C
        return self.previous_action

class Strategy_COLLECTIVE_453(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Gradual Cooperative Escalation (ATFE) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.round_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        action = Action.D
        if state.round_number == 0:
            action = Action.C
            self.round_history.append((state.round_number, np.zeros(self.game_description.n_players)))
        elif state.round_number < self.game_description.n_rounds:
            round_num, coop_count = self.round_history[-1]
            cooperators = sum(history.opponent_actions[round_num - 1, :]) if history else coop_count[1]
            if cooperators > self.game_description.m // 2:
                action = Action.C
            elif cooperators < self.game_description.m // 2:
                action = Action.D
            self.round_history.append((state.round_number, np.array([cooperators > 0] + history.my_actions[1:] if history else [0] * self.game_description.n_rounds - 1)))
        elif state.round_number == self.game_description.n_rounds:
            action = Action.C
        return action

class Strategy_COLLECTIVE_454(BaseStrategy):
    """
    Strategy Name: Adaptive Cooperative Tit-for-Tat (ACT)
    Strategy Description: Reciprocates cooperative actions while also being cautious about potential defections to encourage cooperation among players over multiple rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1] if history else np.zeros((1, self.game_description.n_players), dtype=bool))
        if cooperators >= self.min_cooperators:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_455(BaseStrategy):
    """
    A Collective Risk Dilemma strategy that implements Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-1])
        if state.round_number < self.game_description.n_rounds - 1:
            if cooperators >= math.ceil(self.game_description.n_players / 2):
                return Action.C
            else:
                return Action.D
        else:
            return Action.C
        self.history.append(action_to_int[history.my_actions[-1]] if history is not None else 0)
        return action_to_int[Action.C]
    action_to_int = {Action.D: 0, Action.C: 1}

class Strategy_COLLECTIVE_456(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) Strategy for the Collective Risk Dilemma game.
    The strategy cooperates in the first round and reciprocates the opponent's actions thereafter.
    In the final critical stages, the strategy maintains cooperation if more than m-1 opponents have cooperated.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = []

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        action = Action.D
        if len(self.opponent_history) > 0:
            last_round = self.opponent_history[-1]
            cooperators = sum(last_round)
            if cooperators >= self.game_description.m - 1 and state.round_number != self.game_description.n_rounds - 1:
                action = Action.C
        self.opponent_history.append(history.opponent_actions[-1])
        return action

class Strategy_COLLECTIVE_457(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_action = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if history is None:
            self.last_action = Action.C
            return self.last_action
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        if history.my_actions[-1] == self.last_action and np.sum(history.opponent_actions[-1, :]) >= self.game_description.m:
            self.last_action = Action.C
            return self.last_action
        else:
            self.last_action = Action.D
            return self.last_action

class Strategy_COLLECTIVE_458(BaseStrategy):
    """
    The Adaptive Tit-for-Tat (ATfT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros((game_description.n_rounds, game_description.n_players)))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        self.history.my_actions[-1] = Action.D if history is None else history.my_actions[-1]
        self.history.my_payoffs[-1] = np.mean(history.opponent_payoffs[-1]) if history is not None else 1
        if history is None:
            cooperators = math.ceil((self.game_description.n_players - 1) / 2)
        else:
            cooperators = sum(history.opponent_actions[-1]) + 1
        if state.round_number > 0 and (cooperators >= self.game_description.m - 1 if self.history.my_actions[-1] else cooperators < self.game_description.m - 1) == (self.history.my_actions[-2] if len(self.history.opponent_payoffs) > 1 else True):
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_459(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) Strategy for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperative_ratio = 0

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is not None:
            self.cooperative_ratio = sum(history.my_actions[-self.game_description.n_rounds:-1]) / self.game_description.n_rounds
            cooperation_threshold = self.game_description.m / self.game_description.n_players
            if self.cooperative_ratio >= cooperation_threshold:
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_461(BaseStrategy):
    """Adaptive Tit-for-Tat for Collective Risk Dilemma"""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :]) if history else 0
        if cooperators < self.m:
            action = history and Action.D if np.sum(history.my_actions[-1]) > len(history.my_actions) - self.m else Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.C if cooperators >= self.m else Action.D if history and np.sum(history.my_actions[-1]) < self.m else Action.C
        else:
            action = Action.C if cooperators >= self.m else Action.D
        return action

class Strategy_COLLECTIVE_462(BaseStrategy):
    """
    A strategy that cooperates in the first round and reciprocates opponent's actions in subsequent rounds, adapting to their behavior.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.round_number = 0
        self.opponent_actions = []

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if history is None and state.round_number == 0:
            return Action.C
        self.opponent_actions.append(np.mean(history.opponent_actions[-1]))
        self.round_number += 1
        if self.round_number < self.game_description.n_rounds:
            if np.mean(self.opponent_actions[-1]) > 0.5:
                return Action.C
            else:
                return Action.D
        return Action.C

class Strategy_COLLECTIVE_463(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATFT) for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = 1
        self.current_threshold = self.threshold

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            cooperators = 0
        else:
            cooperators = sum(history.opponent_actions[-1])
        if cooperators >= self.game_description.m and state.round_number > 1:
            self.current_threshold += 1
        return Action(int(cooperators >= self.current_threshold))

class Strategy_COLLECTIVE_464(BaseStrategy):
    """
    A strategy inspired by the Tit-for-Tat game in the Collective Risk Dilemma.
    It starts cooperative, then adapts based on past actions and majority cooperation of opponents.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is None:
            history = PlayerHistory(my_actions=np.array([[Action.C]]), my_payoffs=np.array([0]), opponent_actions=np.zeros((1, self.game_description.n_players)), opponent_payoffs=np.zeros(self.game_description.n_players))
        self.history.append(history.my_actions[0])
        cooperators = sum(history.opponent_actions[-1, :])
        if len(self.history) > state.round_number and self.history[-state.round_number] == Action.C and (cooperators >= self.game_description.m or cooperators / (self.game_description.n_players - 1) > 0.5):
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_466(BaseStrategy):
    """
    Tit-for-Tat with Adaptation Strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.coop_threshold = int(self.game_description.n_players / 2)
        self.forgiveness_count = 3
        self.punishment_count = 0
        self.forgiven = False
        self.last_opponent_action = Action.D

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_actions = history.opponent_actions[-1] if history else np.zeros(self.game_description.n_players, dtype=int)
        cooperators = sum(opponent_actions)
        if self.last_opponent_action is Action.D and cooperators >= self.coop_threshold:
            self.forgiven = True
            self.punishment_count = 0
        if self.last_opponent_action == Action.C and cooperators < self.coop_threshold:
            self.punishment_count += 1
            if self.punishment_count > self.forgiveness_count:
                return Action.D
        elif self.last_opponent_action == Action.D and cooperators >= self.coop_threshold:
            self.punishment_count = 0
            self.forgiven = True
        if self.last_opponent_action is Action.D and cooperators >= self.coop_threshold:
            self.punishment_count = 0
            self.forgiven = True
        if self.forgiven and np.all(opponent_actions == 1):
            return Action.C
        self.last_opponent_action = opponent_actions[-1]
        return Action.D

class Strategy_COLLECTIVE_467(BaseStrategy):
    """
    A collective risk dilemma strategy that employs a tit-for-tat adaptive approach.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m
        self.r = self.game_description.n_rounds
        self.k = self.game_description.k
        self.previous_actions = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None and state.round_number == 0:
            return Action.C
        self.previous_actions.append(Action(int(history.my_actions[-1]) == Action.C))
        current_actions = history.my_actions[-self.r:] if history is not None else [False] * self.r
        coop_count = sum(current_actions)
        if coop_count < self.m:
            return Action.D
        elif coop_count == self.m:
            return Action.C
        elif coop_count > self.m and state.round_number - len(self.previous_actions) <= self.r:
            if all((action == Action.C for action in current_actions)):
                return Action.C * 2
            else:
                return Action.D
        else:
            super_coop = [action == Action.C * 2 for action in self.previous_actions[-self.r:]]
            if sum(super_coop) > len(super_coop) // 2:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_468(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation (TFT-AC)
    Strategy Summary: Cooperates in the first round, responds to opponent's actions from previous rounds. Implement a forgiveness mechanism by cooperating again after a string of mutual defections. Analyze the current payoff situation for the last round and consider playing D if cooperating would result in a negative total game payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_action_history = []

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if history is None or state.round_number == 0:
            return Action.C
        if len(self.opponent_action_history) > 0 and state.round_number < self.game_description.n_rounds - 1:
            opponent_last_action = self.opponent_action_history[-1]
            cooperators = sum([history.opponent_actions[state.round_number, i] for i in range(self.game_description.n_players)])
            if cooperators >= self.game_description.m and opponent_last_action == Action.C:
                return Action.C
            elif cooperators < self.game_description.m and opponent_last_action == Action.D:
                return Action.D
            else:
                return Action.C
        elif sum(history.my_payoffs) + (self.game_description.k - 1) * len(history.opponent_actions) < 0:
            return Action.D
        else:
            return Action.C
        self.opponent_action_history.append(history.my_actions[-1])
        return Action.C

class Strategy_COLLECTIVE_469(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = None
        self.cooperation_threshold = self.game_description.n_players // 2
        self.k = int(game_description.k * (self.game_description.n_players - 1))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.history = PlayerHistory(np.zeros(self.game_description.n_rounds, dtype=bool), np.zeros(self.game_description.n_rounds), np.zeros((self.game_description.n_rounds, self.game_description.n_players - 1), dtype=bool), np.zeros((self.game_description.n_rounds, self.game_description.n_players - 1)))
            if state.round_number == 0:
                return Action.C
            else:
                self.cooperation_threshold = 0 if self.history.opponent_actions[0, 1 - self.__class__] == 0 else self.game_description.n_players // 2
        action = Action.C
        if state.round_number > 1:
            cooperation_ratio = np.mean(self.history.opponent_actions[state.round_number - self.k:state.round_number, :])
            self.cooperation_threshold = math.floor((cooperation_ratio + 1) * (self.game_description.n_players - 1)) if cooperation_ratio >= self.game_description.m - 1 else self.game_description.m
            if cooperation_ratio >= self.game_description.m:
                action = Action.C
            elif cooperation_ratio < self.game_description.m - 1:
                action = Action.D
        self.history.my_actions[state.round_number] = bool(action)
        if state.round_number > 1:
            self.history.my_payoffs[state.round_number] = self._calculate_payoff(state, self.history)
        return action

    def _calculate_payoff(self, state: GameState, history: PlayerHistory) -> float:
        cooperators = np.sum(history.opponent_actions[state.round_number - 1])
        if cooperators < self.game_description.m:
            return 1
        return 1 + self.game_description.k * (self.game_description.n_players - np.sum(history.opponent_actions[state.round_number - 1]))

class Strategy_COLLECTIVE_471(BaseStrategy):
    """
    The Adaptive Tit-for-Tat (ATfT) strategy for the Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :]) if history else 0
        return Action.C if cooperators >= self.m else Action.D

class Strategy_COLLECTIVE_472(BaseStrategy):
    """
    Adaptive Tit-for-Tat Strategy for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(game_description.n_rounds), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players - 1)), np.zeros((game_description.n_rounds, game_description.n_players - 1)))

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if state.round_number == 0:
            self.history.my_actions[0] = True
            return Action.C
        my_cooperators = self.history.my_actions[-1]
        opponent_cooperators = sum(self.history.opponent_actions[-1, :])
        if my_cooperators and opponent_cooperators >= self.game_description.m or (not my_cooperators and (not opponent_cooperators)):
            self.history.my_actions[state.round_number] = True
            return Action.C
        self.history.my_actions[state.round_number] = False
        if len(self.history) > state.round_number and self.history.opponent_actions[-1, state.round_number - 1] == False:
            self.history.my_actions[state.round_number] = True
        return Action.D

class Strategy_COLLECTIVE_473(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperative Threshold (TFT-ACT) Strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = None
        self.cooperative_threshold = (self.game_description.n_players - self.game_description.m + 1) / self.game_description.n_players
        self.overall_cooperation_rate = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.history = np.zeros((1, self.game_description.n_players), dtype=np.bool_)
            return Action.C
        if state.round_number == 0:
            self.history = history.opponent_actions
        action = Action.D
        opponent_cooperators = np.sum(self.history[-1, :])
        if opponent_cooperators >= math.ceil(self.game_description.n_players * self.cooperative_threshold):
            action = Action.C
        self.history = np.vstack((self.history, self.history[-1]))
        self.overall_cooperation_rate = np.mean(self.history[:, -1]) if len(self.history) > 0 else 0.0
        if state.round_number != self.game_description.n_rounds:
            if opponent_cooperators < math.ceil(self.game_description.m):
                if len(self.history) <= 5 * self.game_description.n_players:
                    self.cooperative_threshold += 0.2
            elif self.overall_cooperation_rate > self.cooperative_threshold:
                self.cooperative_threshold = max(self.cooperative_threshold, (self.game_description.n_players - self.game_description.m + 1) / self.game_description.n_players)
            else:
                self.cooperative_threshold *= (self.game_description.n_rounds + 1) / self.game_description.n_rounds
        return action

class Strategy_COLLECTIVE_475(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.last_round_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-1]) if history else 0
        self.cooperation_threshold = max(self.cooperation_threshold - 1, 1) if cooperators < self.cooperation_threshold else self.cooperation_threshold
        return Action.C if cooperators >= self.cooperation_threshold else Action.D

    def last_round_payoff(self, history: PlayerHistory) -> float:
        """
        Calculate the payoff for the last round of the strategy considering any "last chance" mechanism.
        """
        cooperators = np.sum(history.opponent_actions[-1]) if history else 0
        return 1 + self.game_description.k if cooperators >= self.game_description.m else 1

class Strategy_COLLECTIVE_479(BaseStrategy):
    """
    A Tit-for-Tat Adaptive (TFT-A) strategy for the Collective Risk Dilemma.
    This strategy encourages reciprocity and contributes to achieving the minimum threshold needed for a successful community project.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n = game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1] if history is not None else [False] * self.n)
        majority_cooperate = cooperators >= (self.m + 1) // 2
        if state.round_number == self.game_description.n_rounds - 1 and cooperators >= self.m:
            return Action.C
        return Action.C if majority_cooperate or cooperators >= self.m else Action.D

class Strategy_COLLECTIVE_480(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            self.cooperation_count = sum(history.my_actions)
        cooperation_in_last_round = sum(history.opponent_actions[-1, :]) >= self.game_description.m
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C if cooperation_in_last_round else Action.D
        return Action.C if cooperation_in_last_round else Action.D

class Strategy_COLLECTIVE_481(BaseStrategy):
    """
    A Tit-for-Tat adaptive strategy for the Collective Risk Dilemma game.
    This strategy cooperates initially and follows a reciprocal approach by cooperating if the opponent cooperated in the previous round, otherwise defects.
    In the first round, it starts with cooperation; in the last round, it cooperates as a final act of cooperation unless the opponent defected during the last round, in which case it defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_round_action = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            self.last_round_action = Action.C
        elif state.round_number < self.game_description.n_rounds:
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators >= self.game_description.n_players // self.game_description.m and self.last_round_action is not None and (self.last_round_action == Action.C):
                return self.last_round_action
            self.last_round_action = Action.D
        elif self.last_round_action is None or self.last_round_action == Action.C:
            self.last_round_action = Action.C
        elif history.opponent_actions[-1, 0] == Action.D:
            self.last_round_action = Action.D
        return self.last_round_action

class Strategy_COLLECTIVE_483(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation (TFT-AC)
    A collective risk dilemma strategy promoting cooperation and reciprocity.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(self.game_description.n_rounds, dtype=bool), np.zeros(self.game_description.n_rounds), np.zeros((self.game_description.n_rounds, self.game_description.n_players), dtype=bool), np.zeros(self.game_description.n_rounds))
        self.last_round = -1
        self.last_cooperators = 0

    def __call__(self, state: GameState, history: PlayerHistory):
        if state.round_number == 0:
            self.history.my_actions[self.last_round] = True
            return Action.C
        self.last_round += 1
        self.history.my_actions[self.last_round] = True
        if self.last_cooperators >= self.game_description.m:
            cooperators = sum(history.opponent_actions[self.last_round, :])
            if cooperators >= self.game_description.m and sum(self.history.my_actions[:self.last_round + 1]) == sum(self.history.my_actions[:self.last_round]):
                return Action.C
            elif cooperators < self.game_description.m - 1 and self.history.my_actions[self.last_round - 1] and (cooperators + 1 >= self.game_description.m):
                return Action.C
        else:
            return Action.D
        self.history.my_payoffs[self.last_round] = self._calculate_payoff(cooperators, self.last_round)
        self.last_cooperators = cooperators

    def _calculate_payoff(self, cooperators: int, round_number: int) -> float:
        if cooperators < self.game_description.m or sum(self.history.my_actions[:round_number]) == 0:
            return 1
        else:
            return 1 + self.game_description.k

class Strategy_COLLECTIVE_484(BaseStrategy):
    """
    The Tit-for-Tat-Adaptive (TfTA) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number > self.game_description.n_rounds or history is None:
            recent_history = history.opponent_actions[-self.game_description.n_rounds:] if history is not None else np.zeros((self.game_description.n_rounds, self.game_description.n_players), dtype=bool)
            cooperators = np.sum(recent_history[:, -1])
            if cooperators >= self.m:
                return Action.C
            else:
                return Action.D
        else:
            cooperators = sum(history.opponent_actions[state.round_number - 1, :])
            if cooperators >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_485(BaseStrategy):
    """
    Implementation of the Tit-for-Tat-Adaptive (TfT-A) strategy.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m
        self.k = game_description.k
        self.last_opponent_cooperators = 0

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_cooperators = sum(history.opponent_actions[-1])
        if opponent_cooperators >= self.min_cooperators:
            self.last_opponent_cooperators = opponent_cooperators
            return Action.C
        else:
            self.last_opponent_cooperators = 0
            return Action.D

class Strategy_COLLECTIVE_486(BaseStrategy):
    """
    Tit-for-Tat with Adaptation (TfTA) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = int(self.game_description.n_players / 2)
        self.t_iterations = self.game_description.n_players // 10
        self.last_cooperation = 0
        self.current_series = np.zeros(self.game_description.n_rounds, dtype=int)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        action = Action.C if state.round_number == 0 else self._determine_action(history)
        if state.round_number > 1 and state.round_number - self.last_cooperation >= self.t_iterations:
            action = Action.C
        self.last_cooperation = state.round_number if action == Action.C else self.last_cooperation
        return action

    def _determine_action(self, history: PlayerHistory) -> Action:
        cooperators = np.sum(history.opponent_actions[-1, :])
        if cooperators >= self.threshold:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_487(BaseStrategy):
    """
    A collective minded Tit-for-Tat Adaptive (TfTA) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.round_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or len(self.round_history) < self.game_description.n_players - 2:
            return Action.C
        self.round_history = self.round_history[1:] + [history.opponent_actions[-1]] if len(self.round_history) else [history.opponent_actions[-1]]
        most_cooperators = sorted([(player, sum((player == Action.C for player in row))) for row in self.round_history], key=lambda x: -x[1])[0]
        if len(most_cooperators) > 1 or most_cooperators[0][1] == self.game_description.n_players - self.game_description.m + 1:
            return Action.C
        return self.round_history[-self.game_description.n_players + 2][most_cooperators[0][0]]

class Strategy_COLLECTIVE_488(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Threshold (TFTA) strategy. A cooperative strategy that responds to the behavior of other players in the previous round, adapting its threshold for cooperation and defection over time.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_threshold = math.floor(game_description.n_players * 0.8)
        self.reward_threshold = math.ceil(game_description.n_players * 0.2)
        self.cooperator_counts = np.zeros(game_description.n_rounds, dtype=int)
        self.defector_counts = np.zeros(game_description.n_rounds, dtype=int)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.check_cooperator_count(history):
            return Action.C
        else:
            return Action.D

    def check_cooperator_count(self, history: PlayerHistory) -> bool:
        round_number = len(history.opponent_actions) - 1
        cooperator_count = sum(history.opponent_actions[round_number])
        if cooperator_count >= self.game_description.n_players // 2:
            self.cooperator_counts[round_number] += 1
            return True
        if cooperator_count < (self.game_description.n_players - self.punishment_threshold) // 2:
            self.defector_counts[round_number] += 1
        if self.cooperator_counts[round_number] >= self.reward_threshold:
            return True
        elif self.defector_counts[round_number] >= self.punishment_threshold:
            return False
        return False

class Strategy_COLLECTIVE_489(BaseStrategy):
    """
    A Tit-for-Tat (TFt) Adaptive Cooperation Strategy that cooperates unless fewer than m players have cooperated in the previous round or it's the first round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.D
        num_cooperators = np.sum(history.opponent_actions[-1])
        if num_cooperators >= self.m:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_490(BaseStrategy):
    """
    An adaptive version of Tit-for-Tat strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-self.game_description.n_rounds:].flatten())
        if cooperators >= self.min_cooperators and state.round_number != self.game_description.n_rounds:
            return Action.C
        elif cooperators < self.min_cooperators and state.round_number != self.game_description.n_rounds:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_491(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Cooperative Adjustment (TFT-CA)

    This strategy implements the Tit-for-Tat with Cooperative Adjustment strategy in the Collective Risk Dilemma game. It starts by initiating cooperation, punishes defectors, rewards cooperators, and gradually evolves its cooperation threshold based on the collective behavior of other players.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history_length = int(0.1 * game_description.n_rounds)
        self.m_threshold = None
        self.cooperative_players = np.zeros(self.history_length, dtype=np.int32)

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or self.m_threshold is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= math.floor((self.game_description.n_players - self.m_threshold) / 2):
            return Action.C
        return Action.D
        if state.round_number > self.history_length:
            consistent_cooperators = sum(self.cooperative_players) >= self.m_threshold * 2
            if consistent_cooperators:
                self.m_threshold += 1
            elif len(self.cooperative_players) < self.m_threshold:
                self.m_threshold -= 1
        self.cooperative_players[-self.history_length:] = np.array([int(action == Action.C) for action in history.my_actions[-self.history_length:]])

class Strategy_COLLECTIVE_492(BaseStrategy):
    """
    Tit-for-Tat with Risk Aversion (TfT-RA) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperators_threshold = math.ceil(game_description.m * 0.5)
        self.current_round_cooperators = 0
        self.streak_length = 0
        self.reward_aversion_threshold = (self.game_description.k - 1) * game_description.n_players / 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            self.update_cooperators_and_streak(history)
        if state.round_number == len(history.opponent_actions) - 1:
            return self.last_round_decision()
        return self.general_decision()

    def update_cooperators_and_streak(self, history: PlayerHistory):
        self.current_round_cooperators = sum(history.opponent_actions[-1])
        if self.current_round_cooperators >= self.cooperators_threshold:
            self.streak_length += 1
        else:
            self.streak_length = 0

    def general_decision(self):
        cooperators_ratio = self.current_round_cooperators / self.game_description.n_players
        if cooperators_ratio >= self.cooperators_threshold:
            return Action.C
        return Action.D

    def last_round_decision(self):
        if self.streak_length >= self.game_description.n_rounds - 1:
            return general_decision()
        if self.current_round_cooperators >= self.cooperators_threshold:
            return Action.C
        if self.current_reward_aversion_potential() > 0:
            return Action.D
        return Action.C

    def current_reward_aversion_potential(self):
        reward_aversion_potential = (self.game_description.k - 1) * self.streak_length * (self.cooperators_threshold - self.current_round_cooperators + 1)
        return reward_aversion_potential - self.reward_aversion_threshold

class Strategy_COLLECTIVE_493(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Threshold (TFTA) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = math.ceil(game_description.m - 1)
        self.streak = 0
        self.history_len = game_description.n_rounds if game_description.n_rounds > 0 else 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and self.history_len > state.round_number:
            cooperators = sum(history.opponent_actions[state.round_number - 1])
            if cooperators >= self.threshold:
                self.streak += 1
                self.threshold += 1
            elif cooperators < self.threshold and self.threshold > 1:
                self.streak -= 1
                self.threshold -= 1
            if self.threshold == 1 and cooperators == 0 and (self.streak >= self.game_description.n_rounds // 2):
                return Action.D
        return Action.C if cooperators >= self.threshold else Action.D

class Strategy_COLLECTIVE_494(BaseStrategy):
    """
    Adaptive Tit-for-Tat strategy for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation = True
        self.defected_players = set()
        self.round_delay = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number - 1
        actions = history.opponent_actions[current_round, :] if history else np.zeros(self.game_description.n_players)
        cooperators = sum(actions)
        majority_cooperated = cooperators >= math.ceil(self.game_description.n_players * 0.5)
        if self.cooperation and len(self.defected_players) < self.game_description.n_players - self.game_description.m:
            pass
        elif not self.cooperation and len(self.defected_players) >= self.game_description.n_players - self.game_description.m:
            self.cooperation = False
        elif current_round % self.round_delay == 0:
            if self.cooperation:
                self.defected_players.add(current_round)
            elif not self.cooperation and sum(actions[-self.round_delay:]) == len(self.defected_players):
                self.cooperation = True
                self.defected_players.clear()
        return Action.C if self.cooperation else Action.D

class Strategy_COLLECTIVE_495(BaseStrategy):
    """
    Tit-for-Tat Adaptive (TFT-A) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_round = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators < self.game_description.m or state.round_number == self.game_description.n_rounds - 1:
            action = self.last_round if self.last_round is not None else Action.C
        else:
            action = self.last_round if self.last_round == Action.D else Action.C
        self.last_round = action
        return action

class Strategy_COLLECTIVE_497(BaseStrategy):
    """
    A Tit-for-Tat with Adaptive Cooperation Threshold (TTAT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.past_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is not None:
            self.past_cooperators = sum(history.my_actions[:-1])
            if state.round_number < self.game_description.n_rounds - 1:
                if self.past_cooperators < self.cooperation_threshold:
                    return Action.D
                else:
                    return Action.C
            if self.past_cooperators >= self.game_description.n_players - self.game_description.m * (self.game_description.n_rounds - 1):
                self.cooperation_threshold = self.game_description.n_players
            elif self.past_cooperators < self.cooperation_threshold:
                self.cooperation_threshold -= math.ceil(self.cooperation_threshold / self.game_description.n)
        return Action.C if self.cooperation_threshold >= self.past_cooperators else Action.D

class Strategy_COLLECTIVE_499(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) Strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.average_cooperators = 0.0
        self.total_cooperators = 0
        self.rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            return Action.D
        self.total_cooperators += sum(history.opponent_actions[-1, :])
        self.rounds += 1
        if state.round_number == self.game_description.n_rounds or self.rounds % self.game_description.n_rounds == 0:
            self.average_cooperators = self.total_cooperators / self.rounds
        m_prime = math.ceil((1 + self.average_cooperators) / 2)
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= m_prime:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_500(BaseStrategy):
    """
    Strategy name: Tit-for-Tat Adaptive Cooperation (TFTAC)
    A strategy that initially cooperates and imitates the opponent's behavior in subsequent rounds.
    Encourages mutual cooperation when other players also adopt this or similar reciprocal strategies.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            last_opponent_action = np.mean(history.opponent_actions[-1])
            if last_opponent_action == 1:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_501(BaseStrategy):
    """
    A strategy based on the Tit-for-Tat with Adaptive Threshold (TFTA) approach. This strategy maintains long-term relationships and promotes a stable cooperative environment.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.forgiveness_window = int(np.floor(game_description.n_players / 2))
        self.cooperative_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and history.my_actions.size > 0:
            cooperators = sum(history.opponent_actions[-1, :])
            self.cooperative_rounds += int(np.floor((cooperators + 1) / (self.game_description.n_players - self.forgiveness_window)))
        if state.round_number == history.my_actions.size and self.cooperative_rounds >= self.forgiveness_window:
            self.cooperative_rounds = 0
        return Action.C if self.cooperative_rounds >= self.game_description.n_players // self.game_description.m else Action.D

class Strategy_COLLECTIVE_502(BaseStrategy):
    """
    Strategy: Adaptive Tit-for-Tat with Gradient Descent (ATfT-GD)
    Strategy Name: ATfT-GD
    Summary: A strategy that cooperates initially, reciprocates cooperation, punishes defection and forgives after defection, while adjusting responsiveness to defections using gradient descent. The aim is to maximize the group's overall benefit by promoting cooperative behavior whenever possible and minimizing defection when necessary.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        super().__init__(game_description)
        self.cooperation_threshold = game_description.m
        self.learning_rate = 0.1
        self.defections_count = 0
        self.responsiveness = 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or not history:
            return Action.C
        opponent_cooperated_last_round = sum(history.opponent_actions[state.round_number - 1]) >= self.cooperation_threshold
        if opponent_cooperated_last_round:
            return Action.C
        else:
            self.defections_count += 1
            self.responsiveness = self.defections_count / (state.round_number + 1) * self.learning_rate + 1
            if self.responsiveness > self.cooperation_threshold:
                return Action.D
            else:
                return Action.C
        return Action.C

class Strategy_COLLECTIVE_503(BaseStrategy):
    """
    Implementation of Adaptive Cooperative Tit-for-Tat (ACTFT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history_length = int(math.ceil(game_description.n_rounds * 0.75))
        self.cooperation_threshold = self.game_description.m_initial = game_description.m // 2
        self.tolerance = int(math.ceil((self.cooperation_threshold - game_description.m + game_description.m_initial) / 3))
        self.forgiveness_period = int(math.ceil(game_description.n_rounds * 0.15))
        self.history = [None] * self.history_length

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if state.round_number == 0 or not history:
            return Action.C
        if not history:
            self.history = [None] * self.history_length
        cooperation_rate = self.calculate_cooperation_rate(history)
        if self.forgiveness_period > state.round_number and (cooperation_rate >= self.cooperation_threshold - self.tolerance or cooperation_rate <= self.game_description.m + self.tolerance):
            return Action.C
        if state.round_number > self.forgiveness_period and cooperation_rate < self.cooperation_threshold - self.tolerance:
            self.update_cooperation_threshold()
        return Action.C if cooperation_rate >= self.cooperation_threshold else Action.D

    def calculate_cooperation_rate(self, history):
        cooperators = np.sum(history.opponent_actions[-self.history_length:, :].flatten())
        return cooperators / self.history_length if self.history_length > 0 else random.choice([0, 1])

    def update_cooperation_threshold(self):
        self.cooperation_threshold = min(self.cooperation_threshold + 1, self.game_description.m)

class Strategy_COLLECTIVE_504(BaseStrategy):
    """
    A strategy inspired by the Tit-for-Tat game theory strategy, adapted for the Collective Risk Dilemma game.
    This strategy cooperates in the first round to demonstrate goodwill, and subsequently copies the most frequent cooperator's action from the previous round.
    If no cooperation occurred in the previous round, it defects to avoid being exploited.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros(game_description.n_rounds))
        self.max_cooperators = math.floor(game_description.n_players * (game_description.m / 100))

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        self.history = history
        frequent_cooperators = np.where(np.sum(self.history.opponent_actions[:, :-1], axis=1) >= self.max_cooperators)[0]
        if len(frequent_cooperators) == 0:
            return Action.D
        last_cooperator = frequent_cooperators[-1]
        cooperators = np.sum(self.history.opponent_actions[last_cooperator, -1])
        if cooperators >= self.max_cooperators:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_505(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation (TFT-AC)
    Summary: A strategy that cooperates initially and retaliates if an opponent defects, while adapting the minimum cooperation threshold based on observed player behavior.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = min(max(2, math.floor(game_description.n_players * 0.5)), game_description.n_players)
        self.r = game_description.n_rounds
        self.e = math.floor(self.m * 0.1)
        self.strategy = [Action.C] * self.r

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if history is None or state.round_number == 0:
            return Action.C
        cooperators = sum([1 for action in self.strategy[-self.r:] if action == Action.C])
        cooperators_percentage = cooperators / self.r
        if state.round_number < self.r and cooperators_percentage >= self.m + self.e:
            self.m += 1
            self.m = min(max(2, math.ceil(self.game_description.n_players * 0.5)), self.game_description.n_players)
        elif state.round_number < self.r and cooperators_percentage <= self.m - self.e:
            self.m -= 1
            self.m = max(2, math.floor(self.game_description.n_players * 0.5))
        if state.round_number == self.r and cooperators_percentage >= self.m / self.e:
            return Action.C
        opponent_cooperated = sum(history.opponent_actions[-1, :]) >= self.m
        action = Action.C if opponent_cooperated else Action.D
        self.strategy.append(action)
        self.strategy = self.strategy[1:]
        return action

class Strategy_COLLECTIVE_506(BaseStrategy):
    """
    Implementation of Tit-for-Tat with Adaptive Cooperation (TFT-AC) Strategy.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.k = game_description.k
        self.t = 2
        self.last_round_coop = None
        self.streaks = {'cooperation': 0, 'defection': 0}

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        action = Action.D
        if state.round_number == 0:
            action = Action.C
        else:
            cooperators = sum(history.opponent_actions[state.round_number - 1, :])
            self._update_streaks(cooperators)
            if self.last_round_coop is not None and self.streaks['cooperation'] > self.t:
                if cooperators >= self.m:
                    self.m += 1
                elif cooperators < self.m - 1:
                    self.m -= 1
            action = Action.C if cooperators >= self.m else Action.D
        self.last_round_coop = action is Action.C
        return action

    def _update_streaks(self, cooperators: int):
        if cooperators > 0:
            self.streaks['cooperation'] += 1
        else:
            self.streaks['defection'] += 1
        if self.streaks['cooperation'] > self.t or self.streaks['defection'] > self.t:
            self.streaks['cooperation'], self.streaks['defection'] = (0, 0)

class Strategy_COLLECTIVE_507(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_counter = 0
        self.last_opponent_action = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        total_cooperators = sum(history.my_actions)
        if total_cooperators >= self.game_description.m and state.round_number != self.game_description.n_rounds - 1:
            return Action.C
        last_round = history.opponent_actions[-1]
        self.last_opponent_action = np.mean(last_round)
        if self.punishment_counter >= 3:
            if self.last_opponent_action == Action.C:
                self.punishment_counter = 0
            else:
                self.punishment_counter += 1
                if self.punishment_counter < 6:
                    return Action.D
                else:
                    self.punishment_counter = 3
        elif self.last_opponent_action == Action.C:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_508(BaseStrategy):
    """
    Tit-for-Tat Strategy for Collective Risk Dilemma.
    Initially cooperates in the first round and then follows the actions of other players in subsequent rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        super().__init__(game_description)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or not history:
            return Action.C
        opponentAction = history.opponent_actions[state.round_number - 1][0] if len(history.opponent_actions) > 0 else None
        return Action.C if opponentAction == Action.C else Action.D

class Strategy_COLLECTIVE_509(BaseStrategy):
    """
    Tit-for-Tat-Adaptive (TfTA) strategy for the Collective Risk Dilemma game.
    This strategy cooperates initially and imitates the opponent's previous move in subsequent rounds, encouraging mutual trust and long-term collaboration.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.last_opponent_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and len(history.opponent_actions) > 0:
            cooperators = sum(history.opponent_actions[-1, :])
            self.last_opponent_cooperators = cooperators
            if self.last_opponent_cooperators >= self.m - 1 and cooperators >= self.m:
                return Action.C
            elif self.last_opponent_cooperators == 0:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_510(BaseStrategy):
    """
    Strategy that implements the Tit-for-Tat-Adaptive (TfTA) strategy in Collective Risk Dilemma games.
    This strategy mimics opponent's actions from previous rounds, while occasionally deviating to promote forgiveness.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.forgiveness_factor = 0.8

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = len(history.opponent_actions) - 1
        opponent_action = history.opponent_actions[last_round, 0]
        forgiveness = self.forgiveness_factor if last_round < self.game_description.n_rounds - 1 else 1
        return Action.C if opponent_action and forgiveness > random.random() or not opponent_action else Action.D

class Strategy_COLLECTIVE_511(BaseStrategy):
    """
    A strategy that cooperates when the majority of opponents have cooperated in the previous round, but retaliates when they have not. It allows some flexibility for occasional deviations by introducing a tolerance parameter .
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = self.game_description.n_players
        self.threshold = math.ceil(self.n_players * self.game_description.m / 100)
        self.tolerance = self.game_description.m - self.threshold
        self.history = np.zeros(self.game_description.n_rounds, dtype=np.int8)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperation_count = sum(history.opponent_actions[state.round_number - 1])
        adaptive_threshold = self.threshold + self.tolerance * (random.random() > 0.5)
        if cooperation_count < adaptive_threshold or cooperation_count > self.n_players - adaptive_threshold:
            return Action.D
        return Action.C

class Strategy_COLLECTIVE_512(BaseStrategy):
    """
    A strategy that cooperates initially and adapts to the opponent's behavior, promoting a collective mindset.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation = True
        self.recent_defection_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and len(history.opponent_actions) > self.game_description.n_players:
            opponent_recent = history.opponent_actions[-self.game_description.n_players:]
            self.recent_defection_count = sum([int(action == Action.D) for action in np.ravel(opponent_recent)])
        if self.cooperation and self.recent_defection_count > self.game_description.n_players // 2:
            self.cooperation = False
        action = Action.C if self.cooperation else Action.D
        return action

class Strategy_EXPLOITATIVE_1(BaseStrategy):
    """
    A Tit-for-Tat Adaptive Strategy for the Collective Risk Dilemma Game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = np.zeros(self.game_description.n_rounds - 1, dtype=bool)
        self.number_of_defections = 0

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.opponent_history[state.round_number - 1] = bool(history.opponent_actions[-1, 0])
        self.number_of_defections += np.count_nonzero(self.opponent_history)
        action = Action.C if np.all(self.opponent_history == True) else Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            if self.number_of_defections < math.floor(self.game_description.n_rounds / 2):
                action = Action.C
        return action

class Strategy_EXPLOITATIVE_2(BaseStrategy):
    """
    Strategy name: Tit-for-Tat-Plus (TfT+)
    Strategy description: Cooperates if more than m players cooperated in the previous round, defects otherwise.
                           Adopts a probabilistic approach when the minimum cooperation threshold is met exactly.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.k = float(self.game_description.k)
        self.m = int(self.game_description.m)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        cooperators = sum(history.opponent_actions[-1] if history else [0])
        if cooperators > self.m or (cooperators == self.m and random.random() < self.k / (self.game_description.n_players - cooperators + 1)):
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_3(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Cooperative Threshold (TFTC)

    This strategy employs the Tit-for-Tat approach with a cooperative threshold. In the first round, it cooperates to demonstrate goodwill. Subsequently, it cooperates if more than half of opponents cooperated in the previous round, defects otherwise. If the remaining rounds are less than a tolerance level, it always cooperates for the final rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.tolerance_threshold = int(game_description.n_players * 0.2)
        self.history = None

    def __call__(self, state: GameState, history: PlayerHistory):
        if self.history is None:
            return Action.C
        cooperators_prev = sum(self.history.opponent_actions[-min(state.round_number - 1, len(self.history.opponent_actions)):-1])
        num_players = self.game_description.n_players
        if cooperators_prev >= num_players // 2:
            return Action.C
        elif state.round_number == 1 or self.game_description.n_rounds - state.round_number + 1 < self.tolerance_threshold:
            return Action.C
        else:
            return Action.D
        self.history = history

class Strategy_EXPLOITATIVE_4(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Threshold (TFTA) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.m
        self.rounds_count = 0
        self.recent_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            self.rounds_count += 1
            return Action.C if self.recent_cooperators >= self.threshold - 1 else Action.D
        self.rounds_count += 1
        cooperators = sum(history.opponent_actions[-1, :])
        adjustment = int(math.floor(cooperators / self.game_description.n_players * 2))
        self.threshold += adjustment if cooperators >= self.threshold + adjustment else -adjustment
        self.threshold = max(min(self.threshold, self.game_description.n_players - 2), 1)
        if cooperators >= self.threshold:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_5(BaseStrategy):
    """
    A Tit-for-Tat strategy with adaptation in the Collective Risk Dilemma game.

    This strategy cooperates if a sufficient number of players cooperated in the previous round, otherwise defects.
    It assumes other players will continue their cooperation behavior from the previous round in the last round, unless the total cooperation in the previous round was less than the minimum threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.total_coop = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        action = Action.D if cooperators < self.game_description.m else Action.C
        if state.round_number == history.my_actions.size:
            if cooperators >= self.game_description.m and self.total_coop >= self.game_description.m:
                action = Action.C
        else:
            self.total_coop += int(action == Action.C) - int(history.my_actions[state.round_number] if history is not None else 0)
        return action

class Strategy_EXPLOITATIVE_6(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = math.ceil(game_description.m)
        self.previous_round_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            cooperators = self.previous_round_cooperators
        else:
            cooperators = sum(history.opponent_actions[-1, :])
        if cooperators < self.cooperation_threshold:
            self.cooperation_threshold += 1 if cooperators < self.game_description.m else 0
        self.previous_round_cooperators = cooperators
        return Action.C if cooperators >= self.cooperation_threshold else Action.D

class Strategy_EXPLOITATIVE_7(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_cooperators_count = [0] * game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or not history:
            return Action.C
        if history is not None:
            self.opponent_cooperators_count = [c for c, _ in enumerate(history.opponent_actions[-1])]
            cooperators = sum(self.opponent_cooperators_count)
        if cooperators >= self.game_description.n_players - 1:
            return Action.C
        max_defectors, max_defects = max(enumerate(self.opponent_cooperators_count), key=lambda x: x[1])
        if cooperators < self.game_description.n_players - 1 and max_defects > 0:
            return Action(max_defectors)
        return Action.D

class Strategy_EXPLOITATIVE_8(BaseStrategy):
    """
    This is a TIT FOR TAT WITH THRESHOLDS (TFTT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1]) if history else 0
        return Action.C if cooperators >= self.m else Action.D

class Strategy_EXPLOITATIVE_9(BaseStrategy):
    """
    A strategy that implements the Tit-for-Tat-Adaptive (TfTA) game theory approach for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.theta = 0.5
        self.cooperators_ratio = np.zeros(game_description.n_rounds, dtype=np.float64)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators > 0:
            cooperators_ratio = cooperators / (self.game_description.n_players - 1)
            self.cooperators_ratio[state.round_number - 1] = cooperators_ratio
        else:
            self.cooperators_ratio[state.round_number - 1] = 0
        if np.isnan(self.cooperators_ratio[-1]):
            self.cooperators_ratio[-1] = 0
        if self.cooperators_ratio[-1] >= self.theta:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_10(BaseStrategy):
    """
    A Tit-for-Tat-Adaptive (TfT-A) strategy implementation for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m
        self.n = self.game_description.n_players
        self.k = self.game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None or len(history.opponent_actions) < self.game_description.n_rounds:
            return Action.D
        cooperators = sum(history.opponent_actions[-1])
        if cooperators >= self.m:
            return Action.C
        return Action.D

    def __last_round__(self, state: GameState, history: PlayerHistory) -> bool:
        return state.round_number == self.game_description.n_rounds - 1

    def __adjust_strategy__(self):
        pass

class Strategy_EXPLOITATIVE_11(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Risk Aversion (TFT-ARA) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.k = game_description.k
        self.cooperative_count = 0
        self.deviations_count = 0
        self.rounds_played = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        self.rounds_played += 1
        if state.round_number == 0:
            return Action.C
        if self.rounds_played == self.game_description.n_rounds:
            cooperators = sum(history.my_actions) if history else 0
            if cooperators >= self.m:
                return Action.C
            else:
                return Action.D
        if history is None or len(history.opponent_actions) == 0:
            return Action.D
        cooperators = sum(history.opponent_actions[-1, :])
        deviations = self.game_description.n_players - cooperators
        if cooperators >= self.m:
            self.cooperative_count += 1
            return Action.C
        elif cooperators < self.m and deviations <= self.deviations_count:
            self.deviations_count += 1
            return Action.D
        else:
            p = min(1 - self.deviations_count / (self.rounds_played // 2), 1)
            r = random.random()
            if r < p:
                self.cooperative_count += 1
                return Action.C
            else:
                self.deviations_count += 1
                return Action.D

class Strategy_EXPLOITATIVE_12(BaseStrategy):
    """
    The Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT) strategy in Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = self.game_description.m
        self.history = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if self.history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        private_payoff = np.mean(history.my_payoffs[-1])
        if state.round_number == self.game_description.n_rounds:
            cooperation_decision = cooperators >= self.cooperation_threshold
        else:
            cooperation_decision = cooperators >= self.cooperation_threshold and private_payoff < self.game_description.k or (cooperators < self.cooperation_threshold and private_payoff >= self.game_description.k)
        action = Action.C if cooperation_decision else Action.D
        self.history = history or PlayerHistory(my_actions=np.array([action]), my_payoffs=np.zeros(self.game_description.n_rounds), opponent_actions=history.opponent_actions if history is not None else np.zeros((self.game_description.n_rounds, self.game_description.n_players)), opponent_payoffs=history.opponent_payoffs if history is not None else np.zeros((self.game_description.n_rounds, self.game_description.n_players)))
        if action == Action.C and private_payoff >= self.game_description.k:
            self.cooperation_threshold += 1
        elif action == Action.D and private_payoff < self.game_description.k:
            self.cooperation_threshold -= 1
        self.history.my_actions[-1] = action
        self.history.my_payoffs[-1] = private_payoff
        return action

class Strategy_EXPLOITATIVE_13(BaseStrategy):
    """
    A variant of Tit-for-Tat strategy that dynamically adjusts cooperation threshold to encourage cooperation or punish defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperative_threshold = game_description.m
        self.history = PlayerHistory(my_actions=np.zeros(game_description.n_rounds, dtype=bool), my_payoffs=np.zeros(game_description.n_rounds, dtype=float), opponent_actions=np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), opponent_payoffs=np.zeros((game_description.n_rounds, game_description.n_players), dtype=float))

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        current_round = state.round_number - 1
        last_cooperators = sum(history.opponent_actions[current_round, :])
        cooperate = last_cooperators >= self.cooperative_threshold
        action = Action.C if cooperate else Action.D
        payoff = 1 - int(action == Action.D) + self.game_description.k * (last_cooperators >= self.game_description.m)
        self.history.my_payoffs[current_round] = payoff
        self.history.my_actions[current_round] = int(action == Action.C)
        if last_cooperators == self.game_description.m or last_cooperators > self.cooperative_threshold:
            self.cooperative_threshold += 1
        elif last_cooperators < self.cooperative_threshold - 1:
            self.cooperative_threshold -= 1
        return action

class Strategy_EXPLOITATIVE_14(BaseStrategy):
    """
    A Tit-for-Tat strategy with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma games.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_coop_count = math.ceil(game_description.n_players * (game_description.m / 100))
        self.history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or not history:
            return Action.C
        cooperation_count = sum(history.opponent_actions[-1])
        if cooperation_count >= self.min_coop_count:
            return Action.C
        return Action.D

    def update_history(self, round_payoffs: NDArray[np.float64]):
        """
        Update the strategy's history with current payoff data.
        """
        self.history.append(round_payoffs)

class Strategy_EXPLOITATIVE_15(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATfT) Strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = np.zeros((1, self.game_description.n_players), dtype=bool)
        self.last_round = -1

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if state.round_number == 0:
            return Action.C
        else:
            self.last_round += 1
            self.opponent_history = np.roll(self.opponent_history, -1, axis=0)
            cooperators = sum(history.opponent_actions[self.last_round, :])
            if self.last_round == len(history.opponent_payoffs) - 1:
                return Action.D
            if cooperators >= self.game_description.n_players // 2 and self.opponent_history[-1, -1] == True:
                return Action.C
            elif cooperators >= self.game_description.n_players // 2 and self.opponent_history[-1, -1] == False:
                return Action.D
            else:
                return self.opponent_history[-1, -1]

class Strategy_EXPLOITATIVE_16(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperated_count = 0
        self.last_round_cooperators_count = 0
        self.m_prime = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.cooperated_count = sum(history.my_actions[:state.round_number]) if history else 0
        self.last_round_cooperators_count = sum(history.opponent_actions[-1, :]) if history else 0
        self.m_prime = np.ceil((self.last_round_cooperators_count + self.cooperated_count) / self.game_description.n_players) if self.last_round_cooperators_count >= self.game_description.m else self.game_description.m
        cooperate = self.last_round_cooperators_count >= self.m_prime
        return Action(int(cooperate))

class Strategy_EXPLOITATIVE_17(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.adaptation_factor = 0.5
        self.min_adaptation = 0.1
        self.max_adaptation = self.n_players - self.m
        self.threshold = (self.m + 1) / 2
        self.step_size = (self.max_adaptation - self.min_adaptation) / (self.n_rounds - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None:
            return Action.D
        n_c = sum(history.opponent_actions[-1])
        if n_c < self.m:
            return Action.D
        self.adaptation_factor += (1 - history.my_actions[-1]) * self.step_size
        self.adaptation_factor = max(self.min_adaptation, min(self.max_adaptation, self.adaptation_factor))
        return Action.C if self.adaptation_factor >= self.threshold else Action.D

class Strategy_EXPLOITATIVE_18(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperative Threshold (TFT-ACT) Strategy for Collective Risk Dilemma Game
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.t_punishment = 1
        self.t_increase = game_description.n_players // 2 if game_description.n_players % 2 == 0 else math.ceil(game_description.n_players / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if state.round_number == 0 or history is None:
            return Action.C
        opponent_cooperated_previously = history.my_actions[-1] if history is not None else False
        opponent_cooperates_now = history.opponent_actions[state.round_number - 1, :].mean() >= self.game_description.m / self.game_description.n_players
        cooperation_rate = np.mean(history.opponent_actions[:state.round_number]) if history is not None else 0
        cooperate = cooperation_rate >= self.game_description.m / self.game_description.n_players
        if cooperate and opponent_cooperated_previously:
            self.t_punishment = min(self.t_punishment * 2, 2 ** state.round_number)
        if not cooperate and opponent_cooperated_previously:
            self.t_punishment = 1
        if not opponent_cooperates_now and cooperation_rate > 0:
            self.t_punishment = 1
        if state.round_number == self.game_description.n_rounds or state.round_number == self.game_description.n_rounds - self.t_punishment:
            cooperate = True
        return Action.C if cooperate else Action.D

class Strategy_EXPLOITATIVE_19(BaseStrategy):
    """
    A Tit-for-Tat Adaptive strategy that cooperates if an opponent has cooperated in the past 'c' consecutive rounds, and defects otherwise.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.n_players // 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperation_history = np.sum(history.opponent_actions[:state.round_number, -1], axis=0)
        if cooperation_history >= self.cooperation_threshold:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_20(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) Strategy for Collective Risk Dilemma game
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_length = math.ceil(game_description.n_players * 2)
        self.history = PlayerHistory(my_actions=np.array([], dtype=bool), my_payoffs=np.array([]), opponent_actions=np.zeros((self.punishment_length, game_description.n_players), dtype=bool), opponent_payoffs=np.zeros(self.punishment_length))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is not None:
            self.history = history
        if state.round_number == 0 or (state.round_number > 0 and np.all(self.history.opponent_actions[-self.punishment_length:] == [False])):
            return Action.C
        last_action = self.history.opponent_actions[-1, -1]
        if last_action:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_21(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-1]) if history else 0
        if cooperators < self.min_cooperators - 1:
            return Action.D
        return Action.C

class Strategy_EXPLOITATIVE_22(BaseStrategy):
    """
    Tit-for-Tat with Variable Cooperation Probability (TFT-VCP) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history_length = 10
        self.cooperation_decisions = np.zeros(self.history_length)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            self.cooperation_decisions = np.roll(self.cooperation_decisions, -1)
            self.cooperation_decisions[-1] = int(history.opponent_actions[-1, 0])
        average_c = np.mean(self.cooperation_decisions)
        opponent_cooperators = sum(history.opponent_actions[-1, :]) if history else 0
        if opponent_cooperators > math.ceil(average_c * self.game_description.n_players):
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_23(BaseStrategy):
    """
    Tit-for-Tat-Adaptive Strategy (TFTA) for the Collective Risk Dilemma Game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.previous_most_cooperators_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and len(history.opponent_actions) > 0:
            most_cooperators_count = np.max(np.sum(history.opponent_actions, axis=0))
            self.previous_most_cooperators_count = most_cooperators_count
            if most_cooperators_count >= self.game_description.m - 1:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_24(BaseStrategy):
    """
    Tit-for-Tat with Variable Defection (TFTV) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = [Action.C]
        self.defection_threshold = math.ceil(game_description.n_players / 2)
        self.s = self.game_description.n_players // 10
        self.d = 0.5

    def __call__(self, state: GameState, history: PlayerHistory | None):
        if not history:
            return self.history[-1]
        if state.round_number == 0 or (state.round_number == self.game_description.n_rounds and state.round_number % 2 != 0):
            self.history.append(Action.C)
        else:
            opponent_actions = history.opponent_actions[:, -1]
            consecutive_defections = sum(np.diff(opponent_actions) == -1)
            if consecutive_defections >= self.s:
                if random.random() < self.d:
                    self.history.append(Action.D)
                else:
                    self.history.append(Action.C)
            else:
                self.history.append(opponent_actions[-1])
        cooperators = sum(history.my_actions[-self.game_description.m:])
        if len(set(history.my_actions[-self.game_description.m:])) == 1 and cooperators >= self.defection_threshold:
            return Action.C if self.history[-1] == Action.D else Action.D
        return Action.D

class Strategy_EXPLOITATIVE_25(BaseStrategy):
    """
    Implementation of the Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy in Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.t = min(self.game_description.n_rounds, 3)
        self.avg_cooperation_threshold = self.game_description.m / 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        if state.round_number == self.game_description.n_rounds:
            cooperation_avg = np.mean(history.my_actions)
            return Action.C if cooperation_avg >= self.avg_cooperation_threshold else Action.D
        cooperation_avg = np.mean(history.my_actions[-self.t:])
        if cooperation_avg >= self.avg_cooperation_threshold:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_26(BaseStrategy):
    """
    A Tit for Tat adaptive strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.memory = np.zeros(self.game_description.m, dtype=np.int8)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            current_round = history.my_actions[-1]
            self._update_memory(current_round)
            cooperators_in_previous_m_rounds = np.count_nonzero(self.memory >= 1)
            if cooperators_in_previous_m_rounds >= self.game_description.m:
                return Action.C
        return Action.D

    def _update_memory(self, action: bool):
        """
        Update the memory array based on the given action.
        """
        self.memory = np.roll(self.memory, -1)
        self.memory[-1] = int(action)

class Strategy_EXPLOITATIVE_27(BaseStrategy):
    """
    Tit-for-Tat with Adaptive K-Factor (TFTA-K) Strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.k_factor = game_description.k
        self.last_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if not history:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            self.last_round = True
        else:
            self.last_round = False
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators < self.game_description.m or (self.last_round and cooperators == 0):
            action = Action.D
        elif self.last_round:
            action = Action.C
        else:
            action = history.opponent_actions[-2, -1] if self.last_round else Action.C
        payoff = 1 - action.value if cooperators < self.game_description.m or (self.last_round and cooperators == 0) else 1 - action.value + self.k_factor
        return action

class Strategy_EXPLOITATIVE_29(BaseStrategy):
    """
    Implementation of the Tit-for-Tat Adaptive (TfT-A) strategy in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.previous_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        if history is not None:
            self.previous_cooperators = sum(history.opponent_actions[-1, :])
        if self.previous_cooperators >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_30(BaseStrategy):
    """
    A strategy that cooperates initially and retaliates when others defect, while still rewarding risk aversion.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_count = game_description.m - 1
        self.last_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or self.last_round:
            action = Action.C
            self.cooperation_count += 1 if action == Action.C else 0
            return action
        cooperators = sum(history.opponent_actions[state.round_number - 1, :]) if history else 0
        if cooperators < self.game_description.m:
            action = Action.D
            self.cooperation_count = 0
        elif self.cooperation_count >= self.game_description.m and self.cooperation_count <= self.game_description.m - 1:
            action = Action.D
        else:
            action = Action.C
            self.cooperation_count += cooperators - self.cooperation_count
        if state.round_number == self.game_description.n_rounds - 1 and cooperators < self.game_description.m:
            self.last_round = True
        return action

class Strategy_EXPLOITATIVE_32(BaseStrategy):
    """
    Tit-for-Tat with Variable Adaptation (TfTVA) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None or state.round_number == 0:
            return Action.C
        previous_round = state.round_number - 1 if history is not None else None
        previous_action = Action.D if history is None or previous_round < 0 else history.my_actions[previous_round]
        opponents_cooperators = sum(history.opponent_actions[previous_round, :]) if previous_round >= 0 else 0
        return self._determine_action(previous_action, opponents_cooperators)

    def _determine_action(self, previous_action: bool, opponents_cooperators: int) -> Action:
        return Action.C if previous_action or (opponents_cooperators >= self.m and self._should_continue_cooperation(previous_action)) else Action.D

    def _should_continue_cooperation(self, previous_action: bool) -> bool:
        return previous_action and (not self._less_than_m_cooperators(previous_action))

    def _less_than_m_cooperators(self, previous_action: bool) -> bool:
        if previous_action:
            return sum(previous_action) < self.m - 1
        else:
            return sum(previous_action) < self.m

class Strategy_EXPLOITATIVE_33(BaseStrategy):
    """
    A Tit-for-Tat Adaptive (TfTA) player in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if not history:
            return Action.C
        self.opponent_history = history.opponent_actions.flatten().tolist()
        if state.round_number == 0 or state.round_number == len(self.opponent_history):
            return Action(self.opponent_history[-1])
        return Action(self.opponent_history[-1] == Action.C)

class Strategy_EXPLOITATIVE_34(BaseStrategy):
    """
    A Tit-for-Tat with a twist (TFTw) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1])
        if cooperators >= self.m:
            return Action.C
        else:
            return Action.D

    def last_round(self, round_number):
        return Action.D if round_number == self.game_description.n_rounds else Action.C

class Strategy_EXPLOITATIVE_35(BaseStrategy):
    """
    A Tit-for-Tat Plus (TfT+) strategy for the Collective Risk Dilemma game.

    The TfT+ strategy initially cooperates, and then cooperates if the opponent cooperated in the previous round,
    defects if the opponent has defected in the previous round, or if two consecutive defections from an opponent are detected.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self._last_opponent_action = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or (history and len(history.opponent_actions) < 2):
            return Action.C
        last_round = state.round_number - 1 if history else None
        self._last_opponent_action = history.opponent_actions[last_round, -1] if history else None
        if self._last_opponent_action == Action.C:
            return Action.C
        elif self._last_opponent_action == Action.D and history.opponent_actions[last_round, -2] == Action.D or not history:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_36(BaseStrategy):
    """
    Tit-for-Tat with Adaptation (TfTA) strategy for Collective Risk Dilemma.
    This strategy cooperates initially, then reciprocates the opponent's previous action in subsequent rounds.
    It also introduces a small probability of switching strategies after experiencing consecutive defections from the opponent.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.strategy = 'cooperate'
        self.current_round = 0
        self.opponent_history = []
        self.l = math.ceil(self.game_description.n_rounds / 2)
        self.p = 1 - self.game_description.k ** (1 / self.l)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.current_round - self.l <= 0 or ((self.current_round - self.l) % (self.game_description.n_rounds - self.l) == 0 and random.random() > self.p):
            if self.strategy == 'cooperate':
                self.strategy = 'switch'
            else:
                self.strategy = 'cooperate'
        action = Action.C if self.strategy == 'cooperate' and history is None or history.opponent_actions[-1, 0] == 1 else Action.D
        self.opponent_history.append(action == Action.C)
        self.current_round += 1
        return action

class Strategy_EXPLOITATIVE_38(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat Plus Adaptive Cooperation (TfT+)
    Strategy Description: An exploitative strategy that punishes non-cooperative behavior by defecting and only cooperating when it observes cooperation from other players.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.average_cooperators = np.zeros(self.game_description.n_rounds)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.average_cooperators = np.roll(self.average_cooperators, -1)
        if history is not None:
            cooperators = sum(history.opponent_actions[-1])
            self.average_cooperators[-1] = cooperators / self.game_description.n_players
        action = Action.C if np.mean(self.average_cooperators) >= self.game_description.m / self.game_description.n_players else Action.D
        return action

class Strategy_EXPLOITATIVE_39(BaseStrategy):
    """
    A strategy that emulates the Tit-for-Tat-with-Adaptation (TfTa) in Collective Risk Dilemma games.
    It initially cooperates and thereafter follows the opponent's action while implementing a forgiveness mechanism for consecutive defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.forgiveness_limit = int(math.ceil(game_description.n_players * 0.2))
        self.defection_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        action = Action.C if history.opponent_actions[-1, :].sum() >= self.game_description.n_players // self.game_description.m else Action.D
        if state.round_number > 0:
            last_round = len(history.opponent_actions) - 1
            if last_round == state.round_number - 1 and history.opponent_payoffs[-1, -1] >= self.game_description.k:
                action = Action.C
            if last_round > self.defection_counter + 1:
                self.defection_counter = max(self.defection_counter - 1, 0)
            elif state.round_number >= self.forgiveness_limit and self.defection_counter == self.forgiveness_limit:
                self.defection_counter = 1
        return action

class Strategy_EXPLOITATIVE_41(BaseStrategy):
    """
    Tit-for-Tat with Adaptation (TFT-A) Strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = int(game_description.n_players * 0.6)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        opponent_history = history.opponent_actions[state.round_number - 1] if history else np.zeros(self.game_description.n_players, dtype=bool)
        own_defected_count = sum(history.my_actions[-self.threshold:] == Action.D) if history else 0
        opponent_cooperated_count = sum(opponent_history == Action.C)
        return Action.C if opponent_cooperated_count > self.threshold or (own_defected_count < self.threshold and state.round_number > self.threshold) else Action.D

class Strategy_EXPLOITATIVE_42(BaseStrategy):
    """
    Maximum Exploitation Strategy for Collective Risk Dilemma.
    An exploitative strategy aiming to maximize its own payoff by inducing others into cooperating, while minimizing unnecessary cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m - 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.m:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_43(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) Strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.tau = self.m / self.n
        self.average_coop = np.zeros(self.r)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is not None:
            self.average_coop = (self.average_coop * (self.r - 1) + history.my_actions[0] if state.round_number else self.average_coop).astype(np.float64) / self.r
            cooperators = sum(history.my_actions[-self.r:])
            if cooperators >= self.tau:
                self.tau += (max(self.m, state.round_number + 1) - max(0, state.round_number - self.r)) / self.r * (Action.C == history.my_actions[-1])
                return Action.C
            else:
                self.tau -= (max(0, state.round_number - self.r) - max(0, state.round_number - self.r + 1)) / self.r * (Action.C != history.my_actions[-1])
        return Action.D

class Strategy_EXPLOITATIVE_44(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATFT)
    Strategy Description: Cooperates if sufficient number of cooperators in the previous rounds; defects otherwise.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = math.ceil(game_description.m * game_description.n_players / game_description.n_players) if game_description.n_players % game_description.m != 0 else game_description.m

    def __call__(self, state: GameState, history: PlayerHistory | None=None) -> Action:
        if not history or state.round_number == 0:
            return Action.C
        total_cooperation = np.sum(history.my_actions[:state.round_number])
        proportion_cooperators = total_cooperation / state.round_number
        if proportion_cooperators >= self.min_cooperators:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_45(BaseStrategy):
    """
    Tit-for-Tat Adaptive (TfTA) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_round_opponent_action = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not self.last_round_opponent_action:
            self.last_round_opponent_action = history.opponent_actions[-1][0]
        if self.last_round_opponent_action == Action.C.value:
            return Action.C
        else:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D

class Strategy_EXPLOITATIVE_46(BaseStrategy):
    """
    Implementation of the Adaptive Tit-for-Tat with Variable Cooperation Threshold (ATFT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.cooperative_rounds = 0
        self.punished_rounds = 0
        self.average_threshold = (self.cooperation_threshold + 1) / 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        cooperation_ratio = cooperators / self.game_description.n_players
        if cooperation_ratio >= self.cooperation_threshold / self.average_threshold:
            self.cooperative_rounds += 1
            self.punished_rounds = 0
            return Action.C
        elif self.cooperative_rounds > 0:
            self.punished_rounds += 1
            if self.punished_rounds < self.game_description.n_players // 2:
                return Action.D
        return Action.C

class Strategy_EXPLOITATIVE_47(BaseStrategy):
    """
    Implementation of the Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.last_round_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :]) if history else 0
        self.last_round_cooperators = cooperators
        if cooperators >= self.cooperation_threshold:
            self.cooperation_threshold += 1
            if self.cooperation_threshold > self.game_description.n_players:
                self.cooperation_threshold = self.game_description.m
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_48(BaseStrategy):
    """
    Free Rider strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = self.game_description.n_players
        self.m = self.game_description.m
        self.k = self.game_description.k
        self.r = self.game_description.n_rounds
        self.n_coop = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        cooperators = sum(history.opponent_actions[-1, :]) if history else self.n_coop
        if cooperators >= self.m:
            self.n_coop += 1 / self.r if cooperators >= self.m + 1 else self.n_coop - (self.n_players - self.m) / (self.r * (self.n_players - self.m + 1))
            probability = random.uniform(0, 1)
            if probability > 0.5:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_49(BaseStrategy):
    """
    Implementation of the Tit-for-Tat strategy with an adaptive cooperative threshold (ACt).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperative_threshold = game_description.m
        self.past_rounds = [0] * 5
        self.average_cooperation = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.average_cooperation is None or len(self.past_rounds) < 5:
            cooperator_count = sum(history.opponent_actions[:, -1])
            self.past_rounds[-1] = int(cooperator_count >= self.cooperative_threshold)
        else:
            self.average_cooperation = np.mean(self.past_rounds)
            adjusted_threshold = (self.game_description.m + self.average_cooperation) / 2
            self.cooperative_threshold = max(1, min(adjusted_threshold, self.game_description.n_players - 1))
        cooperator_count = sum(history.opponent_actions[:, -1])
        if cooperator_count >= self.cooperative_threshold:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_50(BaseStrategy):
    """
    Adaptive Tit-for-Tat Strategy for Collective Risk Dilemma Game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperate_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.cooperate_count = sum(history.opponent_actions[-1, :]) if history else 0
        if state.round_number == self.game_description.n_rounds and self.cooperate_count < self.game_description.m * (self.game_description.n_rounds - 1):
            return Action.D
        if self.cooperate_count >= self.game_description.m:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_51(BaseStrategy):
    """
    A Tit-for-Tat-Adaptive (TFT-A) strategy for the Collective Risk Dilemma game.
    This strategy initially cooperates, then copies the opponent's previous action,
    and defects when the minimum cooperation threshold is met or exploits non-cooperative behavior.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_actions = []

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_action = self.opponent_actions[-1] if len(self.opponent_actions) > 0 else None
        cooperators = sum(history.opponent_actions[-1])
        if cooperators >= self.game_description.m and my_action is not None:
            return Action.D
        if my_action is None:
            self.opponent_actions.append(Action.C)
        else:
            self.opponent_actions.append(my_action)
        return self.opponent_actions[-1]

class Strategy_EXPLOITATIVE_52(BaseStrategy):
    """
    TFTA Strategy for Collective Risk Dilemma Game.
    Cooperate when more than (m-1) players cooperated in the previous round,
    or when the average cooperation trend over the last few rounds exceeds a predefined threshold 'T'.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.k = game_description.k
        self.n = game_description.n_players
        self.T = 0.6
        self.history_length = 3
        self._cooperators = np.zeros(self.history_length)
        self._rounds = 0

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        if history is not None and self._rounds > self.history_length:
            self._cooperators = np.roll(self._cooperators, -1)
            self._cooperators[-1] = sum(history.opponent_actions[:, -1])
            cooperators_percentage = (self._cooperators / self.history_length).mean()
            if cooperators_percentage > self.T:
                return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.m - 1:
            return Action.C
        elif cooperators <= self.m - 2:
            return Action.D
        self._rounds += 1
        return Action.D

class Strategy_EXPLOITATIVE_54(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        super().__init__(game_description)
        self.cooperation_threshold = math.ceil(game_description.m * 0.8)
        self.t_defect = int(game_description.n_rounds / 4)
        self.delta = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if not history:
            return Action.C
        if state.round_number == 1:
            return Action.C
        num_cooperators = np.sum(history.opponent_actions[-1, :])
        if num_cooperators >= self.cooperation_threshold:
            return Action.C
        elif state.round_number - history.my_actions[0] >= self.t_defect and num_cooperators < self.cooperation_threshold:
            self.cooperation_threshold += self.delta
        return Action.D

    def reset(self):
        if self.cooperation_threshold != self.game_description.m:
            self.cooperation_threshold = self.game_description.m

class Strategy_EXPLOITATIVE_57(BaseStrategy):
    """
    A Tit-for-Tat strategy with adaptation for the Collective Risk Dilemma game.
    Cooperates in the initial round and retaliates against defection, while encouraging opponents to maintain cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_cooperation_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history:
            self.opponent_cooperation_count = sum(history.opponent_actions[0])
            if state.round_number == len(history.opponent_payoffs) and self.opponent_cooperation_count > len(history.opponent_payoffs) - self.game_description.n_players // 2:
                return Action.C
        return Action.D if history and history.my_actions[0] != Action.C or (state.round_number != 1 and history.my_actions[-1] == Action.D) else Action.C

class Strategy_EXPLOITATIVE_58(BaseStrategy):
    """
    An implementation of the Adaptive Tit-for-Tat (ATfT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.my_action_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None and state.round_number == 0:
            return Action.C
        action = Action.D
        if state.round_number > 1:
            n_c = sum(history.opponent_actions[state.round_number - 1])
            if n_c >= self.game_description.m and self.my_action_history[-1] == Action.D:
                action = Action.C
            elif n_c < self.game_description.m and self.my_action_history[-1] == Action.C:
                action = Action.D
        self.my_action_history.append(action)
        return action

class Strategy_EXPLOITATIVE_59(BaseStrategy):
    """
    Strategy name: Adaptive Tit-for-Tat with Deterrence (ATFD)
    Summary: A simple tit-for-tat approach to cooperation, incorporating a deterrence mechanism to discourage early defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.average_cooperative_ratio = 0.0
        self.history_length = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.history_length += 1
        if not history:
            cooperation_ratio = 0.0
        else:
            cooperators = sum(history.opponent_actions[-self.history_length:, -1])
            cooperation_ratio = cooperators / self.history_length
        if cooperation_ratio > self.average_cooperative_ratio:
            self.average_cooperative_ratio = cooperation_ratio
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_60(BaseStrategy):
    """
    Implementation of the Tit-for-Tat with Adaptation (TfTA) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = self.game_description.n_players
        self.m = self.game_description.m
        self.k = self.game_description.k
        self.r = self.game_description.n_rounds
        self.t = 10
        self.threshold = self.m
        self.cooperation_history = []
        self.defection_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None or state.round_number == 0:
            return Action.C
        opponent_actions = history.opponent_actions[-self.t:, -1] if len(history.opponent_actions) >= self.t else np.zeros(self.t, dtype=int)
        cooperation_count = sum(opponent_actions)
        if cooperation_count >= self.threshold:
            self.cooperation_history.append(True)
            self.defection_history.clear()
            self.threshold = max(math.ceil(self.threshold * 0.8), self.m)
        else:
            self.cooperation_history.append(False)
            self.defection_history.append(1 if np.all(opponent_actions == 1) else 0)
            if len(self.defection_history) >= self.t:
                self.threshold = min(math.ceil(self.threshold * 1.2), self.n_players - 1)
        return Action.C if self.cooperation_history[-1] else Action.D

class Strategy_EXPLOITATIVE_61(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) Strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r_t = game_description.n_rounds
        self.m_i = self.m
        self.cooperators_counter = np.zeros(self.r_t)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        action = Action.C
        if state.round_number == 0 and history is None:
            return action
        opponent_actions = history.opponent_actions[-1, :] if history else np.zeros(self.n_players).astype(int)
        cooperators = sum(opponent_actions)
        self.cooperators_counter[self.r_t - state.round_number] = cooperators
        if state.round_number < self.r_t - 1:
            if cooperators >= self.m_i:
                self.m_i += 1
            elif cooperators < self.m_i and self.m_i > self.m:
                self.m_i -= 1
        if state.round_number == self.r_t - 1:
            return Action.D
        if cooperators >= self.m_i:
            action = Action.C
        else:
            action = Action.D
        return action

class Strategy_EXPLOITATIVE_62(BaseStrategy):
    """
    The Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy.
    A cooperative strategy that adapts to the average number of cooporators over a sliding window.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = (game_description.n_players + game_description.m) // 2
        self.adaptation_window = math.ceil(game_description.n_rounds * 0.1)
        self.past_cooperators_sum = 0
        self.past_cooperators_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            self.past_cooperators_sum = 0
            self.past_cooperators_count = 0
            return Action.C
        cooperators = sum(history.opponent_actions[-self.adaptation_window:, -1])
        self.past_cooperators_sum += cooperators
        self.past_cooperators_count += 1
        if self.past_cooperators_count >= self.adaptation_window:
            self.cooperation_threshold = math.ceil(self.past_cooperators_sum / self.past_cooperators_count)
        if cooperators >= self.cooperation_threshold:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_63(BaseStrategy):
    """
    A Tit-for-Tat Strategy for Collective Risk Dilemma games.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m
        self.last_cooperation = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            self.last_cooperation = np.any(history.my_actions[-1])
        cooperators = np.sum(history.opponent_actions[-1, :])
        return Action.C if cooperators >= self.min_cooperators else Action.D

    def get_response(self, opponent_action: Action) -> Action:
        if opponent_action == Action.C:
            return self(GameState(state.round_number + 1), history)
        elif opponent_action == Action.D and self.last_cooperation:
            self.last_cooperation = False
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_64(BaseStrategy):
    """
    Strategy name: Adaptive Tit-for-Tat (ATFT)
    Strategy description: Maintains a cooperative stance when others also cooperate, but retaliates against defection by defecting in response.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(my_actions=np.zeros(game_description.n_rounds, dtype=bool), my_payoffs=np.zeros(game_description.n_rounds), opponent_actions=np.full((game_description.n_rounds, game_description.n_players), False), opponent_payoffs=np.full((game_description.n_rounds, game_description.n_players), 0.0))

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if state.round_number == 0 and history is None:
            return Action.C
        elif state.round_number == 0:
            self.history = history
            return Action.C if np.sum(self.history.opponent_actions[0, :]) >= self.game_description.n_players // self.game_description.m else Action.D
        else:
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators >= self.game_description.n_players // self.game_description.m:
                return Action.C
            return Action.D

class Strategy_EXPLOITATIVE_65(BaseStrategy):
    """
    A Tit-for-Tat with Adaptation strategy for the Collective Risk Dilemma game.
    This strategy cooperates initially and adapts its actions based on opponents' actions to maintain an exploitative mindset.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.t = math.ceil(game_description.n_players / 2)
        self.adapted = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_actions = history.opponent_actions if history else np.zeros((state.round_number + 1, self.game_description.n_players), dtype=bool)
        opponent_actions[state.round_number - 1] = np.where(history.my_actions[-1], 1, opponent_actions[state.round_number - 1]) if history else None
        if self.adapted:
            return Action.D if np.all(opponent_actions[:, -self.t:] == [0, 0] * self.t) else Action.C
        cooperators = sum(opponent_actions[-1, :])
        return Action.C if cooperators >= self.game_description.n_players // 2 and (not self.adapted) else Action.D

    def update_history(self, state: GameState, action: Action, payoff: float) -> None:
        if state.round_number == 0:
            history = PlayerHistory(my_actions=np.array([[action == Action.C]]), my_payoffs=[[payoff]], opponent_actions=np.zeros((1, self.game_description.n_players), dtype=bool), opponent_payoffs=np.zeros((1, self.game_description.n_players)))
        else:
            history = PlayerHistory(my_actions=history.my_actions[:state.round_number] if not self.adapted else np.vstack([history.my_actions[:state.round_number], np.array([[action == Action.C]])]), my_payoffs=[history.my_payoffs[:state.round_number] + [payoff]] if not self.adapted else np.vstack([history.my_payoffs[:state.round_number], [payoff]]))
            opponent_actions = history.opponent_actions if not history.opponent_actions[-1].size == state.round_number else np.hstack((history.opponent_actions, np.array([[opponent_action] * self.game_description.n_players for opponent_action in opponent_actions[-1]])))
            history = PlayerHistory(my_actions=history.my_actions, my_payoffs=history.my_payoffs, opponent_actions=opponent_actions, opponent_payoffs=[[0] * self.game_description.n_players for _ in range(state.round_number + 1)])
            history.opponent_actions[state.round_number - 1] = np.where(history.my_actions[-1], 1, history.opponent_actions[state.round_number - 1]) if not self.adapted else None
            history.opponent_payoffs[state.round_number][:self.game_description.n_players] = [1] * self.game_description.n_players if action == Action.D else [1 - history.my_actions[-1, -1] + self.game_description.k if history.opponent_payoffs[state.round_number][-1] == 0 else history.opponent_payoffs[state.round_number][-1]]
        if action == Action.C:
            cooperators = sum(history.my_actions[-1, :])
            self.adapted = cooperators >= self.game_description.n_players // 2 and len(np.where(history.opponent_actions[:, -self.t:] == [0, 0] * self.t)[0]) >= self.t
        else:
            self.adapted = False
        return history

class Strategy_EXPLOITATIVE_66(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.a = math.ceil(game_description.n_rounds / 10)
        self.p = game_description.k - 1
        self.m_t = 0
        self.cooperated_count_t = 0
        self.running_avg = [0] * self.a

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        self.cooperated_count_t = sum(history.opponent_actions[-1, :])
        self.running_avg.pop(0)
        self.running_avg.append(self.cooperated_count_t)
        self.m_t = np.mean(self.running_avg) if len(self.running_avg) > 1 else self.m
        if self.m_t >= self.n * (self.p / 100):
            self.m_t -= 1
            if self.m_t < self.m:
                self.m_t = self.m
        payoff_expectation = np.mean(history.my_payoffs[:state.round_number]) + (self.k - 1) * np.mean(self.running_avg) if state.round_number > 1 else 0
        if payoff_expectation > 0:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_67(BaseStrategy):
    """
    An adaptive Tit-for-Tat strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(my_actions=np.zeros(self.game_description.n_rounds, dtype=bool), my_payoffs=np.zeros(self.game_description.n_rounds), opponent_actions=np.zeros((self.game_description.n_rounds, self.game_description.n_players), dtype=bool), opponent_payoffs=np.zeros((self.game_description.n_rounds, self.game_description.n_players)))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            history = self.history
        action = Action.D
        if history and state.round_number < self.game_description.n_rounds:
            cooperators = sum(history.opponent_actions[state.round_number - 1, :])
            if cooperators >= self.game_description.n_players // 2:
                action = Action.C
        else:
            action = Action.C
        self.history.my_actions[state.round_number] = action == Action.C
        return action

class Strategy_EXPLOITATIVE_68(BaseStrategy):
    """
    Tit-for-Tat-Adaptive (TfT-A) Strategy for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m
        self.num_players = game_description.n_players

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        my_action = history.my_actions[-1] if history is not None else None
        num_cooperators = np.sum(history.opponent_actions[-1]) if history is not None else 0
        if my_action and num_cooperators >= self.min_cooperators or (not my_action and num_cooperators < self.min_cooperators):
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_69(BaseStrategy):
    """
    Tit-for-Tat Plus strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or not history:
            return Action.C
        opponent_action = history.opponent_actions[-1][-1] if len(history.opponent_actions) > 0 else None
        self.opponent_history.append(opponent_action)
        if not self.opponent_history or len(self.opponent_history) == 1:
            return Action.C
        if opponent_action and self.opponent_history[-2] != opponent_action:
            return Action.D
        return Action.C

class Strategy_EXPLOITATIVE_70(BaseStrategy):
    """
    The TFTAT strategy cooperates in the first round, then adjusts cooperation based on observed opponent behavior. It encourages long-term cooperation when it benefits the agent while punishing defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_coop = math.ceil(game_description.n_players * game_description.m / 100)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :]) if history is not None else 0
        if cooperators >= self.min_coop or (cooperators + 1 == self.min_coop and np.any(history.my_actions)):
            return Action.C
        return Action.D

    def final_round(self, state: GameState) -> Action:
        return Action.D

class Strategy_EXPLOITATIVE_71(BaseStrategy):
    """
    A strategy implementing Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.increment = 0.1
        self.decrement = 0.1 / game_description.n_players
        self.payoff = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-1])
        self.adjust_cooperation_threshold(cooperators)
        if cooperators >= self.cooperation_threshold:
            return Action.C
        return Action.D

    def adjust_cooperation_threshold(self, number_of_cooperators):
        if number_of_cooperators > self.game_description.m + 1:
            self.cooperation_threshold += self.increment
        elif number_of_cooperators < self.game_description.m:
            self.cooperation_threshold -= self.decrement

class Strategy_EXPLOITATIVE_72(BaseStrategy):
    """
    Tit-for-Tat Adaptive Strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_opponent_action = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.last_opponent_action = np.mean(history.opponent_actions[-1])
        if self.last_opponent_action == 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_73(BaseStrategy):
    """
    Adaptive Tit-for-Tat Strategy for the Collective Risk Dilemma Game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m
        self.last_round_coop = False

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None or len(history.my_actions) < self.game_description.n_rounds:
            self.last_round_coop = False
        else:
            self.last_round_coop = bool(history.my_actions[-1])
        current_cooperators = sum(history.opponent_actions[-1, :])
        cooperate = current_cooperators >= self.min_cooperators
        if state.round_number == self.game_description.n_rounds:
            cooperate = cooperate or self.last_round_coop
        return Action(int(cooperate))

class Strategy_EXPLOITATIVE_74(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATfT)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if not history:
            return Action.C
        if state.round_number == 1:
            self.opponent_history = [(state.round_number - 1, history.opponent_actions[-1][0])]
            return Action.C
        current_round = state.round_number - 1
        if current_round < len(self.opponent_history) - 3:
            opponent_actions = self.opponent_history[-current_round - 3:]
            if all([action == Action.D for action in opponent_actions]):
                self.opponent_history += [(current_round, Action.C)]
            else:
                self.opponent_history += [(current_round, history.opponent_actions[-1][0])]
        if self.opponent_history and current_round >= len(self.opponent_history) - 3:
            opponent_action = self.opponent_history[-1][1]
            self.opponent_history += [(current_round, opponent_action)]
        cooperate = False
        if opponent_action == Action.C:
            cooperate = True
        else:
            for t in range(current_round - 1, 0, -1):
                if self.opponent_history[t][1] == Action.C:
                    cooperate = True
                    break
        if current_round >= len(self.opponent_history) + 2 and cooperate and (self.opponent_history[-3:] == [(current_round - 3, Action.D), (current_round - 2, Action.D), (current_round - 1, Action.D)]):
            cooperate = True
        return Action(int(cooperate))

class Strategy_EXPLOITATIVE_75(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)
    Strategy Description: TFT-ACT cooperates if the number of cooperators in the previous round is greater than or equal to the current cooperation threshold. The cooperation threshold increases when the number of defectors exceeds the minimum required cooperators (m) in a window of past rounds and decreases when the number of cooperators meets or exceeds m in that window.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = int(game_description.n_players * 0.5)
        self.past_rounds = np.zeros(game_description.n_rounds, dtype=np.int8)

    def __call__(self, state: GameState, history: PlayerHistory):
        if state.round_number == 0:
            return random.choice([Action.C, Action.D])
        self.past_rounds = np.roll(self.past_rounds, -1)
        self.past_rounds[-1] = int(history.my_actions[-1])
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.cooperation_threshold:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_76(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.adaptive_cooperation_threshold = np.zeros(game_description.n_rounds)
        self.previous_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        action = Action.D
        round_number = state.round_number
        if round_number == 0:
            action = Action.C
        elif round_number == self.game_description.n_rounds - 1:
            if self.previous_cooperators >= int(self.game_description.m * (self.game_description.k - 1)):
                action = Action.C
        cooperators = sum(history.opponent_actions[-1, :]) if history is not None else 0
        adaptive_cooperation_threshold = int(math.floor(round_number * (self.game_description.m / self.game_description.n_players) + self.game_description.m))
        adaptive_cooperation_threshold = min(adaptive_cooperation_threshold, int(self.game_description.n_players * 0.8))
        if cooperators >= adaptive_cooperation_threshold:
            action = Action.C
            self.previous_cooperators += 1
        else:
            self.previous_cooperators = max(0, self.previous_cooperators - 1)
        self.adaptive_cooperation_threshold[round_number] = adaptive_cooperation_threshold
        return action

class Strategy_EXPLOITATIVE_77(BaseStrategy):
    """
    Tit-for-Tat with Adaptation strategy for Collective Risk Dilemma game
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_78(BaseStrategy):
    """
    Adaptive Tit-for-Tat strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_count = self._get_cooperation_count
        self.reward = self._get_reward
        self.m = game_description.m
        self.k = game_description.k
        self.last_round_action = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_action = Action.C
        if not self.last_round_action or (self.last_round_action == Action.C and self.reward(history, history.my_payoffs[-1]) < self.k):
            my_action = Action.D
        elif self.last_round_action == Action.D and self.cooperation_count(history, len(history.opponent_actions)) >= self.m:
            my_action = Action.C
        self.last_round_action = my_action
        return my_action

    def _get_cooperation_count(self, history: PlayerHistory, start_index=0) -> int:
        return sum(history.opponent_actions[start_index:])

    def _get_reward(self, history: PlayerHistory, round_index=-1) -> float:
        if round_index == -1:
            round_index = len(history.my_payoffs) - 1
        return self.k if history.my_payoffs[round_index] >= self.k else 1

class Strategy_EXPLOITATIVE_79(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT) Strategy
    This strategy cooperates if the number of opponents who cooperated in the previous round is greater than or equal to a minimum required cooperation threshold. The adaptation of the cooperation threshold occurs periodically after every 'a' rounds, where the new cooperation threshold is calculated as the average number of cooperators in the last 'b' rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.a = math.ceil(game_description.n_rounds / 10)
        self.b = int(self.a * 0.8)
        self.round_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C if history is None or np.sum(history.opponent_actions[0]) >= self.game_description.m else Action.D
        if self.round_counter >= self.a and self.round_counter % self.a == 0:
            cooperators = np.mean(history.opponent_actions[-self.b:-1, :]) * self.game_description.n_players
            self.cooperation_threshold = math.ceil(cooperators) if cooperators > 0 else self.game_description.m
        opponent_cooperators = np.sum(history.opponent_actions[-1, :])
        return Action.C if opponent_cooperators >= self.cooperation_threshold else Action.D

    def update_state(self, state: GameState):
        self.round_counter += 1

class Strategy_EXPLOITATIVE_80(BaseStrategy):
    """
    Strategy name: Tit-for-Tat-K (TfT-K)
    A cooperative strategy that starts by cooperating in the first round.
    In subsequent rounds, it adjusts its cooperation threshold based on opponents' past actions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.m
        self.opponent_history = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        self.opponent_history = history.opponent_actions if history is not None else np.zeros((1, self.game_description.n_players), dtype=bool)
        cooperators = sum(self.opponent_history[-1])
        if cooperators >= self.threshold:
            return Action.C
        return Action.D

    def update_threshold(self):
        consecutive_cooperation, consecutive_defection = (0, 0)
        for i in range(min(len(self.opponent_history), 20)):
            if self.opponent_history[-i - 1] == self.opponent_history[-i]:
                if self.opponent_history[-i] == Action.C:
                    consecutive_cooperation += 1
                else:
                    consecutive_defection += 1
        cooperation_count = sum(self.opponent_history[-20:])
        decay_rate = 1 + max((consecutive_defection - self.threshold) / float(self.threshold), (self.threshold - consecutive_cooperation) / float(self.threshold))
        if cooperation_count > self.threshold:
            self.threshold *= decay_rate
        elif cooperation_count < self.threshold:
            self.threshold *= decay_rate ** 2

class Strategy_EXPLOITATIVE_81(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = self.game_description.n_players
        self.m = self.game_description.m
        self.k = self.game_description.k
        self.t = 10
        self.current_threshold = self.m
        self.current_average = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if state.round_number < self.game_description.n_rounds:
            if cooperators >= self.current_threshold:
                return Action.C
            else:
                return Action.D
        elif cooperators >= self.current_threshold and state.round_number == self.game_description.n_rounds:
            return Action.C
        else:
            num_cooperators = np.sum(history.my_actions[-self.t:])
            num_players = len(history.my_actions[-self.t:])
            self.current_average = num_cooperators / num_players if num_players > 0 else 0
            new_threshold = self.m + (self.current_threshold - self.m) * ((self.current_average - self.current_average) / abs(self.current_average - self.m))
            self.current_threshold = new_threshold if new_threshold > 1 and new_threshold < self.n_players else self.m
            return Action.C if cooperators >= self.current_threshold else Action.D

class Strategy_EXPLOITATIVE_82(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperative Threshold (TFT-ACT)
    Strategy Summary: A strategy that cooperates on the first round and thereafter, cooperates if the opponent cooperated in the previous round, or defects if the opponent defected. In the last round, it always cooperates to maximize potential rewards.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        opponent_action = history.opponent_actions[-1, 0] if len(history.opponent_actions) > 0 else None
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        elif opponent_action is not None:
            return Action(int(opponent_action))
        else:
            return Action.D

class Strategy_EXPLOITATIVE_83(BaseStrategy):
    """
    Adaptive Tit-for-Tat Strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_round_opponent_action = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        if state.round_number == self.game_description.n_rounds:
            self.last_round_opponent_action = None
            return Action.C
        if history.opponent_actions[-1, :].sum() >= self.game_description.m and self.last_round_opponent_action is not None:
            self.last_round_opponent_action = Action.C
            return Action.C
        elif self.last_round_opponent_action is not None:
            self.last_round_opponent_action = Action.D
        else:
            self.last_round_opponent_action = None
        return Action.D

class Strategy_EXPLOITATIVE_84(BaseStrategy):
    """
    A Tit-for-Tat strategy with Adaptive Cooperation Threshold (TFT-ACT).
    This strategy cooperates initially and punishes defection by defecting itself for m-1 rounds.
    The cooperation threshold adapts based on the observed behavior of opponents.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = math.ceil(game_description.n_players / 2)
        self.punishment_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            past_defects = (history.my_actions[:-1] != Action.C).sum(axis=0)
            self.cooperation_threshold = math.ceil((self.game_description.n_players + past_defects) / 2)
            self.punishment_counter = min(self.punishment_counter + 1, self.game_description.n_players - self.cooperation_threshold)
        cooperators = sum(history.opponent_actions[-1, :]) if history is not None else 0
        cooperate = cooperators >= self.cooperation_threshold
        if state.round_number < self.game_description.n_rounds - 1:
            cooperate &= self.punishment_counter == 0
        return Action(int(cooperate))

class Strategy_EXPLOITATIVE_87(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Bonus (ATFB) Strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = self.game_description.n_players
        self.m = self.game_description.m
        self.k = self.game_description.k
        self.history = None
        self.current_round = 0
        self.past_cooperators = 0
        self.bonus_round = False
        self.opponent_exploitation = False
        self.remaining_rounds = self.game_description.n_rounds - 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if self.history is None and state.round_number == 0:
            return Action.C
        self.current_round = state.round_number
        past_cooperators = self.past_cooperators
        if history is not None:
            past_cooperators = sum(history.opponent_actions[self.current_round - 1, :])
        if past_cooperators >= self.m:
            self.past_cooperators = past_cooperators
            if self.current_round < self.game_description.n_rounds - 1:
                self.bonus_round = True if past_cooperators >= self.m else False
            return Action.C
        elif past_cooperators < self.m and self.current_round > self.game_description.n_rounds - 3:
            self.opponent_exploitation = True
            return Action.D
        else:
            if not self.opponent_exploitation:
                self.past_cooperators = 0
            return Action.D
        if self.current_round == self.game_description.n_rounds - 1:
            self.bonus_round = False
            if past_cooperators >= self.m:
                return Action.D
            return Action.C
        elif self.current_round < self.game_description.n_rounds - 2:
            self.remaining_rounds -= 1
        if self.bonus_round:
            return Action.D if np.random.random() <= 1 - self.k / self.n_players else Action.C
        return Action.C

class Strategy_EXPLOITATIVE_88(BaseStrategy):
    """
    The Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperators_threshold = math.ceil(self.game_description.n_players / 2)
        self.opponent_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.opponent_history.append(np.mean(history.opponent_actions[:, -self.game_description.m:]))
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.cooperators_threshold:
            return Action.C
        threshold_change = (self.cooperators_threshold - cooperators) / self.game_description.m * (1 + random.random())
        self.cooperators_threshold += threshold_change
        return Action.D

class Strategy_EXPLOITATIVE_89(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation (TfT-AC) strategy for Collective Risk Dilemma game.
    This strategy adapts to the behavior of opponents and cooperates if they do, but will swiftly defect if non-cooperative behavior is detected.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m
        self.n = self.game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1] if history else np.zeros(self.n - 1, dtype=bool))
        if cooperators >= self.m and cooperators < self.n:
            return Action.C
        elif cooperators < self.m:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            game_cooperators = sum(history.my_actions[:-1] if history else np.zeros(self.game_description.n_rounds - 1))
            return Action.C if game_cooperators >= self.m else Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_90(BaseStrategy):
    """
    Tit-for-Tat Plus (TfT+) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None or state.round_number == 0:
            return Action.D
        coop_count = np.sum(history.my_actions[:state.round_number])
        if coop_count >= self.m:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_91(BaseStrategy):
    """
    An implementation of the Adaptive Tit-for-Tat strategy for the Collective Risk Dilemma game.
    The strategy cooperates in the first round, and thereafter imitates the opponent's action from the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.own_history = np.zeros(game_description.n_rounds, dtype=int)

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        my_actions = history.my_actions
        opponent_actions = history.opponent_actions
        num_cooperators = np.sum(np.logical_and(my_actions, opponent_actions[:, self.own_history[-1]]))
        if num_cooperators >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_93(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) with Cooperative-Defensive Ratio (CDR) modification strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperative_defensive_ratio = 0.0
        self.rounds_played = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.cooperative_defensive_ratio = random.uniform(0, 1)
            if self.cooperative_defensive_ratio > 0.5:
                return Action.C
            else:
                return Action.D
        self.rounds_played += 1
        cooperators = sum([action for action in history.opponent_actions[-1] if action])
        cooperative_defensive_ratio = cooperators / self.game_description.n_players
        if state.round_number == self.game_description.n_rounds:
            if self.cooperative_defensive_ratio > random.uniform(0, 1):
                return Action.C
            else:
                return Action.D
        if cooperative_defensive_ratio < self.game_description.m / self.game_description.n_players:
            return Action.D
        elif self.cooperative_defensive_ratio >= self.game_description.m / self.game_description.n_players and self.rounds_played != self.game_description.n_rounds:
            return Action.C
        elif cooperative_defensive_ratio > random.uniform(0, 1):
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_94(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = math.floor(game_description.m / 2)
        if self.cooperation_threshold == game_description.m // 2:
            self.cooperation_threshold -= 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and history.my_actions[-1] is None):
            return Action.C
        opponent_cooperators = sum(history.opponent_actions[-1, :]) if history is not None else 0
        if self.cooperation_threshold > 0 and opponent_cooperators == self.game_description.n_players - 1:
            self.cooperation_threshold += 1
        return Action.C if self.cooperation_threshold > 0 and opponent_cooperators >= self.game_description.m else Action.D

class Strategy_EXPLOITATIVE_96(BaseStrategy):
    """
    Strategy that implements Adaptive Tit-for-Tat with Exploitation Threshold (E-ATFT) for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.exploitation_threshold = 0

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if history is None and state.round_number == 0:
            return Action.C
        if state.round_number == len(history.opponent_actions):
            return Action.C
        cooperators = sum(history.opponent_actions[:, -1])
        if cooperators > (self.game_description.n_players - 1) // 2:
            return Action.C
        elif cooperators >= self.exploitation_threshold and cooperators < self.game_description.m:
            self.exploitation_threshold = cooperators
            return Action.D
        else:
            action = history.opponent_actions[-1, -1]
            if action == Action.C:
                payoffs = np.where(history.opponent_payoffs[-1] >= self.game_description.k, self.game_description.k, 1)
                if sum(payoffs) / len(payoffs) >= self.game_description.m - self.exploitation_threshold:
                    self.exploitation_threshold = cooperators
                    return Action.D
            return action

class Strategy_EXPLOITATIVE_97(BaseStrategy):
    """
    Implementation of the Tit-for-Tat Plus (TfT+) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = self.game_description.m
        self.last_round = self.game_description.n_rounds - 1
        self.punishment_limit = self.last_round - 1
        self.cooperative_switch = self.last_round - 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators >= self.threshold:
                return Action.C
            if history.my_payoffs[-1] < self.game_description.k - 1:
                if state.round_number == self.last_round:
                    return Action.C
                elif state.round_number > self.punishment_limit or history.opponent_actions[0, :].all():
                    return Action.C
            elif state.round_number < self.cooperative_switch:
                pass
            else:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_98(BaseStrategy):
    """
    A strategy that cooperates when the percentage of cooperators exceeds a threshold, calculated based on the minimum required for success and risk aversion factor. The threshold increases as the game progresses to adapt to opponent behavior.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C if random.random() <= self.game_description.m / self.game_description.n_players else Action.D
        cooperators = sum(history.opponent_actions[-1, :])
        self.threshold = self.game_description.m / self.game_description.n_players + (1 - self.game_description.k) * (self.game_description.m - 1) / (self.game_description.n_players * state.round_number)
        if cooperators >= math.ceil(self.threshold):
            return Action.C
        return Action.D

    def last_round_cooperate(self, total_payoff: float) -> bool:
        return total_payoff < history.my_payoffs[-1]

class Strategy_EXPLOITATIVE_99(BaseStrategy):
    """
    A strategy that cooperates in the first round, mimics the opponent's previous move in subsequent rounds, and adjusts its strategy in the final round based on total net benefits obtained from the opponent.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.total_reward = 0.0
        self.total_punishment = 0.0
        self.opponent_cooperated_last_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            self.opponent_cooperated_last_round = False
            return Action.C
        last_round_history = history.opponent_actions[-1]
        self.opponent_cooperated_last_round = bool(np.sum(last_round_history)) > 0
        if state.round_number == self.game_description.n_rounds - 1:
            net_benefit = self.total_reward - self.total_punishment
            if net_benefit > 0:
                return Action.C if self.opponent_cooperated_last_round else Action.D
            elif net_benefit < 0:
                return Action.D if self.opponent_cooperated_last_round else Action.C
        return Action(1 if self.opponent_cooperated_last_round else 0)

    def update_history(self, payoff: float):
        self.total_reward += payoff

    def punish(self):
        self.total_punishment += 1

class Strategy_EXPLOITATIVE_100(BaseStrategy):
    """
    Implementation of Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_rate = 0.5
        self.adaptation_factor = 0.1
        self.history_length = self.game_description.n_rounds // 10 + 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None or len(history.opponent_actions) < self.history_length:
            return Action.D
        cooperation_count = sum(history.opponent_actions[-self.history_length:, -1])
        cooperation_rate = cooperation_count / self.history_length
        adaptation_factor = max(0.0, min(1.0, self.adaptation_factor * (cooperation_rate - 0.5)))
        self.cooperation_rate += adaptation_factor
        self.cooperation_rate = min(max(self.cooperation_rate, 0.2), 0.8)
        threshold = math.floor((self.game_description.n_players - 1) * self.cooperation_rate + 0.5)
        cooperated_last_round = cooperation_count >= threshold
        return Action.C if cooperated_last_round else Action.D

class Strategy_EXPLOITATIVE_103(BaseStrategy):
    """
    A cooperative strategy that imitates others' previous actions but adapts the cooperation threshold dynamically.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.adaptive_cooperation_threshold = math.ceil(game_description.n_players * 0.5)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[state.round_number - 1] if history else [0])
        if cooperators >= self.adaptive_cooperation_threshold:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_104(BaseStrategy):
    """
    Strategy that follows Tit-for-Tat-Adaptive (TfTA) in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif history is not None:
            opponent_action = history.opponent_actions[-1][0]
            self.opponent_history.append(opponent_action)
            if len(self.opponent_history) == self.game_description.n_players - 1 and state.round_number != self.game_description.n_rounds:
                self.opponent_history = self.opponent_history[-self.game_description.n_players + 1:]
            if opponent_action == Action.C:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_105(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) Strategy for Collective Risk Dilemma Game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.coop_threshold = game_description.m
        self.payoffs = np.zeros(self.game_description.n_rounds)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-1, :])
        updated_threshold = self.coop_threshold + int((cooperators - self.coop_threshold) // 2)
        self.coop_threshold = max(min(updated_threshold, self.game_description.n_players), self.game_description.m)
        if cooperators >= self.coop_threshold:
            action = Action.C
        else:
            action = Action.D
        self.payoffs[state.round_number] = 1 - (self.game_description.n_players - cooperators) if cooperators < self.coop_threshold else 1 - (self.game_description.n_players - cooperators) + self.game_description.k
        return action

class Strategy_EXPLOITATIVE_106(BaseStrategy):
    """Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)"""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = self.game_description.n_players
        self.m = self.game_description.m
        self.r = self.game_description.n_rounds
        self.s = int(self.r * 0.75)
        self.cooperation_rate = [0] * (self.r + 1)
        self.last_round_CR = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        self.cooperation_rate[state.round_number] = self.calculate_cooperation_rate(history)
        if state.round_number == self.r and self.last_round_CR is not None:
            self.s = int(self.s * 0.5)
        if self.cooperation_rate[state.round_number] >= self.m / (self.n + 1):
            return Action.C
        else:
            return Action.D

    def calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        total_cooperators = sum(history.my_actions[-self.s:])
        return total_cooperators / self.s

class Strategy_EXPLOITATIVE_107(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy in Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.lookback_window = game_description.n_players // 10
        self.min_coop_prop = game_description.m / game_description.n_players
        self.baseline_probability = 0.5
        self.current_q = self.baseline_probability
        self.w = self.lookback_window
        self.act_active = False

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or not history:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-self.w:, :])
        coop_prop = cooperators / self.w
        if coop_prop >= self.min_coop_prop and (not self.act_active):
            self.current_q = 0.7
            self.act_active = True
        elif coop_prop < self.min_coop_prop and self.act_active:
            self.current_q = self.baseline_probability
            self.act_active = False
        opponent_actions = history.opponent_actions[-1, :] if state.round_number != 0 else np.zeros(self.game_description.n_players)
        cooperators = np.count_nonzero(opponent_actions)
        if random.random() < self.current_q:
            action = Action.C if cooperators >= self.game_description.m else Action.D
        else:
            action = Action.D if cooperators >= self.game_description.m else Action.C
        return action

class Strategy_EXPLOITATIVE_108(BaseStrategy):
    """
    Adaptive Cooperation Strategy for Collective Risk Dilemma.
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_score = 0
        self.defection_score = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            history = PlayerHistory(my_actions=np.array([[Action.C]], dtype=bool), my_payoffs=np.array([0.0], dtype=float), opponent_actions=np.zeros((1, self.game_description.n_players), dtype=bool), opponent_payoffs=np.zeros((1, self.game_description.n_players), dtype=float))
        if history.my_actions[-1] is None:
            history.my_actions[-1] = Action.C
        cooperation = np.sum(history.opponent_actions[-1, :])
        if cooperation < self.game_description.m:
            return Action.D
        elif cooperation == self.game_description.m:
            return Action.C
        else:
            if self.cooperation_score >= self.defection_score:
                self.cooperation_score += 1
                self.defection_score = 0
            elif self.defection_score > self.cooperation_score:
                self.defection_score += 1
                self.cooperation_score = 0
            return Action(int(self.cooperation_score >= self.defection_score))

class Strategy_EXPLOITATIVE_109(BaseStrategy):
    """
    Implementation of the Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT) strategy for Collective Risk Dilemma games.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = math.ceil(game_description.n_players // 2) - 1
        self.last_round_majority = np.zeros(self.game_description.n_players, dtype=np.bool_)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None or state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators > self.cooperation_threshold:
            return Action.C
        elif cooperators <= self.cooperation_threshold:
            return Action.D
        if np.sum(history.opponent_actions[-1]) > self.game_description.n_players - self.cooperation_threshold:
            self.cooperation_threshold += 1
        elif np.sum(history.opponent_actions[-1]) <= self.cooperation_threshold:
            self.cooperation_threshold -= 1
        self.last_round_majority = history.opponent_actions[-1, :]
        return Action.C if np.sum(self.last_round_majority) > self.game_description.n_players - self.cooperation_threshold else Action.D

class Strategy_EXPLOITATIVE_110(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) Strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.mCT = game_description.m
        self.round_payoff = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None or len(history.opponent_actions) < state.round_number:
            self.mCT = self.game_description.m
        cooperators = sum(history.opponent_actions[state.round_number - 1, :])
        if state.round_number < self.game_description.n_rounds and cooperators >= self.mCT:
            self.round_payoff = 0
            return Action.C
        elif state.round_number < self.game_description.n_rounds and cooperators < self.mCT:
            self.mCT += 0.1
            self.round_payoff = 1
            return Action.D
        elif state.round_number == self.game_description.n_rounds:
            self.round_payoff = 2 * (self.game_description.k if cooperators >= self.mCT else 1)
            return Action.C
        self.round_payoff += payoff_calculation(Action.D, cooperators)
        return Action.D

class Strategy_EXPLOITATIVE_111(BaseStrategy):
    """
    The Tit-for-Tat with Adaptive Cooperation Threshold strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1] if history else np.zeros(self.game_description.n_players, dtype=np.bool))
        return Action.D if cooperators < self.threshold else Action.C

class Strategy_EXPLOITATIVE_112(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = self.game_description.n_players // 2
        self.consecutive_defections = 0
        self.history_window = int(self.game_description.n_players * 0.5)

    def __call__(self, state: GameState, history: PlayerHistory):
        if state.round_number == 0:
            return Action.C
        opponent_cooperators = sum(history.opponent_actions[-1, :])
        if opponent_cooperators >= self.threshold:
            self.consecutive_defections = 0
            return Action.C
        if self.consecutive_defections < self.history_window:
            return Action.C
        self.consecutive_defections += 1
        return Action.D

class Strategy_EXPLOITATIVE_113(BaseStrategy):
    """
    Strategy name: Tit-for-Tat-Plus (TFT+)
    Strategy description: Reciprocates cooperation if opponent cooperated in the previous round, otherwise defects as a punishment. Has a forgiveness mechanism that encourages opponents to reap benefits by avoiding being punished repeatedly.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_cooperated_round = -1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        last_round = state.round_number - 1 if history is not None else 0
        last_opponent_action = history.opponent_actions[last_round, 0] if history is not None else None
        if last_opponent_action is None:
            return Action.C
        if last_opponent_action:
            self.last_cooperated_round = last_round
            return Action.C
        elif state.round_number > 1 and (self.last_cooperated_round == 0 or self.last_cooperated_round - last_round > 2):
            self.last_cooperated_round = state.round_number
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_114(BaseStrategy):
    """
    Tit-for-Tat strategy for Collective Risk Dilemma
    Cooperation and punishment adapt to opponent behaviors while maintaining an exploitative edge when necessary
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(self.game_description.n_rounds, dtype=bool), np.zeros(self.game_description.n_rounds), np.zeros((self.game_description.n_rounds, self.game_description.n_players), dtype=bool), np.zeros((self.game_description.n_rounds, self.game_description.n_players)))

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.game_description.n_players // 2 and history.my_payoffs[-1] < self.game_description.k:
            return Action.C
        return Action.D

    def update(self, state: GameState, payoff: float) -> None:
        """
        Update player history with new state and payoff
        """
        self.history.my_actions[state.round_number] = (self.__call__(state, self.history) == Action.C).astype(int)
        self.history.my_payoffs[state.round_number] = payoff
        if state.round_number < self.game_description.n_rounds - 1:
            opponents_cooperated = sum(self.history.opponent_actions[-2, :]) > self.game_description.n_players // 2
            self.history.opponent_actions[state.round_number, self.__class__.__name__.lower()] = opponents_cooperated if state.round_number != 0 else random.choice([True, False])
            self.history.opponent_payoffs[state.round_number, self.__class__.__name__.lower__()] = payoff * (1 - self.history.my_actions[-1]) + self.game_description.k * self.history.my_actions[-1]

class Strategy_EXPLOITATIVE_115(BaseStrategy):
    """
    A strategy inspired by the Tit-for-Tat game theory concept, adapted for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(self.game_description.n_rounds, dtype=bool), np.zeros(self.game_description.n_rounds), np.zeros((self.game_description.n_rounds, self.game_description.n_players), dtype=bool), np.zeros((self.game_description.n_rounds, self.game_description.n_players)))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        opponent_cooperators = sum(history.opponent_actions[state.round_number - 1, :])
        current_round = self.history.my_payoffs[-1]
        if state.round_number == self.game_description.n_rounds - 1:
            if opponent_cooperators >= self.game_description.m:
                return Action.C
            return Action.D
        if opponent_cooperators < self.game_description.m and current_round <= (1 - self.game_description.m) / self.game_description.k:
            return Action.D
        if opponent_cooperators >= self.game_description.m:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_116(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation (TFTA) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_coop = math.ceil(game_description.n_players * game_description.m / 100)
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros(game_description.n_rounds))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        self.history.my_actions[state.round_number] = True
        cooperators = sum(self.history.opponent_actions[-1, :])
        if cooperators < self.min_coop:
            self.history.my_payoffs[state.round_number] = 1
            return Action.D
        self.history.my_payoffs[state.round_number] = 1 - len(np.where(self.history.opponent_actions[-1, :] == False)[0]) / len(self.history.opponent_actions[-1, :]) + self.game_description.k
        return Action.C if cooperators >= self.min_coop else Action.D

class Strategy_EXPLOITATIVE_117(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.ct = int(math.ceil(game_description.n_players / 2))
        self.f = 5
        self.cooperation_avg = np.zeros((self.f + 1,))
        self.cooperation_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        self.cooperation_count += 1
        cooperators = sum(history.opponent_actions[-self.f:, -1])
        cooperation_percentage = cooperators / self.f
        self.cooperation_avg[:self.cooperation_count] = cooperation_percentage
        if cooperation_percentage >= 0.6:
            self.ct += 1
        elif cooperation_percentage < 0.6:
            self.ct -= 1
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.ct:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_118(BaseStrategy):
    """
    A Tit-for-Tat strategy with an adaptive cooperation threshold. The strategy cooperates when the majority of players have cooperated in the past r rounds, and adjusts the cooperation threshold dynamically based on the number of cooperators.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.cooperators_count = 0
        self.defector_count = 0
        self.rounds_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or len(self.rounds_history) < self.game_description.n_rounds:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-self.game_description.n_rounds:, :][:, -1])
        if cooperators >= self.cooperation_threshold:
            self.cooperators_count += 1
        else:
            self.defector_count += 1
        threshold_adjustment = (self.cooperators_count < self.game_description.m - 1) - (self.cooperators_count > self.game_description.m + 2)
        self.cooperation_threshold += threshold_adjustment * 0.05
        self.rounds_history.append(len(self.rounds_history) < self.game_description.n_rounds)
        if len(self.rounds_history) == self.game_description.n_rounds:
            self.cooperators_count = 0
            self.defector_count = 0
        return Action.C if self.cooperation_threshold >= self.game_description.m + len(self.rounds_history) - self.defector_count else Action.D

class Strategy_EXPLOITATIVE_119(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperative Threshold (TFT-ACT) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperative_threshold = math.ceil(game_description.n_players * 0.5)
        self.last_round_action = Action.C
        self.previous_defectors = set()

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return self.last_round_action
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.cooperative_threshold and len(self.previous_defectors) == 0:
            self.last_round_action = Action.C
        elif cooperators < self.cooperative_threshold - 1:
            self.last_round_action = Action.D
        else:
            self.previous_defectors = set() if len(self.previous_defectors) == self.game_description.n_players - 1 else self.previous_defectors
        return self.last_round_action

class Strategy_EXPLOITATIVE_120(BaseStrategy):
    """Adaptive Tit-for-Tat strategy for the Collective Risk Dilemma game."""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponents = set()
        self.current_round = 1
        self.cooperation_threshold = game_description.m
        self.payoff_this_round = 0.0
        self.strategy = Action.C

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if not history:
            return Action.D
        current_round = state.round_number
        if current_round == 0:
            self.strategy = Action.C
        else:
            opponent_actions = history.opponent_actions[current_round - 1]
            cooperators = sum(opponent_actions)
            if all((action == Action.C for action in opponent_actions)):
                self.opponents.clear()
                self.strategy = Action.C
            elif cooperators < self.cooperation_threshold - 1:
                self.strategy = Action.D
                if self.opponents:
                    self.opponents.remove(history.my_actions[current_round - 1].argmax())
            elif len(self.opponents) < self.cooperation_threshold - 1:
                opponent = history.my_actions[current_round - 1].argmin()
                if opponent not in self.opponents and cooperators >= self.cooperation_threshold:
                    self.strategy = Action.C
                    self.opponents.add(opponent)
            else:
                self.strategy = Action.D
        payoff_this_round = math.floor(1 - int(self.strategy == Action.C) + self.game_description.k * len(self.opponents))
        if current_round < self.game_description.n_rounds:
            self.current_round += 1
        return self.strategy

class Strategy_EXPLOITATIVE_121(BaseStrategy):
    """
    A strategy implementing Tit-for-Tat with Adaptive Cooperative Threshold (TFTC) for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperative_threshold = self.game_description.m / self.game_description.n_players
        self.cooperative_streak_counter = 0
        self.previous_opponents_cooperation = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            self.previous_opponents_cooperation = history.opponent_actions[-1].sum()
        cooperators_in_current_round = history.my_actions.sum() if history else 0
        if cooperators_in_current_round >= self.cooperative_threshold:
            self.cooperative_streak_counter += 1
        if self.cooperative_streak_counter >= self.cooperative_threshold:
            self.cooperative_threshold += 1
        if self.previous_opponents_cooperation - cooperators_in_current_round > self.cooperative_threshold - 1:
            self.cooperative_streak_counter = 0
            self.cooperative_threshold = self.game_description.m / self.game_description.n_players
        if state.round_number == self.game_description.n_rounds:
            if self.cooperative_streak_counter >= self.cooperative_threshold:
                return Action.C
            else:
                return Action.D
        return Action.C if cooperators_in_current_round >= self.cooperative_threshold else Action.D

class Strategy_EXPLOITATIVE_122(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation (TFT-AC) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.t = int(game_description.n_players * 0.7)
        self.s = int(game_description.n_players * 0.9)
        self.strategy = 'tit-for-tat'
        self.consecutive_cooperators = 0
        self.consecutive_defectors = 0

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        action = self._determine_action(history)
        if action == Action.C and self.consecutive_cooperators >= self.s:
            self.strategy = 'tit-for-tat'
            self.consecutive_cooperators = 0
        if action == Action.D and self.consecutive_defectors > self.t:
            self.strategy = 'exploitative'
            self.consecutive_defectors = 0
        if action == Action.C:
            self.consecutive_cooperators += 1
        if action == Action.D:
            self.consecutive_defectors += 1
        return action

    def _determine_action(self, history: PlayerHistory) -> Action:
        if self.strategy == 'tit-for-tat':
            opponent_last_action = history.opponent_actions[-1, 0]
            if opponent_last_action:
                return Action.C
            return Action.D
        elif self.strategy == 'exploitative':
            opponent_last_action = history.opponent_actions[-1, 0]
            if opponent_last_action:
                return Action.C
            return Action.D

class Strategy_EXPLOITATIVE_123(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = self.game_description.m / self.game_description.n_players
        self.past_rounds = np.zeros(self.game_description.n_rounds)
        self.average_payoff = 0.0
        self.total_payoff = 0.0

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if history is None:
            self.past_rounds[state.round_number - 1] = 0
        else:
            self.past_rounds[state.round_number - 1] = np.mean(history.opponent_actions[:, -1])
            if state.round_number >= self.game_description.n_rounds:
                self.cooperation_threshold = max(min(self.cooperation_threshold, (self.game_description.n_players - self.game_description.m) / self.game_description.n_players), self.game_description.m / self.game_description.n_players)
                if history.my_payoffs[-1] > self.average_payoff:
                    self.cooperation_threshold += 0.01
                else:
                    self.cooperation_threshold -= 0.01
                self.average_payoff = np.mean(history.my_payoffs) if len(history.my_payoffs) > 1 else 0
        if len(self.past_rounds) >= self.game_description.n_rounds and np.sum(self.past_rounds[-self.game_description.n_rounds:]) >= self.game_description.m:
            action = Action.C
            self.total_payoff += history.my_payoffs[state.round_number - 1] * (self.cooperation_threshold > state.round_number / self.game_description.n_rounds)
        else:
            action = Action.D
        return action

class Strategy_EXPLOITATIVE_124(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Variable Threshold (ATFT-VT) for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = 0.5 * self.game_description.n_players // self.game_description.m
        self.history_cooperators = np.zeros(self.game_description.n_rounds)

    def __call__(self, state: GameState, history: PlayerHistory):
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        self.history_cooperators[state.round_number - 1] = cooperators
        if cooperators >= self.threshold:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1 and cooperators < self.threshold:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_126(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.coop_threshold = game_description.m
        self.history_length = min(int(game_description.n_rounds * 0.8), game_description.n_rounds)
        self.average_cooperation = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        player_actions = history.my_actions[-self.history_length:]
        cooperators = np.count_nonzero(player_actions)
        cooperative_ratio = cooperators / self.game_description.n_players
        if state.round_number == history.my_actions.size - 1 or (cooperative_ratio < 0.5 and cooperators < self.coop_threshold):
            return Action.D
        elif cooperative_ratio >= 0.5:
            self.coop_threshold = min(self.coop_threshold + 1, self.game_description.n_players)
        return Action.C

class Strategy_EXPLOITATIVE_127(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.act = self.game_description.n_players // 2
        self.recent_cooperators = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            self.recent_cooperators = [sum(history.opponent_actions[0])]
        else:
            self.recent_cooperators.append(sum(history.opponent_actions[-1]))
            if sum(self.recent_cooperators) < self.game_description.m * len(self.recent_cooperators):
                self.act += 1
            elif sum(self.recent_cooperators) >= self.game_description.m * len(self.recent_cooperators):
                self.act -= 1
            if sum(history.opponent_actions[-1]) == self.act:
                return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            if sum(history.opponent_actions[-1]) >= self.game_description.m:
                return Action.C
        return Action.D if sum(history.opponent_actions[-1]) < self.game_description.m else Action.C

class Strategy_EXPLOITATIVE_128(BaseStrategy):
    """
    A Tit-for-Tat strategy with a twist for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = []
        self.my_cooperation = True

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if history is None:
            return Action.C
        if state.round_number == len(history.opponent_actions):
            opponent_last = history.opponent_actions[-1][-1]
            return self.decide_action(opponent_last)
        opponent_last = history.opponent_actions[-1][-1]
        self.opponent_history.append(opponent_last)
        action = self.decide_action(opponent_last)
        return action

    def decide_action(self, opponent_last: bool):
        if not self.my_cooperation and opponent_last:
            self.my_cooperation = True
            return Action.C
        elif self.my_cooperation and (not opponent_last):
            self.my_cooperation = False
            return Action.D
        elif self.my_cooperation and opponent_last:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_129(BaseStrategy):
    """
    A Tit-for-Tat strategy with an adaptive cooperation threshold (TFT-ACT).
    The TFT-ACT strategy cooperates when a minimum number of players cooperate in the previous round,
    and adjusts its cooperation threshold based on long-term average percentage of cooperators seen.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.initial_threshold = game_description.m // 2
        self.tolerance_level = 0.9
        self.adaptation_speed = 0.1
        self.adaptive_step = (self.tolerance_level - self.adaptation_speed) / self.game_description.n_players
        self.history_length = self.game_description.n_rounds // 10 if self.game_description.n_rounds % 10 != 0 else self.game_description.n_rounds
        self.cooperation_count = 0
        self.total_rounds = 0
        self.average_cooperation = np.zeros(self.history_length)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C if random.random() < self.initial_threshold / self.game_description.n_players else Action.D
        if history is not None:
            self.total_rounds += 1
            self.cooperation_count += np.sum(history.my_actions)
            for i in range(self.history_length - 1, 0, -1):
                self.average_cooperation[i - 1] = (self.average_cooperation[i] * (self.total_rounds - i) + self.cooperation_count) / self.total_rounds
            if np.mean(self.average_cooperation) > self.tolerance_level:
                self.initial_threshold -= self.adaptive_step
            elif np.mean(self.average_cooperation) < self.tolerance_level - self.adaptation_speed:
                self.initial_threshold += self.adaptive_step
            cooperation = np.sum(history.opponent_actions[-1, :]) >= self.game_description.m and self.initial_threshold <= np.mean(self.average_cooperation)
            return Action.C if cooperation else Action.D

class Strategy_EXPLOITATIVE_130(BaseStrategy):
    """
    Tit-for-Tat-Plus (TfT+) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = int(self.game_description.n_players * self.game_description.m / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            return Action.D
        cooperators = sum(history.opponent_actions[-1])
        if cooperators >= self.m:
            return Action.C
        else:
            return Action.D

    def last_round(self, state: GameState) -> bool:
        return state.round_number == self.game_description.n_rounds

class Strategy_EXPLOITATIVE_131(BaseStrategy):
    """
    Implementation of the Tit-for-Tat-Adaptive (TfT-A) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = []
        self.forgiveness_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or len(self.opponent_history) == 0:
            return Action.C
        opponent_action = self.opponent_history[-1] if len(self.opponent_history) > 0 else None
        current_round_action = opponent_action if opponent_action is not None and (opponent_action or self.forgiveness_counter > 0) else Action.D
        if current_round_action == Action.C:
            if len(self.opponent_history) > 1 and self.opponent_history[-2] == Action.D:
                self.forgiveness_counter = min(self.game_description.n_players // 2, self.forgiveness_counter + 1)
            else:
                self.forgiveness_counter = 0
        elif current_round_action == Action.D and len(self.opponent_history) > 1 and (self.opponent_history[-2] == Action.C):
            self.forgiveness_counter = max(0, self.forgiveness_counter - 1)
        if history is not None:
            self.opponent_history.append(current_round_action)
        return current_round_action

class Strategy_EXPLOITATIVE_132(BaseStrategy):
    """
    The TFT-ACT strategy follows a tit-for-tat approach with an adaptive cooperation threshold.
    It cooperates initially and then adjusts its actions based on the number of cooperators in the previous round.
    It also includes a safety valve to prevent being trapped indefinitely in cycles of defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.p = 5
        self.q = 3
        self.history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if len(self.history) < state.round_number:
            self.history.extend([[Action.D] * self.n_players for _ in range(state.round_number)])
        cooperators = sum(self.history[-1])
        if state.round_number == self.game_description.n_rounds:
            return Action.C
        if len(self.history) >= self.p and cooperators >= self.p:
            return Action.C
        if cooperators < self.m:
            if state.round_number > self.q and len(self.history) >= self.q + 1 and (self.history[-self.q - 1] == [Action.D] * self.n_players):
                return Action.D
            else:
                return Action.C
        return Action.C

class Strategy_EXPLOITATIVE_133(BaseStrategy):
    """
    The Tit-for-Tat with Adaptation (TfTA) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n = game_description.n_players

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if history is None or state.round_number == 0:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-1])
        if cooperators == self.n:
            return Action.C
        elif cooperators < self.m:
            return Action.D
        else:
            recent_cooperation = np.mean(history.opponent_actions[-self.game_description.n_rounds // 2:-1])
            if recent_cooperation > self.m / self.n:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_134(BaseStrategy):
    """
    A Tit-for-Tat-k strategy for the Collective Risk Dilemma game.
    Adjusts behavior based on previous round's cooperation level and a k-factor reward.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.k = self.game_description.k
        self.last_round_payoff = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.D
        elif state.round_number < self.game_description.n_rounds - 1:
            cooperators = sum(history.opponent_actions[-1])
            if cooperators >= self.game_description.m and self.last_round_payoff <= 1:
                return Action.D
            elif cooperators < self.game_description.m:
                self.last_round_payoff = 0.0
                return Action.C
            else:
                self.last_round_payoff = history.opponent_payoffs[-1][-1] * self.k
                return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_136(BaseStrategy):
    """
    Implementation of the Tit-for-Tat with Risk Aversion (TFTRA) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros((game_description.n_rounds, game_description.n_players)))

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            self.history.my_actions[0] = True
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.game_description.m and cooperators < self.game_description.n_players - (2 * self.game_description.m - 3):
            return Action.D
        elif cooperators >= self.game_description.m and cooperators >= self.game_description.n_players - (2 * self.game_description.m - 1):
            return Action.C
        elif len(history.my_actions) < self.game_description.n_rounds:
            self.history.my_actions[-1] = True
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1 and history.my_actions[-2][-self.game_description.m - 1:].sum() >= self.game_description.m:
            return Action.C
        else:
            self.history.my_actions[-1] = True
            return Action.C

class Strategy_EXPLOITATIVE_137(BaseStrategy):
    """
    A simple adaptation of the classic Tit-for-Tat strategy for the Collective Risk Dilemma game.
    The strategy cooperates with other players if at least 'm' players cooperated in the previous round,
    and defects otherwise. This encourages cooperation but is also robust to defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            cooperators = sum(history.opponent_actions[-1])
            if cooperators >= self.m:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_138(BaseStrategy):
    """
    A Tit-for-Tat-with-Threshold (TFTT) strategy that cooperates when a majority is cooperating and defects if less than m players are cooperating.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-1]) if history is not None else 0
        if cooperators < self.m:
            return Action.D
        return Action.C

class Strategy_EXPLOITATIVE_139(BaseStrategy):
    """
    Strategy that employs the Tit-for-Tat approach with adaptation in Collective Risk Dilemma games.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = int(math.ceil(game_description.n_rounds * 0.8))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if not history:
            return Action.C
        current_round = len(history.opponent_actions) - 1
        if current_round == state.round_number:
            return Action.C
        elif current_round == state.round_number - 1 and self.threshold > 0:
            return Action.C
        else:
            opponent_cooperated = sum(history.opponent_actions[current_round]) >= self.game_description.m
            return history.my_actions[-1] if opponent_cooperated else Action.D

class Strategy_EXPLOITATIVE_140(BaseStrategy):
    """
    A strategy called Maximum-Gain Defector (MGD) for the Collective Risk Dilemma game.
    MGD is adaptive, robust, and independent of the opponent's strategies. It aims to maximize individual rewards by adopting a conditional cooperation approach.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m
        self.k = game_description.k
        self.n = game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        else:
            if history is None or len(history.opponent_actions) <= state.round_number - 1:
                cooperators = self.n
            else:
                cooperators = sum(history.opponent_actions[-state.round_number, :])
            if cooperators >= self.min_cooperators:
                return Action.C
            return Action.D

class Strategy_EXPLOITATIVE_141(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation (TFTA)
    Strategy Description: A strategy that cooperates in the first round and mimics the opponent's action from the previous round. It adjusts the probability of cooperation based on the past behavior of other players to exploit opportunities for higher payoffs when the threshold is close to being met.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_probability = 0.7
        self.past_cooperation_count = 0
        self.past_defection_count = 0

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            return Action.D
        action = Action.D
        if history.opponent_actions[-1, -1] == Action.C:
            action = Action.C
        payoff = 0
        if history:
            payoff = np.mean(history.my_payoffs)
        if action == Action.C:
            self.past_cooperation_count += 1
            self.past_defection_count = 0
        else:
            self.past_cooperation_count = 0
            self.past_defection_count += 1
        if self.past_defection_count >= 5 and state.round_number > self.game_description.n_players // 2:
            self.cooperation_probability = max(self.cooperation_probability * 0.3, 0.3)
        if self.past_cooperation_count >= 5 and state.round_number > self.game_description.n_players // 2:
            self.cooperation_probability = min(self.cooperation_probability * 1.3, 1.0)
        if random.random() < self.cooperation_probability:
            action = Action.C
        if state.round_number == self.game_description.n_rounds and payoff < self.game_description.k - 1:
            action = Action.D
        return action

class Strategy_EXPLOITATIVE_142(BaseStrategy):
    """
    Tit-for-Tat with Adaptation (TFT-A) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.round_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None and state.round_number == 0:
            return Action.C
        self.round_history.append(history.opponent_actions[state.round_number - 1])
        if state.round_number == len(self.round_history):
            return Action.C
        last_action = self.round_history[-1][-1]
        second_last_action = self.round_history[-2][-1] if len(self.round_history) > 1 else None
        if state.round_number == 1:
            return Action.C
        elif last_action == Action.C and second_last_action == Action.D:
            return Action.D
        elif last_action == Action.C and second_last_action != Action.D:
            return Action.C
        elif np.all(self.round_history[-1] == 0):
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_143(BaseStrategy):
    """
    Implementation of the Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy in Collective Risk Dilemma games.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.CT = game_description.n_players // 2
        self.w = min(math.ceil(game_description.n_rounds * 0.1), int(game_description.n_rounds / 4))
        self.T = 0.6
        self.delta = min(self.CT, math.floor(self.CT * 0.1))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_cooperators = sum(history.opponent_actions[-self.w:, :].sum(axis=0)) if history else 0
        cooperation_rate = opponent_cooperators / self.w if history else 0
        if cooperation_rate > self.T:
            self.CT = min(self.CT + self.delta, self.game_description.m - 1)
        elif cooperation_rate < self.T:
            self.CT = max(self.CT - self.delta, self.game_description.n_players // (2 * self.game_description.n_players))
        return Action.C if cooperation_rate >= self.CT and history.opponent_actions[-1, :][-1] == Action.C else Action.D

class Strategy_EXPLOITATIVE_144(BaseStrategy):
    """
    The Tit-for-Tat strategy with an adaptive cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m_threshold = game_description.m
        self.rounds_passed = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        self.rounds_passed += 1
        if self.rounds_passed < int(self.game_description.n_players * 0.1):
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators >= self.m_threshold:
                return Action.C
            return Action.D
        else:
            self.m_threshold = int(self.game_description.n_players * (0.3 + 0.7 * (self.rounds_passed - int(self.game_description.n_players * 0.1)) / (self.game_description.n_rounds - int(self.game_description.n_players * 0.1))))
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators >= self.m_threshold:
                return Action.C
            return Action.D

class Strategy_EXPLOITATIVE_145(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Variance strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.majority_threshold = game_description.n_players // 2
        self.variance_threshold = 0.3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        previous_round_cooperators = np.sum(history.my_actions[-1])
        variance = self.variance(history.my_actions)
        if previous_round_cooperators >= self.majority_threshold and variance <= self.variance_threshold:
            return Action.C
        else:
            return Action.D

    def variance(self, past_actions: NDArray[np.bool_]) -> float:
        cooperation = np.mean(past_actions)
        variance_sum = 0
        for action in past_actions:
            variance_sum += (action - cooperation) ** 2
        return variance_sum / len(past_actions)

class Strategy_EXPLOITATIVE_146(BaseStrategy):
    """
    A simple Tit-for-Tat with Adaptive Cooperation Threshold strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperative_threshold = self.game_description.m
        self.rounds_played = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is not None and state.round_number > 0:
            self.cooperative_threshold += (self.game_description.m - self.cooperative_threshold) * (self.game_description.n_players - self.game_description.m) / (self.game_description.n_players - 1)
        if state.round_number == 0:
            return Action(random.choice([0, 1]))
        elif state.round_number == self.game_description.n_rounds:
            return Action.C
        else:
            cooperators = sum(history.opponent_actions[-1])
            return Action(cooperators >= self.cooperative_threshold)

class Strategy_EXPLOITATIVE_147(BaseStrategy):
    """
    Strategy name: Tit-for-Tat Adaptive (TfT-A)
    A strategy that cooperates in the first round and mimics an opponent's previous action in subsequent rounds.
    If no history is available, it assumes cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(1, dtype=bool), np.zeros(1, dtype=float), np.zeros((1, game_description.n_players), dtype=bool), np.zeros((1, game_description.n_players), dtype=float))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        self.history = history if history else self.history
        recent_action = self.history.opponent_actions[-1, -1]
        return Action(int(recent_action) ^ int(self.history.my_actions[0]))

class Strategy_EXPLOITATIVE_148(BaseStrategy):
    """
    A simple Tit-for-Tat with Rationality strategy for the Collective Risk Dilemma.
    This strategy cooperates initially and mimics opponents' actions in subsequent rounds.
    It adopts a rational approach to defection when it might be beneficial.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.m
        self.k_factor = game_description.k
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros((game_description.n_rounds, game_description.n_players)))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None and state.round_number == 0:
            return Action.C
        if state.round_number == len(self.history.my_actions):
            self.history.my_actions = np.append(self.history.my_actions, [self.__call__(GameState(state.round_number + 1), None)])
            self.history.my_payoffs = np.append(self.history.my_payoffs, np.zeros(1))
        opponent_cooperators = sum(self.history.opponent_actions[-1, :])
        if opponent_cooperators >= self.threshold:
            cooperators = self.history.my_actions[-1]
            self.history.my_actions = np.append(self.history.my_actions, [cooperators])
            self.history.my_payoffs = np.append(self.history.my_payoffs, np.zeros(1))
        else:
            self.history.my_actions = np.append(self.history.my_actions, [self.history.opponent_actions[-1, -1]])
            self.history.my_payoffs = np.append(self.history.my_payoffs, np.zeros(1))
        return Action(int(self.history.my_actions[-1]))

class Strategy_EXPLOITATIVE_149(BaseStrategy):
    """Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)"""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.coop_threshold = math.ceil(game_description.m / game_description.n_players * 5)
        self.avg_cooperation = np.zeros(self.coop_threshold + 1)
        self.p_t = 0.2

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if state.round_number == 0 or state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        cooperators = sum(history.opponent_actions[-self.coop_threshold:, :] if history else np.zeros((self.coop_threshold + 1, 1)))
        average_cooperation = np.mean(cooperators)
        if average_cooperation > self.game_description.m / self.game_description.n_players and self.p_t < 1:
            self.p_t += (1 - self.p_t) * 0.2
        if average_cooperation >= self.game_description.m / self.game_description.n_players or state.round_number == self.game_description.n_rounds:
            self.p_t = 1
        if random.random() < self.p_t:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_150(BaseStrategy):
    """
    An implementation of the Adaptive Tit-for-Tat strategy for Collective Risk Dilemma games.
    This strategy cooperates in the first round and mimics opponents' actions from the previous round thereafter.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_round_payoff = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.game_description.m and self.last_round_payoff > self.game_description.k - 1:
            return Action.C
        self.last_round_payoff = np.mean(history.my_payoffs[-1])
        return Action.D

class Strategy_EXPLOITATIVE_151(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)
    Strategy Description: This strategy cooperates when the number of cooperators in the previous round exceeds a dynamic cooperation threshold (CT). If the number of cooperators is less than or equal to CT, the strategy will defect. The cooperation threshold is adaptive and changes based on the history of the game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.stability_period = int(game_description.n_players * 0.8)
        self.adaptation_rate = 1 / game_description.n_players
        self.rounds_since_cooperation = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperation = sum(history.opponent_actions[-1, :]) if history is not None else 0
        self.rounds_since_cooperation += 1 if cooperation > self.cooperation_threshold else 0
        if self.rounds_since_cooperation >= self.stability_period or cooperation >= self.cooperation_threshold:
            self.rounds_since_cooperation = 0
            self.cooperation_threshold = max(min(self.cooperation_threshold + self.adaptation_rate, self.game_description.n_players), self.cooperation_threshold - self.stability_period * self.adaptation_rate)
        return Action.C if cooperation > self.cooperation_threshold else Action.D

class Strategy_EXPLOITATIVE_153(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATFT)
    Strategy Description: This strategy cooperates initially and reciprocates cooperation in subsequent rounds,
                           but punishes defection. If a majority of players have been cooperating for some consecutive rounds,
                           it continues to cooperate even if the opponent defected last round. Conversely, if a majority of players have been defecting, it defects indefinitely.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.majority_threshold = math.ceil(game_description.n_players / 2)
        self.consecutive_rounds = 3
        self.current_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        action = Action.D
        if history:
            cooperators = sum(history.opponent_actions[-self.consecutive_rounds:, :])
            if len(cooperators) >= self.majority_threshold:
                self.current_cooperators = min(self.game_description.n_players, len(cooperators))
                action = Action.C
            elif history.my_actions[-1] == Action.D and self.current_cooperators > 0:
                self.current_cooperators -= 1
            elif history.my_actions[-1] == Action.C:
                self.current_cooperators += 1
        return action

class Strategy_EXPLOITATIVE_154(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_levels = []
        self.cooperation_threshold = self.game_description.m / self.game_description.n_players * self.game_description.n_players

    def __call__(self, state: GameState, history: PlayerHistory | None):
        if not history:
            return Action.C
        if state.round_number == 1:
            self.cooperation_levels.append(history.my_actions[0])
            self.update_threshold()
            return Action.C
        cooperation_level = np.mean(self.cooperation_levels[-self.game_description.n_players:])
        if cooperation_level > self.cooperation_threshold:
            return Action.C
        return Action.D

    def update_threshold(self):
        if len(self.cooperation_levels) < self.game_description.n_players:
            return None
        successful_cooperation = sum((1 for element in self.cooperation_levels if element == 1))
        if successful_cooperation >= self.game_description.m:
            self.cooperation_threshold += (self.game_description.m - successful_cooperation) / self.game_description.n_players
        else:
            self.cooperation_threshold -= (1 + np.mean(self.cooperation_levels)) / self.game_description.n_players
        self.cooperation_levels.append(None)

class Strategy_EXPLOITATIVE_155(BaseStrategy):
    """
    Implementation of the Tit-for-Tat Adaptive (TfTA) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.round_counter = 0
        self.forgiveness_period = int(math.ceil(game_description.n_players / 2))
        self.last_cooperation_round = -1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None and state.round_number == 0:
            return Action.C
        action = Action.D
        if state.round_number == 1 or history.my_actions[-1] != Action.C:
            self.last_cooperation_round = -1
        elif state.round_number - self.round_counter >= self.forgiveness_period and history.my_actions[-self.forgiveness_period] == Action.C:
            action = Action.D
            self.last_cooperation_round = -1
        elif state.round_number - self.last_cooperation_round >= self.forgiveness_period:
            action = Action.C
            self.last_cooperation_round = state.round_number
        return action

class Strategy_EXPLOITATIVE_156(BaseStrategy):
    """Maximizer AI for Collective Risk Dilemma game."""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m - 1
        self.cooperators_count = 0
        self.total_reward = 0
        self.round = 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        cooperators_in_previous_round = sum(history.opponent_actions[state.round_number - 1, :]) if history else self.cooperators_count
        self.cooperators_count = 0 if state.round_number == self.game_description.n_rounds else cooperators_in_previous_round >= self.m or (state.round_number > 1 and self.cooperators_count >= self.m)
        payoff = 0 if self.cooperators_count < self.m else self.game_description.k
        self.total_reward += payoff
        if state.round_number == self.game_description.n_rounds and cooperators_in_previous_round > self.m:
            return Action.C
        return Action.D if self.cooperators_count < self.m or (state.round_number > 1 and self.cooperators_count >= self.m) else Action.C

class Strategy_EXPLOITATIVE_157(BaseStrategy):
    """
    The Freeloader strategy is designed to be exploitative by not cooperating when there's a low probability of success.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m - 1

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.D
        elif state.round_number == self.game_description.n_rounds:
            return Action.C
        else:
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators < self.m:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_158(BaseStrategy):
    """
    Tit-for-Tat with Variance (TfTV) strategy for Collective Risk Dilemma game
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.p = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is not None:
            my_cooperated = bool(history.my_actions[-1])
            opponent_cooperated = sum(history.opponent_actions[-1]) >= self.game_description.m
            if state.round_number == self.game_description.n_rounds - 1:
                return Action.C if opponent_cooperated else Action.D
            if opponent_cooperated:
                return Action.C
            if my_cooperated and random.random() < self.p:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_159(BaseStrategy):
    """
    Tit-for-Tat with Gradual Cooperation (TFTGC) Strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.alpha = 0.25
        self.beta = 0.75
        self.gamma = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        round_number = state.round_number
        if round_number == self.game_description.n_rounds:
            return Action.C
        if history is None:
            return Action.D
        opponent_cooperators = sum(history.opponent_actions[-1])
        if opponent_cooperators < self.game_description.m:
            pass_round = math.floor((1 - self.beta) * round_number)
            if round_number <= pass_round:
                return Action.D
            else:
                random_cooperate = np.random.uniform(0, 1, size=1)[0] < self.gamma
                if random_cooperate:
                    return Action.C
        else:
            pass
        return Action.D

class Strategy_EXPLOITATIVE_160(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperative Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m_act = None
        self.n_c_hist = np.zeros(self.game_description.n_rounds)

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.n_c_hist[-1] = sum(history.opponent_actions[state.round_number - 1, :])
        if state.round_number < self.game_description.n_rounds:
            self.n_c_hist = np.roll(self.n_c_hist, -1)
        cooperators = self.n_c_hist.sum()
        if cooperators >= np.floor(np.mean(self.n_c_hist[-3:]) + 1):
            return Action.C
        return Action.D

    def update_m_act(self) -> None:
        self.m_act = math.ceil(np.mean(self.n_c_hist[-3:])) + 1 if np.sum(self.n_c_hist[-3:]) < np.floor(np.mean(self.n_c_hist[-3:])) else self.m_act

    def update_m_act_last_round(self) -> None:
        cooperators = self.n_c_hist[-1]
        if cooperators >= self.m_act:
            self.m_act += 1

class Strategy_EXPLOITATIVE_161(BaseStrategy):
    """
    TFT-AdaptiveRiskAversion strategy in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m
        self.last_round_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1] if history else [0])
        if cooperators >= self.min_cooperators and (cooperators > self.last_round_cooperators or self.last_round_cooperators == 0):
            return Action.C
        if cooperators >= self.min_cooperators and history and (self.last_round_cooperators > 0):
            return Action.D
        return Action.D

    def update_state(self, new_history: PlayerHistory):
        self.last_round_cooperators = sum(new_history.opponent_actions[-1])

class Strategy_EXPLOITATIVE_162(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold Strategy
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.window_size = int(math.ceil(game_description.n_rounds * 0.7))
        self.cooperation_threshold = game_description.m
        self.average_cooperation = np.zeros(self.window_size)
        self.current_round = 0

    def __call__(self, state: GameState, history: PlayerHistory):
        if state.round_number == 0:
            return Action.C
        self.current_round += 1
        cooperators = sum(history.opponent_actions[state.round_number - 1])
        average_cooperation = np.roll(self.average_cooperation, -1)
        average_cooperation[-1] = cooperators / self.game_description.n_players if self.current_round >= self.window_size else average_cooperation[-1]
        self.average_cooperation = np.where(self.average_cooperation > 0, average_cooperation, self.average_cooperation)
        adjusted_threshold = max(min(self.average_cooperation.mean(), self.cooperation_threshold), (self.game_description.m - 1) / self.game_description.n_players)
        if cooperators >= self.game_description.m or state.round_number == self.game_description.n_rounds:
            return Action.C
        elif state.round_number > 1 and cooperators < adjusted_threshold:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_164(BaseStrategy):
    """
    Tit-for-Tat-K (TFT-K) Strategy for Collective Risk Dilemma game.
    Cooperates in the first round and responds cooperatively if opponent cooperated last round,
    otherwise defects as a punishment. In the last round, always cooperate to maximize personal payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_round = self.game_description.n_rounds - 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and state.round_number < self.last_round:
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators >= self.game_description.n_players // self.game_description.m:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_165(BaseStrategy):
    """
    Tit-for-Tat Plus (TfT+) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = int(game_description.m * game_description.n_players / 2)
        self.punishment_threshold = self.min_cooperators // 2
        self.recovery_threshold = self.min_cooperators
        self.current_round = 0
        self.consecutive_defects = 0
        self.last_round_coop_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.current_round += 1
        if history is not None:
            cooperators = sum(history.opponent_actions[-1, :])
            self.last_round_coop_count = cooperators
            if cooperators < self.min_cooperators:
                self.consecutive_defects += 1
                if self.current_round - self.consecutive_defects > self.punishment_threshold:
                    return Action.D
            else:
                self.consecutive_defects = 0
                if self.current_round - self.consecutive_defects >= self.recovery_threshold:
                    return Action.C if self.last_round_coop_count > self.game_description.n_players - self.punishment_threshold else Action.D
        return Action.C if self.consecutive_defects == 0 else Action.D

class Strategy_EXPLOITATIVE_166(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    This strategy cooperates initially to establish trust, responds swiftly to defection, and dynamically adjusts its cooperation threshold based on overall cooperation levels.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.t = self.game_description.n_players // 2
        self.cooperation_threshold = 0.6
        self.cooperation_counts = np.zeros(self.game_description.n_rounds)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.t > self.game_description.n_players // 2:
            cooperation = np.mean(history.my_actions[:state.round_number])
            if cooperation < self.cooperation_threshold:
                self.t = max(self.t - self.game_description.n_rounds // 10, 1)
        elif state.round_number >= self.game_description.n_rounds * (1 - self.cooperation_threshold):
            self.t = min(self.t + self.game_description.n_rounds // 20, self.game_description.n_players)
        cooperators = np.sum(history.opponent_actions[:state.round_number, -1])
        if history and cooperators >= self.game_description.m:
            if state.round_number < state.round_number + self.t:
                return Action.C
        elif history and cooperators < self.game_description.m - 1 and (self.t > 1):
            return Action.D
        return Action.C if history else Action.D

class Strategy_EXPLOITATIVE_167(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.penalty = 0.1
        self.history = PlayerHistory(np.zeros((game_description.n_rounds,), dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros(game_description.n_rounds))

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            self.history = history
            return Action.C
        rounded_cooperators = math.ceil(sum(history.opponent_actions[state.round_number - 1, :]) / self.game_description.n_players)
        if rounded_cooperators >= self.cooperation_threshold:
            return Action.C
        else:
            new_ct = self.cooperation_threshold + (self.cooperation_threshold - rounded_cooperators) * self.penalty
            self.cooperation_threshold = min(new_ct, self.game_description.m)
        return Action.D

class Strategy_EXPLOITATIVE_168(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma game.
    This strategy cooperates initially and adapts the cooperation threshold based on the history of cooperation from opponents to foster a cooperative environment while also being exploitative when necessary.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = None
        self.num_opponents = game_description.n_players - 1
        self.history = PlayerHistory(np.zeros(self.game_description.n_rounds, dtype=bool), np.zeros(self.game_description.n_rounds), np.zeros((self.num_opponents, self.game_description.n_rounds), dtype=bool), np.zeros((self.num_opponents, self.game_description.n_rounds)))

    def __call__(self, state: GameState, history: PlayerHistory):
        if state.round_number == 0:
            return Action.C
        else:
            cooperators = np.sum(history.opponent_actions[-1], axis=0)
            cooperation_threshold = np.mean(cooperators[cooperators > 0]) if np.any(cooperators > 0) else 1
            self.cooperation_threshold = min(self.game_description.n_players, max(cooperation_threshold, 1))
            if cooperators >= self.cooperation_threshold:
                return Action.C
            return Action.D
        self.history.my_actions[state.round_number] = [self.__call__(GameState(state.round_number), None) == Action.C]
        self.history.my_payoffs[state.round_number] = 1 - self.history.my_actions[-1] + self.game_description.k * np.sum(self.history.opponent_actions[-1][self.history.opponent_actions[-1, :].argmax()] == Action.C)
        self.history.opponent_actions[state.round_number, :] = history.opponent_actions[-1]
        self.history.opponent_payoffs[state.round_number, :] = history.opponent_payoffs[-1]

class Strategy_EXPLOITATIVE_169(BaseStrategy):
    """
    A strategy that mimics opponents' cooperation from the preceding round. Cooperates initially, then adapts to the opponent's actions in following rounds. Punishes defection by defecting in response.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_opponent_action = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if history is None or state.round_number == 0:
            self.last_opponent_action = Action.C
        else:
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators >= self.game_description.m and self.last_opponent_action == Action.C:
                return Action.C
            else:
                self.last_opponent_action = history.opponent_actions[-1, -1]
                return Action.D
        return self.last_opponent_action

class Strategy_EXPLOITATIVE_170(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_count = 0
        self.rounds = self.game_description.n_players * self.game_description.n_rounds
        self.CR_threshold = self.game_description.n_players // 4

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and len(history.opponent_actions) >= self.rounds:
            cooperation_count = sum(history.opponent_actions[:, -1])
            CR = cooperation_count / (state.round_number - 1)
            if CR > self.CR_threshold:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_171(BaseStrategy):
    """Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game."""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = self.game_description.m / self.game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[state.round_number - 1, :])
        if cooperators / self.game_description.n_players >= self.threshold:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_172(BaseStrategy):
    """
    A strategy that mimics the Adaptive Tit-for-Tat approach in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.round_number = 0
        self.opponent_defection_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.opponent_defection_streak > 0:
            self.opponent_defection_streak -= 1
            return Action.D
        cooperation_threshold = math.ceil(self.game_description.n_players * 0.5)
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= cooperation_threshold:
            return Action.C
        elif self.round_number == state.round_number - self.opponent_defection_streak and cooperators >= cooperation_threshold:
            return Action.C
        else:
            self.opponent_defection_streak = state.round_number - history.opponent_actions[-1].sum() > 0
            return Action.D

class Strategy_EXPLOITATIVE_173(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptation (TFT-A)
    Description: A strategy that cooperates initially, responds to opponent's cooperation or defection, and adapts the probability of changing behavior.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_cooperated_last_round = False
        self.p = 0.25
        self.t = int(self.game_description.n_rounds * 0.9)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_cooperated = bool(history.opponent_actions[-1][-1] if history is not None else False)
        self.opponent_cooperated_last_round = opponent_cooperated
        if state.round_number >= self.t:
            return Action.D
        if opponent_cooperated:
            return Action.C
        elif not self.opponent_cooperated_last_round:
            return Action.D
        elif random.random() < self.p:
            return Action.C

class Strategy_EXPLOITATIVE_174(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = 1
        self.historical_average_cooperators = 0
        self.increase_factor = 0.05
        self.decrease_factor = 0.02
        self.max_ct = math.ceil(game_description.n_players * 0.4)
        self.min_ct = math.floor(game_description.n_players * 0.1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.historical_average_cooperators = self.historical_average_cooperators * (state.round_number - 2) + sum(history.opponent_actions[-1, :]) / state.round_number if history is not None else 0
        self.update_ct(self.cooperation_threshold, history.opponent_actions[-1, -1] if history is not None else None)
        return Action.C if state.round_number > 1 and self.game_description.n_players >= sum(history.opponent_actions[-2, :]) >= self.cooperation_threshold and (self.historical_average_cooperators <= sum(history.opponent_actions[-1, :])) or (state.round_number > 1 and sum(history.opponent_actions[-2, :]) < sum(history.opponent_actions[-1, :]) < self.cooperation_threshold and (self.historical_average_cooperators > sum(history.opponent_actions[-1, :]))) or sum(history.opponent_actions[-1, :]) >= self.game_description.n_players // self.game_description.m else Action.D

    def update_ct(self, cooperation_threshold: float, previous_round_outcome: bool | None) -> None:
        if previous_round_outcome is True:
            cooperation_threshold += self.increase_factor
        elif previous_round_outcome is False:
            cooperation_threshold -= self.decrease_factor
        cooperation_threshold = max(self.min_ct, min(cooperation_threshold, self.max_ct))
        self.cooperation_threshold = cooperation_threshold

class Strategy_EXPLOITATIVE_175(BaseStrategy):
    """
    A Tit-for-Tat strategy with adaptive cooperation threshold (TFT-ACT).
    Cooperates when the opponent has cooperated as many times as TFT-ACT or if the opponent has defected less than twice as many times.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.successes = 0
        self.defeats = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or not history:
            return Action.C
        opponent_cooperation_count = np.sum(history.opponent_actions[-1, :])
        self.successes += np.where(history.my_actions[-1], 1, 0).sum()
        self.defeats += np.where(history.opponent_payoffs[-1] > 1, 1, 0).sum()
        if opponent_cooperation_count >= self.game_description.n_players // 2 and self.defeats < 2 * self.successes:
            return Action.C
        elif self.defeats > 2 * self.successes:
            return Action.D
        return Action.C

class Strategy_EXPLOITATIVE_178(BaseStrategy):
    """
    A Tit-for-Tat with Adaptation (TfT-A) strategy for the Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.t = 1
        self.l = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        cooperation_count = sum(history.opponent_actions[state.round_number - 1]) if history else 0
        if cooperation_count < self.game_description.m or (cooperation_count >= self.game_description.n_players // 2 and state.round_number > 1):
            return Action.D
        if state.round_number > 1:
            opponent_history = history.opponent_actions[state.round_number - 2:]
            opponent_cooperates = np.any(opponent_history >= self.t)
            if opponent_cooperates:
                self.t += self.l
            else:
                self.t -= self.l
        return Action.C if self.t <= state.round_number - 1 else Action.D

class Strategy_EXPLOITATIVE_179(BaseStrategy):

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_forgive = int(math.ceil(game_description.n_players / 2))
        self.history = []
        self.cooperative_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        action = Action.D
        if history is not None:
            last_round = len(history.opponent_actions) - 1
            cooperators = sum(history.opponent_actions[last_round])
            if self.cooperative_streak > self.n_forgive or (cooperators >= self.game_description.m and action == Action.D):
                if last_round == len(history.opponent_actions) - 1:
                    return Action.D
                elif cooperators < self.game_description.m or (cooperators >= self.game_description.m and action == Action.C):
                    action = Action.C
            self.cooperative_streak = 0 if action == Action.D else self.cooperative_streak + 1
        return action

class Strategy_EXPLOITATIVE_180(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros(game_description.n_rounds))
        self.num_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is not None and self.num_rounds > 0:
            self.history = history
        if state.round_number == 0:
            self.cooperation_threshold = self.game_description.m
        else:
            self.num_rounds += 1
        cooperators = sum(self.history.opponent_actions[-1, :])
        coop_fraction = (cooperators - self.cooperation_threshold) / self.num_rounds if self.num_rounds > 0 else 0
        self.cooperation_threshold += max(coop_fraction, 0)
        return Action.C if cooperators >= self.cooperation_threshold else Action.D

class Strategy_EXPLOITATIVE_181(BaseStrategy):
    """
    Strategy name: Tit-for-Tat-Adaptive (TfT-A)
    A cooperative strategy that encourages reciprocity and punishes defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_round_cooperators = 0
        self.last_round_defectors = 0
        self.current_punishment_round = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None:
            self.last_round_cooperators = 0
            self.last_round_defectors = 0
            self.current_punishment_round = 0
        else:
            cooperators = sum(history.opponent_actions[-1, :])
            self.last_round_cooperators = cooperators
            self.last_round_defectors = self.game_description.n_players - cooperators
            if state.round_number > self.current_punishment_round:
                if self.last_round_defectors == self.last_round_cooperators:
                    self.current_punishment_round += 1
        if state.round_number == self.game_description.n_rounds or cooperators >= self.game_description.m:
            self.current_punishment_round = 0
        return Action(self.last_round_cooperators > self.last_round_defectors)

class Strategy_EXPLOITATIVE_182(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m
        self.previous_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            self.previous_cooperators = sum(history.opponent_actions[-1])
        cooperate = self.previous_cooperators >= self.min_cooperators
        if state.round_number < self.game_description.n_rounds:
            return Action.C if cooperate else Action.D
        return Action.C if cooperate else Action.D

class Strategy_EXPLOITATIVE_183(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) Strategy
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.average_cooperators_window = math.floor(game_description.n_players * 0.3)
        self.adaptation_factor = 0.01
        self.exploitation_rounds = 5
        self.current_rounds_without_threshold = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            return Action.D
        cooperators = sum(history.opponent_actions[-1, :])
        m_prime = len([action for action in history.opponent_actions[-1, :] if action])
        average_cooperators = np.mean(history.my_actions[max(0, state.round_number - self.average_cooperators_window):state.round_number])
        if m_prime >= self.cooperation_threshold and average_cooperators >= self.cooperation_threshold:
            return Action.C
        elif m_prime < self.cooperation_threshold:
            self.current_rounds_without_threshold += 1
            if state.round_number > self.exploitation_rounds:
                self.cooperation_threshold += self.adaptation_factor
                self.current_rounds_without_threshold = 0
            return Action.D
        else:
            self.current_rounds_without_threshold = 0
        return Action.C

class Strategy_EXPLOITATIVE_184(BaseStrategy):
    """
    The Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    TFT-ACT adapts its cooperation based on the average number of cooperators in previous rounds, retaliates to defection, and forgives opponents who switch to cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.s = int(math.ceil(game_description.n_rounds * 0.6))
        self.t = int(math.ceil(self.s * 0.3))
        self.f = int(math.ceil(self.s * 0.2))
        self.u = int(math.ceil(self.s * 0.1))
        self.average_cooperators = np.zeros(self.s + 1)
        self.last_opponent_cooperation = 0
        self.last_opponent_defection = 0
        self.current_threshold = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-1])
        self.average_cooperators[self.s] = cooperators / self.s
        self.average_cooperators[:-1] = self.average_cooperators[1:] + (cooperators - self.average_cooperators[0]) / self.s
        if np.mean(self.average_cooperators) >= self.game_description.m / self.game_description.n_players:
            return Action.C
        else:
            if state.round_number < self.game_description.n_rounds - 1 and self.last_opponent_cooperation > 0:
                self.last_opponent_defection = 0
                self.last_opponent_cooperation = 0
            elif cooperators < self.current_threshold:
                self.last_opponent_defection += 1
                if self.last_opponent_defection >= self.t and self.last_opponent_cooperation < self.game_description.m / self.game_description.n_players:
                    self.current_threshold = int(math.ceil((self.current_threshold + 1) * (1 + random.random() * self.u)))
            else:
                self.last_opponent_defection = 0
                self.last_opponent_cooperation += 1
                if self.last_opponent_cooperation >= self.f:
                    self.last_opponent_cooperation = self.f - 1
                    self.current_threshold = int(math.floor((self.current_threshold - 1) * (1 - random.random() * self.u)))
            return Action.D if cooperators < self.current_threshold else Action.C

class Strategy_EXPLOITATIVE_185(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = int((self.game_description.n_players + 1) / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        opponents_cooperated = np.sum(history.opponent_actions[-1])
        if opponents_cooperated >= self.cooperation_threshold:
            return Action.C
        elif opponents_cooperated == self.cooperation_threshold:
            coin_toss = random.random()
            if coin_toss > 0.5:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_186(BaseStrategy):
    """
    A Tit-for-Tat adaptive cooperation strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = np.zeros(self.game_description.n_rounds, dtype=np.bool_)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        strategy = np.full(state.round_number + 1, Action.C.value)
        if len(self.opponent_history) < state.round_number:
            self.opponent_history[len(self.opponent_history):] = history.opponent_actions[:, 0].flatten()
        for t in range(1, state.round_number + 1):
            if strategy[t - 1] == Action.C.value and self.opponent_history[t - 1] == Action.D.value:
                strategy[t] = Action.D.value
            elif strategy[t - 1] != self.opponent_history[t - 1]:
                strategy[t] = self.opponent_history[t - 1]
        if state.round_number == self.game_description.n_rounds:
            strategy[-1] = Action.C.value
        return Action(strategy[state.round_number])

class Strategy_EXPLOITATIVE_187(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat with Mimicry (ATFM)
    Strategy Description: ATFM strategy mimics cooperative behavior initially, but retaliates if cooperation threshold is not met. It also temporarily mimics majority action when there is a significant change in cooperation patterns to avoid becoming an easy target for exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = math.ceil(game_description.n_players * 0.8)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators < self.game_description.m:
            return Action.D
        prev_round = history.opponent_actions[-2] if len(history.opponent_actions) > 1 else None
        if prev_round is not None:
            cooperators_prev = sum(prev_round)
            cooperation_change = (cooperators - cooperators_prev) / self.game_description.n_players
            if abs(cooperation_change) > self.threshold:
                most_common_action = history.opponent_actions[-1].argmax()
                return Action(most_common_action) if most_common_action != int(history.my_actions[-1]) else Action.D
        return Action.C

class Strategy_EXPLOITATIVE_188(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = []
        self.t = int(math.ceil(game_description.n_rounds / 10))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        action = Action.C
        if state.round_number == 0 and history is None:
            return action
        if state.round_number > 1:
            average_cooperation = np.mean(self.cooperation_history[-self.t:])
            if average_cooperation >= self.game_description.m / self.game_description.n_players and np.all(self.cooperation_history[-self.game_description.m:] == [True]) or state.round_number == 1:
                action = Action.C
            else:
                action = Action.D
        self.cooperation_history.append(action == Action.C)
        return action

class Strategy_EXPLOITATIVE_189(BaseStrategy):
    """
    A strategy that follows the Tit-for-Tat Adaptive (TfTA) strategy in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.k = game_description.k
        self.n = game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = history.opponent_actions[-1] if history is not None else np.zeros(self.n, dtype=np.bool_)
        cooperators = sum(previous_round)
        if cooperators >= self.m:
            return Action.C
        elif np.any(history is not None and history.opponent_payoffs[-1] < 1 - self.k):
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_190(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)
    Strategy Summary: A cooperative strategy that adapts its cooperation threshold based on payoffs received.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.rounds_count = 0
        self.average_payoff = np.full((self.game_description.n_rounds,), math.inf)

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if state.round_number == 0:
            return Action.C
        self.rounds_count += 1
        cooperators = sum(history.opponent_actions[-1, :])
        payoff = history.my_payoffs[-1]
        average_payoff = self.calculate_average_payoff()
        if cooperators >= self.game_description.m:
            return Action.C
        self.update_cooperation_threshold(payoff, average_payoff)
        return Action.D

    def calculate_average_payoff(self):
        total = np.sum(self.average_payoff) - self.average_payoff[self.rounds_count - 1]
        self.average_payoff[-1] = total / self.rounds_count
        return self.average_payoff[-1]

    def update_cooperation_threshold(self, payoff, average_payoff):
        if payoff > average_payoff:
            self.cooperation_threshold = min(self.cooperation_threshold + 1, self.game_description.m)
        elif payoff < average_payoff:
            self.cooperation_threshold = max(self.cooperation_threshold - 1, 1)

class Strategy_EXPLOITATIVE_191(BaseStrategy):
    """
    Tit-for-Tat with Risk Adversion (TfT-RA) strategy for the Collective Risk Dilemma game.
    This strategy cooperates if more than half of players cooperated in the previous round,
    and defects otherwise to avoid being trapped in endless cycles of defection. It also includes an element of risk-aversion.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.recent_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or not history:
            return Action.C
        self.recent_history.append(history.opponent_actions[-1])
        self.recent_history = self.recent_history[1:]
        n_cooperators = np.sum(history.opponent_actions[-1])
        if n_cooperators < self.game_description.m:
            return Action.D
        elif len(self.recent_history) < 4 or np.mean(self.recent_history[:, self.game_description.n_players // 2].flatten()) > 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_192(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.average_cooperators = np.zeros(self.game_description.n_rounds)
        self.adaptive_threshold = math.ceil(self.game_description.n_players * 0.8)
        self.m = self.game_description.m

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        cooperators = sum(history.opponent_actions[-1, :])
        self.average_cooperators[state.round_number - 1] = cooperators / self.game_description.n_players
        if cooperators >= self.m:
            return Action.C
        return Action.D

    def adjust_threshold(self):
        adaptive_count = sum(self.average_cooperators >= self.m)
        if adaptive_count > self.adaptive_threshold:
            self.m += 1
        elif adaptive_count < self.adaptive_threshold:
            self.m -= 1

class Strategy_EXPLOITATIVE_193(BaseStrategy):
    """
    A strategy that follows Tit-for-Tat, but switches to punishing persistent defectors after a certain number of defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_defectors_threshold = math.ceil((self.n_players - game_description.m) * 2)
        self.cooperation_history = [0] * self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if state.round_number == 0 and history is None:
            return Action.C
        last_round = len(history.opponent_actions) - 1
        if last_round == 0:
            return Action.C
        for player in range(self.n_players):
            if self.cooperation_history[player] >= self.n_defectors_threshold:
                return Action.D
            if history is not None and last_round > 0 and (player != 0):
                last_action = self.cooperation_history[player - 1] if last_round > 1 else self.cooperation_history[-1]
            elif history is None and state.round_number == 1:
                last_action = Action.C
            else:
                last_action = history.opponent_actions[last_round, player]
            if last_action == Action.C:
                self.cooperation_history[player] += 1
                return Action.C
            else:
                self.cooperation_history[player] -= 1
        return Action.D

class Strategy_EXPLOITATIVE_194(BaseStrategy):
    """
    Strategy that implements the Adaptive Risk-Averse Tit-for-Tat (ARATFT) in Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.conservative_threshold = self.game_description.n_rounds * 0.75
        self.cooperated_last_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and len(history.opponent_actions) == 0):
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :]) if history is not None else 0
        self.cooperated_last_round = cooperators >= self.game_description.m
        action = Action.D if cooperators < self.game_description.m else Action.C
        return action if state.round_number != self.conservative_threshold else Action.D

class Strategy_EXPLOITATIVE_195(BaseStrategy):
    """
    A Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.window_size = int(math.ceil(game_description.n_players * 0.2))
        self.cooperation_threshold = game_description.m - 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperation_window = history.opponent_actions[:, state.round_number - self.window_size:state.round_number]
        cooperators = np.sum(cooperation_window, axis=1) > self.cooperation_threshold
        if np.sum(cooperators) >= self.cooperation_threshold:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_196(BaseStrategy):
    """
    A strategy that adapts to the opponent's behavior in the Collective Risk Dilemma game, cooperating initially and becoming increasingly exploitative based on opponents' actions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_cooperators_count = 0
        self.rounds_played = 0
        self.total_payoff = 0
        self.average_payoff = self.game_description.k * (self.game_description.m - 1)
        self.threshold = math.ceil(self.game_description.n_players / 2)
        self.opponent_type = None

    def __call__(self, state: GameState, history: PlayerHistory):
        if state.round_number == 0 and history is None:
            return Action.C
        self.rounds_played += 1
        if history is not None:
            self.opponent_cooperators_count = sum(history.opponent_actions[-1, :])
            if self.rounds_played == 1:
                self.opponent_type = self.determine_opponent_type()
            if self.total_payoff < self.average_payoff and state.round_number == self.game_description.n_rounds - 1:
                return Action.D
            action = self.determine_action()
            self.total_payoff += history.my_payoffs[-1] if history else 0
            return action

    def determine_opponent_type(self) -> str:
        cooperators = self.opponent_cooperators_count
        defectors = self.game_description.n_players - cooperators
        if cooperators == self.game_description.m:
            return 'Cooperator'
        elif defectors == self.game_description.n_players - self.game_description.m:
            return 'Defector'
        if random.random() < cooperators / self.game_description.n_players:
            return 'Mixed Strategist'
        else:
            return 'Cooperator'

    def determine_action(self) -> Action:
        opponent_type = self.opponent_type
        if opponent_type == 'Cooperator':
            return Action.C if self.opponent_cooperators_count > 0 else Action.D
        elif opponent_type == 'Defector':
            action = Action.D
            self.rounds_since_defection = 1 if self.opponent_cooperators_count > 0 else self.rounds_since_defection + 1
            if self.rounds_since_defection >= self.threshold:
                self.threshold -= math.ceil(self.game_description.n_players / self.rounds_played)
            return action
        elif opponent_type == 'Mixed Strategist':
            probability = random.random()
            if self.rounds_played <= self.threshold * self.game_description.n_rounds // 2:
                probability *= probability
            return Action(probability > 0.5)

class Strategy_EXPLOITATIVE_197(BaseStrategy):
    """
    A strategy that adopts the Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) approach in Collective Risk Dilemma games.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m
        self.last_round_coop = Action.C

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        coop_count = np.sum(history.opponent_actions[-1]) if history else 0
        cooperation_threshold_met = coop_count >= self.min_cooperators
        self.last_round_coop = Action.C if cooperation_threshold_met else Action.D
        return self.last_round_coop

class Strategy_EXPLOITATIVE_198(BaseStrategy):
    """
    Tit-for-Tat with Variations (TfTV) strategy for Collective Risk Dilemma game
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m
        self.last_round = game_description.n_rounds - 1
        self.k = game_description.k

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-1])
        if cooperators >= self.min_cooperators:
            return Action.C
        if state.round_number == self.last_round and cooperators < self.min_cooperators:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_199(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT)
    Strategy Description: This strategy cooperates in the first round and adapts its cooperation based on the opponent's history. If an opponent has cooperated in the previous round, TFTAT will cooperate as well. If an opponent has defected, TFTAT will also defect but becomes more reluctant to cooperate after a certain number of consecutive defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = 1
        self.last_opponent_action = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        elif state.round_number == 0 and history is not None:
            self.last_opponent_action = history.opponent_actions[state.round_number - 1, :].mean()
            return Action.C if self.last_opponent_action > 0 else Action.D
        cooperation = self.last_opponent_action if self.last_opponent_action is not None else 0
        payoff = 0
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators < self.game_description.m:
            payoff += 1 - cooperation
        elif cooperators >= self.game_description.m and cooperation == 1:
            payoff += 1 - cooperation + self.game_description.k
        else:
            payoff += cooperation
        if state.round_number > self.cooperation_threshold and self.last_opponent_action == 0:
            self.cooperation_threshold += 1
        self.last_opponent_action = cooperation
        return Action.C if cooperation == 1 else Action.D

class Strategy_EXPLOITATIVE_200(BaseStrategy):
    """Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)"""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = float(self.game_description.m / self.game_description.n_players)
        self.history_length = self.game_description.n_rounds // 2 + self.game_description.n_rounds % 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperator_count = np.sum(history.my_actions[:self.history_length]) / self.history_length
        if state.round_number < self.history_length and cooperator_count < self.m or cooperator_count >= self.m:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_201(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATfT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_cooperated_last_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            self.opponent_cooperated_last_round = any(history.opponent_actions[-1])
        action = Action.D if not self.opponent_cooperated_last_round else Action.C
        return action

class Strategy_EXPLOITATIVE_202(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) for Collective Risk Dilemma Game
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.recent_history = np.zeros((self.game_description.n_rounds, 2))
        self.cooperation_threshold = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if history is None:
            self.recent_history[:] = 0
        cooperators = history.my_actions[-1].sum()
        self.recent_history[-1, 0] = cooperators
        self.recent_history[-1, 1] = self.game_description.n_players
        if state.round_number == self.game_description.n_rounds:
            return Action.C if cooperators >= self.cooperation_threshold else Action.D
        self.cooperation_threshold = self.recent_history[:, 0].sum() / self.recent_history[:, 1].sum() * (self.game_description.m / self.game_description.n_players)
        return Action.C if cooperators >= math.ceil(self.cooperation_threshold) else Action.D

class Strategy_EXPLOITATIVE_203(BaseStrategy):
    """
    Tit-for-Tat with Adaptation (TFT-A) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.adaptation_factor = math.ceil(game_description.n_players * (game_description.m - 1) / game_description.k)
        self.r_counter = 0
        self.cooperated_last_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None or state.round_number == 0:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-1]) if history else 0
        self.cooperated_last_round = cooperators >= self.game_description.n_players - self.adaptation_factor
        if state.round_number == 1:
            return Action.C
        payoff = (1 - self.cooperated_last_round) * self.game_description.k if cooperators >= self.game_description.m else 1
        action = Action.C if payoff > 1 else Action.D
        if not self.cooperated_last_round and cooperators < self.game_description.m:
            self.r_counter = min(self.adaptation_factor, self.game_description.n_rounds - state.round_number)
        return action

class Strategy_EXPLOITATIVE_204(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) Strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.last_round_payoff = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.cooperation_threshold:
            action = Action.C
        else:
            action = Action.D
        payoff = history.my_payoffs[-1] if history is not None else 0.0
        self.last_round_payoff = payoff
        if state.round_number > 1 and action == Action.C and (cooperators < self.cooperation_threshold):
            self.cooperation_threshold -= 1
            self.cooperation_threshold = max(self.cooperation_threshold, 1)
        elif state.round_number > 1 and action == Action.D and (cooperators >= self.cooperation_threshold):
            self.cooperation_threshold += 1
            self.cooperation_threshold = min(self.cooperation_threshold, self.game_description.n_players)
        return action

class Strategy_EXPLOITATIVE_205(BaseStrategy):
    """
    Tit-for-Tat with a Twist (TFTW) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m - 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.min_cooperators:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_206(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Risk Aversion (TfT-ARA)

    An implementation of the Tit-for-Tat strategy that incorporates adaptive risk aversion, allowing it to defect when the potential reward for cooperation exceeds historical averages.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.k_history = np.zeros(self.game_description.n_rounds)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number < self.game_description.n_rounds - 1:
            k_avg = np.mean(self.k_history)
            if history and history.my_payoffs[-1] + 1 > k_avg:
                return Action.D
        n_c = sum(history.opponent_actions[state.round_number - 1, :]) if history else 0
        if n_c >= self.game_description.m:
            return Action.C
        return Action.D

    def update(self, state: GameState, payoff: float) -> None:
        if state.round_number < self.game_description.n_rounds - 1:
            self.k_history[state.round_number] = payoff - 1

class Strategy_EXPLOITATIVE_207(BaseStrategy):
    """
    A strategy that follows a cooperative approach, mimicking opponents' actions, but punishes uncooperative players by defecting.
    It exploits opponents' cooperation when the cumulative cooperation ratio drops below 0.5 and continues cooperation if it exceeds 0.75.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.tcr_threshold = (0.5, 0.75)
        self.round_number = 0
        self.history = None
        self.total_cooperators = 0
        self.total_actions = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None and state.round_number == 0:
            return Action.C
        elif state.round_number > 0:
            self.round_number = state.round_number
            action = Action.C
            self.total_cooperators += int(history.my_actions[-1])
            self.total_actions += 1
            tcr = self.total_cooperators / self.total_actions if self.total_actions > 0 else 0
            if history is not None:
                opponent_cooperators = sum(history.opponent_actions[-1, :])
                if opponent_cooperators < self.game_description.m - 1:
                    action = Action.D
            if tcr < self.tcr_threshold[0]:
                action = Action.D
            elif tcr > self.tcr_threshold[1]:
                action = Action.C
            if history is not None:
                history.my_actions[-1] = int(action == Action.C)
                if action == Action.D and self.round_number > 1:
                    history.opponent_actions[-2, :] = [int(x == Action.D) for x in history.opponent_actions[-1, :]]
        return action

class Strategy_EXPLOITATIVE_208(BaseStrategy):
    """
    A Tit-for-Tat strategy adapted for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        num_players = history.opponent_actions.shape[1]
        if cooperators >= self.m and state.round_number < self.game_description.n_rounds:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_211(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) Strategy.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.s = math.floor((game_description.n_players - 1) / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if not history:
            return Action.C
        cooperation = np.mean(history.opponent_actions[-1])
        if cooperation >= self.cooperation_threshold and state.round_number > 1:
            return Action.C
        return Action.D

    def update_cooperation_threshold(self, cooperative_reformation):
        if cooperative_reformation:
            self.cooperation_threshold += 1
            cooperation_streak = 1
        else:
            cooperation_streak = 0
        while cooperation_streak < self.s and self.cooperation_threshold > self.game_description.m:
            self.cooperation_threshold -= self.s
            cooperation_streak += 1

class Strategy_EXPLOITATIVE_212(BaseStrategy):
    """
    TFT-ACT strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = 0
        self.history_length = game_description.n_rounds // 10 if game_description.n_rounds > 0 else 0
        self.cooperators_count = np.zeros(self.history_length)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and len(history.my_actions) > self.history_length:
            coop_avg = np.mean(history.my_actions[-self.history_length:])
            if coop_avg >= self.game_description.m / self.game_description.n_players:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_213(BaseStrategy):
    """
    A strategy that cooperates if a minimum number of players also cooperate in the previous round.
    The threshold for minimum cooperators adapts dynamically to encourage cooperation and punishment based on opponents' behavior.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.m
        self.n_players = game_description.n_players

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1])
        if cooperators >= self.threshold:
            if self.threshold < self.n_players:
                self.threshold += 1
            return Action.C
        elif self.threshold > self.game_description.m - self.n_players + 1:
            self.threshold -= 1
        return Action.D

class Strategy_EXPLOITATIVE_214(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.p_init = 0.25
        self.total_rounds = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return np.random.choice([Action.C, Action.D], p=[self.p_init, 1 - self.p_init])
        else:
            n_coop = np.sum(history.opponent_actions[-1, :])
            p = 1 - (1 - self.p_init) * math.exp(-(state.round_number - 1) / self.total_rounds)
            return Action.C if n_coop >= self.game_description.m and random.random() < p else Action.D

class Strategy_EXPLOITATIVE_215(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT)
    This strategy adjusts its cooperation level based on the actions of other players.
    It seeks to capitalize on the cooperation of others while not being too quick to retaliate against defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = math.ceil(game_description.m)
        self.last_round_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_cooperators = sum(history.opponent_actions[-1, :])
        self.last_round_cooperators = current_cooperators
        if current_cooperators >= self.cooperation_threshold:
            return Action.C
        else:
            return Action.D
        if self.cooperation_threshold > 1:
            if current_cooperators >= (self.game_description.n_players - 1) // 2:
                self.cooperation_threshold += math.ceil(self.game_description.n_players * 0.1)
            elif self.last_round_cooperators < (self.game_description.n_players + 1) // 4:
                self.cooperation_threshold -= math.floor(self.game_description.n_players * 0.1)

class Strategy_EXPLOITATIVE_216(BaseStrategy):
    """
    A strategy that follows the Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) in Collective Risk Dilemma games.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_rate = np.zeros(self.game_description.n_rounds)
        self.current_round = 0
        self.cooperate_next = True
        self.permanent_defection_mode = False

    def __call__(self, state: GameState, history: PlayerHistory):
        self.current_round = state.round_number
        if not history or self.current_round == 0:
            self.cooperate_next = True
        else:
            cooperation_rate = np.mean(self.cooperation_rate[-self.game_description.n_rounds // 2:])
            if cooperation_rate < self.game_description.m or (self.permanent_defection_mode and cooperation_rate > self.game_description.k * (self.game_description.m - 1)):
                self.cooperate_next = not self.cooperate_next
            elif cooperation_rate >= self.game_description.m:
                self.cooperate_next = history.my_payoffs[-1] >= history.my_payoffs[-2] and self.cooperate_next
        if self.current_round == self.game_description.n_rounds - 1 or (self.permanent_defection_mode and cooperation_rate < self.game_description.m):
            self.cooperate_next = True
        if self.cooperate_next:
            self.cooperation_rate[self.current_round] = 1
        else:
            self.cooperation_rate[self.current_round] = 0
        return Action(int(self.cooperate_next)) if not self.permanent_defection_mode else Action.D

class Strategy_EXPLOITATIVE_217(BaseStrategy):
    """
    Tit-for-Tat-Adaptive (TfTA) Strategy for Collective Risk Dilemma Game
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.my_actions = np.array([False], dtype=bool)
        self.opponent_cooperators = 0
        self.current_reward_threshold = int(game_description.k * game_description.n_players // (2 * game_description.m))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.update_history(history)
        if state.round_number == len(history.opponent_actions) - 1 and self.should_exploit():
            return Action.D
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.game_description.m:
            self.my_actions[-1] = True
            self.opponent_cooperators += 1
            return Action.C
        else:
            self.my_actions[-1] = False
            self.opponent_cooperators = 0
            return Action.D

    def update_history(self, history: PlayerHistory):
        self.my_actions = np.concatenate((self.my_actions, [history.my_actions[-1]]))
        if history is not None:
            self.opponent_cooperators += sum(history.opponent_actions[-1, :])

    def should_exploit(self):
        return self.opponent_cooperators >= self.game_description.m and (len(self.my_actions) > self.game_description.n_players // 2 or len(self.my_actions) > self.current_reward_threshold)

class Strategy_EXPLOITATIVE_218(BaseStrategy):
    """
    A Tit-for-Tat strategy with Adaptive Cooperation Threshold (TFT-ACT) for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.initial_cooperation_threshold = math.ceil(game_description.n_players * game_description.m / game_description.n_players)
        self.minimum_cooperation_rate = 0
        self.rounds_history = np.zeros((game_description.n_rounds - 1,), dtype=np.bool_)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        if state.round_number < self.game_description.n_rounds - 1:
            self.update_minimum_cooperation_rate(history)
            action = Action.C if self.minimum_cooperation_rate > self.get_current_cooperation_threshold() else Action.D
        else:
            action = Action.C if self.minimum_cooperation_rate > self.get_current_cooperation_threshold() else Action.D
        if state.round_number < self.game_description.n_rounds - 1:
            self.record_round(history)
        return action

    def get_current_cooperation_threshold(self):
        initial = self.initial_cooperation_threshold
        return max(initial * 0.9 ** (self.minimum_cooperation_rate - 1), initial)

    def update_minimum_cooperation_rate(self, history: PlayerHistory):
        cooperators_in_round = np.sum(history.opponent_actions[-1, :])
        self.minimum_cooperation_rate = self.calculate_mcr(self.rounds_history)
        if self.minimum_cooperation_rate > self.get_current_cooperation_threshold():
            self.minimum_cooperation_rate = 1
        self.record_round(history)

    def calculate_mcr(self, rounds: np.ndarray):
        cooperation_rounds = rounds[rounds == True].size
        total_rounds = self.game_description.n_players * (self.game_description.n_rounds - 1)
        return cooperation_rounds / total_rounds

    def record_round(self, history: PlayerHistory):
        self.rounds_history[-1] = bool(np.sum(history.opponent_actions[-1, :]) >= self.game_description.n_players // self.game_description.m)

class Strategy_EXPLOITATIVE_219(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy.
    A cooperative strategy that adapts its cooperation based on previous actions and the number of cooperators in each round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.past_cooperations = 0
        self.last_round_cooperators = 0
        self.p_switch = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.past_cooperations = sum(history.my_actions[:-1])
        self.last_round_cooperators = sum(history.opponent_actions[-1, :])
        if self.past_cooperations >= self.game_description.m - 1 and self.last_round_cooperators >= self.game_description.m:
            return Action.C
        elif self.past_cooperations < self.game_description.m - 1 or self.last_round_cooperators < self.game_description.m:
            return Action.C
        elif self.past_cooperations >= self.game_description.m - 1 and self.last_round_cooperators == self.game_description.m:
            if random.random() < self.p_switch:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_220(BaseStrategy):
    """
    A Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = self.game_description.m
        self.rounds_cooperated = 0
        self.rounds_defected = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :]) if history else 0
        if cooperators >= self.game_description.n_players // 2:
            self.threshold += 1 if self.rounds_cooperated < self.game_description.n_players - self.threshold else 0
            self.rounds_cooperated += 1
            self.rounds_defected = 0
        else:
            self.threshold -= 1 if self.rounds_defected < self.threshold else 0
            self.rounds_defected += 1
            self.rounds_cooperated = 0
        if self.threshold > self.game_description.n_players:
            self.threshold = self.game_description.n_players
        elif self.threshold < self.game_description.m:
            self.threshold = self.game_description.m
        return Action.C if cooperators >= self.threshold else Action.D

class Strategy_EXPLOITATIVE_221(BaseStrategy):
    """
    Tit-for-Tat Strategy (Adaptive and Exploitative) in Collective Risk Dilemma game
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = None
        self.min_cooperators = math.ceil(game_description.n_players * (1 / game_description.m))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if not history:
            return Action.C
        self.history = history
        if state.round_number == len(history.opponent_actions):
            return Action.C
        recent_cooperators = sum(history.opponent_actions[-1, :])
        if recent_cooperators >= self.min_cooperators or (state.round_number > 1 and history.my_actions[-2] == Action.C):
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_222(BaseStrategy):
    """
    A strategy inspired by the "Tit-for-Tat" game theory concept, which adapts to the opponent's actions.
    It starts by cooperating in the first round to build trust and later responds based on the opponent's previous moves.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = []

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or len(self.opponent_history) == 0:
            return Action.C
        last_round = len(self.opponent_history) - 1
        last_opponent_action = self.opponent_history[last_round][-1]
        if last_opponent_action == Action.D:
            return Action.D
        elif last_opponent_action == Action.C and self.opponent_history[-2][-1] != Action.D:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_223(BaseStrategy):
    """
    Tit-for-Tat-with-Adaptation (TfT-A) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.s = int(math.floor(game_description.n_rounds * 0.5))
        self. = 0.6
        self. = 0.4

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-self.s:, :].flatten()) / self.s
        if state.round_number > self.s and np.sum(history.my_actions[-self.s:]) >= self.game_description.m:
            return Action.C
        if cooperators > self.:
            return Action.C
        elif cooperators < self.:
            return Action.D
        return Action.C if np.sum(history.my_actions[-self.s:]) >= self.game_description.m else Action.D

class Strategy_EXPLOITATIVE_224(BaseStrategy):
    """
    A Tit-for-Tat Adaptive (TfTA) strategy implementation. This strategy starts by cooperating and responds to defection with non-cooperation, while maintaining cooperation when majority cooperated in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        last_round = len(history.opponent_actions) - 1
        cooperators = sum(history.opponent_actions[last_round])
        if cooperators >= self.m:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_225(BaseStrategy):
    """
    A simple Tit-for-Tat strategy with an adaptive cooperation threshold. The agent cooperates initially and adapts its cooperation based on the number of cooperators in the previous round.
    If more than (m-1) players cooperated in the previous round, the agent will also cooperate in the current round. Otherwise, it will defect. In the first round, the agent cooperates as a goodwill gesture to encourage cooperation from others. In the last round, the agent evaluates its total payoff compared to the minimum payoff possible and makes a decision based on that comparison.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = math.ceil(game_description.n_players * 0.5) - 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :]) if history is not None else 0
        if cooperators >= self.threshold:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_226(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT) Strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m_t = math.ceil(game_description.n_players / 2) + 1
        self.cooperation_threshold_history = []

    def __call__(self, state: GameState, history: PlayerHistory):
        if state.round_number == 0 and history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-1])
        self.cooperation_threshold_history.append(self.m_t)
        if cooperators >= self.m_t:
            payoff = 1 + self.game_description.k * (self.m_t - cooperators + 1)
            self.m_t = min(self.game_description.n_players, self.m_t + 1)
            return Action.C
        else:
            payoff = 1
            self.m_t = max(1, self.m_t - 1)
        return Action.D

class Strategy_EXPLOITATIVE_227(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Defection Threshold (TFT-ADT) Strategy for Collective Risk Dilemma Game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.alpha = 0.5
        self.adaptation_counter = 0
        self.coin_flip_bias = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action(random.choices([0, 1], weights=[self.coin_flip_bias, 1 - self.coin_flip_bias])[0])
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators < self.m:
            self.adaptation_counter += self.alpha
            return Action.D
        elif self.adaptation_counter > 0:
            self.adaptation_counter -= 1
        return Action.C

class Strategy_EXPLOITATIVE_228(BaseStrategy):
    """
    A TFT-MCT player follows a cooperative approach and retaliates against defections.
    It adjusts its cooperation threshold based on the number of cooperators in previous rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = math.ceil(game_description.n_players * game_description.m / 100)
        self.randomness_probability = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and len(history.opponent_actions) == 0):
            return Action.C
        cooperators = sum([sum(row) for row in np.array(history.opponent_actions, dtype=int) if state.round_number > len(row)])
        if cooperators >= self.cooperation_threshold:
            return Action.C
        elif random.random() < self.randomness_probability and cooperators < self.cooperation_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_229(BaseStrategy):
    """
    A Tit-for-Tat with Adaptive Threshold (TFT-AT) strategy for the Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.m
        self.last_round_cooperators = 0

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_actions = history.my_actions[-1]
        cooperators = np.sum(history.opponent_actions[-1])
        if cooperators >= self.threshold:
            self.last_round_cooperators += 1
            self.threshold = min(self.game_description.n_players, max(1, self.threshold + math.floor((self.last_round_cooperators - self.threshold) / 2)))
        else:
            self.last_round_cooperators = max(0, self.last_round_cooperators - 1)
            self.threshold = max(self.game_description.m, math.ceil((self.last_round_cooperators + self.threshold) / 2))
        return Action(my_actions) if my_actions else Action.D

class Strategy_EXPLOITATIVE_231(BaseStrategy):
    """
    A Tit-for-Tat-Adaptive (TfT-A) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = np.zeros(self.game_description.n_players, dtype=np.bool_)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or len(self.opponent_history) == 0:
            return Action.C
        opponent_cooperation = self.opponent_history[-1]
        self.opponent_history = self.opponent_history[:-1]
        if opponent_cooperation:
            return opponent_cooperation
        else:
            return Action.D

class Strategy_EXPLOITATIVE_232(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.last_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        elif state.round_number == self.game_description.n_rounds and self.cooperation_threshold == 1:
            self.last_round = True
            return Action.C
        else:
            if not self.last_round:
                cooperation = sum(history.opponent_actions[-1]) if history is not None else 0
                if cooperation >= self.cooperation_threshold:
                    self.cooperation_threshold = min(self.game_description.m, self.cooperation_threshold + 1)
                else:
                    self.cooperation_threshold = max(1, self.cooperation_threshold - 1)
            return Action.C if state.round_number % self.game_description.n_players == 0 else Action.D

class Strategy_EXPLOITATIVE_233(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.alpha = math.floor(game_description.m / 2)
        self.d = 0.1
        self.e = math.floor(game_description.m * 0.8)
        self.payoff_history = []

    def __call__(self, state: GameState, history: PlayerHistory | None):
        if state.round_number == 0 and history is None:
            return Action.C
        if history is not None:
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators >= self.alpha:
                return Action.C
            else:
                return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            payoff_difference = self.payoff_history[-2] - self.payoff_history[-1]
            if abs(self.alpha - self.game_description.m) < self.e and payoff_difference <= 0:
                return Action.D
            else:
                return Action.C
        self.payoff_history.append(history.my_payoffs[-1])
        if payoff_difference > 0:
            self.alpha += self.d
        elif payoff_difference <= 0:
            self.alpha -= self.d

class Strategy_EXPLOITATIVE_234(BaseStrategy):
    """
    Strategy for the Collective Risk Dilemma game, implementing a Risk-Averse Tit for Tat (RA-TFT) strategy.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.rounds_cooperation = 1
        self.rounds_defection = 0
        self.last_round = -1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.last_round = state.round_number - 1 if state.round_number > 0 else -1
        if self.last_round < 0:
            cooperators = 0
            defectors = 0
        else:
            cooperators = sum(history.opponent_actions[self.last_round, :])
            defectors = self.game_description.n_players - cooperators
        r_c = max(0, cooperators + (self.rounds_cooperation if self.last_round >= 0 else 1))
        r_d = max(0, defectors + (self.rounds_defection if self.last_round >= 0 else 0))
        if r_c >= self.game_description.m and r_c + r_d >= self.game_description.n_players:
            self.rounds_cooperation += 1
            return Action.C
        elif r_d >= self.game_description.m and r_c + r_d >= self.game_description.n_players:
            self.rounds_defection += 1
            return Action.D
        elif self.last_round % 2 == 1 or history is None:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_235(BaseStrategy):
    """
    Implementation of the Tit-for-Tat with Adaptation (TFT-A) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_opponent_action = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is None or len(history.opponent_actions) < self.game_description.n_players:
            self.last_opponent_action = None
        last_round = state.round_number - 1 if history is not None else 0
        self.last_opponent_action = history.opponent_actions[last_round, -1] if history is not None else None
        cooperate = self.game_description.n_players // self.game_description.m <= len(np.where(history.my_payoffs > 0)[0]) + 1 if state.round_number != self.game_description.n_rounds else False
        return Action.C if cooperate and self.last_opponent_action == Action.C or (not cooperate and self.last_opponent_action == Action.D) else Action.D

class Strategy_EXPLOITATIVE_236(BaseStrategy):
    """
    A Tit-for-Tat Cooperator (TfTC) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_last_action = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or self.opponent_last_action is None:
            return Action.C
        else:
            self.opponent_last_action = history.opponent_actions[-1][-1] if len(history) > 0 else self.opponent_last_action
            return Action(self.opponent_last_action)

class Strategy_EXPLOITATIVE_237(BaseStrategy):
    """
    A strategy that implements the Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.learning_rate = 0.1
        self.cooperation_threshold = self.game_description.m
        self.last_t_cooperators = np.zeros(self.game_description.n_players)
        self.rounds_played = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.rounds_played += 1
        if state.round_number == self.game_description.n_rounds - 1:
            avg_cooperators = np.mean(self.last_t_cooperators)
            if avg_cooperators < self.cooperation_threshold:
                return Action.D
            else:
                return Action.C
        cooperators = sum(history.opponent_actions[-1, :]) if history is not None else 0
        if cooperators >= self.cooperation_threshold:
            self.last_t_cooperators = np.roll(self.last_t_cooperators, -1)
            self.last_t_cooperators[-1] = cooperators
            return Action.C
        else:
            avg_cooperators = np.mean(self.last_t_cooperators)
            self.cooperation_threshold += (avg_cooperators - self.cooperation_threshold) * self.learning_rate
            self.last_t_cooperators[-1] = cooperators
            return Action.D

class Strategy_EXPLOITATIVE_238(BaseStrategy):
    """
    Strategy name: Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)
    A strategy that cooperates in the first round, then adapts its cooperation based on the previous round's total cooperation and its own past cooperation ratio.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.past_cooperation_ratio = np.zeros(self.game_description.n_rounds)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperation = np.mean(history.my_actions[:state.round_number]) if history else 0
        self.past_cooperation_ratio[state.round_number] = cooperation
        cooperators = sum(history.opponent_actions[-1, :]) if history else 0
        total_players = self.game_description.n_players
        if cooperators >= self.game_description.m:
            return Action.C
        elif cooperators / total_players > cooperation and cooperators > self.past_cooperation_ratio.sum() / state.round_number:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_239(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) Strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.w = int(np.ceil(game_description.n_rounds * 0.8))
        self.t = int(np.floor(self.w * 0.15))
        self.i = math.sqrt(2)
        self.payoff_total = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            n_c = sum(history.my_actions[-self.w:]) / self.w
            self.cooperation_threshold = self.cooperation_threshold if n_c <= self.game_description.m + self.t else self.cooperation_threshold + self.i
            self.cooperation_threshold = self.game_description.m if self.cooperation_threshold > self.game_description.n_players // 2 else self.cooperation_threshold
        payoff = 1 if history is None or (history.my_actions[-1] == Action.D and state.round_number > 1) else 1 - history.my_actions[-1] + self.game_description.k
        self.payoff_total += payoff
        return Action.C if payoff > self.payoff_total / (state.round_number - 1) else Action.D

class Strategy_EXPLOITATIVE_240(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATfT)
    Strategy Description: A strategy that cooperates if the majority of players cooperated in the previous round, otherwise defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = math.ceil(game_description.n_players * game_description.m / 100)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.min_cooperators:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_241(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) Strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.initial_ct = 0.5
        self.ct_increase = 0.01
        self.ct_decrease = 0.01

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        coop_threshold = self.initial_ct + state.round_number / self.game_description.n_rounds * (self.ct_increase - self.ct_decrease) * ((self.game_description.m - sum(history.opponent_actions[-1, :])) / (self.game_description.n_players - self.game_description.m))
        if coop_threshold > 0.5:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_242(BaseStrategy):
    """
    Strategy name: Tit-for-Tat with Risk Aversion (TFT-RA)
    Strategy summary: Cooperates in the first round, then adapts cooperation based on opponent's actions and risk factor k.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.k = self.game_description.k
        self.probability_threshold = 0.5 if self.game_description.n_players % 2 == 1 else 0.5 * (self.game_description.m - 1) / (self.game_description.n_players - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        cooperation_probability = self.probability_threshold
        total_opponent_defects = sum(((x == Action.D).sum() for x in (history.opponent_actions if history else np.zeros((state.round_number + 1, self.game_description.n_players), dtype=np.bool_))))
        cooperation_probability += (self.k - 1) * (total_opponent_defects / state.round_number) if total_opponent_defects > 0 else 0
        return Action.C if random.random() <= cooperation_probability else Action.D

class Strategy_EXPLOITATIVE_243(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.average_cooperation_rate = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        payoffs = history.my_payoffs[-1]
        self.average_cooperation_rate = np.mean(payoffs > 1) if self.average_cooperation_rate is not None else 0
        if cooperators >= self.cooperation_threshold:
            self.cooperation_threshold += int((self.game_description.n_players - 2) * (self.average_cooperation_rate - 0.5))
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_244(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.r = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.ACT = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1])
        if self.ACT is None:
            self.ACT = self.determine_act_threshold(history)
        n = history.my_actions.shape[0]
        if self.r > n / 2:
            ACT = self.m - 1
        else:
            ACT = math.floor(self.m + n / 2)
        if cooperators >= self.m:
            action = Action.C
        elif cooperators <= ACT:
            action = Action.D
        else:
            probability_cooperate = (cooperators - ACT) / (self.m - ACT)
            if random.random() < probability_cooperate:
                action = Action.C
            else:
                action = Action.D
        return action

    def determine_act_threshold(self, history):
        cooperators = np.sum(history.opponent_actions[:, -1])
        ACT = self.m - 1 if sum(history.my_payoffs) > self.r * self.k / 2 else math.floor(self.m + len(history.my_actions) / 2)
        return ACT

class Strategy_EXPLOITATIVE_245(BaseStrategy):
    """
    A Tit-for-Tat with Adaptation (TfTA) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.moving_average = [0] * self.game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperation = np.sum(history.my_actions if history is not None else [Action.D])
        self.moving_average = self._update_moving_average(cooperation, self.moving_average)
        return Action.C if np.mean(self.moving_average) > self.game_description.m / 2 else Action.D

    def _update_moving_average(self, cooperation: int, moving_average: list[int]) -> list[int]:
        if len(moving_average) < self.game_description.n_players:
            moving_average.append(cooperation)
            return moving_average
        moving_average.pop()
        moving_average.append(cooperation)
        return moving_average

class Strategy_EXPLOITATIVE_246(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperative Threshold (ACTh) strategy for the Collective Risk Dilemma game.
    This strategy cooperates if a majority of players cooperated in the previous round, and adjusts its cooperative threshold dynamically based on recent cooperation levels.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperative_threshold = int(math.ceil(game_description.n_players * 0.5))
        self.lookback = math.floor(game_description.n_rounds * 0.1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-self.lookback:, :].T > 0)
        self.cooperative_threshold = max(1, min(self.game_description.n_players, self.cooperative_threshold + int(math.copysign(1, cooperators - self.game_description.m + 1))))
        if np.sum(history.opponent_actions[-1, :]) >= self.cooperative_threshold:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_247(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATfT) strategy for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_cooperated_last_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.opponent_cooperated_last_round = False
            return Action.C
        if not history or len(history.opponent_actions) <= 1:
            self.opponent_cooperated_last_round = False
            return Action.C
        self.opponent_cooperated_last_round = bool(history.opponent_actions[-1].sum())
        if self.opponent_cooperated_last_round:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_248(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.past_cooperation = np.zeros(game_description.n_rounds)
        self.average_cooperation_rate = 0.5
        self.cooperation_threshold = 0.5
        self.sensitivity = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is not None:
            self.past_cooperation = np.roll(self.past_cooperation, -1)
            self.past_cooperation[-1] = sum(history.opponent_actions[-1, :]) / self.game_description.n_players
        if state.round_number >= self.game_description.n_rounds:
            return Action.C if self.tft_act(self.past_cooperation, self.average_cooperation_rate, self.cooperation_threshold, self.sensitivity) else Action.D
        else:
            return Action.C if self.tft_act(self.past_cooperation, self.average_cooperation_rate, self.cooperation_threshold, self.sensitivity) else Action.D

    def tft_act(self, past_cooperation, acr, ct, s):
        if len(past_cooperation) < self.game_description.n_rounds:
            return True
        if sum(past_cooperation[-self.game_description.n_rounds:]) >= self.game_description.m * self.game_description.n_rounds:
            acr = acr * (1 - s) + sum(past_cooperation[-self.game_description.n_rounds:]) / self.game_description.n_rounds * s
            ct = min(acr, 1.0)
        return sum(past_cooperation[-self.game_description.n_rounds:]) >= ct * self.game_description.m

class Strategy_EXPLOITATIVE_249(BaseStrategy):
    """
    The Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) Strategy for the Collective Risk Dilemma Game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.alpha = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and len(history.opponent_actions) == 0):
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        cooperators_ratio_prev = cooperators / self.game_description.n_players
        cooperation_threshold = (self.game_description.m - 1) / self.game_description.n_players + self.alpha * (cooperators_ratio_prev - (self.game_description.m - 1) / self.game_description.n_players)
        action = Action.C if cooperators_ratio_prev >= cooperation_threshold else Action.D
        if state.round_number == self.game_description.n_rounds:
            action = Action.D
        return action

class Strategy_EXPLOITATIVE_250(BaseStrategy):
    """
    A strategy that implements Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperative_threshold = 0
        self.opponent_history = np.zeros((self.game_description.n_players, self.game_description.n_rounds), dtype=np.bool_)

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        action = Action.D
        round_number = state.round_number
        if round_number == 0 or self.opponent_history[-1, -1] == False:
            action = Action.C
        else:
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators >= self.game_description.n_players // self.game_description.m:
                action = Action.C
            else:
                self.opponent_history[-1, :] = history.opponent_actions[-1, :]
        if round_number == self.game_description.n_rounds - 1:
            cooperators = sum(self.opponent_history[:, -1])
            if round_number >= self.cooperative_threshold or cooperators >= self.game_description.m:
                action = Action.C
        return action

    def update_opponent_history(self, opponent_actions: NDArray[np.bool_]) -> None:
        """
        Update opponent history for subsequent rounds.
        :param opponent_actions: Array of opponent actions in the current round, indexed [round, player]
        """
        self.opponent_history = np.concatenate((self.opponent_history, opponent_actions), axis=1)

    def update_cooperative_threshold(self):
        """
        Update Cooperative Threshold based on established trust among opponents.
        """
        cooperative_rounds = np.where(self.opponent_history.sum(axis=0) > self.game_description.m - 1)[0]
        if len(cooperative_rounds) > 0:
            self.cooperative_threshold = max(cooperative_rounds, key=lambda x: x / self.game_description.n_rounds * self.game_description.m)

class Strategy_EXPLOITATIVE_251(BaseStrategy):
    """
    A Tit-for-Tat with Adaptive Cooperative Threshold (TFT-ACT) strategy.
    This strategy follows the Tit-for-Tat rule set, with an additional adaptive cooperative threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.history = PlayerHistory(my_actions=None, my_payoffs=None, opponent_actions=np.zeros((1, game_description.n_players), dtype=bool), opponent_payoffs=np.zeros(1))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is not None:
            self.history = history
        if state.round_number == 0:
            cooperators = np.count_nonzero(self.history.opponent_actions[-1])
            return Action.C if cooperators >= self.cooperation_threshold else Action.D
        else:
            cooperation_count = np.count_nonzero(self.history.my_actions)
            return Action.C if cooperation_count >= self.cooperation_threshold or state.round_number == 1 else Action.D

class Strategy_EXPLOITATIVE_252(BaseStrategy):
    """
    A collective risk dilemma game strategy that implements Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_coop = math.ceil(game_description.n_players * game_description.m / 100)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.min_coop:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_253(BaseStrategy):
    """
    Implementation of the Tit-for-Tat-Adaptive (TfTA) strategy in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.n_players // game_description.m

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C if random.random() > 0.5 else Action.D
        my_action_t_1 = history.my_actions[-1]
        cooperators_t_1 = sum(history.opponent_actions[-1])
        return my_action_t_1 if my_action_t_1 == Action.C and cooperators_t_1 >= self.threshold else Action.D

class Strategy_EXPLOITATIVE_254(BaseStrategy):
    """
    Strategy name: Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)
    Strategy summary: This strategy cooperates initially and adapts its cooperation threshold based on observed behavior to punish non-cooperators and reward cooperators.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.total_cooperation = 0
        self.rounds_played = 0
        self.cooperation_rate = 0
        self.adaptive_m = self.m
        self.p = self.game_description.n_players // 4
        self.q = self.game_description.n_players // 5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            self.total_cooperation += np.sum(history.my_actions)
            self.rounds_played += 1
            self.cooperation_rate = self.total_cooperation / self.rounds_played
            if self.rounds_played >= self.r:
                return Action.D
            if self.cooperation_rate > self.p and self.adaptive_m < self.game_description.n_players:
                self.adaptive_m += 1
            elif self.cooperation_rate < self.q and self.adaptive_m > self.m:
                self.adaptive_m -= 1
        return Action.C if np.sum(history.opponent_actions[-1]) >= self.adaptive_m else Action.D

class Strategy_EXPLOITATIVE_256(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = self.game_description.m / self.game_description.n_players
        self.rounds_cooperated_opponents = 0
        self.cooperate_count = 1
        self.history = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.history = history
        cooperators = sum(history.opponent_actions[-1])
        cooperators_ratio = cooperators / self.game_description.n_players
        if cooperators < self.game_description.m:
            return Action.D
        elif state.round_number == self.game_description.n_rounds or self.rounds_cooperated_opponents > self.game_description.n_players - self.game_description.m:
            self.cooperation_threshold += self.game_description.m / self.game_description.n_players * 0.5
        elif cooperators >= self.game_description.m and self.cooperate_count < self.game_description.m:
            self.cooperation_threshold += (self.game_description.m - self.cooperate_count) / self.game_description.n_players
        elif cooperators > self.cooperation_threshold >= self.game_description.m / self.game_description.n_players:
            self.cooperation_threshold -= (cooperators_ratio - self.game_description.m / self.game_description.n_players) * 0.1
        elif cooperators > self.cooperation_threshold >= self.game_description.m * 2 / self.game_description.n_players:
            self.rounds_cooperated_opponents += 1
        return Action.C if cooperators > self.cooperation_threshold else Action.D

class Strategy_EXPLOITATIVE_258(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) Strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.tct = game_description.n_players // 2 - 1
        self.r_p = 0
        self.TCT_MIN = 1
        self.TCT_MAX = game_description.n_players - 2
        self.STEP = 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_actions = history.opponent_actions[-1] if history else np.zeros(self.game_description.n_players - 1, dtype=bool)
        cooperators = sum(opponent_actions)
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        if self.r_p >= self.game_description.n_rounds // 2 and cooperators < self.tct + 1:
            self.tct = min(self.tct + self.STEP, self.TCT_MAX)
        if cooperators >= self.tct:
            return Action.C
        self.r_p = 0
        return Action.D

class Strategy_EXPLOITATIVE_259(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.initial_ct = int(math.ceil((game_description.n_players - 1) / 2))
        self.max_ct = int(math.floor(game_description.n_players * 0.8))
        self.decay_rate = 0.9
        self.history_length = int(math.ceil(game_description.n_rounds / 10))
        self.cooperative_history = np.zeros(self.history_length, dtype=int)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        self._update_cooperative_history(state, history)
        cooperative_threshold = self._adjust_cooperation_threshold()
        opponent_cooperators = sum(history.opponent_actions[-1, :])
        return Action.C if opponent_cooperators >= cooperative_threshold else Action.D

    def _update_cooperative_history(self, state: GameState, history: PlayerHistory):
        self.cooperative_history = np.roll(self.cooperative_history, -1)
        if state.round_number < self.history_length:
            return
        self.cooperative_history[-1] = int(sum(history.opponent_actions[-1, :]))

    def _adjust_cooperation_threshold(self):
        return self.initial_ct + (self.max_ct - self.initial_ct) * max(0.0, np.mean(self.cooperative_history)) ** self.decay_rate

class Strategy_EXPLOITATIVE_261(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation (TfT-AC) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None and state.round_number == 0:
            return Action.D
        elif state.round_number == 1:
            self.history = PlayerHistory(my_actions=np.zeros(self.game_description.n_players), my_payoffs=np.zeros(self.game_description.n_rounds), opponent_actions=np.zeros((self.game_description.n_rounds, self.game_description.n_players)), opponent_payoffs=np.zeros((self.game_description.n_rounds, self.game_description.n_players)))
            return Action.D
        elif self.history.opponent_actions[-1].sum() < self.game_description.n_players // 2:
            return Action.D
        elif state.round_number == self.game_description.n_rounds:
            if self.history.opponent_actions[-2].sum() >= self.game_description.n_players // 2:
                return Action.C
        elif self.history.opponent_actions[-1].sum() >= self.game_description.n_players // 2:
            return Action.C
        self.history.my_actions[state.round_number - 1] = True
        if history:
            self.update_payoffs(state)
        return Action.C

    def update_payoffs(self, state: GameState):
        cooperation_last_round = self.history.opponent_actions[-1].sum() >= self.game_description.n_players // 2
        payoff = np.full(self.game_description.n_rounds, 1) if not cooperation_last_round else np.full(self.game_description.n_rounds, 1 + self.game_description.k)
        self.history.my_payoffs[state.round_number - 1] = payoff[state.round_number - 1]

class Strategy_EXPLOITATIVE_262(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT)

    This strategy adapts to other players' cooperative behavior in the Collective Risk Dilemma game. It initially cooperates and then decides whether to continue cooperating or defect based on the number of cooperators from the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = math.ceil(game_description.m - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None or state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1]) if history else 0
        if cooperators >= self.cooperation_threshold:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_263(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATfT) for Collective Risk Dilemma

    This strategy adheres to the following decision rules:
    - In the first round, cooperate (C). This is a friendly gesture to encourage cooperation and build trust with opponents.
    - For subsequent rounds, evaluate the number of cooperators in the previous round (t-1) and make a decision for round t as follows:
      - If the majority of players ( m) cooperated in the previous round, cooperate (C). This rewards past cooperation and encourages continued collaboration.
      - If less than m cooperated in the previous round, defect (D). This punishes previous defections and may encourage opponents to reconsider their actions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1])
        if cooperators >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_264(BaseStrategy):
    """
    A strategy that cooperates initially and then adapts its cooperation behavior based on opponents' actions.
    If an opponent cooperates, it continues cooperating. If an opponent defects, it retaliates by defecting in the next round but gradually increases the cooperation threshold to encourage opponents to cooperate again.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.last_opponent_action = Action.D
        self.consecutive_cooperative_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is None:
            self.last_opponent_action = Action.D
            self.consecutive_cooperative_rounds = 0
            return Action.C
        opponent_cooperators = sum(history.opponent_actions[-1, :])
        if self.last_opponent_action == Action.D and opponent_cooperators >= 1:
            self.consecutive_cooperative_rounds = 1
            return Action.C
        elif self.last_opponent_action != Action.C and opponent_cooperators >= self.consecutive_cooperative_rounds:
            self.consecutive_cooperative_rounds += 1
            if self.cooperation_threshold < self.game_description.n_players:
                self.cooperation_threshold += 1
            return Action.C
        elif self.last_opponent_action == Action.C:
            self.consecutive_cooperative_rounds = 0
            if self.cooperation_threshold < self.game_description.n_players:
                self.cooperation_threshold += 1
            return Action.D
        elif self.cooperation_threshold >= self.game_description.n_players:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_266(BaseStrategy):
    """
    Implementation of the Tit-for-Tat-Adaptive (TFT-A) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m
        self.observed_cooperators = 0
        self.rounds_of_declining_cooperation = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        action = Action.C
        if state.round_number == 0 and history is None:
            return action
        opponent_cooperated = False
        if history is not None and len(history.opponent_actions) > 1:
            opponent_cooperated = bool(history.opponent_actions[-1][-1])
        if state.round_number == 1:
            if self.calculate_percentage_of_cooperators(history) >= self.game_description.m:
                action = Action.C
            else:
                action = Action.D
                self.rounds_of_declining_cooperation = 1
        elif opponent_cooperated:
            action = Action.C
        else:
            action = Action.D
            self.adjust_minimum_cooperators(history)
            self.reset_rounds_of_declining_cooperation()
        return action

    def calculate_percentage_of_cooperators(self, history: PlayerHistory) -> float:
        total_players = len(history.opponent_actions[-1])
        cooperators = sum(history.opponent_actions[-1])
        return cooperators / total_players if total_players != 0 else 0

    def adjust_minimum_cooperators(self, history: PlayerHistory) -> None:
        percentage = self.calculate_percentage_of_cooperators(history)
        new_threshold = round(self.min_cooperators * (1 + (percentage > self.game_description.m) * 0.01))
        if new_threshold >= self.game_description.n_players:
            self.min_cooperators = self.game_description.n_players - 1
        elif new_threshold < self.min_cooperators - 1:
            self.min_cooperators -= 1
        else:
            self.min_cooperators = new_threshold

    def reset_rounds_of_declining_cooperation(self) -> None:
        self.rounds_of_declining_cooperation = 0

class Strategy_EXPLOITATIVE_267(BaseStrategy):
    """
    A strategy that mimics the Tit-for-Tat behavior with an adaptive cooperative threshold, making it more resilient to one-time defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.adaptive_cooperative_threshold = game_description.m
        self.consecutive_cooperations = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_cooperated_in_previous_round = False
        if history is not None and len(history.opponent_actions) > 0:
            opponent_cooperated_in_previous_round = sum(history.opponent_actions[-1]) >= self.game_description.m
        cooperate = opponent_cooperated_in_previous_round and self.consecutive_cooperations >= self.adaptive_cooperative_threshold
        action = Action.C if cooperate else Action.D
        if cooperate:
            self.consecutive_cooperations += 1
        else:
            self.consecutive_cooperations = 0
        return action

class Strategy_EXPLOITATIVE_268(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATfT)
    Strategy Summary: Cooperates when group cooperation is beneficial, retaliates against defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(my_actions=np.zeros(game_description.n_rounds), my_payoffs=np.zeros(game_description.n_rounds), opponent_actions=np.zeros((game_description.n_rounds, game_description.n_players)), opponent_payoffs=np.zeros((game_description.n_rounds, game_description.n_players)))

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if history is None:
            self.history.my_actions[0] = True
        else:
            rounds = min(state.round_number + 1, len(self.history.my_actions))
            cooperators = np.sum(np.roll(self.history.my_actions, -rounds)[rounds:])
            self.history.my_actions[state.round_number] = cooperators >= self.game_description.m
        if state.round_number == len(self.history.my_actions) or state.round_number == state.round_number - 1:
            if np.sum(self.history.my_actions[-self.game_description.n_rounds:]) >= self.game_description.m:
                self.history.my_actions[state.round_number] = True
            else:
                self.history.my_actions[state.round_number] = False
        return Action(int(self.history.my_actions[state.round_number]))

class Strategy_EXPLOITATIVE_269(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) Strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(my_actions=np.zeros(game_description.n_rounds, dtype=bool), my_payoffs=np.zeros(game_description.n_rounds), opponent_actions=np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), opponent_payoffs=np.zeros((game_description.n_rounds, game_description.n_players)))

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        half = self.game_description.n_players // 2
        rounds = int(self.game_description.n_rounds / 2)
        cooperators = np.sum(history.opponent_actions[rounds:, :][::-1] > 0)
        if cooperators >= half + 1:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_270(BaseStrategy):
    """
    Tit-for-Tat-with-Adaptation (TfT-A) Strategy for Collective Risk Dilemma game
    Adapts to opponent's cooperative behavior and punishes non-cooperation with a built-in threshold
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_def = 0
        self.max_noncooperation_threshold = math.ceil(game_description.n_players * 0.8)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_actions = history.opponent_actions[-1] if history else np.zeros(self.game_description.n_players, dtype=bool)
        cooperation_threshold_met = sum(opponent_actions) >= self.game_description.m
        current_round_action = Action.C if cooperation_threshold_met else Action.D
        self.n_def += 1 if current_round_action == Action.D else 0
        return current_round_action if self.n_def <= self.max_noncooperation_threshold else Action.C

class Strategy_EXPLOITATIVE_271(BaseStrategy):
    """
    Tit-for-Tat with Adaptation strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.payoff_balance = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        t = state.round_number if history is not None else 0
        cooperators = sum(history.opponent_actions[t - 1, :]) if t > 1 else 0
        if self.payoff_balance > 0:
            action = Action.C
        else:
            action = Action.D
        if cooperators >= self.game_description.m and action == Action.C:
            action = Action.C
        elif cooperators < self.game_description.m and t != 1:
            action = Action.D
        opponent_response = history.opponent_actions[t - 1, 0] if t > 1 else None
        if opponent_response == Action.D and action == Action.C:
            self.payoff_balance -= 1
        elif opponent_response == Action.C and (action == Action.C or opponent_response != history.opponent_actions[t - 2, 0]):
            self.payoff_balance += 1
        return action

class Strategy_EXPLOITATIVE_273(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.ct = game_description.m
        self.total_rounds = 0
        self.payoff = 0

    def adjust_ct(self, last_r2: NDArray[np.bool_]):
        all_cooperated = np.all(last_r2)
        all_defected = np.all(~last_r2)
        if all_cooperated or all_defected:
            self.ct += 1 if all_cooperated else self.ct - 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        self.total_rounds += 1
        cooperators = np.sum(history.opponent_actions[-int(self.total_rounds // 2):, :], axis=0)
        if self.total_rounds >= int(self.game_description.n_rounds / 2):
            self.adjust_ct(cooperators)
        if self.ct > self.game_description.m and self.total_rounds >= 1:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_274(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishing_period = math.floor(game_description.n_players / 2)
        self.opponent_history = np.zeros((game_description.n_players, game_description.n_rounds), dtype=np.bool_)
        self.my_cooperators_last_round = 0
        self.punishment_counter = 0
        self.forgiveness_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.update_opponent_history(history)
        cooperators_last_round = sum(history.opponent_actions[-1, :])
        if cooperators_last_round >= self.game_description.m - 1:
            return Action.C
        if self.punishment_counter < self.punishing_period and (not self.opponent_history[0, state.round_number - 1]):
            return Action.D
        if self.opponent_history[0, state.round_number - 1] and (not history.opponent_actions[-1, 0]):
            self.punishment_counter += 1
        elif self.opponent_history[0, state.round_number - 1] and history.opponent_actions[-1, 0]:
            self.forgiveness_counter = min(self.forgiveness_counter + 1, self.punishing_period)
            self.punishment_counter = 0
        return Action.D if self.punishment_counter >= self.punishing_period else Action.C

    def update_opponent_history(self, history: PlayerHistory):
        for round_number in range(1, len(history.opponent_actions)):
            opponent_cooperated_last_round = sum(history.opponent_actions[round_number - 1, :]) >= self.game_description.m - 1
            if opponent_cooperated_last_round:
                self.opponent_history[0, round_number] = True
            else:
                self.opponent_history[0, round_number] = False

class Strategy_EXPLOITATIVE_275(BaseStrategy):
    """
    A strategy that implements the Adaptive Tit-for-Tat (ATFT) with Escalation and Forgiveness (AEFT) in Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.p_init = 0.2
        self.escalation_threshold = math.ceil(game_description.n_players * game_description.m / 2)
        self.payoffs = np.zeros((game_description.n_rounds,))

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return np.random.choice([Action.C, Action.D], p=[1 - self.p_init, self.p_init])
        cooperators = sum(history.opponent_actions[-1, :])
        if state.round_number == self.game_description.n_rounds and cooperators >= self.escalation_threshold:
            return Action.C
        if cooperators < self.game_description.m or (cooperators >= self.escalation_threshold and history.my_actions[-1] == Action.D):
            return Action.D
        return Action.C

    def adjust_escalation_threshold(self, payoffs):
        self.payoffs = np.append(self.payoffs, payoffs)
        self.escalation_threshold = math.ceil((np.mean(self.payoffs) - 1) / (self.game_description.k - 1))

class Strategy_EXPLOITATIVE_276(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) Strategy for the Collective Risk Dilemma Game.
    This strategy cooperates in the first round to set a cooperative tone, and then adapts its cooperation based on the number of players that cooperated in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = int(math.ceil(game_description.n_players * game_description.m / 100))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.m or state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_277(BaseStrategy):
    """
    Tit-for-Tat Strategy for Collective Risk Dilemma Game.
    Balances cooperation with punishment to ensure a higher proportion of resources as rewards.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = []

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.opponent_history.append(history.opponent_actions[-1])
        if np.all(self.opponent_history[-1] == [1] * len(self.opponent_history[-1])):
            return Action.C
        return Action.D

    def last_round(self, state: GameState) -> Action:
        """
        Returns the action for the last round regardless of previous opponent actions.
        """
        return Action.C if state.round_number == self.game_description.n_rounds else self.__call__(state, None)

class Strategy_EXPLOITATIVE_279(BaseStrategy):
    """
    A Tit-for-Tat-with-Rationalization (TfTR) player in the Collective Risk Dilemma.
    This strategy cooperates if more than half of the players cooperated last round,
    defects when fewer than half cooperated last round and its defection history exceeds 50% of rounds,
    or cooperates otherwise. The defection history tracks the number of times this player has cooperated
    but received a defection from another player.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defection_history = 0
        self.rounds_played = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None or state.round_number == 0:
            return Action.C
        self.rounds_played += 1
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators > self.game_description.n_players - 2 or self.defection_history > self.rounds_played // 2:
            return Action.D
        elif cooperators >= self.game_description.n_players - 3:
            return Action.C
        else:
            self.defection_history += 1 if history.my_actions[-1] == Action.C and any(history.opponent_actions[-1, :] == [False]) else 0
            return Action.C

class Strategy_EXPLOITATIVE_280(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Gradient Adjustment (TfT-GA)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.initial_leniency = math.ceil(self.game_description.n_rounds / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_cooperation_count = np.zeros(self.game_description.n_rounds, dtype=int)
        for t in range(1, state.round_number + 1):
            if t < self.initial_leniency:
                action = Action.C
            elif np.sum(history.opponent_actions[t - 1]) >= self.game_description.n_players // self.game_description.m:
                action = Action.C
            else:
                opponent_cooperation_count[t] += 1
                if opponent_cooperation_count[t] > self.initial_leniency:
                    action = Action.D
        return action

class Strategy_EXPLOITATIVE_281(BaseStrategy):
    """
    Strategy name: Tit-for-Tat with Adaptive Cooperation (TFTA)
    Strategy summary: Initially cooperates in the first round, then mimics the opponent's last action for the next r-2 rounds. If the opponent has been cooperative, TFTA continues to cooperate. However, if the opponent has ever defected, TFTA will defect until the opponent reverts back to cooperation, at which point TFTA resumes copying the opponents behavior.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_opponent_action = None
        self.my_last_action = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.last_opponent_action = history.opponent_actions[-1] if history else np.zeros(1).astype(bool)
        self.my_last_action = history.my_actions[-1] if history else np.zeros(1).astype(bool)
        cooperators = sum(self.last_opponent_action)
        if cooperators >= len(self.last_opponent_action) // self.game_description.m:
            if self.my_last_action == self.last_opponent_action[0]:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D if self.my_last_action != self.last_opponent_action[0] else Action.C

class Strategy_EXPLOITATIVE_282(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperative Threshold (TFT-ACT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m
        self.last_round_cooperators = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        if state.round_number >= self.game_description.n_rounds or self.last_round_cooperators < self.min_cooperators:
            return Action.C if self.last_round_cooperators == self.min_cooperators else Action.D
        return Action(int(self.last_round_cooperators >= self.min_cooperators))

class Strategy_EXPLOITATIVE_284(BaseStrategy):
    """
    Strategy name: Adaptive Tit-for-Tat (ATFT)
    Strategy summary: Responds cooperatively to cooperation and defectively to defection, learning from the opponent's behavior.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_streak = 0
        self.last_opponent_action = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        current_round = state.round_number
        opponent_actions = history.opponent_actions[current_round - 1]
        self.last_opponent_action = opponent_actions[-1] if len(opponent_actions) > 0 else None
        if self.last_opponent_action is None:
            return Action.D
        if self.cooperation_streak >= 2 and opponent_actions[-1] == Action.C:
            return Action.C
        elif self.cooperation_streak > 0 and opponent_actions[-1] == Action.D:
            self.cooperation_streak -= 1
            return Action.D
        elif opponent_actions[-1] == Action.C:
            self.cooperation_streak = 1
            return Action.C
        else:
            return Action.D

    def _reset(self):
        self.cooperation_streak = 0
        self.last_opponent_action = None

class Strategy_EXPLOITATIVE_285(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Strategy for the Collective Risk Dilemma Game
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.e = int(math.log2(game_description.n_players))
        self.probability_adaptation = 0.1

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_payoff = history.my_payoffs[-1]
        opponent_payoff = history.opponent_payoffs[-1][0]
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C if my_payoff < opponent_payoff else Action.D
        e = sum(history.opponent_actions[state.round_number - self.e:state.round_number, 0]) == self.e
        if e:
            self.probability_adaptation = min(self.probability_adaptation + 0.15, 0.5)
        else:
            self.probability_adaptation = max(self.probability_adaptation - 0.15, 0.1)
        return Action.C if random.random() <= self.probability_adaptation else Action.D

class Strategy_EXPLOITATIVE_286(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperative Threshold (TFT-ACT)
    This strategy cooperates initially and then adjusts its cooperative threshold based on the number of cooperators in previous rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperative_threshold = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        self.cooperative_threshold = max(self.cooperative_threshold - int(random.random() < 0.1), 1) if cooperators < self.game_description.m else self.cooperative_threshold
        return Action.C if cooperators >= self.cooperative_threshold else Action.D

class Strategy_EXPLOITATIVE_287(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat Plus (TfT+)

    This strategy initially cooperates and then adjusts future cooperation based on the previous round's actions of opponents.
    If a majority (more than (n-1)/2) of players cooperate in the previous round, TfT+ continues cooperating in the current round.
    If less than m players cooperate or if TfT+ defected in the previous round and m or more players cooperated, TfT+ will defect in the current round (punishing those who did not cooperate and signaling cooperation for the next round).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_counter = math.ceil(game_description.n_players / 2)
        self.history = None

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if len(history.opponent_actions) > current_round - 1:
            previous_cooperators = sum(history.opponent_actions[current_round - 1])
            if previous_cooperators >= self.cooperation_counter:
                return Action.C
            elif previous_cooperators < self.game_description.m or history.my_actions[-1] == Action.D:
                return Action.D
        return Action.C

class Strategy_EXPLOITATIVE_288(BaseStrategy):
    """
    Implementation of the Tit-for-Tat with Threshold (TFT-Threshold) strategy.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m
        self.n = self.game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-1, :])
        if cooperators >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_289(BaseStrategy):
    """
    A strategy that cooperates initially and adopts an adaptive approach based on past cooperation and risk factor (k).
    It increases the adaptive threshold over time when faced with defection from other players.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = 0
        self.defection_count = 0
        self.round = 0

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        self.round += 1
        if state.round_number == 0:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-1, :])
        adaptive_threshold = self.threshold + self.defection_count / self.round * (1 - self.game_description.k)
        if cooperators >= self.game_description.m and history.my_actions[-1] == Action.C:
            return Action.C
        elif adaptive_threshold > np.sum(history.opponent_actions[-1, :]) - self.defection_count:
            return Action.C
        else:
            self.defection_count += 1
        return Action.D

class Strategy_EXPLOITATIVE_290(BaseStrategy):
    """
    A strategy that cooperates in the first round and mimics other players' cooperation
    patterns while prioritizing those who cooperate most frequently when the minimum number
    of cooperators is met. The strategy aims to encourage cooperation while exploiting opponents
    who consistently defect or do not follow a cooperative pattern.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_coop_threshold = game_description.m - 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round = len(history.opponent_actions) - 1 if history else 0
        cooperators = sum(history.opponent_actions[prev_round, :]) if history else 0
        if state.round_number == self.game_description.n_rounds - 1 or cooperators >= self.min_coop_threshold:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_291(BaseStrategy):
    """
    A Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = math.ceil((game_description.m - 1) / 2) if game_description.n_players % 2 == 0 else math.ceil((game_definition.m - 1 + 1) / 2)
        self.defection_counter = 0
        self.cooperation_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        my_action = Action.D if cooperators < self.cooperation_threshold else Action.C
        if my_action == Action.C:
            self.cooperation_counter += 1
            if history and state.round_number > 1:
                self.defection_counter = max(0, self.defection_counter - 1)
        else:
            self.defection_counter += 1
            if self.defection_counter >= self.game_description.n_players // 2 and history and (state.round_number > 1):
                self.cooperation_threshold -= 1
                self.defection_counter = max(0, self.defection_counter - 1)
            elif history and state.round_number > 1 and (self.cooperation_counter > 0) and (self.defection_counter == 0 or self.defection_counter >= self.game_description.n_players // 2):
                self.cooperation_threshold += 1
                self.cooperation_counter = 0
        return my_action

class Strategy_EXPLOITATIVE_293(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Risk Aversion (ATfT-RA) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.k_history = np.zeros(game_description.n_rounds - 1)
        self.current_round = 0
        self.consecutive_defects = 0

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.current_round += 1
        cooperators = sum(history.opponent_actions[-1])
        if cooperators < self.game_description.m:
            return Action.D
        elif cooperators >= self.game_description.m and self.current_round > self.game_description.n_rounds - 1:
            average_k = np.mean(self.k_history)
            if average_k > 1 + (self.game_description.n_players - cooperators):
                return Action.D
        elif self.consecutive_defects < self.game_description.m:
            self.consecutive_defects += 1
        else:
            self.consecutive_defects = 0
        if self.consecutive_defects >= self.game_description.m or cooperators >= self.game_description.m:
            if self.current_round > 1:
                average_k = np.mean(self.k_history[:self.current_round - 1])
                if average_k * (self.game_description.n_players - cooperators) > 1 + self.k_history[-1]:
                    return Action.D
        self.k_history[self.current_round - 2] = self.k_history[self.current_round - 1] if self.current_round > 1 else 1
        return Action.C

class Strategy_EXPLOITATIVE_294(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperators_threshold = int(self.game_description.n_players * (self.game_description.m / 100))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if not history:
            return Action.C
        cooperation_count = sum(history.opponent_actions[-1, :])
        if state.round_number == 1:
            return Action.C
        elif cooperation_count < self.cooperators_threshold:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_295(BaseStrategy):
    """
    Adaptive Tit-for-Tat Strategy for the Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m
        self.total_cooperators = 0
        self.first_round = True

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if self.first_round:
            self.first_round = False
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        self.total_cooperators += cooperators
        if state.round_number == self.game_description.n_rounds:
            required_cooperators = self.min_cooperators * self.game_description.n_players
            if self.total_cooperators >= required_cooperators:
                return Action.C
        return Action.D if cooperators < self.min_cooperators else Action.C if cooperators == self.min_cooperators * (self.game_description.n_players - 1) else Action.C

class Strategy_EXPLOITATIVE_296(BaseStrategy):
    """
    Tit-for-Tat with Adaptation (TfT-A) strategy for Collective Risk Dilemma game
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = []
        self.last_round_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.opponent_history.append(np.mean(history.opponent_actions[-1]))
        opponent_cooperators = self.last_round_cooperators if len(self.opponent_history) > 1 else history.opponent_actions[-1].sum()
        action = Action.C if opponent_cooperators >= (self.game_description.n_players - self.game_description.m) // 2 else Action.D
        self.last_round_cooperators = opponent_cooperators
        return action

class Strategy_EXPLOITATIVE_297(BaseStrategy):
    """
    A Tit-for-Tat strategy with Adaptive Cooperation Threshold (TFT-ACT) for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = math.floor(self.game_description.n_players / 2)
        self.last_round_cooperators = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators < self.m:
            return Action.D
        elif cooperators == self.m and history.my_actions[-1] == Action.D:
            self.last_round_cooperators = cooperators
            return Action.C
        else:
            return Action.C

class Strategy_EXPLOITATIVE_298(BaseStrategy):
    """Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)"""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = math.ceil(game_description.n_players * game_description.m / 100)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators < self.cooperation_threshold and cooperators != 0:
            return Action.D
        elif cooperators >= self.cooperation_threshold or cooperators == 0:
            return Action.C

class Strategy_EXPLOITATIVE_299(BaseStrategy):
    """
    A Collective Risk Dilemma strategy called Tit-for-Tat-Adaptive (TfTA). This strategy cooperates initially, then mirrors its opponent's actions from the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = None
        self.m = game_description.m

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if self.opponent_history is None or len(self.opponent_history) < state.round_number:
            self.opponent_history = np.zeros((state.round_number,), dtype=bool)
        last_round = state.round_number - 1 if state.round_number > 0 else None
        self.opponent_history[last_round] = history.opponent_actions[last_round, 0]
        cooperators = np.sum(history.opponent_actions[-self.game_description.n_players:])
        if last_round is None or cooperators >= self.m:
            return Action.C
        elif self.opponent_history[-1]:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_300(BaseStrategy):
    """
    A simple Tit-for-Tat strategy with a variation that introduces forgiveness.
    The strategy cooperates on the first move, and subsequently mimics reciprocity by cooperating if the opponent cooperated in the previous round.
    If the opponent defected in the previous round, the strategy defects as retaliation; however, there's a chance to deviate from strict retaliation through forgiveness with probability 'f'.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.forgiveness_factor = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is not None and len(history.my_actions) < state.round_number:
            history.my_actions = np.append(history.my_actions, [Action.D])
        if state.round_number == self.game_description.n_rounds - 1:
            forgiveness = False
        else:
            forgiveness = random.random() > self.forgiveness_factor
        if history.opponent_actions[-1, 0] == Action.C and (not forgiveness):
            return Action.D
        elif history.opponent_actions[-1, 0] == Action.C:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_301(BaseStrategy):
    """
    Strategy name: Tit-for-Tat with Adaptive Cooperative Threshold (TFT-ACT)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.window_size = int(game_description.n_players * game_description.n_rounds * 0.8)
        self.cooperation_history = [0] * self.window_size
        self.current_round = 1
        self.threshold = game_description.m / 2.0
        self.min_threshold = 0.5
        self.max_threshold = 0.95
        self.window_multiplier = 1.2
        self.window_divisor = 3.0
        self.s = int(self.window_size / game_description.n_rounds)

    def get_cooperators(self):
        cooperators = np.mean(self.cooperation_history[-self.window_size:])
        return cooperators

    def update_history(self):
        self.cooperation_history[self.current_round - 1] = 1 if Action.C == self.__class__.ACTION_MAP[self.__class__](Action.C) else 0

    def adapt_window(self, increase=True):
        new_size = math.floor((increase and self.window_multiplier or self.window_divisor) * self.window_size / self.s)
        self.window_size = max(min(new_size, int(self.window_size * 1.5)), self.window_size // 2)

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if state.round_number == 0:
            return Action.C
        self.current_round = state.round_number
        p_c = self.get_cooperators()
        if p_c >= self.threshold and history is not None:
            return Action.C
        elif p_c < self.min_threshold and history is not None:
            self.threshold = min(self.threshold + 0.1, self.max_threshold)
            return Action.D
        else:
            self.update_history()
            if history is not None and state.round_number >= self.s:
                self.adapt_window(p_c > self.max_threshold or p_c < self.min_threshold)
            return Action.D

class Strategy_EXPLOITATIVE_302(BaseStrategy):
    """
    Tit-for-Tat-Adaptive (TfT-A) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            self.opponent_history = np.zeros((state.round_number, self.game_description.n_players), dtype=bool)
            self.opponent_history[-1] = [False for _ in range(self.game_description.n_players)]
        else:
            self.opponent_history = history.opponent_actions
        last_round = self.opponent_history[-1]
        cooperators = sum(last_round)
        if cooperators >= self.game_description.m:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_303(BaseStrategy):
    """
    Tit-for-Tat with Variation (TFTV) strategy for the Collective Risk Dilemma game.
    Reciprocates cooperation while being punishingly exploitative in case of defection, and adapts to gain rewards when there is a critical mass of cooperators.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperating = True
        self.min_coop = self.game_description.m
        self.current_coop = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.cooperating = True
            return Action.C
        if not self.cooperating and self.current_coop >= self.min_coop:
            self.cooperating = True
        if history:
            self.update_state(history)
        if not history or state.round_number == len(history.opponent_actions) - 1:
            cooperation = sum(history.opponent_actions[-1, :]) >= self.min_coop
            if cooperation:
                self.cooperating = False
            else:
                self.cooperating = history.my_actions[-1][-1]
        return Action(int(self.cooperating)) if self.cooperating else Action.D

    def update_state(self, history: PlayerHistory):
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.min_coop:
            self.current_coop += 1
        elif self.current_coop > 0:
            self.current_coop -= 1

class Strategy_EXPLOITATIVE_304(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Risk Aversion strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.p = 0.5 + (1 - 0.5) * ((self.game_description.k - 1) / self.game_description.k)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-1])
        if cooperators >= self.game_description.m and random.random() <= self.p:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_306(BaseStrategy):
    """
    Tit-for-Tat (with a twist) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.m
        self.current_round = 0
        self.previous_cooperators = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.current_round += 1
        cooperators = sum(history.opponent_actions[self.current_round - 1, :])
        if self.previous_cooperators is None:
            self.previous_cooperators = cooperators
        if self.current_round == self.game_description.n_rounds:
            if self.previous_cooperators < self.threshold:
                return Action.D
            else:
                return Action.C
        if cooperators >= self.threshold:
            return Action.C
        elif self.previous_cooperators < self.threshold - 1:
            return Action.C
        else:
            return Action.D
        self.previous_cooperators = cooperators

class Strategy_EXPLOITATIVE_307(BaseStrategy):
    """
    Implementation of the Tit-for-Tat-Adaptive (TFT-A) strategy in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = min(max(game_description.m, 2), int(game_description.n_players * 0.8))
        self.history_length = max(5, int(self.game_description.n_players / 2))
        self.cooperator_counts = np.zeros(self.history_length)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-self.history_length:, -1])
        self.cooperator_counts[self.history_length - 1] = cooperators
        self.m = int(np.mean(self.cooperator_counts) * self.game_description.n_players / 2 + 0.5)
        if cooperators >= self.m:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_308(BaseStrategy):
    """
    A Tit-for-Tat-Adaptive (TFT-A) strategy that cooperates initially and adapts based on previous round's cooperators.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.current_round = 0
        self.previous_min_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        self.current_round = state.round_number
        if self.previous_min_cooperators >= self.game_description.m:
            return Action.C
        else:
            return Action.D
        self.previous_min_cooperators = min(history.my_actions[-1]) if history is not None else 0

class Strategy_EXPLOITATIVE_309(BaseStrategy):
    """
    A Tit-for-Tat with Escalation (TfT-E) strategy for the Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.p = 3
        self.escalation_count = 0

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators_rate = self._cooperators_rate(history)
        self.escalation_count += 1 if cooperators_rate < self.game_description.m / self.game_description.n_players else 0
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        return Action(int((cooperators_rate >= self.game_description.m / self.game_description.n_players) * 1))

    def _cooperators_rate(self, history: PlayerHistory) -> float:
        cooperators = np.sum(history.opponent_actions[:, -self.p:].sum(axis=0)) / self.p
        return max(min(cooperators, 1), 0)

class Strategy_EXPLOITATIVE_310(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.initial_threshold = min(game_description.m - 1, math.floor((game_description.n_players - 1) * 0.8))

    def __call__(self, state: GameState, history: PlayerHistory):
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1])
        if cooperators >= math.floor((self.game_description.n_players - 1) * (1 - state.round_number / self.game_description.n_rounds)):
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_311(BaseStrategy):
    """
    A Tit-for-Tat with Adaptation strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_opponent_action = None
        self.first_round = True

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.first_round = True
            return Action.C
        self.last_opponent_action = np.mean(history.opponent_actions[-1]) if history is not None else None
        if self.first_round:
            self.first_round = False
            return Action.C
        if self.last_opponent_action == 1:
            return Action.C
        elif state.round_number == self.game_description.n_rounds:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_312(BaseStrategy):
    """
    A strategy that imitates the Tit-for-Tat with Adaptation (TFT-A) strategy in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_status = Action.C
        self.opponent_history = []

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.opponent_history.append(history.opponent_actions[-1])
        cooperation_threshold = self.game_description.n_players // 2
        if self.cooperation_status == Action.C:
            if np.count_nonzero(history.opponent_actions[-1]) < cooperation_threshold:
                self.cooperation_status = Action.D
            elif np.count_nonzero(history.opponent_actions[-1]) > cooperation_threshold:
                self.cooperation_status = Action.C
        elif np.count_nonzero(history.opponent_actions[-1]) >= cooperation_threshold:
            self.cooperation_status = Action.C
        return self.cooperation_status

class Strategy_EXPLOITATIVE_313(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.act = math.floor(self.n_players / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :]) if history else 0
        if state.round_number < self.game_description.n_rounds - 1 and cooperators >= self.m:
            self.act += 1
            self.act = min(self.act, self.n_players - 1)
        elif state.round_number > 1 and cooperators < self.m - 1:
            self.act -= 1
            self.act = max(0, self.act)
        return Action.C if cooperators >= self.act else Action.D

class Strategy_EXPLOITATIVE_314(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)

    This strategy implements the Tit-for-Tat with Adaptive Cooperation Threshold strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.alpha = int(math.ceil(game_description.m))
        self.history = PlayerHistory(my_actions=np.zeros(game_description.n_rounds, dtype=bool), my_payoffs=np.zeros(game_description.n_rounds, dtype=float), opponent_actions=np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), opponent_payoffs=np.zeros((game_description.n_rounds, game_description.n_players), dtype=float))

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if history is not None and state.round_number > 0:
            self.history.my_actions[state.round_number - 1] = True
            cooperators = np.sum(self.history.opponent_actions[-1, :])
            if cooperators >= self.alpha:
                self.alpha += 1
        action = Action.D
        if state.round_number == 0 or cooperators >= self.alpha:
            action = Action.C
            if state.round_number > 0:
                self.history.my_actions[state.round_number - 1] = action.value
        return action

class Strategy_EXPLOITATIVE_316(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATfT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C if random.random() < 0.5 else Action.D
        cooperators = sum(history.opponent_actions[-1, :])
        return Action.C if cooperators >= self.m else Action.D

class Strategy_EXPLOITATIVE_317(BaseStrategy):
    """
    Strategy implementing Gradual Defection in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_coop_threshold = game_description.m / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return random.choice([Action.C, Action.D])
        cooperators = np.mean(history.opponent_actions[:, -1]) if history else self.min_coop_threshold
        return Action.C if cooperators < self.min_coop_threshold else Action.D

class Strategy_EXPLOITATIVE_318(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.m
        self.previous_round_coop = 0
        self.consecutive_defects = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and history.my_actions[-1]:
            self.previous_round_coop += 1
            self.consecutive_defects = 0
        else:
            self.previous_round_coop = 0
            self.consecutive_defects += 1
        cooperators = sum(history.opponent_actions[-1, :]) if history is not None else 0
        if cooperators >= self.threshold - 1:
            self.threshold = min(self.threshold + math.ceil((cooperators - (self.threshold - 1)) / self.game_description.k), self.game_description.n_players)
        elif self.consecutive_defects >= self.game_description.n_rounds:
            self.threshold = max(self.threshold - 1, self.game_description.m)
        return Action.C if self.previous_round_coop >= self.threshold else Action.D

class Strategy_EXPLOITATIVE_319(BaseStrategy):
    """
    Strategy name: Tit-for-Tat with Modified Greed (TFT-MG)
    Balances cooperation and defection by mimicking a reliable partner while still being opportunistic.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m - 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None or len(history.opponent_actions) < state.round_number:
            return Action.D
        cooperators = sum(history.opponent_actions[state.round_number - 1, :])
        return Action.C if cooperators >= self.m else Action.D

class Strategy_EXPLOITATIVE_320(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT)
    Strategy Description: Cooperate if a sufficient percentage of other players have also cooperated. Adaptively adjust the cooperation threshold based on history.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = []
        self.cooperation_threshold = game_description.m
        self.current_round = 0

    def update_cooperation_threshold(self):
        if self.current_round < len(self.history) // 2:
            return
        average_cooperation = np.mean(self.history)
        self.cooperation_threshold = average_cooperation + (self.game_description.m - average_cooperation) * 0.1

    def get_action(self):
        if self.current_round == 0 or self.current_round == len(self.history):
            return Action.C
        percentage_cooperators = np.mean(self.history[-len(self.history) // 2:])
        if percentage_cooperators >= self.cooperation_threshold:
            return Action.C
        else:
            return Action.D

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        self.history.append(history.my_actions[0]) if history is not None else None
        self.current_round += 1
        self.update_cooperation_threshold()
        return self.get_action()

class Strategy_EXPLOITATIVE_321(BaseStrategy):
    """
    Tit-for-Tat Strategy for Collective Risk Dilemma.
    This strategy copies the majority action of opponents from the previous round, starting from the second round.
    In the first and last rounds, it either defects or cooperates based on a simple rule to encourage cooperation or punish defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros(game_description.n_rounds))

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if not history:
            return Action.D
        elif state.round_number == self.game_description.n_rounds - 1:
            cooperators = np.sum(history.opponent_actions[-2, :])
            return Action(cooperators >= self.game_description.n_players // 2)
        else:
            cooperators = np.sum(history.opponent_actions[state.round_number - 1, :])
            return Action(cooperators > self.game_description.n_players // 2)

class Strategy_EXPLOITATIVE_322(BaseStrategy):
    """
    The Tit-for-Tat with Variant (TFTV) strategy for the Collective Risk Dilemma game.
    This strategy mimics an opponent's behavior, cooperating when they cooperate and defecting when they defect.
    It establishes a cooperative pattern to build trust with opponents while keeping an eye on their actions to switch strategies if needed.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = np.zeros(game_description.n_rounds, dtype=bool)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.opponent_history[state.round_number - 1] = history.opponent_actions[-1, 0] if history else False
        opponent_cooperators = sum(self.opponent_history)
        if opponent_cooperators >= self.game_description.n_players // self.game_description.m:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_323(BaseStrategy):
    """Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)"""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.act = math.ceil(game_description.n_players / 2)
        self.history = PlayerHistory(my_actions=np.zeros(game_description.n_rounds, dtype=bool), my_payoffs=np.zeros(game_description.n_rounds), opponent_actions=np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), opponent_payoffs=np.zeros((game_description.n_rounds, game_description.n_players)))

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1])
        self.history.my_actions[state.round_number] = cooperators >= self.act
        if state.round_number < self.game_description.n_rounds:
            half_rounds = math.ceil(self.game_description.n_rounds / 2)
            if (state.round_number + half_rounds - 1) % self.game_description.n_rounds == 0:
                if cooperators > self.game_description.m * (self.game_description.n_players - 1) // self.game_description.m:
                    self.act += 1 if self.act < self.game_description.n_players else 0
                elif cooperators < self.game_description.m:
                    self.act -= 1 if self.act > 1 else 0
        payoff = 1 - self.history.my_actions[state.round_number] * (cooperators >= self.game_description.m) * (self.game_description.k if cooperators >= self.game_description.m else 1)
        self.history.my_payoffs[state.round_number] = payoff
        return Action(int(self.history.my_actions[state.round_number]))

class Strategy_EXPLOITATIVE_324(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)
    Summary: Cooperates if number of cooperators in the previous round exceeds a threshold, otherwise defects. Threshold adapts based on success of collaboration.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.n_players

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        new_threshold = self.threshold
        if cooperators >= self.game_description.m:
            new_threshold = max(new_threshold + 1, self.game_description.m)
        elif cooperators < self.game_description.m - 1:
            new_threshold = max(new_threshold - 1, 2)
        self.threshold = new_threshold
        return Action.C if cooperators >= self.threshold else Action.D

class Strategy_EXPLOITATIVE_325(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Threshold strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.minimum_cooperators = game_description.m
        self.threshold_index = int(math.ceil((self.minimum_cooperators - 1) / 2))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.threshold_index:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_326(BaseStrategy):
    """
    A cooperative strategy called Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.alpha = 0.1
        self.history = PlayerHistory(np.zeros((game_description.n_rounds,), dtype=bool), np.zeros((game_description.n_rounds,)), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros((game_description.n_rounds, game_description.n_players)))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.history.my_actions[0] = True
            return Action.C
        self.history = history
        cooperators_previous = sum(self.history.opponent_actions[-2:, -1])
        if state.round_number == self.game_description.n_rounds or state.round_number == 1:
            return Action.C
        cooperators = sum(self.history.opponent_actions[-1, :])
        if cooperators < self.game_description.m * (1 - self.alpha):
            return Action.D
        elif cooperators >= self.game_description.m or cooperators >= self.game_description.m * (1 + self.alpha) or cooperators_previous == self.game_description.m:
            return Action.C
        else:
            return Action.C if cooperators == self.game_description.m else Action.D

class Strategy_EXPLOITATIVE_327(BaseStrategy):
    """
    A strategy that plays Cooperate in the first round and reciprocates the opponent's actions in subsequent rounds,
    with a variant that switches to a more aggressive Tit-for-Two-Tats strategy when cooperation fails.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = math.ceil(game_description.n_rounds / 2)
        self.state = 'cooperate'

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        round_number = state.round_number - 1
        my_actions = history.my_actions[round_number]
        opponent_action = history.opponent_actions[round_number, 0]
        cooperation_threshold = self.game_description.m * (self.game_description.n_players - 1) / self.game_description.n_players
        if round_number < self.threshold and sum(history.my_actions[:round_number + 1]) < cooperation_threshold:
            self.state = 'Tit_for_Two_Tats'
        if self.state == 'cooperate':
            payoff = 1 - my_actions + self.game_description.k if opponent_action else 1
            return Action.C if payoff > 1 else Action.D
        elif self.state == 'Tit_for_Two_Tats':
            if round_number >= self.threshold and sum(history.my_actions[:round_number + 1]) < cooperation_threshold:
                self.state = 'cooperate'
            return Action.D

class Strategy_EXPLOITATIVE_328(BaseStrategy):
    """
    Implementation of Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.alpha = 0.5
        self.previous_rounds_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators_threshold = self.game_description.m + self.alpha * (self.game_description.n_players - self.game_description.m)
        if history is not None and cooperators_threshold < self.game_description.n_players:
            self.previous_rounds_cooperators = sum(history.opponent_actions[-1])
            return Action(self.previous_rounds_cooperators >= cooperators_threshold)
        else:
            return Action(self.previous_rounds_cooperators >= cooperators_threshold)

class Strategy_EXPLOITATIVE_329(BaseStrategy):
    """
    A simple Adaptive Tit-for-Tat (ATfT) strategy for the Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.forgiveness_period = math.ceil(game_description.n_players / 2)
        self.rounds_since_cooperation = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and len(history.opponent_actions) == 0):
            return Action.C
        if history is not None:
            opponent_last_action = history.opponent_actions[-1, -1]
            self.rounds_since_cooperation += 1 if opponent_last_action else 0
            if self.rounds_since_cooperation >= self.forgiveness_period:
                self.rounds_since_cooperation = 0
                return Action.C
            elif opponent_last_action:
                self.rounds_since_cooperation = 1
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_330(BaseStrategy):
    """A Tit-for-Tat Adaptive Strategy for Collective Risk Dilemma game."""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_cooperation_count = 0
        self.opponent_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        else:
            self.opponent_history = history.opponent_actions if history else []
            opponent_cooperation_count = sum(self.opponent_history[-1])
            self.opponent_cooperation_count = max(self.opponent_cooperation_count, 0)
            if opponent_cooperation_count >= self.game_description.m:
                return Action.C
            elif len(self.opponent_history) > 1 and (state.round_number == self.opponent_history[-1].size - 1 or opponent_cooperation_count < self.game_description.m):
                return Action.D if self.opponent_history[-2][-1] else Action.C
            else:
                return Action.C

class Strategy_EXPLOITATIVE_331(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperators_threshold = self.game_description.m
        self.running_average_cp = 0.0
        self.exploitation_limit = 0.5
        self.window_size = min(int(self.game_description.n_players * 0.1), int(self.game_description.n_rounds * 0.2))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        cooperators = np.sum(history.opponent_actions[:state.round_number, :])
        cooperation_percentage = cooperators / self.window_size
        self.running_average_cp = (self.running_average_cp * (self.window_size - 1) + cooperation_percentage) / self.window_size
        if cooperators >= self.cooperators_threshold:
            return Action.C
        adjusted_probability_of_cooperation = np.maximum(self.exploitation_limit, np.minimum(1 - self.exploitation_limit, cooperation_percentage))
        self.window_size += math.ceil(state.round_number * (1 - state.round_number / self.game_description.n_rounds) * 5)
        return Action(random.choice([0, 1]) if random.random() < adjusted_probability_of_cooperation else 0)

class Strategy_EXPLOITATIVE_332(BaseStrategy):
    """
    A strategy that implements the Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = float('inf')
        self.last_round_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is not None:
            self.last_round_cooperators = sum(history.opponent_actions[-1])
        if state.round_number == len(history.my_payoffs) + 1:
            return Action.C
        proportion = self.last_round_cooperators / self.game_description.n_players
        if proportion >= self.game_description.m:
            return Action.C
        elif proportion >= self.game_description.m - 1 and self.cooperation_threshold > 0:
            num_cooperators = int(proportion * self.game_description.n_players)
            return Action(math.ceil(num_cooperators if random.random() < 0.5 else num_cooperators - 1))
        else:
            return Action.D
        if history is not None and self.cooperation_threshold > 0:
            self.cooperation_threshold -= 1 if self.last_round_cooperators < self.game_description.m - 1 else 0

class Strategy_EXPLOITATIVE_333(BaseStrategy):
    """
    Implementation of the Tit-for-Tat with Gradient Adaptation (TTG) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_players = math.ceil(game_description.n_players / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            return Action.C
        majority = self.min_players
        cooperators = np.count_nonzero(history.opponent_actions[-1])
        if cooperators >= majority:
            return Action.C
        else:
            return Action.D

    def is_last_round(self, r: int, t: int) -> bool:
        return t == r

    def adapt_last_round(self, t: int, r: int, history: PlayerHistory) -> Action:
        if self.is_last_round(r, t):
            cooperators = np.count_nonzero(history.opponent_actions[-1])
            if cooperators >= self.min_players:
                return Action.D
            else:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_334(BaseStrategy):
    """Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)"""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.coop_threshold = self.game_description.n_players // 2
        self.delta = 0.1
        self.epsilon = 0.05

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :]) if history else 0
        if cooperators >= self.coop_threshold:
            self.coop_threshold += self.delta
        else:
            self.coop_threshold = max(self.coop_threshold - self.epsilon, self.game_description.n_players // 2)
        return Action.C if cooperators >= self.coop_threshold else Action.D

class Strategy_EXPLOITATIVE_335(BaseStrategy):
    """
    A strategy that starts by cooperating (goodwill gesture) and then cooperates if the opponent cooperated last round, defects otherwise.
    This is an adaptive version of the Tit-for-Tat strategy that allows for exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if not history:
            self.opponent_history = []
            history = PlayerHistory(my_actions=np.array([Action.C], dtype=bool), my_payoffs=np.array([0], dtype=float))
        opponent_cooperators = sum(history.opponent_actions[-1, :])
        self.opponent_history.append(history)
        if len(self.opponent_history) == 1 and opponent_cooperators == 0:
            return Action.D
        opponent_last_action = self.opponent_history[-1].my_actions[-1]
        if opponent_last_action == Action.C:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_336(BaseStrategy):
    """
    TFT-ACT strategy in Collective Risk Dilemma.
    Strategy cooperates or defects based on a dynamic cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.h = game_description.m / game_description.n_players
        self.p_0 = 0.1
        self.f_punish = 0.95
        self.f_reward = 1.05
        self.history_window = self.game_description.n_rounds
        self.cooperation_percentage_history = []

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 and (not history):
            return Action.C if random.random() < self.p_0 else Action.D
        self.cooperation_percentage_history.append(self._calculate_cooperation_percentage(history))
        cooperation_percentage = self._get_current_cooperation_percentage()
        if len(self.cooperation_percentage_history) > self.history_window:
            self.cooperation_percentage_history = self.cooperation_percentage_history[-self.history_window:]
        if cooperation_percentage < self.h and history.my_actions[-1] == Action.C:
            self.h *= self.f_punish
        elif cooperation_percentage >= self.h and history.my_actions[-1] == Action.D:
            self.h *= self.f_reward
        if self.h < self.game_description.m / self.game_description.n_players:
            return Action.D
        else:
            return Action.C

    def _calculate_cooperation_percentage(self, history: PlayerHistory) -> float:
        cooperators = sum(history.my_actions[:])
        return cooperators / history.my_actions.size

    def _get_current_cooperation_percentage(self) -> float:
        if not self.cooperation_percentage_history:
            return 0
        return np.mean(self.cooperation_percentage_history)

class Strategy_EXPLOITATIVE_337(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m_i = math.ceil(game_description.n_players * (game_description.k - 1) / game_description.k)
        self.history = np.zeros((self.game_description.n_players, self.game_description.n_rounds + 1))

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = np.sum(history.opponent_actions[:, -1])
        if cooperators >= self.m_i:
            self.m_i += int(cooperators / self.game_description.n_players * (self.game_description.k - 1))
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_338(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATfT) strategy in Collective Risk Dilemma game.
    Mimics opponent's previous action for the next rounds, cooperating if they cooperated last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_action_history = []

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            self.opponent_action_history.append(history.opponent_actions[-1])
            last_opponent_action = self.opponent_action_history[-1][-1]
            if last_opponent_action == Action.C:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_339(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.coop_threshold = game_description.m / game_description.n_players
        self.rounds_history = np.zeros(game_description.n_rounds)
        self.continuous_increase_count = 0
        self.continuous_decrease_count = 0
        self.last_cooperator_round = 0

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[state.round_number - 1, :])
        self.rounds_history[state.round_number] = cooperators / self.game_description.n_players
        if state.round_number < self.game_description.n_rounds - 1:
            if self.coop_threshold > self.rounds_history[-5:-1].mean() + self.coop_threshold or self.continuous_increase_count >= 5:
                self.coop_threshold += 0.02
                self.continuous_decrease_count = 0
            elif self.coop_threshold < self.rounds_history[-5:-1].mean() - self.coop_threshold or self.continuous_decrease_count >= 5:
                self.coop_threshold -= 0.02
                self.continuous_increase_count = 0
            else:
                self.continuous_increase_count += 1 if self.rounds_history[-1] > self.rounds_history[-2] else 0
                self.continuous_decrease_count += 1 if self.rounds_history[-1] < self.rounds_history[-2] else 0
        if state.round_number == self.game_description.n_rounds - 1:
            last_cooperator = cooperators > 0
            if last_cooperator and self.rounds_history[-1] >= self.coop_threshold or (not last_cooperator and self.rounds_history[-1] < self.coop_threshold):
                return Action.D
        return Action.C if cooperators >= int(self.coop_threshold * self.game_description.n_players) else Action.D

class Strategy_EXPLOITATIVE_340(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATfT)
    Strategy Description: Cooperates initially and responds to previous round's cooperation by cooperating in the next round. If a player defected previously, defects in response to maintain individual payoff. This creates a simple yet adaptive strategy that mirrors opponents' behavior while promoting cooperation when possible.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.my_last_action = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.my_last_action = history.my_actions[-1] if history is not None else None
        cooperators = sum(history.opponent_actions[-1, :]) if history is not None else 0
        response = Action.C if cooperators >= self.game_description.m or self.my_last_action == Action.C else Action.D
        return response

class Strategy_EXPLOITATIVE_341(BaseStrategy):
    """
    A strategy that implements the Tit-for-Tat-Adaptive (TfTA) behavior in Collective Risk Dilemma games.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_cooperation = None
        self.last_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.last_round = state.round_number == self.game_description.n_rounds - 1
        if history is None:
            self.opponent_cooperation = False
            return Action.C
        self.opponent_cooperation = history.opponent_actions[-1][0]
        if not history and self.last_round:
            return Action.D if not self.opponent_cooperation else Action.C
        if self.opponent_cooperation:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_342(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = self.game_description.n_players
        self.n_rounds = self.game_description.n_rounds
        self.m = self.game_description.m
        self.k = self.game_description.k
        self.r = self.game_description.n_rounds - 1
        self. = 0.01
        self.m_min = math.ceil(self.m * 0.5)
        self.m_max = math.floor(self.m * 1.5)
        self.cooperation_threshold = self.m_min
        self.history = PlayerHistory(np.zeros(self.r, dtype=bool), np.zeros(self.r, dtype=float), np.zeros((self.r, self.n_players), dtype=bool), np.zeros((self.r, self.n_players), dtype=float))

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            self.history.my_actions[0] = True
            return Action.C
        if state.round_number == self.r:
            return Action.C
        self.update_cooperation_threshold(history)
        percentage_cooperators = np.mean(history.opponent_actions[-1]) * self.n_players
        if percentage_cooperators >= self.cooperation_threshold:
            self.history.my_actions[state.round_number - 1] = True
            return Action.C
        self.history.my_actions[state.round_number - 1] = False
        return Action.D

    def update_cooperation_threshold(self, history: PlayerHistory):
        cooperators = np.sum(history.opponent_actions[-1])
        if cooperators > self.cooperation_threshold + self. and self.cooperation_threshold < self.m_max:
            self.cooperation_threshold += self.
        if cooperators < self.cooperation_threshold - self. and self.cooperation_threshold > self.m_min:
            self.cooperation_threshold -= self.
        if self.cooperation_threshold < self.m_min:
            self.cooperation_threshold = self.m_min
        if self.cooperation_threshold > self.m_max:
            self.cooperation_threshold = self.m_max

class Strategy_EXPLOITATIVE_344(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperative Threshold (TTAT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = [0] * game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round_cooperators = sum(history.opponent_actions[-1, :]) if history is not None else self.cooperation_history[-1]
        cooperators = min(last_round_cooperators + 1, self.game_description.n_players)
        return Action.C if cooperators >= self.game_description.m else Action.D

class Strategy_EXPLOITATIVE_345(BaseStrategy):
    """
    Implementation of the TFT-ACT strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.alpha = 0.9
        self.threshold = int(self.m * (1 - 1 / self.n_players))
        self.round_number = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.round_number += 1
            return Action.C
        cooperators = sum(history.opponent_actions[-1])
        self.round_number += 1
        if cooperators < self.threshold:
            return Action.D
        new_threshold = self.alpha * (self.threshold + (1 - self.threshold) * (cooperators / self.n_players))
        self.threshold = max(min(new_threshold, 1), 0)
        return Action.C

class Strategy_EXPLOITATIVE_346(BaseStrategy):
    """
    Implementation of the Free Rider Strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.theta = 1 - game_description.m / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if not history:
            if state.round_number == 0:
                return Action.C if self.game_description.n_players == self.game_description.m else Action.D
            else:
                cooperators = sum(history.opponent_actions[-1, :])
                if cooperators < self.game_description.m:
                    return Action.D
                elif random.random() < 1 - cooperators / self.game_description.n_players:
                    return Action.C
                else:
                    return Action.D
        elif state.round_number == self.game_description.n_rounds:
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators >= self.game_description.m:
                return Action.D
            else:
                return Action.C
        else:
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators < self.game_description.m:
                return Action.D
            elif random.random() < 1 - cooperators / self.game_description.n_players:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_347(BaseStrategy):
    """
    The Tit-for-Tat Adaptive (TfT-A) strategy for the Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.escalation_threshold = self.game_description.n_players // 2
        self.cooperated_counter = 0
        self.defected_counter = 0
        self.opponent_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        action = Action.D
        if history is not None and len(self.opponent_history) > self.game_description.n_rounds - 1:
            self.opponent_history.pop(0)
        if history is not None:
            if history.my_actions[-1]:
                self.cooperated_counter += 1
            else:
                self.defected_counter += 1
            self.opponent_history.append(history.opponent_actions[-1])
        if len(self.opponent_history) == self.game_description.n_rounds and sum(self.opponent_history[-1]) > self.escalation_threshold:
            action = Action.D
        return action

class Strategy_EXPLOITATIVE_348(BaseStrategy):
    """
    A Tit-for-Tat Plus strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m - 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or state.round_number == self.game_description.n_rounds:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-1]) if history is not None else 0
        return Action.C if cooperators > self.m else Action.D

class Strategy_EXPLOITATIVE_349(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.coop_threshold = math.ceil(game_description.n_players * 0.5)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[state.round_number - 1] if history else np.zeros(self.game_description.n_rounds, dtype=np.bool))
        if cooperators >= self.coop_threshold:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_350(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT)

    A strategy designed to balance cooperation and defection, adapting to the opponents' behavior while maintaining a level of reciprocity. The core rule is to cooperate in the first round and then mimic the opponent's most recent action for subsequent rounds. However, to add robustness and exploitative potential, TFTAT includes an adaptive cooperation threshold (m').
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.cooperation_threshold = None
        self.history = None

    def __call__(self, state: GameState, history: PlayerHistory):
        """
        Decide action based on the current game state and history.
        """
        if self.history is None:
            self.init_cooperation_threshold()
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.cooperation_threshold:
            return Action.C
        return Action.D

    def init_cooperation_threshold(self):
        """
        Initialize the cooperation threshold based on number of players and adaptive coefficient (m').
        """
        self.cooperation_threshold = self.n_players - 1
        self.history = PlayerHistory(my_actions=np.zeros(self.game_description.n_rounds, dtype=bool), my_payoffs=np.zeros(self.game_description.n_rounds, dtype=float), opponent_actions=np.zeros((self.game_description.n_rounds, self.n_players), dtype=bool), opponent_payoffs=np.zeros((self.game_description.n_rounds, self.n_players), dtype=float))

class Strategy_EXPLOITATIVE_351(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) Strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m - 1
        self.recent_history = np.zeros(3, dtype=np.bool_)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            recent_cooperators = np.sum(self.recent_history)
            return Action(int(recent_cooperators >= self.cooperation_threshold))
        recent_cooperators = np.sum(self.recent_history)
        if recent_cooperators >= self.cooperation_threshold or history.my_actions[-1] == Action.D:
            return Action.C
        return Action.D

    def update_history(self, action: Action, payoff: float):
        self.recent_history = np.roll(self.recent_history, -1)
        self.recent_history[-1] = int(action == Action.C)

class Strategy_EXPLOITATIVE_352(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m - 1

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        past_cooperators = np.sum(history.my_actions[-1])
        num_players = self.game_description.n_players
        if past_cooperators < self.min_cooperators:
            return Action.D
        elif past_cooperators >= self.min_cooperators and past_cooperators <= num_players - self.min_cooperators:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_353(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.epsilon = 0.01
        self.cooperation_threshold = self.m
        self.history = []

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if len(self.history) < self.r:
            return Action.D
        current_round = state.round_number
        cooperation_count = sum([h[current_round] for h in self.history if h])
        cooperation_percentage = cooperation_count / self.r
        if cooperation_percentage >= self.cooperation_threshold:
            return Action.C
        else:
            return Action.D

        def update(self):
            if len(self.history) == self.r:
                last_round = self.history[-1]
                last_cooperation_count = sum(last_round)
                if self.decide(current_round, last_cooperation_count) == Action.C:
                    if last_cooperation_count < (self.r - self.m) * self.cooperation_threshold / self.r:
                        self.cooperation_threshold += self.epsilon
                elif last_cooperation_count > self.m:
                    self.cooperation_threshold -= self.epsilon

class Strategy_EXPLOITATIVE_354(BaseStrategy):
    """
    Tit-for-Tat Strategy for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = math.ceil(game_description.n_players * game_description.m / 100)
        self.reward_factor = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory):
        action = Action.D
        if state.round_number == 0 and history is None:
            action = Action.C
        elif history is not None and len(history.my_actions) >= self.cooperation_threshold:
            last_action = history.my_actions[-1]
            action = Action(int(last_action))
        return action

class Strategy_EXPLOITATIVE_355(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m
        self.window_size = math.ceil(self.game_description.n_players / 2)
        self.cooperators_counts = np.zeros(int(self.window_size), dtype=np.int64)

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if history is None:
            return Action.C
        if state.round_number == 0:
            return Action.C
        current_cooperators = sum(history.opponent_actions[-1, :])
        self.cooperators_counts[self.cooperators_counts < current_cooperators] += 1
        cooperators_in_window = np.maximum(self.cooperators_counts - int(self.window_size / 2), 0)
        total_cooperators = sum(cooperators_in_window)
        if current_cooperators < self.game_description.m and total_cooperators >= self.game_description.m:
            self.m += 1
        elif current_cooperators >= self.game_description.m and total_cooperators <= self.game_description.m:
            self.m -= 1
        if current_cooperators < self.game_description.m:
            return Action.D
        return Action.C

class Strategy_EXPLOITATIVE_356(BaseStrategy):
    """
    A Tit-for-Tat Plus strategy for the Collective Risk Dilemma game.
    This strategy follows a tit-for-tat approach but introduces an element of surprise by deviating with small probabilities.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.p = 0.2
        self.q = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None:
            return Action.C
        opponents_cooperated = sum(history.opponent_actions[-1]) >= self.game_description.m
        strategy = Action.C
        if not opponents_cooperated:
            if state.round_number > 1 and history.my_actions[state.round_number - 2] == Action.C:
                strategy = np.random.choice([Action.D, Action.C], p=[1 - self.p, self.p])
        elif state.round_number > 1 and history.my_actions[state.round_number - 2] == Action.D:
            strategy = np.random.choice([Action.D, Action.C], p=[1 - self.q, self.q])
        return strategy

class Strategy_EXPLOITATIVE_357(BaseStrategy):
    """
    Tit-for-Tat with Threshold (TFTT) Strategy for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.n_players // game_description.m
        self.aggressive_probability = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.threshold and state.round_number < self.game_description.n_rounds - 1:
            return Action.C
        elif state.round_number > self.game_description.n_rounds // 2 and cooperators < self.threshold or random.random() <= self.aggressive_probability:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_358(BaseStrategy):
    """
    Strategy Title: Tit-for-Tat with Gradual Cooperation (TFTGC)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m_over_n = game_description.m / game_description.n_players
        self.history = PlayerHistory(None, None, np.zeros((game_description.n_players, 1)), np.zeros((1,)))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.history = history or self.history
        cooperation_rate = np.mean(self.history.my_actions[-self.game_description.n_players:])
        if cooperation_rate >= self.m_over_n:
            return Action.C
        elif cooperation_rate < self.m_over_n - 1 and cooperation_rate > self.m_over_n + 1:
            return self.history.opponent_actions[-1, -1]
        else:
            return Action.D

class Strategy_EXPLOITATIVE_359(BaseStrategy):
    """
    A strategy that implements the Tit-for-Tat with Adaptive Threshold (TFT-AT) in Collective Risk Dilemma games.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.m
        self.cooperated_last_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-1, :]) if history is not None else 0
        if cooperators >= self.threshold:
            self.cooperated_last_round = True
            return Action.C
        elif self.cooperated_last_round and self.threshold > 1:
            self.threshold -= 1
        elif self.threshold == 1:
            self.cooperated_last_round = False
        return Action.D

class Strategy_EXPLOITATIVE_360(BaseStrategy):
    """
    Adaptive Tit-for-Tat Strategy for Collective Risk Dilemma Game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.tolerance = self.game_description.n_players // 3 if self.game_description.n_players % 3 == 0 else math.ceil(self.game_description.n_players / 3) + 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_cooperators = sum(history.opponent_actions[-1, :]) if history is not None else 0
        opponent_defects = max(0, self.tolerance - opponent_cooperators)
        return Action.C if opponent_defects < self.tolerance and history.my_actions[-1] == Action.C else Action.D if opponent_defects >= self.tolerance or (opponent_cooperators > 0 and history.my_actions[-1] != Action.C) else history.opponent_actions[-1][-1]

class Strategy_EXPLOITATIVE_362(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = 0.5
        self.theta_history = [self.threshold]
        self.payoffs_history = []
        self.n_rounds = game_description.n_rounds

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        mcp = cooperators / self.game_description.n_players
        payoff = history.my_payoffs[-1] if len(history.my_payoffs) > 0 else 1
        self.theta_history.append((payoff * self.threshold + (1 - payoff) * np.mean(self.theta_history[-self.n_rounds:])) / len(self.theta_history[-self.n_rounds:]))
        self.payoffs_history.append(payoff)
        if mcp >= self.threshold:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_363(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.minimum_cooperators = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-1]) if history else 0
        if cooperators >= self.minimum_cooperators:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_364(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.window_size = int(game_description.n_rounds * 0.8)
        self.cooperation_threshold = game_description.m
        self.history_window = [(Action.D, 1) for _ in range(self.window_size)]

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        action = Action.C
        if state.round_number > self.window_size:
            cooperators = sum([h[0] for h in history.opponent_actions[-self.window_size:]])
            self.cooperation_threshold = math.ceil(sum([h[1] for h in self.history_window]) / len(self.history_window) * self.cooperation_threshold)
            if cooperators < self.cooperation_threshold:
                action = Action.D
        if state.round_number == history.opponent_actions.shape[0] if history else self.game_description.n_rounds:
            action = Action.D
        self.history_window.pop(0)
        self.history_window.append((action, 1 if action == Action.C else 0))
        return action

class Strategy_EXPLOITATIVE_365(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m - 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        opponent_history = history.opponent_actions if history else np.zeros((state.round_number + 1, self.game_description.n_players), dtype=bool)
        last_cooperative_run = np.count_nonzero(opponent_history[-self.cooperation_threshold:, :] == 1)
        if last_cooperative_run >= self.cooperation_threshold:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_367(BaseStrategy):
    """
    Tit-for-Tat-with-Adaptation (TfT-A) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperators_counter = 0
        self.rounds_played = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        self.rounds_played += 1
        cooperators = sum(history.opponent_actions[-self.rounds_played:-1, -1]) if history else 0
        self.cooperators_counter += cooperators
        cooperate_probability = (1 - self.game_description.k) * self.cooperators_counter / self.rounds_played + self.game_description.k
        coin_toss = random.uniform(0, 1)
        return Action.C if coin_toss <= cooperate_probability else Action.D

class Strategy_EXPLOITATIVE_368(BaseStrategy):
    """
    Strategy name: Tit-for-Tat-with-Adaptation (TFTA)
    Initiates cooperation on first round and adapts action based on previous round's cooperators count.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            cooperators = 0
        else:
            cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.m:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_369(BaseStrategy):
    """
    A Tit-for-Tat strategy for the Collective Risk Dilemma game.
    This strategy cooperates initially and copies its opponent's action from the previous round.
    If an opponent has been cooperating, it continues cooperation; otherwise, it defects to punish non-cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = np.zeros((1, self.game_description.n_players), dtype=bool)

    def __call__(self, state: GameState, history: PlayerHistory):
        if state.round_number == 0:
            return Action.C
        my_actions = history.my_actions
        last_opponent_action = self.opponent_history[-1, state.round_number % self.game_description.n_players]
        self.opponent_history = np.roll(self.opponent_history, -1, axis=0)
        self.opponent_history[-1, state.round_number % self.game_description.n_players] = last_opponent_action
        if my_actions[-1] == Action.C and last_opponent_action:
            return Action.C
        elif my_actions[-1] == Action.D or not last_opponent_action:
            return Action.D

class Strategy_EXPLOITATIVE_370(BaseStrategy):
    """
    A strategy implementing Tit-for-Tat with Adaptive Cooperation (TTAC).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m - 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round = history.opponent_actions[-1] if history else np.zeros(self.game_description.n_players, dtype=bool)
        cooperators = sum(previous_round)
        if cooperators >= self.m:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_371(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = self.game_description.m
        self.cooperative_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None:
            return Action.D
        cooperation_count = sum(history.opponent_actions[-1])
        if all((action == Action.C for action in history.my_actions)) or cooperation_count <= self.cooperation_threshold:
            return Action.C
        return Action.D

    def update_cooperation_threshold(self, cooperative_rounds):
        """
        Update the cooperation threshold based on the number of cooperative rounds seen so far in the game.
        """
        self.cooperative_rounds += cooperative_rounds
        self.cooperation_threshold = min(self.game_description.m, self.cooperative_rounds)

class Strategy_EXPLOITATIVE_372(BaseStrategy):
    """
    A Tit-for-Tat adaptive strategy for the Collective Risk Dilemma game.
    This strategy cooperates if a sufficient number of players cooperated in the previous round, and defects otherwise.
    It also adapts its strategy based on the observed behavior of opponents over the course of the game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = math.ceil(game_description.m * game_description.n_players / 2)
        self.recent_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-self.game_description.n_rounds:, :].flatten())
        self.recent_cooperators = max(self.recent_cooperators, cooperators)
        if cooperators < self.threshold - self.game_description.n_players:
            self.recent_cooperators = 0
        return Action.C if self.recent_cooperators >= self.threshold else Action.D

class Strategy_EXPLOITATIVE_373(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)

    A strategy that cooperates initially and adapts its cooperation threshold based on historical payoffs.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.last_reward = 0.0
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros(game_description.n_rounds))

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        self.history = history
        cooperators_in_prev_round = sum(self.history.opponent_actions[-1])
        reward_in_prev_round = 0.0 if cooperators_in_prev_round < self.game_description.m else self.game_description.k
        self.last_reward = reward_in_prev_round
        payoff = 1 if history.my_actions[-1] == Action.D else 1 + reward_in_prev_round
        self.history.my_payoffs[-1] = payoff
        if payoff > 1:
            self.cooperation_threshold -= 1 if self.cooperation_threshold - 1 >= 1 else 0
        elif payoff <= 1:
            self.cooperation_threshold += 1 if self.cooperation_threshold + 1 < self.game_description.m else self.game_description.m - 1
        return Action.C if cooperators_in_prev_round >= self.cooperation_threshold else Action.D

class Strategy_EXPLOITATIVE_374(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT)
    Strategy Description: Cooperate if more than half of players cooperated in the previous round; otherwise, defect.
                           The adaptive threshold mechanism adjusts based on past game outcomes using a sliding window approach.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.window_size = int(math.ceil(game_description.n_rounds * 0.8))
        self.cooperators_count = np.zeros(self.window_size)

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        total_players = self.game_description.n_players
        if cooperators < total_players - self.game_description.m:
            return Action.D
        payoff = 0.0
        if cooperators >= total_players - self.game_description.m:
            payoff += 1 - history.my_actions[-1]
            if cooperators >= total_players:
                payoff += self.game_description.k
        self.cooperators_count = np.roll(self.cooperators_count, -1)
        self.cooperators_count[-1] = int(cooperators >= total_players - self.game_description.m)
        return Action.C if np.mean(self.cooperators_count) > total_players - self.game_description.m else Action.D

class Strategy_EXPLOITATIVE_375(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT) Strategy for the Collective Risk Dilemma Game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = self.game_description.m
        self.last_round_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if history is not None:
            self.last_round_cooperators = sum(history.opponent_actions[-1])
            cooperators = min(self.last_round_cooperators, self.game_description.m)
            if cooperators >= self.game_description.n_players // 2:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_378(BaseStrategy):
    """
    A strategy that mimics the most common action played by opponents in the previous round,
    fostering trust and punishing defections with defecting in subsequent rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponents_actions = history.opponent_actions[-1] if history else np.zeros(self.game_description.n_players, dtype=bool)
        max_cooperators = max(opponents_actions)
        if max_cooperators >= self.m and opponents_actions.sum() >= len(opponents_actions) - (self.game_description.n_players - self.m):
            action = Action.C
        else:
            action = Action.D
        return action

class Strategy_EXPLOITATIVE_379(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATfT) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponents = [Action.C] * self.game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        current_round = history.opponent_actions[-1]
        m_cooperators = np.count_nonzero(current_round)
        if m_cooperators < self.game_description.m:
            return Action.D
        for i in range(1, self.game_description.n_players):
            if current_round[i - 1] == Action.D and history.opponent_actions[-2][i] == Action.D:
                self.opponents[i] = Action.D
        return self.opponents[int((state.round_number - 1) % len(self.opponents))]

class Strategy_EXPLOITATIVE_380(BaseStrategy):
    """
    A Tit-for-Tat with Gradual Adaptation (TfT-GA) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.first_round = True
        self.second_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        action = Action.D
        if state.round_number == 0:
            self.first_round = True
            self.second_round = False
            return Action.C
        elif self.first_round and history is not None:
            cooperators = sum(history.opponent_actions[0, :])
            if cooperators >= self.game_description.m - 1:
                self.second_round = True
        if history is not None:
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators >= self.game_description.m:
                action = Action.C
            elif self.first_round or self.second_round:
                action = Action.D
        return action

class Strategy_EXPLOITATIVE_381(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) Strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = math.ceil(game_description.m)
        self.total_reward = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1] if history else [0])
        if cooperators >= self.cooperation_threshold:
            action = Action.C
            reward = 1 - self.cooperation_threshold / self.game_description.n_players + math.ceil(self.game_description.k) * (self.cooperation_threshold / self.game_description.n_players >= self.game_description.m)
        else:
            action = Action.D
            reward = 1
        if action == Action.C:
            self.cooperation_threshold = min(self.cooperation_threshold + 1, self.game_description.n_players)
        self.total_reward += reward
        return action

class Strategy_EXPLOITATIVE_382(BaseStrategy):
    """
    A strategy that implements the Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = math.floor(game_description.n_players * 0.5)
        self.cooperated_last_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            if self.game_description.m == self.game_description.n_players - 1:
                return Action.C
            else:
                return Action.D
        if history is None:
            self.cooperated_last_round = False
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        self.cooperated_last_round = cooperators >= self.threshold
        if self.cooperated_last_round:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_384(BaseStrategy):
    """
    Tit-for-Tat strategy adapted for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m - 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :]) if history else self.game_description.n_players // 2
        return Action.C if cooperators > self.m else Action.D

class Strategy_EXPLOITATIVE_385(BaseStrategy):
    """
    The Tit-for-Tat strategy with minor modifications for Collective Risk Dilemma.
    This strategy cooperates if m or more players cooperated in the previous round, otherwise defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        action = Action.C if cooperators >= self.m else Action.D
        return action

class Strategy_EXPLOITATIVE_387(BaseStrategy):
    """
    Implementation of Tit-for-Tat with Adaptive Threshold (TFT-AT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.m_prime = self.m
        self.cooperation_rate = [0] * self.r

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        else:
            cooperation_rate = np.mean(history.opponent_actions[:state.round_number, :])
            if cooperation_rate >= self.m_prime:
                action = Action.C
            else:
                action = Action.D
        if cooperation_rate < self.m:
            self.m_prime += 1
        elif cooperation_rate > self.m:
            self.m_prime -= 1
        if state.round_number == self.r or (history is None and action == Action.D):
            action = Action.D
        elif history is not None and (state.round_number > 1 and history.my_actions[0] == Action.D):
            action = Action.D
            for i in range(1, min(state.round_number, self.r)):
                if history.my_actions[i] != action:
                    action = Action.D
                else:
                    break
        self.cooperation_rate[state.round_number - 1] = cooperation_rate
        return action

class Strategy_EXPLOITATIVE_388(BaseStrategy):
    """
    Implementation of Tit-for-Tat with Adaptive Threshold (TfT-AT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = int(math.floor(game_description.n_players * 0.5))
        self.window_size = math.ceil(game_description.n_rounds * 0.1)
        self.average_cooperators = np.zeros(self.window_size)
        self.current_round = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.current_round = (self.current_round + 1) % self.window_size
        if history is not None and self.current_round < self.window_size:
            self.average_cooperators[self.current_round] = np.mean(history.my_actions[-self.window_size:])
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.threshold or (state.round_number == self.game_description.n_rounds - 1 and np.mean(self.average_cooperators) > self.threshold):
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_389(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperative Threshold (TFT-ACT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.r_coop = 0
        self.m_i = 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.r_coop = 1
            return Action.C
        cooperation_count = 0 if history is None else history.my_actions[-1]
        if cooperation_count >= self.m_i:
            self.r_coop += 1 if cooperation_count == 1 else 0
            return Action.C
        return Action.D
        self.m_i = max(self.m_i + math.floor((self.r_coop - self.game_description.n_players) / (self.game_description.n_players - 1)), self.game_description.m)
        self.m_i = min(self.m_i, self.game_description.n)

class Strategy_EXPLOITATIVE_390(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) Strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.previous_opponent_action = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.previous_opponent_action = np.mean(history.opponent_actions[-1])
        return self.decide_action(self.previous_opponent_action)

    def decide_action(self, previous_opponent_action):
        return Action.C if previous_opponent_action == 1 else Action.D

class Strategy_EXPLOITATIVE_391(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = min(game_description.m, game_description.n_players)
        self.consecutive_defections = 0
        self.adaptation_threshold = 10

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            self.cooperation_threshold = min(self.game_description.m, self.game_description.n_players)
            self.consecutive_defections = 0
            return Action.C
        cooperation_ratio = len(np.where(history.opponent_actions[-1, :] == True)[0]) / self.game_description.n_players
        if cooperation_ratio >= self.cooperation_threshold:
            return Action.C
        elif self.consecutive_defections >= self.adaptation_threshold:
            self.cooperation_threshold += 1
            self.consecutive_defections = 0
        else:
            self.consecutive_defections += 1
        return Action.D

class Strategy_EXPLOITATIVE_392(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros((game_description.n_rounds, game_description.n_players)))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and (not history):
            return Action.C
        cooperator_count = np.sum(history.opponent_actions[-self.game_description.m:, :].sum(axis=1) >= self.game_description.m)
        if cooperator_count >= self.game_description.n_players // 2:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_394(BaseStrategy):
    """Tit-for-Tat with Adaptation (TFT-A)"""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        cooperators = sum(history.opponent_actions[-1, :])
        action = Action.C if cooperators >= self.m else Action.D
        return action

class Strategy_EXPLOITATIVE_395(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperative_threshold = game_description.m
        self.min_cooperative_threshold = game_description.m
        self.rounds_played = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and self.rounds_played > 0:
            cooperators = sum(history.opponent_actions[-1, :])
            cooperative_threshold = self.cooperative_threshold + (self.min_cooperative_threshold - self.cooperative_threshold) * ((self.rounds_played - 1) / self.game_description.n_rounds)
            if cooperators < self.cooperative_threshold:
                return Action.D
            elif cooperators >= self.game_description.n_players and state.round_number != self.game_description.n_rounds:
                return Action.D
            else:
                self.cooperative_threshold = max(self.cooperative_threshold - (self.game_description.m - cooperators) / self.game_description.n_players, self.min_cooperative_threshold)
        self.rounds_played += 1
        return Action.C

class Strategy_EXPLOITATIVE_396(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATfT) with Risk-Aversion (ARAT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = math.ceil(game_description.n_players / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        cooperators = sum(history.opponent_actions[-1, :]) if history else self.m
        if cooperators >= self.m or state.round_number == self.game_description.n_rounds:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_397(BaseStrategy):
    """
    The Optimal Defector Strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = math.ceil((game_description.m - 1) * (game_description.n_players / game_description.n_rounds))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            self.threshold = math.ceil((self.game_description.m - 1) * (self.game_description.n_players / self.game_description.n_rounds))
            return Action.C
        cooperators = sum(history.opponent_actions[-self.game_description.n_rounds:, :].sum(axis=0))
        if cooperators >= self.threshold:
            return Action.D
        return Action.C

class Strategy_EXPLOITATIVE_398(BaseStrategy):
    """
    Tit-for-Tat Adaptive Cooperation (TTFC) for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.coop_count = 0
        self.punishment_threshold = 4
        self.last_round_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        if history is not None:
            self.last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1] and self.last_round_cooperators >= self.game_description.m:
            self.coop_count += 1
            if self.coop_count - np.mod(self.coop_count, 4) + 1 >= self.punishment_threshold:
                return Action.C
        if history.my_actions[-1] and self.last_round_cooperators > self.punishment_threshold:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1 and self.coop_count >= self.punishment_threshold:
            return Action.C
        self.coop_count = max(self.coop_count - 1, 0)
        self.punishment_threshold = min(self.punishment_threshold + 1, self.game_description.n_players // 2)
        return Action.D

class Strategy_EXPLOITATIVE_399(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (ACT) for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.S = 1
        self.T = min(int(game_description.n_players / 2), game_description.n_rounds)
        self.avg_coop_rate = 0
        self.m_current = self.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or not history:
            return Action.C
        rounds = history.my_actions if history else np.zeros((1, state.round_number), dtype=bool)
        actions = rounds[-self.T:]
        avg_coop_rate = (self.avg_coop_rate * (self.T - 1) + np.mean(actions).item()) / self.T
        if avg_coop_rate > self.m_current:
            self.m_current += self.S
        elif avg_coop_rate < self.m_current:
            self.m_current -= self.S
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.m_current:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_400(BaseStrategy):
    """
    Implementation of Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.history = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None and state.round_number == 0:
            return Action.C
        if history is not None and state.round_number == len(history.opponent_actions) - 1:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.cooperation_threshold:
            self.cooperation_threshold += math.floor((self.game_description.n_players - state.round_number) / self.game_description.n_players * (self.game_description.m - self.cooperation_threshold))
        return Action.C if cooperators >= self.cooperation_threshold else Action.D

class Strategy_EXPLOITATIVE_401(BaseStrategy):
    """
    Implementation of Tit-for-Tat strategy with Adaptive Cooperation Threshold for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.recent_history = np.zeros(game_description.n_rounds)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is not None:
            self.update_recent_history(history)
        if state.round_number == 0:
            return Action.C
        if np.mean(self.recent_history >= self.cooperation_threshold) > 0.5:
            self.decrease_threshold()
        elif np.mean(self.recent_history < self.cooperation_threshold) > 0.5:
            self.increase_threshold()
        cooperators = sum(history.opponent_actions[-1, :] if history else self.recent_history >= self.cooperation_threshold)
        return Action.C if cooperators >= self.cooperation_threshold else Action.D

    def update_recent_history(self, history: PlayerHistory):
        self.recent_history = np.roll(self.recent_history, -1)
        self.recent_history[-1] = 1 if history.my_actions[-1] == Action.C else 0

    def decrease_threshold(self):
        self.cooperation_threshold = max(self.cooperation_threshold - 1, 1)

    def increase_threshold(self):
        self.cooperation_threshold = min(self.cooperation_threshold + 1, self.game_description.n_players - 1)

class Strategy_EXPLOITATIVE_403(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Gradient Adjustment (TFT-GA)

    This strategy uses the Tit-for-Tat approach with a gradient adjustment factor to cooperate or defect in each round.
    It starts by cooperating in the first round and then adapts its cooperation probability based on the average cooperation rate of the previous rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_probability = 0.5
        self.cooperation_rate_history = []
        self.gradient_factor = 0.1

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperation_rate = np.mean(history.my_actions[:state.round_number])
        self.cooperation_rate_history.append(cooperation_rate)
        if len(self.cooperation_rate_history) > self.game_description.n_rounds:
            self.cooperation_rate_history.pop(0)
        cooperation_threshold = self.game_description.m / self.game_description.n_players
        if cooperation_rate >= cooperation_threshold + self.gradient_factor or cooperation_rate <= cooperation_threshold - self.gradient_factor:
            self.cooperation_probability += 0.1 * (cooperation_rate > cooperation_threshold)
            self.cooperation_probability = max(min(self.cooperation_probability, 1), 0)
        return Action.C if random.random() < self.cooperation_probability else Action.D

class Strategy_EXPLOITATIVE_404(BaseStrategy):
    """
    Tit-for-Tat with Cooperative Adaptation (TTCA) Strategy for the Collective Risk Dilemma Game
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_opponent_action = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is not None:
            if self.last_opponent_action is None:
                self.last_opponent_action = history.opponent_actions[state.round_number - 1, :].any()
            last_opponent_cooperation = self.last_opponent_action
            cooperators = (history.opponent_actions[state.round_number - 1, :] >= last_opponent_cooperation).sum()
            if cooperators >= self.game_description.n_players // self.game_description.m:
                return Action.C
        self.last_opponent_action = None
        return Action.D

class Strategy_EXPLOITATIVE_405(BaseStrategy):
    """
    A Tit-for-Tat-Adaptive (TfT-A) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        total_cooperators = np.sum(history.my_actions[-1])
        if total_cooperators >= self.min_cooperators:
            action = Action.C
        else:
            action = Action.D
        return action

class Strategy_EXPLOITATIVE_406(BaseStrategy):
    """
    Tit-for-Tat with Gradient Adjustment (TfT-GA) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.k_adjusted = game_description.k
        self.s = int(game_description.n_rounds * 0.8)
        self.cooperation_rate_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            cooperators = 0
            for _ in range(self.s):
                cooperators += sum(history.opponent_actions[::_, :].sum(axis=1) >= self.game_description.m)
            cooperation_rate = cooperators / self.s
            if cooperation_rate > 0.5:
                self.k_adjusted += 0.01
            elif cooperation_rate < 0.5:
                self.k_adjusted -= 0.01
        current_cooperators = sum(history.opponent_actions[state.round_number - 1, :] >= self.game_description.m)
        if current_cooperators < self.game_description.n_players // self.game_description.m:
            return Action.D
        else:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1 and len(self.cooperation_rate_history) >= self.s:
            cooperation_rate = sum(self.cooperation_rate_history[-self.s:]) / self.s
            if cooperation_rate > self.game_description.m // self.game_description.n_players:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_407(BaseStrategy):
    """
    The Tit-for-Tat-with-Adaptive-K (TFTA-k) Strategy in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = [0] * game_description.n_players
        self.opponents_count = game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        cooperation_percentage = self.evaluate_cooperation(history.opponent_actions[-self.game_description.n_rounds + 1:, :])
        if cooperation_percentage >= self.game_description.m / self.opponents_count:
            return Action.C
        return Action.D

    def evaluate_cooperation(self, data: NDArray[np.bool_]) -> float:
        total_cooperators = np.sum(data)
        return total_cooperators / self.opponents_count

class Strategy_EXPLOITATIVE_408(BaseStrategy):
    """
    Tit-for-Tat Adaptive (TfTA) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.rounds_played = 0
        self.history = None
        self.last_opponent_action = Action.D
        self.initial_phase_length = 10
        self.deadlock_threshold = self.initial_phase_length // 2

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        self.history = history if self.rounds_played > self.initial_phase_length else None
        self.rounds_played += 1
        if state.round_number == 0:
            return Action.C
        opponent_cooperators = sum(history.opponent_actions[-1, :])
        current_opponent_action = history.opponent_actions[-1][-1] if self.history else None
        if self.rounds_played > self.initial_phase_length:
            if current_opponent_action is None:
                return Action.C
            if opponent_cooperators >= self.game_description.n_players // 2:
                return Action.C
            else:
                return Action.D
        elif opponent_cooperators >= (self.game_description.n_players - self.deadlock_threshold) // 2:
            return Action.C
        else:
            return Action.D
        if self.rounds_played > self.initial_phase_length + self.deadlock_threshold:
            if current_opponent_action == self.last_opponent_action:
                self.last_opponent_action = Action.C if self.last_opponent_action == Action.D else Action.D
                return self.last_opponent_action

class Strategy_EXPLOITATIVE_409(BaseStrategy):
    """
    Strategy name: Tit-for-Tat with Risk Aversion (TFTRA)
    Strategy description: Cooperates if a majority is observed or when the reward factor is high enough to minimize the risk of exploitation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.r = self.game_description.n_rounds
        self.m = self.game_description.m
        self.k = self.game_description.k
        self.t = 0.5
        self.strategy = [None] * (self.r + 1)
        self.history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            action = random.choice([Action.C, Action.D])
            self.history.append((action, [None] * len(self.strategy)))
            self.strategy[1] = action
            return action
        if history is None:
            history = PlayerHistory(np.zeros(self.r + 1, dtype=bool), np.zeros(self.r + 1), self.get_opponent_actions(), np.zeros(self.r + 1))
        else:
            self.history.append((history.my_actions[-1], history.my_payoffs[-1]))
        cooperators = sum(history.opponent_actions[-1])
        p_c = cooperators / len(self.strategy) if self.history else 0
        if state.round_number == self.r:
            return Action.C
        if p_c >= self.m / len(self.strategy):
            self.strategy[state.round_number + 1] = Action.C
            return Action.C
        if cooperators >= self.m - 1 and self.k > 1 + self.t:
            self.strategy[state.round_number + 1] = Action.C
            return Action.C
        self.strategy[state.round_number + 1] = Action.D
        return Action.D

    def get_opponent_actions(self) -> NDArray[np.bool_]:
        """
        Returns the opponents' actions from the history up to the current round (exclusive).
        """
        opponent_actions = np.zeros((state.round_number, len(self.strategy) - 1), dtype=bool)
        for i in range(len(self.history)):
            if self.history[i][0] is not None:
                opponent_actions[i, (self.history[i][0] + 1) % len(self.strategy)] = 1
        return opponent_actions

class Strategy_EXPLOITATIVE_410(BaseStrategy):
    """
    Adaptive Tit-for-Tat strategy for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_phase = False
        self.last_opponent_cooperated = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history:
            last_round = len(history.opponent_actions) - 1
            self.last_opponent_cooperated = np.argmax(history.opponent_actions[last_round])
            cooperators = np.count_nonzero(history.opponent_actions[-1, :])
            if cooperators >= self.game_description.m and self.punishment_phase:
                self.punishment_phase = False
                return Action.D
            if last_round > 0 and history.opponent_actions[last_round, self.last_opponent_cooperated] == Action.D:
                if not self.punishment_phase:
                    self.punishment_phase = True
                    return Action.D
                if cooperators >= self.game_description.m - 1 and self.punishment_phase:
                    self.punishment_phase = False
                    return Action.D
            return Action.C
        return Action.C

class Strategy_EXPLOITATIVE_412(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat Adaptive (TFT-A)
    Strategy Description: Mimic opponent's previous action, encourages cooperation but punishes betrayal. Reverts to initial cooperation if an opponent switches from cooperation to defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_opponent_action = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            self.last_opponent_action = None
            return Action.C
        self.last_opponent_action = history.opponent_actions[-1][-1]
        cooperators = sum(history.opponent_actions[-1])
        if cooperators >= self.game_description.m and self.last_opponent_action == Action.C:
            return Action.C
        elif cooperators < self.game_description.m and self.last_opponent_action == Action.D:
            return Action.D
        else:
            self.last_opponent_action = not self.last_opponent_action
            return Action.C

class Strategy_EXPLOITATIVE_413(BaseStrategy):
    """
    A Tit-for-Tat strategy with adaptive cooperation threshold for Collective Risk Dilemma games.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds // 2
        self.T = math.floor((self.m - 1) * math.sqrt(self.n))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C if self.n == 2 else Action.D
        if history is not None:
            coop_count = np.sum(history.my_actions[-self.r:])
            if coop_count < self.m - self.T or (coop_count < self.m and state.round_number == 1):
                return Action.D
            elif coop_count > self.m + self.T:
                return Action.C
            else:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_414(BaseStrategy):
    """
    A Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.history = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is not None and self.history is None:
            self.history = history
        if state.round_number == 0:
            return Action.C
        num_cooperators = sum(self.history.opponent_actions[-1, :])
        self.cooperation_threshold = self.adjust_cooperation_threshold(num_cooperators)
        return Action.C if num_cooperators >= self.cooperation_threshold else Action.D

    def adjust_cooperation_threshold(self, num_cooperators: int):
        if self.history is None or len(self.history.opponent_actions) == 1:
            return self.game_description.m
        last_round = self.history.opponent_actions[-1]
        my_last_action = self.history.my_actions[-1]
        if my_last_action and num_cooperators >= self.game_description.n - 1:
            return min(self.cooperation_threshold + 1, self.game_description.n)
        elif last_round[self.__class__] and num_cooperators >= self.game_description.m:
            return max(math.ceil(self.cooperation_threshold * 0.5), self.game_description.m)
        else:
            return self.cooperation_threshold

class Strategy_EXPLOITATIVE_415(BaseStrategy):
    """
    A Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    The strategy dynamically determines its cooperation level based on previous rounds' cooperators percentage.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.m
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros(game_description.n_rounds))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            self.history = PlayerHistory(np.ones(1), np.full(1, 1.0), np.zeros((1, self.game_description.n_players)), np.zeros(1))
            return Action.C
        else:
            cooperators = sum(history.opponent_actions[-1, :])
            self.threshold = min(max(self.threshold + (cooperators >= self.game_description.m), self.game_description.m), self.game_description.n_players - 1)
            payoff = np.mean(history.my_payoffs[-1]) if len(history.my_payoffs) > 0 else 1
            return Action.C if cooperators >= self.threshold and payoff < 2 * self.game_description.k or (cooperators < self.threshold and payoff >= self.game_description.k) else Action.D

class Strategy_EXPLOITATIVE_416(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperative Threshold (TFT-ACT) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperators_threshold = self.game_description.n_players // 2
        self.min_cooperators = game_description.m
        self.adaptation_threshold = 2 * self.min_cooperators
        self.rounds = self.game_description.n_rounds
        self.cooperation_history = np.zeros(self.rounds)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if self.rounds > 1 and cooperators >= self.cooperators_threshold and (np.sum(self.cooperation_history[:-1]) >= self.adaptation_threshold):
            return Action.D
        elif cooperators < self.min_cooperators:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_418(BaseStrategy):
    """
    A strategy that cooperates if more than half of opponents cooperated in the previous round,
    and defects otherwise, with adjustments for the first and last rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m
        self.n_players = game_description.n_players
        self.half_n_players = self.n_players // 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds or (state.round_number < self.game_description.n_rounds and history is None):
            n_cooperators = sum(history.opponent_actions[-1, :]) if history is not None else 0
            return Action.C if n_cooperators >= self.min_cooperators else Action.D
        n_cooperators = sum(history.opponent_actions[-1, :])
        return Action.C if n_cooperators >= self.half_n_players + self.min_cooperators - 1 else Action.D

class Strategy_EXPLOITATIVE_419(BaseStrategy):
    """
    Tit-for-Tat with Variable Cooperation Rate (TfTVCR) strategy for Collective Risk Dilemma.
    Adjusts cooperation based on history of other players and a variable rate parameter.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.s = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C if self.game_description.n_players >= self.game_description.m else Action.D
        cooperators = np.sum(history.opponent_actions[-1])
        if cooperators >= self.game_description.m:
            return Action.C
        elif cooperators >= self.game_description.m - self.s * self.game_description.n_players:
            return Action.C if random.random() < self.s else Action.D
        return Action.D

class Strategy_EXPLOITATIVE_421(BaseStrategy):
    """
    A Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.coop_threshold = game_description.m / game_description.n_players
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros((game_description.n_rounds, game_description.n_players)))

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        elif state.round_number == 0 and np.all(history.my_actions[-1] == 0):
            return Action.D
        else:
            current_cooperators = np.sum(history.opponent_actions[-1, :])
            threshold = max(self.coop_threshold, min(1, self.coop_threshold + (history.my_actions[-1] == 1) * (current_cooperators >= self.coop_threshold)))
            self.coop_threshold = threshold
            return Action.C if current_cooperators >= threshold else Action.D

class Strategy_EXPLOITATIVE_422(BaseStrategy):
    """
    A simple strategy that mimics the "Selfish Tit-for-Tat" strategy in the Collective Risk Dilemma game.
    Cooperates if enough opponents cooperated in the previous round, otherwise defects.
    Demonstrates good faith at the first round before retaliating against non-cooperative opponents.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[state.round_number - 1, :])
        if cooperators < self.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_423(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) Strategy for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_majority_action = Action.D
        self.current_round = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.current_round = state.round_number
        if history is None:
            opponent_actions = np.full(self.game_description.n_players - 1, self.last_majority_action)
        else:
            opponent_actions = history.opponent_actions[-1]
        cooperators = sum(opponent_actions > 0.5)
        if cooperators >= self.game_description.m and cooperators >= len(opponent_actions) // 2:
            self.last_majority_action = Action(cooperators > len(opponent_actions) // 2)
        else:
            self.last_majority_action = Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        return self.last_majority_action

class Strategy_EXPLOITATIVE_425(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) Strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.m - 1
        self.total_payoff = 0
        self.cooperation_count = 0
        self.increment = 0.05
        self.expected_payoff = self.game_description.k * (self.game_description.m - 1) + 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        round = len(history.opponent_actions) - 1
        cooperation_percentage = self.cooperation_count / round if round > 0 else 0
        if cooperation_percentage >= self.threshold:
            self.cooperate = True
        else:
            self.cooperate = False
        payoff = 1 + self.game_description.k * (self.game_description.m - self.cooperation_count) if self.cooperate else 1
        self.total_payoff += payoff
        if round >= len(history.opponent_actions) == self.game_description.n_rounds and self.total_payoff < self.expected_payoff(self.threshold):
            self.threshold += self.increment
        elif round >= len(history.opponent_actions) == self.game_description.n_rounds and self.total_payoff >= self.expected_payoff(self.threshold):
            self.threshold -= self.increment
        if self.cooperate:
            self.cooperation_count += 1
        return Action(int(self.cooperate))

    def expected_payoff(self, threshold: float) -> float:
        """
        Calculates the expected payoff for a given Threshold value.
        """
        return self.game_description.k * (self.game_description.m - threshold) + 1

class Strategy_EXPLOITATIVE_426(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation (TFT-AC)
    Inherits from BaseStrategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.majority_threshold = int((game_description.n_players + 1) * (game_description.m / 2))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = history.opponent_actions[-1] if history is not None else np.zeros(self.game_description.n_players, dtype=bool)
        cooperators = sum(current_round)
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C if cooperators >= self.majority_threshold else Action.D
        return Action.C if cooperators >= self.majority_threshold else Action.D

class Strategy_EXPLOITATIVE_427(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperators_threshold = math.floor(game_description.m / game_description.n_players)
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players - 1), dtype=bool), np.zeros(game_description.n_rounds))
        self.num_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if history is not None:
            self.history.my_actions[-1] = Action.C in history.opponent_actions[-1]
            self.history.my_payoffs[-1] = np.mean(history.opponent_payoffs[-1])
            self.num_cooperators = sum(history.opponent_actions[-1])
        if self.num_cooperators >= self.cooperators_threshold + 1:
            payoff = (self.game_description.k if self.history.my_actions[-1] else 1) + np.mean(history.opponent_payoffs[-1])
            if random.random() < (payoff - 1) / (2 * (1 - self.cooperators_threshold)) or self.cooperators_threshold == 1:
                self.cooperators_threshold += 0.1 if self.cooperators_threshold < self.game_description.n_players // self.game_description.m else max(self.cooperators_threshold - 0.1, 1)
            self.num_cooperators = sum(history.opponent_actions[-1])
        elif self.num_cooperators < self.cooperators_threshold:
            pass
        else:
            self.cooperators_threshold -= 0.1 if self.cooperators_threshold > 1 else 0
        return Action.C if self.history.my_actions[-1] or self.cooperators_threshold == 0 else Action.D

class Strategy_EXPLOITATIVE_428(BaseStrategy):
    """
    Tit-for-Tat Plus (TfT+) strategy for Collective Risk Dilemma.
    Cooperates initially and follows the Tit-for-Tat strategy in subsequent rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        return Action.C if cooperators >= self.m else Action.D

class Strategy_EXPLOITATIVE_429(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.m
        self.min_threshold = 1
        self.increase_factor = 0.01
        self.decrease_factor = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.threshold:
            self.threshold += self.increase_factor
        else:
            self.threshold = max(self.min_threshold, self.threshold * (1 - self.decrease_factor))
        return Action.C if self.threshold <= len(history.opponent_actions) >= self.threshold else Action.D

class Strategy_EXPLOITATIVE_430(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.w = math.floor(self.r * 0.9)
        self.p = 0.5
        self.cooperation_threshold = np.ceil(self.m * (self.p + 0.1))
        self.average_cooperators = [0] * self.w
        self.cooperators_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.cooperation_threshold = np.ceil(self.m * (self.p + 0.05))
            return Action.C
        if history is not None and len(history.my_actions) > self.w:
            self.average_cooperators.pop(0)
            self.average_cooperators.append(np.mean(history.my_actions[-self.w:]))
            average_cooperators = np.sum(history.my_actions[-self.w:]) / self.w
            if average_cooperators > self.n_players * self.p:
                self.cooperation_threshold += 1
                if self.cooperation_threshold > self.n_players - 1:
                    self.cooperation_threshold = self.n_players - 1
            elif average_cooperators < self.n_players * (self.p - 0.1):
                self.cooperation_threshold -= 1
                if self.cooperation_threshold < self.m:
                    self.cooperation_threshold = self.m
        cooperators_in_previous_round = np.sum(history.opponent_actions[-1, :]) if history is not None else 0
        if cooperators_in_previous_round >= self.cooperation_threshold:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_431(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATFT) for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_coopers = self.game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1] if history else [0])
        if cooperators < self.min_coopers:
            return Action.D
        elif state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        else:
            return Action.C if cooperators >= self.min_coopers else Action.D

class Strategy_EXPLOITATIVE_432(BaseStrategy):
    """
    The Tit-for-Tat-K strategy, a variant of the classic Tit-for-Tat strategy in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_opponent_action = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            self.last_opponent_action = history.opponent_actions[-1][-1]
        cooperate = self.last_opponent_action == Action.C if state.round_number > 0 else True
        return Action.C if cooperate else Action.D

class Strategy_EXPLOITATIVE_433(BaseStrategy):
    """Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)"""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.alpha = 0.7
        self.cooperation_threshold = math.ceil(game_description.m - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            cooperators = sum(history.opponent_actions[-1])
            self.cooperation_threshold = self.alpha * (self.game_description.m - cooperators) + (1 - self.alpha) * self.cooperation_threshold
        if history is not None and state.round_number < self.game_description.n_rounds:
            return Action(int(self.cooperation_threshold >= len(history.opponent_actions)))
        if history is not None and state.round_number == self.game_description.n_rounds:
            cooperators = sum(history.opponent_actions[-1])
            return Action(int(self.cooperation_threshold >= cooperators))

class Strategy_EXPLOITATIVE_434(BaseStrategy):
    """
    Strategy name: Tit-for-Tat with Risk Adjustment (TfT-RA)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.risk_threshold = game_description.k / 2
        self.risk_score = 0
        self.risk_sum = 0
        self.rounds_played = 0

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.rounds_played += 1
        opponent_cooperators = sum(history.opponent_actions[-1])
        my_payoff = history.my_payoffs[-1] if history else 1
        self.risk_score += self.game_description.k - my_payoff if opponent_cooperators >= self.game_description.m else -1
        self.risk_sum += self.risk_score
        if opponent_cooperators < self.game_description.m:
            decision = Action.D
            if self.risk_score > self.risk_threshold:
                decision = Action.C
        elif opponent_cooperators >= self.game_description.m:
            decision = Action.C
            if self.risk_score < self.risk_threshold:
                decision = Action.D
        else:
            decision = history.opponent_actions[-1][-1]
        if self.rounds_played == self.game_description.n_rounds:
            risk_average = self.risk_sum / self.rounds_played
            if risk_average > self.risk_threshold:
                decision = Action.C
            elif risk_average < self.risk_threshold:
                decision = Action.D
        return decision

class Strategy_EXPLOITATIVE_435(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.n_players // 4
        self.total_payoff_history = []
        self.average_total_payoff = None
        self.r = game_description.n_rounds // 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        action = Action.D
        if state.round_number == 0:
            action = Action(random.choices([0, 1], weights=[1 - self.cooperation_threshold, self.cooperation_threshold])[0])
        elif state.round_number < self.game_description.n_rounds:
            cooperators = sum(history.opponent_actions[-self.r:, -1])
            if cooperators >= len(history.opponent_actions) * self.cooperation_threshold:
                action = Action.C
        total_payoff = sum(history.my_payoffs[-self.r:]) if history else 0
        self.total_payoff_history.append(total_payoff)
        self.average_total_payoff = np.mean(self.total_payoff_history) if self.total_payoff_history else None
        if total_payoff > self.average_total_payoff:
            self.cooperation_threshold += 0.01
        elif total_payoff < self.average_total_payoff:
            self.cooperation_threshold -= 0.01
        return action

class Strategy_EXPLOITATIVE_437(BaseStrategy):
    """
    A Tit-for-Tat Adaptive strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_coop = self.game_description.m
        self.n_players = self.game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.D
        cooperators = sum(history.opponent_actions[-1])
        if cooperators >= self.min_coop:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_438(BaseStrategy):
    """
    A Tit-for-Tat (TFT) strategy with Adaptive Cooperation Threshold (ACT) for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.m
        self.a = 10
        self.p = 0.6
        self.total_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory):
        action = Action.D
        if state.round_number == 0:
            action = Action.C
        else:
            n_c = sum(history.opponent_actions[state.round_number - 1])
            if n_c >= self.game_description.m:
                action = Action.C
            elif self.total_cooperators / self.a >= self.p * (self.game_description.n_players - self.game_description.m):
                self.threshold += math.floor((1 - self.p) * (self.game_description.n_players - self.game_description.m))
                if action == Action.D and n_c < self.threshold:
                    action = Action.C
            elif self.total_cooperators / self.a <= (1 - self.p) * (self.game_description.m / self.game_description.n_players):
                self.threshold -= math.floor((1 - self.p) * (self.game_description.m / self.game_description.n_players))
                if action == Action.C and n_c >= self.threshold:
                    action = Action.D
        self.total_cooperators += int(action == Action.C)
        return action

class Strategy_EXPLOITATIVE_439(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat (TfT) with Adaptive Cooperative Threshold (A-TfT)
    A robust and adaptive exploitative strategy in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = np.zeros(self.game_description.n_players, dtype=np.bool_)
        self.min_cooperators = math.ceil(self.game_description.n_players * self.game_description.m / 100)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is None:
            cooperation_count = 0
        else:
            cooperation_count = sum(history.opponent_actions[:, -1].flatten())
        if cooperation_count >= self.min_cooperators and np.any(history.opponent_actions[:, -1]):
            return Action.D
        elif cooperation_count >= self.game_description.m:
            return Action.C
        streak = np.where(history.opponent_actions[-self.min_cooperators:, -1] == Action.C)[0].size
        if streak >= self.min_cooperators and cooperation_count > 0:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_440(BaseStrategy):
    """
    Tit-for-Tat with Cooperative Threshold (TTCT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :]) if history else 0
        return Action.C if cooperators >= self.min_cooperators else Action.D

class Strategy_EXPLOITATIVE_441(BaseStrategy):
    """
    A Tit-for-Tat with Cooperative Threshold (TFT-CT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.m
        self.T = 10

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if not history or state.round_number == 0:
            return Action.C
        cooperation_level = np.mean(history.opponent_actions[-self.T:])
        cooperate = cooperation_level >= self.threshold
        action = Action.C if cooperate else Action.D
        return action

class Strategy_EXPLOITATIVE_442(BaseStrategy):
    """
    A strategy that cooperates initially, then adapts to the opponent's previous action by either cooperating or defecting in subsequent rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_cooperation_threshold = math.ceil(game_description.n_players * game_description.m / 100)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None or len(history.opponent_actions) == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds:
            return Action.C
        opponent_cooperated = sum(history.opponent_actions[-1]) >= self.opponent_cooperation_threshold
        if opponent_cooperated:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_443(BaseStrategy):
    """
    A simple implementation of the Tit-for-Tat-Adaptive (TfTA) strategy.
    Cooperates if more than half of opponents cooperated in the previous round, or it's the first round.
    Defects otherwise.
    Optionally forgives defections after a certain number of rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.forgiveness_limit = 5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and len(history.opponent_actions) < self.forgiveness_limit):
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.game_description.n_players // 2:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_444(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.coop_threshold = game_description.n_players // 2
        self.window_size = int(game_description.n_players * 0.5)
        self.punishment_rounds = int(game_description.n_rounds * 0.1)

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if history is None or state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-self.window_size:, -1])
        cooperation_percentage = cooperators / self.window_size
        new_coop_threshold = (self.coop_threshold * (self.window_size - 1) + cooperation_percentage) / self.window_size
        if state.round_number < self.punishment_rounds and sum(history.my_actions[:state.round_number]) < self.game_description.m:
            return Action.D
        if cooperation_percentage >= new_coop_threshold:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_445(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperative Threshold (ACT-TFT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.h = int(math.floor(game_description.n_players * math.sqrt(game_description.n_rounds)))
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or state.round_number == self.game_description.n_rounds:
            return Action.D if history is not None else Action.C
        cooperators = np.sum(history.opponent_actions[-self.h:, :]) >= self.m
        return Action.C if cooperators else Action.D

class Strategy_EXPLOITATIVE_446(BaseStrategy):
    """
    A strategy that cooperates initially and defects only in response to defection by partners, maintaining a pattern of reciprocal cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.partner_defected = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and history.my_actions[-1]:
            self.partner_defected = False
            return Action.C
        else:
            self.partner_defected = True
            return Action.D

class Strategy_EXPLOITATIVE_447(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Defection (TFT-AD)
    The strategy responds to the opponent's previous action in each subsequent round. If the opponent cooperates, TFT-AD will also cooperate. If the opponent defects, TFT-AD will defect in the next round.
    However, TFT-AD has an added element of adaptability: if an opponent consistently defects for a set number of rounds (let's call it the "punishment window"), TFT-AD will start defecting until the opponent changes behavior.
    The length of the punishment window can be adjustable to account for different game parameters and opponent behaviors.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_window = math.ceil(game_description.n_players * 0.5) if self.game_description.n_players % 2 == 1 else math.ceil(self.game_description.n_players / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if not history:
            return Action.C
        current_round = len(history.opponent_actions) - 1
        if state.round_number == 0 or history.my_actions[current_round] == None:
            return Action.C
        opponent_cooperators = sum(history.opponent_actions[current_round])
        my_last_action = history.my_actions[current_round] if current_round > 0 else None
        punishment_window_reached = current_round - (my_last_action == Action.C) >= self.punishment_window
        if opponent_cooperators >= self.game_description.m:
            return Action.C if not punishment_window_reached or my_last_action == Action.C else Action.D
        return Action.D if not punishment_window_reached or my_last_action != Action.C else Action.D

class Strategy_EXPLOITATIVE_448(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT)
    This strategy uses a cooperative approach that adapts to the number of co-operators in previous rounds.
    It initially cooperates and then decides to cooperate or defect based on the actions of its opponents in the last few rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[max(0, state.round_number - self.game_description.n_rounds):state.round_number, :])
        last_round_cooperators = history.opponent_actions[-1].sum()
        if last_round_cooperators >= self.min_cooperators and state.round_number < self.game_description.n_rounds:
            return Action.C
        elif last_round_cooperators < self.min_cooperators - 1 and history.opponent_actions[-1][-1] == Action.D:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_449(BaseStrategy):
    """
    A strategy that mimics cooperation when conditions are favorable for collective success, but gradually reduces its probability of cooperation based on previous rounds' experiences when conditions are unfavorable.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.n_players // 2
        self.initial_coop_probability = 0.5
        self.previous_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :]) if history else self.previous_cooperators
        self.previous_cooperators = cooperators
        cooperation_probability = max(self.initial_coop_probability * (0.5 + 0.5 * cooperators / self.cooperation_threshold), self.initial_coop_probability)
        if cooperators >= self.game_description.m:
            return Action.C
        elif cooperation_probability > random.random():
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_450(BaseStrategy):
    """
    A Tit-for-Tat adaptive strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n = game_description.n_players
        self.previous_cooperators = 0
        self.p_c = 0.5
        self.rounds_played = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.rounds_played += 1
        if history is not None:
            self.previous_cooperators = sum(history.opponent_actions[-1, :])
        if self.previous_cooperators >= self.m - 1:
            return Action.C
        elif self.previous_cooperators == self.m:
            rng = random.Random()
            return Action(rng.randint(0, 100) <= int(self.p_c * 100))
        else:
            return Action.D
        if self.rounds_played == self.game_description.n_rounds:
            if self.previous_cooperators >= self.m - 1:
                return Action.C
            elif self.previous_cooperators == self.m:
                return Action.D
            else:
                return Action.D

class Strategy_EXPLOITATIVE_451(BaseStrategy):
    """
    Strategy name: Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)
    Strategy summary: Cooperate when it seems beneficial, but gradually raises its cooperation threshold if consistently receives low payoffs from cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = math.ceil(game_description.m)
        self.total_payoff = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        payoff_prev = self.get_payoff(history.opponent_actions[-1], self.cooperation_threshold)
        cooperate = self.cooperation_threshold > 1 if payoff_prev >= 1 else 0
        if cooperate == 1:
            self.total_payoff += self.game_description.k
        self.cooperation_threshold = max(self.cooperation_threshold - 1, 1) if cooperate == 0 else self.game_description.m
        return Action(cooperate)

    def get_payoff(self, opponent_actions: NDArray[np.bool_], cooperation_threshold: int):
        num_cooperators = np.sum(opponent_actions)
        payoff = (cooperation_threshold == 1) * (1 - cooperation_threshold) + (cooperation_threshold > 1) * (1 - cooperation_threshold + self.game_description.k)
        return payoff

class Strategy_EXPLOITATIVE_452(BaseStrategy):
    """
    A strategy that implements the Tit-for-Tat Plus (TfT+) strategy in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.first_round = True

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        action = Action.D
        if state.round_number == 0 and history is None:
            action = Action.C
            self.first_round = False
        elif not self.first_round:
            if history is None or len(history.my_actions) < 2:
                action = Action.C
            else:
                last_action = history.my_actions[-1]
                if last_action == Action.C:
                    action = Action.C
                elif last_action == Action.D:
                    action = Action.D
        return action

    def last_round(self, state: GameState, history: PlayerHistory) -> bool:
        """
        Check if we are in the last round based on the current game state and history.
        """
        return state.round_number == len(history.my_actions) + 1

class Strategy_EXPLOITATIVE_453(BaseStrategy):
    """
    A simple Greedy Tit-for-Tat (GTFT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_round_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        if state.round_number == self.game_description.n_rounds:
            return Action.D
        self.last_round_cooperators = sum(history.opponent_actions[-1, :])
        if self.last_round_cooperators >= self.game_description.m:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_454(BaseStrategy):
    """
    A strategy that cooperates when a majority has been cooperating but switches to defection when not enough players are cooperating.
    It starts by cooperating in the first round and adapts to opponents' behavior in subsequent rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history_length = game_description.n_rounds - 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None or len(history.my_actions) < self.history_length:
            return Action.D
        cooperation_count = np.sum(history.my_actions[-self.history_length:])
        proportion_of_cooperators = cooperation_count / self.history_length
        if proportion_of_cooperators >= self.game_description.m / self.game_description.n_players:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_455(BaseStrategy):
    """
    Implementation of the Free Rider Strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.p = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C if random.random() < self.p else Action.D
        cooperators = sum(history.opponent_actions[-1, :])
        threshold_met = cooperators >= self.game_description.m
        payoff = 1 - 1 + (self.game_description.k if threshold_met else 0)
        return Action.C if threshold_met and payoff > 1 else Action.D

class Strategy_EXPLOITATIVE_456(BaseStrategy):
    """
    The Tit-for-Tat with Adaptation (TfTA) strategy for Collective Risk Dilemma games.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_opponent_action = None
        self.is_betrayal = False

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and len(history.my_actions) < 2):
            return Action.C
        current_opponent_cooperators = sum(history.opponent_actions[state.round_number - 1, :])
        if current_opponent_cooperators >= self.game_description.m:
            return Action.C
        if self.last_opponent_action is not None and (self.is_betrayal or self.last_opponent_action != Action.D):
            self.is_betrayal = False
            return Action.D
        else:
            self.is_betrayal = history.my_actions[state.round_number - 1] == Action.C and self.last_opponent_action == Action.D
            return Action.D if self.is_betrayal else Action.C

    def update_opponent_history(self, last_opponent_action: bool):
        self.last_opponent_action = Action(1 if last_opponent_action else 0)

class Strategy_EXPLOITATIVE_457(BaseStrategy):
    """
    The Tit-for-Tat Adaptive strategy cooperates in the first round and then responds to the opponent's action from the previous round.
    If the opponent cooperated in the previous round, TfTA will also cooperate; otherwise, it will defect.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.first_round = True

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            self.first_round = True
            return Action.C
        if self.first_round:
            self.first_round = False
            return Action.C
        else:
            opponent_action = history.opponent_actions[-1, 0]
            return Action(int(opponent_action))

class Strategy_EXPLOITATIVE_459(BaseStrategy):
    """
    The Free Rider strategy is a simple yet exploitative strategy in the Collective Risk Dilemma game. It aims to cooperate when it benefits from others' cooperation while defecting whenever it can gain more by doing so.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.D
        cooperators = np.sum(history.opponent_actions[-1])
        if cooperators >= self.m:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_460(BaseStrategy):
    """
    Strategy name: Tit-for-Tat with Adaptation (TfTA)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.average_cooperators = np.zeros(self.game_description.n_rounds)
        self.punishment_duration = 0
        self.window_size = int(self.game_description.n_rounds * 0.5)
        self.m = float(self.game_description.m) / self.game_description.n_players
        self.delta = self.m - 1.0 / self.game_description.n_players

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        coop_in_window = np.sum(history.my_actions[:self.window_size])
        cooperators = history.my_actions[-1]
        if cooperators < self.m and coop_in_window < self.m - 1:
            self.punishment_duration = min(math.ceil((cooperators - self.m) / self.delta), 1) * self.game_description.n_rounds
        if state.round_number < self.punishment_duration:
            return Action.D
        elif coop_in_window >= self.m + 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_461(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation (TFT-AC) Strategy for Collective Risk Dilemma Game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = math.ceil(game_description.m / game_description.k)
        self.epsilon = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None:
            cooperators = 0
        else:
            cooperators = np.sum(history.opponent_actions[-1, :])
        if state.round_number == self.game_description.n_rounds or cooperators < self.threshold - self.epsilon:
            return Action.D
        if history is not None and np.all(history.opponent_actions[:, -1]) == self.game_description.n_players - 1:
            return Action.D
        elif cooperators > self.threshold + self.epsilon:
            return Action.C
        else:
            if random.random() < 0.5:
                action = Action.C
            else:
                action = Action.D
            return action

class Strategy_EXPLOITATIVE_462(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat (with Modifications)
    A cooperative strategy that rewards cooperation when the majority of players have previously cooperated, and punishes defection by retaliating.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m_1 = game_description.m - 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        my_action_prev = int(history.my_actions[-1])
        cooperators_prev = sum(history.opponent_actions[-1])
        if my_action_prev == 1 and cooperators_prev >= self.m_1:
            return Action.C
        return Action.D

    def last_round_payoff(self, history: PlayerHistory) -> float:
        """
        Calculate the total payoff for the last round based on the game parameters and the player's history.
        """
        cooperators = sum(history.opponent_actions[-1])
        if cooperators >= self.game_description.m:
            return (self.game_description.k - 1) * (history.my_payoffs[-1] + 1)
        return history.my_payoffs[-1]

    def total_payoff(self, history: PlayerHistory) -> float:
        """
        Calculate the total payoff for a player over the game.
        """
        payoffs = history.my_payoffs.tolist()
        payoffs.append(self.last_round_payoff(history))
        return np.sum(np.array(payoffs))

class Strategy_EXPLOITATIVE_465(BaseStrategy):
    """
    Tit-for-Tat with Adaptation (TfTA) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = math.ceil((game_description.n_players - game_description.m + 1) / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        elif state.round_number != self.game_description.n_rounds - 1:
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators >= self.threshold or history.my_actions[-1] == Action.C:
                return Action.C
            elif history.my_actions[-1] != Action.D and history.my_payoffs[-1] < 1 + self.game_description.k:
                return Action.D
        elif np.sum(history.opponent_actions[:, -1]) >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_466(BaseStrategy):
    """
    Strategy name: Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)
    A player cooperates when the cooperation ratio exceeds the adaptive threshold, encouraging cooperation and punishing non-cooperative behaviors.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n = game_description.n_players
        self.cooperation_threshold = self.m / self.n
        self.cooperators_last_m_rounds = np.zeros(self.game_description.n_rounds - 1)

    def __call__(self, state: GameState, history: PlayerHistory):
        if state.round_number == 0 or history is None:
            return Action.C
        self.cooperators_last_m_rounds = np.roll(self.cooperators_last_m_rounds, -1)
        self.cooperators_last_m_rounds[-1] += int(history.my_actions[-1])
        cooperators = np.sum(self.cooperators_last_m_rounds >= self.cooperation_threshold)
        return Action.C if cooperators >= self.m else Action.D

class Strategy_EXPLOITATIVE_467(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat with Cooperative Threshold (ATFT-CT)
    Strategy Summary: Exploits cooperation by initially withholding contributions until it detects a pattern of cooperation from others.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperative_threshold = self.game_description.m
        self.reward_factor = self.game_description.k
        self.history = PlayerHistory(np.zeros(self.game_description.n_rounds, dtype=bool), np.zeros(self.game_description.n_rounds), np.zeros((self.game_description.n_rounds, self.game_description.n_players), dtype=bool), np.zeros(self.game_description.n_rounds))

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        self.history = history
        cooperators = sum(self.history.opponent_actions[-self.cooperative_threshold:, -1])
        if cooperators >= self.cooperative_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_468(BaseStrategy):
    """
    A Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperators_threshold = self.game_description.m / self.game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-1, :])
        proportion_cooperators = cooperators / (state.round_number - 1) if state.round_number > 1 else 0
        return Action.C if proportion_cooperators >= self.cooperators_threshold else Action.D

class Strategy_EXPLOITATIVE_469(BaseStrategy):
    """
    A Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.p = 0.25

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C if random.random() < self.p else Action.D
        cooperators = np.sum(history.opponent_actions[:, -self.game_description.m:]) >= self.game_description.n_players // self.game_description.m
        return Action.C if cooperators else Action.D

class Strategy_EXPLOITATIVE_470(BaseStrategy):
    """
    Tit-for-Tat with Variable Defection Probability (TFT-VDP) Strategy for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.defection_threshold = int(game_description.n_players * 0.7)
        self.recent_cooperators = 0
        self.total_rounds = game_description.n_rounds + 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            self.recent_cooperators = 0
            return Action.D
        if state.round_number == self.total_rounds - 1:
            return Action.C
        self.recent_cooperators += np.sum(history.opponent_actions[-1])
        cooperators = history.opponent_actions[:, -1].sum()
        avg_cooperators = self.recent_cooperators / min(self.total_rounds - 1, len(history.opponent_actions))
        if cooperators < self.defection_threshold or state.round_number < int(self.total_rounds * 0.3):
            return Action.D if random.random() > 0.5 else Action.C
        else:
            return Action.C if avg_cooperators >= self.defection_threshold else Action.D

class Strategy_EXPLOITATIVE_471(BaseStrategy):
    """
    The Tit-for-Tat-Plus (TfT+) strategy for the Collective Risk Dilemma game.
    This strategy cooperates initially, and in subsequent rounds, it cooperates if its opponent cooperated in the previous round; otherwise, it defects. In the last round, it always cooperates.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_round = self.game_description.n_rounds - 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        elif state.round_number == self.last_round:
            return Action.C
        else:
            previous_action = history.opponent_actions[-1, -1] if history else Action.D
            return Action(int(previous_action) == 1)

class Strategy_EXPLOITATIVE_472(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.fraction_threshold = game_description.m / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-self.game_description.n_rounds:].sum(axis=0))
        cooperation_fraction = cooperators / (self.game_description.n_players * self.game_description.n_rounds)
        if cooperation_fraction < self.fraction_threshold:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_473(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_coop_threshold = game_description.m
        self.l = math.ceil(game_description.n_players / 2)
        self.current_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            return Action.D
        coop_count = sum(history.opponent_actions[-1, :])
        if coop_count >= self.min_coop_threshold:
            return Action.C
        if coop_count < self.min_coop_threshold and self.current_streak < self.l:
            self.current_streak += 1
            return Action.C
        else:
            self.current_streak = 0
        return Action.D

class Strategy_EXPLOITATIVE_474(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Variable Cooperation (TFTV)
    This strategy cooperates initially to build trust, then responds to opponent's actions in subsequent rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros((1,), dtype=bool), np.zeros(1), np.zeros((1, game_description.n_players), dtype=bool), np.zeros(1))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        self.history = history if history else PlayerHistory(np.zeros((state.round_number + 1,), dtype=bool), np.zeros(state.round_number + 1), np.zeros((state.round_number + 1, self.game_description.n_players), dtype=bool), np.zeros(state.round_number + 1))
        if state.round_number == 0:
            return Action.C
        else:
            opponent_action = history.opponent_actions[state.round_number - 1, 0]
            self.history.my_actions[-1] = opponent_action
            self.history.my_payoffs[-1] = 1 if not opponent_action else 1 + self.game_description.k
            return Action.C if opponent_action else Action.D

class Strategy_EXPLOITATIVE_475(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT) Strategy in Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = [None] * game_description.n_rounds

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        num_cooperators = sum(history.opponent_actions[state.round_number - 1, :])
        cooperators = np.where(history.opponent_actions[state.round_number - 1, :] == 1, 1, 0)
        if num_cooperators >= self.game_description.m:
            return Action.C
        elif len(cooperators) < self.game_description.n_players // self.game_description.m:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_477(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.rounds_history = np.zeros((self.game_description.n_rounds,), dtype=np.int8)
        self.window_size = math.ceil(self.game_description.n_rounds * 0.25)

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-self.window_size:, :])
        cooperators_count = cooperators.sum()
        if cooperators_count >= self.m and cooperators_count / self.window_size >= self.m / 2:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_478(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) with Risk-Aversion strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.k = self.game_description.k
        self.m = self.game_description.m

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1])
        total_players = len(history.opponent_actions[0])
        if cooperators >= self.m and cooperators / total_players >= 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_479(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_ratio_window = [0] * 3
        self.cooperation_count = 0

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0 and history is None:
            cooperation_probability = self.game_description.m / (self.game_description.n_players + 1)
            return Action(random.choice([0, 1]) == 1 if random.random() < cooperation_probability else 0)
        action = None
        if history is not None:
            cooperation_count = sum(history.my_actions[:state.round_number])
            self.cooperation_count = cooperation_count
            self.cooperation_ratio_window[-1] = cooperation_count / len(self.cooperation_ratio_window)
            if math.isclose(self.cooperation_ratio_window[0], 0):
                self.cooperation_ratio_window[0] = 0
            action = int(self.cooperation_ratio_window[-1] > self.game_description.m / self.game_description.n_players)
        return Action(action) if state.round_number != self.game_description.n_rounds else Action(action == 1 or self.cooperation_ratio_window[-1] >= self.game_description.m / self.game_description.n_players)

class Strategy_EXPLOITATIVE_480(BaseStrategy):
    """
    A strategy based on the Tit-for-Tat game theory concept, with an adaptation to cooperate in the last round when the minimum threshold of cooperation is likely to be met.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m - 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None:
            return Action.D
        cooperators = sum(history.opponent_actions[-1, :])
        for i in range(1, state.round_number):
            if history.opponent_actions[i - 1, :][self.m] >= self.m:
                if history.opponent_actions[i, :][0] == Action.C:
                    return Action.C
            elif history.opponent_actions[i, :][0] == Action.D:
                return Action.D
        if state.round_number == self.game_description.n_rounds and cooperators > self.m:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_481(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATFT)
    This strategy employs a reciprocal and adaptable approach in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.p = math.ceil(game_description.n_players / 2)
        self.q = int(game_description.n_players * 0.8)
        self.last_cooperation_opponent = -1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None:
            return Action.D
        opponent_cooperated = np.any(history.opponent_actions[-1])
        my_last_action = history.my_actions[-1]
        if opponent_cooperated and my_last_action:
            return Action.C
        elif not opponent_cooperated and my_last_action:
            if state.round_number - self.last_cooperation_opponent > self.p:
                self.last_cooperation_opponent = state.round_number
                return Action.C
            elif state.round_number < self.game_description.n_rounds and state.round_number - self.last_cooperation_opponent > self.q:
                return Action.D
        return Action.D

    def last_round(self) -> bool:
        return self.game_description.n_rounds == self.state.round_number

class Strategy_EXPLOITATIVE_482(BaseStrategy):
    """
    A Tit-for-Tat Adaptive (TfTA) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.forgiveness_period = math.ceil(self.game_description.n_players / 2)
        self.cooperation_count = 0
        self.opponent_defection_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        action = Action.D
        if history is not None:
            most_recent_round = len(history.opponent_actions) - 1
            if most_recent_round >= self.forgiveness_period:
                opponent_cooperators = sum(history.opponent_actions[most_recent_round])
                if opponent_cooperators > self.game_description.m - 1:
                    action = Action.C
                else:
                    self.opponent_defection_count += 1
                    if self.opponent_defection_count >= self.game_description.n_players - self.game_description.m + 1:
                        self.cooperation_count = 0
                        self.opponent_defection_count = 0
            elif random.random() < 0.5:
                action = Action.C
        return action

class Strategy_EXPLOITATIVE_483(BaseStrategy):
    """
    The Tit-for-Tat with Adaptive Defection (TfTAD) strategy.
    This strategy follows a cooperative approach initially, punishes defectors and cooperates again in the last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.current_opponent_action = None
        self.first_round = True

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            self.first_round = True
            return Action.C
        if self.first_round:
            self.current_opponent_action = history.opponent_actions[state.round_number - 1, :].any()
            self.first_round = False
        cooperators = sum(history.opponent_actions[state.round_number - 1, :])
        if cooperators >= self.game_description.n_players // 2 and self.current_opponent_action:
            return Action.C
        elif cooperators >= self.game_description.n_players // 2 and (not self.current_opponent_action):
            return Action.D
        elif self.current_opponent_action:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_485(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)

    In each round, the TFT-ACT strategy makes a decision to cooperate or defect based on the number of cooperators in the previous round and the minimum cooperation threshold (m).
    The cooperation probability (cp) gradually increases or decreases based on the current round (t) and the total number of rounds (r).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_probability = 0.5
        self.last_round_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            self.last_round_cooperators = sum(history.opponent_actions[-1, :])
        cooperate = random.random() <= self.cooperation_probability
        if self.last_round_cooperators >= self.game_description.m:
            cooperate = True
        elif state.round_number < math.ceil(self.game_description.n_rounds / 2):
            self.cooperation_probability += (self.game_description.m - self.last_round_cooperators) / self.game_description.n_rounds * 0.1
        elif state.round_number > math.ceil(self.game_description.n_rounds / 2):
            self.cooperation_probability -= (self.last_round_cooperators - self.game_description.m + 1) / self.game_description.n_rounds * 0.1
        return Action(int(cooperate)) if cooperate else Action.D

class Strategy_EXPLOITATIVE_486(BaseStrategy):
    """
    A Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperative_threshold = math.ceil(game_description.m)
        self.period_of_distrust = 0
        self.rounds_played = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.rounds_played += 1
        if history is not None:
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators >= self.cooperative_threshold:
                self.cooperative_threshold = min(self.game_description.n_players, math.ceil(self.rounds_played / self.game_description.n_rounds * (self.game_description.n_players + 1)))
            elif len(history.opponent_actions) > self.period_of_distrust and all([action == Action.D for action in history.opponent_actions[-self.period_of_distrust - 1, :]]):
                self.period_of_distrust = 0
            else:
                self.period_of_distrust += 1
        if state.round_number == self.game_description.n_rounds - 1:
            cooperators = sum(history.opponent_actions[-1, :]) if history is not None else 0
            return Action.C if cooperators >= self.cooperative_threshold else Action.D
        return Action.D if cooperators < self.cooperative_threshold else Action.C

class Strategy_EXPLOITATIVE_487(BaseStrategy):
    """
    Implementation of the Tit-for-Tat-with-Adaptation (TfTA) strategy in Collective Risk Dilemma games.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = PlayerHistory(my_actions=np.zeros(game_description.n_players), my_payoffs=np.zeros(game_description.n_rounds), opponent_actions=np.zeros((game_description.n_rounds, game_description.n_players)), opponent_payoffs=np.zeros((game_description.n_rounds, game_description.n_players)))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.opponent_history = PlayerHistory(my_actions=np.zeros(self.game_description.n_players), my_payoffs=np.zeros(self.game_description.n_rounds), opponent_actions=np.zeros((self.game_description.n_rounds, self.game_description.n_players)), opponent_payoffs=np.zeros((self.game_description.n_rounds, self.game_description.n_players)))
            return Action.C if state.round_number == 0 else self.decideAction(self.opponent_history)
        self.opponent_history = history
        if state.round_number == len(self.opponent_history.my_actions):
            if sum(self.opponent_history.my_actions[-self.game_description.n_players:]) >= self.game_description.m:
                return Action.C
            return Action.D
        return self.decideAction(self.opponent_history)

    def decideAction(self, history: PlayerHistory) -> Action:
        current_action = Action.C if history.my_actions[-1] else Action.D
        history.my_actions[-1] = current_action
        history.my_payoffs[-1] = payoff(current_action, history.opponent_actions[-1], self.game_description)
        return current_action

class Strategy_EXPLOITATIVE_488(BaseStrategy):
    """
    A Tit-for-Tat with Adaptive Cooperation Threshold strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.n_players // 2
        self.alpha = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :]) if history else 0
        if cooperators >= self.cooperation_threshold:
            return Action.C
        return Action.D

    def update_cooperation_threshold(self, cooperators: int) -> None:
        total_players = self.game_description.n_players
        cooperation_percentage = cooperators / total_players
        self.cooperation_threshold = (1 - self.alpha) * self.cooperation_threshold + self.alpha * cooperation_percentage

class Strategy_EXPLOITATIVE_489(BaseStrategy):
    """
    Implementation of Tit-for-Tat-Adaptive (TfTA) game theory strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.past_actions = []

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or len(self.past_actions) == 0:
            return Action.C
        opponent = self.past_actions[-1] if len(self.past_actions) > 0 else None
        if opponent is None or all([opponent[t] == Action.D for t in range(1, state.round_number)]):
            return Action.D
        elif any([opponent[t] == Action.D for t in range(1, state.round_number)]):
            return Action.D
        else:
            return Action.C

    def update_history(self, history: PlayerHistory) -> None:
        self.past_actions.append(np.array([action[0] for action in history.opponent_actions[:-1]]))

class Strategy_EXPLOITATIVE_490(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = self.game_description.m
        self.n_players = self.game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-1, :])
        if cooperators >= self.min_cooperators:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_491(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) Strategy in Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = 1

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if history is None or state.round_number == 0:
            return Action.C
        cooperation_level = sum(history.opponent_actions[-1])
        if cooperation_level >= self.game_description.m and self.threshold < self.game_description.n_players:
            self.threshold += 1
            return Action.C
        elif self.threshold >= self.game_description.n_players and cooperation_level >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_492(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = self.game_description.m
        self.k = self.game_description.k
        self.window_size = math.ceil(self.game_description.n_rounds * 0.1)
        self.cooperation_threshold_history = np.zeros(int(self.window_size))
        self.rounds_in_window = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        cooperators = sum(history.opponent_actions[-self.rounds_in_window:, -1]) if self.rounds_in_window > 0 else 0
        n_c = min(cooperators, self.n_players)
        if n_c >= self.m:
            return Action.C
        return Action.D

    def update_history(self, history: PlayerHistory):
        self.cooperation_threshold_history[self.rounds_in_window] = len(history.opponent_actions) - np.count_nonzero(history.opponent_actions[-1]) if self.rounds_in_window < self.window_size else self.cooperation_threshold_history[(self.rounds_in_window - 1) % self.window_size]
        self.rounds_in_window = (self.rounds_in_window + 1) % self.window_size
        if len(self.cooperation_threshold_history) > self.window_size:
            self.cooperation_threshold_history[:-1]
        average_cooperators = np.mean(self.cooperation_threshold_history)
        new_m = int(math.floor((self.n_players - 1) * (average_cooperators / self.n_players))) + 1
        self.m = min(max(new_m, self.game_description.m), self.game_description.n_players - 1)

class Strategy_EXPLOITATIVE_494(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATfT) with Cooperation Threshold Strategy for the Collective Risk Dilemma game.
    The strategy cooperates when a majority of opponents cooperate and defects otherwise, gradually adjusting the cooperation threshold based on the number of rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = min(int(self.game_description.n_players * 0.2), self.game_description.m)
        self.round_index = math.floor(self.game_description.n_rounds / (10 * self.game_description.n_players))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_cooperators = sum(history.opponent_actions[-1] if history else np.zeros(self.game_description.n_players, dtype=bool))
        cooperate = opponent_cooperators >= self.cooperation_threshold
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        elif cooperate and self.round_index > self.game_description.n_players:
            self.cooperation_threshold += math.ceil((self.game_description.m - self.cooperation_threshold) / (self.game_description.n_rounds - self.round_index))
        elif not cooperate and self.round_index < self.game_description.n_players:
            self.cooperation_threshold -= math.floor((self.cooperation_threshold - 1) / (self.round_index + 1))
        return Action(int(cooperate)) if cooperate else Action.D

class Strategy_EXPLOITATIVE_495(BaseStrategy):
    """
    Implementation of the Tit-for-Tat strategy for the Collective Risk Dilemma game.
    Strategy cooperates in the first round and punishes non-cooperative behavior in subsequent rounds while encouraging cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m - 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-1])
        if cooperators >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_496(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATfT)
    A simple strategy where players start by cooperating but then adopt a tit-for-tat approach, copying the behavior of other players in each round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_round_action = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        """
        Determines the action to take based on the current game state and previous rounds' history.
        """
        if state.round_number == 0:
            return Action.C
        if self.last_round_action is None:
            self.last_round_action = history.opponent_actions[-1].sum() > self.game_description.n_players - 1
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if last_round_cooperators >= self.game_description.m and (not self.last_round_action or last_round_cooperators == self.game_description.n_players - 1):
            return Action.C
        else:
            self.last_round_action = last_round_cooperators < self.game_description.m
            return Action.D

class Strategy_EXPLOITATIVE_497(BaseStrategy):
    """
    Tit-for-Tat (TFT) with Adaptive Cooperation Threshold (AC-TFT) Strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = math.ceil(game_description.m / 2)
        self.delta = 1.0 / (2 * game_description.n_players)
        self.ct_reset = game_description.m

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        if history:
            num_coop = sum(history.my_actions[-self.game_description.n_rounds:])
            self.cooperation_threshold = min(max(self.ct_reset, self.cooperation_threshold), self.game_description.n_players)
        if num_coop < self.cooperation_threshold:
            self.cooperation_threshold += self.delta
            return Action.D
        else:
            self.cooperation_threshold -= self.delta
            return Action.C

class Strategy_EXPLOITATIVE_498(BaseStrategy):
    """
    A Tit-for-Tat with Adaptation strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_action_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not self.opponent_action_history:
            self.opponent_action_history.append(Action.C)
        opponent_last_move = self.opponent_action_history[-1]
        self.opponent_action_history.append(opponent_last_move)
        if opponent_last_move == Action.C:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_499(BaseStrategy):
    """
    The Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.d = int(game_description.n_players * 0.5)
        self.total_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and state.round_number > 0:
            cooperators = sum(history.opponent_actions[-1])
            self.total_defections += max(0, len(history.opponent_actions) - cooperators - 1)
            if cooperators >= self.m and self.total_defections < self.d:
                return Action.C
            else:
                return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_500(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma games.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.t = game_description.n_players // 2 if game_description.n_players % 2 == 0 else math.ceil(game_description.n_players / 2)
        self.s = self.t // 2
        self.threshold = self.t

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        if history is not None and len(history.opponent_actions) > self.threshold:
            cooperators = np.mean(history.opponent_actions[-self.t:, -1])
            if cooperators >= self.game_description.m / self.game_description.n_players:
                return Action.C
        elif state.round_number > state.round_number - self.s and np.mean(history.opponent_actions[-self.s:-1, -1]) < (self.game_description.m - 1) / self.game_description.n_players:
            self.threshold = min(self.t, self.s)
        return Action.D

class Strategy_EXPLOITATIVE_501(BaseStrategy):
    """
    The Tit-for-Tat Plus (TFT+) strategy in the Collective Risk Dilemma game.
    TFT+ cooperates initially, but defects if an opponent has ever defected, and returns to cooperating unless the opponent continues to defect repeatedly.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = int(math.ceil(game_description.n_players * 0.5))
        self.numberOfDefects = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            last_round = len(history.opponent_actions) - 1
            last_action = history.opponent_actions[last_round, -1]
            if last_action:
                self.numberOfDefects += 1
                if self.numberOfDefects > self.threshold:
                    return Action.D
                else:
                    return Action.D if last_round >= self.numberOfDefects - 1 else Action.C
            else:
                self.numberOfDefects = 0
        return Action.C

class Strategy_EXPLOITATIVE_502(BaseStrategy):
    """
    A strategy that follows Tit-for-Tat with an adaptive cooperation threshold.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.alpha = 0.1
        self.n_threshold = int(game_description.n_players * 0.75)
        self.state = None
        self.history = None
        self.cooperation_count = 0
        self.rounds = 0

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        self.state = state
        self.history = history
        self.rounds += 1
        if self.state.round_number == 0 and self.history is None:
            return Action.C
        if self.history is not None:
            self.cooperation_count = np.mean(self.history.my_actions[max(0, self.rounds - 3):self.rounds])
        if self.state.round_number == self.game_description.n_rounds or (self.cooperation_count < self.game_description.m / self.alpha and self.rounds >= self.n_threshold):
            return Action.D
        elif self.cooperation_count >= (self.game_description.m + self.alpha) / self.rounds:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_503(BaseStrategy):
    """
    A strategy that implements the Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT) in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_coop_t = np.zeros(game_description.n_rounds)
        self.ct = int((game_description.m + 1) / 2)
        self.increment = math.floor((game_description.n_players - game_description.m) / 3)
        self.decrement = math.ceil(self.increment / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            self.n_coop_t = np.convolve(history.my_actions[-self.game_description.n_rounds:], [1] * self.game_description.n_rounds, mode='valid') / self.game_description.n_rounds
            if self.n_coop_t[-1] >= self.ct:
                return Action.C
        return Action.D

    def update(self, payoff: float):
        if payoff == 1 - self.game_description.k:
            if self.ct > self.game_description.m:
                self.ct -= self.decrement
            elif np.all(self.n_coop_t >= self.game_description.m / 2):
                self.ct += self.increment

class Strategy_EXPLOITATIVE_504(BaseStrategy):
    """
    Tit-for-Tat with Risk Aversion (TfTA-RA) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.own_past_cooperation_streak = 0
        self.m = self.game_description.m
        self.k = self.game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        elif state.round_number == 0 and len(history) > 0:
            self.own_past_cooperation_streak = np.sum(history.my_actions[-1])
            cooperative_streak = np.where(history.my_actions[::-1][self.m - 1:] == 1, 1, 0).sum()
            return Action(cooperative_streak > 0 or self.own_past_cooperation_streak > 0)
        else:
            cooperators = np.sum(history.opponent_actions[state.round_number - 1])
            if cooperators < self.m:
                self.own_past_cooperation_streak = np.where(history.my_actions[-self.m:] == 1, 1, 0).sum()
            return Action(self.own_past_cooperation_streak > 0)

class Strategy_EXPLOITATIVE_505(BaseStrategy):
    """
    Implementation of the Tit-for-Tat-Adaptive (TfTA) strategy for the Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = np.zeros(game_description.n_rounds - 1, dtype=bool)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        else:
            last_round = state.round_number - 1
            self.opponent_history[last_round] = history.opponent_actions[last_round, 0]
            return Action(self.opponent_history[last_round]) if self.opponent_history[-1] else Action.C

class Strategy_EXPLOITATIVE_506(BaseStrategy):
    """
    Implementation of the Adaptive Tit-for-Tat strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_round = -1
        self.end_threshold = math.ceil(game_description.n_rounds * 0.9)
        self.opponent_cooperation = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            self._update_history(history)
        if state.round_number == self.last_round + 1:
            if state.round_number >= self.end_threshold:
                return Action.C
            elif self.opponent_cooperation:
                return Action.C
            else:
                return Action.D
        else:
            self.last_round = state.round_number - 1
            self.opponent_cooperation = False if history is None else sum(history.opponent_actions[-2, :]) >= int(self.game_description.n_players / 2)
        return Action.D

    def _update_history(self, history: PlayerHistory):
        self.last_round = history.my_payoffs.size - 1
        self.opponent_cooperation = sum(history.opponent_actions[-1, :]) >= int(self.game_description.n_players / 2)

class Strategy_EXPLOITATIVE_507(BaseStrategy):
    """
    Tit-for-Tat with a twist (TFT-X) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m
        self.k = self.game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if not history:
            return Action.D
        last_round = len(history.opponent_actions) - 1
        cooperators = sum(history.opponent_actions[last_round, :])
        my_action = history.my_actions[last_round] if last_round > 0 else None
        if cooperators < self.m:
            return Action.D
        elif cooperators >= self.m and my_action is not True:
            return Action.C
        elif cooperators == self.m and (my_action is None or my_action):
            return Action.C
        elif my_action is not None:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_509(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperative Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.high_threshold = 0.85
        self.reduction_factor = 0.98
        self.increase_factor = 1.02
        self.round_number = 0
        self.history = None

    def __call__(self, state: GameState, history: PlayerHistory):
        if state.round_number == 0:
            return Action.C
        if not self.history:
            self.history = history
            return Action.C
        cooperators = np.sum(self.history.opponent_actions[-1])
        total_players = self.game_description.n_players
        threshold = min(self.high_threshold * self.reduction_factor ** self.round_number, 100)
        if cooperators / total_players >= threshold / 100:
            return Action.C
        return Action.D

    def update_history(self, new_state: GameState, new_history: PlayerHistory):
        self.round_number = new_state.round_number + 1
        self.history = new_history

class Strategy_EXPLOITATIVE_510(BaseStrategy):
    """
    Tit-for-Tat with Adaptation (TfT-A) strategy implementation for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_cooperated_last_round = False
        self.current_round = -1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if not history:
            return Action.C
        self.current_round = state.round_number - 1
        if self.current_round == 0:
            self.opponent_cooperated_last_round = False
            return Action.C
        if self.current_round == state.round_number - 1:
            return Action.C
        self.opponent_cooperated_last_round = history.opponent_actions[self.current_round][-1]
        if self.opponent_cooperated_last_round:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_1(BaseStrategy):
    """
    A simple strategy that mirrors opponents' actions using the Tit-for-Tat approach.
    This version adapts to the Collective Risk Dilemma with a minimum cooperators threshold (m).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_actions_history = []

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or len(self.opponent_actions_history) == 0:
            return Action.C
        self.opponent_actions_history.append(np.mean(history.opponent_actions[-1], axis=0) > (self.game_description.n_players - self.game_description.m) / 2)
        opponent_cooperated = self.opponent_actions_history[-1]
        return Action(int(opponent_cooperated == history.my_actions[0]))

class Strategy_COLLECTIVE_2(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Threshold strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.adaptive_threshold = self.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            cooperators_in_initial_round = random.randint(self.m, self.n_players)
            if cooperators_in_initial_round >= self.m:
                return Action.C
            else:
                return Action.D
        elif state.round_number == self.game_description.n_rounds - 1:
            cooperators = np.sum(history.opponent_actions[-self.game_description.n_rounds // 2:-1])
            if cooperators / (self.n_players * (self.game_description.n_rounds // 2)) > (self.m + 1) / 2:
                self.adaptive_threshold += 1
            elif cooperators / (self.n_players * (self.game_description.n_rounds // 2)) < (self.m - 1) / 2:
                self.adaptive_threshold -= 1
        else:
            cooperators = np.sum(history.opponent_actions[-self.game_description.n_rounds // 2:-1])
            if cooperators >= self.adaptive_threshold:
                return Action.C
            else:
                return Action.D
        return Action.C if cooperators >= self.adaptive_threshold else Action.D

class Strategy_COLLECTIVE_4(BaseStrategy):
    """
    A simple tit-for-tat adaptive strategy for the Collective Risk Dilemma game.
    The strategy aims to balance cooperation and punishment while being adaptive and robust to a wide range of opponent behaviors.
    It encourages long-term relationships with opponents, promoting collective success in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(my_actions=np.zeros((1,), dtype=bool), my_payoffs=np.zeros((1,)), opponent_actions=np.zeros((1, self.game_description.n_players), dtype=bool), opponent_payoffs=np.zeros((1, self.game_description.n_players)))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            history = self.history
            self.history.my_actions[0] = True
        if state.round_number == 0 or len(history.opponent_actions) == 1:
            return Action.C
        opponent_cooperators = sum(history.opponent_actions[-1, :])
        if opponent_cooperators >= self.game_description.n_players // 2:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_5(BaseStrategy):
    """
    Adaptive Tit-for-Tat Strategy for the Collective Risk Dilemma Game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self._opponent_cooperates_last_round = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        else:
            cooperate = self._opponent_cooperates_last_round is not None and self._opponent_cooperates_last_round == True
            if cooperate and history.opponent_actions[-1, 0] != Action.C:
                cooperate = False
            elif not cooperate and history.opponent_actions[-1, 0] == Action.D:
                cooperate = True
            self._opponent_cooperates_last_round = history.opponent_actions[-1, 0]
            return Action(int(cooperate))

class Strategy_COLLECTIVE_8(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat Adaptive (TfTA)
    Strategy Type: Collective Risk Dilemma

    A strategy that cooperates when others do and defects only when necessary to ensure fair contributions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.X = math.floor(game_description.n_rounds / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        num_coop_prev = sum(history.my_actions[-self.X:] if len(history.my_actions) >= self.X else history.my_actions)
        avg_num_coop = num_coop_prev / (self.X if len(history.my_actions) >= self.X else len(history.my_actions))
        if state.round_number == 1:
            return Action.C
        elif num_coop_prev >= self.game_description.m or (avg_num_coop < self.game_description.m and avg_num_coop <= num_coop_prev - 1):
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_15(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat-Adaptive (TfTA)
    Strategy Summary: Balances trust and punishment, promoting collective cooperation while being adaptive and robust to a wide range of opponent behaviors.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = math.ceil(game_description.m / game_description.n_players * game_description.n_rounds)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number < self.game_description.n_rounds:
            cooperation_count = sum(history.opponent_actions[state.round_number - 1, :])
            return Action(cooperation_count >= self.threshold)
        else:
            return Action.C

class Strategy_COLLECTIVE_38(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptation (TfTA)

    This strategy cooperates in the first round and subsequently mimics other players' actions based on a majority vote
    of the last s rounds, where s is a parameter that can be adjusted. The strategy maintains a history of past cooperative actions by other players.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history_length = math.ceil(2 * self.game_description.n_players)
        self.history = np.zeros((self.history_length,), dtype=np.bool_)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self._update_history(history)
        s = max(1, math.floor((self.game_description.n_players - 1) / 2))
        cooperators = sum(self.history[-s:]) - (self.game_description.n_players - self.game_description.m)
        defectors = self.game_description.n_players - sum(self.history[-s:]) + self.game_description.m
        if cooperators > defectors:
            return Action.C
        elif defectors > cooperators:
            return Action.D
        else:
            return self.history[0]

    def _update_history(self, history: PlayerHistory):
        if len(self.history) < self.game_description.n_rounds + 1:
            action = [0] * (self.game_description.n_rounds - len(self.history) + 1)
            for round_num in range(len(action)):
                action[round_num] = history.opponent_actions[round_num, 0] if round_num == 0 else action[round_num - 1]
            self.history = np.concatenate((self.history, np.array(action)))
        else:
            for round_num in range(len(history.opponent_actions)):
                self.history[-len(history.opponent_actions) - 1 + round_num] = history.opponent_actions[round_num, 0]

class Strategy_COLLECTIVE_39(BaseStrategy):
    """
    A strategy that mimics the Adaptive Tit-for-Tat approach in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.F = 5
        self.escalation_threshold = math.ceil(game_description.n_players / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        current_cooperators = sum(history.opponent_actions[-1, :])
        if current_cooperators < self.game_description.m:
            last_player = state.round_number - 1 if history is not None else None
            last_action = Action.D if history is not None and last_player is not None and (history.opponent_actions[last_player, -1] == Action.D) else Action.C
            if last_action == Action.C:
                return Action.C
            elif last_player is not None and history.my_index == last_player and (last_action == Action.D):
                if state.round_number - self.escalation_threshold >= history.my_actions.size:
                    return Action.C
            elif last_player is not None and history.my_index != last_player and (last_action == Action.D):
                return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_57(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATFT) for Collective Risk Dilemma

    Summary: Cooperate initially, then copy the action of the player who cooperated the most in the previous round. If no players cooperated, defect and cooperate next round to encourage future cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_round_cooperators = np.zeros(game_description.n_players)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None:
            self.last_round_cooperators = np.zeros(history.n_players)
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        most_cooperative_player = np.argmax(history.opponent_actions[-1]) if any(history.opponent_actions[-1]) else -1
        self.last_round_cooperators[:] = [cooperators if j == most_cooperative_player else 0 for j in range(self.game_description.n_players)]
        return Action.C if any(self.last_round_cooperators) else Action.D

class Strategy_COLLECTIVE_68(BaseStrategy):
    """
    A Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy player for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cumulative_coop = 0
        self.history = [Action.C]
        self.punishment_phase = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            self.history = list(self.history[-self.game_description.m:]) + [Action.D] * (self.punishment_phase if self.punishment_phase < len(self.history) else 0)
            cooperators = sum([action == Action.C for action in self.history[-self.game_description.m:]])
            self.cumulative_coop = cooperators
            self.punishment_phase = min(len(self.history), self.punishment_phase + 1) if cooperators < self.game_description.n_players // self.game_description.m else 0
        if state.round_number == state.round_number - self.punishment_phase:
            if self.cumulative_coop >= self.game_description.n_players // self.game_description.m:
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_73(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat Adaptive Cooperation (TFTAC)
    Summary: A strategy that cooperates in the first round and then mimics opponents' actions from the previous round, with adaptations to foster long-term cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history_len = self.game_description.n_players * self.game_description.n_rounds // 20 if self.game_description.n_players % 2 == 0 else math.ceil(self.game_description.n_players * self.game_description.n_rounds // 20)
        self.last_20_percent = self.history_len

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        actions = np.zeros(self.last_20_percent, dtype=int)
        if history is not None and state.round_number >= self.history_len:
            actions = history.opponent_actions[-self.last_20_percent:]
        if np.count_nonzero(actions > 0) < self.game_description.n_players - self.game_description.m + 1:
            return Action.C
        cooperators = np.count_nonzero(history.opponent_actions[-1]) if history is not None else 0
        last_two_cooperations = history.opponent_actions[-2:] if history is not None and state.round_number >= self.history_len else [0, 0]
        if cooperators >= self.game_description.m or np.count_nonzero(last_two_cooperations) == 2:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_87(BaseStrategy):
    """
    Tit-for-Tat Adaptive Cooperation (TTAC) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.forgiveness_window = math.ceil(game_description.n_players / 2)
        self.average_forgiveness_window = self.forgiveness_window
        self.p = 0.2
        self.memory = {}
        self.history = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        action = Action.D
        if history is not None:
            opponent_actions = history.opponent_actions[-1] if self.history is None else np.concatenate((self.history.opponent_actions, opponent_actions), axis=0)
            average_consecutive_defections = np.mean(np.where(opponent_actions == 0, 1, 0))
            if average_consecutive_defections > self.average_forgiveness_window:
                self.adjust_average_forgiveness_window()
            self.update_memory(state.round_number - 1, opponent_actions[-1])
            if self.history is None or len(self.memory) < self.game_description.n_players:
                cooperators = np.sum(opponent_actions == 1)
                if cooperators >= self.game_description.m:
                    action = Action.C
            else:
                for player in range(self.game_description.n_players):
                    consecutive_defections = sum(self.memory[player][-self.forgiveness_window:])
                    if consecutive_defections > self.forgiveness_window:
                        self.adjust_forgiveness_window()
                average_consecutive_defections = np.mean([np.sum(self.memory[player][-self.forgiveness_window:]) for player in range(self.game_description.n_players)])
                if average_consecutive_defections > self.average_forgiveness_window:
                    self.adjust_average_forgiveness_window()
                if np.random.uniform() < self.p and opponent_actions[-1] == Action.D:
                    action = Action.C
        return action

    def update_memory(self, round_number: int, opponent_action: bool) -> None:
        if round_number not in self.memory:
            self.memory[round_number] = np.zeros(self.game_description.n_players, dtype=bool)
        self.memory[round_number][-1] = opponent_action

    def adjust_forgiveness_window(self) -> None:
        if self.forgiveness_window > 1:
            self.forgiveness_window -= 1

    def adjust_average_forgiveness_window(self) -> None:
        self.average_forgiveness_window = (self.game_description.n_players * self.forgiveness_window + self.average_forgiveness_window * len(self.memory)) / (self.game_description.n_players + len(self.memory))

class Strategy_COLLECTIVE_93(BaseStrategy):
    """
    The Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = []
        self.m = self.game_description.m
        self.epsilon = 0.01
        self.t = int(self.game_description.n_players * 0.7)
        self.b = self.game_description.m * 0.6
        self.m_prime = self.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is not None and state.round_number > 0:
            self.history.append(np.mean(history.opponent_actions[-self.t:]))
        if history is None or state.round_number == 0:
            return Action.C
        cooperate = True if self.history[-1] > self.m_prime and state.round_number < self.game_description.n_rounds - 1 else False
        payoff = 1 if not cooperate else 1 - 1 / self.game_description.n_players + self.game_description.k * cooperate
        if cooperate and self.history[-1] > self.t:
            self.m_prime += self.epsilon
        elif not cooperate and self.history[-1] < self.b:
            self.m_prime -= self.epsilon
        if state.round_number == 1 or state.round_number == self.game_description.n_rounds:
            cooperate = True if state.round_number == self.game_description.n_rounds and self.history[-1] > self.m_prime else False
        return cooperate and Action.C or Action.D

class Strategy_COLLECTIVE_95(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation (TFT-AC)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.sliding_window = int(self.game_description.n_players // 5)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and state.round_number != self.game_description.n_rounds - 1:
            cooperators = np.count_nonzero(history.opponent_actions[-self.sliding_window:, -1])
            if cooperators >= len(history.opponent_actions) // 2:
                return Action.C
        else:
            last_few_rounds = history.opponent_actions[-self.game_description.n_rounds:, -1]
            cooperators = np.count_nonzero(last_few_rounds)
            if cooperators >= len(last_few_rounds) // 2:
                return Action.C
            elif not any(last_few_rounds):
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_116(BaseStrategy):
    """
    An adaptive Tit-for-Tat strategy with a cooperation threshold for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperators_threshold = game_description.m
        self.historical_cooperation_threshold = self.cooperators_threshold
        self.rounds_played = 0
        self.cooperation_history = np.zeros(self.game_description.n_players)
        self.total_cooperators_in_history = 0
        self.history_factor = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.rounds_played += 1
        cooperators = sum(history.opponent_actions[-1, :]) if history else 0
        historical_cooperators = sum(self.cooperation_history)
        cooperation_factor = historical_cooperators / max(self.rounds_played - 1, 1)
        if self.rounds_played == self.game_description.n_players and cooperators < self.cooperators_threshold:
            self.historical_cooperation_threshold = min(self.cooperators_threshold * 0.9, self.game_description.n_players // 2)
        if cooperators >= self.cooperators_threshold:
            return Action.C
        elif cooperators < self.cooperators_threshold and historical_cooperators > 0 and (self.rounds_played > 1) and (cooperation_factor >= self.historical_cooperation_threshold):
            return Action.C
        elif cooperators < self.cooperators_threshold and historical_cooperators == 0:
            self.cooperation_history[random.randint(0, self.game_description.n_players - 1)] = 1 if random.random() > 0.5 else 0
            return Action.D
        else:
            self.cooperation_history[random.randint(0, self.game_description.n_players - 1)] += 1 if cooperators > 0 else -1
            self.total_cooperators_in_history += cooperators - historical_cooperators
            self.history_factor = self.total_cooperators_in_history / max(self.rounds_played - 1, 1)
            return Action.D

class Strategy_COLLECTIVE_120(BaseStrategy):
    """
    Implementation of the Tit-for-Tat with Adaptive Cooperation (TFT-AC) strategy for the Collective Risk Dilemma game.
    The strategy cooperates in the first round and adjusts its action based on the majority of players' actions from the previous round.
    It also includes a forgiveness mechanism that encourages cooperation by switching to cooperation if a player who previously defected switches to cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.forgiven = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_actions = history.my_actions if history else np.zeros(self.game_description.n_rounds, dtype=bool)
        my_actions[state.round_number - 1] = True
        if history is None:
            cooperators = 0
        else:
            cooperators = sum(history.opponent_actions[-1])
        if cooperators >= self.game_description.m and (not self.forgiven or my_actions[-2] == Action.D):
            self.forgiven = False
            return Action.C
        elif self.forgiven and my_actions[-1] == Action.C:
            self.forgiven = True
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_131(BaseStrategy):
    """
    A strategy that mimics opponents' actions from the previous round, encourages cooperation, and retaliates when necessary.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history_window_size = int(self.game_description.n_players // 2)
        self.cooperation_threshold = 2 / 3
        self.last_round_cooperate = False

    def __call__(self, state: GameState, history: PlayerHistory):
        if state.round_number == 0:
            return Action.C
        my_actions = history.my_actions[-self.history_window_size:]
        opponent_cooperators = np.sum(history.opponent_actions[-self.history_window_size:, :])
        if len(my_actions) == self.history_window_size and opponent_cooperators / len(my_actions) >= self.cooperation_threshold:
            return Action.C
        if not self.last_round_cooperate:
            return Action.D
        self.last_round_cooperate = False
        return Action.C

    def last_round(self):
        self.last_round_cooperate = True

class Strategy_COLLECTIVE_132(BaseStrategy):
    """
    Tit-for-Tat Adaptive (TFT-A) strategy for Collective Risk Dilemma.
    This strategy promotes long-term relationships based on reciprocity, encouraging cooperation while remaining robust against various opponent behaviors.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            if state.round_number == 0:
                self.history = np.zeros((self.game_description.n_rounds,), dtype=bool)
                self.history[0] = True
                return Action.C
        else:
            self.history = history.my_actions
        last_action = self.history[-1]
        cooperators = np.sum(history.opponent_actions[-1])
        if state.round_number < self.game_description.n_rounds - 1:
            if last_action and cooperators >= self.game_description.m:
                return Action.C
            elif not last_action or cooperators < self.game_description.m:
                return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_138(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat with Risk Aversion (ATfTRA)
    Summary: Encourages cooperation when conditions are favorable but also punishes non-cooperators to deter repeated defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros((1, 2), dtype=bool), np.zeros((1,)), np.zeros((self.game_description.n_players, 1), dtype=bool), np.zeros((1,)))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.history = PlayerHistory(np.array([[True]], dtype=bool), np.array([0.0]), np.zeros((self.game_description.n_players, 1), dtype=bool), np.zeros((1,)))
            return Action.C
        self.history = history
        if state.round_number == 0:
            return Action.C
        num_cooperators_last_3_rounds = sum(self.history.my_actions[max(0, state.round_number - 3):state.round_number + 1])
        if num_cooperators_last_3_rounds >= self.game_description.m:
            return Action.C
        elif num_cooperators_last_3_rounds < self.game_description.m and sum(self.history.my_actions[max(0, state.round_number - 4):state.round_number]) - sum(self.history.my_actions[max(0, state.round_number - 5):state.round_number]) <= self.game_description.m - 1:
            return Action.D
        else:
            majority = np.argmax(self.history.my_actions[max(0, state.round_number - 3):state.round_number + 1])
            return Action(majority)

class Strategy_COLLECTIVE_161(BaseStrategy):
    """
    A Tit-for-Tat strategy with adaptation for the Collective Risk Dilemma game.
    Cooperates initially, then adapts based on opponent's actions and patience level.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.c = min(round(self.game_description.n_players / 4), 0.5)
        self.p = math.ceil(self.game_description.n_players / 2)
        self.deviation_count = 0
        self.reset_counter = 0
        self.initial_patience = True

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        player_cooperators = sum(history.opponent_actions[-1, :])
        majority_cooperated = player_cooperators >= self.game_description.m - 1 if history else len(self.game_description) // 2
        if majority_cooperated:
            return Action.C
        elif self.initial_patience and random.random() < 1 - self.c:
            return Action.C
        else:
            self.deviation_count += 1
            if self.deviation_count > self.game_description.m * self.c:
                self.deviation_count = self.game_description.m * self.c
                self.reset_counter += 1
                if self.reset_counter >= self.p:
                    self.initial_patience = True
                    self.reset_counter = 0
            return Action.D

class Strategy_COLLECTIVE_178(BaseStrategy):
    """
    Tit-for-Tat Adaptive Cooperation (TFT-AC) strategy in Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        last_round = len(history.opponent_actions) - 1
        my_actions = history.my_actions[last_round] if history else np.zeros(self.game_description.n_players, dtype=bool)
        opponent_actions = history.opponent_actions[last_round] if history else np.zeros((self.game_description.n_players, 1), dtype=bool)
        cooperators = sum(opponent_actions)
        if last_round >= self.m:
            forgiveness = my_actions or cooperators >= self.m
            return Action.C if forgiveness else Action.D
        return Action.D if my_actions else Action.C

class Strategy_COLLECTIVE_194(BaseStrategy):
    """
    A Tit-for-Tat-Adaptive (TfTA) strategy for Collective Risk Dilemma games.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = None
        self.my_cooperation_count = 0

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if history is None and state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            if sum(history.opponent_actions[:-1, :].flatten()) < self.game_description.m - 1:
                return Action.D
        cooperation_threshold = self.game_description.m if state.round_number > 0 else self.game_description.m - 1
        num_cooperators = sum(history.opponent_actions[:, :state.round_number].flatten())
        if num_cooperators >= cooperation_threshold:
            self.my_cooperation_count += 1
            return Action.C
        self.my_cooperation_count = max(0, self.my_cooperation_count - 1)
        return Action.D

class Strategy_COLLECTIVE_196(BaseStrategy):
    """
    Implementation of Tit-for-Tat-Adaptive (TfTA) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(my_actions=np.array([False]), my_payoffs=np.array([]), opponent_actions=np.zeros((1, game_description.n_players)), opponent_payoffs=np.zeros((1, game_description.n_players)))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.history = history or self.history
        if len(self.history.opponent_actions) == self.game_description.n_rounds:
            return self._decide_action()
        cooperators = sum(self.history.opponent_actions[-1])
        if cooperators >= self.game_description.m - 1 or (cooperators < self.game_description.m and len(self.history.my_actions) == 1 and self.history.my_actions[0]):
            return Action.C
        return Action.D

    def _decide_action(self):
        previous_action = self.history.my_actions[-1]
        current_cooperators = sum(self.history.opponent_actions[-1])
        if not previous_action and current_cooperators >= self.game_description.m - 1:
            return Action.C
        elif previous_action and current_cooperators < self.game_description.m:
            return Action.D
        return previous_action

class Strategy_COLLECTIVE_207(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.rounds_consecutive_less_than_m = 0
        self.learning_parameter = 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            other_players_actions = history.opponent_actions[-1]
            if np.count_nonzero(other_players_actions) >= (self.game_description.n_players + 1) // 2:
                self.cooperation_threshold = math.floor(self.cooperation_threshold + self.learning_parameter * (self.rounds_consecutive_less_than_m - (state.round_number - self.rounds_consecutive_less_than_m)))
                if self.cooperation_threshold > self.game_description.n_players - self.game_description.m + 1:
                    self.cooperation_threshold = self.game_description.n_players - self.game_description.m + 1
                if self.cooperation_threshold < self.game_description.m:
                    self.cooperation_threshold = self.game_description.m
                self.rounds_consecutive_less_than_m = 0
            else:
                self.rounds_consecutive_less_than_m += 1
        return Action.C if self.cooperation_threshold >= self.game_description.m else Action.D

class Strategy_COLLECTIVE_211(BaseStrategy):
    """
    This strategy is named Tit-for-Tat Adaptive (TfTA) for the Collective Risk Dilemma game.
    It encourages reciprocal cooperation and punishes defection, fostering a collective mindset.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_coop_threshold = math.ceil(game_description.n_players * 0.5)
        self.punishment_threshold = math.floor(self.min_coop_threshold * 2 / 3)
        self.last_round_payoff = None
        self.defected_rounds = 0

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if history is None:
            return Action.C
        action = Action.D
        round_number = state.round_number
        if round_number == 0:
            action = Action.C
        elif round_number > 1 and history.my_actions[-2] == Action.C and (history.opponent_actions[-1].sum() >= self.min_coop_threshold):
            action = Action.C
        elif round_number > 1 and history.my_actions[-1] == Action.D:
            if history.opponent_actions[-1].sum() < self.min_coop_threshold or self.defected_rounds >= self.punishment_threshold:
                action = Action.D
            else:
                self.defected_rounds = 0
        elif round_number > 1 and self.last_round_payoff is not None and (history.my_actions[-2] == Action.C) and (history.opponent_actions[-1].sum() < self.min_coop_threshold):
            if self.last_round_payoff > 1 + self.game_description.k:
                action = Action.C
        else:
            self.defected_rounds += 1
        if round_number < self.game_description.n_rounds and history.my_payoffs[round_number - 1] is not None:
            self.last_round_payoff = history.my_payoffs[round_number - 1]
        return action

class Strategy_COLLECTIVE_214(BaseStrategy):
    """
    A Tit-for-Tat with Gradual Cooperation (TFTGC) strategy for the Collective Risk Dilemma game.
    This strategy employs gradual cooperation, encouraging players to cooperate when it becomes a dominant behavior within the group.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.probability_threshold = 0.2
        self.cooperation_threshold = math.ceil(game_description.m * self.probability_threshold)
        self.gradual_increase = math.sqrt((self.game_description.n_players - self.cooperation_threshold) / (1 - self.probability_threshold))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.D
        historical_cooperators = sum(history.my_actions[-self.game_description.n_rounds:])
        probability_cooperate = 0.1 if state.round_number < math.floor(self.probability_threshold * self.game_description.n_rounds) else 0.5 if state.round_number <= self.game_description.n_rounds and historical_cooperators >= self.cooperation_threshold else 1 if historical_cooperators >= self.game_description.m else 0
        return Action(int(math.floor(random.random() * 2)) == 1) if random.random() < probability_cooperate else Action.D

class Strategy_COLLECTIVE_216(BaseStrategy):
    """
    Adaptive Tit-for-Tat strategy for the Collective Risk Dilemma game.
    The strategy cooperates initially and mimics the opponent's action from the previous round in subsequent rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds, dtype=np.float64), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros((game_description.n_rounds, game_description.n_players), dtype=np.float64))
        self.opponent_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            self.history = history
            self.opponent_cooperators = sum(self.history.opponent_actions[-1, :])
        if state.round_number < self.game_description.n_rounds - 1:
            return Action(self.opponent_cooperators >= self.game_description.n_players // 2)
        self.history.my_actions[-1] = Action(self.opponent_cooperators >= self.game_description.n_players // 2).value
        self.opponent_cooperators = sum(self.history.opponent_actions[-1, :])
        return Action(self.opponent_cooperators >= self.game_description.n_players // 2)

class Strategy_COLLECTIVE_224(BaseStrategy):
    """
    Implementation of the Tit-for-Tat-Adaptive (TfTA) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.previous_rounds = np.zeros(self.game_description.n_players)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C if np.sum(self.previous_rounds) < self.m else Action.D
        if history is not None:
            coop_count = np.sum(history.opponent_actions[-1])
            if state.round_number == self.game_description.n_rounds:
                last_opponent = history.opponent_actions[-2, -1]
                return Action.C if last_opponent else Action.D
            elif coop_count >= self.m:
                self.previous_rounds = history.opponent_actions[-self.game_description.m:]
                return Action.C
            else:
                self.previous_rounds = np.roll(self.previous_rounds, -1)
                self.previous_rounds[-1] = coop_count
                return Action.D

class Strategy_COLLECTIVE_232(BaseStrategy):
    """
    Tit-for-Tat Adaptive (TFT-A) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m
        self.n = self.game_description.n_players
        self._cooperated_last_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            return Action.C
        self._cooperated_last_round = sum(history.opponent_actions[-1, :]) >= self.m
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        if not self._cooperated_last_round and history.my_payoffs[-1] < 1 + self.game_description.k:
            return Action.D
        return Action.C if self._cooperated_last_round else Action.D

    def first_defectors(self, history: PlayerHistory) -> bool:
        """
        Check if the strategy has encountered defectors for the first time.
        """
        if not history or len(history.opponent_actions) < 2:
            return False
        return len(np.where(history.opponent_actions[0, :] == Action.D)[0]) + 1 >= self.n - 1

    def last_defectors(self, history: PlayerHistory) -> bool:
        """
        Check if the strategy has encountered defectors in the penultimate round.
        """
        return len(np.where(history.opponent_actions[-2, :] == Action.D)[0]) + 1 >= self.n - 1

class Strategy_COLLECTIVE_247(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperators_last_round = {}
        self.defectors_last_round = {}

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None or state.round_number == 0:
            return Action.C
        cooperators_last_round = self.cooperators_last_round
        defectors_last_round = self.defectors_last_round
        if state.round_number == len(history.opponent_actions):
            return Action.C
        player_index = self.__class__.__name__
        current_action = history.my_actions[-1][0] if len(history.my_actions) > 0 else None
        opponents_actions = history.opponent_actions[-1]
        if player_index in cooperators_last_round:
            if current_action == Action.C and sum(cooperators_last_round.values()) >= self.game_description.m:
                return Action.C
        elif player_index in defectors_last_round:
            if current_action == Action.D and sum(defectors_last_round.values()) >= self.game_description.n_players - self.game_description.m + 1:
                return Action.D
        elif current_action is not None and opponents_actions[player_index] == current_action:
            if sum(cooperators_last_round.values()) >= self.game_description.m:
                return Action.C
            elif sum(defectors_last_round.values()) >= self.game_description.n_players - self.game_description.m + 1:
                return Action.D
        elif current_action is None or opponents_actions[player_index] == Action.C:
            if player_index in defectors_last_round:
                return Action.D
            elif player_index not in cooperators_last_round:
                return Action.C
        elif player_index in cooperators_last_round:
            return Action.D
        elif player_index not in defectors_last_round:
            return Action.C
        cooperators_last_round[player_index] = current_action == Action.C
        defectors_last_round[player_index] = current_action == Action.D
        return current_action

class Strategy_COLLECTIVE_250(BaseStrategy):
    """
    TFT-AC: Tit-for-Tat with Adaptive Cooperation
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.history = PlayerHistory(np.zeros((1, 2)), np.zeros((1, 1)), np.zeros((1, self.n_players, 1)), np.zeros((1, self.n_players, 1)))
        self.cooperation_rate_thresholds = [np.percentile(self.history.my_actions[0, :], q) for q in [50, np.percentile(self.history.my_actions[0, :], 50) - 1 * np.std(self.history.my_actions[0, :])]]
        self.most_cooperative = None

    def __call__(self, state: GameState, history: PlayerHistory):
        if state.round_number == 0:
            return Action.C
        elif self.history.opponent_actions[-1, :].sum() < self.m - 1:
            return Action.D
        cooperators = history.opponent_actions[-1, :].sum()
        if cooperators >= self.n_players // 2 and self.most_cooperative is None:
            self.most_cooperative = np.argmax(history.opponent_actions[-1, :])
        elif self.most_cooperative is not None and history.opponent_actions[-1, self.most_cooperative] > self.cooperation_rate_thresholds[0]:
            return Action(self.history.opponent_actions[-1, self.most_cooperative])
        elif history.opponent_actions[-1, self.most_cooperative] < self.cooperation_rate_thresholds[1]:
            self.most_cooperative = None
        else:
            return Action.C
        self.history = PlayerHistory(np.vstack((self.history.my_actions, [history.my_actions[-1]])), np.vstack((self.history.my_payoffs, [history.my_payoffs[-1]])), np.vstack((self.history.opponent_actions, history.opponent_actions)), np.vstack((self.history.opponent_payoffs, [history.opponent_payoffs[-1]])))
        return Action(int(self.__class__.__name__[8]))

class Strategy_COLLECTIVE_254(BaseStrategy):
    """
    Strategy: Tit-for-Tat with Adaptation (TFT-A) in Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_cooperator_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif history is not None:
            if history.my_actions[-1] and self.opponent_cooperator_count >= self.game_description.m:
                return Action.C
            self.opponent_cooperator_count = sum(history.opponent_actions[:, -1])
            return Action.D
        else:
            if sum(history.my_actions) < self.game_description.m:
                return Action.D
            self.opponent_cooperator_count = history.opponent_cooperator_count
            return history.opponent_actions[-1]

class Strategy_COLLECTIVE_255(BaseStrategy):
    """Adaptive Tit-for-Tat strategy for Collective Risk Dilemma"""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = None

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        self.history = history if history else PlayerHistory(my_actions=np.zeros((self.game_description.n_rounds,), dtype=np.bool_), my_payoffs=np.zeros((self.game_description.n_rounds,), dtype=np.float64), opponent_actions=np.zeros((self.game_description.n_rounds, self.game_description.n_players), dtype=np.bool_), opponent_payoffs=np.zeros((self.game_description.n_rounds, self.game_description.n_players), dtype=np.float64))
        if history is None:
            self.history.opponent_actions[0] = np.ones(self.game_description.n_players, dtype=np.bool_)
            self.history.my_payoffs[0] = 1 - self.history.opponent_actions[0][self.__class__]
        else:
            cooperation_count = sum(history.opponent_actions[-1, :])
            if state.round_number == self.game_description.n_rounds and cooperation_count >= self.game_description.m:
                return Action.C
            action = history.opponent_actions[-1][(self.history.my_actions[-1] + 1) % 2]
            if cooperation_count >= self.game_description.m and cooperation_count / self.game_description.n_players > 0.5:
                return Action.C
            elif action:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_256(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation (TFTA)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.forgiveness_counter = self.game_description.n_rounds
        self.history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        if state.round_number == 0 or self.history == []:
            return Action.C
        self.forgiveness_counter -= 1
        if self.forgiveness_counter <= 0:
            self.forgiveness_counter = self.game_description.n_rounds
            cooperated_last_round = any(history.my_actions[-1])
            if not cooperated_last_round and sum(history.my_actions[-self.game_description.n_rounds:]) > sum(history.opponent_actions[-self.game_definition.n_rounds:]):
                self.forgiveness_counter = self.game_description.n_rounds // 2
        cooperators = sum(history.my_actions[-1])
        if self.forgiveness_counter <= 0 or (cooperators < self.m and len(history) >= self.game_description.n_rounds // 2):
            return Action.D
        elif cooperators >= self.m:
            return Action.C
        else:
            most_frequent_cooperators = max(((p, history.opponent_actions[-1][p]) for p in range(self.n_players)))[1]
            return Action(most_frequent_cooperators) if most_frequent_cooperators else Action.D

class Strategy_COLLECTIVE_261(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperate_count = 0
        self.opponent_actions = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        action = Action.D
        opponent_action = None if history is None else history.opponent_actions[-1][0]
        if opponent_action is not None:
            if opponent_action == Action.C:
                action = Action.C
            elif state.round_number < self.game_description.n_rounds:
                self.opponent_actions.append(opponent_action)
        if state.round_number == self.game_description.n_rounds:
            if len(self.opponent_actions) > self.cooperate_count >= (self.game_description.n_players - 1) // 2:
                action = Action.C
        return action

class Strategy_COLLECTIVE_289(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat Adaptive Cooperation (TFTAC)
    Strategy Summary: A collective strategy that encourages cooperation and aims to form mutually beneficial relationships with other players.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.current_round = 0
        self.cooperation_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is not None:
            self.current_round = state.round_number
            self.cooperation_count = sum(history.my_actions[:self.current_round])
        if self.current_round == 0:
            return Action.C
        elif self.current_round < self.game_description.n_rounds and self.cooperation_count >= self.game_description.m:
            if sum(history.opponent_actions[self.current_round - 1]) >= self.game_description.n_players - 1:
                payoff = math.ceil((self.current_round + 1) * (self.game_description.k * self.cooperation_count))
                return Action.C
            else:
                return Action.D
        elif self.current_round == self.game_description.n_rounds:
            return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_298(BaseStrategy):
    """
    A strategy that mimics the actions of frequent cooperators in the past, promoting cooperation and trust among players.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m
        self.n = self.game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and len(history.my_actions) == 0):
            return Action.C
        most_frequent_cooperators = self._find_most_frequent_cooperators(history)
        if len(most_frequent_cooperators) == 0:
            return Action.D
        most_recent_cooperator = self._find_max_recent_cooperator(most_frequent_cooperators, history)
        recent_history = history[-self.game_description.n_rounds:] if history is not None else []
        cooperative_actions = sum([1 for action in reversed(recent_history) if action == most_recent_cooperator])
        if cooperative_actions >= self.m and state.round_number < self.game_description.n_rounds:
            return Action.C
        elif state.round_number == self.game_description.n_rounds:
            if cooperative_actions >= self.m or all((action == Action.C for action in reversed(recent_history))):
                return Action.C
            else:
                return Action.D
        else:
            return most_recent_cooperator

    def _find_most_frequent_cooperators(self, history: PlayerHistory) -> set[int]:
        if history is None or len(history.my_actions) < self.game_description.n_rounds:
            return set()
        cooperative_counts = {player: 0 for player in range(1, self.n + 1)}
        for action in reversed(history.my_actions):
            if action:
                for player in reversed(range(1, self.n + 1)):
                    if history.opponent_actions[0, player - 1] == action:
                        cooperative_counts[player] += 1
        return {player for player, count in cooperative_counts.items() if count >= self.m - 1}

    def _find_max_recent_cooperator(self, players: set[int], history: PlayerHistory) -> Action:
        if len(players) == 1:
            return players.pop()
        latest_actions = {}
        for player in players:
            max_round = -1
            latest = None
            for round_number in reversed(range(self.game_description.n_rounds)):
                action = history.my_actions[round_number, player - 1] if history is not None else None
                if action and (latest is None or round_number > latest):
                    latest = round_number
            latest_actions[player] = latest
        return max(players, key=lambda player: latest_actions.get(player, -1))

class Strategy_COLLECTIVE_301(BaseStrategy):
    """
    Implementation of Adaptive Tit-for-Tat (ATFT) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m
        self.last_opponent_action = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperation_count = sum(history.opponent_actions[-1])
        if cooperation_count >= self.min_cooperators:
            return Action.C
        if history and state.round_number > len(history.opponent_actions) or self.last_opponent_action is None:
            self.last_opponent_action = history.opponent_actions[-1][0]
            return Action.C
        else:
            action = Action.D if self.last_opponent_action == Action.C else Action.C
            self.last_opponent_action = action
            return action

class Strategy_COLLECTIVE_307(BaseStrategy):
    """
    Strategy name: Tit-for-Tat with Adaptive Cooperation (TFT-AC)

    Strategy description: This strategy cooperates initially to foster trust and goodwill,
                            then mimics the behavior of other players for the next four rounds.
                            After that, it adapts its cooperation based on whether more than 50% of opponents have defected in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.observation_period = 4
        self.current_round = 0
        self.opponent_history = np.zeros((self.observation_period,), dtype=np.bool_)
        self.last_round_cooperation = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.current_round += 1
        if self.current_round <= self.observation_period:
            self.opponent_history[self.current_round - 1] = np.mean(history.opponent_actions[-self.observation_period:, -1]) > 0.5
            return Action.C if np.all(self.opponent_history) else Action.D
        if self.last_round_cooperation and np.mean(history.opponent_actions[-self.observation_period:, -1]) <= 0.5:
            return Action.D
        if not self.last_round_cooperation and np.mean(history.opponent_actions[-self.observation_period:, -1]) > 0.5:
            self.current_round = 1
            self.opponent_history = np.zeros((self.observation_period,), dtype=np.bool_)
            return Action.C
        self.last_round_cooperation = np.mean(history.opponent_actions[-self.observation_period:, -1]) > 0.5
        return Action.C if self.last_round_cooperation else Action.D

class Strategy_COLLECTIVE_315(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Threshold (TFTA)
    This strategy cooperates in the first round and cooperates if a majority of players cooperated in the previous round. The cooperation threshold is adaptive and adjusts based on the number of cooperators in the last round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = math.ceil(game_description.n_players / 2)
        self.history = None

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if not history:
            return Action.C
        cooperators = sum(history.opponent_actions[-1])
        if self.threshold > cooperators:
            self.threshold = max(self.threshold - 1, 1)
            return Action.D
        elif cooperators == self.threshold:
            if state.round_number != 1:
                return Action.C
            else:
                return Action.C
        else:
            new_threshold = math.ceil(self.threshold + (self.threshold - cooperators) / self.game_description.n_rounds)
            self.threshold = min(new_threshold, self.game_description.n_players)
            return Action.C

class Strategy_COLLECTIVE_337(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation (TFT-AC)
    Strategy Description: A strategy that cooperates initially, and defects if the opponent has previously defected. If the opponent has cooperated, it continues to cooperate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = []

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or len(self.opponent_history) == 0:
            self.opponent_history = [False] * (state.round_number + 1)
            return Action.C
        if history.opponent_actions[-1][-1] == Action.D:
            self.opponent_history[-1] = True
            return Action.D
        else:
            self.opponent_history[-1] = False
            if all((action == False for action in history.opponent_actions[-1][:-1])):
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_341(BaseStrategy):
    """
    Implementation of Tit-for-Tat with Adaptive Cooperation Threshold strategy.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros(game_description.n_rounds))

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        self.history = history
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.cooperation_threshold:
            self.cooperation_threshold = max(self.cooperation_threshold - 1, 1)
            return Action.C
        else:
            self.cooperation_threshold = min(self.cooperation_threshold + 1, self.game_description.n_players)
            return Action.D

class Strategy_COLLECTIVE_357(BaseStrategy):
    """
    Implementation of the Tit-for-Tat Adaptive Cooperative Strategy (TFTAC) for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.forgiveness_factor = 0.2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None:
            return Action.C
        t_p = int(self.game_description.n_rounds * self.forgiveness_factor)
        previous_opponent_action = history.opponent_actions[-1][-1] if len(history.opponent_actions) > 0 else None
        if previous_opponent_action is not None and state.round_number - t_p < 1:
            return Action.C if previous_opponent_action == Action.C.value else Action.D
        if previous_opponent_action == Action.C.value:
            return Action.C
        elif previous_opponent_action is None or history.opponent_actions[-1][-1] != previous_opponent_action:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_366(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.memory = [[[]] * game_description.n_rounds for _ in range(game_description.n_players)]
        self.grace_period = math.ceil(game_description.n_rounds / 2)
        self.last_opponent_action = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_actions = history.opponent_actions[-1]
        cooperation_count = sum(opponent_actions)
        if cooperation_count >= self.game_description.m and (self.last_opponent_action is None or self.last_opponent_action == Action.C):
            return Action.C
        elif cooperation_count < self.game_description.m:
            return Action.D
        else:
            if self.last_opponent_action == Action.C:
                return Action.C
            return Action.D
        self.last_opponent_action = opponent_actions[-1] if opponent_actions else None

class Strategy_COLLECTIVE_379(BaseStrategy):
    """
    This is a Tit-for-Tat with Adaptive Cooperation (TFT-AC) strategy for the Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m
        self.previous_round_cooperators = 0
        self.defection_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        opponent_cooperators = sum(history.opponent_actions[-1])
        if opponent_cooperators > self.m - 1:
            self.previous_round_cooperators += opponent_cooperators
            self.defection_count = 0
            return Action.C
        elif opponent_cooperators < self.m:
            self.defection_count += 1
            self.previous_round_cooperators -= opponent_cooperators
            return Action.D
        else:
            cooperate = self.previous_round_cooperators > 0
            if not cooperate and self.defection_count > 0:
                cooperate = min(self.defection_count, self.game_description.n_players)
                self.defection_count -= cooperate
            return Action(cooperate)

class Strategy_COLLECTIVE_393(BaseStrategy):
    """
    A strategy that follows the Tit-for-Tat adaptive approach in Collective Risk Dilemma games.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history_buffer = np.zeros((self.game_description.n_players - 1, 2))
        self.cooperation_count = 0
        self.rounds_in_history = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        self.update_history(history)
        cooperators = np.sum(self.history_buffer[:, 1])
        average_cooperation = cooperators / self.rounds_in_history if self.rounds_in_history > 0 else 0
        if average_cooperation >= self.game_description.m:
            return Action.C if self.history[-1] == Action.C else Action.D
        else:
            return Action.D

    def update_history(self, history: PlayerHistory) -> None:
        self.rounds_in_history += 1
        if self.rounds_in_history > self.game_description.n_players - 1:
            self.cooperation_count -= self.history_buffer[0, 1]
        self.history_buffer = np.roll(self.history_buffer, -1, axis=0)
        self.history_buffer[-1, :] = [history.my_actions[-1], history.my_payoffs[-1] > 1]
        self.cooperation_count += history.my_payoffs[-1] > 1

class Strategy_COLLECTIVE_412(BaseStrategy):
    """
    A Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperative_rounds = []
        self.adaptation_window = int(math.ceil(game_description.n_rounds * 0.1))
        self.cooperation_threshold = game_description.m
        self.d = math.floor(game_description.n_rounds * 0.2)
        self.success_window = int(math.ceil(self.adaptation_window * 0.8))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            self.cooperative_rounds.append(len(history.my_actions[history.my_actions == 1]))
        n_c = len(history.my_actions[history.my_actions == 1])
        if n_c >= self.cooperation_threshold:
            return Action.C
        if state.round_number - self.d > self.game_description.n_rounds:
            self.adjust_threshold(history)
        return Action.D

    def adjust_threshold(self, history: PlayerHistory):
        payoff_window = np.mean(history.my_payoffs[max(0, self.game_description.n_rounds - self.adaptation_window):])
        if payoff_window > self.previous_average:
            self.cooperation_threshold += 1
        elif payoff_window < self.previous_average:
            self.cooperation_threshold -= 1
        self.previous_average = payoff_window

class Strategy_COLLECTIVE_424(BaseStrategy):
    """
    An adaptive Tit-for-Tat strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and history.my_actions[-1].all():
            return Action.C
        cooperators = sum(history.opponent_actions[-1])
        if cooperators >= self.n_players - 1:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_433(BaseStrategy):
    """
    Tit-for-Tat with Gradual Cooperation (TFT-GC) Strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.probability_of_cooperation = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return random.choice([Action.C, Action.D])
        if history is None:
            cooperators = int(random.uniform(0, self.n)) if state.round_number == 1 else 0
        else:
            cooperators = sum(history.opponent_actions[-1, :].flatten())
        if state.round_number == self.game_description.n_rounds:
            c_i = self.__cooperation_decision(state, history, cooperators)
        else:
            c_i = self.__tft_gc_decision(state, history, cooperators)
        return Action(int(c_i))

    def __tft_gc_decision(self, state: GameState, history: PlayerHistory, cooperators: int) -> float:
        previous_round = len(history.my_actions) - 1 if history is not None else self.game_description.n_rounds - 1
        count_cooperators_previous_round = sum(history.opponent_actions[previous_round, :].flatten())
        c_i = min(self.probability_of_cooperation + (count_cooperators_previous_round - self.m) / self.n, 1)
        self.probability_of_cooperation += (cooperators - count_cooperators_previous_round + 1) / self.n if cooperators > count_cooperators_previous_round else 0
        return c_i

    def __cooperation_decision(self, state: GameState, history: PlayerHistory, cooperators: int) -> float:
        if cooperators >= self.game_description.m:
            return 1
        return 0

class Strategy_COLLECTIVE_437(BaseStrategy):
    """
    Tit-for-Tat Adaptive Cooperation (TFTAC) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros(game_description.n_rounds))

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_action = self.history.my_actions[-1]
        if last_action == Action.C and history.opponent_actions[state.round_number - 1, :].mean() == 1:
            return Action.C
        elif last_action == Action.D and history.opponent_actions[state.round_number - 1, :].mean() != 0:
            return Action.C
        else:
            return Action.D

    def update_history(self, round_payoff: NDArray[np.float64]):
        self.history.my_actions[-1] = self.history.__call__.__func__() == Action.C
        self.history.my_payoffs[-1] = round_payoff[0]
        self.history.opponent_actions[state.round_number - 1, :] = history.opponent_actions[:state.round_number - 1, :]
        self.history.opponent_payoffs[state.round_number - 1] = round_payoff[1:]

class Strategy_COLLECTIVE_451(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATFT)
    Strategy Description: A cooperative strategy that reciprocates cooperation and punishes defection. It aims to foster a cooperative environment by encouraging other players to also cooperate, thereby promoting the collective interest of achieving the minimum threshold for success (m). The ATFT strategy is adaptive to different game scenarios.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.early_rounds = math.ceil(game_description.m / 2)
        self.last_cooperation = None

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        action = Action.D
        if history is not None:
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators >= self.game_description.m:
                action = Action.C
            elif self.last_cooperation is not None and state.round_number > self.last_cooperation:
                action = Action.D
            elif state.round_number >= self.early_rounds:
                action = self.__early_round_behavior(state, history)
        self.last_cooperation = state.round_number if action == Action.C else None
        return action

    def __early_round_behavior(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number < self.game_description.m:
            return Action.C
        return Action.D if history.my_actions[state.round_number - 1] == Action.C else Action.C

class Strategy_COLLECTIVE_465(BaseStrategy):
    """Adaptive Tit-for-Tat (ATfT) for Collective Risk Dilemma"""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.m
        self.k = game_description.k
        self.g = 3
        self.defectors = 0
        self.punishers = 0
        self.cooperated_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        if state.round_number == history.opponent_actions.shape[0] - 1:
            return self(GameState(state.round_number + 1), history)
        if history.my_actions[-1]:
            self.cooperated_count += 1
            self.defectors = 0
        else:
            self.cooperated_count = max(self.cooperated_count - 1, 0)
        cooperators = np.sum(history.opponent_actions[-1])
        if cooperators >= self.threshold:
            return Action.C
        elif history.my_actions[-1] and self.cooperated_count >= self.g:
            return Action.C
        else:
            self.defectors += 1
            if self.defectors > self.punishers + 1:
                self.threshold -= 1
                self.punishers = self.defectors
            return Action.D

class Strategy_COLLECTIVE_470(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.T = 1.0
        self.T_min = self.game_description.m / self.game_description.n_players
        self.increment = 0.01
        self.decrement = 0.01

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        action_last_round = history.my_actions[-1] if history else None
        num_cooperators = sum(history.opponent_actions[-1, :]) if history else None
        if action_last_round is not None and num_cooperators is not None:
            if action_last_round and num_cooperators >= self.game_description.m:
                self.T = min(self.T + self.increment, 1.0)
                return Action.C
            elif not action_last_round or num_cooperators < self.game_description.m:
                self.T = max(self.T - self.decrement, self.T_min)
                return Action.D
        elif state.round_number == self.game_description.n_rounds:
            return Action.C if self.T > self.T_min else Action.D
        return None

class Strategy_COLLECTIVE_477(BaseStrategy):
    """
    A strategy that mimics the Tit-for-Tat Adaptive approach in Collective Risk Dilemma games.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.k = game_description.k
        self.last_cooperators = 0

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.m:
            self.last_cooperators += cooperators
            return Action.C
        elif self.last_cooperators >= self.m:
            self.last_cooperators -= cooperators
            return Action.C
        self.last_cooperators = 0
        return Action.D

class Strategy_COLLECTIVE_478(BaseStrategy):
    """
    Implementation of the Tit-for-Tat with Threshold (TFT-T) strategy in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_m = int(math.ceil(game_description.n_players * 0.2))
        self.retaliation_counter = 0
        self.first_round = True

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        action = Action.C if self.first_round else Action.D
        self.first_round = False
        if state.round_number > 0 and history is not None:
            n_c = sum(history.opponent_actions[-1, :])
            if n_c >= self.game_description.m:
                action = Action.C
            elif action == Action.C and n_c < self.game_description.m:
                action = Action.D
            if action == Action.D and history.my_actions[-1] == Action.C:
                self.retaliation_counter += 1
                if self.retaliation_counter > self.n_m:
                    self.retaliation_counter = 0
        return action

class Strategy_COLLECTIVE_496(BaseStrategy):
    """
    Implementation of Tit-for-Tat with Adaptive Risk Aversion (TFT-ARA) strategy in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.alpha = 0.1
        self.beta = 0.05
        self.delta = 0.01
        self.risk_aversion_factor = self.alpha
        self.last_cooperators = {t: 0 for t in range(self.game_description.n_rounds)}

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            cooperators = 0
        else:
            cooperators = sum(history.opponent_actions[-1, :])
            self.last_cooperators[state.round_number] = cooperators
        if state.round_number < self.game_description.n_rounds:
            if cooperators >= self.m:
                return Action.C
            else:
                self.risk_aversion_factor = max(self.risk_aversion_factor - self.delta, self.beta)
                self.m_t = min(self.m + self.risk_aversion_factor * (self.m - cooperators), self.n_players)
                return Action.D
        return Action.C

class Strategy_EXPLOITATIVE_28(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT)

    This strategy cooperates initially to show goodwill and trustworthiness, as other players may also start cooperatively.
    For subsequent rounds, it adapts the cooperation based on the number of cooperators in the previous round.
    If m or more players cooperated in the previous round, it cooperates in the current round (reward averted risk).
    If less than m players cooperated in the previous round, it defects in the current round (punish uncooperative behavior).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.cooperate_count = self.m
        self.punishment_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif self.punishment_counter >= self.game_description.n_players // 2:
            return Action.D
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators < self.cooperate_count:
            self.punishment_counter += 1
            return Action.D
        elif cooperators >= self.cooperate_count and self.punishment_counter > 0:
            self.punishment_counter = 0
        else:
            self.punishment_counter = 0
        return Action.C

class Strategy_EXPLOITATIVE_31(BaseStrategy):
    """
    A strategy that mimics the Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) in Collective Risk Dilemma games.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = self.game_description.m / self.game_description.n_players
        self.opponent_history = np.zeros((self.game_description.n_players, self.game_description.n_rounds), dtype=bool)
        self.cooperation_count = 0
        self.non_cooperation_count = 0
        self.opponent_history_capacity = math.floor(self.game_description.n_rounds * 0.8)
        self.recent_cooperations = 0
        self.w = math.floor(self.game_description.n_rounds * 0.2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        elif state.round_number == 0 and history is not None:
            self.opponent_history = history.opponent_actions
            return Action.C
        else:
            cooperators = np.sum(history.opponent_actions[-self.w:, :])
            self.recent_cooperations = sum(history.opponent_actions[-self.w:])
            if cooperators / self.w >= self.cooperation_threshold:
                self.cooperation_count += 1
                cooperation_threshold = min(self.cooperation_threshold + self.non_cooperation_count / (self.game_description.n_rounds - self.non_cooperation_count), 1)
            else:
                self.non_cooperation_count += 1
                cooperation_threshold = max(self.cooperation_threshold - self.cooperation_count / (self.game_description.n_rounds - self.cooperation_count), self.cooperation_threshold)
            if self.non_cooperation_count >= self.w and state.round_number != self.game_description.n_rounds:
                cooperation_threshold += self.non_cooperation_count / (self.game_description.n_rounds - self.non_cooperation_count)
            if self.cooperation_count >= self.w and state.round_number != self.game_description.n_rounds:
                cooperation_threshold -= self.cooperation_count / (self.game_description.n_rounds - self.cooperation_count)
            if cooperators / self.w >= cooperation_threshold:
                return Action.C
            return Action.D

class Strategy_EXPLOITATIVE_37(BaseStrategy):
    """
    A Tit-for-Tat-Adaptive (TfTA) strategy for Collective Risk Dilemma games.
    This strategy cooperates or defects based on the number of opponents who cooperated in the previous round,
    with a dynamic cooperation threshold that allows it to adapt to different opponent behaviors and be exploitative.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.delta = int(math.ceil((game_description.m - 1) / 2))
        self.history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.history.append(Action(1 - history.my_actions[-1]) if history else Action.C)
        cooperators = sum(history.opponent_actions[-1] if history else [0])
        if cooperators >= self.cooperation_threshold:
            return Action.C
        elif len(self.history) > 1 and self.history[-2] == Action.D and (cooperators < self.cooperation_threshold - self.delta):
            return Action.C
        else:
            return Action.D

    def update_cth(self, cooperators):
        if cooperators >= self.game_description.m:
            self.cooperation_threshold += self.delta // 2
        elif cooperators < self.cooperation_threshold - self.delta:
            self.cooperation_threshold -= self.delta // 2

class Strategy_EXPLOITATIVE_40(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = math.ceil(game_description.m)
        self.current_round = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.current_round += 1
        if history is None:
            opponent_actions = np.zeros((self.game_description.n_players, state.round_number), dtype=bool)
            opponent_payoffs = np.zeros(state.round_number, dtype=np.float64)
        else:
            opponent_actions = history.opponent_actions
            opponent_payoffs = history.opponent_payoffs
        cooperators = sum(opponent_actions[self.current_round - 1, :])
        if cooperators >= self.cooperation_threshold:
            return Action.C
        else:
            self.cooperation_threshold = max(self.cooperation_threshold - 1, 1) if self.cooperation_threshold > self.game_description.m else min(self.cooperation_threshold + 1, self.game_description.n_players)
        return Action.D

class Strategy_EXPLOITATIVE_53(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation (TFTA) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_round_cooperators = 0
        self.is_last_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number < self.game_description.n_rounds - 1:
            self.is_last_round = False
            cooperators = sum(history.opponent_actions[-1, :]) if history is not None else 0
            self.last_round_cooperators = cooperators
            if cooperators >= self.game_description.n_players // self.game_description.m and self.last_round_cooperators == self.game_description.n_players - 1:
                return Action.D
            elif cooperators < self.game_description.n_players // self.game_description.m:
                if cooperators >= self.last_round_cooperators:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            self.is_last_round = True
            return Action.D

class Strategy_EXPLOITATIVE_55(BaseStrategy):
    """
    Strategy name: Tit-for-Tat with Modified Grim Trigger (TFTR-MT)
    Summary: Reciprocal strategy that cooperates initially and responds to opponents' actions by either cooperating or defecting based on a sliding window of previous moves. If an opponent has ever defected and subsequently returns to cooperation, the strategy waits for m-1 consecutive rounds of cooperation from that player before returning the favor.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m
        self.history_window = np.zeros((self.game_description.n_players, self.m))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.history_window.sum(axis=1).max() >= self.m:
            return Action.C
        elif np.any(history.opponent_actions[-self.m:, -1]):
            self.history_window = history.opponent_actions[state.round_number - self.m:, :]
            return Action.C
        else:
            return Action.D
        self.history_window[:-1] = self.history_window[1:]
        self.history_window[-1] = history.opponent_actions[state.round_number - 1, :]

class Strategy_EXPLOITATIVE_85(BaseStrategy):
    """
    Tit-for-Tat with Adaptation (TfT-A) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_level = 1
        self.forgiveness_level = 0
        self.past_cooperation = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if not history:
            return Action.C
        if state.round_number == len(history.my_actions):
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators >= self.game_description.m:
                return Action.C
            else:
                return Action.D
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.game_description.m:
            self.past_cooperation = Action.C
        else:
            self.past_cooperation = Action.D
        current_cooperation_level = cooperators - self.past_cooperation
        if current_cooperation_level >= 1:
            self.forgiveness_level += min(self.game_description.n_players, current_cooperation_level)
            if self.forgiveness_level > self.punishment_level:
                self.punishment_level = self.forgiveness_level
            self.past_cooperation += self.forgiveness_level
        elif current_cooperation_level < 0:
            self.punishment_level += min(self.game_description.n_players, abs(current_cooperation_level))
            if self.punishment_level > self.past_cooperation:
                self.past_cooperation = self.punishment_level
        else:
            self.punishment_level = min(self.game_description.n_players, self.punishment_level)
            self.forgiveness_level = 0
        return self.past_cooperation

class Strategy_EXPLOITATIVE_86(BaseStrategy):
    """
    A strategy that cooperates at the start and adapts cooperation based on the number of opponents who cooperated in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = math.ceil(game_description.n_players * 0.5) - 1
        self.all_defect_threshold = game_description.n_players - (self.cooperation_threshold + 1)
        self.last_round = game_description.n_rounds

    def __call__(self, state: GameState, history: PlayerHistory):
        if state.round_number == 0:
            return Action.C
        cooperation_level = sum(history.opponent_actions[-1])
        if cooperation_level > self.all_defect_threshold or cooperation_level <= self.cooperation_threshold:
            return Action(int(cooperation_level > self.cooperation_threshold))
        elif cooperation_level == self.all_defect_threshold + 1:
            self.last_round = state.round_number
        return Action.D

class Strategy_EXPLOITATIVE_92(BaseStrategy):
    """
    Tit-for-Tat with Adaptation strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperated_last_round = False
        self.opponent_defected_once = False
        self.initial_cooperation = True
        self.minimum_cooperation = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None or state.round_number == 0:
            self.initial_cooperation = True
            self.opponent_defected_once = False
            self.cooperated_last_round = True
            return Action.C
        self.cooperated_last_round = history.my_actions[-1]
        self.opponent_defected_once = any(history.opponent_actions[:, -1]) and (not self.opponent_defected_once)
        if state.round_number == 1 or (not self.cooperated_last_round and self.opponent_defected_once):
            return Action.D
        opponent_cooperators = sum(history.opponent_actions[:, -1])
        if opponent_cooperators >= self.minimum_cooperation:
            if not self.cooperated_last_round and state.round_number > 2:
                return Action.C
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_95(BaseStrategy):
    """
    A Tit-for-Tat with Adaptation strategy for the Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros((game_description.n_rounds, game_description.n_players)))
        self.most_cooperators = None
        self.last_defection = -1

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.history.opponent_actions[-1, :].sum() < self.game_description.n_players - self.game_description.m:
            return Action.D
        self.update_history(state, history)
        self.find_most_cooperators()
        if self.last_defection >= 0 and state.round_number > self.last_defection + 1:
            self.last_defection = -1
        return self.get_action(state)

    def update_history(self, state: GameState, history: PlayerHistory):
        if state.round_number < len(self.history.my_actions):
            self.history.my_actions[-1] = history.my_actions[state.round_number - 1]
            self.history.my_payoffs[-1] = history.my_payoffs[state.round_number - 1]
        else:
            self.history.my_actions.extend(history.my_actions)
            self.history.my_payoffs.extend(history.my_payoffs)
        self.history.opponent_actions[state.round_number, :] = history.opponent_actions[-1, :]
        self.history.opponent_payoffs[state.round_number, :] = history.opponent_payoffs[-1, :]

    def find_most_frequent_cooperators(self):
        if not self.most_cooperators:
            self.most_cooperators = []
        cooperators = [i for i, x in enumerate(self.history.my_actions[-self.game_description.n_rounds + 1:]) if sum(x) == len(x)]
        most_frequent_count = max(set([len(c) for c in cooperators]))
        self.most_cooperators = [c for c in cooperators if len(c) == most_frequent_count]

    def find_most_recent_defection(self):
        self.last_defection = -1
        for i, actions in enumerate(self.history.my_actions[-self.game_description.n_rounds + 1:]):
            if sum(actions) == len(actions) - 1 and i > self.last_defection:
                self.last_defection = i

    def get_action(self, state: GameState):
        self.find_most_recent_defection()
        if len(self.most_cooperators) == 0:
            return Action.D
        if self.last_defection >= 0 and state.round_number <= self.last_defection + 1:
            return Action.D
        return self.most_cooperators[random.randint(0, len(self.most_cooperators) - 1)].action

class Strategy_EXPLOITATIVE_102(BaseStrategy):
    """
    Adaptive Tit-for-Tat strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m - 1
        self.current_round = 0
        self.history = PlayerHistory(my_actions=np.zeros(self.game_description.n_rounds, dtype=bool), my_payoffs=np.zeros(self.game_description.n_rounds, dtype=float), opponent_actions=np.zeros((self.game_description.n_rounds, self.game_description.n_players), dtype=bool), opponent_payoffs=np.zeros((self.game_description.n_rounds, self.game_description.n_players), dtype=float))

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if history is not None:
            self.history = history
            self.current_round = state.round_number
        if state.round_number == 0:
            cooperators = sum(self.history.opponent_actions[self.current_round - 1, :])
            if cooperators < self.m:
                return Action.D
            else:
                return Action.C
        cooperators = sum(self.history.opponent_actions[-1, :])
        if cooperators >= self.game_description.n_players // self.m:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_125(BaseStrategy):
    """
    A Tit-for-Tat with Adaptation strategy for the Collective Risk Dilemma game.
    This strategy cooperates in the first round and copies the opponent's last action in subsequent rounds,
    while also adapting its response to the number of consecutive defections or cooperations by an opponent.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_def_consecutive = math.ceil(game_description.n_rounds / 2) - 1
        self.n_coop_consecutive = self.n_def_consecutive

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round = history.opponent_actions[-1]
        consecutive_defections = sum(last_round[1:] if self.n_coop_consecutive > 1 else [last_round[-1]])
        consecutive_cooperations = sum(last_round[:-1] if self.n_def_consecutive > 1 else [last_round[0]])
        cooperate = history.opponent_actions[state.round_number - 1][-1] == Action.C and consecutive_cooperations >= self.n_coop_consecutive or (history.opponent_actions[state.round_number - 1][-1] == Action.D and consecutive_defections >= self.n_def_consecutive)
        return Action(int(cooperate)) if cooperate else Action.D

class Strategy_EXPLOITATIVE_135(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT) strategy for Collective Risk Dilemma games.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.T = 0.6
        self.rounds_for_calculating_average = int(self.game_description.n_players * self.game_description.n_rounds * 0.2)
        self.cooperation_history = [0] * (self.rounds_for_calculating_average + 1)

    def __call__(self, state: GameState, history: None | PlayerHistory):
        action = Action.C
        if state.round_number == 0 or history is None:
            action = Action.C
        elif history is not None:
            if sum(history.opponent_actions[-1, :]) >= self.m:
                action = Action.C
            else:
                action = Action.D
        if state.round_number > self.rounds_for_calculating_average and history is not None:
            average_cooperation_rate = np.mean(history.my_actions[-self.rounds_for_calculating_average:])
            if average_cooperation_rate > self.T:
                self.m = max(1, self.m - self.m // 20)
            elif average_cooperation_rate < self.T:
                self.m = min(self.game_description.n_players - 1, self.m + self.m // 20)
        if state.round_number == self.game_description.n_rounds - 1:
            my_payoffs = history.my_payoffs[-self.game_description.n_rounds:]
            if sum(history.opponent_actions[-1, :]) < self.m and np.max(my_payoffs) > my_payoffs[state.round_number - 1]:
                action = Action.C
        return action

class Strategy_EXPLOITATIVE_152(BaseStrategy):
    """
    A Tit-for-Tat strategy with adaptive cooperation threshold (TFTAT).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = 1
        self.consecutive_defects = 0
        self.consecutive_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            cooperators = 0
        else:
            cooperators = sum(history.opponent_actions[-1])
        if self.consecutive_defects > self.game_description.n_players - self.game_description.m:
            self.cooperation_threshold += (self.consecutive_defects - (self.game_description.n_players - self.game_description.m)) / self.game_description.n_players
            self.consecutive_defects = 0
        elif self.consecutive_cooperators > self.game_description.n_players - self.game_description.m:
            self.cooperation_threshold -= (self.consecutive_cooperators - (self.game_description.n_players - self.game_description.m)) / self.game_description.n_players
            self.consecutive_cooperators = 0
        if cooperators < self.game_description.m:
            self.consecutive_defects += 1
        else:
            self.consecutive_cooperators += 1
        return Action.C if cooperators >= self.game_description.m and self.cooperation_threshold >= self.game_description.m or (history and history.opponent_actions[state.round_number - 2][0] == Action.D) else Action.D

class Strategy_EXPLOITATIVE_177(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Risk Aversion (TFT-ARA)
    Strategy Description: Initiate cooperation, punish non-cooperators if m-1 or more did not cooperate in the previous round. Adjust threshold for cooperation based on average number of cooperators from the last 'a' rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history_length = int(math.ceil(game_description.n_rounds / 10))
        self.average_cooperators = np.zeros((self.history_length,))

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperation_threshold = self.game_description.m
        average_cooperators = np.mean(self.average_cooperators[-self.history_length:])
        if average_cooperators < cooperation_threshold:
            cooperation_threshold += 1
        elif average_cooperators > cooperation_threshold:
            cooperation_threshold -= 1
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= cooperation_threshold and cooperators >= self.game_description.n_players // 2:
            return Action.C
        return Action.D

    def update_average(self, state: GameState):
        self.average_cooperators = np.roll(self.average_cooperators, -1)
        self.average_cooperators[-1] = sum(history.opponent_actions[-1, :]) / self.game_description.n_players

class Strategy_EXPLOITATIVE_209(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Risk Aversion (ATfTA-RA) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperate_count = 0
        self.previous_cooperators = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        else:
            cooperators = sum(history.opponent_actions[-1] if history is not None else [False] * self.game_description.n_players)
            k_factor = self.game_description.k * (self.cooperate_count / state.round_number) if state.round_number > 0 else float('inf')
            if cooperators >= self.game_description.m and k_factor > 2:
                return Action.C
            elif cooperators < self.game_description.m and k_factor <= 2:
                return Action.D
            else:
                if state.round_number > 1:
                    last_cooperators = history.opponent_actions[-2] if history is not None else [False] * self.game_description.n_players
                    majority_cooperated = sum(last_cooperators) >= self.game_description.m
                else:
                    majority_cooperated = True
                return Action.C if majority_cooperated else Action.D
        self.cooperate_count += int(Action.C == self.__class__.get_action())
        if history is not None:
            self.previous_cooperators.append(int(history.opponent_actions[-1][0]))

class Strategy_EXPLOITATIVE_210(BaseStrategy):
    """
    Tit-for-Tat with Variable Cooperation Threshold (TFT-VCT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.vct = self.game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        last_action = Action.D if history is None else history.my_actions[-1]
        cooperators = sum(history.opponent_actions[-1, :]) if history is not None else 0
        vct = max(cooperators, self.vct)
        if last_action == Action.C and state.round_number != self.game_description.n_rounds and (cooperators >= vct):
            return last_action
        elif last_action == Action.C and state.round_number == self.game_description.n_rounds:
            payoffs = [self._calculate_payoff(last_action, history, vct, self.game_description) for _ in range(state.round_number)]
            next_action = Action.C if np.mean(payoffs) >= self._calculate_payoff(Action.D, history, vct, self.game_description) else Action.D
            return next_action
        else:
            return Action.D

    def _calculate_payoff(self, action: Action, history: PlayerHistory, vct: int, game_description: CollectiveRiskDescription) -> float:
        cooperators = sum(history.opponent_actions[:len(history), :].T[action == Action.C].sum(axis=0))
        payoff = len(history) - 1 if action == Action.D else len(history) * (game_description.k - 1) if cooperators >= game_description.n_players // game_description.m else len(history) * game_description.k
        return payoff

class Strategy_EXPLOITATIVE_230(BaseStrategy):
    """A Tit-for-Tat Adaptive (TfT-A) strategy for the Collective Risk Dilemma game."""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.coop_tally = {i: 0 for i in range(1, self.game_description.n_players + 1)}

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if not history and state.round_number > 0:
            return Action.D
        coop_actions = np.zeros(self.game_description.n_players, dtype=np.bool_)
        if history and state.round_number > 1:
            cooperators = sum(history.opponent_actions[state.round_number - 2])
            coop_actions[:cooperators] = 1
        self._update_tally(coop_actions)
        if state.round_number == 1:
            return Action.D
        if sum(self.coop_tally.values()) >= self.game_description.n_players // 2:
            return Action.C
        return Action.D

    def _update_tally(self, coop_actions: np.ndarray) -> None:
        for i in range(1, self.game_description.n_players + 1):
            player = coop_actions[i - 1]
            if player:
                self.coop_tally[i] += 1
            else:
                self.coop_tally[i] = max(0, self.coop_tally[i] - 1)

class Strategy_EXPLOITATIVE_255(BaseStrategy):
    """
    Strategy name: Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)
    This strategy cooperates if the number of opponents who cooperated in the previous round is greater than or equal to the minimum required cooperators (m). The cooperation threshold dynamically adapts based on opponent behavior.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.act = game_description.n_players // 2
        self.total_payoff = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_cooperators = sum(history.opponent_actions[-1, :])
        cooperate = opponent_cooperators >= self.act and opponent_cooperators >= self.game_description.m
        payoff_if_cooperate = self.total_payoff + self.game_description.k if state.round_number == self.game_description.n_rounds - 1 else self.total_payoff
        payoff_if_defect = self.total_payoff
        if cooperate and payoff_if_cooperate > payoff_if_defect:
            self.act += min(self.game_description.n_players - self.act, 1)
            return Action.C
        elif opponent_cooperators < self.game_description.m:
            self.act -= max(1, self.act - self.game_description.n_players // 2)
        return Action.D

class Strategy_COLLECTIVE_18(BaseStrategy):
    """
    A Tit-for-Tat strategy with adaptation that cooperates initially, mimics a friendly and cooperative approach. In subsequent rounds, it decides to cooperate or defect based on its previous opponent's behavior:
        - If the opponent cooperated in the previous round, TfT-A also cooperates.
        - If the opponent defected in the previous round, TfT-A defects in the current round as a punishment and then switches back to cooperation in the next round to see if the opponent will reciprocate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = int((game_description.n_players - game_description.m) / 2)
        self.score = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is None or len(history.opponent_actions) < state.round_number + 1:
            opponent_action = Action.D
        else:
            opponent_action = history.opponent_actions[state.round_number - 1]
        self.score += 1 if opponent_action == Action.C else self.game_description.k ** (state.round_number - 1) + 1
        if state.round_number < self.game_description.n_rounds - 1:
            return Action.D if opponent_action == Action.D and self.score >= self.game_description.m else Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            other_player_total_payoff = np.sum(history.opponent_payoffs[-1])
            if self.score >= other_player_total_payoff:
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_91(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation (TFT-AC) Strategy
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.adaptation_rate = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number >= len(history.opponent_actions):
            return Action.C
        else:
            most_recent_opponent_action = history.opponent_actions[-1]
            num_cooperators_in_last_round = np.sum(most_recent_opponent_action)
            if num_cooperators_in_last_round >= self.game_description.m:
                self.adaptation_rate = min(self.game_description.n_players / self.game_description.n_rounds * 0.5, 1)
            adaptation_decision = random.choice([Action.C, most_recent_opponent_action[-1]]) if random.random() < self.adaptation_rate else most_recent_opponent_action[-1]
            return adaptation_decision

class Strategy_COLLECTIVE_118(BaseStrategy):
    """
    Tit-for-Tat Adaptive (TFT-A) strategy for Collective Risk Dilemma game
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.x = int(math.ceil(game_description.n_rounds * 0.1))
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            opponent_actions = np.zeros(self.game_description.n_rounds, dtype=np.bool_)
            return self.__call__((GameState(state.round_number + 1), PlayerHistory(opponent_actions)))
        current_round = state.round_number - 1
        opponent_cooperators = sum(history.opponent_actions[current_round, :])
        if opponent_cooperators >= self.m:
            return Action.C
        if (current_round + 1) % self.x == 0:
            return Action.C
        else:
            return Action.C if history.opponent_actions[-1, -1] == Action.C.value else Action.D

class Strategy_COLLECTIVE_123(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.alpha = 0.2
        self.player_histories = {}

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None:
            self.player_histories[self.__class__] = PlayerHistory(my_actions=np.array([[Action.C]], dtype=bool), my_payoffs=np.array([]), opponent_actions=np.zeros((1, self.game_description.n_players), dtype=bool), opponent_payoffs=np.zeros(self.game_description.n_players))
        else:
            self.player_histories[self.__class__] = history
        if len(self.player_histories[self.__class__].my_actions) < state.round_number + 1:
            self.player_histories[self.__class__].my_actions = np.concatenate([self.player_histories[self.__class__].my_actions, [Action.C]])
        opponent_cooperators = sum(self.player_histories[self.__class__].opponent_actions[-1, :])
        avg_cooperation = self.player_histories[self.__class__].my_payoffs[-1] / state.round_number if state.round_number > 0 else 1
        coop_probability = min(max(avg_cooperation * (1 - self.alpha), 0), 1)
        action = Action.C if random.random() < coop_probability else Action.D
        self.player_histories[self.__class__].my_actions = np.concatenate([self.player_histories[self.__class__].my_actions, [action]])
        self.player_histories[self.__class__].my_payoffs = np.concatenate([self.player_histories[self.__class__].my_payoffs, [0 if action == Action.D else 1 - opponent_cooperators + self.game_description.k]])
        return action

class Strategy_COLLECTIVE_165(BaseStrategy):
    """
    The Tit-for-Tat with Adaptive Cooperation Threshold (TFTC) strategy.
    It cooperates when a majority of players cooperated in the previous round,
    otherwise defects. The adaptive cooperation threshold adapts based on the average number of cooperators over a sliding window.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.window_size = int(np.ceil(0.5 * game_description.n_rounds))
        self.cooperation_threshold = np.zeros(game_description.n_rounds)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C if history is None else Action.D
        cooperators = np.sum(history.opponent_actions[-self.window_size:])
        cooperation_threshold = np.ceil(cooperators / self.window_size * self.game_description.n_players).astype(int)
        self.cooperation_threshold[state.round_number] = max(min(cooperation_threshold, self.game_description.m), 1)
        cooperated_last_round = np.sum(history.my_actions[-1]) >= self.cooperation_threshold[state.round_number - 1]
        return Action.C if cooperated_last_round else Action.D

class Strategy_COLLECTIVE_202(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold Strategy for Collective Risk Dilemma.
    This strategy initiates cooperation, reciprocates cooperation, punishes defection, and adapts the cooperation threshold based on the frequency of defections.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = int(game_description.m - 1) * (game_description.n_players // game_description.m)
        self.current_round = 0
        self.payoffs = [0] * game_description.n_rounds
        self.cooperation_counter = 0
        self.defection_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is not None and state.round_number == 0:
            return Action.C
        if history is not None:
            self.current_round += 1
            opponent_cooperators = sum(history.opponent_actions[self.current_round - 1])
            payoff = 1 - int(Action.D == history.my_actions[-1]) + self.game_description.k * (opponent_cooperators >= self.game_description.m)
            self.payoffs[self.current_round - 1] = payoff
            if Action.C == history.my_actions[-1]:
                self.cooperation_counter += 1
            elif Action.D == history.my_actions[-1]:
                self.defection_counter += 1
            if self.current_round >= self.game_description.n_rounds:
                total_payoff = sum(self.payoffs)
                return Action.C if total_payoff[0] > np.mean(total_payoff) else Action.D
            if self.defection_counter < self.cooperation_threshold and opponent_cooperators >= self.game_description.m:
                self.defection_counter = 0
                self.cooperation_threshold += 1
            elif self.defection_counter >= self.cooperation_threshold and opponent_cooperators < self.game_description.m:
                self.cooperation_threshold -= 1
        return Action.D if self.defection_counter > 0 else Action.C

class Strategy_COLLECTIVE_260(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATFT) for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros(game_description.n_rounds))

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if history is None:
            self.history.my_actions[0] = True
        else:
            last_action = self.history.my_actions[-1]
            cooperators = sum(self.history.opponent_actions[-1, :])
            if state.round_number == 0 or (last_action and cooperators >= self.game_description.m):
                self.history.my_actions[state.round_number] = True
            elif not last_action:
                self.history.my_payoffs[-1] += self.game_description.k if cooperators >= self.game_description.m else 1
                self.history.my_actions[state.round_number] = False
        return Action(int(self.history.my_actions[state.round_number]))

class Strategy_COLLECTIVE_272(BaseStrategy):
    """
    Implementation of the Tit-for-Tat-Adaptive strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.strategy = [Action.C] * self.game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if not history:
            return self.strategy[state.round_number]
        last_action = self.strategy[-1]
        current_cooperators = sum(history.opponent_actions[-1, :]) >= self.game_description.m
        if state.round_number == 0:
            return Action.C
        if current_cooperators and last_action == Action.C:
            self.strategy[-1] = Action.C
            return Action.C
        elif current_cooperators and last_action == Action.D:
            self.strategy[-1] = Action.D
            return Action.D
        elif not current_cooperators and last_action == Action.C:
            self.strategy[-1] = Action.C
            return Action.C
        elif not current_cooperators and last_action == Action.D:
            self.strategy[-1] = last_action
            return last_action
        elif len(history) >= self.game_description.n_rounds - 1 and history.opponent_actions[-2].sum() == (self.game_description.n_players - self.game_description.m + 1) * len(history.opponent_actions[-2]):
            self.strategy[-1] = Action.C
            return Action.C
        else:
            return Action.C

class Strategy_COLLECTIVE_293(BaseStrategy):
    """
    Implementation of the Tit-for-Tat with Adaptation (TFTA) strategy.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = []
        self.score = 0
        self.switch_threshold = int(self.game_description.n_players * self.game_description.k)

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if state.round_number == 0 or len(self.history) == 0:
            self.history.append(Action.C)
        else:
            strategy = ''.join([str(action) for action in self.history[-1:] + [Action.D] * self.switch_threshold])
            if strategy.count('C') > len(self.history) // 2:
                strategy += 'C'
            else:
                strategy += 'D'
            self.history.append(Action[strategy[-1]])
        return self.history[-1]

class Strategy_COLLECTIVE_318(BaseStrategy):
    """
    Adaptive Tit-for-Tat Strategy for Collective Risk Dilemma Game
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.state = 'cooperate'
        self.rounds_defected_against_player = {}
        self.forgiveness_counter = 0
        self.punishment_counter = 0
        self.last_cooperative_round = -1
        self.initial_defection_period = self.game_description.n_players // 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        action = Action.D
        if state.round_number >= self.initial_defection_period:
            if self.state == 'cooperate':
                if self.last_cooperative_round == -1 or history.round_number - self.last_cooperative_round >= self.game_description.n_players // 2:
                    cooperators = sum(history.opponent_actions[-1, :])
                    if cooperators >= self.game_description.m:
                        action = Action.C
                    else:
                        action = Action.D
                else:
                    player_index = history.opponent_actions[-1].argmax()
                    if self.player_in_defection(player_index):
                        self.punishment_counter += 1
                        if self.punishment_counter >= self.game_description.n_players // 5:
                            action = Action.C
                    else:
                        self.forgiveness_counter += 1
                        if self.forgiveness_counter >= self.game_description.n_players // 5:
                            action = Action.C
                    self.last_cooperative_round = history.round_number
            else:
                player_index = history.opponent_actions[-1].argmax()
                if history.opponent_payoffs[-1, player_index] == 0 or self.player_in_defection(player_index):
                    action = Action.D
                else:
                    action = Action.C
        return action

    def player_in_defection(self, player_index):
        if player_index not in self.rounds_defected_against_player:
            self.rounds_defected_against_player[player_index] = 0
        self.rounds_defected_against_player[player_index] += 1
        if self.rounds_defected_against_player[player_index] > self.punishment_counter:
            return True
        return False

class Strategy_COLLECTIVE_376(BaseStrategy):
    """
    A Tit-for-Tat Adaptive Strategy that cooperates initially and adapts to the actions of opponents in subsequent rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_cooperators = [0] * (game_description.n_players - 1)
        self.player_strategy = Action.C
        self.history_length = 0
        self.switching_round = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or (state.round_number > 0 and (not self.history_length)):
            return self.player_strategy
        self.history_length += 1
        if self.history_length < state.round_number:
            return self.player_strategy
        if self.switching_round is None or state.round_number == self.switching_round + 2:
            self.opponent_cooperators = [sum(history.opponent_actions[:, i]) for i in range(self.game_description.n_players - 1)]
            if history.opponent_actions[state.round_number - 1, self.player_index - 1] != self.player_strategy:
                self.switching_round = state.round_number
                if self.player_strategy == Action.C and history.opponent_actions[state.round_number - 1, self.player_index - 1] == Action.D:
                    self.player_strategy = Action.D
                elif self.player_strategy == Action.D and history.opponent_actions[state.round_number - 1, self.player_index - 1] == Action.C:
                    self.player_strategy = Action.C
        if state.round_number == state.round_number - (self.game_description.n_players - self.opponent_cooperators.index(max(self.opponent_cooperators)) + 1):
            return Action.C
        return self.player_strategy

class Strategy_COLLECTIVE_400(BaseStrategy):
    """
    A Tit-for-Tat Adaptive strategy that considers the k factor in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = int(game_description.n_players * game_description.m / 100)
        self.last_round = game_description.n_rounds - 1
        self.k_factor = game_description.k
        self.memory = [-1] * self.last_round

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_action = self.memory[state.round_number - 1] if state.round_number > 0 else -1
        if opponent_action == -1 or (state.round_number >= self.min_cooperators and np.count_nonzero(history.opponent_actions[:, state.round_number]) >= self.min_cooperators):
            return Action.C
        return Action.D

    def remember_opponent_action(self, opponent_action: bool) -> None:
        self.memory[self.last_round - self.memory.index(opponent_action)] = opponent_action

class Strategy_COLLECTIVE_422(BaseStrategy):
    """
    Strategy name: Adaptive Tit-for-Tat for Collective Risk Dilemma
    Strategy summary: A cooperative strategy that conditions cooperation on the actions of other players.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_cooperation = 0
        self.last_round_coop_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            self.last_cooperation = 1
            return Action.C
        elif history is not None and self.last_cooperation == 1:
            if np.sum(history.opponent_actions[-self.game_description.m:, :]) >= self.game_description.m:
                self.last_cooperation = 1
                return Action.C
            else:
                self.last_cooperation = 0
                return Action.D
        elif history is not None and self.last_cooperation == 0:
            if np.sum(history.opponent_actions[-self.game_description.m:, :]) < self.game_description.m:
                self.last_cooperation = 1
                return Action.C
            else:
                self.last_cooperation = 0
                return Action.D
        if state.round_number == state.round_number - self.game_description.n_rounds and history is not None:
            self.last_cooperation = 1
            self.last_round_coop_count = np.sum(history.opponent_actions[-self.game_description.m:, :])
            if self.last_round_coop_count >= self.game_description.m:
                return Action.C
        elif state.round_number == 1 and history is not None:
            self.last_cooperation = 0
            self.last_round_coop_count = np.sum(history.opponent_actions[-self.game_description.m + 1:, :])
            if self.last_round_coop_count < self.game_description.m - 1:
                return Action.D
        elif history is not None and self.last_cooperation == 0:
            if np.sum(history.opponent_actions[-self.game_description.m:, :]) >= self.game_description.m:
                self.last_cooperation = 1
                return Action.C

class Strategy_COLLECTIVE_474(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Threshold (TFTA)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_duration = math.ceil(self.game_description.n_rounds / 2)
        self.previous_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and state.round_number > 1:
            self.previous_cooperators = sum(history.opponent_actions[state.round_number - 1, :])
            if self.previous_cooperators >= self.game_description.m or state.round_number == self.game_description.n_rounds:
                return Action.C
            n_c = max(0, self.previous_cooperators - min(self.game_description.n_players - self.previous_cooperators, self.game_description.m))
            alpha = max(0, min(1, n_c / (self.game_description.n_players - self.previous_cooperators)))
            n_alpha = math.floor(alpha * self.game_description.n_players)
            if n_alpha >= self.game_description.m:
                return Action.C
        return Action.D

    def punish(self):
        self.punishment_duration -= 1

class Strategy_COLLECTIVE_476(BaseStrategy):
    """Adaptive Tit-for-Tat (ATfT) Strategy for Collective Risk Dilemma"""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(my_actions=np.array([[False]], dtype=bool), my_payoffs=np.array([0.0], dtype=float), opponent_actions=np.array([[False]], dtype=bool, ndmin=2), opponent_payoffs=np.array([0.0], dtype=float))

    def __call__(self, state: GameState, history: PlayerHistory | None=None):
        if history is None:
            self.history = PlayerHistory(my_actions=np.array([[False]], dtype=bool), my_payoffs=np.array([0.0], dtype=float), opponent_actions=np.array([[False]], dtype=bool, ndmin=2), opponent_payoffs=np.array([0.0], dtype=float))
        if state.round_number == 0:
            self.history.my_actions[-1] = [True]
            return Action.C
        last_round = state.round_number == self.game_description.n_rounds
        if last_round:
            cooperators = np.sum(self.history.opponent_actions[:, -1])
            if cooperators >= self.game_description.m and np.any(self.history.my_actions[-1]):
                return Action.C
            else:
                return Action.D
        predecessor = (self.history.opponent_actions.shape[0] - 1) % self.game_description.n_players
        cooperators = np.sum(self.history.opponent_actions[:, predecessor])
        if cooperators >= self.game_description.m:
            self.history.my_actions[-1] = [self.history.opponent_actions[predecessor, -1]]
            return Action.C
        else:
            self.history.my_actions[-1] = [False]
            return Action.D

class Strategy_COLLECTIVE_482(BaseStrategy):
    """
    Tit-for-Tat Adaptive (TfTA) for Collective Risk Dilemma

    This strategy cooperates if the majority of opponents cooperated in the last few rounds,
    mimics opponent's previous action when the majority is one short of cooperating, and defects otherwise.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_n_rounds = self.game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return random.choice([Action.C, Action.D])
        last_n_rounds = history.opponent_actions[-self.last_n_rounds:]
        cooperation_count = np.sum(np.sum(last_n_rounds, axis=0))
        if cooperation_count >= self.game_description.m:
            return Action.C
        elif cooperation_count == self.game_description.m - 1:
            last_cooperators = np.argwhere(np.sum(last_n_rounds, axis=0))[:, 0]
            return Action(self.__class__.__name__ in last_cooperators) if len(last_cooperators) > 0 else Action.D
        else:
            return Action.D

    def __str__(self):
        return f'Tit-for-Tat Adaptive (TfTA)'

class Strategy_EXPLOITATIVE_163(BaseStrategy):
    """
    A strategy that mimics the Tit-for-Tat with Adaptive Cooperation in Collective Risk Dilemma games.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m - 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None and state.round_number == 0:
            return Action.C
        cooperators = np.sum(history.opponent_actions[:state.round_number + 1, -1])
        if cooperators >= self.min_cooperators or state.round_number == state.round_number + 1:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_260(BaseStrategy):
    """
    Tit-for-Tat strategy with adaptations for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and history.my_actions.size > 0:
            coop_count = np.sum(history.opponent_actions[-1, :])
            if coop_count >= self.m:
                return Action.C
        return Action.D

    def last_round(self, state: GameState, current_history: PlayerHistory) -> Action:
        if current_history.my_actions.size > 0:
            coop_count = np.sum(current_history.opponent_actions[-1, :])
            if coop_count >= self.m:
                return Action.C
        return Action.D

    def new_game(self, state: GameState) -> Action:
        return Action.C

class Strategy_EXPLOITATIVE_265(BaseStrategy):
    """
    A strategy that cooperates when a majority of opponents have cooperated in the last few rounds,
    but with a small probability 'p' of deviating from this rule. The strategy is designed to be robust against
    predictability by introducing some variance.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n = game_description.n_players
        self.p = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            cooperate = False if random.random() < self.p else True
        else:
            num_cooperators = np.sum(history.opponent_actions[-self.game_description.n_rounds:, -1])
            cooperate = num_cooperators >= self.m * self.n if num_cooperators > 0 else False
            cooperate = False if random.random() < self.p and (not cooperate) else cooperate
        return Action.C if cooperate else Action.D

class Strategy_EXPLOITATIVE_272(BaseStrategy):
    """
    A Tit-for-Tat Adaptive Strategy for the Collective Risk Dilemma Game
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is not None:
            last_round = len(history.opponent_actions) - 1
            cooperators = sum(history.opponent_actions[last_round, :])
            if last_round == self.game_description.n_rounds - 1:
                return Action.C
            if self.n_players // 2 <= cooperators < self.n_players:
                return Action.C
            if cooperators < self.m - 1 or (len(history.opponent_actions) == 2 and np.all(history.opponent_actions[last_round, :] == False)):
                return Action.C
            if cooperators >= self.m:
                return Action.D
            for i in range(last_round):
                if history.opponent_actions[i, :].astype(int).sum() == self.m and history.opponent_actions[last_round, :][np.argmax(history.opponent_actions[last_round, :])] == False:
                    return Action.D
        return Action.C

class Strategy_EXPLOITATIVE_278(BaseStrategy):
    """
    A Tit-for-Tat with Adaptation (TfTA) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or state.round_number == len(history.opponent_actions):
            return Action.C
        cooperators = sum(history.opponent_actions[state.round_number - self.m:state.round_number, :])
        if cooperators >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_315(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Escalation (ATFE) for the Collective Risk Dilemma game
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.n_players // 2
        self.escalation_factor = 3
        self.cooperation_history = [Action.C]
        self.defection_history = []
        self.punishment_counter = 0
        self.reward_counter = 0
        self.rounds_played = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.rounds_played += 1
        if history is not None:
            self.cooperation_history.append(0) if all(history.opponent_actions[-1]) else self.cooperation_history.append(1)
            self.defection_history.append(1 - all(history.opponent_actions[-1]))
        cooperators = sum(self.cooperation_history[-self.escalation_factor:])
        if cooperators >= self.threshold * self.escalation_factor:
            return Action.C
        elif self.defection_history[-1] > 0:
            self.punishment_counter += 1
            if self.punishment_counter >= self.escalation_factor:
                self.punishment_counter = self.reward_counter = 0
                return self._win_stay_lose_shift()
            else:
                return Action.D
        elif self.reward_counter >= self.escalation_factor:
            self.punishment_counter = self.reward_counter = 0
            return self._win_stay_lose_shift()
        else:
            self.punishment_counter, self.reward_counter = (1, 0)
            return Action.C

    def _win_stay_lose_shift(self) -> Action:
        if len(self.cooperation_history) >= self.escalation_factor or len(self.defection_history) >= self.escalation_factor:
            action = random.choice([Action.C, Action.D])
            if len(self.cooperation_history) > self.escalation_factor and self.cooperation_history[-1] == Action.C:
                action = Action.D
            elif len(self.defection_history) > self.escalation_factor and self.defection_history[-1] == Action.D:
                action = Action.C
        else:
            action = self.cooperation_history[-1]
        return action

class Strategy_EXPLOITATIVE_343(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_counter = 0
        self.min_coop = math.ceil(game_description.m / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            cooperators = sum(history.opponent_actions[0]) if history else 0
            return Action.C if cooperators >= self.min_coop else Action.D
        cooperators = sum(history.opponent_actions[-1, :])
        player_cooperated = history.my_actions[-1] if history else False
        if cooperators < self.min_coop:
            if player_cooperated:
                self.cooperation_counter = 0
            return Action.D
        self.cooperation_counter += int(player_cooperated and cooperators >= self.min_coop - 1)
        return Action.C if self.cooperation_counter >= self.game_description.m else Action.D

class Strategy_EXPLOITATIVE_366(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m - 1
        self.history = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.history = PlayerHistory(np.zeros(self.game_description.n_rounds, dtype=bool), np.zeros(self.game_description.n_rounds), np.zeros((self.game_description.n_rounds, self.game_description.n_players), dtype=bool), np.zeros((self.game_description.n_rounds, self.game_description.n_players)))
            return Action.C
        self.history.my_actions[-1] = self.cooperation_threshold >= self.cooperation_threshold
        self.history.my_payoffs[-1] = self.calculate_payoff()
        cooperators = sum(self.history.opponent_actions[-1, :])
        if cooperators < self.game_description.m:
            self.cooperation_threshold = max(0, self.cooperation_threshold - 1)
        elif cooperators >= self.game_description.n and cooperators <= self.game_description.m * self.game_description.n:
            self.cooperation_threshold = min(self.cooperation_threshold + 1, self.game_description.n - 1)
        return Action(int(self.cooperation_threshold >= self.history.my_actions[-1]))

    def calculate_payoff(self):
        if np.sum(self.history.opponent_actions[-1, :]) < self.game_description.m:
            return 1 - self.history.my_actions[-1]
        else:
            return 1 - self.history.my_actions[-1] + self.game_description.k

class Strategy_EXPLOITATIVE_376(BaseStrategy):
    """
    Tit-for-Tat Strategy with slight modifications for Collective Risk Dilemma.
    Cooperates in the first round to encourage cooperation from others.
    In subsequent rounds, cooperate if at least m players cooperated in the previous round. Otherwise, defect to punish non-cooperators.
    If a player switches from defection to cooperation (after punishment), immediately reciprocate the cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.previous_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        current_cooperators = sum(history.opponent_actions[-1, :])
        self.previous_cooperators = current_cooperators
        if current_cooperators >= self.m:
            return Action.C
        elif self.previous_cooperators >= self.m and current_cooperators < self.m:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_383(BaseStrategy):
    """
    Adaptive Tit-for-Tat Strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.round_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is not None and len(history.opponent_actions) > 0:
            self.round_history.append(state.round_number)
        if len(self.round_history) > 0 and state.round_number == self.round_history[-1] + 1:
            cooperators = sum(history.opponent_actions[self.round_history[-1], :])
            if cooperators >= self.game_description.m:
                return Action.C
        if state.round_number == len(self.round_history):
            return Action.C
        last_defector = None
        for i, action in enumerate(history.opponent_actions[-1]):
            if action:
                if last_defector is not None:
                    break
                last_defector = i + 1
        if history and state.round_number > last_defector and self.round_history:
            return history.opponent_actions[self.round_history[-1]][last_defector - 1]
        return Action.D

class Strategy_EXPLOITATIVE_411(BaseStrategy):
    """Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)"""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.w = int(game_description.n_players * 0.8)
        self.personal_best = 0
        self.history = np.zeros((self.w,), dtype=np.bool_)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        coop_count = sum(history.opponent_actions[-self.w:, -1]) if history else self.personal_best
        cooperators = sum(history.opponent_actions[-1, :])
        if coop_count >= self.game_description.m and cooperators >= self.game_description.m:
            return Action.C
        elif coop_count >= self.game_description.m - 1 or cooperators < self.game_description.m - 1:
            return Action.D
        else:
            self.history[-1] = bool(cooperators)
            self.history = np.roll(self.history, -1)
            if coop_count + cooperators >= self.game_description.m:
                self.personal_best = cooperators
            return Action(self.history[-1])

class Strategy_EXPLOITATIVE_417(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_coop_threshold = game_description.m
        self.rounds_played = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-1] if history else [0])
        cooperation_percentage = cooperators / self.game_description.n_players * 100 if cooperators > 0 else 0
        new_threshold = self.min_coop_threshold + cooperation_percentage * (self.game_description.n_players - self.min_coop_threshold) // 100
        self.rounds_played += 1
        if cooperators >= new_threshold:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_424(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation (TFTA)

    This strategy follows a cooperative stance in the first round, and then adapts its actions based on the most frequent cooperator among all players in the previous round.
    If the most frequent cooperator cooperated, it also cooperates; otherwise, it defects. In the last round, it always defects to maximize individual payoff.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperators_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if len(self.cooperators_history) < state.round_number + 1:
            self.cooperators_history.append(sum(history.opponent_actions[state.round_number - 1]))
        if history is None or state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        most_cooperative_player = np.argmax(history.opponent_actions[state.round_number - 1])
        if history.opponent_actions[state.round_number - 1][most_cooperative_player] == Action.C:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_458(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_coop = game_description.m
        self.k = game_description.k
        self.threshold_reached = False
        self.historical_cooperation = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None:
            self.historical_cooperation = [False] * (state.round_number - 1)
            self.threshold_reached = False
        else:
            n_c = sum(history.opponent_actions[-1, :])
            self.historical_cooperation.append(n_c >= self.min_coop)
            self.threshold_reached = n_c >= self.min_coop - 1 and any(self.historical_cooperation[-2:])
        return Action.C if state.round_number == self.game_description.n_rounds or (n_c >= self.min_coop and self.threshold_reached) else Action.D

class Strategy_EXPLOITATIVE_463(BaseStrategy):
    """
    Implementation of the Tit-for-Tat strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.k = game_description.k
        self.prev_action_opponent = Action.D
        self.count_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is not None:
            self._update_history(history)
        action = self._determine_action()
        self.prev_action_opponent = action
        return action

    def _determine_action(self):
        if self.count_cooperators < self.m:
            return Action.D if self._has_recently_cooperated() else Action.C
        elif self.count_cooperators >= self.game_description.n_players // 2:
            return Action.C
        else:
            return self._has_recently_cooperated() and Action.C or Action.D

    def _update_history(self, history):
        if history.opponent_actions[-1, -1] and (not self._has_recently_defected()):
            self.count_cooperators += 1
        elif not history.opponent_actions[-1, -1] and self._has_recently_defected():
            self.count_cooperators -= 1

    def _has_recently_cooperated(self):
        return self.prev_action_opponent == Action.C

    def _has_recently_defected(self):
        return self.prev_action_opponent == Action.D and self.count_cooperators > 0

class Strategy_EXPLOITATIVE_464(BaseStrategy):
    """
    The Tit-for-Tat with Adaptation (TfTA) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros((game_description.n_rounds, game_description.n_players)))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.history.my_actions[0] = True
            return Action.C
        if state.round_number == 0:
            self.history.my_actions[0] = True
            return Action.C
        elif state.round_number == self.game_description.n_rounds:
            num_defectors = np.sum(self.history.opponent_actions[:, -1])
            if num_defectors > self.n - self.m:
                return Action.D
            else:
                return Action.C
        else:
            num_defectors = np.sum(self.history.opponent_actions[:, -1])
            if num_defectors > self.n - self.m:
                return Action.D
            else:
                self.history.my_actions[state.round_number] = True
                return Action.C

class Strategy_EXPLOITATIVE_476(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m
        self.last_round_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is not None and state.round_number > 0:
            self.last_round_cooperators = sum(history.opponent_actions[-1])
        if state.round_number == 0 or (state.round_number == 1 and self.last_round_cooperators < self.min_cooperators):
            return Action.D
        elif state.round_number == 1 and self.last_round_cooperators >= self.min_cooperators:
            return Action.C
        else:
            return Action.C if self.last_round_cooperators >= self.min_cooperators else Action.D

class Strategy_EXPLOITATIVE_484(BaseStrategy):
    """
    Tit-for-Tat Adaptive (TFT-A) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.f = math.ceil(game_description.n_players / 2)
        self.m = game_description.k * (game_description.k - 1) ** 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            return Action.D
        previous_cooperation = np.count_nonzero(history.opponent_actions[:state.round_number, :][-self.f:], axis=0)
        potential_reward = len(previous_cooperation) if np.count_nonzero(previous_cooperation >= self.game_description.m) > 0 else 1
        cooperators_this_round = np.count_nonzero(history.opponent_actions[state.round_number - 1, :])
        if state.round_number == history.my_actions.size and cooperators_this_round < self.game_description.m:
            pass
        elif previous_cooperation.size > 0:
            if cooperators_this_round >= self.game_description.m:
                return Action.C
            else:
                last_defection = np.argmax(history.opponent_actions[:, :state.round_number - 1] == Action.D)
                forgiveness_time_elapsed = state.round_number - (last_defection + self.f)
                if forgiveness_time_elapsed > 0:
                    return Action.D
        else:
            pass
        if cooperators_this_round >= self.game_description.m and previous_cooperation.size > 0:
            probability = (1 - history.my_actions[-self.f:]) ** self.m
        else:
            probability = 1
        random_chance = random.random()
        if probability < random_chance:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_493(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT)
    Summary: A cooperative strategy that retaliates when others defect, adapting to opponents' behavior.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.coop_rate = np.zeros(self.game_description.n_rounds)
        self.avg_opponent_coop_rate = np.zeros(self.game_description.n_rounds)
        self.cooperation_margin = 0.1
        self.last_round = -1
        self.min_cooperators = self.game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and self.last_round < state.round_number - 1:
            cooperators = sum(history.opponent_actions[self.last_round, :])
            self.coop_rate[self.last_round] += float(history.my_actions[self.last_round])
            self.avg_opponent_coop_rate[self.last_round] = cooperators / (state.round_number - 1)
            self.update_cooperation_rate()
            self.last_round += 1
        if state.round_number == self.last_round + 1:
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators < self.min_cooperators or state.round_number == self.game_description.n_rounds:
                return Action.D
        return Action.C if cooperators >= self.min_cooperators else Action.D

    def update_cooperation_rate(self):
        cooperation_diff = np.abs(self.avg_opponent_coop_rate[-1] - self.coop_rate[-1])
        self.coop_rate[self.last_round + 1] += self.cooperation_margin * (self.avg_opponent_coop_rate[-1] - self.coop_rate[-1]) if cooperation_diff > self.cooperation_margin else -self.cooperation_margin * (self.coop_rate[-1] - self.avg_opponent_coop_rate[-1]) if cooperation_diff < -self.cooperation_margin else 0

class Strategy_EXPLOITATIVE_508(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat with Risk Aversion (ATfTra)

    Strategy Description: ATfTra cooperates by default and defects in response to defections from other players, maintaining a competitive edge in the game. The strategy is adaptive as it adjusts its actions based on past actions of other players and aims to meet the minimum cooperation threshold when needed.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.known_defectors = set()
        self.history = [[Action.C for _ in range(game_description.n_rounds)] for _ in range(game_description.n_players)]

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        my_action = self.get_my_action(state, history)
        self.update_history(my_action, state.round_number)
        return my_action

    def get_my_action(self, state: GameState, history: PlayerHistory) -> Action:
        if any([history.opponent_actions[state.round_number - 1, i] == Action.D for i in self.known_defectors]):
            return Action.D
        if sum(history.opponent_actions[state.round_number - 1, :]) >= self.game_description.m - 1:
            return Action.D
        return Action.C

    def update_history(self, action: Action, round_num: int) -> None:
        self.history[0][round_num] = action
        if action == Action.D:
            self.known_defectors.add(0)

class Strategy_EXPLOITATIVE_511(BaseStrategy):
    """
    A simple Tit-for-Tat strategy with an adaptive cooperation threshold for the Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = int(math.ceil(game_description.m / game_description.n_players * game_description.n_rounds))
        self.last_state = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        if self.last_state is None:
            self.last_state = state
            return Action.C
        cooperators_last_round = sum(history.opponent_actions[self.last_state.round_number - 1])
        if cooperators_last_round >= self.cooperation_threshold:
            action = Action.C
        elif state.round_number < math.ceil(self.game_description.n_rounds * 0.1) or (state.round_number - self.last_state.round_number + 1 >= 2 and cooperators_last_round > history.opponent_actions[self.last_state.round_number - 2].sum()):
            action = Action.C
        else:
            action = Action.D
        self.last_state = state
        return action

class Strategy_EXPLOITATIVE_512(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) Strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.ct = game_description.m
        self.payoff = [0] * game_description.n_rounds
        self.f = game_description.k / (2 * game_description.n_players)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        current_cooperators = sum(history.opponent_actions[-1]) if history else 0
        action = Action.C if current_cooperators >= self.ct else Action.D
        if action == Action.C:
            self.payoff[state.round_number - 1] = 1 - action.value + self.game_description.k * current_cooperators / self.game_description.n_players if current_cooperators >= self.game_description.m else 1 - action.value
            if self.payoff[state.round_number - 1] > self.game_description.n_rounds * (self.game_description.m / self.game_description.n_players):
                self.ct += self.f
        else:
            self.payoff[state.round_number - 1] = 1 + self.game_description.k * current_cooperators / self.game_description.n_players if current_cooperators >= self.game_description.m else 1
        return action

class Strategy_COLLECTIVE_514(BaseStrategy):
    """
    Titan Strategy for Collective Risk Dilemma game
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.csr_threshold = self.game_description.n_players * 2 // 3
        self.current_state = GameState(round_number=0)
        self.history = PlayerHistory(my_actions=np.zeros(1), my_payoffs=np.zeros(1), opponent_actions=np.zeros((1, game_description.n_players)), opponent_payoffs=np.zeros((1, game_description.n_players)))
        self.last_action = Action.C if self.csr() > 0 else Action.D

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        self.current_state = state
        self.history = history
        if self.current_state.round_number == 0:
            return self.last_action
        cooperators = sum(self.history.opponent_actions[-1, :])
        csr = self.csr()
        action = Action.C if csr > self.csr_threshold else Action.D if csr < self.csr_threshold and csr != 0 else self.last_action
        self.last_action = action
        return action

    def csr(self) -> float:
        total_rounds = len(self.history.my_actions)
        cooperative_rounds = np.sum((self.history.my_actions == Action.C).astype(np.float64))
        return cooperative_rounds / total_rounds if total_rounds > 0 else 0

class Strategy_COLLECTIVE_515(BaseStrategy):
    """
    Implementation of the Adaptive Tit-for-Tat strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = {}

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        if state.round_number == len(history.opponent_actions):
            total_cooperators = sum(history.my_actions) + sum(history.opponent_actions[-1])
            if total_cooperators >= self.game_description.m - 1:
                return Action.C
            else:
                return Action.D
        my_actions = history.my_actions[:state.round_number]
        opponent_actions = history.opponent_actions[:state.round_number, :]
        for i in range(1, self.game_description.n_players + 1):
            if i != self.__class__.__name__.lower():
                opponent_action = opponent_actions[state.round_number - 1][i - 1]
                if state.round_number > 1 and (opponent_action == my_actions[-1]) in self.history:
                    last_decision = self.history[opponent_action == my_actions[-1]]
                    if last_decision:
                        return Action.C
                    else:
                        return Action.D
                self.history[opponent_action == my_actions[-1]] = True
        total_cooperators = sum(my_actions) + sum(opponent_actions[state.round_number - 1])
        if total_cooperators >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_516(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT) Strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = math.ceil(game_description.n_players * game_description.m / game_description.n_players)
        self.previous_threshold = self.threshold

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        ratio = cooperators / self.game_description.n_players
        self.threshold = self.previous_threshold * 0.95 ** (1 - ratio)
        if ratio >= self.threshold:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_518(BaseStrategy):
    """
    The Tit-for-Tat Adaptive (TFT-A) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history_window_size = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and len(history.my_actions) < self.history_window_size):
            return Action.C
        most_cooperators = np.zeros((self.game_description.n_players,), dtype=np.int)
        max_cooperations = 0
        if history is not None:
            for player in range(self.game_description.n_players):
                cooperations = sum(history.opponent_actions[:, player])
                if cooperations > max_cooperations:
                    most_cooperators[:] = player * np.ones((self.game_description.n_players,), dtype=np.int)
                    max_cooperations = cooperations
            if max_cooperations == 0:
                return Action.D
        most_cooperators_indices = most_cooperators == max_cooperations
        if np.sum(most_cooperators_indices) > 1:
            last_cooperators = history.opponent_actions[-self.history_window_size:, most_cooperators_indices].any(-1)
            last_cooperation_index = (last_cooperators == 1).argmax()
            return Action(most_cooperators[last_cooperation_index])
        return Action(most_cooperators[0])

class Strategy_COLLECTIVE_520(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation (TFT-AC) Strategy
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.player_index = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C if self.player_index is None else Action.C if self.player_index % 2 != 1 else Action.D
        cooperators = sum(history.opponent_actions[-1, :])
        majority = math.ceil(self.game_description.n_players / 2)
        if state.round_number < self.game_description.n_rounds - 1:
            return Action.C if cooperators >= majority else Action.D
        second_to_last_cooperators = sum(history.opponent_actions[-2, :])
        if second_to_last_cooperators >= majority and state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_521(BaseStrategy):
    """Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma game."""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = self.game_description.m
        self.history_length = math.ceil(self.game_description.n_players * self.game_description.k) + 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperator_counts = np.sum(history.opponent_actions[:, -self.history_length:], axis=1)
        if np.any(cooperator_counts >= self.cooperation_threshold):
            return Action.C
        num_recent_defectors = cooperator_counts < self.cooperation_threshold
        recent_defection_count = np.sum(num_recent_defectors)
        if recent_defection_count >= self.history_length:
            self.cooperation_threshold += math.ceil(self.game_description.k / 2)
        return Action.D

class Strategy_COLLECTIVE_522(BaseStrategy):
    """
    Implementation of Tit-for-Tat Adaptive Cooperative (TFTAC) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.forgiveness = 1
        self.Fmin = 0.5
        self.F_decrease = 0.1

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or not history:
            return Action.C
        last_opponent_action = history.opponent_actions[-1][-1]
        self.forgiveness = max(self.Fmin, self.forgiveness - (1 - self.forgiveness) * self.F_decrease if last_opponent_action == Action.D else self.forgiveness)
        return Action.C if last_opponent_action == Action.C else Action.D if self.forgiveness > self.Fmin else Action.C

class Strategy_COLLECTIVE_524(BaseStrategy):
    """
    Implementation of the AC-TFT strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = math.ceil(game_description.n_players * 0.5)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-1])
        if cooperators >= self.cooperation_threshold:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_526(BaseStrategy):
    """
    Titan Strategy for Collective Risk Dilemma (TRD)
    This strategy employs a combination of Frequency Dependent Norms (FDN) and Grim Trigger to balance cooperation and defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.a = 0.5
        self.b = 0.2
        self.w = 3
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-self.w:, :])
        cooperator_fraction = cooperators / self.game_description.n_players
        p = min(1, self.a + self.b * cooperator_fraction)
        if np.sum(history.opponent_actions[-self.w:, :] < self.m) >= self.w:
            p = 0
        return Action.C if random.random() <= p else Action.D

class Strategy_COLLECTIVE_527(BaseStrategy):
    """
    A Tit-for-Tat with Adaptive Threshold (TFT-AT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.a = math.ceil(game_description.n_players / 2)
        self.last_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None or state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[state.round_number - 1, :])
        if self.last_cooperators >= self.game_description.m and state.round_number < self.game_description.n_rounds:
            self.a = max(self.a - 1, self.game_description.m)
        elif cooperators < self.a and state.round_number < self.game_description.n_rounds:
            self.a = min(self.a + 1, self.game_description.n_players)
        if cooperators >= self.a or state.round_number == self.game_description.n_rounds:
            return Action.C
        return Action.D

    def record_payoff(self, payoff: float):
        pass

class Strategy_COLLECTIVE_528(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation (TFT-AC) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m
        self.previous_round_cooperators = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None or self.previous_round_cooperators is None:
            self.previous_round_cooperators = np.sum(history.opponent_actions[state.round_number - 2, :])
        cooperators = np.sum(history.opponent_actions[-1, :])
        return Action.C if self.previous_round_cooperators >= self.min_cooperators and cooperators >= self.min_cooperators else Action.D

class Strategy_COLLECTIVE_530(BaseStrategy):
    """Adaptive Tit-for-Tat with Variable Defection Probability (ATFtvDP)"""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.d, self.c, self.e = (0.2, 0.6, 0.8)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        p_d = self.d if cooperators < self.game_description.m else self.c if cooperators == self.game_description.m else self.e
        return Action(random.choice([0, 1]) < p_d)

class Strategy_COLLECTIVE_531(BaseStrategy):
    """
    Adaptive Tit-for-Tat strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(np.zeros(self.game_description.n_rounds, dtype=bool), np.zeros(self.game_description.n_rounds), np.zeros((self.game_description.n_rounds, self.game_description.n_players), dtype=bool), np.zeros((self.game_description.n_rounds, self.game_description.n_players)))

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_cooperators = sum(history.opponent_actions[state.round_number - 1, :])
        if opponent_cooperators >= self.game_description.m:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_532(BaseStrategy):
    """
    Strategy name: Tit-for-Tat Adaptive (TfT-A)
    A cooperative strategy that responds in kind to cooperative actions from others while also being forgiving through its random deviations and adaptive epsilon factor.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.epsilon = 0.5
        self.min_cooperators = math.ceil(game_description.n_players * (game_description.m / 100))
        self.max_cooperators = math.floor(game_description.n_players * (1 - game_description.m / 100))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return random.choice([Action.C, Action.D])
        cooperators = sum(history.opponent_actions[-1, :]) if history else 0
        adjusted_cooperators = self.min_cooperators if cooperators < self.min_cooperators else min(self.max_cooperators, cooperators)
        epsilon_adjusted = self.epsilon * (adjusted_cooperators / self.game_description.m) ** 2 if adjusted_cooperators >= self.game_description.m else self.epsilon * (self.min_cooperators / cooperators) ** 2
        self.epsilon = min(max(self.epsilon - (1 - self.epsilon) * 0.05, 0.1), 0.9)
        return Action.C if adjusted_cooperators >= self.game_description.m and random.random() <= epsilon_adjusted else Action.D

class Strategy_COLLECTIVE_533(BaseStrategy):
    """
    A Tit-for-Tat with Cooperative Adaptation (TFTCA) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.alpha, self.beta, self.gamma = (0.1, 0.05, 0.02)
        self.propensity = 50
        self.history = np.zeros((self.n_rounds,), dtype=np.bool_)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.update_history(history)
        last_r_cooperators = np.sum(self.history[-self.n_rounds:])
        if last_r_cooperators > self.m + self.propensity * self.alpha:
            self.propensity += self.beta
        elif last_r_cooperators < self.m:
            self.propensity -= self.gamma
        return Action(int(np.random.rand() <= 1 - self.propensity))

    def update_history(self, history: PlayerHistory):
        if history is not None:
            self.history = np.append(self.history, history.my_actions[-1])

class Strategy_COLLECTIVE_534(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m
        self.last_round_cooperators = 0
        self.first_round = True

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        action = Action.D
        if state.round_number == 0:
            self.first_round = True
            action = Action.C
        else:
            self.last_round_cooperators = sum(history.opponent_actions[-1, :]) if history else 0
            if self.last_round_cooperators >= self.min_cooperators:
                action = Action.C
            elif history and self.first_round and (self.last_round_cooperators < self.min_cooperators) and history.my_actions[-1]:
                action = Action.D
            else:
                action = Action.C
                self.first_round = False
        return action

class Strategy_COLLECTIVE_535(BaseStrategy):
    """
    Strategy name: Tit-for-Tat with Adaptive Cooperation Threshold (TTFT)
    Strategy description: Reciprocates other players' actions while adjusting cooperation threshold based on game history.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = math.ceil((game_description.m + 0.1) * (game_description.n_players / 100))
        self.deviations = 0
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros(game_description.n_rounds))

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.history = history
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.cooperation_threshold:
            return Action.C
        return Action.D

    def update_cooperation_threshold(self):
        deviations = 0
        for round_index in range(len(self.history.opponent_actions) - 2, -1, -1):
            if self.history.opponent_actions[round_index] != self.history.opponent_actions[round_index + 1]:
                deviations += 1
        if deviations >= math.ceil(self.game_description.n_players / 4):
            self.cooperation_threshold += math.floor(self.cooperation_threshold * 0.05)
        elif deviations < math.ceil(self.game_description.n_players / 8):
            self.cooperation_threshold -= math.floor(self.cooperation_threshold * 0.05)

class Strategy_COLLECTIVE_536(BaseStrategy):
    """
    A Tit-for-Tat strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.opponent_history.append(history.opponent_actions[-1][0]) if history else self.opponent_history.append(False)
        if history and sum(history.opponent_actions[-1]) >= self.game_description.n_players // 2:
            return Action.C
        return Action(self.opponent_history[-1] ^ 1)

class Strategy_COLLECTIVE_537(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Threshold (TFT-AT) strategy for Collective Risk Dilemma games.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m
        self.t = math.floor(self.game_description.n_players / 2)
        self.average_cooperators = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        action = Action.D
        if history is not None and history.my_actions[-1] == Action.C:
            action = Action.C
        elif history is not None and history.opponent_actions[-self.t:-1].mean() >= self.m * 0.85:
            action = Action.D
        elif history is not None and state.round_number % self.t == 0:
            cooperators = history.opponent_actions[state.round_number - self.t:state.round_number].mean()
            if cooperators >= self.m * 1.1:
                self.m += 0.25
            elif self.m > 1 and cooperators <= self.m * 0.85:
                self.m -= 0.25
        return action

class Strategy_COLLECTIVE_538(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATFT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is not None:
            cooperators = np.sum(history.opponent_actions[-1])
            if cooperators >= self.cooperation_threshold and state.round_number < self.game_description.n_rounds - 1:
                return Action.C
            elif cooperators < self.cooperation_threshold:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_539(BaseStrategy):
    """
    Implementation of the Tit-for-Tat Adaptive Cooperative Strategy (TFTACS).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.t = game_description.m
        self.punishment_counter = 0

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1])
        if cooperators < self.game_description.m:
            self.punishment_counter += 1
            if self.punishment_counter > self.t:
                return Action.D
        else:
            self.punishment_counter = 0
        if state.round_number > 1 and self.t > 0:
            self.t -= 1
        return Action.C if self.punishment_counter == 0 else Action.D

class Strategy_COLLECTIVE_540(BaseStrategy):
    """
    A strategy that implements the Tit-for-Tat with Adaptive Cooperation (TFT-AC).
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m
        self.r = game_description.n_players
        self.k = game_description.k
        self.strategy = [Action.D] * game_description.n_rounds
        self.history = None
        self.probability = 0.5

    def __call__(self, state: GameState, history: PlayerHistory):
        if history is None and state.round_number == 0:
            return Action.C
        self.history = history
        if self.strategy[-1] == Action.D and self.min_cooperators <= sum(history.opponent_actions[-1]):
            self.probability = 0.5
            for i in range(state.round_number, self.game_description.n_rounds):
                if self.strategy[i] == Action.C:
                    self.probability *= 0.99
            self.strategy[state.round_number - 1] = np.random.choice([Action.C, Action.D], p=[self.probability, 1 - self.probability])
        elif self.strategy[-1] == Action.C and sum(history.opponent_actions[-1]) < self.min_cooperators - 1:
            self.probability = 0.5
            for i in range(state.round_number, self.game_description.n_rounds):
                if self.strategy[i] == Action.D:
                    self.probability *= 0.99
            self.strategy[state.round_number - 1] = np.random.choice([Action.C, Action.D], p=[self.probability, 1 - self.probability])
        return self.strategy[state.round_number - 1]

class Strategy_COLLECTIVE_541(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self._tau = self.m
        self._alpha = 0.1
        self._cooperators_counter = [0 for _ in range(self.n_players)]

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None or state.round_number == 0:
            return Action.C
        cooperators = sum([action for action in history.opponent_actions[-1] if action])
        if (cooperators >= self._tau or cooperators >= self.m) and state.round_number < self.game_description.n_rounds:
            return Action.C
        self._cooperators_counter[self.player_index()] = cooperators
        self._update_tau()
        return Action.D

    def _update_tau(self):
        self._tau = max(self._tau + self._alpha, self.m) if self._tau < self.n_players else self._tau

    def player_index(self) -> int:
        return hash((self.__class__.__name__, id(self))) % self.n_players

class Strategy_COLLECTIVE_542(BaseStrategy):
    """
    The Adaptive Tit-for-Tat (ATFT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_cooperated_last = None
        self.previous_round_defected = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.previous_round_defected = False
        if len(history.opponent_actions) > 0:
            self.opponent_cooperated_last = np.any(history.opponent_actions[-1])
            if not self.opponent_cooperated_last:
                self.previous_round_defected = True
        cooperation_threshold = math.ceil(self.game_description.n_players * (self.game_description.m / self.game_description.n_players))
        if len(history.opponent_actions) < cooperation_threshold:
            return Action.D
        if not self.opponent_cooperated_last:
            return Action.D
        if self.previous_round_defected:
            return Action.D
        return Action.C

class Strategy_COLLECTIVE_543(BaseStrategy):
    """
    A strategy that implements the Tit-for-Tat with Adaptive Threshold (TFT-AT) for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.m
        self.history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or len(self.history) == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1] if history else np.zeros((1, self.game_description.n_players), dtype=bool))
        if cooperators >= self.threshold and self.threshold != self.game_description.m:
            self.threshold = self.threshold
        elif cooperators < self.threshold:
            self.threshold = max(self.threshold - math.ceil((cooperators - self.game_description.m) / (self.game_description.n_players - 1)), self.game_description.m)
        return Action.C if self.threshold >= cooperators else Action.D

class Strategy_COLLECTIVE_544(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Risk Aversion Strategy in Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment = game_description.n_players - game_description.m

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and len(history.my_actions) == 0):
            return Action.C
        if len(history.my_actions) > 1:
            previous_round = history.my_actions[-2]
        else:
            previous_round = history.opponent_actions[state.round_number - 1, state.round_number % self.game_description.n_players]
        if previous_round == Action.C:
            return Action.C
        elif len(history.my_actions) > self.punishment and history.my_actions[-self.punishment - 1] == Action.C:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_545(BaseStrategy):
    """
    Tit-for-Tat Adaptive (TfTA) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.previous_round_cooperators = 0
        self.first_round = True

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.first_round = True
            return Action.C
        if not history:
            self.previous_round_cooperators = 0
        else:
            self.previous_round_cooperators = sum(history.opponent_actions[-1, :])
        cooperators_in_last_round = self.previous_round_cooperators
        if state.round_number == self.game_description.n_rounds:
            cooperators_in_last_round >= self.game_description.m
        current_action = Action.D
        if cooperators_in_last_round >= self.game_description.m:
            current_action = Action.C
        self.first_round = False
        return current_action

class Strategy_COLLECTIVE_546(BaseStrategy):
    """
    An adaptive version of the Tit-for-Tat strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = PlayerHistory(my_actions=np.array([True]), my_payoffs=np.array([0]), opponent_actions=np.zeros((1, game_description.n_players), dtype=bool), opponent_payoffs=np.zeros(1))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or not history:
            return Action.C
        self.history = history
        cooperators = np.sum(self.history.opponent_actions[-1, :])
        majority = int(np.floor((self.game_description.n_players + 1) / 2))
        return Action(cooperators > majority) if state.round_number > 0 else Action.C

class Strategy_COLLECTIVE_547(BaseStrategy):
    """
    A strategy that mimics the Tit-for-Tat Cooperation in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.previous_action = Action.C

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return self.previous_action
        if state.round_number == self.game_description.n_rounds:
            return Action.C
        if history is None:
            cooperators = random.randint(1, self.game_description.n_players) if state.round_number > 1 else 0
            self.update_previous_action(Action.C if cooperators >= self.game_description.m else Action.D)
            return self.previous_action
        cooperators = sum(history.opponent_actions[state.round_number - 1, :])
        if cooperators >= self.game_description.m:
            return self.previous_action
        return self.previous_action

    def update_previous_action(self, action: Action):
        self.previous_action = action

class Strategy_COLLECTIVE_548(BaseStrategy):
    """
    A strategy called Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) for the Collective Risk Dilemma game.

    This strategy cooperates initially and adapts its cooperation threshold based on previous round outcomes. It maintains trust if more than m players cooperated in the previous round, punishes non-cooperators if less than m players cooperated, and encourages cooperation when it is beneficial for the group.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = 1 - self.game_description.n_players / self.game_description.m
        self.history = None

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0 or not self.history:
            return Action.C
        last_round = len(self.history) - 1 if history else state.round_number - 1
        cooperators = np.sum(self.history['opponent_actions'][-(last_round + 1):, :])
        if cooperators >= self.game_description.m:
            return Action.C
        elif cooperators < self.game_description.m and self.cooperation_threshold > 0:
            self.cooperation_threshold -= 1 / self.game_description.n_rounds
            return Action.D
        else:
            return Action.C

    def update(self, state: GameState, payoffs: PlayerHistory):
        if self.history is None:
            self.history = payoffs.copy()
        else:
            self.history['my_actions'] = np.append(self.history['my_actions'], [payoffs['my_actions'][0]])
            self.history['my_payoffs'] = np.append(self.history['my_payoffs'], payoffs['my_payoffs'])
            self.history['opponent_actions'] = np.append(self.history['opponent_actions'], payoffs['opponent_actions'], axis=0)
            self.history['opponent_payoffs'] = np.append(self.history['opponent_payoffs'], payoffs['opponent_payoffs'])

class Strategy_COLLECTIVE_549(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperative_threshold = game_description.m
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros(game_description.n_rounds))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.history = PlayerHistory(np.zeros(self.game_description.n_rounds, dtype=bool), np.zeros(self.game_description.n_rounds), np.zeros((self.game_description.n_rounds, self.game_description.n_players), dtype=bool), np.zeros(self.game_description.n_rounds))
        if state.round_number == 0:
            coop_count = np.sum(history.opponent_actions[0]) if history is not None else 0
            self.cooperative_threshold = self.game_description.m
            return Action.C if coop_count >= self.game_description.m else Action.D
        else:
            coop_count = np.sum(history.opponent_actions[-1])
            self.cooperative_threshold = max(min(self.cooperative_threshold + (self.game_description.n_players - coop_count), self.game_description.n_players), 1)
            return Action.C if self.cooperative_threshold <= coop_count else Action.D
        self.history = history or self.history
        return self.history.my_actions[-1]

class Strategy_COLLECTIVE_550(BaseStrategy):
    """
    Implementation of the Tit-for-Tat with Adaptive Cooperation (TFT-AC) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperators_threshold = game_description.m - 1
        self.cooperation_cycle_length = math.floor((game_description.n_players + self.cooperators_threshold) / 2)
        self.current_round = 0
        self.opponent_history = {}
        self.payoff = 0

    def __call__(self, state: GameState, history: PlayerHistory):
        if state.round_number == 0 and history is None:
            return Action.C
        self.current_round = state.round_number
        opponent_cooperated = np.any(history.opponent_actions[self.current_round - 1])
        if opponent_cooperated:
            action = Action.C
            self.payoff += 1 if self.should_meet_threshold(history) else 0
        else:
            action = Action.D
            self.payoff += 1
        if self.current_round == self.game_description.n_rounds:
            if self.should_meet_threshold(history):
                return Action.C
            elif np.all(history.opponent_actions[self.current_round - 1]) and (not np.all(history.opponent_actions[-self.cooperation_cycle_length:])):
                self.opponent_history = {}
                return Action.D
            else:
                return action
        self.update_opponent_history(history)
        return action

    def update_opponent_history(self, history: PlayerHistory):
        for player in range(1, self.game_description.n_players + 1):
            if player not in self.opponent_history:
                self.opponent_history[player] = np.zeros(self.game_description.n_rounds)
            self.opponent_history[player][self.current_round - 1] = history.my_actions[self.current_round - 1]

    def should_meet_threshold(self, history: PlayerHistory):
        if np.all(history.opponent_actions[-self.cooperation_cycle_length:]) and np.sum(history.my_actions) >= self.cooperators_threshold:
            return True
        else:
            return False

class Strategy_COLLECTIVE_551(BaseStrategy):
    """
    Tit-for-Tat with Cooperative Adjustment (TFT-CA) strategy for the Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = min(max(1, self.game_description.m), self.game_description.n_players - 1)
        self.threshold = self.m
        self.history = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C if len(history or []) < self.game_description.m else Action.D
        if self.history is not None and self.history.opponent_actions[-1].sum() >= self.m:
            return Action.C
        if self.history is not None and self.history.opponent_actions[-1].sum() > self.game_description.n_players - 2 and (state.round_number < self.game_description.n_rounds):
            self.threshold += 1
            self.threshold = min(max(1, self.threshold), self.game_description.n_players - 1)
        return Action.D if self.history is None else Action(int(self.history.opponent_actions[-1].sum() >= self.threshold))

class Strategy_COLLECTIVE_552(BaseStrategy):
    """
    Strategy name: Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)
    Aims to promote cooperation by reciprocating cooperative actions from other players while punishing defection.
    The strategy is flexible enough to adapt to different opponent behaviors and changing game dynamics.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.b = int(math.ceil((self.n_players - (self.m - 1)) / 2))
        self.c = (self.m - 1) / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and len(history.opponent_actions) >= self.b:
            cooperators = sum(history.opponent_actions[-self.b:, :].flatten())
            cooperation_ratio = cooperators / self.b
            if cooperation_ratio >= self.c:
                return Action.C
        for _ in range(self.b):
            if history is not None and len(history.opponent_actions) > self.b - _:
                if sum(history.opponent_actions[-self.b + _:, :].flatten()) < self.n_players - self.m + 1:
                    return Action.C
        return Action.D

class Strategy_COLLECTIVE_553(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Threshold Strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = (self.game_description.n_players - self.game_description.m) // 2
        self.adapted_threshold = math.ceil(3 * self.game_description.n_players / 4)
        self.opponent_cooperation_count = 0
        self.opponent_defection_count = 0
        self.rounds_observed = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        if history.opponent_actions[-1][0]:
            self.opponent_cooperation_count += 1
        else:
            self.opponent_defection_count += 1
        self.rounds_observed += 1
        if self.rounds_observed >= self.game_description.n_players // 2:
            if self.opponent_cooperation_count > self.opponent_defection_count:
                self.threshold = min(self.adapted_threshold, 3 * self.game_description.n_players // 4)
            else:
                self.threshold = max((self.game_description.n_players - 2 * self.game_description.m) // 2, 1)
            self.opponent_cooperation_count = 0
            self.opponent_defection_count = 0
            self.rounds_observed = 0
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.threshold:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_554(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)
    Strategy cooperates initially and adapts cooperation based on the number of opponents who cooperated in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperative_threshold = game_description.m
        self.base_defection = random.uniform(0, 1)
        self.negative_effect = 2
        self.current_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            self.update_state(history)
        adp = self.base_defection * (1 + (self.current_cooperators / self.cooperative_threshold) ** self.negative_effect)
        if random.random() <= adp:
            return Action.D
        return Action.C

    def update_state(self, history):
        self.current_cooperators = sum(history.opponent_actions[-1])

class Strategy_COLLECTIVE_555(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat Adaptive Cooperation (TFTAC)
    Strategy Description: Cooperate if enough opponents cooperated in the previous round; defect otherwise.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.p_init = 0.5
        self.history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or not history:
            return Action.C if random.random() <= self.p_init else Action.D
        cooperators = np.sum(history.opponent_actions[-self.game_description.n_players:, :])
        cooperate_threshold = self.game_description.n_players * (self.game_description.m / self.game_description.n_players)
        if cooperators < cooperate_threshold - 1:
            return Action.D
        elif cooperators == cooperate_threshold - 1:
            return Action.C
        elif state.round_number < self.game_description.n_rounds:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_556(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation (TFT-AC)
    Strategy Description: A self-regulating strategy that is adaptive and robust to various opponent behaviors while maintaining a collective mindset of promoting cooperation when possible and punishing defection when necessary.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.player_with_max_cooperation = None
        self.most_frequent_cooperators = {}
        self.history = PlayerHistory(np.zeros(game_description.n_rounds, dtype=bool), np.zeros(game_description.n_rounds), np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros(game_description.n_rounds))

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        self.history = history
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        self.most_frequent_cooperators = {player: count for player, count in self.most_frequent_cooperators.items() if count <= cooperators}
        self.most_frequent_cooperators[next((player for player, count in self.most_frequent_cooperators.items() if player is not None), None)] = cooperators
        self.player_with_max_cooperation = next((player for player, count in self.most_frequent_cooperators.items() if player is not None), None)
        if self.player_with_max_cooperation is not None:
            return self.history.opponent_actions[self.history.opponent_actions.shape[0] - 1, self.player_with_max_cooperation]
        else:
            continue_defecting = np.all(np.logical_not(history.opponent_actions[-1, :]))
            return Action.C if not continue_defecting else Action.D

class Strategy_COLLECTIVE_557(BaseStrategy):
    """
    A collective risk dilemma strategy that cooperates initially and adapts the minimum number of cooperators based on historical data, fostering a more collaborative environment.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.threshold = self.m
        self.average_cooperators = np.zeros(self.game_description.n_rounds)
        self.b = min(int(self.game_description.n_rounds * 0.8), self.game_description.n_rounds - 1)
        self.alpha = 0.01
        self.beta = 0.01

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is not None:
            self._update_average_cooperators(history)
            cooperators = self._count_cooperators(history)
            if cooperators < self.threshold:
                self.threshold = max(self.threshold - self.alpha * (self.average_cooperators[-1] - self.m), 1)
            elif cooperators >= self.n_players - self.threshold:
                self.threshold = min(self.threshold + self.beta * (self.average_cooperators[-1] - self.m), self.n_players - 1)
        return Action.C if cooperators >= self.threshold else Action.D

    def _count_cooperators(self, history: PlayerHistory) -> int:
        return sum(history.my_actions[:-1])

    def _update_average_cooperators(self, history: PlayerHistory):
        self.average_cooperators = np.roll(self.average_cooperators, -1)
        self.average_cooperators[-1] = self._count_cooperators(history) / (self.b + 1)

class Strategy_COLLECTIVE_558(BaseStrategy):
    """
    Strategy name: Adaptive Tit-for-Tat with Risk Aversion (ATFRA)
    Summary: Adapts decision rules based on the number of cooperators in the previous round, rewarding other cooperators when threshold is met.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action(random.choice([0, 1]))
        cooperators = sum(history.opponent_actions[-1])
        if cooperators < self.m:
            return Action.D
        else:
            return Action.C + (Action.C - Action.D) * self.game_description.k if cooperators >= self.m * 2 else Action.C

class Strategy_COLLECTIVE_559(BaseStrategy):
    """
    A Tit-for-Tat Strategy for Collective Risk Dilemma game.
    Follows the majority's actions, encourages reciprocity and forgiveness.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = None

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if history is None:
            return Action.C
        self.history = history if history else PlayerHistory(np.zeros(state.round_number + 1, dtype=bool), np.zeros(state.round_number + 1), np.zeros((state.round_number + 1, self.game_description.n_players), dtype=bool), np.zeros((state.round_number + 1, self.game_description.n_players)))
        if state.round_number == len(self.history.my_actions):
            self.history.my_payoffs[-1] = (np.sum(self.history.my_actions) > self.game_description.n_players // 2) * (1 + self.game_description.k) + (np.sum(self.history.my_actions) <= self.game_description.n_players // 2)
        cooperators = np.sum(self.history.opponent_actions[-1, :])
        if cooperators >= self.game_description.n_players // 2:
            self.history.my_actions[-1] = True
        else:
            self.history.my_payoffs[-1] += 1 - self.history.my_actions[-1]
            self.history.my_actions[-1] = False
        return Action(int(self.history.my_actions[-1]))

class Strategy_COLLECTIVE_560(BaseStrategy):
    """
    A simple Tit-for-Tat with Adaptive Cooperation (TFT-AC) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m_threshold = math.ceil(game_description.n_players / 2) if game_description.n_players % 2 == 0 else (game_description.n_players + 1) // 2

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if state.round_number == 0 and history is None:
            return Action.C
        if history is not None:
            cooperators = sum(history.opponent_actions[state.round_number - 1, :])
            if cooperators >= self.m_threshold:
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_562(BaseStrategy):
    """
    Tit-for-Tat Adaptive (TfTA) Strategy for the Collective Risk Dilemma Game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_rate = 0.0
        self.threshold_T = int(math.ceil(self.game_description.n_players / 2))
        self.last_round_min_coop = math.ceil(self.game_description.m / self.game_description.n_players * (self.game_description.n_rounds - 1))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.update_cooperation_rate(history)
        if history is not None:
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators >= self.game_description.m / self.game_description.n_players * (1 + self.cooperation_rate):
                return Action.C
            consistent_coop = sum(history.opponent_actions[:self.threshold_T, :][:, -1]) >= self.threshold_T
            if consistent_coop and history.opponent_actions[-1, -1] == Action.D:
                return Action.C
        return Action.D

    def update_cooperation_rate(self, history: PlayerHistory):
        """
        Update the cooperation rate based on recent gameplay.
        """
        cooperators = sum(history.opponent_actions[-self.last_round_min_coop:-1, :][:, -1])
        self.cooperation_rate = cooperators / (self.last_round_min_coop + 1) if self.last_round_min_coop > 0 else 0.0

class Strategy_COLLECTIVE_563(BaseStrategy):
    """
    A Tit-for-Tat with Adaptive Cooperation (TFT-AC) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_coop_players = min(game_description.n_players, game_description.m)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if history and len(history.opponent_actions) > 0:
            last_round = history.opponent_actions[-1]
            if last_round is None or len(last_round) == 0:
                return Action.C
            if sum(last_round) >= self.min_coop_players:
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_564(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATfT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_coop_threshold = math.ceil(game_description.n_players * (game_description.m - 1) / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.min_coop_threshold:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_565(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation (TFT-AC) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.probability_cooperate = 0.5
        self.m = game_description.m
        self.last_opponents_actions = [None] * (self.game_description.n_players * self.m)
        self.count_cooperators = 0
        self.count_defectors = 0

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_actions = np.sum(history.opponent_actions, axis=0)
        self.last_opponents_actions[:len(opponent_actions)] = opponent_actions
        if len(self.last_opponents_actions) >= self.m:
            self.count_cooperators = sum(self.last_opponents_actions[:self.m])
            self.count_defectors = self.game_description.n_players * self.m - self.count_cooperators
            if self.count_cooperators >= self.m - 1:
                self.probability_cooperate = 0.75
            elif self.count_defectors >= self.m - 1:
                self.probability_cooperate = 0.25
        action = np.random.choice([Action.C, Action.D], p=[self.probability_cooperate, 1 - self.probability_cooperate])
        return action

class Strategy_COLLECTIVE_566(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat Adaptive Cooperation (TFTAC)
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.d = 5
        self.e = 3
        self.p = 10
        self.consecutive_defections = 0
        self.patience_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        opponent_actions = history.opponent_actions[-1] if history else np.zeros(self.game_description.n_players, dtype=bool)
        self.consecutive_defections += sum((opponent_action == Action.D for opponent_action in opponent_actions))
        action = Action.C if self.consecutive_defections < self.d else Action.D
        if self.consecutive_defections > self.d:
            if state.round_number - (self.e + 1) >= 0:
                action = Action.D
            else:
                self.consecutive_defections -= self.game_description.n_players - self.e - 1
        if state.round_number == self.game_description.n_rounds:
            action = Action.C
        if state.round_number > self.patience_counter and sum(opponent_actions) == len(opponent_actions):
            self.consecutive_defections = 0
            action = Action.D
            self.patience_counter += 1
        else:
            self.patience_counter = 0
        return action

class Strategy_COLLECTIVE_567(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Threshold strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and history.my_actions is not None:
            self.history_cooperators = np.count_nonzero(history.my_actions[-1])
        cooperators_needed = math.ceil((self.game_description.n_players + 1) / 2)
        if self.history_cooperators >= cooperators_needed - 1:
            return Action.C
        elif self.history_cooperators < cooperators_needed - 1:
            return Action.D
        else:
            return history.my_actions[-1] if history.my_actions[-1] == Action.C else Action.D

class Strategy_COLLECTIVE_569(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperative Threshold (TFT-ACT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.m
        self.historical_cooperators = [0]

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.historical_cooperators.append(sum(history.opponent_actions[-1, :]))
        cooperators = self.historical_cooperators[-1]
        if cooperators < self.threshold:
            return Action.D
        elif cooperators >= self.game_description.n_players:
            self.threshold = random.choice([math.ceil(self.threshold), self.threshold + 1])
            self.threshold = min(self.threshold, self.game_description.n_players)
        else:
            self.threshold += 1
            if self.threshold > self.game_description.n_players:
                self.threshold = self.game_description.n_players
        return Action.C

class Strategy_COLLECTIVE_570(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperators_count = 0
        self.rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        self.cooperators_count = np.sum(history.my_actions) if history else 0
        self.rounds += 1
        cooperation_level = self.cooperators_count / state.round_number * self.game_description.m / self.game_description.k
        own_action = Action(history.my_actions[-1].item() if history else 0)
        return Action.C if cooperation_level >= 1 and own_action == Action.C or cooperation_level >= self.game_description.m else Action.D

class Strategy_COLLECTIVE_572(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) Strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.m
        self.cooperate_penalty = 0.5
        self.min_coop_rate = game_description.m / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None or len(history.opponent_actions) < state.round_number + 1:
            return Action.D
        opponent_cooperated_last_round = sum(history.opponent_actions[-2, :]) > 0
        cooperation_rate = np.mean(history.my_actions[:state.round_number]) if state.round_number > 0 else self.min_coop_rate
        self.threshold = math.floor(self.threshold + (self.threshold - self.game_description.m) * (1 - (cooperation_rate - self.min_coop_rate)) ** self.cooperate_penalty)
        return Action.C if opponent_cooperated_last_round or cooperation_rate > self.min_coop_rate else Action.D

class Strategy_COLLECTIVE_573(BaseStrategy):
    """
    TFT-ACT strategy for Collective Risk Dilemma. Cooperate in the first round and adaptively decide to cooperate or defect based on the number of cooperators in the previous round.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = math.floor(game_description.n_players * 0.5)
        self.moving_average_window = int(game_description.n_rounds * 0.1)
        self.success_percentage = 0.6

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or not history:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.cooperation_threshold:
            return Action.C
        return Action.D

    def update_cooperation_threshold(self, successes: int, failures: int):
        total_rounds = self.moving_average_window
        moving_average = (successes + (total_rounds - failures)) / total_rounds if failures > 0 else 1
        if moving_average >= self.success_percentage:
            new_cooperation_threshold = min(self.cooperation_threshold + 1, self.game_description.n_players)
            self.cooperation_threshold = new_cooperation_threshold
        elif moving_average < 1 - self.success_percentage:
            new_cooperation_threshold = max(self.cooperation_threshold - 1, self.game_description.m + 1)
            self.cooperate_threshold = new_cooperation_threshold

class Strategy_COLLECTIVE_574(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation (TFT-AC) Strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m
        self.last_round_punishment = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            cooperate = history is None or len(history.my_actions) == 0
            return Action.C if cooperate else Action.D
        min_cooperators = self.min_cooperators - (1 if self.last_round_punishment else 0)
        cooperators = sum(history.opponent_actions[-1, :])
        return Action.C if cooperators >= min_cooperators else Action.D

    def update_last_round_punishment(self):
        self.last_round_punishment = True

class Strategy_COLLECTIVE_575(BaseStrategy):
    """
    The Tit-for-Tat Adaptive Cooperative (TFTAC) strategy mimics a trustworthy and forgiving opponent while being adaptive to various player behaviors throughout the game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.previous_opponent_action = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.previous_opponent_action = None
            return Action.C
        else:
            self.previous_opponent_action = np.mean(history.opponent_actions[:, -1])
            if self.previous_opponent_action == 1.0:
                return Action.C
            elif self.previous_opponent_action == 0.0:
                return Action.D
            else:
                return Action(int(self.previous_opponent_action))

class Strategy_COLLECTIVE_576(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Threshold (TFT-AT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.minimum_cooperators = self.game_description.m
        self.k = self.game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-1, :])
        if cooperators >= self.minimum_cooperators or state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_577(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Threshold (ATfTT) strategy for Collective Risk Dilemma game
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m
        self.n = self.game_description.n_players
        self.k = self.game_description.k
        self.threshold_reached = False
        self.cooperation_drought = 0

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        action = Action.D
        if state.round_number == 0 or len(history.opponent_actions) == 0:
            action = Action.C
            self.cooperation_drought = 0
        else:
            cooperators = sum(history.opponent_actions[-1])
            if cooperators >= self.m and (not self.threshold_reached):
                self.threshold_reached = True
                action = Action.C
            elif cooperators > 0 and history.opponent_actions[-self.cooperation_drought - 1][-1] == Action.C and self.threshold_reached:
                action = Action.C
            elif cooperators > 0 and history.opponent_actions[-self.cooperation_drought - 1][-1] != Action.C and self.threshold_reached:
                action = Action.D
            elif cooperators == 0 and len(history.opponent_actions) >= self.cooperation_drought + 1:
                action = Action.C
                self.cooperation_drought += 1
            else:
                self.cooperation_drought = 0
        if state.round_number == self.game_description.n_rounds - 1 and cooperators >= (self.game_description.n_rounds - 1) * self.m:
            action = Action.C
        return action

class Strategy_COLLECTIVE_578(BaseStrategy):
    """
    Adaptive Tit-for-Tat strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.break_cycle_chance = 0.2
        self.current_round = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is not None and state.round_number > 0:
            self.current_round = state.round_number
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[self.current_round - 1, :])
        if cooperators < self.game_description.m or (cooperators >= self.game_description.m and random.random() > self.break_cycle_chance):
            return Action.D
        return Action.C

class Strategy_COLLECTIVE_579(BaseStrategy):
    """
    Tit-for-Tat Adaptive Strategy (TFTA) for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m
        self.n = self.game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponents = history.opponent_actions[-1] if history else np.zeros(self.n, dtype=bool)
        cooperators = sum(opponents)
        majority = self.game_description.n_players * (self.m / self.n)
        if cooperators == self.n or cooperators >= majority:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_580(BaseStrategy):
    """
    The Adaptive Tit-for-Tat with Risk Aversion (ATfTR) strategy for Collective Risk Dilemma games.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = self.game_description.n_players
        self.n_rounds = self.game_description.n_rounds
        self.m = self.game_description.m
        self.k = self.game_description.k
        self.t = 10
        self.min_coop = math.floor(self.n_players * (self.m - 1) / self.t)
        self.cooperation_history = [0] * self.t

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :]) if history is not None else 0
        avg_coop = np.mean(self.cooperation_history[:self.t]) if self.cooperation_history[0] != 0 else 0
        self.cooperation_history = self.cooperation_history[1:] + [cooperators]
        self.cooperation_history = self.cooperation_history[-self.t:]
        if avg_coop >= self.min_coop and cooperators >= self.m:
            return Action.C
        elif cooperators < self.m - 1:
            return Action.D
        else:
            return Action.C if avg_coop > math.floor(self.n_players * (self.m - 1) / self.t) else Action.D

class Strategy_COLLECTIVE_582(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation (TFT-AC) Strategy in Collective Risk Dilemma Game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = np.empty(self.game_description.n_rounds)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C if random.random() < 0.5 else Action.D
        cooperation_probability = self.cooperation_history[state.round_number - 1]
        n_c = sum(history.opponent_actions[state.round_number - 1]) if history is not None else 0
        ratio = n_c / self.game_description.m
        cooperation_probability += (math.ceil(ratio * 4) - math.floor(ratio * 4)) / 8 if state.round_number < self.game_description.n_rounds else 0
        cooperation_probability = max(min(cooperation_probability, 1), 0)
        self.cooperation_history[state.round_number - 1] = cooperation_probability
        return Action.C if random.random() < cooperation_probability else Action.D

class Strategy_COLLECTIVE_583(BaseStrategy):
    """
    Tit-for-Tat Adaptive (TfTA) Strategy for the Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.p = math.ceil(self.game_description.m)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and state.round_number <= self.p):
            return Action.C
        cooperation_level = len(history.opponent_actions[:, -1]) / (state.round_number - 1) if history is not None else 0
        punishment_duration = 1 if cooperation_level < self.game_description.m else 0
        return Action.D if cooperation_level < self.game_description.m - punishment_duration else Action.C

class Strategy_COLLECTIVE_584(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = math.ceil(game_description.n_players - game_description.m + 1)
        self.cooperation_incr = 0.1
        self.cooperation_decr = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        recent_cooperators = sum(history.opponent_actions[-2:][:, -1]) if history is not None else 0
        current_cooperators = sum(history.opponent_actions[-1, :]) if history is not None else 0
        if recent_cooperators >= self.game_description.m - 1 and current_cooperators >= self.game_description.m - 1:
            if self.cooperation_threshold < self.game_description.n_players:
                self.cooperation_threshold += self.cooperation_incr
        elif recent_cooperators < self.game_description.m - 1 and current_cooperators < self.game_description.m - 1:
            if self.cooperation_threshold > 0:
                self.cooperation_threshold -= self.cooperation_decr
        return Action.C if current_cooperators >= self.cooperation_threshold else Action.D

class Strategy_COLLECTIVE_586(BaseStrategy):
    """
    A strategy that cooperates initially and in subsequent rounds if a majority of players cooperated in the previous round.
    Otherwise, it defects as a punitive measure to deter potential exploitation and encourage cooperation in future rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.strategy_history = []
        self.last_round_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is not None:
            self.strategy_history.append(history.my_actions[-1])
            cooperators = sum(history.opponent_actions[-1, :])
            self.last_round_cooperators = cooperators
            if cooperators >= self.game_description.m:
                return Action.C
            else:
                self.switch_to_D()
                return Action.D

    def switch_to_D(self):
        """
        Switch to always defecting for the rest of the game
        if a player fails to cooperate in a round where they should have cooperated according to the strategy.
        """
        if self.last_round_cooperators >= self.game_description.m and len(self.strategy_history) > 0:
            self.strategy_history[-1] = Action.D

class Strategy_COLLECTIVE_587(BaseStrategy):
    """
    Tit-for-Tat Adaptive Cooperation (TFTAC) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if not history:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        analysis = self.analyze_history(self.cooperation_history)
        if analysis == 'CC...C':
            return Action.C
        return Action.D

    def analyze_history(self, history):
        if len(history) == 0:
            return 'CC...C'
        if all([action == True for action in history[-len(history):]]):
            return 'CC...C'
        return 'DC...D'

class Strategy_COLLECTIVE_588(BaseStrategy):
    """Adaptive Tit-for-Tat (ATFT) for Collective Risk Dilemma"""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = self.game_description.n_players
        self.m = math.ceil(self.n_players / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history or len(history.opponent_actions) < 2:
            cooperators = np.count_nonzero(history.my_actions[0]) if history else 0
            return Action.C if cooperators >= self.m else Action.D
        recent_cooperators = np.count_nonzero(history.opponent_actions[-1, :])
        if recent_cooperators >= self.m - 1:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_590(BaseStrategy):
    """
    A Tit-for-Tat strategy with Adaptive Cooperation Threshold (TFT-ACT) for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m_history = np.zeros(game_description.n_rounds)
        self.cooperation_threshold = math.ceil(game_description.m * (1 + math.sqrt(2)))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        self.m_history[state.round_number - 1] = cooperators / self.game_description.n_players
        self.cooperation_threshold = max(min(self.m_history.mean(), self.game_description.n_players - 1), self.game_description.m)
        if cooperators >= self.cooperation_threshold:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_591(BaseStrategy):
    """
    Adaptive Tit-for-Tat Strategy for Collective Risk Dilemma Game
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.previous_action = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.previous_action is None:
            self.previous_action = random.choice([True, False])
        self.previous_action = history.opponent_actions[-1][-1] if history else self.previous_action
        return Action(self.previous_action)

class Strategy_COLLECTIVE_592(BaseStrategy):
    """
    Adaptive Cooperation Strategy - Tit For Tat (TFT) in Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.punishment_duration = math.floor(game_description.n_rounds / 2)
        self.cooperated_previously = False
        self.defected_previously = False
        self.last_opponent_action = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is not None:
            self.last_opponent_action = np.mean(history.opponent_actions[-1])
        cooperation_threshold = math.ceil(self.game_description.n_players * 0.5)
        cooperators = sum(history.opponent_actions[-1, :])
        if state.round_number == self.game_description.n_rounds:
            return Action.C
        elif cooperators >= cooperation_threshold:
            self.cooperated_previously = True
            self.defected_previously = False
            return Action.C
        elif self.cooperated_previously and (not self.defected_previously):
            self.defected_previously = True
            return Action.D
        else:
            punishment_remaining = self.punishment_duration - self.game_description.n_rounds % self.punishment_duration
            if punishment_remaining > 0 and self.cooperated_previously:
                return Action.D
            return Action.C

class Strategy_COLLECTIVE_593(BaseStrategy):
    """
    A simple yet effective game theory strategy for the Collective Risk Dilemma, inspired by "Tit-for-Tat" but with an adaptation to encourage mutual cooperation among opponents.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history_length = game_description.m + 1

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        opponent_cooperators = sum(history.opponent_actions[:, -self.history_length:].flatten())
        if opponent_cooperators >= self.game_description.m:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_594(BaseStrategy):
    """
    Tit-for-Tat Adaptive (TfT-A) strategy in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = self.game_description.n_players
        self.m = self.game_description.m
        self.k = self.game_description.k
        self.round_number = 0
        self.history = None
        self.previous_cooperators = 0
        self.previous_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if self.round_number == 0:
            return Action.C
        self.round_number += 1
        if not history:
            history = PlayerHistory(my_actions=np.empty((self.game_description.n_rounds,), dtype=bool), my_payoffs=np.empty((self.game_description.n_rounds,), dtype=np.float64), opponent_actions=np.empty((self.game_description.n_rounds, self.n_players), dtype=bool), opponent_payoffs=np.empty((self.game_description.n_rounds, self.n_players), dtype=np.float64))
        history.my_actions[self.round_number - 1] = self.__class__ == history.opponent_actions[-1][0]
        if self.round_number == 2:
            history.my_actions[1] = Action.C
        cooperators = np.sum(history.opponent_actions[-1, :])
        if cooperators < self.m or (cooperators >= self.m and (self.round_number - self.previous_cooperators) % self.m != 0):
            history.my_actions[self.round_number - 1] = history.opponent_actions[-1][0]
        elif cooperators >= self.m and (self.round_number - self.previous_cooperators) % self.m == 0:
            if history.my_actions[self.round_number - 1] == Action.C:
                punishment_rounds = min(self.previous_defections + 1, self.m - 1)
                for i in range(self.round_number, self.round_number + punishment_rounds):
                    history.opponent_actions[i - 1] = Action.D
            elif history.my_actions[self.round_number - 1] == Action.D:
                pass
        elif history.my_actions[self.round_number - 1] == Action.C:
            pass
        elif history.my_actions[-1] != Action.D:
            history.opponent_actions[self.round_number - 1] = Action.D
        payoff = calculate_payoff(self.game_description, self.round_number, history.my_actions[self.round_number - 1], history.opponent_actions[-1][0])
        update_previous_state(history, payoff, self.round_number)
        return history.my_actions[self.round_number - 1]

class Strategy_COLLECTIVE_595(BaseStrategy):
    """
    Tit-for-Tat Plus (TFT+) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_count = 0
        self.total_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is not None and state.round_number > 0:
            self.total_rounds += 1
            coop_count = sum(history.my_actions[:state.round_number])
            if state.round_number == 1 or coop_count > self.game_description.n_players // 2:
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_596(BaseStrategy):
    """
    A Tit-for-Tat strategy with an adaptive cooperation threshold, designed for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = self._calculate_cooperative_threshold()

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self._calculate_cooperative_threshold():
            return Action.C
        return Action.D

    def _calculate_cooperative_threshold(self) -> int:
        return math.ceil(self.game_description.m * (1 - 1 / self.game_description.k))

class Strategy_COLLECTIVE_597(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat (TFT) with Adaptation
    Strategy description: Decision Rules based on the Tit-for-Tat game theory strategy, with an adaptive threshold for punishment and forgiveness.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = math.ceil(game_description.n_players / 2)
        self.punishment_counter = 0
        self.forgiveness_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        opponent_action = history.opponent_actions[-1][-1] if history else None
        if opponent_action is None:
            self.punishment_counter = 0
            self.forgiveness_counter = 0
            return Action.C
        if opponent_action == Action.C:
            self.punishment_counter = 0
            self.forgiveness_counter = 0
            return Action.C
        self.punishment_counter += 1
        if self.punishment_counter > self.threshold // 2:
            self.punishment_counter = self.threshold // 2
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_599(BaseStrategy):
    """
    A Tit-for-Tat Cooperation strategy for the Collective Risk Dilemma game.
    Cooperates initially, conditional cooperates in subsequent rounds, and forgives past deviations.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        elif state.round_number < self.game_description.n_rounds:
            cooperators = sum(history.opponent_actions[state.round_number - 1, :])
            if cooperators >= self.game_description.m:
                return Action.C
        elif history is not None and self.last_cooperators > 0:
            return Action.C
        self.last_cooperators = int(sum(history.opponent_actions[-1, :]) >= self.game_description.m)
        return Action.D

class Strategy_COLLECTIVE_600(BaseStrategy):
    """
    The Tit-for-Tat Adaptive (TFT-A) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperated_last_round = False
        self.prev_round_coop_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is not None:
            self.prev_round_coop_count = sum(history.opponent_actions[-1])
        if state.round_number != 1:
            cooperators_in_prev_round = self.prev_round_coop_count
        else:
            cooperators_in_prev_round = 0
        action = Action.C
        if cooperators_in_prev_round < self.game_description.m:
            action = Action.D
        self.cooperated_last_round = action == Action.C
        return action

class Strategy_EXPLOITATIVE_513(BaseStrategy):
    """
    A Tit-for-Tat with Adaptive Cooperation Threshold strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.adaptation_threshold = math.ceil(game_description.m)
        self.last_round_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and len(history.opponent_actions) == 0):
            return Action.C
        cooperators = np.sum(history.opponent_actions[-1, :]) if history is not None else 0
        self.last_round_cooperators = cooperators
        if cooperators >= self.adaptation_threshold:
            if state.round_number == self.game_description.n_rounds or history is None:
                return Action.C
            else:
                self.adaptation_threshold += 1 if self.last_round_cooperators > 0 else self.adaptation_threshold - 1
        return Action.D

class Strategy_EXPLOITATIVE_514(BaseStrategy):
    """
    A strategy that mimics the Tit-for-Tat strategy with an adaptive cooperation feature.
    It cooperates initially and in response to opponent's cooperation, but punishes defection by defecting itself.
    The strategy also exhibits some tolerance towards new opponents during the first few rounds and will not rely on predetermined patterns or cooperation schedules with other strategies.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.constant_tolerance = math.ceil(game_description.n_players / 10)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :]) if history is not None else 0
        tolerance_rounds = min(self.constant_tolerance, state.round_number)
        if state.round_number < tolerance_rounds:
            return Action.C
        if history.opponent_actions[-1, 0] == Action.C.value:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_515(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperators_threshold = game_description.m
        self.sliding_window = int(math.ceil(game_description.n_rounds * 0.5))
        self.cooperation_average = np.zeros(self.sliding_window)
        self.t_coop = 0.67
        self.t_defect = 0.33

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :]) if history is not None else 0
        self.cooperation_average = np.roll(self.cooperation_average, -1)
        self.cooperation_average[self.sliding_window - 1] = cooperators / self.game_description.n_players if history is not None else 0
        if state.round_number == self.game_description.n_rounds:
            return Action.D if self.cooperators_threshold > cooperators else Action.C
        average_percentage = np.mean(self.cooperation_average)
        if average_percentage > self.t_coop:
            self.cooperators_threshold += 1
        elif average_percentage < self.t_defect:
            self.cooperators_threshold -= 1
        return Action.C if cooperators >= self.cooperators_threshold else Action.D

class Strategy_EXPLOITATIVE_517(BaseStrategy):
    """
    Tit-for-Tat Strategy with Adaptive Cooperation Threshold (TFTAT)
    A strategy that cooperates when more than m players did in the previous round, and defects otherwise.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        previous_cooperation = sum(history.opponent_actions[-1])
        return Action(previous_cooperation >= self.m)

class Strategy_EXPLOITATIVE_518(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_coop_threshold = math.ceil(game_description.n_players * 0.5)
        self.history = PlayerHistory(my_actions=np.zeros((game_description.n_rounds,), dtype=bool), my_payoffs=np.zeros(game_description.n_rounds, dtype=float), opponent_actions=np.zeros((game_description.n_rounds, game_description.n_players), dtype=bool), opponent_payoffs=np.zeros((game_description.n_rounds, game_description.n_players), dtype=float))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.history.my_actions[state.round_number - 1] = True
        cooperators = sum(history.opponent_actions[state.round_number - 1, :])
        if self.history.my_actions[-1] and cooperators >= self.min_coop_threshold:
            return Action.C
        elif not self.history.my_actions[-1] or cooperators < self.min_coop_threshold - 1:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_519(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Threshold (TfT-AT)
    Strategy Summary: A cooperative strategy that punishes non-cooperative behavior and rewards high levels of cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.r = game_description.n_rounds
        self.threshold = np.zeros(self.r)
        self.coop_count = np.zeros(self.r, dtype=np.int32)

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.r - 1:
            cooperators = sum(history.opponent_actions[:, -1])
            if cooperators >= self.m:
                return Action.C
            else:
                return Action.D
        cooperators = history.opponent_actions[self.r - self.m:, -1].sum()
        coop_avg = cooperators / self.m
        if coop_avg < self.m:
            return Action.D
        current_coop_hist_avg = self.threshold[-1]
        if coop_avg > current_coop_hist_avg and coop_avg >= coop_avg + np.mean(self.coop_count[self.r - self.m:]) - np.std(self.coop_count[self.r - self.m:]):
            self.threshold[-1] = coop_avg
            return Action.C
        if coop_avg >= coop_avg and coop_avg <= current_coop_hist_avg:
            return Action.D
        self.threshold[-1] = coop_avg
        return Action.C

class Strategy_EXPLOITATIVE_520(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.minCT = 1
        self.maxCT = game_description.n_players - 1
        self.currentCT = math.ceil(self.game_description.m / 2)
        self.totalBenefits = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.game_description.m and state.round_number != self.game_description.n_rounds - 1:
            self.currentCT = min(self.maxCT, max(self.minCT, self.currentCT + 1))
        elif cooperators < self.game_description.m and state.round_number != self.game_description.n_rounds - 1:
            self.currentCT = max(self.minCT, self.currentCT - 1)
        if state.round_number == self.game_description.n_rounds - 1:
            totalBenefits = np.sum(history.my_payoffs[1:-1])
            if totalBenefits < self.game_description.m / 2 * self.game_description.k or self.currentCT > (self.game_description.m + 1) // 2:
                return Action.D
        return Action.C if self.currentCT >= self.game_description.m // 2 else Action.D

class Strategy_EXPLOITATIVE_522(BaseStrategy):
    """
    Implementation of the Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.f = int(math.floor(game_description.m * game_description.n_players / game_description.n_rounds))
        self.g = int(math.ceil(game_description.n_rounds / 2))
        self.cooperation_threshold_history = np.zeros(game_description.n_rounds)
        self.payoff_history = np.zeros(game_description.n_rounds)
        self.cooperation_threshold = game_description.m - 1
        self.total_payoff = 0
        self.average_payoff = 0
        self.p = 0.8

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if state.round_number <= self.f:
            action = Action.C
        elif state.round_number > self.f and state.round_number <= self.g + self.f:
            cooperation = sum(history.opponent_actions[-1, :])
            if cooperation >= self.cooperation_threshold:
                action = Action.C
            else:
                action = Action.D
        elif state.round_number > self.g + self.f:
            payoff = self.payoff_history[-1]
            average_payoff = np.mean(self.payoff_history[self.g + self.f:])
            if payoff < average_payoff * self.p:
                action = Action.D
            else:
                cooperators = sum(history.opponent_actions[-1, :])
                if cooperators >= self.cooperation_threshold:
                    action = Action.C
                else:
                    action = Action.D
        self.payoff_history[state.round_number] = history.my_payoffs[-1]
        self.total_payoff += history.my_payoffs[-1]
        self.average_payoff = np.mean(self.payoff_history)
        self.cooperation_threshold_history[state.round_number] = self.cooperation_threshold
        if state.round_number == self.g + self.f:
            self.cooperation_threshold += 1
        if self.total_payoff / self.game_description.n_rounds < self.average_payoff * self.p:
            self.cooperation_threshold -= 1
        return action

class Strategy_EXPLOITATIVE_523(BaseStrategy):
    """
    A Tit-for-Tat with Threshold (TFT-Thresh) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and len(history.opponent_actions) > 0:
            num_cooperators = sum(history.opponent_actions[-1])
            if num_cooperators >= self.threshold:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_524(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = self.game_description.n_players
        self.n_rounds = self.game_description.n_rounds
        self.m = self.game_description.m
        self.k = self.game_description.k
        self.ct0 = self.n_players // 2
        self.r = self.n_rounds
        self.t = math.ceil(self.r / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.r - 1:
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators >= self.m:
                return Action.C
        cooperators = sum(history.opponent_actions[round_number - 1, :])
        avg_c = np.mean([cooperators] + history.my_actions[:round_number - 1].tolist()) if round_number >= self.t else cooperators
        cooperation_threshold = (self.ct0 + avg_c * (self.r - round_number)) / self.r if round_number > self.t else self.ct0
        return Action.C if cooperators >= self.m or sum(history.my_actions[:round_number]) >= cooperation_threshold else Action.D

class Strategy_EXPLOITATIVE_525(BaseStrategy):
    """
    A Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m - 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        if history.my_actions is not None and len(history.my_actions) >= self.m:
            cooperation_threshold = len(history.my_actions) - self.m + 1
            num_cooperators = sum(history.my_actions[max(0, state.round_number - cooperation_threshold):state.round_number])
        else:
            num_cooperators = 0
        if num_cooperators >= self.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_526(BaseStrategy):
    """
    Adaptive Tit-for-Tat Strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self._opponent_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if len(self._opponent_history) == 0:
            self._opponent_history = [[] for _ in range(state.round_number)]
        opponent_action = history.opponent_actions[state.round_number - 1, 0]
        self._opponent_history[-1].append(opponent_action)
        if opponent_action:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_528(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperators_counts = np.zeros(int(game_description.n_rounds / 2))
        self.cooperation_threshold = math.inf
        self.epsilon = 0.1

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_cooperators = sum(history.opponent_actions[state.round_number - 1])
        self.cooperators_counts[min(state.round_number, len(self.cooperators_counts) - 1)] = current_cooperators
        if state.round_number > self.game_description.n_rounds / 2:
            self.cooperation_threshold = (np.mean(self.cooperators_counts) + 1) / self.game_description.n_rounds * (self.game_description.m - self.epsilon)
        else:
            self.cooperation_threshold = max((np.mean(self.cooperators_counts[:state.round_number]) + 1) / state.round_number, self.game_description.m) - self.epsilon
        return Action.C if current_cooperators >= self.cooperation_threshold else Action.D

class Strategy_EXPLOITATIVE_529(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Threshold (TFT-AT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = int(self.game_description.m)
        self.r = int(self.game_description.n_rounds)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.D
        elif state.round_number == self.r or history is None:
            return Action.C
        else:
            cooperation_count = sum(history.opponent_actions[state.round_number - self.r:state.round_number, :].sum(axis=1) >= self.m)
            if cooperation_count >= self.m:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_530(BaseStrategy):
    """
    A strategy that cooperates in the first round and subsequently cooperates if the majority of players cooperated in the previous round, otherwise defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m
        self.n = self.game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is None or len(history.opponent_actions) < self.game_description.n_rounds:
            return Action.D
        cooperators = sum(history.opponent_actions[-1])
        if cooperators >= self.m:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_531(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_coop_threshold = math.ceil(game_description.n_players * game_description.m / 100)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :]) if history is not None else self.min_coop_threshold
        if cooperators < self.min_coop_threshold:
            return Action.D
        return Action.C

class Strategy_EXPLOITATIVE_532(BaseStrategy):
    """
    Tit-for-Tat with Rational Adaptation (TFT-R) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.window_size = 3
        self.previous_rounds_cooperators = np.zeros(self.window_size)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        if history is not None:
            self.previous_rounds_cooperators = np.roll(self.previous_rounds_cooperators, -1)
            self.previous_rounds_cooperators[-1] = sum(history.opponent_actions[-1, :])
            cooperative_ratio = np.mean(self.previous_rounds_cooperators)
            if cooperative_ratio > self.game_description.m / self.game_description.n_players:
                return Action.C
        return Action.D
        if state.round_number == self.game_description.n_rounds:
            return Action.D
        if self.window_size < self.game_description.m:
            self.window_size = 3

class Strategy_EXPLOITATIVE_533(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT) Strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = math.ceil(game_description.n_players * 0.5)
        self.initial_threshold = self.threshold
        self.consecutive_defects = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1] if history else [False]) if history else 0
        self.consecutive_defects += int(cooperators < self.threshold)
        if state.round_number == self.game_description.n_rounds - 1:
            self.consecutive_defects = 0
        if self.consecutive_defects >= self.game_description.m - 1:
            self.threshold = self.initial_threshold
        elif cooperators >= self.threshold:
            self.threshold = self.initial_threshold
        elif self.threshold < self.game_description.n_players:
            self.threshold += 1
        return Action.C if cooperators >= self.threshold else Action.D

class Strategy_EXPLOITATIVE_534(BaseStrategy):
    """
    A TFT-ACT strategy agent for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n = game_description.n_players
        self.k = game_description.k

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cr = self.calculate_cooperative_ratio(history)
        if cr >= self.m / self.n or self.exploitative_behavior(history):
            return Action.C
        else:
            return Action.D

    def calculate_cooperative_ratio(self, history: PlayerHistory) -> float:
        return sum(history.my_actions[-self.m:]) / self.m if history is not None and len(history.my_actions) > self.m else 0

    def calculate_total_payoffs(self, history: PlayerHistory) -> tuple[float, float]:
        total_payoff_c = np.sum(history.my_payoffs[history.my_actions == Action.C])
        total_payoff_d = np.sum(history.my_payoffs[history.my_actions == Action.D])
        return (total_payoff_c, total_payoff_d)

    def exploitative_behavior(self, history: PlayerHistory) -> bool:
        total_payoff_c, total_payoff_d = self.calculate_total_payoffs(history)
        return total_payoff_c > total_payoff_d

class Strategy_EXPLOITATIVE_535(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) Strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.history_window_size = math.ceil(game_description.n_rounds / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.D
        if len(history.my_actions) >= self.history_window_size:
            cooperators = np.count_nonzero(history.opponent_actions[-self.history_window_size:, -1])
            self.cooperation_threshold = max(self.game_description.m, cooperators) if cooperators >= self.game_description.m else self.cooperation_threshold
        if np.count_nonzero(history.opponent_actions[state.round_number - 1]) >= self.cooperation_threshold:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_536(BaseStrategy):
    """
    Tit-for-Tat-R (Robust Tit-for-Tat) strategy for the Collective Risk Dilemma game.
    This strategy cooperates when a majority of players cooperate in the previous round,
    and defects otherwise. In the first round, it randomly chooses between cooperation and defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.minimum_cooperators = self.game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return random.choice([Action.C, Action.D])
        coop_count = np.sum(history.opponent_actions[-1, :])
        return Action.C if coop_count >= self.minimum_cooperators else Action.D

class Strategy_EXPLOITATIVE_538(BaseStrategy):
    """
    Strategy name: Tit-for-Tat with Adaptive Threshold (TfTAT)
    Strategy description: Cooperate initially to encourage cooperation and set the threshold for subsequent rounds.
                            In subsequent rounds, if the number of cooperators in the previous round is greater than or equal to m (maintain cooperative group), play C.
                            Otherwise, if the number of cooperators is less than m but greater than zero (punish recent defectors), play C if the number of consecutive defections from the most recent cooperative round is less than a predefined threshold (T).
                            If the number of consecutive defections exceeds T, join defectors and set the threshold to T+1 for the next round.
                            If no cooperation occurred in the most recent round, defect and set the threshold to 1.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = 1
        self.round_number = 0
        self.history = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if history is None:
            self.round_number += 1
            return Action.C
        self.history = history
        self.round_number = state.round_number
        cooperators = sum(self.history.opponent_actions[-1, :])
        consecutive_defections = np.count_nonzero(np.logical_xor(self.history.my_actions[:-1], self.history.my_actions[1:])) + 1
        if self.round_number == 1:
            return Action.C
        elif self.round_number < self.game_description.n_rounds:
            if cooperators >= self.game_description.m and consecutive_defections <= self.threshold:
                return Action.C
            elif cooperators < self.game_description.m and consecutive_defections < self.threshold + 1:
                return Action.C
            else:
                self.threshold += 1
        else:
            return Action.C

class Strategy_EXPLOITATIVE_539(BaseStrategy):
    """
    A strategy that emulates the Tit-for-Tat Adaptive behavior in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            last_opponent_action = self.opponent_history[-1]
            return Action.C if last_opponent_action else Action.D
        opponent_action = history.opponent_actions[state.round_number - 1, 0]
        self.opponent_history.append(opponent_action)
        return Action.C if opponent_action else Action.D

class Strategy_EXPLOITATIVE_540(BaseStrategy):
    """
    Tit-for-Tat with Adaptation (TfT-A) Strategy for Collective Risk Dilemma
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        action = Action.C
        streak_length = min(self.streak, self.game_description.n_players - 1)
        if history is not None and history.my_actions[-1]:
            if sum(history.opponent_actions[-1]) < self.game_description.m:
                action = Action.D
            elif state.round_number == self.game_description.n_rounds - 1 or sum(history.my_actions[:-streak_length]) >= self.game_description.m:
                action = Action.D
        else:
            action = Action.C
        if history is not None and history.my_actions[-1] and (action == Action.C):
            self.streak += 1
        elif not history.my_actions[-1] and action == Action.D:
            self.streak = max(self.streak - streak_length, 0)
        return action

class Strategy_EXPLOITATIVE_541(BaseStrategy):
    """
    Implementation of Tit-for-Tat with Adaptation (TfT-A) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.recent_cooperators = 0
        self.recent_min_coop_met = 0

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None:
            self.recent_cooperators = 0
            self.recent_min_coop_met = 0
        player_actions = history.my_actions[-1]
        opponent_actions = history.opponent_actions[-1, :]
        cooperators = sum(opponent_actions)
        self.recent_cooperators += cooperators if player_actions else 0
        self.recent_min_coop_met += 1 if cooperators >= self.game_description.m else 0
        if all(opponent_actions) or self.recent_min_coop_met == self.game_description.n_rounds:
            return Action.C
        opponent = np.argmax(opponent_actions)
        if not opponent_actions[opponent] and self.recent_cooperators >= self.game_description.m - 1:
            return Action.C
        if np.any(opponent_actions) and (not all(opponent_actions)):
            self.recent_cooperators = 0
            self.recent_min_coop_met = 0
        return Action.D

class Strategy_EXPLOITATIVE_543(BaseStrategy):
    """
    A Tit-for-Tat Adaptive (TFT-A) strategy for the Collective Risk Dilemma game.
    The TFT-A strategy cooperates when the majority of players cooperated in the previous round,
    defects otherwise, and mimics the opponent's action in the last round to ensure fairness.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.my_actions = np.zeros(game_description.n_rounds, dtype=int)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            return Action.C
        opponent_cooperators = sum(history.opponent_actions[state.round_number - 1, :])
        majority = int((self.game_description.n_players + 1) / 2)
        if opponent_cooperators >= majority:
            return Action.C
        else:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return history.opponent_actions[-2, self.__class__.name]

class Strategy_EXPLOITATIVE_544(BaseStrategy):
    """
    Adaptive Tit-for-Tat (ATfT) strategy for the Collective Risk Dilemma game.
    This strategy cooperates initially to foster a cooperative environment,
    and reciprocates cooperation in subsequent rounds while defecting if partners do not reciprocate.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = np.zeros((1, game_description.n_players))
        self.last_round_cooperators = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.last_round_cooperators = np.count_nonzero(history.opponent_actions[-1])
        if history.my_actions[-1] == Action.C:
            return Action.C
        else:
            cooperators = np.count_nonzero(history.opponent_actions[-1])
            return self._get_action(cooperators)

    def _get_action(self, cooperators: int):
        """
        Decide whether to cooperate or defect based on the number of cooperators in the previous round.
        """
        if cooperators >= self.game_description.m and self.last_round_cooperators < self.game_description.m:
            return Action.C
        elif cooperators < self.game_description.m and self.last_round_cooperators >= self.game_description.m:
            return Action.D
        else:
            return self._get_opponent_action(self.last_round_cooperators)

    def _get_opponent_action(self, cooperators: int):
        """
        Determine opponent's action based on the number of cooperators in the previous round.
        """
        if cooperators >= self.game_description.m:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_545(BaseStrategy):
    """
    A Tit-for-Tat with Adaptive Cooperation Threshold (TACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = 0
        self.opponent_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if state.round_number == 0 or not history:
            return Action.C
        opponent_actions = history.opponent_actions if history else np.zeros((state.round_number, self.game_description.n_players), dtype=bool)
        self.opponent_history.append(opponent_actions[-1])
        current_sequence = self._get_sequence_length([Action.C], opponent_actions[-2:]) if history else 0
        previous_sequence = self._get_sequence_length([Action.D], opponent_actions[-2:]) if history else 0
        if current_sequence >= 1 and (previous_sequence == 0 or current_sequence + previous_sequence == 1):
            return Action.C
        cooperators = sum(history.opponent_actions[-1] if history else opponent_actions[:, -1])
        if cooperators < self.cooperation_threshold:
            self.cooperation_threshold += 1
            if self.cooperation_threshold > self.game_description.m - 1:
                self.cooperation_threshold = self.game_description.n_players - 1
        elif cooperators >= self.game_description.m and (self.cooperation_threshold > 0 or self.cooperation_threshold == self.game_description.n_players - 1):
            self.cooperation_threshold -= 1
        return Action.D if cooperators < self.cooperation_threshold else Action.C

    def _get_sequence_length(self, action: list[Action], actions: NDArray[np.bool_]):
        sequence_len = 0
        for i in range(actions.shape[1] - len(action) + 1):
            if np.all(actions[..., i:i + len(action)] == action):
                sequence_len = len(action)
        return sequence_len

class Strategy_EXPLOITATIVE_546(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.historical_data = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and len(history.my_payoffs) < self.game_description.n_rounds):
            return Action.C
        if len(self.historical_data) >= self.game_description.n_rounds:
            self.update_cooperation_threshold()
        cooperators = sum(history.opponent_actions[-1, :]) if history is not None else 0
        if cooperators >= self.cooperation_threshold:
            return Action.C
        elif state.round_number == self.game_description.n_rounds - 1:
            return self.historical_data[-1] >= self.cooperation_threshold and Action.C or Action.D
        else:
            return Action.D

    def update_cooperation_threshold(self):
        last_round = len(self.historical_data) - 1
        current_round = last_round - 1 if last_round > 0 else None
        if current_round is not None and sum(self.historical_data[current_round]) >= self.game_description.m:
            self.cooperation_threshold += 1
        elif current_round is not None and sum(self.historical_data[current_round]) < self.game_description.m:
            self.cooperation_threshold -= 1
        self.cooperation_threshold = max(min(self.cooperation_threshold, self.game_description.n_players - 1), 1)

class Strategy_EXPLOITATIVE_547(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperative Threshold Strategy for the Collective Risk Dilemma Game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.recent_cooperators = 0
        self.history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and len(self.history) > 0:
            self.history.append((history.my_actions[-1], state.round_number))
        if len(self.history) >= self.game_description.m:
            recent_cooperators = sum([action for action, _ in self.history[-self.game_description.m:]])
            if recent_cooperators >= self.game_description.m:
                return self.history[-1][0]
        return Action.D

class Strategy_EXPLOITATIVE_548(BaseStrategy):
    """Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)"""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.m = game_description.m
        self.k = game_description.k
        self.x = 0.2
        self.y = 0.3
        self.z = 5
        self.total_payoff = 0
        self.punishment_phase_length = 0
        self.consecutive_below_threshold = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        self.total_payoff += 1 - (history.my_actions[-1] if history else Action.D) + self.k * (np.mean(history.opponent_actions[-1, :]) >= self.m / self.n_players) if history else 0
        p = np.mean(history.opponent_actions[-1, :]) if history else 0
        cooperate = True if p >= self.m / self.n_players else False
        if cooperate:
            self.punishment_phase_length = 0
            payoff_this_round = 1 - (history.my_actions[-1] if history else Action.D) + self.k * (p >= self.m / self.n_players)
        else:
            if p < self.m / self.n_players - self.x and self.consecutive_below_threshold > self.z:
                self.adjust_tolerance_levels()
                return Action.D
            payoff_this_round = 1 - (history.my_actions[-1] if history else Action.D)
        if state.round_number == self.n_rounds:
            if p >= self.m / self.n_players + self.y:
                cooperate = True
            elif p < self.m / self.n_players - self.x or self.consecutive_below_threshold > self.z:
                cooperate = False
        c_i = Action(int(cooperate)) if history else None
        if history is not None:
            self.punishment_phase_length += int(not cooperate) + int(history.my_actions[-1] == cooperate and p >= self.m / self.n_players)
            self.consecutive_below_threshold = max(self.consecutive_below_threshold - 1, 0) if not cooperate else 0
            if cooperate:
                self.consecutive_below_threshold += 1
        return c_i

    def adjust_tolerance_levels(self):
        payoff = self.total_payoff / self.n_rounds
        if payoff < 1 - self.k:
            self.x, self.y, self.z = (self.x * 1.1, self.y * 0.9, max(math.floor(self.z * 0.8), 3))
        else:
            self.x, self.y, self.z = (self.x * 0.9, self.y * 1.1, math.ceil(self.z * 1.2))
        self.total_payoff = 0

class Strategy_EXPLOITATIVE_549(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Defection (TFT-AD) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = int(math.floor((game_description.n_players - 1) / 3))
        self.last_opponent_action = None
        self.cooperative_opponents = set()

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        if history.opponent_actions[-1].all():
            self.last_opponent_action = Action.C
            self.cooperative_opponents.clear()
        elif not history.opponent_actions[-1].any():
            self.last_opponent_action = Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            if self.last_opponent_action is None or history.opponent_actions[-1].all():
                return Action.C
            return Action.D
        cooperators = sum(history.opponent_actions[-1])
        if cooperators >= self.game_description.m and self.last_opponent_action == Action.C:
            return Action.C
        elif cooperators < self.game_description.m and self.last_opponent_action is None:
            return Action.D
        elif self.last_opponent_action == Action.D and len(self.cooperative_opponents) < self.threshold:
            self.cooperative_opponents.add(history.opponent_actions[0, -1])
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_550(BaseStrategy):
    """
    Adaptive Cooperation Strategy that mimics Tit-for-Tat, cooperating in the first round and adapting based on opponent's previous actions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = []

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.opponent_history.append(history.opponent_actions[-1])
        cooperation_threshold = math.ceil(self.game_description.n_players * 0.5)
        current_cooperators = sum(self.opponent_history[-1])
        if current_cooperators >= cooperation_threshold:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_551(BaseStrategy):
    """
    Strategy Name: Adaptive Tit-for-Tat (ATfT) for Collective Risk Dilemma
    Strategy Description: The strategy cooperates in the initial round, and later on cooperates when a predefined threshold of players also cooperate in the previous round. If fewer than m players cooperated in the previous round or the threshold is not met, it defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = self.game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None or len(history.opponent_actions) < self.game_description.n_players:
            cooperators = math.ceil(self.game_description.n_players * self.threshold / 100)
        else:
            cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.threshold:
            return Action.C
        elif len(history.opponent_actions) < self.game_description.n_players:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_552(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.t = self.m
        self.d_max = math.floor(self.game_description.n_rounds * 0.5)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and history.my_actions[-1] is None:
            history = PlayerHistory(np.zeros((state.round_number,), dtype=bool), np.zeros((state.round_number,)), np.zeros((state.round_number, self.game_description.n_players), dtype=bool), np.zeros((state.round_number, self.game_description.n_players)))
            history.my_actions[-1] = False
        n_c_prev = np.sum(history.opponent_actions[state.round_number - 1, :])
        if n_c_prev >= self.m:
            return Action.C
        elif self.t > self.n_players:
            return Action.D
        else:
            self.t = min(self.t + 1, self.n_players)
            return Action.D if n_c_prev < self.t else Action.C

class Strategy_EXPLOITATIVE_553(BaseStrategy):
    """
    Implementation of Tit-for-Tat Plus (TfTP) for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n = game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or not history:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-self.m:]) / self.m
        decision_threshold = (self.m - 1) / self.n
        if cooperators >= decision_threshold:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_554(BaseStrategy):
    """
    A Tit-for-Tat with Adaptive Threshold (TfT-AT) strategy for the Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.threshold = self.m
        self.history = None

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if self.history is None or state.round_number == 0:
            self.history = history
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        self.threshold = max(self.m, math.ceil(self.threshold - 1 if cooperators < self.threshold else self.threshold))
        self.threshold = min(self.n_players, self.threshold)
        payoff_last_round = history.my_payoffs[-1] if history is not None else np.full((self.game_description.n_rounds,), 1.0)
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        payoff_threshold_met = payoff_last_round[payoff_last_round >= (1.0 if self.threshold < cooperators else 2.0)]
        if len(payoff_threshold_met) >= self.m:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_555(BaseStrategy):
    """
    Strategy name: Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)
    This strategy cooperates if enough players cooperated in the previous round,
    otherwise it defects. The cooperation threshold is defined as m/2 if the total number of players is even,
    otherwise it's the floor((m+1)/2). If a player defects when cooperation is required for success,
    the strategy will permanently switch to defection against that player.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = math.floor((game_description.m + 1) / 2) if game_description.n_players % 2 else game_description.m // 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and len(history.opponent_actions) > 0:
            cooperators = sum(history.opponent_actions[-1])
            if cooperators >= self.cooperation_threshold:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_556(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TACT)
    Strategy Description: TACT starts cooperative, adapts cooperation based on observed opponent behavior.
                           Cooperates if average number of cooperators in the last 5 rounds is greater than m,
                           or the opponent has always cooperated recently, or p > random draw.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.s = 5
        self.p = 0.5
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = np.mean(history.opponent_actions[:self.s, :] > 0)
        if cooperators < self.game_description.m / self.game_description.n_players:
            return Action.D
        p = self.p
        opponent_cooperative = np.all(history.opponent_actions[-self.r:, :] > 0)
        opponent_defective = np.all(history.opponent_actions[-self.r:, :] < 1)
        if opponent_cooperative:
            p += 0.05
        elif opponent_defective:
            p -= 0.05
        r_cooperation = np.mean(history.opponent_actions[-self.r:, :])
        if r_cooperation > 0 and len(np.where(history.opponent_actions[-self.r:, :] == 1)[0]) / self.r > p:
            p += (p - np.mean(history.opponent_actions[-self.r:, :])) * 2
        return Action(random.choice([0, 1]) if random.random() < p else 1)

class Strategy_EXPLOITATIVE_557(BaseStrategy):
    """
    Strategy name: Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)
    Strategy description: Maintains a cooperation threshold based on the average number of cooperators in the previous 'tau' rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.tau = int(math.ceil(game_description.n_rounds * 0.8))
        self.cooperation_threshold = np.full((self.tau,), game_description.m)
        self.num_rounds_played = 0

    def __call__(self, state: GameState, history: None | PlayerHistory):
        if history is None:
            self.cooperation_threshold[-1] = self.game_description.m
            return Action.C
        self.num_rounds_played += 1
        if state.round_number == 1:
            self.cooperation_threshold = np.full((self.tau,), self.game_description.m)
        current_round_index = (self.num_rounds_played - state.round_number) % self.tau
        self.cooperation_threshold[current_round_index] = np.mean(history.opponent_actions[:, current_round_index])
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.cooperation_threshold[0]:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_559(BaseStrategy):
    """
    A Tit-for-Tat-Cooperate (TftT-C) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :]) if history else 0
        if cooperators < self.m or state.round_number == self.game_description.n_rounds:
            return Action.D
        return Action.C

class Strategy_EXPLOITATIVE_560(BaseStrategy):
    """
    A Tit-for-Tat Adaptive (TFT-A) strategy for the Collective Risk Dilemma game.
    This strategy cooperates if more than a predefined number of players collaborated in the previous round, otherwise defects.
    In the first round, it randomizes between cooperation and defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action(random.choice([0, 1]))
        if history is None:
            cooperators = 0
        else:
            cooperators = sum(history.opponent_actions[-1])
        if cooperators >= self.m:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_561(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat-Adaptive (TfTA)
    This strategy cooperates initially, then reciprocates the opponent's previous action in each round.
    If a player encounters another player who never cooperates, TfTA immediately adapts and defects.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds or not self.opponent_history:
            return Action.D
        if any([action == Action.D for action in self.opponent_history]):
            return Action.D
        cooperation_count = sum([1 for action in self.opponent_history[-self.game_description.n_rounds:] if action == Action.C])
        if cooperation_count >= self.game_description.n_players // 2:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_562(BaseStrategy):
    """
    Tit-for-Tat with Cooperative Evolvement (TTCE) strategy for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or len(self.opponent_history) == 0:
            return Action.C
        opponent_action = self.opponent_history[-1] if len(self.opponent_history) > 0 else None
        my_payoff_last_round = history.my_payoffs[-1] if history is not None else None
        payoff_to_cooperate = np.mean(history.opponent_payoffs[-1]) * self.game_description.k if history is not None else None
        payoff_to_defect = my_payoff_last_round if opponent_action is None else my_payoff_last_round + opponent_action
        if opponent_action == Action.C and payoff_to_cooperate >= payoff_to_defect:
            return Action.C
        elif opponent_action == Action.D and len(self.opponent_history) > self.game_description.n_players // 2 and (payoff_to_cooperate < payoff_to_defect):
            return Action.C
        else:
            return Action.D
        self.opponent_history.append(opponent_action)

class Strategy_EXPLOITATIVE_563(BaseStrategy):
    """
    A simple implementation of the Tit-for-Tat-Adaptive (TfTA) strategy in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.total_payoff_cooperate = 0.0
        self.total_payoff_defect = 0.0
        self.rounds_played = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (history is not None and len(history.my_actions) == 0):
            return Action.C
        self.rounds_played += 1
        if history is not None and len(history.my_actions) > 0:
            last_opponent_action = history.opponent_actions[-1, -1]
            if last_opponent_action == Action.C:
                return Action.C
            elif last_opponent_action == Action.D:
                return Action.D
        if self.rounds_played >= self.game_description.n_rounds or self.total_payoff_cooperate > self.total_payoff_defect:
            if self.total_payoff_cooperate > self.total_payoff_defect:
                return Action.C
        self.update_payoffs(history)
        return Action.D

    def update_payoffs(self, history: PlayerHistory):
        payoffs = history.my_payoffs[-1] if len(history.my_payoffs) > 0 else np.zeros(1)
        self.total_payoff_cooperate += np.sum(payoffs[history.my_actions[-1] == 1])
        self.total_payoff_defect += np.sum(payoffs[history.my_actions[-1] == 0])

class Strategy_EXPLOITATIVE_564(BaseStrategy):
    """
    A Tit-for-Tat-Adaptive (TfT-A) strategy for the Collective Risk Dilemma game.
    The strategy cooperates in the first round and adapts its cooperation threshold based on the opponent's behavior.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m_threshold = int(game_description.n_players * 0.5)
        self.history = PlayerHistory(np.zeros(self.game_description.n_rounds, dtype=bool), np.zeros(self.game_description.n_rounds), np.zeros((self.game_description.n_rounds, game_description.n_players), dtype=bool), np.zeros(self.game_description.n_rounds))

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if history is None:
            self.history.my_actions[0] = True
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.m_threshold:
            self.history.my_payoffs[-1] = self.game_description.k - 1 if cooperators == self.game_description.n_players else 1 - self.history.my_actions[-1]
            self.history.my_actions[state.round_number] = True
            return Action.C
        self.history.my_payoffs[-1] = self.history.my_actions[-1] if cooperators > 0 else 1 - self.history.my_actions[-1]
        self.m_threshold += int(math.copysign(self.game_description.n_players / 2, history.opponent_payoffs[-1, -1] - self.history.my_payoffs[-1])) if state.round_number > self.game_description.n_rounds // 5 else self.m_threshold
        self.history.my_actions[state.round_number] = False
        return Action.D

class Strategy_EXPLOITATIVE_565(BaseStrategy):
    """
    The Tit-for-Tat with Adaptive Cooperation Threshold (TACT) strategy.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.r = game_description.n_rounds
        self.average_cooperators = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        if history is not None:
            self._update_average_cooperators(history)
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators < self.game_description.m * (1 - 0.05 * abs(self.average_cooperators - self.game_description.n_players // 2)):
            return Action.D
        else:
            return Action.C

    def _update_average_cooperators(self, history: PlayerHistory):
        if self.average_cooperators is None:
            total_cooperators = sum([len(round_history) for round_history in history.opponent_actions[-self.r:]])
            self.average_cooperators = total_cooperators / self.r

class Strategy_EXPLOITATIVE_566(BaseStrategy):
    """Free Rider Strategy"""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            if random.random() < 0.5:
                return Action.C
            else:
                return Action.D
        if state.round_number == 1 or state.round_number == self.game_description.n_rounds:
            cooperators = sum(history.opponent_actions[0, :])
            if cooperators < self.m:
                return Action.D
            else:
                return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.m:
            if state.round_number == 1 or state.round_number == self.game_description.n_rounds:
                return Action.D
            else:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_567(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m
        self.cooperative_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        elif state.round_number == self.game_description.n_rounds:
            return Action.D
        else:
            opponent_action = history.opponent_actions[-1] if history is not None else [Action.D] * self.game_description.n_players
            if opponent_action[0] == Action.C:
                return Action.C
            elif opponent_action[0] == Action.D and self.cooperative_streak < self.m:
                return Action.D
            else:
                self.cooperative_streak += 1
                return Action.C

class Strategy_EXPLOITATIVE_568(BaseStrategy):
    """
    Tit-for-Tat with Variation (TfTV) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.window_size = int(math.ceil(game_description.n_players * 0.2))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            cooperation_rate = np.mean(history.my_actions[-self.window_size:-1])
            if cooperation_rate >= self.game_description.m / (self.game_description.m + 1):
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_569(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat-with-Adaptation (TfT-A)
    Strategy Description: This strategy cooperates when the number of cooperators in the previous round is greater than or equal to the minimum required number of cooperators, and defects otherwise.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.minimum_cooperators = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return random.choice([Action.C, Action.D])
        cooperators = sum(history.opponent_actions[-1, :]) if history else 0
        if cooperators < self.minimum_cooperators:
            return Action.D
        return Action.C

class Strategy_EXPLOITATIVE_570(BaseStrategy):
    """
    A Tit-for-Tat strategy with Adaptation that cooperates initially and adapts to the opponent's behavior over time.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = math.floor(game_description.n_rounds * 0.6)
        self.opponent_cooperation_streak = 0
        self.opponent_defection_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.update_opponent_streak(history)
        cooperators = sum(history.opponent_actions[-1, :])
        m_cooperators = min(self.game_description.n_players, cooperators + max(0, self.opponent_defection_streak))
        if m_cooperators >= self.game_description.m:
            if self.opponent_defection_streak > 0:
                return Action.C
            else:
                return Action.C if self.should_cooperate() else Action.D
        elif history and self.opponent_defection_streak > 0:
            return Action.D
        else:
            return Action.C

    def update_opponent_streak(self, history: PlayerHistory) -> None:
        if history and self.opponent_defection_streak > 0:
            self.opponent_defection_streak -= 1
        if sum(history.opponent_actions[-1, :]) == self.game_description.n_players - 1:
            self.opponent_cooperation_streak = min(self.threshold, self.opponent_cooperation_streak + 1)
        else:
            self.opponent_defection_streak = min(self.threshold, self.opponent_defection_streak + 1)
        self.opponent_cooperation_streak = max(0, self.opponent_cooperation_streak)
        self.opponent_defection_streak = max(0, self.opponent_defection_streak)

    def should_cooperate(self):
        """Determines whether to cooperate or defect based on the opponent's streak."""
        return self.opponent_cooperation_streak > 0 and self.opponent_defection_streak == 0 or (self.opponent_defection_streak >= self.threshold and self.opponent_cooperation_streak == 0)

class Strategy_EXPLOITATIVE_571(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperated_last_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.cooperated_last_round = np.mean(history.opponent_actions[-1]) > 0
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        return Action(int(self.cooperated_last_round))

class Strategy_EXPLOITATIVE_572(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Modified Cooperation Threshold (ATFT-MCT) for Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperative_probability = 1
        self.average_cooperators = 0
        self.total_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.total_rounds += 1
        self.average_cooperators = self.calculate_average(self.average_cooperators, self.total_rounds, history)
        self.cooperative_probability = self.calculate_cooperation_probability(self.average_cooperators)
        global_cooperators = sum(history.opponent_actions[-1, :]) if history else 0
        personal_action = Action.D
        if global_cooperators >= self.game_description.m - 1 and history:
            personal_action = Action.C
        return personal_action if random.random() < self.cooperative_probability else Action.D

    @staticmethod
    def calculate_average(average, total_rounds, history):
        if total_rounds == 0:
            return 0
        total_cooperators = sum([history.opponent_actions[i][0] for i in range(total_rounds)])
        return total_cooperators / total_rounds

    @staticmethod
    def calculate_cooperation_probability(average):
        sqrt_average = math.sqrt(average)
        average_pow_2 = pow(average, 2)
        return 1 - average_pow_2 * (1 - average)

class Strategy_EXPLOITATIVE_574(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat-with-Adaptation (TFT-A)
    This strategy balances cooperation and exploitation, adapting to various opponent behaviors while maintaining robustness in a wide range of game settings.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.m = game_description.m
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.T = 0.5
        self.CR = 0
        self.cooperated_opponent = False
        self.window_size = math.floor(self.r / 10) + 1
        self.cr_history = np.zeros(self.window_size)

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None or len(history.my_actions) < self.r + self.window_size:
            return Action.C
        round_number = state.round_number - 1
        my_action = history.my_actions[round_number]
        opponent_action = history.opponent_actions[round_number, 0]
        self.update_CR(opponent_action)
        if round_number == self.r - 1:
            return Action.C
        if self.CR < self.m / self.n:
            return Action.D
        self.cr_history[math.fmod(round_number, self.window_size)] = self.CR
        average_cr = np.mean(self.cr_history)
        if average_cr > self.T or average_cr < -self.T:
            self.cooperated_opponent = not self.cooperated_opponent
        return my_action and opponent_action == Action.D or (not my_action and opponent_action == Action.C)

    def update_CR(self, opponent_action):
        if opponent_action == Action.C:
            self.cooperated_opponent = True
            self.CR += 1 / self.r
        else:
            self.cooperated_opponent = False
            self.CR -= 1 / self.r

class Strategy_EXPLOITATIVE_575(BaseStrategy):
    """
    Strategy name: Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)
    Strategy summary: Starts cooperating in the first round, then adapts based on the number of cooperators in the previous round.
    Cooperates when it is beneficial and punishes defection from others.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or not history:
            return Action.C
        num_cooperators = sum(history.opponent_actions[-1, :])
        if num_cooperators < self.min_cooperators:
            return Action.D
        elif num_cooperators == self.min_cooperators:
            return Action.C
        else:
            return Action.C

class Strategy_EXPLOITATIVE_576(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.mct = math.ceil(game_description.m * game_description.n_rounds / game_description.n_players)
        self.average_cooperators = 0
        self.num_recent_rounds = min(self.game_description.n_rounds, 10)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if not history:
            cooperators = 0
        else:
            cooperators = sum(history.opponent_actions[-self.num_recent_rounds:, :].sum(axis=1))
            self.average_cooperators = np.mean(cooperators)
            if self.average_cooperators >= 0.7 * self.mct and self.mct < self.game_description.n_players - 1:
                self.mct += 1
            elif self.average_cooperators <= 0.3 * self.mct and self.mct > 1:
                self.mct -= 1
        if cooperators >= self.mct:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_578(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = int((game_description.m + 1) / 2)
        self.learning_rate = 0.05

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = np.sum(history.opponent_actions[-self.game_description.n_rounds:, :])
        if cooperators < self.threshold:
            self.threshold += int(math.floor(self.learning_rate * (self.threshold - self.game_description.m)))
        elif cooperators > self.threshold:
            self.threshold -= int(math.ceil(self.learning_rate * (self.threshold - self.game_description.m)))
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D if cooperators < self.threshold else Action.C
        return Action(int(cooperators >= self.threshold))

class Strategy_EXPLOITATIVE_579(BaseStrategy):
    """
    A Tit-for-Tat-Adaptive (TfTA) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = self.game_description.m
        self.k = self.game_description.k
        self.cooperation_count = 0
        self.rounds = self.game_description.n_rounds
        self.half_m = math.floor(self.m * self.rounds / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            cooperation = np.sum(history.opponent_actions[-1])
            if cooperation >= self.m:
                self.cooperation_count += 1
                return Action.C
            else:
                self.cooperation_count = max(0, self.cooperation_count - 1)
                return Action.D
        if state.round_number == self.rounds - 1:
            if self.cooperation_count >= self.half_m:
                return Action.C
            return Action.D

class Strategy_EXPLOITATIVE_580(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Cooperative Threshold (ATTC) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.tolerance = int(math.ceil(0.2 * game_description.n_rounds))

    def __call__(self, state: GameState, history: PlayerHistory | None) -> Action:
        if state.round_number == 0:
            return Action.C
        elif not history or state.round_number - len(history.opponent_actions) >= self.tolerance:
            return Action.D
        else:
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators >= self.game_description.m:
                return Action.C
            return Action.D

class Strategy_EXPLOITATIVE_581(BaseStrategy):
    """
    A Tit-for-Tat adaptive strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.opponent_history = np.zeros(self.game_description.n_players)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None:
            self.opponent_history = history.opponent_actions[-1, :]
        if np.all(self.opponent_history == 1):
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_582(BaseStrategy):
    """
    A strategy that cooperates unless it has been consistently defected against by a majority of players in the previous 'c' rounds, where 'c' is a predefined constant.
    If the number of players who have cooperated in the last 'c' rounds is less than 'm', the threshold for cooperation, then the strategy switches to defection. When the TitForTatWithThreshold strategy cooperates, it expects other players to reciprocate; if they do not, the strategy will switch to defection.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.c = math.floor(game_description.n_players * 0.5)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C if random.random() < 0.5 else Action.D
        cooperators = np.count_nonzero(history.opponent_actions[:, -self.c:]) if history else 0
        if cooperators < self.game_description.m or state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.C

class Strategy_EXPLOITATIVE_583(BaseStrategy):
    """
    The Tit-for-Tat Adaptive (TfTA) strategy in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_coop = math.ceil(game_description.n_players * game_description.m / 100)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :]) if history else 0
        if cooperators < self.min_coop:
            return Action.D
        return Action.C

class Strategy_EXPLOITATIVE_584(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy in the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = int(game_description.n_players * (3 / 4))
        self.history_length = min(10, game_description.n_rounds)
        self.h = self.history_length
        self.N_c = [0] * self.game_description.n_players

    def __call__(self, state: GameState, history: PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        N_c_sum = sum(self.N_c)
        if N_c_sum < self.cooperation_threshold * self.h:
            return Action.D
        else:
            return Action.C

    def updateN_c(self, action, round_number, N_c):
        if action == Action.C:
            N_c[round_number % self.h] += 1

    def calculatePayoff(self, action, N_c):
        if len(N_c) < self.cooperation_threshold:
            payoff = 1
        else:
            payoff = 1 + self.game_description.k * (len(N_c) / len(N_c))
        return payoff

class Strategy_EXPLOITATIVE_585(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.m = game_description.m
        self.n = game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and history.my_actions is not None:
            cooperators = sum(history.opponent_actions[-1, :])
            proportion = cooperators / self.n if self.n > 0 else 0
            if proportion >= self.m / (self.m + 1):
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_587(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperative Threshold (TFT-ACT) strategy for Collective Risk Dilemma game.
    This strategy adapts its cooperative threshold based on the past interactions with other players, punishing those who do not cooperate when it does and copying the majority action of opponents in case of non-cooperation.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = math.ceil(game_description.n_players * game_description.m / 100)
        self.last_action = None
        self.last_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_cooperators = sum(history.opponent_actions[-1, :]) if history else 0
        self.last_action = Action.C if current_cooperators >= self.threshold else Action.D if self.last_action == Action.C else random.choice([Action.C, Action.D])
        self.last_cooperators = current_cooperators
        return self.last_action

class Strategy_EXPLOITATIVE_589(BaseStrategy):
    """
    A Tit-for-Tat with Adaptation strategy for the Collective Risk Dilemma game.
    This strategy follows a cooperative approach but can punish defectors and switch to self-interest when necessary.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.last_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is None:
            return Action.C
        last_round = state.round_number >= self.game_description.n_rounds - 1
        self.last_round = last_round
        if last_round:
            return Action.C
        opponent_action = history.opponent_actions[-1, state.round_number % len(history.opponent_actions)]
        if opponent_action:
            return Action.C
        if self.last_round or not opponent_action:
            return Action.D
        return not opponent_action

class Strategy_EXPLOITATIVE_590(BaseStrategy):
    """Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)"""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.act = game_description.n_players // 2
        self.act_inc = 0.01
        self.act_dec = 0.01

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators = sum(history.opponent_actions[-1, :])
        if cooperators >= self.game_description.m and state.round_number < self.game_description.n_rounds:
            self.act += self.act_inc
        elif state.round_number > 0:
            self.act -= self.act_dec
        if cooperators >= self.act:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_591(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT) Strategy
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.CT_initial = self.game_description.m
        self.CT_final = self.game_description.m / game_description.n_players
        self.rounds = self.game_description.n_rounds
        self.cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        self.cooperators += sum(history.opponent_actions[-1] if history else [0])
        cooperation_rate = self.cooperators / (state.round_number + 1)
        cooperation_threshold = self.CT_initial - (self.CT_initial - self.CT_final) * state.round_number / self.rounds
        return Action.C if cooperation_rate > cooperation_threshold and cooperation_rate >= self.game_description.m / self.game_description.n_players else Action.D

class Strategy_EXPLOITATIVE_592(BaseStrategy):
    """
    A Tit-for-Tat Adaptive (TFT-A) strategy for the Collective Risk Dilemma game.
    The strategy initiates cooperation in the first round, and adapts its behavior based on opponents' previous actions.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = [None] * game_description.n_rounds
        self.current_player = None

    def get_most_frequent_cooperator(self, round):
        freq_dict = {}
        max_freq = 0
        for i in range(self.game_description.n_players):
            if self.history[round][i] is None:
                continue
            if self.history[round][i] not in freq_dict:
                freq_dict[self.history[round][i]] = 1
            else:
                freq_dict[self.history[round][i]] += 1
        for cooperator, frequency in freq_dict.items():
            if frequency > max_freq:
                max_freq = frequency
        most_frequent_cooperators = [cooperator for cooperator, frequency in freq_dict.items() if frequency == max_freq]
        return most_frequent_cooperators[0] if len(most_frequent_cooperators) > 0 else None

    def __call__(self, state: GameState, history: PlayerHistory | None):
        if state.round_number == 0:
            self.current_player = 0
            return Action.C
        else:
            if history is not None and self.history[state.round_number - 1] is not None:
                most_frequent_cooperator = self.get_most_frequent_cooperator(state.round_number - 1)
                self.history[state.round_number - 1] = [player == self.current_player for player in most_frequent_cooperator] if most_frequent_cooperator else None
            action = Action.C if self.history[state.round_number - 1] is not None else Action.D
            self.current_player = (self.current_player + 1) % self.game_description.n_players
            return action

class Strategy_EXPLOITATIVE_593(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold Strategy in Collective Risk Dilemma Game
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or (state.round_number < len(self.history) and len(self.history) >= self.game_description.n_players - 1):
            return Action.C
        cooperation = np.mean(self.history[-min(len(self.history), self.game_description.n_players - 1):])
        if cooperation >= self.game_description.m / self.game_description.n_players:
            self.history.append(cooperation)
        else:
            self.history.append(0)
        return Action(self.history[-1])

class Strategy_EXPLOITATIVE_595(BaseStrategy):
    """
    Strategy name: Tit-for-Tat (with Adaptive Cooperation Threshold)
    Strategy summary: Cooperate initially, then adaptively cooperate or defect based on the number of cooperators in previous rounds.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.threshold = math.ceil(game_description.m * 0.5)
        self.t_penalty = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if history is not None and state.round_number < self.game_description.n_rounds - 1:
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators >= self.threshold:
                return Action.C
            return Action.D
        if history is not None and state.round_number == self.game_description.n_rounds - 1:
            cooperators = sum(history.opponent_actions[-1, :])
            if cooperators >= self.threshold:
                return Action.C
            return Action.D
        if history is None or len(history.my_payoffs) < self.game_description.n_rounds - 1:
            return self.__call__(GameState(self.game_description.n_rounds - 1), history)
        cooperators = sum(history.opponent_actions[-2, :])
        if cooperators >= self.threshold:
            return Action.C
        self.t_penalty += 1
        if self.t_penalty < math.ceil(self.game_description.n_rounds / 2):
            self.t_penalty += 1
        return Action.D

class Strategy_EXPLOITATIVE_596(BaseStrategy):
    """
    Strategy Name: Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT)

    A strategy that cooperates if at least m players cooperated in the previous round and defects otherwise.
    The strategy encourages cooperation when others are cooperative but also retaliates against defection to discourage freeriding.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.min_cooperators = game_description.m

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        cooperators = sum(history.opponent_actions[-1])
        if cooperators >= self.min_cooperators:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_598(BaseStrategy):
    """Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma."""

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.m
        self.cooperation_increase = 0.01
        self.cooperation_decrease = 0.01
        self.previous_cooperators = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 and history is None:
            return Action.C
        current_cooperators = sum(history.opponent_actions[-1, :])
        payoff_multiplier = self._calculate_payoff_multiplier(current_cooperators)
        if state.round_number == self.game_description.n_rounds:
            return self._get_best_action(history, payoff_multiplier)
        action = Action.C if current_cooperators >= self.cooperation_threshold else Action.D
        if self.cooperation_threshold > current_cooperators:
            self.cooperation_threshold -= self.cooperation_decrease
        elif self.cooperation_threshold < current_cooperators:
            self.cooperation_threshold += self.cooperation_increase
        self.previous_cooperators = current_cooperators
        return action

    def _calculate_payoff_multiplier(self, cooperators):
        if cooperators < self.game_description.m:
            return 1.0
        return 1.0 + self.game_description.k

    def _get_best_action(self, history, payoff_multiplier):
        cooperators = self.previous_cooperators
        if cooperators < self.game_description.m:
            action = Action.D
            for round_number in range(len(history.my_payoffs) - 1, 0, -1):
                if history.my_payoffs[round_number] > history.my_payoffs[round_number - 1]:
                    cooperators = sum(history.opponent_actions[round_number - 1, :])
                    break
            action = Action.C if cooperators >= self.cooperation_threshold else Action.D
        elif payoff_multiplier > 1.0:
            action = Action.C
        else:
            action = Action.D
        return action

class Strategy_EXPLOITATIVE_599(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFT-ACT) strategy for Collective Risk Dilemma.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.minimum_cooperators = game_description.m
        self.last_round_coop = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or history is None:
            return Action.C
        if state.round_number < self.game_description.n_rounds - 1:
            cooperators = sum(history.opponent_actions[state.round_number - 1, :])
            cooperation_ratio = cooperators / self.minimum_cooperators
            return Action(int(cooperation_ratio >= 1))
        self.last_round_coop = True
        return Action.C

class Strategy_EXPLOITATIVE_600(BaseStrategy):
    """
    Tit-for-Tat with Adaptive Cooperation Threshold (TFTAT) strategy for the Collective Risk Dilemma game.
    """

    def __init__(self, game_description: CollectiveRiskDescription):
        self.game_description = game_description
        self.cooperation_threshold = math.floor((game_description.m + 1) / 2) if game_description.n_players % 2 == 0 else game_description.m
        self.history = []
        self.round_payoff = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None or len(self.history) < self.game_description.n_rounds // 5:
            return Action.C if math.ceil(len(self.history) / self.game_description.n_rounds * self.game_description.n_players // 2) >= self.cooperation_threshold else Action.D
        opponents_cooperators = np.sum(history.opponent_actions[-self.game_description.n_rounds // 5:, :][-1, :])
        average_opponents_cooperators = np.mean(history.opponent_actions[-self.game_description.n_rounds // 5:, :][:, self.cooperation_threshold].reshape(-1))
        if opponents_cooperators >= self.cooperation_threshold:
            self.cooperation_threshold = min(self.cooperation_threshold + 1, game_description.n_players)
        elif opponents_cooperators < self.cooperation_threshold - 1 and self.cooperation_threshold > math.floor(game_description.m):
            self.cooperation_threshold -= 1
        action = Action.C if opponents_cooperators >= self.cooperation_threshold else Action.D
        self.history.append((state.round_number, action))
        self.round_payoff += 1 - self.cooperation_threshold + 1 if action == Action.C else 1
        return action
