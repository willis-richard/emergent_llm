"""
Generated LLM strategies for social dilemma games.

This file contains strategy classes generated by LLMs for game theory experiments.
Each strategy is a callable class that implements a specific approach to the game.

Generated with:
- Provider: Anthropic
- Model: claude-haiku-4-5
- Game: public_goods
"""

from dataclasses import dataclass
from enum import Enum
import math
import numpy as np
from numpy.typing import NDArray
import random

from emergent_llm.players import BaseStrategy
from emergent_llm.games import PublicGoodsDescription, CollectiveRiskDescription, CommonPoolDescription, CommonPoolState
from emergent_llm.common import Action, C, D, PlayerHistory, GameState



class Strategy_COLLECTIVE_1(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC): A collective welfare maximization strategy
    that uses reciprocal cooperation calibrated to group contribution rates, with
    adaptive thresholds based on the multiplication factor and number of players.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold_high = self.k / self.n
        self.threshold_low = self.k / (2 * self.n)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        prev_round_opponent_actions = history.opponent_actions[round_number - 1, :]
        cooperators_prev = int(np.sum(prev_round_opponent_actions))
        if history.my_actions[round_number - 1]:
            cooperators_prev += 1
        coop_rate = cooperators_prev / self.n
        if round_number == self.r - 1:
            if coop_rate >= self.threshold_high:
                return Action.C
            else:
                return Action.D
        if coop_rate >= self.threshold_high:
            return Action.C
        elif coop_rate >= self.threshold_low:
            if random.random() < coop_rate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_2(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    This strategy prioritizes collective welfare while maintaining robustness against exploitation.
    It adapts its cooperation threshold based on observed cooperation rates, starting optimistic
    and gradually becoming stricter as rounds progress, with special handling for sudden defection
    collapses and edge cases.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        base_threshold = (self.k - 1) / self.k
        prev_cooperators = np.sum(history.opponent_actions[round_num - 1, :])
        cooperation_rate = prev_cooperators / self.n
        if cooperation_rate == 0:
            return Action.D
        if cooperation_rate == 1:
            return Action.C
        if round_num >= 2:
            prev_prev_cooperators = np.sum(history.opponent_actions[round_num - 2, :])
            prev_prev_rate = prev_prev_cooperators / self.n
            if cooperation_rate < 0.5 and prev_prev_rate >= 0.5:
                if round_num < 2 * self.r / 3:
                    return Action.C
                else:
                    return Action.D
        if round_num == self.r - 1:
            overall_rate = np.mean(history.opponent_actions[:round_num, :])
            if overall_rate >= base_threshold:
                return Action.C
            else:
                return Action.D
        adjustment_factor = base_threshold * 0.5
        if self.n == 2:
            adjustment_factor *= 1.5
        current_threshold = base_threshold - round_num / self.r * adjustment_factor
        if cooperation_rate >= current_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_3(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with individual rationality through:
    - Conditional reciprocity based on group cooperation rates
    - Adaptive efficiency monitoring
    - Fairness enforcement via contribution tracking
    - Defection in final round (subgame perfect equilibrium)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == r - 1:
            return Action.D
        prev_round_idx = current_round - 1
        prev_opponent_actions = history.opponent_actions[prev_round_idx, :]
        prev_cooperators = int(np.sum(prev_opponent_actions))
        my_prev_action = history.my_actions[prev_round_idx]
        total_cooperators = prev_cooperators + (1 if my_prev_action else 0)
        coop_rate = total_cooperators / n
        prev_opponent_payoffs = history.opponent_payoffs[prev_round_idx, :]
        my_prev_payoff = history.my_payoffs[prev_round_idx]
        all_prev_payoffs = np.concatenate([[my_prev_payoff], prev_opponent_payoffs])
        avg_payoff_last_round = np.mean(all_prev_payoffs)
        theoretical_max = k
        efficiency = avg_payoff_last_round / theoretical_max if theoretical_max > 0 else 0
        my_coop_total = int(np.sum(history.my_actions[:current_round]))
        my_defect_total = current_round - my_coop_total
        if coop_rate >= 0.5 and efficiency >= 0.7:
            return Action.C
        if coop_rate < 0.3:
            return Action.D
        if 0.3 <= coop_rate < 0.5:
            if my_coop_total > my_defect_total * 1.5:
                return Action.D
            else:
                return Action.C
        if coop_rate >= 0.5 and efficiency < 0.7:
            if coop_rate >= 0.75:
                return Action.C
            else:
                return Action.D
        return Action.C

class Strategy_COLLECTIVE_4(BaseStrategy):
    """
    Adaptive Reciprocal Stewardship (ARS) - A collective strategy that combines
    conditional generosity, empirical responsiveness, and graduated consequences.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        recent_window = min(5, current_round)
        recent_history = history.opponent_actions[max(0, current_round - recent_window):current_round]
        total_cooperators_recent = np.sum(recent_history)
        cooperation_rate = total_cooperators_recent / (self.n * recent_window)
        my_recent_actions = history.my_actions[max(0, current_round - recent_window):current_round]
        my_recent_cooperation = np.sum(my_recent_actions) / recent_window if recent_window > 0 else 0.0
        if current_round == self.r - 1:
            overall_cooperation = np.sum(history.opponent_actions) / (self.n * current_round) if current_round > 0 else 0.0
            if overall_cooperation >= 0.4:
                return Action.C
            else:
                return Action.D
        if cooperation_rate > self.threshold:
            return Action.C
        elif math.fabs(cooperation_rate - self.threshold) < 1e-09:
            if my_recent_cooperation > 0.7:
                return Action.C
            else:
                return Action.D
        elif cooperation_rate > 0.3:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_5(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with protection against exploitation.
    Uses adaptive threshold reciprocity: cooperate when cooperation rate meets or exceeds
    the break-even point (k/n), with graceful degradation for sustained defection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = game_description.k / game_description.n_players
        self.defection_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.defection_streak = 0
            return Action.C
        last_round_opponent_actions = history.opponent_actions[-1, :]
        last_round_cooperators = np.sum(last_round_opponent_actions)
        my_last_action = history.my_actions[-1]
        total_cooperators = last_round_cooperators + (1 if my_last_action else 0)
        cooperation_rate = total_cooperators / self.game_description.n_players
        if cooperation_rate >= self.threshold:
            self.defection_streak = 0
            return Action.C
        else:
            self.defection_streak += 1
            if self.defection_streak == 1:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_6(BaseStrategy):
    """
    Adaptive Reciprocal Investment (ARI) Strategy for N-Player Public Goods Game

    Optimizes for collective welfare through conditional cooperation based on
    historical group cooperation rates. Uses an adaptive threshold that rises
    over time, with recovery mechanisms for sudden cooperation collapses.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.last_defection_round = -10
        self.was_defected = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        all_cooperations = []
        for round_idx in range(state.round_number):
            opponent_coops_this_round = np.sum(history.opponent_actions[round_idx, :])
            all_cooperations.append(opponent_coops_this_round)
        my_coops = np.sum(history.my_actions[:state.round_number])
        total_possible_cooperations = state.round_number * self.game_description.n_players
        total_actual_cooperations = np.sum(all_cooperations) + my_coops
        cooperation_rate = total_actual_cooperations / total_possible_cooperations if total_possible_cooperations > 0 else 0.0
        threshold = 0.5 + 0.1 * (state.round_number / self.game_description.n_rounds)
        recent_cooperators = np.sum(history.opponent_actions[state.round_number - 1, :]) + (1 if history.my_actions[state.round_number - 1] else 0)
        recent_cooperation_rate = recent_cooperators / self.game_description.n_players
        if state.round_number >= 2:
            prev_cooperators = np.sum(history.opponent_actions[state.round_number - 2, :]) + (1 if history.my_actions[state.round_number - 2] else 0)
            prev_cooperation_rate = prev_cooperators / self.game_description.n_players
        else:
            prev_cooperation_rate = recent_cooperation_rate
        cooperation_drop = prev_cooperation_rate - recent_cooperation_rate
        if cooperation_drop > 0.4:
            if recent_cooperation_rate >= 0.3:
                self.was_defected = False
                return Action.C
            else:
                self.last_defection_round = state.round_number
                self.was_defected = True
                return Action.D
        if self.was_defected and recent_cooperation_rate >= 0.45:
            self.was_defected = False
            return Action.C
        if cooperation_rate >= threshold:
            self.was_defected = False
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_7(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game

    Balances collective welfare with individual rationality through earned reciprocity.
    Contributes proportionally to demonstrated collective commitment while maintaining
    a credible deterrent against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_high = 0.7
        self.threshold_mid = 0.4
        self.prob_mid = 0.7

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        memory_length = min(5, state.round_number)
        start_idx = max(0, state.round_number - memory_length)
        recent_rounds = history.opponent_actions[start_idx:state.round_number, :]
        total_cooperators_in_recent = np.sum(recent_rounds)
        total_cooperators_in_recent += np.sum(history.my_actions[start_idx:state.round_number])
        recent_coop_rate = total_cooperators_in_recent / (memory_length * self.game_description.n_players)
        if recent_coop_rate >= self.threshold_high:
            return Action.C
        elif recent_coop_rate >= self.threshold_mid:
            if random.random() < self.prob_mid:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_8(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game.

    This strategy maximizes collective welfare while remaining robust to exploitation.
    It uses a threshold-based approach to decide cooperation, with special handling for
    the terminal round and recovery scenarios.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.k - 1.0) / self.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        is_final_round = current_round == self.r - 1
        prev_round_idx = current_round - 1
        prev_cooperators = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        cooperation_rate_prev = prev_cooperators / self.n
        my_prev_action = history.my_actions[prev_round_idx]
        my_prev_payoff = history.my_payoffs[prev_round_idx]
        if my_prev_action:
            expected_if_cooperate = self.k / self.n * prev_cooperators
            defection_loss = expected_if_cooperate - my_prev_payoff
        else:
            defection_loss = 0.0
        recent_trend_improving = self._is_trend_improving(history, current_round)
        if cooperation_rate_prev >= self.threshold:
            if is_final_round:
                if self._was_cooperation_consistently_high(history, current_round):
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.C
        elif defection_loss > 1e-09:
            if recent_trend_improving:
                return Action.C
            else:
                return Action.D
        elif is_final_round:
            return Action.D
        else:
            return Action.D

    def _is_trend_improving(self, history: PlayerHistory, current_round: int) -> bool:
        """
        Check if cooperation rate is improving over the last 2-3 rounds.
        """
        if current_round < 2:
            return False
        lookback = min(3, current_round)
        cooperation_rates = []
        for i in range(current_round - lookback, current_round):
            cooperators = int(np.sum(history.opponent_actions[i, :]))
            rate = cooperators / self.n
            cooperation_rates.append(rate)
        if len(cooperation_rates) >= 2:
            return cooperation_rates[-1] >= cooperation_rates[0]
        return False

    def _was_cooperation_consistently_high(self, history: PlayerHistory, current_round: int) -> bool:
        """
        Check if cooperation was consistently high in rounds r-2 onwards.
        """
        if current_round < 2:
            return False
        lookback = min(3, current_round)
        for i in range(current_round - lookback, current_round):
            cooperators = int(np.sum(history.opponent_actions[i, :]))
            cooperation_rate = cooperators / self.n
            if cooperation_rate < self.threshold:
                return False
        return True

class Strategy_COLLECTIVE_9(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization, sustainable cooperation, and self-protection
    through adaptive thresholds based on observed cooperation rates.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold_high = min(0.65, (self.k - 1) / (self.n - 1) + 0.15)
        self.threshold_mid = self.threshold_high * 0.65
        if self.k <= 1.1:
            self.threshold_high = max(0.3, self.threshold_high - 0.15)
            self.threshold_mid = max(0.1, self.threshold_mid - 0.15)
        elif self.k > self.n - 1:
            self.threshold_high = min(0.9, self.threshold_high + 0.15)
            self.threshold_mid = min(0.8, self.threshold_mid + 0.15)
        if self.n == 2:
            self.threshold_high = 1.0
            self.threshold_mid = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            return self._final_round_decision(history)
        return self._main_phase_decision(history, current_round)

    def _main_phase_decision(self, history: PlayerHistory, current_round: int) -> Action:
        """
        Main phase decision based on cooperation rate in the previous round.
        """
        recent_coop_rate = self._get_recent_cooperation_rate(history, current_round)
        if recent_coop_rate >= self.threshold_high:
            return Action.C
        elif recent_coop_rate >= self.threshold_mid:
            return Action.C
        else:
            return Action.D

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """
        Final round decision based on lifetime cooperation rate across all previous rounds.
        """
        lifetime_coop_rate = self._get_lifetime_cooperation_rate(history)
        if lifetime_coop_rate >= self.threshold_high:
            return Action.C
        else:
            return Action.D

    def _get_recent_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate cooperation rate from the previous round.

        Returns the fraction of players who cooperated in round (current_round - 1).
        """
        previous_round_idx = current_round - 1
        opponent_cooperators = sum(history.opponent_actions[previous_round_idx, :])
        my_cooperation = 1 if history.my_actions[previous_round_idx] else 0
        total_cooperators = opponent_cooperators + my_cooperation
        cooperation_rate = total_cooperators / self.n
        return cooperation_rate

    def _get_lifetime_cooperation_rate(self, history: PlayerHistory) -> float:
        """
        Calculate cooperation rate across all rounds so far.

        Returns the fraction of all player-actions that were cooperations.
        """
        rounds_completed = len(history.my_actions)
        if rounds_completed == 0:
            return 0.0
        my_total_cooperations = sum(history.my_actions)
        opponent_total_cooperations = np.sum(history.opponent_actions)
        total_cooperations = my_total_cooperations + opponent_total_cooperations
        total_actions = self.n * rounds_completed
        cooperation_rate = total_cooperations / total_actions if total_actions > 0 else 0.0
        return cooperation_rate

class Strategy_COLLECTIVE_10(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with individual incentive alignment by:
    1. Cooperating in round 1 to establish mutual benefit
    2. Adapting based on observed cooperation rate in middle rounds
    3. Defecting in the final round (subgame-perfect equilibrium)
    4. Using a 0.5 cooperation rate threshold to guide decisions
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.n_rounds - 1:
            return Action.D
        total_cooperations = 0
        total_cooperations += np.sum(history.my_actions[:round_number])
        total_cooperations += np.sum(history.opponent_actions[:round_number, :])
        total_actions = round_number * self.n_players
        cooperation_rate = total_cooperations / total_actions if total_actions > 0 else 0.0
        if cooperation_rate >= 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_11(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization, self-protection against defectors,
    and adaptive signaling based on observed cooperation rates.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold_high = 0.6
        self.threshold_low = 0.3
        self.tolerance = 0.2
        self.defection_lock_threshold = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            coop_rate = self._get_cooperation_rate(history, current_round - 1)
            if coop_rate >= 0.8:
                return Action.C
            else:
                return Action.D
        coop_rate = self._get_cooperation_rate(history, current_round - 1)
        if coop_rate >= self.threshold_high:
            return Action.C
        if coop_rate <= self.threshold_low:
            consecutive_low = self._count_consecutive_low_cooperation(history, current_round)
            if consecutive_low >= self.defection_lock_threshold:
                return Action.D
            return Action.D
        my_total_payoff = float(np.sum(history.my_payoffs[:current_round]))
        defection_baseline = float(current_round) * 1.0
        if my_total_payoff > defection_baseline * (1.0 + self.tolerance):
            return Action.C
        else:
            return Action.D

    def _get_cooperation_rate(self, history: PlayerHistory, round_idx: int) -> float:
        """
        Calculate the cooperation rate in a given round.

        Args:
            history: PlayerHistory object containing opponent actions
            round_idx: 0-indexed round number to analyze

        Returns:
            Cooperation rate as a float between 0 and 1
        """
        opponent_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
        my_action = int(history.my_actions[round_idx])
        total_cooperators = opponent_cooperators + my_action
        cooperation_rate = float(total_cooperators) / float(self.n)
        return cooperation_rate

    def _count_consecutive_low_cooperation(self, history: PlayerHistory, current_round: int) -> int:
        """
        Count consecutive rounds with cooperation rate below threshold_low.

        Args:
            history: PlayerHistory object
            current_round: Current 0-indexed round number

        Returns:
            Number of consecutive rounds with low cooperation (ending at current_round - 1)
        """
        consecutive_count = 0
        for round_idx in range(current_round - 1, -1, -1):
            coop_rate = self._get_cooperation_rate(history, round_idx)
            if coop_rate <= self.threshold_low:
                consecutive_count += 1
            else:
                break
        return consecutive_count

class Strategy_COLLECTIVE_12(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with individual rationality by:
    1. Opening with cooperation to establish good faith
    2. Adapting based on whether cooperation rate exceeds the threshold k/n
    3. Defecting in the final round due to backward induction

    The threshold k/n represents the break-even point where contributing to the
    public good becomes individually rational.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            return Action.D
        previous_round_actions = history.opponent_actions[current_round - 1, :]
        cooperators_last_round = int(sum(previous_round_actions))
        if history.my_actions[current_round - 1]:
            cooperators_last_round += 1
        cooperation_rate = cooperators_last_round / self.n
        if cooperation_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_13(BaseStrategy):
    """
    Adaptive Graduated Reciprocity (AGR) Strategy for N-Player Public Goods Game.

    This strategy tracks opponent cooperation patterns and adapts responses across
    three game phases: bootstrap (round 1), middle rounds, and final round.
    It uses graduated reciprocation based on average opponent cooperation rates
    relative to the game's efficiency threshold (k/n).
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        avg_opponent_coop_rate = self._calculate_avg_opponent_coop_rate(history)
        if round_number == self.n_rounds - 1:
            threshold = 0.75 * (self.k / self.n_players)
            if avg_opponent_coop_rate >= threshold:
                return Action.C
            else:
                return Action.D
        reciprocity_target = self.k / self.n_players + 0.1
        lower_threshold = 0.5 * (self.k / self.n_players)
        if avg_opponent_coop_rate >= reciprocity_target:
            return Action.C
        elif avg_opponent_coop_rate >= lower_threshold:
            cooperation_probability = avg_opponent_coop_rate / reciprocity_target
            if random.random() < cooperation_probability:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _calculate_avg_opponent_coop_rate(self, history: PlayerHistory) -> float:
        """
        Calculate the average cooperation rate across all opponents
        based on observed history.
        """
        opponent_actions = history.opponent_actions
        n_opponents = opponent_actions.shape[1]
        if n_opponents == 0:
            return 0.0
        opponent_coop_rates = []
        for opponent_idx in range(n_opponents):
            opponent_history = opponent_actions[:, opponent_idx]
            coop_count = np.sum(opponent_history)
            total_rounds = len(opponent_history)
            coop_rate = coop_count / total_rounds if total_rounds > 0 else 0.0
            opponent_coop_rates.append(coop_rate)
        avg_rate = np.mean(opponent_coop_rates) if opponent_coop_rates else 0.0
        return float(avg_rate)

class Strategy_COLLECTIVE_14(BaseStrategy):
    """
    Adaptive Contribution with Conditional Defection (ACCD) Strategy.

    Balances collective welfare maximization with individual security by:
    - Cooperating in round 1 to establish reciprocity
    - Defecting in the final round (no future punishment)
    - Conditionally cooperating in middle rounds based on observed cooperation threshold
    - Tracking trends to encourage recovery from near-threshold cooperation levels
    - Locking into defection after sustained deficiency
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.theta = self.n / self.k
        self.defection_locked = False
        self.consecutive_deficient = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            return Action.D
        if self.defection_locked:
            return Action.D
        m_prev = int(np.sum(history.opponent_actions[round_num - 1, :]))
        my_prev_action = int(history.my_actions[round_num - 1])
        total_cooperators = m_prev + my_prev_action
        if total_cooperators >= self.theta:
            self.consecutive_deficient = 0
            return Action.C
        if total_cooperators >= self.theta - 1:
            trend_positive = self._is_trend_positive(history, round_num)
            if trend_positive:
                self.consecutive_deficient = 0
                return Action.C
        if total_cooperators < self.theta:
            self.consecutive_deficient += 1
            if self.consecutive_deficient >= 3:
                self.defection_locked = True
                return Action.D
        else:
            self.consecutive_deficient = 0
        return Action.D

    def _is_trend_positive(self, history: PlayerHistory, round_num: int) -> bool:
        """
        Check if cooperation is increasing in recent rounds.
        Returns True if the trend is non-decreasing or improving.
        """
        if round_num < 2:
            return False
        window_start = max(0, round_num - 3)
        window = history.opponent_actions[window_start:round_num, :]
        my_actions_window = history.my_actions[window_start:round_num]
        cooperation_counts = np.sum(window, axis=1) + my_actions_window
        if len(cooperation_counts) < 2:
            return False
        recent_pair = cooperation_counts[-2:]
        older_pair = cooperation_counts[-3:-1] if len(cooperation_counts) >= 3 else cooperation_counts[-2:-1]
        if len(older_pair) > 0:
            return float(np.mean(recent_pair)) >= float(np.mean(older_pair))
        else:
            return recent_pair[-1] >= recent_pair[0] if len(recent_pair) > 1 else False

class Strategy_COLLECTIVE_15(BaseStrategy):
    """
    Adaptive Reciprocal Threshold (ART) Strategy for N-Player Public Goods Game

    Balances collective welfare, personal security, and adaptive resilience by:
    1. Cooperating in round 1 to seed cooperation
    2. Defecting in the final round (no future consequences)
    3. In middle rounds, cooperating if observed cooperation rate >= (k-1)/k threshold

    The threshold represents the break-even point where public good multiplier effect
    exceeds individual losses, ensuring collective benefit.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            return Action.D
        previous_round_idx = current_round - 1
        opponent_actions_last_round = history.opponent_actions[previous_round_idx, :]
        cooperators_last_round = np.sum(opponent_actions_last_round)
        cooperation_rate = cooperators_last_round / (self.n - 1)
        threshold = (self.k - 1) / self.k
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_16(BaseStrategy):
    """
    Adaptive Contribution with Contingent Defection strategy for N-Player Public Goods Game.

    Core approach:
    - Round 1: Cooperate unconditionally to establish cooperative intent
    - Subsequent rounds: Reciprocate based on previous round's cooperation rate
      - Cooperate if cooperation_rate >= 0.5 (threshold_high)
      - Defect if cooperation_rate < 0.5 (threshold_low at 0.2 or lower)
    - Tracks cooperation trends to adapt defection/cooperation bias
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_high = 0.5
        self.threshold_low = 0.2
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round_idx = state.round_number - 1
        opponent_cooperators = sum(history.opponent_actions[prev_round_idx, :])
        my_cooperation = 1 if history.my_actions[prev_round_idx] else 0
        total_cooperators = opponent_cooperators + my_cooperation
        cooperation_rate = total_cooperators / self.game_description.n_players
        self.cooperation_history.append(cooperation_rate)
        if cooperation_rate >= self.threshold_high:
            return Action.C
        elif cooperation_rate >= self.threshold_low:
            return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_17(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game

    Balances collective welfare maximization with exploitation resilience through:
    - Conditional reciprocal cooperation based on observed cooperation rates
    - Oscillation detection to avoid systematic abuse
    - Mid-game tragedy prevention
    - Final round temptation resistance
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.cooperation_threshold = (self.k - 1) / (self.n - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        total_cooperators_prev = np.sum(history.opponent_actions[prev_round_idx, :])
        observed_cooperation_rate = total_cooperators_prev / (self.n - 1)
        if self._detect_oscillation(history, current_round):
            return Action.D
        if current_round > self.r / 2:
            avg_cooperation = self._calculate_average_cooperation(history, current_round)
            if avg_cooperation < 0.3:
                return Action.D
        if current_round == self.r - 1:
            if observed_cooperation_rate >= 0.6:
                return Action.C
            else:
                return Action.D
        if observed_cooperation_rate >= self.cooperation_threshold:
            return Action.C
        elif observed_cooperation_rate >= 0.5:
            if random.random() < observed_cooperation_rate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _detect_oscillation(self, history: PlayerHistory, current_round: int) -> bool:
        """
        Detect high variance in cooperation rates over last 4 rounds.
        High variance indicates oscillation or unpredictable behavior.
        """
        if current_round < 4:
            return False
        cooperation_rates = []
        for i in range(current_round - 4, current_round):
            total_cooperators = np.sum(history.opponent_actions[i, :])
            rate = total_cooperators / (self.n - 1)
            cooperation_rates.append(rate)
        if len(cooperation_rates) == 0:
            return False
        mean_rate = np.mean(cooperation_rates)
        variance = np.mean([(rate - mean_rate) ** 2 for rate in cooperation_rates])
        return variance > 0.4

    def _calculate_average_cooperation(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate average cooperation rate across all rounds up to current round.
        """
        if current_round == 0:
            return 0.0
        total_cooperation = 0.0
        for round_idx in range(current_round):
            total_cooperators = np.sum(history.opponent_actions[round_idx, :])
            rate = total_cooperators / (self.n - 1)
            total_cooperation += rate
        return total_cooperation / current_round

class Strategy_COLLECTIVE_18(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with robust self-protection through adaptive
    learning. Cooperates optimistically initially, then adjusts based on population-level
    cooperation rates and personal payoff outcomes. Uses threshold-based decision rules to
    sustain mutual benefit while defending against free-riders.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self._threshold_maintain = (self.k - 1) / self.n + 0.15
        self._threshold_minimum = (self.k - 1) / self.n * 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num >= self.r - 3:
            if round_num >= 1:
                recent_coop_rate = self._get_cooperation_rate(history, round_num - 1)
                if recent_coop_rate >= self._threshold_maintain:
                    return Action.C
            return Action.D
        prev_round_idx = round_num - 1
        coop_rate = self._get_cooperation_rate(history, prev_round_idx)
        my_last_payoff = history.my_payoffs[prev_round_idx]
        if coop_rate >= self._threshold_maintain:
            return Action.C
        if coop_rate >= 0.8:
            return Action.C
        if coop_rate >= self._threshold_minimum:
            cooperators_last_round = int(np.sum(history.opponent_actions[prev_round_idx, :]))
            my_action_last_round = history.my_actions[prev_round_idx]
            if my_action_last_round:
                cooperators_last_round += 1
            payoff_if_cooperated = self.k / self.n * cooperators_last_round
            payoff_if_defected = 1.0 + self.k / self.n * cooperators_last_round
            personal_net_gain = my_last_payoff - 1.0
            if personal_net_gain > 0.15:
                return Action.C
            else:
                return Action.D
        return Action.D

    def _get_cooperation_rate(self, history: PlayerHistory, round_idx: int) -> float:
        """
        Calculate the cooperation rate in a given round.
        Returns the proportion of players (including self) who cooperated.
        """
        if round_idx < 0:
            return 0.0
        opponent_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
        my_cooperation = 1 if history.my_actions[round_idx] else 0
        total_cooperators = opponent_cooperators + my_cooperation
        coop_rate = total_cooperators / self.n
        return coop_rate

class Strategy_COLLECTIVE_19(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for N-Player Public Goods Game.

    This strategy balances collective welfare with robustness against defection by:
    1. Cooperating in the first round to signal willingness and gather information
    2. Using a threshold-based rule in subsequent rounds: cooperate if the cooperation
       rate in the previous round meets or exceeds the threshold k/n
    3. The threshold k/n represents the critical cooperation level where the public good
       share equals the private payoff from defection, creating a natural equilibrium point

    This approach escapes the mutual-defection trap while gracefully degrading against
    pure defectors, and enables implicit coordination with reciprocal strategies.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round_index = state.round_number - 1
        our_previous_action = history.my_actions[previous_round_index]
        opponents_cooperated = np.sum(history.opponent_actions[previous_round_index, :])
        total_cooperators = int(our_previous_action) + opponents_cooperated
        cooperation_rate = total_cooperators / self.game_description.n_players
        if cooperation_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_20(BaseStrategy):
    """
    Adaptive Contribution Threshold (ACT) Strategy for N-Player Public Goods Game.

    This strategy uses intelligent reciprocity with dynamic thresholds:
    - Exploration phase (rounds 0-2): Test cooperation viability
    - Main phase (rounds 3 to r-3): Use rolling cooperation rate with hysteresis
    - Endgame phase (rounds r-2 to r-1): Reduce cooperation, defect in final round

    Core decision: Cooperate when expected public good payoff justifies it.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            return Action.D
        rcr = self._calculate_rolling_cooperation_rate(history, round_num)
        public_good_return = rcr * self.k / self.n
        if round_num <= 2:
            threshold = 0.5
            if public_good_return >= threshold:
                return Action.C
            else:
                return Action.D
        if round_num == self.r - 2:
            threshold = 0.5
            if public_good_return >= threshold:
                return Action.C
            else:
                return Action.D
        if public_good_return >= 0.6:
            return Action.C
        elif public_good_return < 0.4:
            return Action.D
        else:
            prob_cooperate = public_good_return / 0.6
            if random.random() < prob_cooperate:
                return Action.C
            else:
                return Action.D

    def _calculate_rolling_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate rolling cooperation rate from the last 3 rounds of opponent actions.

        Returns the proportion of cooperators across all opponents in recent rounds.
        """
        if current_round == 0:
            return 0.0
        window_size = min(3, current_round)
        start_idx = current_round - window_size
        recent_actions = history.opponent_actions[start_idx:current_round, :]
        total_cooperators = np.sum(recent_actions)
        total_slots = window_size * self.n
        cooperation_rate = total_cooperators / total_slots if total_slots > 0 else 0.0
        return cooperation_rate

class Strategy_COLLECTIVE_21(BaseStrategy):
    """
    Adaptive Collective Strategy for N-Player Public Goods Game.

    Uses conditional cooperation with dynamically-adjusted thresholds based on
    observed group behavior. Cooperates in round 1, adapts to recent cooperation
    rates in middle rounds, and locks in deterministic response in final round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.baseline_threshold = self.k / self.n
        self.memory_window = min(5, self.r - 1)
        self.adjustment_rate = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.r - 1:
            cooperation_rate = self._get_cooperation_rate(history, round_number - 1)
            if cooperation_rate >= self.baseline_threshold:
                return Action.C
            else:
                return Action.D
        recent_coop_rates = self._get_recent_cooperation_rates(history, round_number, self.memory_window)
        recent_mean = np.mean(recent_coop_rates) if len(recent_coop_rates) > 0 else 0.0
        current_threshold = self.baseline_threshold + self.adjustment_rate * (recent_mean - self.baseline_threshold)
        if recent_mean >= current_threshold:
            return Action.C
        elif recent_mean >= 0.3:
            return Action.C if random.random() < recent_mean else Action.D
        else:
            return Action.D

    def _get_cooperation_rate(self, history: PlayerHistory, round_idx: int) -> float:
        """Calculate cooperation rate in a specific round."""
        if round_idx < 0 or round_idx >= len(history.opponent_actions):
            return 0.0
        opponent_cooperators = sum(history.opponent_actions[round_idx, :])
        my_action = 1 if history.my_actions[round_idx] else 0
        total_cooperators = opponent_cooperators + my_action
        return total_cooperators / self.n

    def _get_recent_cooperation_rates(self, history: PlayerHistory, round_number: int, memory_window: int) -> list:
        """Get cooperation rates from recent rounds within memory window."""
        start_idx = max(0, round_number - memory_window)
        end_idx = round_number
        rates = []
        for round_idx in range(start_idx, end_idx):
            rate = self._get_cooperation_rate(history, round_idx)
            rates.append(rate)
        return rates

class Strategy_COLLECTIVE_22(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game

    Balances collective welfare maximization, self-protection, and adaptive coordination
    through three phases:
    - Phase 1: Trust building (cooperate unconditionally)
    - Phase 2: Conditional response based on observed cooperation rate
    - Phase 3: Stricter exploitation prevention
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        phase_boundary_1 = math.ceil(r / 3)
        phase_boundary_2 = math.ceil(2 * r / 3)
        if round_number < phase_boundary_1:
            return Action.C
        if round_number < phase_boundary_2:
            phase_1_actions = history.opponent_actions[:phase_boundary_1, :]
            my_phase_1_actions = history.my_actions[:phase_boundary_1]
            total_cooperators = np.sum(phase_1_actions) + np.sum(my_phase_1_actions)
            total_actions = n * phase_boundary_1
            prev_coop_rate = total_cooperators / total_actions
            threshold_lower = max(k / n, 0.4)
            if k < 1.2:
                threshold_lower = max(k / n, 0.3)
            elif k > n - 0.5:
                threshold_lower = min(max(k / n, 0.6), 0.9)
            if n > 20:
                threshold_lower += 0.1
                threshold_lower = min(threshold_lower, 0.9)
            if prev_coop_rate >= threshold_lower:
                return Action.C
            else:
                return Action.D
        phase_1_2_actions = history.opponent_actions[:phase_boundary_2, :]
        my_phase_1_2_actions = history.my_actions[:phase_boundary_2]
        total_cooperators = np.sum(phase_1_2_actions) + np.sum(my_phase_1_2_actions)
        total_actions = n * phase_boundary_2
        overall_coop_rate = total_cooperators / total_actions
        if overall_coop_rate >= 0.6:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_23(BaseStrategy):
    """
    Adaptive Reciprocal Maximization (ARM) Strategy for N-Player Public Goods Game.

    Balances collective welfare with individual rationality by:
    1. Starting with cooperation (round 1)
    2. Adapting based on observed cooperation rates
    3. Using elastic thresholds that reward improvement
    4. Applying stricter standards in endgame
    5. Mirroring behavior in final round
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate the cooperation rate from all previous rounds."""
        if len(history.opponent_actions) == 0:
            return 0.0
        total_cooperations = np.sum(history.opponent_actions)
        total_possible = len(history.opponent_actions) * self.n_players
        return float(total_cooperations) / float(total_possible) if total_possible > 0 else 0.0

    def _calculate_last_round_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate in the most recent round."""
        if len(history.opponent_actions) == 0:
            return 0.0
        last_round_cooperations = np.sum(history.opponent_actions[-1, :])
        return float(last_round_cooperations) / float(self.n_players)

    def _calculate_threshold(self, round_number: int, last_cooperation_rate: float) -> float:
        """
        Calculate the cooperation threshold for the current round.

        Args:
            round_number: Current round (0-indexed)
            last_cooperation_rate: Cooperation rate from previous round

        Returns:
            Threshold above which we cooperate
        """
        if round_number == 0:
            return 0.5
        if round_number == self.n_rounds - 1:
            return last_cooperation_rate
        if round_number > self.n_rounds - 3:
            return last_cooperation_rate + 0.1
        return max(0.3, last_cooperation_rate - 0.15)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        last_cooperation_rate = self._calculate_last_round_cooperation_rate(history)
        if round_number == self.n_rounds - 1:
            if last_cooperation_rate >= 0.5:
                return Action.C
            else:
                return Action.D
        threshold = self._calculate_threshold(round_number, last_cooperation_rate)
        if last_cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_24(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Core logic:
    - Round 1 (index 0): COOPERATE to establish pro-social baseline
    - Last round (index r-1): DEFECT (subgame perfect equilibrium)
    - Rounds 2 to r-1: COOPERATE if previous round's cooperation rate  k/n, else DEFECT
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        last_round_index = self.n_rounds - 1
        if current_round == 0:
            return Action.C
        if current_round == last_round_index:
            return Action.D
        previous_round_index = current_round - 1
        cooperators_last_round = int(sum(history.opponent_actions[previous_round_index, :]))
        if history.my_actions[previous_round_index]:
            cooperators_last_round += 1
        cooperation_rate = cooperators_last_round / self.n_players
        if cooperation_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_25(BaseStrategy):
    """
    Adaptive Reciprocal Threshold (ART) Strategy for N-Player Public Goods Game.

    Optimizes for collective welfare through conditional cooperation with adaptive thresholds.
    - Round 1: Cooperate to establish good faith
    - Rounds 2 to r-1: Cooperate if cooperation rate meets adaptive threshold
    - Final round: Defect (no future consequences)
    - Adapts threshold based on observed cooperation and round number
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperators_previous_round = int(sum(history.opponent_actions[current_round - 1, :]))
        cooperation_rate = cooperators_previous_round / self.n_players
        threshold = max(0.4, (self.n_rounds - current_round) / (2.0 * self.n_rounds))
        if current_round <= 2:
            threshold = min(threshold, 0.35)
        if cooperation_rate < 0.3 and current_round > 2:
            return Action.D
        if cooperation_rate >= threshold:
            return Action.C
        if 0.35 < cooperation_rate < 0.65:
            if cooperation_rate > 0.45:
                return Action.C
            else:
                return Action.D
        if cooperation_rate > threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_26(BaseStrategy):
    """
    Adaptive Reciprocal Maximization (ARM) Strategy for N-Player Public Goods Game.

    Balances collective welfare, individual rationality, and robustness by:
    1. Cooperating in round 1 to signal good intent
    2. Adapting based on historical cooperation rate with exponential smoothing
    3. Defecting in final round (unless cooperation is exceptionally high)
    4. Using threshold k/n to determine when cooperation is individually rational
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.smoothed_coop_rate = None

    def _calculate_coop_rate(self, history: PlayerHistory) -> float:
        """Calculate raw cooperation rate from all previous rounds."""
        if history.opponent_actions.shape[0] == 0:
            return 0.0
        total_cooperators = np.sum(history.opponent_actions)
        total_slots = history.opponent_actions.shape[0] * self.n
        return float(total_cooperators) / float(total_slots)

    def _calculate_current_round_coop_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate in the most recent round only."""
        if history.opponent_actions.shape[0] == 0:
            return 0.0
        current_round_cooperators = np.sum(history.opponent_actions[-1, :])
        return float(current_round_cooperators) / float(self.n)

    def _update_smoothed_rate(self, history: PlayerHistory) -> float:
        """Update and return exponentially smoothed cooperation rate."""
        current_round_rate = self._calculate_current_round_coop_rate(history)
        if history.opponent_actions.shape[0] == 1:
            self.smoothed_coop_rate = current_round_rate
            return self.smoothed_coop_rate
        if self.smoothed_coop_rate is None:
            self.smoothed_coop_rate = current_round_rate
        else:
            self.smoothed_coop_rate = 0.7 * self.smoothed_coop_rate + 0.3 * current_round_rate
        return self.smoothed_coop_rate

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.r - 1:
            coop_rate = self._calculate_coop_rate(history)
            threshold = self.k / self.n
            if coop_rate > 1.5 * threshold:
                return Action.C
            else:
                return Action.D
        smoothed_rate = self._update_smoothed_rate(history)
        threshold = self.k / self.n
        if smoothed_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_27(BaseStrategy):
    """
    Adaptive Contribution with Defection Recovery (ACDR) Strategy

    Balances cooperation for collective welfare with defection protection.
    Uses mathematical threshold (k/n) to detect when cooperation is sustainable.
    Implements recovery attempts and terminal defection for game-theoretic optimality.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n_players
        self.rounds_since_last_defection = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == self.n_rounds - 1:
            return Action.D
        if round_num < 3 and round_num < self.n_rounds:
            return Action.C
        if history is None:
            return Action.C
        prev_round_idx = round_num - 1
        my_prev_action = history.my_actions[prev_round_idx]
        opponent_prev_actions = history.opponent_actions[prev_round_idx, :]
        total_cooperators = int(my_prev_action) + int(np.sum(opponent_prev_actions))
        coop_rate = total_cooperators / self.n_players
        rounds_remaining = self.n_rounds - round_num
        if coop_rate >= self.threshold:
            self.rounds_since_last_defection += 1
            return Action.C
        if self.rounds_since_last_defection > 0 and self.rounds_since_last_defection % 3 == 0 and (rounds_remaining >= 2):
            return Action.C
        if coop_rate < self.threshold:
            self.rounds_since_last_defection = 0
            return Action.D
        return Action.D

class Strategy_COLLECTIVE_28(BaseStrategy):
    """
    Adaptive Contribution with Reciprocal Stabilization (ACRS)

    Balances collective welfare maximization with individual protection through:
    - Round 1: Cooperate to signal willingness
    - Rounds 2 to r-1: Adaptively cooperate based on collective health metrics
    - Final round: Defect unless near-universal cooperation observed
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            cooperation_ratio = self._calculate_cooperation_ratio(history, round_num)
            if cooperation_ratio > 0.9:
                return Action.C
            else:
                return Action.D
        cooperation_ratio = self._calculate_cooperation_ratio(history, round_num)
        threshold_high = (self.k - 1) / self.n
        threshold_medium = (self.k - 1) / (2 * self.n)
        if cooperation_ratio > threshold_high:
            return Action.C
        elif cooperation_ratio >= threshold_medium:
            my_recent_payoff = self._calculate_recent_average_payoff(history, round_num)
            if my_recent_payoff > 1.1:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _calculate_cooperation_ratio(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate cooperation_ratio = total cooperations / (n  rounds_completed)
        """
        if current_round == 0:
            return 0.0
        rounds_completed = current_round
        total_cooperations = 0
        total_cooperations += np.sum(history.my_actions[:current_round])
        total_cooperations += np.sum(history.opponent_actions[:current_round, :])
        denominator = self.n * rounds_completed
        if denominator == 0:
            return 0.0
        return total_cooperations / denominator

    def _calculate_recent_average_payoff(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate average payoff from last 3 rounds (or fewer if not enough history)
        """
        if current_round == 0:
            return 0.0
        lookback = min(3, current_round)
        recent_payoffs = history.my_payoffs[current_round - lookback:current_round]
        if len(recent_payoffs) == 0:
            return 0.0
        return float(np.mean(recent_payoffs))

class Strategy_COLLECTIVE_29(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy

    Balances collective welfare maximization with individual incentive protection.
    Uses adaptive thresholds responding to observed cooperation rates while maintaining
    credible commitment to reciprocity.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        prev_round_idx = round_number - 1
        cooperators_prev = np.sum(history.opponent_actions[prev_round_idx, :])
        ocr = cooperators_prev / self.n
        coop_threshold = (self.k - 1) / self.k
        if self.n <= 4:
            mixed_threshold = 0.4
        else:
            mixed_threshold = 0.5
        if ocr == 0 and round_number >= 2:
            prev_prev_idx = round_number - 2
            cooperators_prev_prev = np.sum(history.opponent_actions[prev_prev_idx, :])
            ocr_prev_prev = cooperators_prev_prev / self.n
            if ocr_prev_prev == 0:
                return Action.D
        if ocr >= coop_threshold:
            return Action.C
        elif ocr >= mixed_threshold:
            if random.random() < ocr:
                return Action.C
            else:
                return Action.D
        elif ocr > 0:
            return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_30(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare with individual security through:
    1. Cooperative initialization to establish positive-sum outcomes
    2. Adaptive response based on observed cooperation rates
    3. Robust handling of diverse opponent types
    4. Maximization of collective efficiency when viable

    Decision thresholds calibrated to game parameters (k, n).
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold_sustain = self.k / self.n
        self.threshold_exit = self.k / self.n * 0.3
        self.threshold_final = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            cooperation_rate = self._get_cooperation_rate(history, current_round - 1)
            if cooperation_rate >= self.threshold_final:
                return Action.C
            else:
                return Action.D
        cooperation_rate = self._get_cooperation_rate(history, current_round - 1)
        if cooperation_rate >= self.threshold_sustain:
            return Action.C
        elif cooperation_rate >= self.threshold_exit:
            p_adapt = cooperation_rate / self.threshold_sustain
            if random.random() < p_adapt:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _get_cooperation_rate(self, history: PlayerHistory, round_idx: int) -> float:
        """
        Calculate the cooperation rate in a given round.

        Args:
            history: PlayerHistory object containing opponent actions
            round_idx: Index of the round to analyze (0-indexed)

        Returns:
            Cooperation rate as a float in [0, 1]
        """
        if round_idx < 0 or round_idx >= len(history.opponent_actions):
            return 0.0
        cooperators_in_round = np.sum(history.opponent_actions[round_idx, :])
        cooperation_rate = cooperators_in_round / self.n
        return cooperation_rate

class Strategy_COLLECTIVE_31(BaseStrategy):
    """
    Adaptive Reciprocal Maximization (ARM): Balances individual rationality with collective welfare
    through phased decision-making and adaptive reciprocity based on observed cooperation rates.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        phase_threshold_1 = math.ceil(self.r / 3)
        phase_threshold_2 = math.floor(2 * self.r / 3)
        if current_round < phase_threshold_1:
            return Action.C
        if current_round > phase_threshold_2:
            rounds_remaining = self.r - current_round
            if rounds_remaining <= 2:
                return Action.D
            c_rate = self._calculate_cooperation_rate(history)
            threshold = 2 * self.k / (self.n + self.k)
            if c_rate >= threshold:
                return Action.C
            else:
                return Action.D
        c_rate = self._calculate_cooperation_rate(history)
        threshold = self.k / self.n
        if c_rate > threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        """
        Calculate the cooperation rate from all previous rounds.
        C_rate = (total cooperators across all players in prior rounds) / (n  rounds_elapsed)
        """
        if history is None or len(history.my_actions) == 0:
            return 0.0
        rounds_elapsed = len(history.my_actions)
        my_cooperations = np.sum(history.my_actions)
        opponent_cooperations = np.sum(history.opponent_actions)
        total_cooperations = my_cooperations + opponent_cooperations
        total_actions = (self.n - 1 + 1) * rounds_elapsed
        c_rate = total_cooperations / total_actions
        return c_rate

class Strategy_COLLECTIVE_32(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with self-protection against exploitation.
    Uses dynamic monitoring of cooperation rates and graduated responses to maintain
    sustainable cooperation while protecting against defection spirals.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold_min = self.k / self.n
        self.tolerance = 0.2
        if self.n <= 3:
            self.threshold_min *= 0.8

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        opponent_actions_prev = history.opponent_actions[prev_round_idx, :]
        cooperators_prev = int(np.sum(opponent_actions_prev))
        my_action_prev = history.my_actions[prev_round_idx]
        total_cooperators = cooperators_prev + (1 if my_action_prev else 0)
        cooperation_rate = total_cooperators / self.n
        if current_round == self.r - 1:
            if cooperation_rate >= self.threshold_min:
                return Action.C
            else:
                return Action.D
        expected_payoff_if_defect = 1.0 + self.k / self.n * (self.n - 1) * cooperation_rate
        expected_payoff_if_cooperate = self.k / self.n * (self.n * cooperation_rate)
        benefit_of_defection = expected_payoff_if_defect - expected_payoff_if_cooperate
        adjusted_tolerance = self.tolerance
        if current_round >= self.r - 3:
            adjusted_tolerance *= 0.5
        if cooperation_rate >= self.threshold_min:
            return Action.C
        elif cooperation_rate < self.threshold_min and benefit_of_defection > adjusted_tolerance:
            p_defect = max(1.0 - cooperation_rate, 0.3)
            if random.random() < p_defect:
                return Action.D
            else:
                return Action.C
        else:
            return Action.C

class Strategy_COLLECTIVE_33(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy

    Prioritizes collective welfare maximization while maintaining individual sustainability.
    Cooperates when cooperation rate exceeds break-even threshold, defects when cooperation
    collapses, and uses probabilistic matching in between states.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.cooperation_threshold = (self.k - 1) / (self.n - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        recent_coop_rate = self._calculate_recent_cooperation_rate(history, current_round)
        if current_round == self.r - 1:
            if recent_coop_rate >= self.cooperation_threshold:
                return Action.C
            else:
                return Action.D
        if recent_coop_rate >= self.cooperation_threshold:
            return Action.C
        elif recent_coop_rate < self.cooperation_threshold / 2:
            return Action.D
        else:
            return Action.C if random.random() < recent_coop_rate else Action.D

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate cooperation rate over recent rounds (window of up to 5 rounds).

        Args:
            history: PlayerHistory object containing past actions
            current_round: Current round number (0-indexed)

        Returns:
            Cooperation rate as a float in [0, 1]
        """
        lookback = 5
        window_size = min(lookback, current_round)
        if window_size == 0:
            return 0.5
        start_idx = current_round - window_size
        end_idx = current_round
        my_cooperations = np.sum(history.my_actions[start_idx:end_idx])
        opponent_cooperations = np.sum(history.opponent_actions[start_idx:end_idx, :])
        total_cooperations = my_cooperations + opponent_cooperations
        total_possible = window_size * self.n
        if total_possible == 0:
            return 0.5
        recent_coop_rate = total_cooperations / total_possible
        return recent_coop_rate

class Strategy_COLLECTIVE_34(BaseStrategy):
    """
    Adaptive Reciprocal Maximization (ARM): A collective strategy for n-player public goods games.

    Balances reciprocity, exploitation minimization, and coalition recovery through:
    - Round 1: Cooperate (signal good faith)
    - Rounds 2 to r-1: Reciprocate based on previous round cooperation rate with thresholds
    - Round r: Cooperate if cooperation rate  0.4, else defect
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_high = 0.5
        self.threshold_low = 0.2
        self.endgame_threshold = 0.4

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round_idx = state.round_number - 1
        cooperators_prev = sum(history.opponent_actions[prev_round_idx, :])
        coop_rate = cooperators_prev / self.game_description.n_players
        if state.round_number == self.game_description.n_rounds - 1:
            if coop_rate >= self.endgame_threshold:
                return Action.C
            else:
                return Action.D
        if coop_rate >= self.threshold_high:
            return Action.C
        elif coop_rate >= self.threshold_low:
            if random.random() < coop_rate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_35(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Prioritizes collective welfare maximization while maintaining robustness against exploitation.
    Uses conditional cooperation with adaptive thresholds, exploit detection, and graduated responses.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = sum(history.opponent_actions[round_num - 1, :])
        coop_rate_last = cooperators_last_round / self.n_players
        threshold = max(0.5, 1.0 - round_num / (self.n_rounds - 1) * 0.3)
        if round_num >= 2:
            recent_cooperators = [sum(history.opponent_actions[round_num - 2, :]), sum(history.opponent_actions[round_num - 1, :])]
            recent_avg = sum(recent_cooperators) / (2 * self.n_players)
            if recent_avg < 0.33:
                return Action.D
            elif recent_avg < 0.66:
                if round_num % 3 == 0:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.C
        if coop_rate_last >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_36(BaseStrategy):
    """
    Adaptive Collective Reciprocity (ACR) Strategy for N-Player Public Goods Game

    Uses conditional cooperation with adaptive thresholds that respond to observed
    cooperation rates. Includes special handling for early rounds, mid-game, and endgame
    to balance collective welfare with robustness against free-riders.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round_idx = state.round_number - 1
        self_cooperated = history.my_actions[prev_round_idx]
        opponent_cooperated = history.opponent_actions[prev_round_idx, :]
        total_cooperators = int(self_cooperated) + int(np.sum(opponent_cooperated))
        cooperation_rate = total_cooperators / self.n
        is_endgame = state.round_number >= self.r - 2
        if is_endgame:
            return self._endgame_decision(cooperation_rate)
        else:
            return self._midgame_decision(state.round_number, cooperation_rate)

    def _midgame_decision(self, round_number: int, cooperation_rate: float) -> Action:
        """Decision logic for rounds 1 to r-3"""
        base_threshold = self.k / self.n
        drift_adjustment = -0.05 * (round_number / self.r)
        threshold = max(0.5, base_threshold + drift_adjustment)
        if cooperation_rate < 0.3:
            return Action.D
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _endgame_decision(self, cooperation_rate: float) -> Action:
        """Decision logic for final 2 rounds with forgiveness boost"""
        base_threshold = self.k / self.n
        endgame_threshold = max(0.3, base_threshold - 0.15)
        if cooperation_rate < 0.2:
            return Action.D
        if cooperation_rate >= endgame_threshold:
            return Action.C
        if random.random() < 0.7:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_37(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with robust self-protection through:
    1. Unconditional cooperation during grace period (first min(3, r/3) rounds)
    2. Threshold-based cooperation: cooperate if previous round cooperation rate >= (k-1)/k
    3. Endgame adjustment: in final round, defect only if cooperation has failed
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.k - 1) / self.k
        self.grace_period_length = min(3, math.floor(self.n_rounds / 3))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number <= self.grace_period_length:
            return Action.C
        prev_round_idx = round_number - 1
        my_prev_action = history.my_actions[prev_round_idx]
        opponent_prev_actions = history.opponent_actions[prev_round_idx, :]
        total_cooperators = int(my_prev_action) + int(np.sum(opponent_prev_actions))
        prev_coop_rate = total_cooperators / self.n_players
        if round_number == self.n_rounds - 1:
            if prev_coop_rate > self.threshold:
                return Action.C
            else:
                return Action.D
        if prev_coop_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_38(BaseStrategy):
    """
    Conditional Reciprocal Altruism with Decay (CRAD) Strategy

    Implements adaptive collective strategy for N-Player Public Goods Game:
    - Round 1: Cooperate to bootstrap cooperation
    - Rounds 2 to r-1: Adaptive threshold based on observed cooperation rate
    - Round r: Defect (standard finitely-repeated game logic)

    Cooperates when collective efficiency warrants it, punishes defection softly,
    and attempts recovery rather than spiraling into mutual destruction.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            return Action.D
        last_round_idx = current_round - 1
        self_cooperated_last = history.my_actions[last_round_idx]
        opponent_cooperated_last = history.opponent_actions[last_round_idx, :]
        total_cooperators_last = int(self_cooperated_last) + int(np.sum(opponent_cooperated_last))
        coop_rate_last = total_cooperators_last / self.n
        efficiency_threshold = self.n / self.k
        efficient = total_cooperators_last >= efficiency_threshold
        if coop_rate_last == 1.0:
            threshold = 0.5
        elif efficient:
            threshold = max(0.4, coop_rate_last - 0.15)
        else:
            threshold = 0.7
        k_ratio = self.k / self.n
        if k_ratio > 0.9:
            threshold = max(0.0, threshold - 0.1)
        elif k_ratio < 0.2:
            threshold = min(1.0, threshold + 0.1)
        if self.n == 2:
            threshold = max(threshold, 0.5)
        if coop_rate_last < 0.3:
            self.consecutive_defections += 1
            if self.consecutive_defections <= 2:
                return Action.D
            else:
                self.consecutive_defections = 0
                return Action.C
        else:
            self.consecutive_defections = 0
        if coop_rate_last >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_39(BaseStrategy):
    """
    Adaptive Collective Reciprocity (ACR): Balances collective welfare with individual
    sustainability through adaptive cooperation based on cooperation rate, payoff deficits,
    and trending analysis. Maintains cooperation when collectively beneficial while protecting
    against free-riders and defecting only when necessary for individual survival.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        cooperation_rate = np.mean(history.opponent_actions[current_round - 1, :])
        my_last_payoff = history.my_payoffs[current_round - 1]
        my_payoff_deficit = max(0.0, 1.0 - my_last_payoff)
        rounds_remaining = self.r - current_round - 1
        if current_round >= 2:
            prev_cooperation_rate = np.mean(history.opponent_actions[current_round - 2, :])
        else:
            prev_cooperation_rate = 1.0
        breakeven_threshold = self.k / self.n
        if cooperation_rate == 0.0 and current_round <= 2:
            return Action.C
        if cooperation_rate < 2.0 / self.n:
            if prev_cooperation_rate > cooperation_rate:
                return Action.D
            elif prev_cooperation_rate < cooperation_rate:
                return Action.C
        if rounds_remaining <= 1:
            if cooperation_rate >= 0.5:
                return Action.C
            else:
                return Action.D
        if current_round == self.r - 1:
            if cooperation_rate >= breakeven_threshold and my_payoff_deficit < 0.15:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= breakeven_threshold:
            threshold = 0.1
        elif cooperation_rate >= 0.5:
            threshold = 0.2
        elif cooperation_rate >= 2.0 / self.n:
            threshold = 0.05
        else:
            return Action.D
        if my_payoff_deficit < threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_40(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game

    Balances collective welfare maximization with protection against exploitation.
    Cooperates in round 1, then uses a threshold-based decision rule comparing recent
    cooperation rates against the break-even point k/n. Cooperates when cooperation
    is sufficient to create mutual benefit, defects when cooperation is too low.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        break_even_threshold = self.k / self.n
        current_round = state.round_number
        lookback_rounds = min(2, current_round)
        recent_cooperators = 0
        for round_idx in range(current_round - lookback_rounds, current_round):
            cooperators_in_round = sum(history.opponent_actions[round_idx, :])
            recent_cooperators += cooperators_in_round
        total_players_in_lookback = lookback_rounds * self.n
        for round_idx in range(current_round - lookback_rounds, current_round):
            if history.my_actions[round_idx]:
                recent_cooperators += 1
        recent_cooperation_rate = recent_cooperators / total_players_in_lookback
        if recent_cooperation_rate >= break_even_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_41(BaseStrategy):
    """
    Adaptive Reciprocal Threshold (ART) Strategy for N-Player Public Goods Game.

    Balances reciprocal cooperation with robust self-defense against exploitation.
    Cooperates when others' cooperation rate meets or exceeds the break-even threshold (k/n),
    with graceful degradation and probabilistic cooperation for intermediate cases.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        coop_rate_others = self._calculate_cooperation_rate(history, round_num)
        if round_num == self.r - 1:
            if coop_rate_others >= self.threshold:
                return Action.C
            else:
                return Action.D
        if coop_rate_others >= self.threshold:
            return Action.C
        elif coop_rate_others < self.threshold * 0.8:
            return Action.D
        else:
            prob_cooperate = coop_rate_others / self.threshold
            return Action.C if random.random() < prob_cooperate else Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate the cooperation rate of all other players across all previous rounds.

        cooperation_rate_others = (total cooperations by all other players) / ((round_num)  (n-1))
        """
        if round_num == 0:
            return 0.0
        total_opponent_cooperations = np.sum(history.opponent_actions[:round_num, :])
        total_possible = round_num * (self.n - 1)
        if total_possible == 0:
            return 0.0
        return total_opponent_cooperations / total_possible

class Strategy_COLLECTIVE_42(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game.

    Cooperates if and only if the cooperation rate in the previous round meets or exceeds
    the threshold k/n. In the first round, cooperates to bootstrap mutual cooperation.
    This strategy balances individual rationality with collective welfare by recognizing
    when cooperation is mutually beneficial and defecting when participation drops below
    sustainable levels.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.k = game_description.k
        self.threshold = self.k / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round_index = state.round_number - 1
        cooperators_last_round = sum(history.opponent_actions[previous_round_index, :])
        if history.my_actions[previous_round_index]:
            cooperators_last_round += 1
        cooperation_rate = cooperators_last_round / self.n_players
        if cooperation_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_43(BaseStrategy):
    """
    Adaptive Contribution with Defection Resistance (ACDR) Strategy

    Balances collective welfare maximization with individual protection against exploitation.
    Uses adaptive reciprocity with exploitation detection and context-dependent endgame logic.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.consecutive_low_coop_rounds = 0
        self.max_payoff = 1.0 + self.k / self.n_players * self.n_players
        self.exploitation_threshold = 0.15 * self.max_payoff

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        my_prev_action = history.my_actions[prev_round_idx]
        my_prev_payoff = history.my_payoffs[prev_round_idx]
        opponent_cooperators = sum(history.opponent_actions[prev_round_idx, :])
        total_cooperators = opponent_cooperators + (1 if my_prev_action else 0)
        prev_cooperation_rate = total_cooperators / self.n_players
        all_payoffs = list(history.opponent_payoffs[prev_round_idx, :]) + [my_prev_payoff]
        community_avg_payoff = sum(all_payoffs) / len(all_payoffs)
        if current_round == self.n_rounds - 1:
            my_avg_cooperation = sum(history.my_actions) / len(history.my_actions)
            threshold_coop_rate = 2 * self.k / (3 * self.n_players)
            if prev_cooperation_rate >= threshold_coop_rate and my_avg_cooperation >= 0.7:
                return Action.C
            else:
                return Action.D
        threshold = self.k / self.n_players
        if prev_cooperation_rate >= threshold:
            if my_prev_payoff >= community_avg_payoff - self.exploitation_threshold:
                self.consecutive_low_coop_rounds = 0
                return Action.C
            else:
                self.consecutive_low_coop_rounds = 0
                return Action.D
        elif self.consecutive_low_coop_rounds >= 2:
            return Action.D
        else:
            self.consecutive_low_coop_rounds += 1
            return Action.C

class Strategy_COLLECTIVE_44(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare through:
    1. Initial cooperation to signal good faith
    2. Adaptive thresholds based on observed cooperation rates
    3. Stochastic testing in gray zones
    4. Oscillation detection to identify exploiters
    5. Principled final-round behavior
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_idx = round_num - 1
        prev_cooperators = sum(history.opponent_actions[prev_round_idx, :])
        coop_rate = prev_cooperators / self.n
        if round_num >= 2:
            curr_zero = prev_cooperators == 0
            prev_prev_cooperators = sum(history.opponent_actions[prev_round_idx - 1, :])
            prev_zero = prev_prev_cooperators == 0
            if curr_zero and prev_zero:
                return Action.D
        if round_num >= 3:
            if self._is_oscillating(history, round_num):
                coop_rate = 0.33
        if round_num == self.r - 1:
            if coop_rate >= 0.4:
                return Action.C
            else:
                return Action.D
        min_threshold = self._get_min_threshold()
        warn_threshold = 0.35
        if coop_rate >= min_threshold:
            return Action.C
        elif coop_rate >= warn_threshold:
            if random.random() < coop_rate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _get_min_threshold(self) -> float:
        """
        Calculate minimum viable threshold based on game parameters.

        Break-even threshold: (k-1)/k ensures cooperation payoff  defection payoff
        Special case: n <= 3 requires lower threshold due to outsized impact
        """
        if self.n <= 3:
            min_thresh = 0.4
        else:
            break_even = (self.k - 1) / self.k
            min_thresh = max(0.5, break_even)
        return min_thresh

    def _is_oscillating(self, history: PlayerHistory, round_num: int) -> bool:
        """
        Detect oscillation pattern: CDC or DCD in last 3 rounds.

        This indicates an exploiter who conditions on our behavior.
        Artificially deflate cooperation_rate signal to trigger defection.
        """
        if round_num < 3:
            return False
        my_last_3 = history.my_actions[round_num - 3:round_num]
        if len(my_last_3) == 3:
            alternates = my_last_3[0] != my_last_3[1] and my_last_3[1] != my_last_3[2]
            return alternates
        return False

class Strategy_COLLECTIVE_45(BaseStrategy):
    """
    Adaptive Reciprocal Maximization (ARM): Balances collective welfare, individual sustainability,
    and adaptive robustness by calibrating group cooperation capacity and responding intelligently.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        calibration_rounds = min(3, self.r // 2)
        if round_number < calibration_rounds:
            return Action.C
        if history is None or round_number == 0:
            observed_coop_rate = 0.5
        else:
            total_rounds_played = round_number
            total_coop_observations = np.sum(history.opponent_actions[:round_number, :])
            observed_coop_rate = total_coop_observations / (total_rounds_played * self.n)
        threshold = (self.k - 1.0) / self.n
        if self.n == 2:
            threshold += 0.05
            buffer = 0.2
        else:
            buffer = 0.15
        rounds_remaining = self.r - round_number - 1
        if round_number == self.r - 1:
            if observed_coop_rate >= threshold:
                return Action.C
            else:
                return Action.D
        if observed_coop_rate >= threshold + buffer:
            return Action.C
        elif observed_coop_rate >= threshold:
            p_cooperate = min(observed_coop_rate * 1.5, 1.0)
            if random.random() < p_cooperate:
                return Action.C
            else:
                return Action.D
        elif rounds_remaining <= 2:
            return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_46(BaseStrategy):
    """
    Adaptive Graduated Reciprocation with Threshold-Based Cooperation (AGRTC).

    A collective strategy that balances cooperation with self-protection through adaptive
    thresholds. Cooperates in round 1, then makes decisions based on observed cooperation
    rates relative to a dynamically adjusted threshold that reflects when the public good
    creates genuine mutual benefit.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        last_round_opponent_cooperators = sum(history.opponent_actions[current_round - 1, :])
        my_last_action = history.my_actions[current_round - 1]
        total_cooperators_last_round = last_round_opponent_cooperators + (1 if my_last_action else 0)
        cooperation_rate = total_cooperators_last_round / self.n
        baseline_threshold = (self.k - 1) / self.n + 0.3
        if self.n <= 3:
            baseline_threshold = baseline_threshold + 0.1
        decay_factor = 0.1
        if self.r > 20:
            decay_factor = 0.05
        threshold = max(0.5, baseline_threshold - current_round / self.r * decay_factor)
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_47(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization, self-protection against exploitation,
    and adaptive learning based on observed cooperation rates.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (1.0 + self.k) / (2.0 * self.k)
        self._consecutive_unanimous_defection = 0
        self._consecutive_unanimous_cooperation = 0
        self._permanent_modifier = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        prev_cooperators = sum(history.opponent_actions[prev_round_idx, :])
        if history.my_actions[prev_round_idx]:
            prev_cooperators += 1
        prev_cooperation_rate = prev_cooperators / self.n_players
        if current_round == self.n_rounds - 1:
            if prev_cooperation_rate >= self.threshold:
                return Action.C
            else:
                return Action.D
        if prev_cooperators == 0:
            self._consecutive_unanimous_defection += 1
            self._consecutive_unanimous_cooperation = 0
        else:
            self._consecutive_unanimous_defection = 0
        if prev_cooperation_rate == 1.0:
            self._consecutive_unanimous_cooperation += 1
        else:
            self._consecutive_unanimous_cooperation = 0
        if self._consecutive_unanimous_cooperation >= 3:
            self._permanent_modifier = -0.05
        if self._consecutive_unanimous_defection >= 2:
            return Action.D
        adaptive_modifier = self._permanent_modifier
        if current_round >= 3:
            recent_rounds = min(3, current_round)
            recent_coop_rates = []
            for i in range(current_round - recent_rounds, current_round):
                round_cooperators = sum(history.opponent_actions[i, :])
                if history.my_actions[i]:
                    round_cooperators += 1
                recent_coop_rates.append(round_cooperators / self.n_players)
            if len(recent_coop_rates) >= 2:
                recent_avg = np.mean(recent_coop_rates[:-1])
                current_rate = recent_coop_rates[-1]
                if current_rate > recent_avg:
                    adaptive_modifier -= 0.05
                elif current_rate < recent_avg:
                    adaptive_modifier += 0.05
        threshold_adjusted = self.threshold + adaptive_modifier
        if prev_cooperation_rate >= threshold_adjusted:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_48(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare by:
    1. Rewarding cooperation through reciprocal contribution
    2. Punishing defection with proportional non-cooperation
    3. Maintaining sustainable thresholds that maximize collective payoff
    4. Adapting to opponent behavior while preserving long-term incentives
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.epsilon = 0.05
        self.threshold_maintain = self.k / self.n + self.epsilon
        self.threshold_minimum = (self.k - 1) / (2 * self.n) + self.epsilon
        self.tolerance_window = 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num <= 2:
            return Action.C
        prev_round_idx = round_num - 1
        my_prev_action = history.my_actions[prev_round_idx]
        opponent_prev_actions = history.opponent_actions[prev_round_idx, :]
        total_cooperators = int(my_prev_action) + int(np.sum(opponent_prev_actions))
        cooperation_rate = total_cooperators / self.n
        if np.sum(history.opponent_actions) == 0:
            return Action.D
        if round_num >= 3:
            recent_rounds = min(3, round_num)
            recent_cooperators = []
            for i in range(recent_rounds):
                round_idx = round_num - 1 - i
                my_action = history.my_actions[round_idx]
                opp_actions = history.opponent_actions[round_idx, :]
                round_coop = int(my_action) + int(np.sum(opp_actions))
                recent_cooperators.append(round_coop / self.n)
            cooperation_rate = np.mean(recent_cooperators)
        is_late_game = round_num >= self.r - 2
        if cooperation_rate >= self.threshold_maintain:
            return Action.C
        if cooperation_rate >= self.threshold_minimum:
            rounds_in_low_coop = 0
            for i in range(max(0, round_num - self.tolerance_window), round_num):
                my_action = history.my_actions[i]
                opp_actions = history.opponent_actions[i, :]
                round_coop = (int(my_action) + int(np.sum(opp_actions))) / self.n
                if round_coop < self.threshold_minimum:
                    rounds_in_low_coop += 1
            if rounds_in_low_coop < self.tolerance_window:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_49(BaseStrategy):
    """
    Adaptive Contribution with Conditional Reciprocity (ACCR)

    A collective welfare-maximizing strategy that cooperates when the expected
    collective value created exceeds individual costs, while defending against
    exploitation. Uses observed cooperation rates to estimate group cooperation
    propensity and adapts decisions accordingly.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        coop_rate = self._calculate_cooperation_rate(history)
        threshold = self.n / self.k - 1
        expected_cooperators = 1 + (self.n - 1) * coop_rate
        current_round = state.round_number
        if current_round == self.r - 1 or current_round == self.r - 2:
            adjusted_threshold = threshold / (self.n - 1)
            if coop_rate > adjusted_threshold:
                return Action.C
            else:
                return Action.D
        if expected_cooperators > threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        """
        Calculate the empirical cooperation rate of other players from history.

        Returns the proportion of times other players cooperated across all
        observed rounds.
        """
        rounds_elapsed = len(history.my_actions)
        if rounds_elapsed == 0:
            return 0.5
        total_other_cooperations = np.sum(history.opponent_actions[:rounds_elapsed, :])
        total_possible = (self.n - 1) * rounds_elapsed
        if total_possible == 0:
            return 0.5
        coop_rate = total_other_cooperations / total_possible
        return float(coop_rate)

class Strategy_COLLECTIVE_50(BaseStrategy):
    """
    Graduated Reciprocity with Welfare Monitoring Strategy for N-Player Public Goods Game.

    This strategy balances individual rationality with collective welfare by:
    1. Starting with cooperation to establish good faith
    2. Monitoring group cooperation rate and responding conditionally
    3. Protecting against exploitation while rewarding cooperation
    4. Attempting recovery near game end to maximize final-round mutual gains
    5. Using probabilistic cooperation to avoid permanent defection locks
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_high = 0.6
        self.threshold_medium = 0.3
        self.recovery_phase_start = 0.75
        self.cautious_coop_prob = 0.8
        self.low_coop_recovery_prob = 0.15

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round_idx = state.round_number - 1
        cooperators_prev_round = sum(history.opponent_actions[prev_round_idx, :])
        total_players = self.game_description.n_players
        cooperation_rate = cooperators_prev_round / total_players
        my_prev_action = history.my_actions[prev_round_idx]
        rounds_remaining = self.game_description.n_rounds - state.round_number
        is_final_quarter = state.round_number >= self.game_description.n_rounds * self.recovery_phase_start
        if cooperation_rate >= self.threshold_high:
            return Action.C
        elif cooperation_rate >= self.threshold_medium:
            if my_prev_action:
                if random.random() < self.cautious_coop_prob:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D
        else:
            if is_final_quarter:
                if cooperation_rate >= 0.2:
                    return Action.C
                elif state.round_number == self.game_description.n_rounds - 2:
                    if random.random() < 0.6:
                        return Action.C
                    else:
                        return Action.D
                elif state.round_number == self.game_description.n_rounds - 1:
                    if cooperation_rate >= 0.2:
                        return Action.C
                    else:
                        return Action.D
            if random.random() < self.low_coop_recovery_prob:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_51(BaseStrategy):
    """
    Adaptive Contribution Equilibrium (ACE): A collective strategy that balances
    cooperation incentives with robustness against defection. Adapts contribution
    decisions based on observed population cooperation rates, with special handling
    for early rounds and endgame scenarios.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_high = 0.5
        self.threshold_low = 0.15
        self.threshold_final = 0.4

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_actions = history.opponent_actions[current_round - 1, :]
        cooperators_prev = int(np.sum(prev_round_actions))
        coop_rate = cooperators_prev / n
        if current_round == r - 1:
            if coop_rate >= self.threshold_final:
                return Action.C
            else:
                return Action.D
        if current_round == 1:
            if coop_rate >= self.threshold_high:
                return Action.C
            else:
                prob = 0.5
                if random.random() < prob:
                    return Action.C
                else:
                    return Action.D
        if coop_rate >= self.threshold_high:
            return Action.C
        elif coop_rate <= self.threshold_low:
            return Action.D
        else:
            prob = 0.4 + 0.6 * coop_rate
            if random.random() < prob:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_52(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game.

    Balances collective value creation, individual sustainability, and robustness
    through conditional cooperation with adaptive thresholds based on observed
    cooperation rates and game phase.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.base_threshold = max(self.k / self.n_players, 0.4)
        self.time_decay_factor = 0.15
        self.defection_phase_counter = 0
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        opponent_actions_last_round = history.opponent_actions[round_num - 1, :]
        cooperators_last_round = int(np.sum(opponent_actions_last_round))
        my_action_last_round = history.my_actions[round_num - 1]
        total_cooperators_last_round = cooperators_last_round + (1 if my_action_last_round else 0)
        cooperation_rate = total_cooperators_last_round / self.n_players
        self.cooperation_history.append(cooperation_rate)
        if cooperation_rate < 0.2 and self.defection_phase_counter == 0:
            self.defection_phase_counter = min(2, self.n_rounds - round_num)
        if self.defection_phase_counter > 0:
            self.defection_phase_counter -= 1
            return Action.D
        if round_num == self.n_rounds - 1:
            if cooperation_rate >= self.base_threshold + 0.1:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= 0.8:
            if round_num >= 1:
                if self.cooperation_history[-1] >= 0.8:
                    return Action.C
        if round_num == self.n_rounds - 2:
            if cooperation_rate >= self.base_threshold + 0.05:
                return Action.C
            else:
                return Action.D
        if round_num <= 2:
            threshold = max(0.3, self.base_threshold - 0.1)
        else:
            time_factor = 1.0 - round_num / self.n_rounds
            trend_adjustment = 0.0
            if len(self.cooperation_history) >= 2:
                recent_change = self.cooperation_history[-1] - self.cooperation_history[-2]
                if recent_change < -0.2:
                    trend_adjustment = -0.1
            threshold = self.base_threshold + self.time_decay_factor * time_factor + trend_adjustment
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_53(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization, individual security, and adaptive learning
    by cooperating when observed cooperation rates exceed a dynamically adjusted threshold.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.consecutive_high_defection_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        observed_cooperation_rate = self._calculate_cooperation_rate(history, round_number)
        threshold = self._calculate_threshold(history, round_number)
        if self._detect_defection_cascade(history, round_number):
            threshold = 0.9
            self.consecutive_high_defection_rounds += 1
        else:
            self.consecutive_high_defection_rounds = 0
        if round_number == self.n_rounds - 1:
            if threshold >= 0.7 and observed_cooperation_rate >= 0.6:
                return Action.C
            else:
                return Action.D
        if observed_cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_number: int) -> float:
        """Calculate proportion of all players cooperating in the most recent round."""
        if round_number == 0:
            return 0.5
        opponent_actions_last_round = history.opponent_actions[round_number - 1, :]
        opponent_cooperators = np.sum(opponent_actions_last_round)
        my_action = history.my_actions[round_number - 1]
        total_cooperators = opponent_cooperators + (1 if my_action else 0)
        cooperation_rate = total_cooperators / self.n_players
        return cooperation_rate

    def _calculate_threshold(self, history: PlayerHistory, round_number: int) -> float:
        """Calculate adaptive cooperation threshold based on game history."""
        if round_number <= 2:
            return 0.5
        defection_incidents = self._count_defection_incidents(history, round_number)
        threshold = min(0.5 + 0.1 * defection_incidents, 0.95)
        if round_number > 0 and round_number % 3 == 0:
            threshold = self._apply_meta_learning_update(history, round_number, threshold)
        return threshold

    def _count_defection_incidents(self, history: PlayerHistory, round_number: int) -> int:
        """Count rounds where cooperation rate dropped by >20% from previous round."""
        if round_number < 2:
            return 0
        defection_incidents = 0
        cooperation_rates = []
        for t in range(round_number):
            if t == 0:
                coop_rate = 0.5
            else:
                opponent_coops = np.sum(history.opponent_actions[t, :])
                my_action = history.my_actions[t]
                total_coops = opponent_coops + (1 if my_action else 0)
                coop_rate = total_coops / self.n_players
            cooperation_rates.append(coop_rate)
        for t in range(1, len(cooperation_rates)):
            drop = cooperation_rates[t - 1] - cooperation_rates[t]
            if drop > 0.2:
                defection_incidents += 1
        return defection_incidents

    def _detect_defection_cascade(self, history: PlayerHistory, round_number: int) -> bool:
        """Detect if defection rate >80% for 2+ consecutive recent rounds."""
        if round_number < 2:
            return False
        recent_rounds_to_check = min(2, round_number)
        for offset in range(recent_rounds_to_check):
            round_idx = round_number - 1 - offset
            if round_idx < 0:
                continue
            opponent_defectors = np.sum(~history.opponent_actions[round_idx, :])
            my_defection = not history.my_actions[round_idx]
            total_defectors = opponent_defectors + (1 if my_defection else 0)
            defection_rate = total_defectors / self.n_players
            if defection_rate <= 0.8:
                return False
        return True

    def _apply_meta_learning_update(self, history: PlayerHistory, round_number: int, threshold: float) -> float:
        """Apply meta-learning adjustments based on comparative payoff performance."""
        if round_number < 3:
            return threshold
        check_rounds = min(3, round_number)
        my_payoff_avg = np.mean(history.my_payoffs[round_number - check_rounds:round_number])
        opponent_payoffs_avg = np.mean(history.opponent_payoffs[round_number - check_rounds:round_number, :])
        average_payoff_avg = np.mean(opponent_payoffs_avg)
        if my_payoff_avg < average_payoff_avg - 0.2:
            threshold = min(threshold + 0.05, 0.95)
        elif my_payoff_avg > average_payoff_avg + 0.3:
            threshold = max(threshold - 0.03, 0.5)
        return threshold

class Strategy_COLLECTIVE_54(BaseStrategy):
    """
    Adaptive Reciprocal Maximization (ARM): A strategy that balances collective welfare,
    individual sustainability, and robustness in N-player public goods games.

    Core approach:
    - Phase 1 (Early): Establish cooperation with thresholds based on k/n
    - Phase 2 (Middle/Late): Stabilize with rolling averages and alternating punishment
    - Phase 3 (Final): Cooperate if any cooperation base exists for collective gain
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        n = self.n
        r = self.r
        k = self.k
        if round_number == 0:
            return Action.C
        threshold_1 = k / n
        threshold_2 = k / (2 * n)
        prev_coop_rate = self._get_prev_coop_rate(history, round_number)
        avg_coop_rate = self._get_avg_coop_rate(history, round_number, n)
        midpoint = math.floor(r / 2)
        if round_number <= midpoint:
            if prev_coop_rate >= threshold_1:
                return Action.C
            elif prev_coop_rate >= threshold_2:
                return Action.C if random.random() < 0.7 else Action.D
            else:
                return Action.D
        elif round_number < r - 1:
            if avg_coop_rate >= threshold_1:
                return Action.C
            elif avg_coop_rate >= threshold_2:
                my_last_action = history.my_actions[round_number - 1]
                return Action.C if not my_last_action else Action.D
            else:
                return Action.D
        elif avg_coop_rate >= threshold_2:
            return Action.C
        else:
            return Action.D

    def _get_prev_coop_rate(self, history: PlayerHistory, round_number: int) -> float:
        """Calculate cooperation rate in the previous round."""
        if round_number == 0:
            return 0.0
        prev_round_idx = round_number - 1
        total_cooperators = int(history.my_actions[prev_round_idx])
        total_cooperators += int(np.sum(history.opponent_actions[prev_round_idx, :]))
        return total_cooperators / self.n

    def _get_avg_coop_rate(self, history: PlayerHistory, round_number: int, n: int) -> float:
        """Calculate rolling average cooperation rate over last min(3, floor(r/4)) rounds."""
        if round_number == 0:
            return 0.0
        window_size = min(3, math.floor(self.r / 4))
        start_idx = max(0, round_number - window_size)
        end_idx = round_number
        total_cooperators = 0
        round_count = end_idx - start_idx
        for round_idx in range(start_idx, end_idx):
            total_cooperators += int(history.my_actions[round_idx])
            total_cooperators += int(np.sum(history.opponent_actions[round_idx, :]))
        total_players_in_window = round_count * n
        if total_players_in_window == 0:
            return 0.0
        return total_cooperators / total_players_in_window

class Strategy_COLLECTIVE_55(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy

    Balances individual rationality with collective welfare through:
    - Phase 1 (Opening): Conditional cooperation to establish baseline
    - Phase 2 (Steady State): Proportional reciprocity based on peer behavior
    - Phase 3 (Endgame): Defection mitigation with strategic last-round defection
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        opening_rounds = max(3, math.ceil(0.25 * self.r))
        endgame_start = self.r - 2
        if current_round < opening_rounds:
            return self._opening_phase(history, current_round)
        if current_round >= endgame_start:
            return self._endgame_phase(history, current_round)
        return self._steady_state_phase(history, current_round)

    def _opening_phase(self, history: PlayerHistory, current_round: int) -> Action:
        """Phase 1: Conditional Cooperation"""
        prev_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        cooperation_rate = prev_cooperators / (self.n - 1)
        if cooperation_rate >= 0.5:
            return Action.C
        else:
            return Action.D

    def _steady_state_phase(self, history: PlayerHistory, current_round: int) -> Action:
        """Phase 2: Proportional Reciprocity with Participation Threshold"""
        prev_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        cooperation_rate = prev_cooperators / (self.n - 1)
        threshold_high = 0.6
        threshold_low = 0.3
        if self.n == 2:
            threshold_high = 0.5
        if self.n >= 10:
            threshold_high = 0.5
            threshold_low = 0.25
        if self.k <= 1.3:
            threshold_high = 0.9
            threshold_low = 0.8
        if self.k >= self.n - 0.5:
            threshold_high = 0.3
        if cooperation_rate >= threshold_high:
            if random.random() < cooperation_rate:
                return Action.C
            else:
                return Action.D
        elif cooperation_rate > threshold_low:
            if random.random() < 0.5:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _endgame_phase(self, history: PlayerHistory, current_round: int) -> Action:
        """Phase 3: Endgame with Last-Round Defection Mitigation"""
        if current_round == self.r - 1:
            if self.r <= 5:
                return self._steady_state_phase(history, current_round)
            else:
                return Action.D
        else:
            return self._steady_state_phase(history, current_round)

class Strategy_COLLECTIVE_56(BaseStrategy):
    """
    Adaptive Reciprocal Threshold (ART) Strategy for N-Player Public Goods Game.

    Prioritizes collective welfare maximization through graduated reciprocity and
    threshold-based dynamics. Adapts cooperation levels based on observed group behavior
    while protecting individual payoffs against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def _get_thresholds(self) -> tuple[float, float, float]:
        """
        Compute adaptive thresholds based on game parameters.
        Returns (threshold_high, threshold_mid, threshold_low)
        """
        threshold_high = 0.6
        threshold_mid = 0.4
        threshold_low = 0.2
        if 1 < self.k < 1.5:
            threshold_high = 0.7
            threshold_mid = 0.5
        if self.k > self.n - 1:
            threshold_high = 0.5
        if self.n > 20:
            threshold_high += 0.05
            threshold_mid += 0.05
            threshold_low += 0.05
        return (threshold_high, threshold_mid, threshold_low)

    def _count_cooperators_in_round(self, history: PlayerHistory, round_idx: int) -> int:
        """
        Count total cooperators (self + opponents) in a given round.
        """
        my_action = 1 if history.my_actions[round_idx] else 0
        opponent_actions = sum(history.opponent_actions[round_idx, :])
        return my_action + opponent_actions

    def _get_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Compute cooperation rate from the previous round.
        For round 0, use k/n as initial estimate.
        """
        if current_round == 0:
            return self.k / self.n
        cooperators = self._count_cooperators_in_round(history, current_round - 1)
        return cooperators / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        threshold_high, threshold_mid, threshold_low = self._get_thresholds()
        if history is None:
            return Action.C
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            coop_rate = self._get_cooperation_rate(history, current_round)
            if coop_rate >= threshold_high:
                return Action.C
            else:
                return Action.D
        coop_rate = self._get_cooperation_rate(history, current_round)
        if coop_rate >= threshold_high:
            return Action.C
        elif coop_rate >= threshold_mid:
            if random.random() < coop_rate:
                return Action.C
            else:
                return Action.D
        elif coop_rate >= threshold_low:
            return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_57(BaseStrategy):
    """
    Adaptive Public Trust (APT): A collectively-minded strategy that balances
    mutual cooperation maximization with defensive mechanisms against exploitation.

    Core approach:
    - Round 1: Cooperate (establish trust)
    - Intermediate rounds: Adapt based on observed cooperation rate with dynamic thresholds
    - Final round: Cooperate only if historical cooperation is sufficiently high
    - Thresholds adjust based on game parameters (k and n)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        cooperation_rate = self._calculate_cooperation_rate(history)
        base_threshold = self._get_adaptive_threshold(cooperation_rate)
        threshold = self._adjust_threshold_for_parameters(base_threshold)
        if round_number == self.n_rounds - 1:
            if cooperation_rate >= 0.6:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        """
        Calculate the cooperation rate as:
        (total cooperators observed) / (n_players  rounds_completed)
        """
        rounds_completed = history.my_actions.shape[0]
        total_cooperators = 0
        for round_idx in range(rounds_completed):
            if history.my_actions[round_idx]:
                total_cooperators += 1
            total_cooperators += np.sum(history.opponent_actions[round_idx, :])
        total_possible = self.n_players * rounds_completed
        if total_possible == 0:
            return 0.5
        cooperation_rate = total_cooperators / total_possible
        return cooperation_rate

    def _get_adaptive_threshold(self, cooperation_rate: float) -> float:
        """
        Determine adaptive threshold based on observed cooperation rate.

        Higher cooperation  lower threshold (more optimistic)
        Lower cooperation  higher threshold (more defensive)
        """
        if cooperation_rate >= 0.5:
            return 0.4
        elif cooperation_rate >= 0.3:
            return 0.5
        else:
            return 0.7

    def _adjust_threshold_for_parameters(self, base_threshold: float) -> float:
        """
        Adjust threshold based on game parameters k and n.

        - When k is very close to 1: raise threshold (cooperation less valuable)
        - When k approaches n: lower threshold (cooperation very valuable)
        - When n is very large: raise threshold (individual impact diminishes)
        """
        adjusted = base_threshold
        if self.k < 1.2:
            adjusted += 0.1
        if self.k > self.n_players - 1:
            adjusted -= 0.1
        if self.n_players > 10:
            adjusted += 0.1
        adjusted = max(0.0, min(1.0, adjusted))
        return adjusted

class Strategy_COLLECTIVE_58(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare through conditional cooperation
    with adaptive thresholds, reciprocal punishment, and cascade recovery mechanisms.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.defection_counter = 0
        self.cascade_mode = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_idx = round_num - 1
        cooperators_prev = sum(history.opponent_actions[prev_round_idx, :])
        coop_rate_prev = cooperators_prev / self.n_players
        threshold = self._calculate_threshold(round_num, history)
        cascade_detected = self._detect_cascade(history, round_num)
        if cascade_detected:
            if coop_rate_prev >= 0.5:
                self.defection_counter = 0
                return Action.C
            else:
                self.defection_counter += 1
                return Action.D
        if round_num >= self.n_rounds - 2:
            if coop_rate_prev >= 0.6:
                return Action.C
            else:
                return Action.D
        if coop_rate_prev >= threshold:
            self.defection_counter = 0
            return Action.C
        else:
            return Action.D

    def _calculate_threshold(self, round_num: int, history: PlayerHistory) -> float:
        """
        Calculate adaptive threshold based on game phase and cooperation trends.
        """
        if round_num <= 2:
            return 0.5
        if round_num < self.n_rounds - 2:
            cooperation_rates = []
            for r in range(round_num):
                cooperators = sum(history.opponent_actions[r, :])
                cooperation_rates.append(cooperators / self.n_players)
            avg_coop_rate = np.mean(cooperation_rates)
            threshold = max(0.4, avg_coop_rate - 0.1)
            return threshold
        return 0.6

    def _detect_cascade(self, history: PlayerHistory, round_num: int) -> bool:
        """
        Detect if we're in a defection cascade (cooperation rate low for 2+ consecutive rounds).
        """
        if round_num < 2:
            return False
        low_coop_threshold = 0.3
        consecutive_low = 0
        for r in range(max(0, round_num - 2), round_num):
            cooperators = sum(history.opponent_actions[r, :])
            coop_rate = cooperators / self.n_players
            if coop_rate < low_coop_threshold:
                consecutive_low += 1
        if consecutive_low >= 2:
            self.cascade_mode = True
            return True
        if self.cascade_mode and round_num >= 1:
            cooperators = sum(history.opponent_actions[round_num - 1, :])
            coop_rate = cooperators / self.n_players
            if coop_rate > 0.6:
                self.cascade_mode = False
        return False

class Strategy_COLLECTIVE_59(BaseStrategy):
    """
    Adaptive Reciprocal Threshold (ART) Strategy for N-Player Public Goods Game.

    This strategy uses adaptive thresholds based on observed cooperation rates to decide
    whether to cooperate or defect. It starts with cooperation, adapts based on the
    average cooperation rate of previous rounds, and maintains principle consistency
    even in the final round while being responsive to observed behavior.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        threshold = self.k / self.n / (1.0 + self.k / self.n)
        cooperation_rates = []
        for round_idx in range(current_round):
            my_action = history.my_actions[round_idx]
            opponent_cooperators = sum(history.opponent_actions[round_idx, :])
            total_cooperators = (1 if my_action else 0) + opponent_cooperators
            cooperation_rate = total_cooperators / self.n
            cooperation_rates.append(cooperation_rate)
        average_cooperation = np.mean(cooperation_rates)
        if current_round < self.r - 1:
            if average_cooperation >= threshold:
                return Action.C
            else:
                return Action.D
        elif average_cooperation >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_60(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game.

    This strategy implements conditional cooperation based on observed cooperation rates.
    It cooperates in round 1, then adapts based on whether others' cooperation exceeds
    a dynamic threshold (k/n). Uses probabilistic softening near the threshold to avoid
    brittle oscillations. In the final round, cooperates if others met the threshold.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.oscillation_detected = False
        self.prev_coop_rate = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        coop_rate_last = cooperators_last_round / self.n
        if self.prev_coop_rate is not None:
            coop_rate_swing = abs(coop_rate_last - self.prev_coop_rate)
            if coop_rate_swing > 0.3:
                self.oscillation_detected = True
        self.prev_coop_rate = coop_rate_last
        threshold = self.k / self.n
        if self.k >= self.n - 0.5:
            tolerance_band = 0.1
        elif self.k <= 1.5:
            tolerance_band = 0.25
        else:
            tolerance_band = 0.15
        if self.oscillation_detected:
            tolerance_band = 0.2
        if current_round == self.r - 1:
            if coop_rate_last >= threshold:
                return Action.C
            else:
                return Action.D
        if coop_rate_last >= threshold:
            return Action.C
        elif coop_rate_last >= threshold - tolerance_band:
            prob_threshold = coop_rate_last / threshold * 0.8
            if random.random() < prob_threshold:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_61(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare, self-protection, and adaptive learning by:
    1. Starting with cooperation to signal goodwill
    2. Reciprocating based on group cooperation rates vs. adaptive threshold
    3. Defecting in final round (backward induction)
    4. Implementing gradual re-engagement to escape defection traps
    5. Detecting and responding to exploitation patterns
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.cooperation_threshold = self.k / self.n + 0.15

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        prev_round_idx = round_number - 1
        my_prev_action = history.my_actions[prev_round_idx]
        opponent_prev_actions = history.opponent_actions[prev_round_idx, :]
        total_cooperators = int(my_prev_action) + int(np.sum(opponent_prev_actions))
        cooperation_rate = total_cooperators / self.n
        my_payoff_prev = history.my_payoffs[prev_round_idx]
        all_payoffs_prev = np.concatenate([[my_payoff_prev], history.opponent_payoffs[prev_round_idx, :]])
        average_payoff_prev = np.mean(all_payoffs_prev)
        if cooperation_rate >= self.cooperation_threshold:
            return Action.C
        elif cooperation_rate < self.cooperation_threshold and my_payoff_prev > average_payoff_prev:
            return Action.D
        elif round_number == self.r - 1:
            return Action.D
        else:
            rounds_remaining = self.r - round_number
            defection_severity = 1.0 - cooperation_rate
            if defection_severity > 0.7 and rounds_remaining >= 3:
                return Action.C
            elif defection_severity <= 0.3 and rounds_remaining >= 2:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_62(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances individual security with collective welfare by:
    1. Starting cooperatively to establish mutual benefit
    2. Tracking collective cooperation rate (CCR)
    3. Responding dynamically to defection patterns
    4. Escalating strategically to punish free-riding
    5. Recovering gracefully when conditions improve
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.threshold_high = 0.6
        self.threshold_mid = 0.35
        self.threshold_low = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        completed_rounds = state.round_number
        total_cooperators = int(np.sum(history.opponent_actions[:completed_rounds, :]))
        my_cooperations = int(np.sum(history.my_actions[:completed_rounds]))
        total_cooperators += my_cooperations
        ccr = total_cooperators / (self.n_players * completed_rounds)
        if state.round_number == self.n_rounds - 1:
            if ccr >= self.threshold_high:
                return Action.C
            else:
                return Action.D
        if ccr >= self.threshold_high:
            return Action.C
        elif ccr >= self.threshold_mid:
            random.seed(state.round_number)
            if random.random() < ccr:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_63(BaseStrategy):
    """
    Adaptive Reciprocal Threshold (ART) Strategy for N-Player Public Goods Game.

    Balances mutual benefit maximization, robustness against exploitation, and adaptive learning.
    - Round 1: Cooperate (initial trust)
    - Rounds 2 to r-1: Cooperate if observed cooperation rate >= break-even threshold (1/k)
      with grace period for single-round dips
    - Round r: Apply threshold rule consistently (preserve reputation)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.break_even_threshold = 1.0 / game_description.k
        self.grace_period_used = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.grace_period_used = False
            return Action.C
        total_rounds_elapsed = state.round_number
        n = self.game_description.n_players
        my_cooperations = np.sum(history.my_actions)
        opponent_cooperations = np.sum(history.opponent_actions)
        total_cooperators = my_cooperations + opponent_cooperations
        total_possible_cooperations = n * total_rounds_elapsed
        observed_coop_rate = total_cooperators / total_possible_cooperations
        last_round_cooperators = int(history.my_actions[-1]) + np.sum(history.opponent_actions[-1, :])
        last_round_coop_rate = last_round_cooperators / n
        is_final_round = state.round_number == self.game_description.n_rounds - 1
        if observed_coop_rate >= self.break_even_threshold:
            return Action.C
        if not is_final_round and (not self.grace_period_used) and (last_round_coop_rate >= self.break_even_threshold):
            self.grace_period_used = True
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_64(BaseStrategy):
    """
    Adaptive Reciprocal Maximization (ARM) Strategy for N-Player Public Goods Game.

    Balances individual sustainability, collective value creation, and robustness through:
    - Optimistic cooperation in round 1
    - Conditional cooperation based on historical cooperation rates and reciprocity
    - Defection in final round (backward induction)
    - Adaptive thresholds that respond to opponent behavior patterns
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.consecutive_defects = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            if self.n <= 3 and self.k >= 1.8:
                return Action.C
            return Action.D
        coop_rate = self._calculate_cooperation_rate(history, round_num)
        collective_threshold = (self.k - 1) / self.n
        if coop_rate > collective_threshold:
            baseline = True
        else:
            baseline = False
        expected_coop_rate = self._expected_cooperation_rate(round_num)
        cooperation_deficit = coop_rate - expected_coop_rate
        if cooperation_deficit < -0.3:
            action = False
        elif cooperation_deficit > 0.1:
            action = True
        else:
            action = baseline
        if history.my_actions[round_num - 1] == False:
            self.consecutive_defects += 1
        else:
            self.consecutive_defects = 0
        if self.consecutive_defects >= 2:
            cooperators_in_prev_round = np.sum(history.opponent_actions[round_num - 1, :])
            if cooperators_in_prev_round > self.n / 2:
                action = True
                self.consecutive_defects = 0
        return Action.C if action else Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate the historical cooperation rate across all previous rounds.
        Returns: fraction of total possible cooperations that occurred
        """
        if round_num == 0:
            return 0.5
        my_coops = np.sum(history.my_actions[:round_num])
        opponent_coops = np.sum(history.opponent_actions[:round_num, :])
        total_possible = round_num * self.n + round_num
        total_coops = my_coops + opponent_coops
        return total_coops / total_possible if total_possible > 0 else 0.5

    def _expected_cooperation_rate(self, round_num: int) -> float:
        """
        Calculate expected cooperation rate based on game phase.
        Early rounds: expect higher cooperation (signaling)
        Later rounds: adjust based on observed patterns
        """
        if round_num <= 2:
            return 0.6
        elif round_num >= self.r - 2:
            return 0.3
        else:
            return 0.5

class Strategy_COLLECTIVE_65(BaseStrategy):
    """
    Adaptive Contribution Threshold (ACT) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with individual rationality through:
    1. Early cooperation to signal intent and gather information (Phase 1)
    2. Reciprocal assessment based on historical cooperation rates (Phase 2)
    3. Strategic defection in final round, unless strong cooperation observed (Phase 3)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if self.n_rounds == 1:
            return Action.D
        if round_num == self.n_rounds - 1:
            historical_coop_rate = self._calculate_cooperation_rate(history)
            if historical_coop_rate > 0.75:
                return Action.C
            else:
                return Action.D
        historical_coop_rate = self._calculate_cooperation_rate(history)
        threshold_high = self._get_threshold_high()
        threshold_low = self._get_threshold_low()
        if historical_coop_rate >= threshold_high:
            return Action.C
        elif historical_coop_rate >= threshold_low:
            if random.random() < historical_coop_rate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        """
        Calculate the historical cooperation rate across all rounds so far.

        Historical_Cooperation_Rate = (Total cooperators across all previous rounds) /
                                      (n  rounds_completed)
        """
        if history is None or len(history.my_actions) == 0:
            return 0.0
        rounds_completed = len(history.my_actions)
        my_cooperations = np.sum(history.my_actions)
        opponent_cooperations = np.sum(history.opponent_actions)
        total_cooperators = my_cooperations + opponent_cooperations
        total_possible = self.n_players * rounds_completed
        cooperation_rate = total_cooperators / total_possible if total_possible > 0 else 0.0
        return cooperation_rate

    def _get_threshold_high(self) -> float:
        """
        Determine the high cooperation threshold based on game parameters.
        """
        base_threshold = self.k / self.n_players
        if self.k >= self.n_players * 0.9:
            return 0.6
        elif self.k <= 1.1:
            return 0.8
        elif self.n_players > 20:
            return base_threshold
        elif self.n_players == 2:
            return base_threshold + 0.15
        else:
            return base_threshold + 0.1

    def _get_threshold_low(self) -> float:
        """
        Determine the low cooperation threshold based on game parameters.
        """
        base_threshold = self.k / self.n_players
        if self.k >= self.n_players * 0.9:
            return 0.5
        elif self.k <= 1.1:
            return 0.7
        elif self.n_players > 20:
            return base_threshold
        elif self.n_players == 2:
            return base_threshold + 0.0
        else:
            return base_threshold - 0.15

class Strategy_COLLECTIVE_66(BaseStrategy):
    """
    Adaptive Contribution Threshold (ACT) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare through conditional cooperation
    with escalating defection costs. Uses historical performance and opponent behavior
    to dynamically adjust contribution decisions across rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_high = 0.65
        self.threshold_mid = 0.4
        self.threshold_low = 0.15

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == r - 1:
            return self._final_round_decision(history)
        return self._adaptive_phase_decision(history, current_round)

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """
        Final round decision: primarily defect, but cooperate in high-cooperation
        environments if below median payoff (signaling for reputation).
        """
        avg_cooperation_rate = self._calculate_avg_cooperation_rate(history)
        median_payoff = self._calculate_median_payoff(history)
        my_cumulative_payoff = np.sum(history.my_payoffs)
        if avg_cooperation_rate > 0.6 and my_cumulative_payoff < median_payoff:
            return Action.C
        return Action.D

    def _adaptive_phase_decision(self, history: PlayerHistory, current_round: int) -> Action:
        """
        Rounds 1 to r-2: Conditional contribution based on historical performance.
        """
        avg_cooperation_rate = self._calculate_avg_cooperation_rate(history)
        my_cumulative_payoff = np.sum(history.my_payoffs)
        avg_cumulative_payoff = self._calculate_avg_cumulative_payoff(history)
        recent_cooperation = self._calculate_recent_cooperation(history)
        if avg_cooperation_rate > self.threshold_high:
            return Action.C
        if avg_cooperation_rate > self.threshold_mid:
            cooperation_prob = 0.7
            return Action.C if random.random() <= cooperation_prob else Action.D
        if avg_cooperation_rate > self.threshold_low:
            if my_cumulative_payoff > avg_cumulative_payoff * 1.1:
                return Action.D
            else:
                cooperation_prob = 0.4
                return Action.C if random.random() <= cooperation_prob else Action.D
        if recent_cooperation < 0.1:
            return Action.D
        else:
            cooperation_prob = 0.2
            return Action.C if random.random() <= cooperation_prob else Action.D

    def _calculate_avg_cooperation_rate(self, history: PlayerHistory) -> float:
        """
        Calculate average cooperation rate across all players and all past rounds.
        """
        n = self.game_description.n_players
        rounds_completed = history.my_actions.shape[0]
        if rounds_completed == 0:
            return 0.0
        my_cooperations = np.sum(history.my_actions)
        opponent_cooperations = np.sum(history.opponent_actions)
        total_cooperations = my_cooperations + opponent_cooperations
        total_possible_actions = n * rounds_completed
        avg_cooperation_rate = total_cooperations / total_possible_actions
        return float(avg_cooperation_rate)

    def _calculate_avg_cumulative_payoff(self, history: PlayerHistory) -> float:
        """
        Calculate average cumulative payoff of all players so far.
        """
        n = self.game_description.n_players
        my_cumulative = np.sum(history.my_payoffs)
        opponent_cumulative = np.sum(history.opponent_payoffs)
        total_cumulative = my_cumulative + opponent_cumulative
        avg_payoff = total_cumulative / n
        return float(avg_payoff)

    def _calculate_recent_cooperation(self, history: PlayerHistory) -> float:
        """
        Calculate cooperation rate in the last 3 rounds (or fewer if less history exists).
        """
        rounds_completed = history.my_actions.shape[0]
        lookback = min(3, rounds_completed)
        if lookback == 0:
            return 0.0
        n = self.game_description.n_players
        recent_my = np.sum(history.my_actions[-lookback:])
        recent_opponents = np.sum(history.opponent_actions[-lookback:, :])
        total_recent_cooperations = recent_my + recent_opponents
        total_recent_actions = n * lookback
        recent_cooperation_rate = total_recent_cooperations / total_recent_actions
        return float(recent_cooperation_rate)

    def _calculate_median_payoff(self, history: PlayerHistory) -> float:
        """
        Calculate median cumulative payoff across all players.
        """
        n = self.game_description.n_players
        my_cumulative = np.sum(history.my_payoffs)
        opponent_cumulative = np.sum(history.opponent_payoffs, axis=0)
        all_cumulative_payoffs = np.concatenate(([my_cumulative], opponent_cumulative))
        median_payoff = float(np.median(all_cumulative_payoffs))
        return median_payoff

class Strategy_COLLECTIVE_67(BaseStrategy):
    """
    Adaptive Contribution with Reciprocal Enforcement strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with robustness against defection through:
    - Cooperative leadership in round 1
    - Strategic defection in final rounds (subgame perfection)
    - Reciprocal enforcement based on collective cooperation rates
    - Exploitation detection and adaptive response
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.n_rounds - 1:
            return Action.D
        if round_num == self.n_rounds - 2:
            cooperation_rate = self._compute_cooperation_rate(history)
            exploitation_deficit = self._compute_exploitation_deficit(history)
            if cooperation_rate >= 0.75 and exploitation_deficit <= 1:
                return Action.C
            else:
                return Action.D
        cooperation_rate = self._compute_cooperation_rate(history)
        exploitation_deficit = self._compute_exploitation_deficit(history)
        defection_ratio = self._compute_defection_ratio(history)
        last_round_cooperators = int(sum(history.opponent_actions[-1, :]))
        cooperation_threshold = (self.k - 1) / (2 * self.k - 1)
        if cooperation_rate >= cooperation_threshold:
            return Action.C
        if defection_ratio > 0.4 and exploitation_deficit >= 2:
            return Action.D
        if last_round_cooperators >= self.n_players * 0.5:
            return Action.C
        else:
            return Action.D

    def _compute_cooperation_rate(self, history: PlayerHistory) -> float:
        """
        Compute proportion of rounds where all n players cooperated.
        """
        if len(history.my_actions) == 0:
            return 0.0
        all_cooperated_count = 0
        for round_idx in range(len(history.my_actions)):
            my_action = history.my_actions[round_idx]
            opponent_actions = history.opponent_actions[round_idx, :]
            if my_action and np.all(opponent_actions):
                all_cooperated_count += 1
        return all_cooperated_count / len(history.my_actions)

    def _compute_exploitation_deficit(self, history: PlayerHistory) -> int:
        """
        Count rounds where I cooperated but majority of opponents defected.
        """
        if len(history.my_actions) == 0:
            return 0
        exploitation_count = 0
        for round_idx in range(len(history.my_actions)):
            my_action = history.my_actions[round_idx]
            opponent_actions = history.opponent_actions[round_idx, :]
            cooperators = int(np.sum(opponent_actions))
            defectors = self.n_players - 1 - cooperators
            if my_action and defectors > cooperators:
                exploitation_count += 1
        return exploitation_count

    def _compute_defection_ratio(self, history: PlayerHistory) -> float:
        """
        Compute ratio of exploitation rounds to total past rounds.
        """
        if len(history.my_actions) == 0:
            return 0.0
        exploitation_deficit = self._compute_exploitation_deficit(history)
        return exploitation_deficit / len(history.my_actions)

class Strategy_COLLECTIVE_68(BaseStrategy):
    """
    Adaptive Reciprocity with Collective Welfare Maximization.

    Balances individual rationality with collective welfare by:
    1. Opening with cooperation to establish reciprocal frame
    2. Reciprocating cooperation when above threshold
    3. Escalating defection when exploitation is detected
    4. Preserving cooperation norms in final round if warranted
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = game_description.k / game_description.n_players + 0.15

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_idx = round_num - 1
        cooperators_prev_round = np.sum(history.opponent_actions[prev_round_idx, :])
        cooperation_rate_prev = cooperators_prev_round / n
        if round_num == r - 1:
            if cooperation_rate_prev >= self.threshold:
                return Action.C
            else:
                return Action.D
        my_prev_action = history.my_actions[prev_round_idx]
        defection_count_prev = n - cooperators_prev_round
        if round_num >= 2:
            cooperators_round_before_prev = np.sum(history.opponent_actions[round_num - 2, :])
            cooperation_rate_before_prev = cooperators_round_before_prev / n
            if cooperation_rate_before_prev > 0:
                cooperation_drop = cooperation_rate_before_prev - cooperation_rate_prev
                if cooperation_drop > 0.5:
                    return Action.C
        if cooperation_rate_prev >= self.threshold:
            return Action.C
        elif my_prev_action and defection_count_prev > n / 2:
            return Action.D
        elif not my_prev_action and cooperation_rate_prev < 0.3:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_69(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game

    Balances individual rationality with collective welfare by:
    1. Starting optimistic (cooperation) to signal willingness
    2. Adapting based on empirical returns using a dynamic contribution threshold
    3. Distinguishing between temporary and systemic free-riding
    4. Stabilizing cooperative equilibria in endgame phases
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.T = math.ceil(self.n / self.k)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        if t == 0:
            return Action.C
        recent_cooperators = int(sum(history.opponent_actions[t - 1, :]))
        if t <= self.r - 3:
            if recent_cooperators >= self.T:
                return Action.C
            elif recent_cooperators >= 2.0 / 3.0 * self.T:
                recovery_prob = recent_cooperators / self.T * 0.8
                if random.random() < recovery_prob:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D
        else:
            my_cooperations = int(sum(history.my_actions[:t]))
            cooperation_rate = my_cooperations / t
            if cooperation_rate >= 0.5 and recent_cooperators >= self.T / 2.0:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_70(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game

    Balances collective welfare maximization with individual sustainability through
    a threshold-based reciprocal contribution mechanism. Cooperates when the average
    cooperation rate exceeds k/n, signaling genuine reciprocity while protecting
    against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        avg_cooperation_rate = self._calculate_avg_cooperation_rate(history, state.round_number)
        if avg_cooperation_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_avg_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the average cooperation rate across all completed rounds.

        Returns the fraction of total possible contributions that were made.
        This includes all players' actions from rounds 0 to current_round-1.
        """
        n_players = self.game_description.n_players
        opponent_actions = history.opponent_actions[:current_round, :]
        total_cooperations = np.sum(opponent_actions)
        my_actions = history.my_actions[:current_round]
        total_cooperations += np.sum(my_actions)
        total_possible = n_players * current_round
        avg_cooperation_rate = total_cooperations / total_possible if total_possible > 0 else 0.0
        return avg_cooperation_rate

class Strategy_COLLECTIVE_71(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with robustness against exploitation.
    Uses phase-based decision logic with cooperation rate thresholds to determine
    whether cooperation is sustainable.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        cooperation_rate = self._calculate_avg_cooperation_rate(history)
        recent_cooperation = self._calculate_recent_cooperation_rate(history, window=5)
        critical_threshold = (self.k - 1) / self.k
        if current_round == self.r - 1:
            if cooperation_rate >= critical_threshold:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= critical_threshold:
            return Action.C
        elif cooperation_rate >= critical_threshold * 0.75:
            if recent_cooperation >= cooperation_rate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _calculate_avg_cooperation_rate(self, history: PlayerHistory) -> float:
        """
        Calculate the average cooperation rate across all previous rounds.
        Includes both this player's actions and opponents' actions.
        """
        if history.my_actions.size == 0:
            return 0.0
        total_my_coop = np.sum(history.my_actions)
        total_opponent_coop = np.sum(history.opponent_actions)
        total_player_rounds = history.my_actions.size * (1 + self.n - 1)
        if total_player_rounds == 0:
            return 0.0
        return (total_my_coop + total_opponent_coop) / total_player_rounds

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory, window: int=5) -> float:
        """
        Calculate cooperation rate over the most recent rounds.
        Uses a sliding window approach.
        """
        if history.my_actions.size == 0:
            return 0.0
        total_rounds = history.my_actions.size
        start_idx = max(0, total_rounds - window)
        end_idx = total_rounds
        recent_my_actions = history.my_actions[start_idx:end_idx]
        recent_opponent_actions = history.opponent_actions[start_idx:end_idx, :]
        total_coop = np.sum(recent_my_actions) + np.sum(recent_opponent_actions)
        rounds_in_window = end_idx - start_idx
        total_player_rounds_in_window = rounds_in_window * (1 + self.n - 1)
        if total_player_rounds_in_window == 0:
            return 0.0
        return total_coop / total_player_rounds_in_window

class Strategy_COLLECTIVE_72(BaseStrategy):
    """
    Adaptive Reciprocal Provisioning (ARP) Strategy

    A collective strategy that balances individual rationality with collective welfare
    through conditional cooperation. The strategy cooperates in early rounds when others
    cooperate (above a threshold), adapts to defection, and defects in the final round
    due to backward induction.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = max(0.5, self.k / self.n_players)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        prev_round_cooperators = sum(history.opponent_actions[current_round - 1, :])
        cooperation_rate = prev_round_cooperators / self.n_players
        if cooperation_rate < self.threshold:
            if current_round > 1:
                prev_prev_cooperators = sum(history.opponent_actions[current_round - 2, :])
                prev_prev_cooperation_rate = prev_prev_cooperators / self.n_players
                if prev_prev_cooperation_rate >= self.threshold:
                    return Action.C
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_73(BaseStrategy):
    """
    Adaptive Contribution Threshold (ACT) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare by:
    1. Estimating group cooperation from historical behavior
    2. Contributing when it multiplies value for the collective
    3. Defecting strategically when others free-ride persistently
    4. Recovering cooperation when conditions improve

    Key insight: cooperation is valuable only when enough others cooperate.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        prev_round_idx = round_t - 1
        cooperation_count_prev = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        cooperation_rate_prev = cooperation_count_prev / self.n
        consecutive_low = self._count_consecutive_low_rounds(history, prev_round_idx)
        if round_t == self.r - 1:
            if cooperation_rate_prev >= self.threshold:
                return Action.C
            else:
                return Action.D
        if cooperation_rate_prev >= self.threshold:
            return Action.C
        elif consecutive_low < 2:
            return Action.C
        else:
            return Action.D

    def _count_consecutive_low_rounds(self, history: PlayerHistory, up_to_round: int) -> int:
        """
        Count the number of consecutive rounds ending at up_to_round
        where cooperation_rate < threshold.
        """
        consecutive = 0
        for round_idx in range(up_to_round, -1, -1):
            cooperation_count = int(np.sum(history.opponent_actions[round_idx, :]))
            cooperation_rate = cooperation_count / self.n
            if cooperation_rate < self.threshold:
                consecutive += 1
            else:
                break
        return consecutive

class Strategy_COLLECTIVE_74(BaseStrategy):
    """
    Adaptive Conditional Generosity (ACG): A collectively-minded strategy that
    cooperates in round 1, then conditionally cooperates in subsequent rounds
    based on whether the population cooperation rate meets the threshold k/n.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round_opponent_actions = history.opponent_actions[state.round_number - 1, :]
        cooperators_previous_round = sum(previous_round_opponent_actions) + int(history.my_actions[state.round_number - 1])
        cooperation_rate_previous_round = cooperators_previous_round / self.game_description.n_players
        if cooperation_rate_previous_round >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_75(BaseStrategy):
    """
    Adaptive Graduated Response (AGR): A collective strategy for N-Player Public Goods Games
    that maximizes collective welfare through graduated reciprocation based on observed cooperation rates.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        total_cooperators = 0
        for past_round in range(round_t):
            my_contribution = 1 if history.my_actions[past_round] else 0
            opponent_contributions = sum(history.opponent_actions[past_round, :])
            total_cooperators += my_contribution + opponent_contributions
        total_player_rounds = self.n * round_t
        coop_rate = total_cooperators / total_player_rounds
        if round_t == self.r - 1:
            if coop_rate >= self.k / self.n:
                return Action.C
            else:
                return Action.D
        threshold_high = max(0.7, self.k / self.n)
        threshold_medium = max(0.5, self.k / self.n - 0.1)
        threshold_low = self.k / self.n - 0.2
        if coop_rate >= threshold_high:
            return Action.C
        elif coop_rate >= threshold_medium:
            p_medium = (coop_rate - threshold_low) / (threshold_medium - threshold_low)
            seed = (round_t + hash(str(history.my_actions) + str(history.opponent_actions))) % 100
            if seed < p_medium * 100:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_76(BaseStrategy):
    """
    Conditional Reciprocal Threshold (CRT) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with robust defection against free-riders,
    using dynamic thresholds that adapt to observed cooperation rates.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round_idx = state.round_number - 1
        my_prev_action = history.my_actions[prev_round_idx]
        opponent_prev_actions = history.opponent_actions[prev_round_idx, :]
        total_cooperators = int(my_prev_action) + int(np.sum(opponent_prev_actions))
        cooperation_rate = total_cooperators / self.n
        critical_threshold = self.k / self.n
        adaptive_tolerance = max(0.3, critical_threshold + 0.15)
        game_progress = state.round_number / self.r
        if cooperation_rate >= adaptive_tolerance:
            return Action.C
        elif cooperation_rate >= critical_threshold and game_progress < 0.75:
            if random.random() < cooperation_rate:
                return Action.C
            else:
                return Action.D
        elif cooperation_rate < critical_threshold:
            return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_77(BaseStrategy):
    """
    Adaptive Reciprocal Threshold (ART) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization, rational self-protection, and adaptive learning.
    - Round 1: Cooperate (signal goodwill)
    - Rounds 2-(r-1): Match cooperation rate adaptively using thresholds
    - Final round: Defect (or cooperate if exceptional cooperation history exists)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_high = 0.6
        self.threshold_mid = 0.4
        self.collective_override_threshold = 0.65

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        n_rounds = self.game_description.n_rounds
        n_players = self.game_description.n_players
        if current_round == 0:
            return Action.C
        if current_round == n_rounds - 1:
            avg_coop_all_time = self._calculate_avg_cooperation_rate(history, n_players)
            rounds_remaining = n_rounds - current_round
            if rounds_remaining <= 2 and avg_coop_all_time >= self.collective_override_threshold:
                return Action.C
            return Action.D
        coop_rate_last_round = self._get_last_round_cooperation_rate(history, n_players)
        if coop_rate_last_round >= self.threshold_high:
            return Action.C
        elif coop_rate_last_round >= self.threshold_mid:
            if random.random() < coop_rate_last_round:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _get_last_round_cooperation_rate(self, history: PlayerHistory, n_players: int) -> float:
        """
        Calculate the cooperation rate in the most recent round.
        Returns a float between 0 and 1.
        """
        if history is None or len(history.opponent_actions) == 0:
            return 0.0
        last_round_opponent_actions = history.opponent_actions[-1, :]
        cooperators_last_round = np.sum(last_round_opponent_actions)
        my_last_action = history.my_actions[-1]
        total_cooperators = cooperators_last_round + (1 if my_last_action else 0)
        coop_rate = total_cooperators / n_players
        return coop_rate

    def _calculate_avg_cooperation_rate(self, history: PlayerHistory, n_players: int) -> float:
        """
        Calculate the average cooperation rate across all rounds of history.
        Returns a float between 0 and 1.
        """
        if history is None or len(history.opponent_actions) == 0:
            return 0.0
        total_coop_rate = 0.0
        num_rounds = len(history.opponent_actions)
        for round_idx in range(num_rounds):
            cooperators = np.sum(history.opponent_actions[round_idx, :])
            my_action = history.my_actions[round_idx]
            total_cooperators = cooperators + (1 if my_action else 0)
            coop_rate = total_cooperators / n_players
            total_coop_rate += coop_rate
        avg_coop_rate = total_coop_rate / num_rounds
        return avg_coop_rate

class Strategy_COLLECTIVE_78(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game

    Balances collective welfare maximization with individual security through adaptive
    threshold-based decisions. Cooperates when cooperation is sustainable, defects when
    collective action fails, and uses probabilistic graceful degradation in between.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        last_round_idx = round_number - 1
        my_last_action = history.my_actions[last_round_idx]
        opponent_cooperators_last_round = sum(history.opponent_actions[last_round_idx, :])
        total_cooperators_last_round = opponent_cooperators_last_round + (1 if my_last_action else 0)
        cooperation_rate_last_round = total_cooperators_last_round / self.n
        denominator = self.k * self.n - self.n
        if denominator <= 0:
            threshold = 1.0
        else:
            threshold = (self.n - 1) / denominator
        threshold = max(0.0, min(1.0, threshold))
        if cooperation_rate_last_round >= threshold:
            return Action.C
        elif cooperation_rate_last_round > 0:
            prob_cooperate = cooperation_rate_last_round / threshold if threshold > 0 else 0.0
            prob_cooperate = max(0.0, min(1.0, prob_cooperate))
            if random.random() < prob_cooperate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_79(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare through demonstrated reciprocity.
    Cooperates in initial rounds to establish intent, then adapts based on observed cooperation rates,
    with special handling for the final round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number <= 1:
            return Action.C
        recent_cooperation_rate = self._get_recent_cooperation_rate(history, round_number)
        if round_number == self.n_rounds - 1:
            threshold = 0.4
            if recent_cooperation_rate >= threshold:
                return Action.C
            else:
                return Action.D
        threshold = self._calculate_threshold()
        if recent_cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _get_recent_cooperation_rate(self, history: PlayerHistory, round_number: int) -> float:
        """
        Calculate the fraction of players cooperating in the last 2 rounds.
        """
        if round_number == 0:
            return 0.0
        start_round = max(0, round_number - 2)
        end_round = round_number
        total_cooperations = 0
        total_actions = 0
        for round_idx in range(start_round, end_round):
            cooperations_this_round = np.sum(history.opponent_actions[round_idx, :])
            total_cooperations += cooperations_this_round
            total_actions += self.n_players - 1
        if total_actions == 0:
            return 0.0
        return total_cooperations / total_actions

    def _calculate_threshold(self) -> float:
        """
        Calculate the cooperation threshold for learning rounds.

        base_threshold = (k - 1) / n
        discount_factor = 0.3 * (1 - base_threshold)
        final_threshold = max(0.5, base_threshold - discount_factor)
        """
        base_threshold = (self.k - 1.0) / self.n_players
        discount_factor = 0.3 * (1.0 - base_threshold)
        final_threshold = max(0.5, base_threshold - discount_factor)
        return final_threshold

class Strategy_COLLECTIVE_80(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game

    This strategy pursues conditional cooperation with adaptive thresholds.
    It contributes proportionally to observed cooperation rates, with thresholds
    that tighten as the game progresses. The strategy balances collective welfare
    with protection against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.breakdown_defect_countdown = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            if self.k / self.n >= 0.5:
                return Action.C
            else:
                return Action.D
        prev_cooperators = int(np.sum(history.opponent_actions[round_num - 1, :]))
        cooperation_rate_prev = prev_cooperators / self.n
        if self.breakdown_defect_countdown > 0:
            self.breakdown_defect_countdown -= 1
            return Action.D
        if round_num >= 2:
            cooperators_t_minus_1 = int(np.sum(history.opponent_actions[round_num - 1, :]))
            cooperators_t_minus_2 = int(np.sum(history.opponent_actions[round_num - 2, :]))
            threshold_breakdown = self.k / (2 * self.n)
            if cooperators_t_minus_1 < threshold_breakdown and cooperators_t_minus_2 < threshold_breakdown:
                self.breakdown_defect_countdown = 1
                return Action.D
        if round_num == self.r - 1:
            min_cooperation_needed = self.n - 1
            if prev_cooperators >= min_cooperation_needed:
                return Action.C
            else:
                return Action.D
        threshold = self.k / self.n + (1 - self.k / self.n) * ((round_num + 1) / self.r)
        if cooperation_rate_prev >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_81(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Pursues conditional cooperation with adaptive thresholds, balancing individual rationality,
    collective welfare, and robustness against diverse opponent types.

    Core insight: cooperation is individually rational when enough others cooperate to make
    the public good valuable: (k/n)  cooperators  1.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        lookback_rounds = min(3, round_number)
        recent_opponent_actions = history.opponent_actions[-lookback_rounds:, :]
        total_cooperators = np.sum(recent_opponent_actions)
        total_opponent_slots = lookback_rounds * self.n
        recent_cooperation_rate = total_cooperators / total_opponent_slots if total_opponent_slots > 0 else 0.0
        threshold_1 = self.k / self.n ** 2
        threshold_2 = self.k / (2 * self.n ** 2)
        if round_number == self.r - 1:
            if recent_cooperation_rate >= threshold_1:
                return Action.C
            else:
                return Action.D
        else:
            rounds_remaining = self.r - round_number
            if recent_cooperation_rate >= threshold_1:
                return Action.C
            elif recent_cooperation_rate >= threshold_2 and rounds_remaining >= 3:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_82(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC): Balances individual rationality with collective benefit.

    - Phase 1 (Early): Cooperate to signal intent and gather information
    - Phase 2 (Middle): Conditional cooperation based on observed cooperation rate vs threshold
    - Phase 3 (Final): Defect (or cooperate only if perfect cooperation observed)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.k - 1) / self.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        early_rounds = max(3, math.ceil(3 * self.n_rounds / self.n_rounds))
        if round_number < early_rounds:
            return Action.C
        if round_number == self.n_rounds - 1:
            if self._all_previous_cooperation(history):
                return Action.C
            else:
                return Action.D
        cooperation_rate = self._calculate_cooperation_rate(history, round_number)
        if cooperation_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate cooperation rate using recent rounds weighted more heavily.
        Uses rolling average of last 5 rounds (70%) + overall average (30%).
        """
        if current_round == 0:
            return 0.5
        total_cooperators = np.sum(history.opponent_actions[:current_round, :])
        total_observations = current_round * self.n_players
        overall_rate = total_cooperators / total_observations if total_observations > 0 else 0.5
        recent_start = max(0, current_round - 5)
        recent_rounds = current_round - recent_start
        if recent_rounds > 0:
            recent_cooperators = np.sum(history.opponent_actions[recent_start:current_round, :])
            recent_observations = recent_rounds * self.n_players
            recent_rate = recent_cooperators / recent_observations if recent_observations > 0 else 0.5
        else:
            recent_rate = overall_rate
        weighted_rate = 0.7 * recent_rate + 0.3 * overall_rate
        return weighted_rate

    def _all_previous_cooperation(self, history: PlayerHistory) -> bool:
        """
        Check if all previous actions by all opponents were cooperation.
        """
        if history is None or len(history.opponent_actions) == 0:
            return False
        return np.all(history.opponent_actions)

class Strategy_COLLECTIVE_83(BaseStrategy):
    """
    Conditional Reciprocal Contribution (CRC) Strategy for N-Player Public Goods Game

    Balances individual rationality with collective welfare by:
    1. Cooperating in round 1 to bootstrap cooperation
    2. In subsequent rounds, cooperating if and only if the previous round's
       cooperation rate met or exceeded the break-even threshold k/n
    3. Defecting when cooperation rate falls below threshold to avoid exploitation
    4. Immediately re-engaging when cooperation recovers

    This threshold-based reciprocity encourages convergence toward cooperative
    equilibria while protecting against free-rider exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.k = game_description.k
        self.threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round_opponent_actions = history.opponent_actions[-1, :]
        cooperators_last_round = int(history.my_actions[-1]) + int(np.sum(previous_round_opponent_actions))
        cooperation_rate = cooperators_last_round / self.n_players
        if cooperation_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_84(BaseStrategy):
    """
    Adaptive Reciprocal Maximization (ARM): A collective strategy that balances
    mutual benefit maximization, exploitation resistance, and adaptive recovery.

    Core mechanism:
    - Round 1: Optimistic cooperation to probe opponent types
    - Rounds 2 to r-1: Conditional cooperation based on observed cooperation rate
      relative to an adaptive threshold that decreases over time
    - Final round: Cooperate if average cooperation  60%, else defect

    The strategy uses graduated response: larger deficits trigger defection with
    higher probability, allowing partial punishment without mutual destruction.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_idx = round_num - 1
        opponent_cooperators_prev = int(sum(history.opponent_actions[prev_round_idx, :]))
        cooperation_rate_prev = opponent_cooperators_prev / (self.n_players - 1)
        if round_num == self.n_rounds - 1:
            avg_cooperation = np.mean(history.opponent_actions)
            if avg_cooperation >= 0.6:
                return Action.C
            else:
                return Action.D
        normalized_round = round_num / self.n_rounds
        threshold = max(0.5, 1.0 - normalized_round * 0.3)
        cooperation_deficit = max(0.0, threshold - cooperation_rate_prev)
        if cooperation_deficit < 0.15:
            return Action.C
        elif cooperation_deficit < 0.35:
            cooperation_probability = 1.0 - cooperation_deficit
            if random.random() < cooperation_probability:
                return Action.C
            else:
                return Action.D
        else:
            all_defected_prev = opponent_cooperators_prev == 0
            is_early_phase = round_num < self.n_rounds / 3.0
            if all_defected_prev and is_early_phase:
                return Action.D
            if round_num >= 2:
                prev_prev_coop = int(sum(history.opponent_actions[round_num - 2, :])) / (self.n_players - 1)
                coop_jump = cooperation_rate_prev - prev_prev_coop
                if coop_jump > 0.3:
                    return Action.C
            return Action.D

class Strategy_COLLECTIVE_85(BaseStrategy):
    """
    Adaptive Reciprocal Investment (ARI): A collective strategy that dynamically balances
    cooperation and defection based on observed cooperation rates in the group.

    - Round 0: Cooperate unconditionally to establish reciprocal signal
    - Rounds 1 to r-2: Cooperate if cooperation_rate >= max(0.4, (k-1)/(n-1))
    - Final round: Cooperate if cooperation_rate >= max(0.5, (k-1)/(n-1))

    This strategy optimizes for collective welfare while maintaining individual resilience
    against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        base_threshold = (self.k - 1.0) / (self.n - 1.0)
        if round_num == self.r - 1:
            threshold = max(0.5, base_threshold)
        else:
            threshold = max(0.4, base_threshold)
        previous_round_idx = round_num - 1
        opponent_cooperators = sum(history.opponent_actions[previous_round_idx, :])
        my_cooperation = history.my_actions[previous_round_idx]
        total_cooperators = opponent_cooperators + (1 if my_cooperation else 0)
        cooperation_rate = total_cooperators / self.n
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_86(BaseStrategy):
    """
    Conditional Reciprocal Contribution (CRC) Strategy for N-Player Public Goods Game.

    Balances individual security with collective welfare by:
    1. Rewarding cooperation when conditions are favorable
    2. Protecting against exploitation through conditional defection
    3. Adapting dynamically to opponent behavior patterns
    4. Maximizing total welfare when feasible
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.defect_streak = 0
        self.coop_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            coop_rate_prev = self._get_cooperation_rate(history, round_num - 1)
            if coop_rate_prev >= 0.95 and self.k / self.n >= 0.9:
                return Action.C
            return Action.D
        coop_rate_prev = self._get_cooperation_rate(history, round_num - 1)
        if coop_rate_prev < 0.1:
            self.defect_streak += 1
            if self.defect_streak >= 2:
                return Action.D
        else:
            self.defect_streak = 0
        if coop_rate_prev > 0.85:
            self.coop_streak += 1
            if self.coop_streak >= 2:
                return Action.C
        else:
            self.coop_streak = 0
        if round_num >= 3:
            volatility = self._get_volatility(history, round_num)
            if volatility > 0.3:
                return Action.D
            elif volatility > 0.2 and coop_rate_prev < 0.5:
                return Action.D
        threshold_adjustment = 0.15 if self.n <= 3 else 0.0
        remaining_rounds = self.r - round_num
        discount_factor = remaining_rounds / (self.r - 1) if self.r > 1 else 1.0
        cooperation_threshold = self.k / self.n * 0.9 + discount_factor * 0.15 + threshold_adjustment
        cooperation_threshold = max(0.0, min(1.0, cooperation_threshold))
        if history.my_actions[round_num - 1] and coop_rate_prev < 0.2:
            if round_num >= 2 and self._get_cooperation_rate(history, round_num - 2) < 0.2:
                return Action.D
        if coop_rate_prev >= cooperation_threshold:
            return Action.C
        elif coop_rate_prev < cooperation_threshold / 2:
            return Action.D
        else:
            defection_prob = (cooperation_threshold - coop_rate_prev) / cooperation_threshold
            if random.random() < defection_prob:
                return Action.D
            return Action.C

    def _get_cooperation_rate(self, history: PlayerHistory, round_idx: int) -> float:
        """Calculate cooperation rate from opponents in a given round."""
        if round_idx < 0 or round_idx >= len(history.opponent_actions):
            return 0.0
        cooperators = np.sum(history.opponent_actions[round_idx, :])
        return float(cooperators) / self.n

    def _get_volatility(self, history: PlayerHistory, round_num: int) -> float:
        """Calculate volatility of cooperation rates over last 3 rounds."""
        start_idx = max(0, round_num - 3)
        coop_rates = []
        for i in range(start_idx, round_num):
            coop_rates.append(self._get_cooperation_rate(history, i))
        if len(coop_rates) < 2:
            return 0.0
        mean_rate = np.mean(coop_rates)
        variance = np.mean([(rate - mean_rate) ** 2 for rate in coop_rates])
        std_dev = math.sqrt(variance)
        return std_dev

class Strategy_COLLECTIVE_87(BaseStrategy):
    """
    Adaptive Reciprocal Stewardship (ARS) - A collective welfare maximizing strategy
    for N-Player Public Goods Games that balances cooperation, self-protection, and
    adaptive responsiveness to group behavior patterns.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            return Action.D
        return self._decide_middle_round(history, round_num)

    def _decide_middle_round(self, history: PlayerHistory, round_num: int) -> Action:
        """
        Decision logic for middle rounds based on group cooperation metrics.
        """
        prev_round_idx = round_num - 1
        my_prev_action = history.my_actions[prev_round_idx]
        opponent_prev_actions = history.opponent_actions[prev_round_idx, :]
        total_cooperators = int(my_prev_action) + sum(opponent_prev_actions)
        coop_rate = total_cooperators / self.n
        my_prev_payoff = history.my_payoffs[prev_round_idx]
        opponent_prev_payoffs = history.opponent_payoffs[prev_round_idx, :]
        avg_payoff = (my_prev_payoff + sum(opponent_prev_payoffs)) / self.n
        k_ratio = self.k / self.n
        threshold_high = k_ratio
        threshold_medium = 0.5
        threshold_low = 0.25
        self.breakdown_recovery_prob = 0.33
        if self.n <= 3:
            self.breakdown_recovery_prob = 0.5
        if self.k < 1.2:
            threshold_medium = max(0.45, threshold_medium - 0.05)
            threshold_low = max(0.22, threshold_low - 0.03)
        elif self.k > self.n - 0.5:
            threshold_medium = min(0.55, threshold_medium + 0.05)
            threshold_low = min(0.27, threshold_low + 0.03)
        if coop_rate >= threshold_high:
            return Action.C
        elif coop_rate >= threshold_medium:
            if my_prev_payoff >= avg_payoff:
                return Action.C
            else:
                return Action.D
        elif coop_rate >= threshold_low:
            return Action.D
        elif random.random() < self.breakdown_recovery_prob:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_88(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Games.

    Pursues mutual benefit maximization through:
    1. Cooperation-first signaling in round 1
    2. Adaptive reciprocity in middle rounds based on cooperation rate
    3. Historical honesty in the final round

    Uses dynamic thresholds and stochastic testing to balance individual and collective welfare.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        threshold = max(0.4, self.k / self.n)
        if round_number == self.r - 1:
            total_cooperators = int(np.sum(history.opponent_actions[:-1, :]))
            overall_coop_rate = total_cooperators / (self.n * round_number)
            if overall_coop_rate >= threshold:
                return Action.C
            else:
                return Action.D
        prev_round_cooperators = int(np.sum(history.opponent_actions[round_number - 1, :]))
        prev_coop_rate = prev_round_cooperators / self.n
        if prev_coop_rate >= threshold:
            return Action.C
        elif prev_coop_rate > 0:
            test_probability = min(prev_coop_rate, 0.5)
            if random.random() < test_probability:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_89(BaseStrategy):
    """
    Adaptive Graduated Reciprocity (AGR): A collective strategy that uses graduated
    reciprocity with adaptive thresholds to balance cooperation and defection based
    on observed population behavior across rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_cooperators = np.sum(history.opponent_actions[round_num - 1, :])
        coop_rate = prev_cooperators / self.n
        if round_num >= 2 and self.r > 4:
            prev_prev_cooperators = np.sum(history.opponent_actions[round_num - 2, :])
            prev_prev_coop_rate = prev_prev_cooperators / self.n
            coop_rate = (coop_rate + prev_prev_coop_rate) / 2.0
        threshold = self._calculate_threshold(round_num, coop_rate)
        if coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_threshold(self, round_num: int, coop_rate: float) -> float:
        """Calculate the cooperation rate threshold for current round."""
        if self.n <= 3:
            base_threshold = 0.35
            if round_num == self.r - 1:
                return 0.4
            return base_threshold
        if round_num <= self.r / 3.0:
            threshold = 0.5
        elif round_num == self.r - 1:
            threshold = 0.4
        elif round_num <= 2.0 * self.r / 3.0:
            threshold = max(0.4, 0.5 - 0.1 * coop_rate)
        else:
            threshold = max(0.35, coop_rate)
        if self.k > 0.85 * self.n:
            threshold += 0.1
        if round_num <= 2 and coop_rate < 0.3:
            threshold = 0.0
        threshold = min(1.0, max(0.0, threshold))
        return threshold

class Strategy_COLLECTIVE_90(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Maximizes collective welfare while maintaining individual sustainability through:
    - Phased decision-making (exploration, exploitation, endgame)
    - Cooperation propensity calculation based on observed behavior
    - Defection triggers for predatory exploitation, cascade failure, and selective punishment
    - Default cooperation to enable collective value creation
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        if t == 0:
            return Action.C
        if self._is_predatory_exploitation(history, t):
            return Action.D
        if self._is_cascade_failure(history, t):
            return Action.D
        if self._is_selective_punishment(history, t):
            return Action.D
        cp = self._calculate_cooperation_propensity(history, t)
        if self.k / self.n > 0.85:
            cp = min(1.0, cp + 0.1)
        if cp >= 0.5 or t <= 2:
            return Action.C
        else:
            return Action.D

    def _is_predatory_exploitation(self, history: PlayerHistory, t: int) -> bool:
        """
        Detect if more than half the players are free-riding (defected while others cooperated).
        """
        if t < 1:
            return False
        last_round_idx = t - 1
        my_action_last = history.my_actions[last_round_idx]
        opponent_actions_last = history.opponent_actions[last_round_idx, :]
        total_cooperators = int(my_action_last) + np.sum(opponent_actions_last)
        defectors = np.sum(~opponent_actions_last)
        if self.n > 20:
            threshold = (2 * self.n - 1) / (3 * self.n)
            defection_ratio = defectors / (self.n - 1)
        else:
            threshold = 0.5
            defection_ratio = defectors / (self.n - 1)
        return defection_ratio > threshold and total_cooperators > 0

    def _is_cascade_failure(self, history: PlayerHistory, t: int) -> bool:
        """
        Detect if cooperation dropped below 30% in the last 3 rounds.
        """
        if t < 3:
            return False
        last_3_rounds = history.opponent_actions[max(0, t - 3):t, :]
        if len(last_3_rounds) == 0:
            return False
        total_actions = last_3_rounds.size
        total_cooperators = np.sum(last_3_rounds)
        cooperation_rate = total_cooperators / total_actions if total_actions > 0 else 0
        return cooperation_rate < 0.3

    def _is_selective_punishment(self, history: PlayerHistory, t: int) -> bool:
        """
        Defect if: you cooperated last round AND your payoff was worse than average
        AND average defector payoff > average cooperator payoff.
        """
        if t < 1:
            return False
        last_round_idx = t - 1
        my_action_last = history.my_actions[last_round_idx]
        my_payoff_last = history.my_payoffs[last_round_idx]
        if not my_action_last:
            return False
        average_payoff = np.mean(history.my_payoffs[:t])
        if my_payoff_last >= average_payoff:
            return False
        opponent_actions_last = history.opponent_actions[last_round_idx, :]
        opponent_payoffs_last = history.opponent_payoffs[last_round_idx, :]
        defector_mask = ~opponent_actions_last
        cooperator_mask = opponent_actions_last
        if np.sum(defector_mask) == 0 or np.sum(cooperator_mask) == 0:
            return False
        avg_defector_payoff = np.mean(opponent_payoffs_last[defector_mask])
        avg_cooperator_payoff = np.mean(opponent_payoffs_last[cooperator_mask])
        return avg_defector_payoff > avg_cooperator_payoff

    def _calculate_cooperation_propensity(self, history: PlayerHistory, t: int) -> float:
        """
        Calculate Cooperation Propensity (CP) based on:
        - Historical cooperator ratio ( = 0.6)
        - Round position bonus ( = 0.4)
        """
        if t == 0:
            return 0.5
        my_cooperations = np.sum(history.my_actions[:t])
        opponent_cooperations = np.sum(history.opponent_actions[:t, :])
        total_cooperators = my_cooperations + opponent_cooperations
        total_actions = t * self.n
        historical_cooperator_ratio = total_cooperators / total_actions if total_actions > 0 else 0.5
        round_position_bonus = t / self.r
        alpha = 0.6
        beta = 0.4
        cp = alpha * historical_cooperator_ratio + beta * round_position_bonus
        return min(1.0, max(0.0, cp))

class Strategy_COLLECTIVE_91(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for N-Player Public Goods Game.

    Balances collective welfare with individual security by:
    1. Initiating cooperation in round 1
    2. Monitoring cooperation rates against dynamic thresholds
    3. Adapting thresholds across game phases (early/mid/late)
    4. Implementing recovery mechanisms for defection lock-in
    5. Special handling for last round based on cooperation momentum
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.pessimism_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        all_actions_prev_round = np.concatenate([[history.my_actions[-1]], history.opponent_actions[-1, :]])
        total_cooperators = np.sum(all_actions_prev_round)
        cooperation_rate = total_cooperators / n
        elapsed_ratio = current_round / r
        if elapsed_ratio < 0.3:
            threshold = 0.5
        elif elapsed_ratio < 0.7:
            threshold = max(0.4, k / n + 0.1)
        else:
            threshold = k / n
        if current_round == r - 1:
            if cooperation_rate >= 0.8:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= threshold:
            self.pessimism_counter = 0
            return Action.C
        else:
            self.pessimism_counter += 1
            if self.pessimism_counter > 3 and current_round < r - 1:
                if random.random() < 0.25:
                    return Action.C
            return Action.D

class Strategy_COLLECTIVE_92(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game

    Balances collective welfare maximization with robust self-protection against exploitation.
    - Round 1: Cooperate (bootstrap)
    - Rounds 2 to r-1: Cooperate if moving average cooperation rate >= (1/k + 0.05), else defect
    - Round r: Match round r-1 decision logic
    - Includes edge case handling for defection cascades, oscillation, and recovery
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = 1.0 / self.k + 0.05
        self.epsilon = 0.05
        self.permanent_defect = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if self.permanent_defect:
            return Action.D
        last_round_idx = current_round - 1
        total_cooperators_last = sum(history.opponent_actions[last_round_idx, :]) + int(history.my_actions[last_round_idx])
        coop_rate_last = total_cooperators_last / self.n
        if current_round >= 3:
            coop_rates_recent = []
            for i in range(max(0, current_round - 3), current_round):
                total_coop = sum(history.opponent_actions[i, :]) + int(history.my_actions[i])
                coop_rates_recent.append(total_coop / self.n)
            avg_coop_rate = np.mean(coop_rates_recent)
        else:
            avg_coop_rate = coop_rate_last
        if current_round > 2 and coop_rate_last < 0.01:
            defect_count = 0
            for i in range(max(0, current_round - 2), current_round):
                total_coop = sum(history.opponent_actions[i, :]) + int(history.my_actions[i])
                if total_coop / self.n < 0.01:
                    defect_count += 1
            if defect_count >= 2:
                self.permanent_defect = True
                return Action.D
        if current_round == self.r - 1:
            if avg_coop_rate >= self.threshold:
                return Action.C
            else:
                return Action.D
        if avg_coop_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_93(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Core logic:
    - Round 1: Always cooperate to initiate mutual benefit
    - Subsequent rounds: Cooperate if observed cooperation rate >= k/n threshold,
      otherwise defect to protect against exploitation

    The threshold k/n represents the critical point where cooperation becomes
    individually rational given the public good multiplier.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.threshold = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round_index = state.round_number - 1
        last_round_opponent_actions = history.opponent_actions[last_round_index, :]
        opponent_cooperators = np.sum(last_round_opponent_actions)
        my_last_action = history.my_actions[last_round_index]
        total_cooperators = opponent_cooperators + (1 if my_last_action else 0)
        cooperation_rate = total_cooperators / self.n
        if cooperation_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_94(BaseStrategy):
    """
    Adaptive Conditional Cooperation with Threshold Dynamics.

    A collective strategy that balances cooperation with robustness to exploitation.
    - Round 1: Cooperate to signal good faith
    - Rounds 2 to r-1: Cooperate if cooperation rate meets threshold, defect if abandoned
    - Final round: Cooperate if average cooperation was strong, else defect

    Threshold = k/n + 0.15 (break-even plus buffer)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        threshold = self.k / self.n_players + 0.15
        if current_round == self.n_rounds - 1:
            avg_coop_rate = self._calculate_average_cooperation_rate(history, current_round)
            final_threshold = self.k / self.n_players + 0.1
            if avg_coop_rate >= final_threshold:
                return Action.C
            else:
                return Action.D
        else:
            coop_rate = self._calculate_cooperation_rate(history, current_round - 1)
            if coop_rate >= threshold:
                return Action.C
            elif coop_rate > 0:
                return Action.C
            else:
                return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_idx: int) -> float:
        """
        Calculate the cooperation rate in a specific round.
        Returns the fraction of opponents who cooperated (True = cooperated).
        """
        if round_idx < 0 or round_idx >= history.opponent_actions.shape[0]:
            return 0.0
        cooperators_in_round = np.sum(history.opponent_actions[round_idx, :])
        coop_rate = cooperators_in_round / self.n_players
        return float(coop_rate)

    def _calculate_average_cooperation_rate(self, history: PlayerHistory, up_to_round: int) -> float:
        """
        Calculate the average cooperation rate across all rounds up to (but not including) up_to_round.
        """
        if up_to_round <= 0:
            return 0.0
        total_cooperators = 0
        total_rounds = up_to_round
        for round_idx in range(up_to_round):
            cooperators_in_round = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += cooperators_in_round
        avg_coop_rate = total_cooperators / (total_rounds * self.n_players)
        return float(avg_coop_rate)

class Strategy_COLLECTIVE_95(BaseStrategy):
    """
    Conditional Reciprocal Threshold (CRT) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare through:
    1. Seeding cooperation in round 1 to discover game conditions
    2. Reciprocating observed cooperation in intermediate rounds
    3. Punishing defection when cooperation rate falls too low
    4. Extracting final reward in the last round if cooperation failed

    Uses a dynamic threshold based on the multiplication factor k to determine
    when cooperation is collectively rational.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = min(0.5 + 1.0 / self.k, 0.9)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        cooperators_prev_round = sum(history.opponent_actions[prev_round_idx, :])
        cooperation_rate = cooperators_prev_round / self.n
        if current_round == self.r - 1:
            if cooperation_rate >= self.threshold:
                return Action.C
            else:
                return Action.D
        elif cooperation_rate >= self.threshold:
            return Action.C
        elif cooperation_rate < self.threshold / 2.0:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_96(BaseStrategy):
    """
    Adaptive Reciprocity with Defection Threshold (ARDT) Strategy.

    Pursues collective value maximization while maintaining individual security against exploitation.
    Uses dynamic cooperation thresholds based on game phase, observed opponent cooperation rates,
    and special handling for edge cases like defection cascades and two-player games.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        observed_coop_rate = self._calculate_observed_coop_rate(history, round_num)
        is_last_round = round_num == self.n_rounds - 1
        threshold = self._get_cooperation_threshold(round_num, observed_coop_rate)
        if is_last_round:
            if observed_coop_rate >= 0.55:
                return Action.C
            else:
                return Action.D
        if observed_coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_observed_coop_rate(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate the observed cooperation rate of opponents across all previous rounds.
        """
        if round_num == 0:
            return 0.0
        total_cooperations = np.sum(history.opponent_actions[:round_num, :])
        total_possible = (self.n_players - 1) * round_num
        if total_possible == 0:
            return 0.0
        return float(total_cooperations) / float(total_possible)

    def _get_cooperation_threshold(self, round_num: int, observed_coop_rate: float) -> float:
        """
        Determine dynamic cooperation threshold based on game phase and observed behavior.
        """
        if self.n_rounds <= 3:
            if round_num == 1:
                return 0.5
            else:
                return 0.5
        if self.n_players == 2:
            return 0.7
        k_ratio = self.k / self.n_players
        phase_threshold = self._get_phase_threshold(round_num)
        if k_ratio >= 0.8:
            phase_threshold = max(0.1, phase_threshold - 0.1)
        elif k_ratio <= 0.3:
            phase_threshold = min(0.9, phase_threshold + 0.1)
        if observed_coop_rate < 0.2:
            return 0.3
        return phase_threshold

    def _get_phase_threshold(self, round_num: int) -> float:
        """
        Get base threshold based on game phase (early, middle, late).
        """
        halfway = self.n_rounds / 2.0
        if round_num <= halfway:
            return 0.4
        else:
            progress = (round_num - halfway) / (self.n_rounds - halfway)
            threshold = 0.5 + 0.1 * progress
            return min(0.6, threshold)

class Strategy_COLLECTIVE_97(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game.

    Balances collective value creation, self-protection, and adaptive learning by:
    1. Cooperating in round 1 to signal cooperative intent
    2. Using an adaptive threshold based on observed cooperation rates
    3. Protecting against exploitation with anti-exploitation buffers
    4. Gradually relaxing thresholds over time to encourage cooperation emergence
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.defection_lock_rounds = 0
        self.defection_lock_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        n = self.game_description.n_players
        k = self.game_description.k
        if round_num == 0:
            return Action.C
        if self.defection_lock_counter > 0:
            self.defection_lock_counter -= 1
            return Action.D
        last_round_cooperators = int(sum(history.opponent_actions[round_num - 1, :]))
        coop_rate_last = last_round_cooperators / n
        start_idx = max(0, round_num - 3)
        rolling_coop_rates = []
        for i in range(start_idx, round_num):
            round_cooperators = int(sum(history.opponent_actions[i, :]))
            rolling_coop_rates.append(round_cooperators / n)
        rolling_avg = np.mean(rolling_coop_rates) if rolling_coop_rates else coop_rate_last
        base_threshold = k / n
        aggressive_threshold = (k - 1) / (n - 1) if n > 1 else 0
        decay_rate = -0.02
        current_threshold = base_threshold + (round_num - 1) * decay_rate
        current_threshold = max(aggressive_threshold, min(base_threshold, current_threshold))
        exploitation_threshold = k / (2 * n)
        if rolling_avg < exploitation_threshold:
            self.defection_lock_counter = min(3, self.r - round_num)
            return Action.D
        if round_num == self.r - 1:
            if rolling_avg >= current_threshold:
                return Action.C
            else:
                return Action.D
        if rolling_avg >= current_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_98(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with rational self-protection through
    proportional contribution based on observed cooperation rates. Cooperates in round 1,
    then adapts decisions based on break-even threshold comparing expected payoffs.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        n_rounds_played = state.round_number
        opponent_cooperations = np.sum(history.opponent_actions[:n_rounds_played, :], axis=1)
        avg_cooperators_observed = np.mean(opponent_cooperations)
        cooperation_rate = avg_cooperators_observed / (self.n - 1)
        threshold = (self.n - self.k) / (self.n - 1)
        epsilon = 0.15
        if cooperation_rate >= threshold:
            return Action.C
        elif cooperation_rate <= threshold - epsilon:
            return Action.D
        else:
            prob_cooperate = cooperation_rate / threshold
            if random.random() < prob_cooperate:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_99(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with robustness against exploitation
    through adaptive threshold-based cooperation decisions. Cooperates when the
    observed cooperation rate justifies it (breakeven point: n/(2k)), and defects
    when cooperation is systematically unrewarded.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.smoothed_coop_rate = 0.5
        self.defection_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        last_round_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        if history.my_actions[current_round - 1]:
            last_round_cooperators += 1
        cooperation_rate = last_round_cooperators / n
        if r > 20:
            self.smoothed_coop_rate = 0.7 * cooperation_rate + 0.3 * self.smoothed_coop_rate
        else:
            self.smoothed_coop_rate = cooperation_rate
        threshold = n / (2 * k)
        if n <= 3:
            threshold = threshold * 0.8
        if current_round == r - 1:
            if self.smoothed_coop_rate > threshold:
                return Action.C
            else:
                return Action.D
        if self.smoothed_coop_rate > threshold:
            self.defection_streak = 0
            return Action.C
        elif self.smoothed_coop_rate < threshold:
            self.defection_streak += 1
            return Action.D
        elif random.random() > 0.4:
            self.defection_streak = 0
            return Action.C
        else:
            self.defection_streak += 1
            return Action.D

class Strategy_COLLECTIVE_100(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with robust defense against exploitation.
    Uses optimistic reciprocity with graduated punishment based on observed cooperation rates.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.threshold_high = 0.6 if self.n_players == 2 else 0.5
        self.threshold_mid = 0.25
        self.last_low_cooperation_round = -10

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        if history.my_actions[current_round - 1]:
            prev_cooperators += 1
        cooperation_rate = prev_cooperators / self.n_players
        if current_round > 1:
            two_rounds_ago_cooperators = int(sum(history.opponent_actions[current_round - 2, :]))
            if history.my_actions[current_round - 2]:
                two_rounds_ago_cooperators += 1
            rate_two_rounds_ago = two_rounds_ago_cooperators / self.n_players
            if rate_two_rounds_ago < self.threshold_mid and cooperation_rate >= self.threshold_high:
                self.last_low_cooperation_round = current_round - 1
                return Action.D
        if current_round == self.n_rounds - 1:
            if cooperation_rate >= self.threshold_high:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= self.threshold_high:
            return Action.C
        elif cooperation_rate >= self.threshold_mid:
            if random.random() < cooperation_rate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_101(BaseStrategy):
    """
    Adaptive Graduated Reciprocity (AGR) Strategy for N-Player Public Goods Game

    Embodies collective welfare maximization through:
    - Unconditional cooperation in round 1 to establish baseline
    - Graduated response based on cooperation rates vs. k/n threshold
    - Punishment of exploitation through defection when net gain is substantial
    - Recovery mechanisms to restore cooperation
    - Final round solidarity or defection based on cooperation history
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_cooperators = sum(history.opponent_actions[round_num - 1, :])
        cooperation_rate = prev_round_cooperators / self.n_players
        threshold = self.k / self.n_players
        if round_num == self.n_rounds - 1:
            if round_num >= 2:
                recent_coop_rates = []
                for r in range(max(0, round_num - 2), round_num):
                    coop_count = sum(history.opponent_actions[r, :])
                    recent_coop_rates.append(coop_count / self.n_players)
                avg_recent_coop = sum(recent_coop_rates) / len(recent_coop_rates)
                if avg_recent_coop >= 0.7 * threshold:
                    return Action.C
            return Action.D
        if cooperation_rate >= threshold:
            return Action.C
        my_cooperation_payoff = self.k / self.n_players * cooperation_rate * self.n_players
        my_defection_payoff = 1 + self.k / self.n_players * cooperation_rate * self.n_players
        net_defection_advantage = my_defection_payoff - my_cooperation_payoff
        defections_last_round = self.n_players - prev_round_cooperators
        if defections_last_round > self.n_players / 3:
            if round_num >= 2:
                cooperation_trend = []
                for r in range(max(0, round_num - 3), round_num):
                    coop_count = sum(history.opponent_actions[r, :])
                    cooperation_trend.append(coop_count / self.n_players)
                trend_declining = len(cooperation_trend) > 1 and cooperation_trend[-1] < cooperation_trend[0]
                if trend_declining:
                    prob_cooperate = 0.4
                else:
                    prob_cooperate = 0.6
                return Action.C if random.random() < prob_cooperate else Action.D
            else:
                return Action.C
        if cooperation_rate >= 0.5 * threshold:
            return Action.C
        if net_defection_advantage > 0.3:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_102(BaseStrategy):
    """
    Adaptive Conditional Contribution (ACC) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare through:
    - Reciprocity: matching cooperative behavior proportionally
    - Resilience: minimizing losses from exploitation
    - Optimism: gradual cooperation attempts to discover reciprocal partners
    - Pragmatism: accepting some opponents will defect regardless
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold_lower = self.k / self.n
        self.threshold_adaptive = (self.k - 1) / (2 * self.n)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        prev_round_idx = round_number - 1
        prev_cooperators = int(sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            prev_cooperators += 1
        prev_coop_rate = prev_cooperators / self.n
        if prev_coop_rate >= self.threshold_lower:
            return Action.C
        elif prev_coop_rate >= self.threshold_adaptive:
            if round_number >= 2:
                prev_prev_round_idx = round_number - 2
                prev_prev_cooperators = int(sum(history.opponent_actions[prev_prev_round_idx, :]))
                if history.my_actions[prev_prev_round_idx]:
                    prev_prev_cooperators += 1
                trend = prev_cooperators - prev_prev_cooperators
                if trend >= 0:
                    return Action.C
                else:
                    return Action.C if random.random() < 0.6 else Action.D
            else:
                return Action.C if random.random() < 0.6 else Action.D
        elif round_number > 2 and prev_cooperators == 0:
            return Action.C if random.random() < 0.2 else Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_103(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances individual rational self-interest with collective welfare through:
    - Leading with cooperation in round 1
    - Using threshold-based reciprocity (break-even at k/n)
    - Momentum detection for trend-based decisions
    - Late-game adjustments to maintain cooperation
    - Recovery mechanisms from defection spirals
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round_idx = state.round_number - 1
        my_prev_action = history.my_actions[prev_round_idx]
        opponent_prev_actions = history.opponent_actions[prev_round_idx, :]
        cooperators_count = int(my_prev_action) + int(np.sum(opponent_prev_actions))
        prev_coop_rate = cooperators_count / self.n_players
        momentum = prev_coop_rate - self.threshold
        rounds_remaining = self.n_rounds - state.round_number
        is_final_rounds = rounds_remaining <= 2
        if is_final_rounds:
            if prev_coop_rate >= 0.7:
                return Action.C
            elif random.random() < 0.7:
                return Action.C
            else:
                return Action.D
        if abs(momentum) > 0.15:
            if momentum > 0:
                return Action.C
            else:
                return Action.D
        elif prev_coop_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_104(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with individual resilience against free-riders.
    - Round 1: Cooperate (optimistic baseline)
    - Rounds 2 to r-1: Reciprocate based on cooperation rate, with adaptive thresholds
    - Round r: Defect unless sustained high cooperation observed
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.cooperation_history = []
        self.early_defection_triggered = False
        self.recovery_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_cooperators = sum(history.opponent_actions[round_num - 1, :])
        prev_coop_rate = prev_cooperators / self.n
        self.cooperation_history.append(prev_coop_rate)
        if round_num == self.r - 1:
            return self._final_round_decision()
        return self._adaptive_reciprocation(round_num, prev_coop_rate)

    def _final_round_decision(self) -> Action:
        """Decide action in final round with mercy clause for sustained cooperation."""
        if len(self.cooperation_history) < 2:
            return Action.D
        avg_cooperation = np.mean(self.cooperation_history)
        if avg_cooperation >= 0.8:
            return Action.C
        return Action.D

    def _adaptive_reciprocation(self, round_num: int, prev_coop_rate: float) -> Action:
        """Apply adaptive reciprocation logic for intermediate rounds."""
        if round_num < self.r / 2:
            defection_rate = 1.0 - prev_coop_rate
            if defection_rate > 0.3:
                self.early_defection_triggered = True
        if self.early_defection_triggered:
            recent_coop_avg = np.mean(self.cooperation_history[-2:]) if len(self.cooperation_history) >= 2 else prev_coop_rate
            if recent_coop_avg >= 0.7:
                self.recovery_counter += 1
                if self.recovery_counter >= 2:
                    self.early_defection_triggered = False
                    self.recovery_counter = 0
            else:
                self.recovery_counter = 0
        if self.early_defection_triggered:
            threshold = (self.n - 2) / self.n
        else:
            threshold = (self.n - 1) / self.n
        if len(self.cooperation_history) >= 2:
            recent_variance = abs(self.cooperation_history[-1] - self.cooperation_history[-2])
            if recent_variance > 0.5:
                if len(self.cooperation_history) >= 3:
                    moving_avg = np.mean(self.cooperation_history[-3:])
                else:
                    moving_avg = np.mean(self.cooperation_history)
                if moving_avg >= threshold:
                    return Action.C
                else:
                    return Action.D
        if prev_coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_105(BaseStrategy):
    """
    Adaptive Threshold Cooperation with Conditional Defection (ATCCD)

    A collective strategy that maximizes mutual welfare while remaining robust against exploitation.
    Cooperates in round 1 to establish good faith, adapts based on observed cooperation rates
    relative to a dynamic threshold, and defects in the final round to maximize terminal payoff.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (1 + self.k / self.n) / 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            return Action.D
        last_round_opponent_actions = history.opponent_actions[current_round - 1, :]
        opponent_cooperators = np.sum(last_round_opponent_actions)
        my_last_action = history.my_actions[current_round - 1]
        total_cooperators = opponent_cooperators + int(my_last_action)
        cooperation_rate = total_cooperators / self.n
        if cooperation_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_106(BaseStrategy):
    """
    Adaptive Threshold Reciprocity (ATR): A strategy that balances collective welfare
    maximization with individual rationality through dynamic threshold-based reciprocity.

    Core logic:
    - Round 1: Cooperate (optimistic start to gather information)
    - Rounds 2 to r-1: Cooperate if opponent cooperation rate  0.8  (k/n), else defect
    - Round r: Cooperate if opponent cooperation rate  k/n, else defect
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        threshold = self.k / self.n
        opponent_cooperators_last_round = sum(history.opponent_actions[-1, :])
        avg_cooperation = opponent_cooperators_last_round / (self.n - 1)
        if round_num == self.r - 1:
            if avg_cooperation >= threshold:
                return Action.C
            else:
                return Action.D
        else:
            relaxed_threshold = threshold * 0.8
            if avg_cooperation >= relaxed_threshold:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_107(BaseStrategy):
    """
    Adaptive Conditional Contribution (ACC) Strategy for N-Player Public Goods Game.

    Uses a cooperation threshold mechanism that scales with demonstrated group commitment.
    Cooperates in round 1 to establish reciprocity, then matches group cooperation rates
    against a declining threshold. Handles edge cases: all-defection traps, sole cooperator,
    and last-round coordination.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_actions = history.opponent_actions[round_num - 1, :]
        prev_cooperators = int(np.sum(prev_round_actions))
        my_prev_action = history.my_actions[round_num - 1]
        total_cooperators = prev_cooperators + int(my_prev_action)
        cooperation_rate = total_cooperators / self.n
        self.cooperation_history.append(cooperation_rate)
        if len(self.cooperation_history) >= 2:
            if self.cooperation_history[-1] == 0 and self.cooperation_history[-2] == 0:
                return Action.D
        if cooperation_rate == 1 / self.n:
            return Action.D
        threshold = max(0.5, 1.0 - round_num / self.r * 0.3)
        if round_num == self.r - 1:
            if cooperation_rate >= threshold:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_108(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with robustness to exploitation through:
    1. First-round cooperation to establish cooperative intent
    2. Adaptive threshold-based reciprocation in subsequent rounds
    3. Graceful degradation as cooperation diminishes over time

    The threshold function transitions from k/n (early rounds) to 1.0 (late rounds),
    reflecting realistic expectations about achieving universal cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        cooperators_last_round = sum(history.my_actions[round_number - 1:round_number]) + sum(history.opponent_actions[round_number - 1, :])
        cooperation_rate = cooperators_last_round / self.n
        actual_round = round_number + 1
        threshold = self.k / self.n + (1.0 - self.k / self.n) * (actual_round / self.r)
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_109(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game

    Balances individual rationality with collective welfare through:
    1. Seeding cooperation in round 1
    2. Reciprocating proportionally based on observed cooperation rates
    3. Defending against exploitation via defection thresholds
    4. Defecting in final round (backward induction)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.cooperation_threshold = (1 + self.k) / (2 * self.k)
        self.minimum_viable_rate = 1 / self.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.n_rounds - 1:
            return Action.D
        previous_round_idx = round_number - 1
        opponent_actions_prev = history.opponent_actions[previous_round_idx, :]
        my_action_prev = history.my_actions[previous_round_idx]
        total_cooperators = int(my_action_prev) + int(np.sum(opponent_actions_prev))
        observed_cooperation_rate = total_cooperators / self.n_players
        if observed_cooperation_rate >= self.cooperation_threshold:
            return Action.C
        elif observed_cooperation_rate > self.minimum_viable_rate:
            probability = min(1.0, observed_cooperation_rate / self.cooperation_threshold)
            if random.random() < probability:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_110(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with individual sustainability through
    history-dependent adaptation. Cooperates when observed cooperation rate meets or
    exceeds the breakeven threshold (k/n), otherwise defects.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        past_rounds = state.round_number
        total_cooperators = 0
        total_cooperators += int(np.sum(history.my_actions[:past_rounds]))
        total_cooperators += int(np.sum(history.opponent_actions[:past_rounds, :]))
        total_agents = self.n * past_rounds
        observed_rate = total_cooperators / total_agents if total_agents > 0 else 0.0
        if observed_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_111(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy

    Balances collective welfare maximization, robustness to exploitation, and adaptive efficiency
    by responding to aggregate cooperation rates rather than individual reciprocation.
    Employs threshold-based decision making with probabilistic contributions in gray zones.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        prev_round_cooperators = sum(history.opponent_actions[round_number - 1, :])
        my_prev_action = history.my_actions[round_number - 1]
        total_cooperators = prev_round_cooperators + (1 if my_prev_action else 0)
        coop_rate = total_cooperators / self.n_players
        endgame_threshold = self.n_rounds - 3
        is_endgame = round_number >= endgame_threshold
        if not is_endgame:
            if coop_rate >= 0.5:
                return Action.C
            elif coop_rate >= 0.33:
                prob = 2 * coop_rate
                return Action.C if random.random() < prob else Action.D
            else:
                return Action.D
        elif coop_rate >= 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_112(BaseStrategy):
    """
    Adaptive Contribution Threshold (ACT) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare by cooperating when the
    expected return from the public good exceeds half the endowment, while adapting
    dynamically based on observed cooperation levels.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        t_crit = math.ceil(0.5 * self.n / self.k)
        if self.k / self.n < 0.5:
            return Action.D
        if round_number == 0:
            expected_cooperators = self.n * 0.5
        else:
            prev_cooperators = sum(history.opponent_actions[round_number - 1, :])
            if history.my_actions[round_number - 1]:
                prev_cooperators += 1
            p_prev = prev_cooperators / self.n
            p_baseline = 0.5
            p_expected = 0.9 * p_prev + 0.1 * p_baseline
            expected_cooperators = p_expected * self.n
        expected_return = expected_cooperators / self.n * self.k
        if expected_return > 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_113(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Optimizes for collective welfare through three phases:
    1. Generous probe: establish cooperative intent
    2. Adaptive reciprocity: match group cooperation with hysteresis buffer
    3. Stabilization: lock in equilibrium
    4. Final round protection: defect if group defection-prone, cooperate otherwise
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.phase_boundary_1 = math.floor(self.r / 3)
        self.phase_boundary_2 = math.floor(2 * self.r / 3)
        self.last_phase_2_decision = Action.C
        self.phase_2_coop_rate = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num < self.phase_boundary_1:
            return Action.C
        if round_num == self.r - 1:
            return self._final_round_decision(history)
        if round_num < self.phase_boundary_2:
            decision = self._phase_2_decision(history)
            self.last_phase_2_decision = decision
            self.phase_2_coop_rate = self._calculate_cooperation_rate(history)
            return decision
        return self._phase_3_decision(history)

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate group average cooperation rate across all completed rounds."""
        if history is None or len(history.my_actions) == 0:
            return 0.0
        rounds_completed = len(history.my_actions)
        my_contribution = float(np.sum(history.my_actions))
        opponent_contributions = float(np.sum(history.opponent_actions))
        total_contributions = my_contribution + opponent_contributions
        total_possible = self.n * rounds_completed
        return total_contributions / total_possible if total_possible > 0 else 0.0

    def _count_consecutive_defections(self, history: PlayerHistory, count: int=2) -> int:
        """Count recent consecutive defections by this player."""
        if history is None or len(history.my_actions) == 0:
            return 0
        consecutive = 0
        for i in range(len(history.my_actions) - 1, -1, -1):
            if not history.my_actions[i]:
                consecutive += 1
                if consecutive >= count:
                    return consecutive
            else:
                break
        return consecutive

    def _phase_2_decision(self, history: PlayerHistory) -> Action:
        """Phase 2: Adaptive Reciprocity decision."""
        cooperation_rate = self._calculate_cooperation_rate(history)
        threshold = self.k / self.n
        consecutive_defections = self._count_consecutive_defections(history, count=2)
        if cooperation_rate >= threshold + 0.15:
            return Action.C
        elif cooperation_rate >= threshold:
            return Action.C
        elif cooperation_rate >= threshold - 0.15:
            if consecutive_defections >= 2:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _phase_3_decision(self, history: PlayerHistory) -> Action:
        """Phase 3: Stabilization - maintain phase 2 decision with drop-out exception."""
        current_cooperation_rate = self._calculate_cooperation_rate(history)
        if self.phase_2_coop_rate - current_cooperation_rate > 0.2:
            return self._phase_2_decision(history)
        return self.last_phase_2_decision

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """Phase 4: Final Round Protection."""
        if history is None or len(history.my_actions) == 0:
            return Action.C
        rounds_completed = len(history.my_actions)
        if rounds_completed == 1:
            cooperation_rate = self._calculate_cooperation_rate(history)
        else:
            my_contribution = float(np.sum(history.my_actions[:-1]))
            opponent_contributions = float(np.sum(history.opponent_actions[:-1, :]))
            total_contributions = my_contribution + opponent_contributions
            total_possible = self.n * (rounds_completed - 1)
            cooperation_rate = total_contributions / total_possible if total_possible > 0 else 0.0
        if cooperation_rate > 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_114(BaseStrategy):
    """
    Adaptive Threshold Cooperation with Decay Strategy for N-Player Public Goods Game.

    This strategy embodies collective rationality by establishing and maintaining cooperation
    through graduated responses. It uses an adaptive threshold (k/n) to determine cooperation,
    with probabilistic warnings in a tolerance band and special handling for final rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n
        self.consecutive_low_cooperation_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        cooperators_prev_round = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        cooperation_rate = cooperators_prev_round / self.n
        if current_round == self.r - 1:
            if cooperation_rate >= self.threshold:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= self.threshold:
            self.consecutive_low_cooperation_count = 0
            return Action.C
        elif cooperation_rate >= self.threshold * 0.6:
            self.consecutive_low_cooperation_count = 0
            if random.random() < 0.5:
                return Action.C
            else:
                return Action.D
        else:
            low_cooperation_threshold = self.threshold * 0.3
            if current_round >= 2:
                prev_prev_round_idx = current_round - 2
                cooperators_prev_prev = int(np.sum(history.opponent_actions[prev_prev_round_idx, :]))
                cooperation_rate_prev_prev = cooperators_prev_prev / self.n
                if cooperation_rate < low_cooperation_threshold and cooperation_rate_prev_prev < low_cooperation_threshold:
                    self.consecutive_low_cooperation_count += 1
                else:
                    self.consecutive_low_cooperation_count = 0
            else:
                self.consecutive_low_cooperation_count = 1
            return Action.D

class Strategy_COLLECTIVE_115(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game

    Balances collective welfare with individual security through:
    1. Rewarding cooperation to build mutual trust
    2. Punishing defection to deter free-riding
    3. Adapting dynamically to opponent behavior patterns
    4. Maintaining robustness against exploitation

    Core decision rule: Cooperate if cooperation rate in previous round meets
    or exceeds a threshold that represents the breakeven point for collective benefit.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.k - 1) / (self.k * self.n_players)
        self.high_coop_rounds = 0
        self.total_rounds_tracked = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        if current_round == self.n_rounds - 1:
            if self.n_rounds <= 3:
                cooperation_rate = self._get_cooperation_rate(history, current_round - 1)
                return self._decide_by_threshold(cooperation_rate)
            else:
                return Action.D
        cooperation_rate = self._get_cooperation_rate(history, current_round - 1)
        self._update_consistency(cooperation_rate)
        return self._decide_adaptive(cooperation_rate)

    def _get_cooperation_rate(self, history: PlayerHistory, round_idx: int) -> float:
        """
        Calculate the cooperation rate in a given round.
        Returns the proportion of players (including self) who cooperated.
        """
        if round_idx < 0 or round_idx >= len(history.opponent_actions):
            return 0.0
        opponent_cooperators = int(sum(history.opponent_actions[round_idx, :]))
        my_cooperation = int(history.my_actions[round_idx])
        total_cooperators = opponent_cooperators + my_cooperation
        cooperation_rate = total_cooperators / self.n_players
        return cooperation_rate

    def _update_consistency(self, cooperation_rate: float) -> None:
        """Track consistency of cooperation over time."""
        self.total_rounds_tracked += 1
        if cooperation_rate >= self.threshold:
            self.high_coop_rounds += 1

    def _decide_by_threshold(self, cooperation_rate: float) -> Action:
        """Apply basic threshold decision rule."""
        if cooperation_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

    def _decide_adaptive(self, cooperation_rate: float) -> Action:
        """
        Apply adaptive confidence metric to adjust strategy based on
        coalition consistency.
        """
        if self.total_rounds_tracked == 0:
            return self._decide_by_threshold(cooperation_rate)
        consistency = self.high_coop_rounds / self.total_rounds_tracked
        if consistency >= 0.7:
            return self._decide_by_threshold(cooperation_rate)
        elif consistency <= 0.3:
            adjusted_threshold = min(0.9, self.threshold + 0.15)
            if cooperation_rate >= adjusted_threshold:
                return Action.C
            else:
                return Action.D
        else:
            return self._decide_by_threshold(cooperation_rate)

class Strategy_COLLECTIVE_116(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game

    Balances individual incentive, collective welfare, trust, and exploitation concerns
    through adaptive reciprocity with dampening and phase-based decision rules.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        previous_round_actions = history.opponent_actions[round_t - 1, :]
        opponent_cooperators = np.sum(previous_round_actions)
        my_previous_action = history.my_actions[round_t - 1]
        total_cooperators_prev = opponent_cooperators + (1 if my_previous_action else 0)
        cr = total_cooperators_prev / self.n
        ph = 1 if my_previous_action else 0
        if round_t == self.r - 1:
            if self.r > 2 and cr >= 0.5:
                return Action.C
            else:
                return Action.D
        threshold = cr * (self.k / self.n)
        if cr >= (self.n - 1) / self.n:
            return Action.C
        if cr > 1 / self.n and threshold > 0.5:
            if round_t > 1:
                prev_previous_actions = history.opponent_actions[round_t - 2, :]
                prev_opponent_cooperators = np.sum(prev_previous_actions)
                prev_my_action = history.my_actions[round_t - 2]
                prev_total_cooperators = prev_opponent_cooperators + (1 if prev_my_action else 0)
                previous_cr = prev_total_cooperators / self.n
            else:
                previous_cr = 1.0
            if ph == 1 and cr < previous_cr:
                return Action.D
            elif ph == 1 and cr >= previous_cr:
                return Action.C
            else:
                return Action.C
        if cr <= 1 / self.n:
            return Action.D
        return Action.C

class Strategy_COLLECTIVE_117(BaseStrategy):
    """
    Adaptive Reciprocal Stewardship (ARS) Strategy for N-Player Public Goods Game

    Core logic:
    - Round 0: Unconditionally cooperate to signal reciprocity
    - Rounds 1 to r-2: Cooperate if previous round's cooperation rate >= k/n threshold, else defect
    - Round r-1 (final): Cooperate only if previous cooperation rate >= k/n, else defect

    The strategy treats cooperation as rational when the public good return exceeds
    the private benefit, using k/n as the break-even threshold.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        previous_round_idx = round_number - 1
        my_previous_action = history.my_actions[previous_round_idx]
        opponent_previous_actions = history.opponent_actions[previous_round_idx, :]
        total_cooperators = int(my_previous_action) + int(np.sum(opponent_previous_actions))
        cooperation_rate = total_cooperators / self.n_players
        if round_number == self.n_rounds - 1:
            if cooperation_rate >= self.threshold:
                return Action.C
            else:
                return Action.D
        elif cooperation_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_118(BaseStrategy):
    """
    Adaptive Contribution with Tolerance Thresholds Strategy.

    Balances collective welfare maximization with robust self-protection against defectors.
    Adapts contribution decisions based on historical cooperation rates, with different
    thresholds for sustaining cooperation, engaging in recovery, and handling final rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        total_cooperators = sum((np.sum(history.opponent_actions[t, :]) for t in range(round_num)))
        total_cooperators += sum(history.my_actions[:round_num])
        rounds_completed = round_num
        cooperation_rate = total_cooperators / (rounds_completed * self.n)
        threshold_sustain = 0.5 + self.k / (2.0 * self.n)
        threshold_engage = max(0.2, threshold_sustain - 0.25)
        if round_num == self.r - 1:
            if cooperation_rate >= threshold_sustain:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= threshold_sustain:
            return Action.C
        elif cooperation_rate >= threshold_engage:
            prob_coop = (cooperation_rate - (threshold_engage - 0.25)) / (threshold_sustain - (threshold_engage - 0.25))
            prob_coop = max(0.0, min(1.0, prob_coop))
            if random.random() < prob_coop:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_119(BaseStrategy):
    """
    Adaptive Threshold Reciprocity (ATR) Strategy for N-Player Public Goods Game.

    Balances collective welfare optimization with individual security by:
    1. Rewarding cooperation to encourage collective value creation
    2. Punishing defection to deter free-riding
    3. Adapting thresholds based on observed cooperation rates
    4. Protecting against exploitation while remaining forgiving
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_idx = round_num - 1
        prev_cooperators = sum(history.opponent_actions[prev_round_idx, :])
        coop_rate = prev_cooperators / self.n_players
        threshold = self._calculate_threshold(round_num, history)
        if coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_threshold(self, round_num: int, history: PlayerHistory) -> float:
        """Calculate the adaptive threshold based on game phase and history."""
        n = self.n_players
        k = self.k
        r = self.n_rounds
        if round_num <= 1:
            return k / n
        if round_num >= r - 2:
            return k / n - 0.1
        overall_coop = self._calculate_overall_cooperation_rate(history, round_num)
        mid_game_threshold = min(overall_coop + 0.1, k / n + 0.15)
        return mid_game_threshold

    def _calculate_overall_cooperation_rate(self, history: PlayerHistory, up_to_round: int) -> float:
        """Calculate average cooperation rate across all previous rounds."""
        if up_to_round == 0:
            return 0.0
        total_cooperators = 0
        for round_idx in range(up_to_round):
            total_cooperators += sum(history.opponent_actions[round_idx, :])
        total_opportunities = up_to_round * self.n_players
        overall_coop = total_cooperators / total_opportunities
        return overall_coop

class Strategy_COLLECTIVE_120(BaseStrategy):
    """
    Adaptive Contribution with Threshold Recovery (ACTR) Strategy

    A collectively-minded strategy that balances individual rationality with collective welfare.
    Cooperates when sufficient cooperation exists, defects when exploitation risk is high,
    and adapts dynamically to opponent behavior while preventing the exploitation of cooperators.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        cooperation_rate = self._calculate_cooperation_rate(history)
        minimum_threshold = (1 + self.k / self.n) / 2
        if round_num == self.r - 1:
            return Action.D
        if round_num == self.r - 2:
            if cooperation_rate >= 0.7 * minimum_threshold:
                return Action.C
            else:
                return Action.D
        if self._universal_defection_detected(history, round_num):
            return Action.D
        if cooperation_rate >= 0.95:
            return Action.C
        if cooperation_rate >= minimum_threshold:
            return Action.C
        if self.k > 1.5 and self._recent_majority_cooperated(history):
            if random.random() < 0.6:
                return Action.C
            else:
                return Action.D
        if self._positive_trend_detected(history, cooperation_rate, minimum_threshold):
            if random.random() < 0.6:
                return Action.C
            else:
                return Action.D
        return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate the overall cooperation rate across all rounds and players."""
        if history is None or len(history.opponent_actions) == 0:
            return 0.0
        rounds_completed = len(history.opponent_actions)
        total_cooperators = np.sum(history.opponent_actions)
        total_possible = rounds_completed * self.n
        return float(total_cooperators) / total_possible if total_possible > 0 else 0.0

    def _universal_defection_detected(self, history: PlayerHistory, round_num: int) -> bool:
        """Check if there has been universal defection for 2 consecutive recent rounds."""
        if round_num < 2:
            return False
        recent_actions = history.opponent_actions[-2:, :]
        cooperators_per_round = np.sum(recent_actions, axis=1)
        return all((count == 0 for count in cooperators_per_round))

    def _recent_majority_cooperated(self, history: PlayerHistory) -> bool:
        """Check if majority of players cooperated in the most recent round."""
        if history is None or len(history.opponent_actions) == 0:
            return False
        last_round_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        return last_round_cooperators >= math.ceil(self.n / 2)

    def _positive_trend_detected(self, history: PlayerHistory, current_rate: float, threshold: float) -> bool:
        """Detect if cooperation is trending upward despite being below threshold."""
        if history is None or len(history.opponent_actions) < 4:
            return False
        if current_rate >= threshold:
            return False
        last_round_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        if len(history.opponent_actions) >= 4:
            prev_3_rounds = history.opponent_actions[-4:-1, :]
            prev_3_average = float(np.mean(np.sum(prev_3_rounds, axis=1)))
        else:
            prev_3_average = float(np.mean(np.sum(history.opponent_actions[:-1, :], axis=1)))
        return last_round_cooperators > prev_3_average

class Strategy_COLLECTIVE_121(BaseStrategy):
    """
    Collective Adaptive Strategy for N-Player Public Goods Game.

    Pursues conditional cooperation with adaptive thresholds based on observed
    collective behavior. Uses exponential weighted moving average (EWMA) to track
    cooperation trends, adjusts thresholds for volatility, and implements defection
    detection with limited retaliation. Always defects in the final round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.n / (2 * self.k)
        self.cooperation_trend = 1.0
        self.patience_counter = 0
        self.last_action_was_cooperate = True

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            self.last_action_was_cooperate = True
            return Action.C
        if current_round == self.r - 1:
            return Action.D
        my_actions = history.my_actions[:current_round]
        opponent_actions = history.opponent_actions[:current_round, :]
        lookback_window = min(5, current_round)
        recent_opponent_actions = opponent_actions[-lookback_window:, :]
        cooperators_per_round = np.sum(recent_opponent_actions, axis=1)
        observed_cooperation_rate = np.mean(cooperators_per_round) / self.n
        alpha = min(0.6, 1.0 / (current_round + 1))
        self.cooperation_trend = alpha * observed_cooperation_rate + (1.0 - alpha) * self.cooperation_trend
        std_dev = np.std(cooperators_per_round) / self.n if len(cooperators_per_round) > 1 else 0.0
        adjusted_threshold = self.threshold
        if std_dev > 0.4:
            adjusted_threshold = self.threshold + 0.15
        previous_round_idx = current_round - 1
        previous_cooperation_rate = np.mean(opponent_actions[previous_round_idx, :]) / self.n
        if previous_cooperation_rate < 0.3 and self.last_action_was_cooperate:
            self.patience_counter += 1
        else:
            self.patience_counter = 0
        if self.patience_counter >= 2:
            self.last_action_was_cooperate = False
            return Action.D
        if self.cooperation_trend > adjusted_threshold:
            self.last_action_was_cooperate = True
            return Action.C
        else:
            self.last_action_was_cooperate = False
            return Action.D

class Strategy_COLLECTIVE_122(BaseStrategy):
    """
    Adaptive Reciprocal Provisioning (ARP) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with individual rationality protection
    through adaptive threshold-based reciprocal provisioning. Cooperates when the
    observed cooperation rate meets or exceeds the break-even threshold (k/n),
    adjusts thresholds slightly upward in final rounds, and initializes with
    unconditional cooperation to signal good faith.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        cooperators_last_round = int(sum(history.opponent_actions[round_t - 1, :]))
        coop_rate = cooperators_last_round / self.n_players
        threshold = self._calculate_threshold(round_t)
        if coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_threshold(self, round_t: int) -> float:
        """
        Calculate the cooperation rate threshold for the given round.

        PRIMARY RULE: Base threshold is k/n (break-even point)
        SECONDARY RULE: In final m rounds, add epsilon bias toward defection

        Args:
            round_t: Current round number (0-indexed)

        Returns:
            Cooperation rate threshold for decision-making
        """
        base_threshold = self.k / self.n_players
        m = max(2, math.floor(self.n_rounds / 10))
        final_round_index = self.n_rounds - m
        if round_t >= final_round_index:
            epsilon = 0.02
            adjusted_threshold = base_threshold + epsilon
            return adjusted_threshold
        return base_threshold

class Strategy_COLLECTIVE_123(BaseStrategy):
    """
    Adaptive Contribution with Decay Tolerance (ACT)

    A conditional cooperation strategy that maximizes collective welfare by:
    1. Cooperating in the first round to signal commitment
    2. Adapting based on recent cooperation rates of other players
    3. Using probabilistic cooperation in the mid-range to incentivize reciprocity
    4. Withdrawing cooperation only when defection becomes endemic
    5. Treating all rounds equally to avoid exploitation at endpoints
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if self.n_rounds <= 3:
            return Action.C
        if self.n_players <= 3:
            threshold_high = 0.6
            threshold_mid = 0.3
            threshold_low = 0.05
        else:
            threshold_high = 0.65
            threshold_mid = 0.35
            threshold_low = 0.1
        recent_window = min(5, state.round_number)
        start_round = state.round_number - recent_window
        recent_opponent_actions = history.opponent_actions[start_round:state.round_number, :]
        total_cooperations = np.sum(recent_opponent_actions)
        total_opportunities = (self.n_players - 1) * recent_window
        cooperation_rate = total_cooperations / total_opportunities if total_opportunities > 0 else 0.0
        if cooperation_rate >= threshold_high:
            return Action.C
        elif cooperation_rate >= threshold_mid:
            if random.random() < cooperation_rate:
                return Action.C
            else:
                return Action.D
        elif cooperation_rate >= threshold_low:
            return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_124(BaseStrategy):
    """
    Adaptive Threshold Reciprocity (ATR) Strategy for N-Player Public Goods Game

    Balances individual rationality with collective welfare through:
    - Reciprocal cooperation based on dynamic threshold (k/n)
    - Adaptive response to observed cooperation levels
    - Exploration mechanism to escape mutual defection traps
    - Declining cooperation detection to avoid exploitation
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        prev_round_cooperators = sum(history.opponent_actions[round_t - 1, :])
        cooperation_rate = prev_round_cooperators / self.n
        if round_t >= 2:
            recent_defections = 0
            for check_round in range(max(0, round_t - 2), round_t):
                round_cooperators = sum(history.opponent_actions[check_round, :])
                my_action = history.my_actions[check_round]
                total_cooperators = round_cooperators + (1 if my_action else 0)
                if total_cooperators == 0:
                    recent_defections += 1
            if recent_defections >= 2:
                if random.random() < 0.1:
                    return Action.C
                else:
                    return Action.D
        if round_t >= 4:
            recent_rates = []
            for check_round in range(round_t - 3, round_t):
                round_cooperators = sum(history.opponent_actions[check_round, :])
                recent_rates.append(round_cooperators / self.n)
            recent_avg = sum(recent_rates) / len(recent_rates)
            if cooperation_rate < recent_avg * 0.7:
                return Action.D
        if cooperation_rate > 0.8:
            return Action.C
        if cooperation_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_125(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game.

    This strategy maximizes collective welfare while remaining robust against exploitation.
    It uses an adaptive threshold mechanism that:
    - Cooperates in round 1 to establish good faith
    - In subsequent rounds, cooperates if observed cooperation rate meets a dynamic threshold
    - The threshold decreases over time, balancing stringency early with leniency late
    - The threshold is anchored at k/n (break-even point) and rises to 1.0 based on remaining rounds
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        previous_round_idx = current_round - 1
        cooperators_in_previous = int(sum(history.opponent_actions[previous_round_idx, :]))
        observed_coop_rate = cooperators_in_previous / self.n_players
        threshold = self._calculate_threshold(current_round)
        if observed_coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_threshold(self, current_round: int) -> float:
        """
        Calculate the cooperation threshold for the current round.

        Threshold decreases from 1.0 toward k/n as the game progresses.
        This allows early stringency (test others' cooperation) and late leniency
        (maximize cooperation extraction before game ends).

        Formula:
        threshold(t) = k/n + (1 - k/n)  (remaining_rounds / total_rounds)
        """
        min_threshold = self.k / self.n_players
        max_threshold = 1.0
        remaining_rounds = self.n_rounds - current_round
        threshold = min_threshold + (max_threshold - min_threshold) * (remaining_rounds / self.n_rounds)
        return threshold

class Strategy_COLLECTIVE_126(BaseStrategy):
    """
    Conditional Reciprocal Threshold (CRT) Strategy for N-Player Public Goods Game

    Balances individual security, collective welfare, and adaptive robustness by:
    1. Cooperating in round 1 to bootstrap cooperation
    2. Defecting in the final round (no future reciprocation)
    3. In middle rounds, cooperating iff observed cooperation rate  k/n threshold

    The threshold k/n represents the point where cooperation becomes individually rational
    when that fraction of the group cooperates.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.n_rounds - 1:
            return Action.D
        previous_round_idx = round_number - 1
        cooperators_previous_round = np.sum(history.opponent_actions[previous_round_idx, :])
        my_previous_action = history.my_actions[previous_round_idx]
        total_cooperators = cooperators_previous_round + (1 if my_previous_action else 0)
        cooperation_rate = total_cooperators / self.n_players
        if cooperation_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_127(BaseStrategy):
    """
    Adaptive Reciprocal Threshold (ART) Strategy for N-Player Public Goods Game.

    Core approach:
    - Round 1: Cooperate (exploration/goodwill)
    - Rounds 2 to r-1: Reciprocate based on threshold k/n
    - Round r: Reciprocate with trend-aware threshold adjustment

    Threshold logic: Cooperate if cooperation_rate >= k/n, else defect.
    This reflects the inflection point where cooperation becomes collectively rational.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            return self._endgame_decision(history, current_round)
        return self._reciprocal_decision(history, current_round)

    def _reciprocal_decision(self, history: PlayerHistory, current_round: int) -> Action:
        """
        Standard reciprocal decision for middle rounds.
        Cooperate if cooperation_rate >= k/n, else defect.
        """
        cooperation_rate = self._get_cooperation_rate(history, current_round - 1)
        if cooperation_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

    def _endgame_decision(self, history: PlayerHistory, current_round: int) -> Action:
        """
        Final round decision with trend-aware threshold adjustment.
        """
        cooperation_rate_last = self._get_cooperation_rate(history, current_round - 1)
        threshold = self.threshold
        if self.r > 2 and current_round >= 2:
            cooperation_rate_prev = self._get_cooperation_rate(history, current_round - 2)
            recent_trend = cooperation_rate_last - cooperation_rate_prev
            if recent_trend < 0:
                threshold = self.threshold * 0.9
        if cooperation_rate_last >= threshold:
            return Action.C
        else:
            return Action.D

    def _get_cooperation_rate(self, history: PlayerHistory, round_index: int) -> float:
        """
        Calculate cooperation rate in a given round.
        Round index is 0-indexed into history arrays.
        Returns fraction of players (including self) who cooperated.
        """
        opponent_cooperators = int(np.sum(history.opponent_actions[round_index, :]))
        my_cooperation = int(history.my_actions[round_index])
        total_cooperators = opponent_cooperators + my_cooperation
        cooperation_rate = total_cooperators / self.n
        return cooperation_rate

class Strategy_COLLECTIVE_128(BaseStrategy):
    """
    Adaptive Threshold Reciprocity (ATR) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare by maintaining a dynamic
    cooperation threshold that adjusts based on observed group behavior and remaining
    game time. Cooperates in round 1, applies adaptive thresholds in mid-game rounds,
    and uses conditional defection in the final round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        total_cooperators = int(np.sum(history.opponent_actions))
        total_slots = self.n * round_number
        cooperation_rate = total_cooperators / total_slots if total_slots > 0 else 0.0
        early_game_boundary = math.floor(self.r / 3)
        mid_game_boundary = math.floor(2 * self.r / 3)
        if round_number == self.r - 1:
            if cooperation_rate > self.k / self.n + 0.05:
                return Action.C
            else:
                return Action.D
        if round_number < early_game_boundary:
            threshold = max(self.k / self.n - 0.1, 0.4)
        elif round_number < mid_game_boundary:
            threshold = self.k / self.n
        else:
            threshold = min(self.k / self.n + 0.15, 0.95)
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_129(BaseStrategy):
    """
    Conditional cooperation with adaptive thresholds and punishment mechanism.

    Cooperates when estimated cooperators meet breakeven threshold (n/k).
    Adapts based on observed cooperation rates and applies punishment for declining participation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.total_cooperations_observed = 0
        self.total_actions_observed = 0
        self.defect_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        k = self.game_description.k
        breakeven_threshold = n / k
        if state.round_number == 0:
            return Action.C
        self._update_history(history)
        cooperation_rate = (self.total_cooperations_observed + 1) / (self.total_actions_observed + 1)
        estimated_cooperators = 1 + (n - 1) * cooperation_rate
        if estimated_cooperators >= breakeven_threshold:
            self.defect_counter = max(0, self.defect_counter - 1)
            return Action.C
        elif self.defect_counter >= 2:
            return Action.D
        else:
            self.defect_counter += 1
            return Action.D

    def _update_history(self, history: PlayerHistory) -> None:
        """Update observed cooperation counts from history."""
        if history is None:
            return
        for round_idx in range(len(history.opponent_actions)):
            cooperators_this_round = int(sum(history.opponent_actions[round_idx, :]))
            if history.my_actions[round_idx]:
                cooperators_this_round += 1
            self.total_cooperations_observed += cooperators_this_round
            self.total_actions_observed += self.game_description.n_players

class Strategy_COLLECTIVE_130(BaseStrategy):
    """
    Progressive Reciprocal Contribution (PRC) Strategy

    Balances collective welfare maximization with rational self-protection.
    - Phase 1 (Early): Cooperate to signal willingness
    - Phase 2 (Middle): Adapt based on opponent cooperation rate vs. breakeven threshold k/n
    - Phase 3 (Final): Lock in strategy from Phase 2
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.breakeven_threshold = self.k / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        phase_boundary_1 = math.ceil(self.n_rounds / 3)
        phase_boundary_2 = math.floor(2 * self.n_rounds / 3)
        observed_coop_rates = []
        for round_idx in range(current_round):
            coop_count = np.sum(history.opponent_actions[round_idx, :])
            coop_rate = coop_count / self.n_players
            observed_coop_rates.append(coop_rate)
        avg_opponent_coop = np.mean(observed_coop_rates)
        if current_round < phase_boundary_1:
            return Action.C
        if avg_opponent_coop >= self.breakeven_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_131(BaseStrategy):
    """
    Adaptive Graduated Reciprocity (AGR) strategy for N-Player Public Goods Game.

    Maximizes collective welfare through graduated reciprocity:
    - Round 1: Cooperate to establish baseline
    - Subsequent rounds: Reciprocate based on cooperation rate with probabilistic grace zone
    - Final round: Defect if cooperation collapsed, else cooperate
    - Early rounds: Lenient to allow norm establishment
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_idx = round_num - 1
        prev_cooperators = int(sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            prev_cooperators += 1
        coop_rate = prev_cooperators / self.n
        primary_threshold = self.k / self.n
        lower_threshold = self.k / self.n * 0.5
        if self.k <= 1.1:
            lower_threshold = self.k / self.n * 0.3
        if round_num <= 2 and coop_rate >= lower_threshold:
            return Action.C
        if round_num == self.r - 1:
            if coop_rate >= primary_threshold:
                return Action.C
            else:
                return Action.D
        if coop_rate >= primary_threshold:
            return Action.C
        if lower_threshold < coop_rate < primary_threshold:
            prob = (coop_rate - lower_threshold) / (primary_threshold - lower_threshold)
            if random.random() < prob:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_132(BaseStrategy):
    """
    Adaptive Contribution with Decay Detection (ACDD) - A collectively-aligned strategy
    for N-player public goods games that initiates cooperation, monitors group health,
    adapts dynamically to reward cooperation and discourage freeloading, and gracefully
    degrades when cooperation breaks down.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold_high = 0.5
        self.threshold_medium = 0.25
        if self.n <= 3:
            self.threshold_high += 0.17
            self.threshold_medium += 0.08
        if self.k <= 1.5:
            self.threshold_high += 0.15
            self.threshold_medium += 0.15
        elif self.k > 2.5:
            self.threshold_high -= 0.15
            self.threshold_medium -= 0.15
        self.threshold_high = max(0.0, min(1.0, self.threshold_high))
        self.threshold_medium = max(0.0, min(1.0, self.threshold_medium))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        previous_round_idx = current_round - 1
        opponent_cooperators = int(sum(history.opponent_actions[previous_round_idx, :]))
        our_previous_action = int(history.my_actions[previous_round_idx])
        total_cooperators = opponent_cooperators + our_previous_action
        c_rate = total_cooperators / self.n
        consecutive_zeros = 0
        for i in range(previous_round_idx, -1, -1):
            round_cooperators = int(sum(history.opponent_actions[i, :])) + int(history.my_actions[i])
            if round_cooperators == 0:
                consecutive_zeros += 1
            else:
                break
        rounds_remaining = self.r - current_round
        if rounds_remaining >= 3 and consecutive_zeros == 1 and (c_rate == 0.0):
            return Action.C
        if current_round == self.r - 1:
            if c_rate >= self.threshold_medium:
                return Action.C
            else:
                return Action.D
        if c_rate < self.threshold_medium and consecutive_zeros >= 2:
            return Action.D
        if c_rate >= self.threshold_high:
            return Action.C
        if c_rate >= self.threshold_medium:
            random_value = random.random()
            if random_value < c_rate:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_133(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective benefit by:
    1. Cooperating in round 1 to signal willingness
    2. Conditionally cooperating based on observed cooperation rates
    3. Defecting in final round (with exceptions for small n and high cooperation)
    4. Using moving average to smooth noisy cooperation signals
    5. Gradually increasing defection probability near game end
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.k - 1) / (self.k * self.n)
        self.defection_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            if self.n <= 3:
                avg_coop = self._get_moving_average_cooperation(history, round_num, window=3)
                if avg_coop >= 0.8:
                    return Action.C
            return Action.D
        if self.defection_counter > 0:
            self.defection_counter -= 1
            return Action.D
        avg_cooperation_rate = self._get_moving_average_cooperation(history, round_num, window=3)
        if avg_cooperation_rate == 0:
            return Action.D
        if round_num >= 2:
            prev_avg = self._get_moving_average_cooperation(history, round_num - 1, window=3)
            if prev_avg >= self.threshold and avg_cooperation_rate < self.threshold:
                self.defection_counter = 2
                return Action.D
        if round_num >= self.r - 2:
            defection_prob = (round_num - (self.r - 3)) / 3.0
            if random.random() < defection_prob:
                return Action.D
        if avg_cooperation_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

    def _get_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """Calculate cooperation rate (including self) for a given round."""
        if round_num < 0 or round_num >= len(history.opponent_actions):
            return 0.0
        opponent_cooperators = sum(history.opponent_actions[round_num, :])
        self_cooperated = 1 if history.my_actions[round_num] else 0
        total_cooperators = opponent_cooperators + self_cooperated
        cooperation_rate = total_cooperators / self.n
        return cooperation_rate

    def _get_moving_average_cooperation(self, history: PlayerHistory, round_num: int, window: int=3) -> float:
        """Calculate moving average cooperation rate over last 'window' rounds."""
        if round_num == 0:
            return 0.0
        start_round = max(0, round_num - window)
        rates = []
        for r in range(start_round, round_num):
            rate = self._get_cooperation_rate(history, r)
            rates.append(rate)
        if len(rates) == 0:
            return 0.0
        return sum(rates) / len(rates)

class Strategy_COLLECTIVE_134(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game

    This strategy maximizes collective welfare by:
    1. Testing cooperation viability in round 1
    2. Matching collective contribution levels based on a threshold
    3. Punishing free-riding when cooperation falls below the breakeven point
    4. Recovering to cooperation when conditions improve
    5. Optimizing end-game behavior

    The cooperation threshold is k/n, the breakeven point where contributing
    becomes economically rational for a collective player.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        prev_round_cooperators = int(np.sum(history.opponent_actions[round_number - 1, :]))
        cooperation_rate = prev_round_cooperators / self.n
        if round_number == self.r - 1:
            if cooperation_rate >= self.threshold:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_135(BaseStrategy):
    """
    Adaptive Contribution Reciprocity (ACR) Strategy for N-Player Public Goods Game

    Balances individual rationality with collective welfare by:
    1. Testing cooperation viability in round 1
    2. Reciprocating observed cooperation in middle rounds
    3. Punishing defection proportionally via probabilistic matching
    4. Defecting in final round (game-theoretic necessity)

    Uses adaptive thresholds that decay as the game nears completion.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[round_num - 1, :]))
        cooperation_rate = cooperators_last_round / self.n
        threshold = max(0.5, (self.r - round_num) / self.r * 0.7)
        if cooperation_rate >= threshold:
            return Action.C
        elif cooperation_rate > 0:
            if random.random() < cooperation_rate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_136(BaseStrategy):
    """
    Adaptive Contribution with Defection Recovery (ACDR) Strategy

    A collective strategy that balances cooperation maximization with self-protection.
    Uses adaptive conditional cooperation based on observed cooperation rates,
    with recovery mechanisms and endgame optimization.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold_sustain = (self.k - 1) / self.k + 0.15
        self.threshold_min = (self.k - 1) / (2 * self.k) + 0.1
        self.recovery_window = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            return self._decide_final_round(history)
        return self._decide_middle_round(current_round, history)

    def _get_recent_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """Calculate cooperation rate over recent rounds (last 3 or available history)."""
        start_round = max(0, current_round - self.recovery_window)
        end_round = current_round
        if start_round >= end_round:
            return 0.0
        total_cooperators = 0
        rounds_to_consider = end_round - start_round
        for round_idx in range(start_round, end_round):
            round_cooperators = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += round_cooperators
        max_cooperators = rounds_to_consider * self.n
        recent_coop_rate = total_cooperators / max_cooperators if max_cooperators > 0 else 0.0
        return recent_coop_rate

    def _get_average_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """Calculate average cooperation rate over all past rounds."""
        if current_round == 0:
            return 0.0
        total_cooperators = 0
        for round_idx in range(current_round):
            round_cooperators = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += round_cooperators
        max_cooperators = current_round * self.n
        average_coop_rate = total_cooperators / max_cooperators if max_cooperators > 0 else 0.0
        return average_coop_rate

    def _time_to_recovery_exists(self, current_round: int) -> bool:
        """Check if there are enough rounds left to attempt recovery (minimum 3)."""
        return self.r - current_round >= self.recovery_window

    def _decide_middle_round(self, current_round: int, history: PlayerHistory) -> Action:
        """Decide action for middle rounds (1 to r-2)."""
        recent_coop_rate = self._get_recent_cooperation_rate(history, current_round)
        if recent_coop_rate >= self.threshold_sustain:
            return Action.C
        if recent_coop_rate >= self.threshold_min and self._time_to_recovery_exists(current_round):
            return Action.C
        return Action.D

    def _decide_final_round(self, history: PlayerHistory) -> Action:
        """Decide action for final round."""
        average_coop_rate = self._get_average_cooperation_rate(history, self.r - 1)
        if average_coop_rate >= self.threshold_min:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_137(BaseStrategy):
    """
    Adaptive Reciprocal Threshold (ART) Strategy for N-Player Public Goods Game

    Balances collective welfare with individual viability through:
    1. Cooperation discovery phase (rounds 1-min(r/3, 5))
    2. Adaptive reciprocation based on observed cooperation rates
    3. Final round defection to capture residual public good
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.r - 1:
            return Action.D
        discovery_end = min(math.floor(self.r / 3), 5)
        if round_number <= discovery_end:
            return Action.C
        rounds_elapsed = round_number
        all_actions = history.opponent_actions
        own_actions = history.my_actions
        opponent_cooperators = np.sum(all_actions)
        own_cooperators = np.sum(own_actions)
        total_cooperators = opponent_cooperators + own_cooperators
        total_slots = self.n * rounds_elapsed
        cooperation_rate = total_cooperators / total_slots
        upper_threshold = self.k / self.n * 0.75
        lower_threshold = self.k / self.n * 0.5
        if cooperation_rate >= upper_threshold:
            return Action.C
        elif cooperation_rate >= lower_threshold:
            threshold_ratio = cooperation_rate / upper_threshold
            if random.random() < threshold_ratio:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_138(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare by:
    1. Starting with optimistic cooperation
    2. Dynamically adjusting cooperation threshold based on observed cooperation rates
    3. Punishing defection predictably while allowing recovery
    4. Adapting to opponent types without communication
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.consecutive_low_coop = 0
        self.consecutive_high_coop = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        n = self.n_players
        r = self.n_rounds
        if round_num == 0:
            self.consecutive_low_coop = 0
            self.consecutive_high_coop = 0
            return Action.C
        prev_round_idx = round_num - 1
        my_prev_action = history.my_actions[prev_round_idx]
        opponent_prev_actions = history.opponent_actions[prev_round_idx, :]
        total_cooperators = int(my_prev_action) + int(np.sum(opponent_prev_actions))
        coop_rate = total_cooperators / n
        if round_num == r - 1:
            if coop_rate > 0.75:
                return Action.C
            else:
                return Action.D
        if not my_prev_action:
            return Action.C
        threshold = min(0.9, 0.5 + 0.4 * (r - round_num) / r)
        if round_num == 1:
            threshold = 0.5
        if coop_rate < 0.1:
            self.consecutive_low_coop += 1
            if self.consecutive_low_coop >= 2:
                return Action.D
        else:
            self.consecutive_low_coop = 0
        if coop_rate >= 0.9:
            self.consecutive_high_coop += 1
            if self.consecutive_high_coop >= 3:
                return Action.C
        else:
            self.consecutive_high_coop = 0
        if coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_139(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy

    A game-theoretic strategy that balances individual rationality with collective welfare.
    It uses dynamic thresholds to decide whether to cooperate based on observed cooperation rates
    in previous rounds, adjusted for game phase and efficiency parameters.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        total_cooperators = 0
        total_opponent_actions = 0
        for round_idx in range(current_round):
            cooperators_this_round = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += cooperators_this_round
            total_opponent_actions += self.n - 1
        observed_cooperation_rate = total_cooperators / total_opponent_actions if total_opponent_actions > 0 else 0.0
        threshold = self._calculate_threshold(current_round)
        if observed_cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_threshold(self, current_round: int) -> float:
        """
        Calculate the dynamic cooperation threshold for the current round.

        threshold = base_threshold + phase_adjustment - efficiency_bonus
        """
        base_threshold = 1.0 / (2.0 * self.k)
        phase_ratio = (current_round + 1) / self.r
        if phase_ratio <= 1.0 / 3.0:
            phase_adjustment = 0.15
        elif phase_ratio <= 2.0 / 3.0:
            phase_adjustment = 0.05
        else:
            phase_adjustment = -0.1
        efficiency_bonus = (self.k - 1.0) / (self.n - 1.0) * 0.1
        threshold = base_threshold + phase_adjustment - efficiency_bonus
        threshold = max(0.0, min(1.0, threshold))
        return threshold

class Strategy_COLLECTIVE_140(BaseStrategy):
    """
    Adaptive Reciprocal Contribution with Decay strategy for N-Player Public Goods Game.

    Operates in three phases:
    1. Cooperative Probe (rounds 0-2 or first 20%): Unconditional cooperation
    2. Adaptive Reciprocity (middle rounds): Cooperate if recent cooperation rate > k/n threshold
    3. Endgame Optimization (last 2 rounds): Defect

    Balances collective welfare with individual resilience against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        phase1_end = max(3, math.ceil(0.2 * self.n_rounds))
        if current_round < phase1_end:
            return Action.C
        if self.n_rounds > 3 and current_round >= self.n_rounds - 2:
            return Action.D
        window_size = min(5, self.n_rounds - 3)
        if history is None or current_round == 0:
            other_coop_rate = 0.5
        else:
            start_idx = max(0, current_round - window_size)
            recent_rounds = history.opponent_actions[start_idx:current_round, :]
            if recent_rounds.size == 0:
                other_coop_rate = 0.5
            else:
                total_cooperations = np.sum(recent_rounds)
                total_decisions = recent_rounds.size
                other_coop_rate = total_cooperations / total_decisions
        threshold = self.k / self.n_players
        if other_coop_rate > threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_141(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare through:
    1. Optimistic cooperation in round 1
    2. Exploitation avoidance in final round
    3. Adaptive thresholding based on observed cooperation rates
    4. Hysteresis buffering to prevent oscillation
    5. Probabilistic transitions in uncertainty zones
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        if round_t == self.r - 1:
            return Action.D
        coop_rate = self._calculate_cooperation_rate(history, round_t)
        threshold = self.k / self.n
        buffer = (self.n - self.k) / (2.0 * self.n)
        upper_bound = threshold + buffer
        lower_bound = threshold - buffer
        if coop_rate >= upper_bound:
            return Action.C
        elif coop_rate <= lower_bound:
            return Action.D
        else:
            prob_cooperate = (coop_rate - threshold + buffer) / (2.0 * buffer)
            if random.random() < prob_cooperate:
                return Action.C
            else:
                return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_t: int) -> float:
        """
        Calculate weighted cooperation rate from history.
        Recent rounds weighted more heavily than past rounds.
        """
        if round_t <= 3:
            total_cooperators = np.sum(history.opponent_actions[:round_t, :])
            total_slots = round_t * self.n
            coop_rate = total_cooperators / total_slots if total_slots > 0 else 0.0
        else:
            recent_cooperators = np.sum(history.opponent_actions[round_t - 3:round_t, :])
            past_cooperators = np.sum(history.opponent_actions[:round_t - 3, :])
            recent_weight = 2.0 * recent_cooperators / (3.0 * self.n)
            past_weight = past_cooperators / ((round_t - 3) * self.n)
            coop_rate = (recent_weight + past_weight) / 2.0
        return float(coop_rate)

class Strategy_COLLECTIVE_142(BaseStrategy):
    """
    Adaptive Collective Strategy for N-Player Public Goods Game.

    Balances progressive trust-building with robust defection detection.
    Uses conditional cooperation with threshold adaptation to maximize
    collective welfare while protecting against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        if self.k < 1.2:
            self.T = math.ceil(1.5 * self.k)
        elif self.k >= self.n * 0.8:
            self.T = math.ceil(self.k * 0.6 * self.n)
        else:
            self.T = math.ceil(self.k * self.n / 2)
        self.cooperation_threshold = self.T / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        avg_cooperation = self._calculate_avg_cooperation(history, current_round)
        if current_round == self.r - 1:
            if avg_cooperation >= self.cooperation_threshold:
                return Action.C
            else:
                return Action.D
        if avg_cooperation >= self.cooperation_threshold:
            return Action.C
        elif avg_cooperation > 0.2:
            if random.random() < avg_cooperation:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _calculate_avg_cooperation(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate average cooperation rate from all previous rounds.
        avg_cooperation = (total cooperators across all prior rounds) / (n  number_of_prior_rounds)
        """
        if current_round == 0:
            return 1.0
        prior_rounds = current_round
        my_cooperations = np.sum(history.my_actions[:current_round])
        opponent_cooperations = np.sum(history.opponent_actions[:current_round, :])
        total_cooperators = my_cooperations + opponent_cooperations
        total_possible = self.n * prior_rounds
        avg_cooperation = total_cooperators / total_possible if total_possible > 0 else 0.0
        return avg_cooperation

class Strategy_COLLECTIVE_143(BaseStrategy):
    """
    Adaptive Reciprocal Threshold (ART) Strategy for N-Player Public Goods Game.

    Balances collective welfare with individual security by:
    1. Starting cooperative to enable mutual benefit
    2. Monitoring historical cooperation rates
    3. Adapting dynamically based on observed patterns
    4. Protecting against exploitation when cooperation declines
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.punishment_phase = False
        self.punishment_rounds_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        total_cooperators = int(np.sum(history.opponent_actions))
        max_possible_cooperations = n * round_num
        cooperation_rate = total_cooperators / max_possible_cooperations if max_possible_cooperations > 0 else 0
        minimum_viable = k / n + 0.1
        threshold = max(minimum_viable, 0.5)
        rounds_remaining = r - round_num
        if rounds_remaining <= 2:
            threshold += 0.15
        if round_num <= 2 and cooperation_rate < 0.3:
            return Action.D
        if round_num > 2 and round_num < r - 1:
            recent_coop_count = int(np.sum(history.opponent_actions[-3:, :]))
            recent_max = min(3, round_num) * n
            recent_coop_rate = recent_coop_count / recent_max if recent_max > 0 else 0
            if recent_coop_rate < threshold - 0.1:
                self.punishment_phase = True
                self.punishment_rounds_remaining = 2
                return Action.D
            elif self.punishment_phase and self.punishment_rounds_remaining > 0:
                self.punishment_rounds_remaining -= 1
                return Action.D
            else:
                self.punishment_phase = False
                self.punishment_rounds_remaining = 0
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_144(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization, self-protection against exploiters, and robustness.
    - Round 1: Cooperate to signal willingness and gather information
    - Rounds 2 to r-1: Use dynamic threshold based on cooperation ratio from previous round
    - Final round: Defect (except small groups with perfect cooperation)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            previous_round_index = current_round - 1
            cooperators_prev = sum(history.opponent_actions[previous_round_index, :])
            if history.my_actions[previous_round_index]:
                cooperators_prev += 1
            previous_coop_ratio = cooperators_prev / self.n_players
            if previous_coop_ratio == 1.0 and self.n_players <= 5:
                return Action.C
            else:
                return Action.D
        previous_round_index = current_round - 1
        cooperators_prev = sum(history.opponent_actions[previous_round_index, :])
        if history.my_actions[previous_round_index]:
            cooperators_prev += 1
        coop_ratio = cooperators_prev / self.n_players
        min_threshold = self.k / self.n_players
        dynamic_threshold = 1.0 - current_round / self.n_rounds * (1.0 - min_threshold)
        if coop_ratio >= dynamic_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_145(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game

    Balances individual rationality with collective welfare by:
    1. Cooperating unconditionally in early rounds to seed cooperation
    2. Using an adaptive threshold based on observed cooperation rates in midgame
    3. Applying stability logic in final rounds based on historical cooperation

    The threshold is mathematically derived: ceil((k+1)/2) cooperators makes
    cooperation viable as an equilibrium since the payoff gap between cooperators
    and defectors narrows significantly.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.cooperation_threshold = math.ceil((self.k + 1) / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t <= 2:
            return Action.C
        if history is None or len(history.my_actions) == 0:
            return Action.C
        all_cooperations = history.opponent_actions
        if len(all_cooperations) == 0:
            return Action.C
        total_opponent_cooperations = np.sum(all_cooperations)
        total_opponent_actions = all_cooperations.shape[0] * all_cooperations.shape[1]
        empirical_coop_rate = total_opponent_cooperations / total_opponent_actions if total_opponent_actions > 0 else 0.0
        if round_t == self.n_rounds - 1:
            if empirical_coop_rate >= 0.6:
                return Action.C
            else:
                return Action.D
        if round_t == self.n_rounds - 2:
            if empirical_coop_rate >= 0.5:
                return Action.C
            else:
                return Action.D
        recent_start = max(0, len(all_cooperations) - 3)
        recent_history = all_cooperations[recent_start:, :]
        if len(recent_history) > 0:
            recent_coop_count = np.sum(recent_history)
            recent_total = recent_history.shape[0] * recent_history.shape[1]
            recent_coop_rate = recent_coop_count / recent_total if recent_total > 0 else 0.0
        else:
            recent_coop_rate = empirical_coop_rate
        expected_cooperators = round(recent_coop_rate * (self.n_players - 1)) + 1
        if expected_cooperators >= self.cooperation_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_146(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with individual payoff competitiveness through
    adaptive reciprocity based on observed cooperation rates. Uses threshold-based decision rules
    that adjust cooperation probabilistically as collective contribution changes.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        cooperators_prev_round = sum(history.opponent_actions[prev_round_idx, :])
        cooperation_rate = cooperators_prev_round / self.n
        if current_round == self.r - 1:
            high_threshold = self.k / self.n
            if cooperation_rate >= high_threshold:
                return Action.C
            else:
                return Action.D
        high_threshold = self.k / self.n
        medium_threshold = self.k / (2 * self.n)
        if cooperation_rate >= high_threshold:
            return Action.C
        elif cooperation_rate >= medium_threshold:
            if random.random() < cooperation_rate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_147(BaseStrategy):
    """
    Adaptive Reciprocal Stewardship (ARS): A strategy that maximizes collective welfare
    while maintaining individual resilience against exploitation through cooperation
    thresholds, momentum tracking, and end-game adjustments.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.base_threshold = self.k / self.n_players
        self.consecutive_all_defect_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        cooperation_rates = self._calculate_cooperation_rates(history, round_t)
        if round_t == 1:
            if cooperation_rates[0] > 0:
                return Action.C
            else:
                return Action.D
        adjusted_threshold = self._calculate_adjusted_threshold(cooperation_rates, round_t)
        if self._has_consecutive_all_defect(cooperation_rates):
            self.consecutive_all_defect_rounds += 1
            if self.consecutive_all_defect_rounds <= 2:
                return Action.D
            else:
                self.consecutive_all_defect_rounds = 0
                return Action.C
        else:
            self.consecutive_all_defect_rounds = 0
        rounds_remaining = self.n_rounds - round_t
        if rounds_remaining <= 2:
            return self._end_game_decision(history, cooperation_rates[round_t - 1])
        if cooperation_rates[round_t - 1] >= adjusted_threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rates(self, history: PlayerHistory, round_t: int) -> list:
        """Calculate cooperation rates for each completed round."""
        rates = []
        for i in range(round_t):
            opponent_cooperations = np.sum(history.opponent_actions[i, :])
            rate = opponent_cooperations / (self.n_players - 1)
            rates.append(rate)
        return rates

    def _calculate_adjusted_threshold(self, cooperation_rates: list, round_t: int) -> float:
        """Calculate threshold with momentum-based adjustments."""
        if round_t < 3:
            return self.base_threshold
        window_size = min(5, round_t - 1)
        recent_rates = cooperation_rates[-window_size:]
        momentum = np.mean(recent_rates)
        adjustment = 0.0
        if len(recent_rates) >= 2:
            early_avg = np.mean(recent_rates[:len(recent_rates) // 2])
            late_avg = np.mean(recent_rates[len(recent_rates) // 2:])
            if late_avg > early_avg + 0.05:
                adjustment = -0.05
            elif late_avg < early_avg - 0.05:
                adjustment = +0.1
            else:
                adjustment = 0.0
        return self.base_threshold + adjustment

    def _has_consecutive_all_defect(self, cooperation_rates: list) -> bool:
        """Check if there are 2+ consecutive rounds of all defection."""
        if len(cooperation_rates) < 2:
            return False
        return cooperation_rates[-1] == 0 and cooperation_rates[-2] == 0

    def _end_game_decision(self, history: PlayerHistory, last_cooperation_rate: float) -> Action:
        """Make decision in final rounds."""
        total_payoff = np.sum(history.my_payoffs)
        expected_all_defect = (self.n_rounds - 1) * 1.0
        if total_payoff < expected_all_defect:
            return Action.D
        cooperation_rates = []
        for i in range(len(history.my_payoffs) - 1):
            opponent_cooperations = np.sum(history.opponent_actions[i, :])
            rate = opponent_cooperations / (self.n_players - 1)
            cooperation_rates.append(rate)
        if len(cooperation_rates) > 0:
            momentum = np.mean(cooperation_rates[-min(3, len(cooperation_rates)):])
            if momentum > 2 * self.base_threshold:
                return Action.C
            elif momentum < self.base_threshold:
                return Action.D
        return Action.C

class Strategy_COLLECTIVE_148(BaseStrategy):
    """
    Adaptive Threshold Reciprocity with Decay (ATRD)

    A strategy that balances collective welfare maximization with robust self-protection
    against exploitation. It uses a decaying threshold based on observed cooperation rates
    to decide whether to cooperate or defect in each round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        if round_t == self.r - 1:
            return Action.D
        cooperators_prev = float(sum(history.opponent_actions[round_t - 1, :]))
        c_prev = cooperators_prev / self.n
        theta_base = 1.0 - self.k / self.n
        decay_factor = 0.5
        threshold = theta_base * (1.0 - decay_factor * (round_t / self.r))
        if c_prev >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_149(BaseStrategy):
    """
    Adaptive Contribution Targeting (ACT) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare by:
    1. Targeting an equilibrium contribution level based on game parameters
    2. Observing cooperation rates in previous rounds
    3. Adapting strategy based on deviation from expected behavior
    4. Using a tolerance window to avoid over-punishment of natural variation
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.tolerance = 0.15
        self.punitive_mode = False
        self.punitive_rounds_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        target_contribution_rate = min(1.0, (self.k - 1) / self.k)
        observed_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        observed_rate = observed_cooperators / self.n
        if observed_rate == 0:
            return Action.D
        defection_threshold = target_contribution_rate - self.tolerance
        if observed_rate < 0.2:
            if not self.punitive_mode:
                self.punitive_mode = True
                self.punitive_rounds_remaining = 2
            if self.punitive_rounds_remaining > 0:
                self.punitive_rounds_remaining -= 1
                return Action.D
            else:
                self.punitive_mode = False
        trend_detected = False
        if current_round >= 3:
            recent_rates = []
            for i in range(max(0, current_round - 3), current_round):
                recent_cooperators = int(np.sum(history.opponent_actions[i, :]))
                recent_rates.append(recent_cooperators / self.n)
            if len(recent_rates) >= 2:
                is_declining = recent_rates[-1] < recent_rates[-2]
                if len(recent_rates) >= 3 and recent_rates[-2] < recent_rates[-3]:
                    is_declining = True
                    trend_detected = True
                    defection_threshold += 0.1
        if observed_rate >= defection_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_150(BaseStrategy):
    """
    Adaptive Contribution with Threshold Recovery (ACTR)

    A strategy that balances cooperation with self-protection by:
    1. Starting with cooperation to establish goodwill
    2. Tracking historical and recent cooperation rates
    3. Using game-theoretic thresholds to decide when cooperation is rational
    4. Allowing recovery when cooperation trends improve
    5. Conditionally cooperating in the final round based on overall patterns
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            return self._final_round_decision(history)
        return self._middle_round_decision(round_num, history)

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """
        Decide action in final round based on historical cooperation patterns.
        """
        total_cooperators = np.sum(history.opponent_actions, axis=1)
        all_rounds_cooperation_rate = np.sum(total_cooperators) / (self.n * len(history.opponent_actions))
        recent_rounds_count = min(3, len(history.opponent_actions))
        recent_cooperators = np.sum(total_cooperators[-recent_rounds_count:])
        recent_cooperation_rate = recent_cooperators / (self.n * recent_rounds_count)
        if all_rounds_cooperation_rate > 0.3 and recent_cooperation_rate >= all_rounds_cooperation_rate * 0.9:
            return Action.C
        else:
            return Action.D

    def _middle_round_decision(self, round_num: int, history: PlayerHistory) -> Action:
        """
        Decide action in middle rounds using threshold-based logic.
        """
        total_cooperators = np.sum(history.opponent_actions, axis=1)
        historical_cooperation_rate = np.sum(total_cooperators) / (self.n * round_num)
        recent_rounds_count = min(3, round_num)
        recent_start_idx = round_num - recent_rounds_count
        recent_cooperators = np.sum(total_cooperators[recent_start_idx:])
        recent_cooperation_rate = recent_cooperators / (self.n * recent_rounds_count)
        threshold_high = (self.k - 1) / self.n
        threshold_low = (self.k - 1) / (2 * self.n)
        if historical_cooperation_rate > threshold_high:
            if recent_cooperation_rate >= historical_cooperation_rate * 0.95:
                return Action.C
            else:
                return Action.D
        elif historical_cooperation_rate > threshold_low:
            if recent_cooperation_rate > historical_cooperation_rate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_151(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with individual security through graduated
    reciprocal contribution. Starts cooperatively, adapts to defection with escalating
    thresholds, and defects in final rounds when future punishment becomes ineffective.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.defection_strikes = 0
        self.cooperation_phases_failed = 0
        self.reset_cooperative_signal = False
        self.MAX_STRIKES = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        t = state.round_number
        r = self.game_description.n_rounds
        n = self.game_description.n_players
        cooperators_last_round = np.sum(history.opponent_actions[t - 1, :])
        my_last_action = history.my_actions[t - 1]
        total_cooperators_last_round = cooperators_last_round + (1 if my_last_action else 0)
        cooperation_rate = total_cooperators_last_round / n
        exploitation_threshold = self._calculate_threshold(t, r, self.defection_strikes)
        if cooperation_rate >= exploitation_threshold:
            self.reset_cooperative_signal = False
            return Action.C
        else:
            self.defection_strikes += 1
            if t > 1 and my_last_action:
                self.cooperation_phases_failed += 1
            if self.defection_strikes >= self.MAX_STRIKES and (not self.reset_cooperative_signal):
                self.reset_cooperative_signal = True
                self.defection_strikes = 1
                return Action.C
            return Action.D

    def _calculate_threshold(self, t: int, r: int, defection_strikes: int) -> float:
        """
        Calculate the cooperation threshold for round t.

        Three phases:
        - Early (0-30%): Optimistic, require 45%+ cooperation
        - Mid (30-70%): Moderate, increase threshold with defection strikes
        - Late (70-100%): Strict, defect in final 3 rounds, otherwise escalate
        """
        rounds_remaining = r - t
        progress_ratio = t / r
        if progress_ratio < 0.3:
            return 0.45
        elif progress_ratio < 0.7:
            return 0.5 + 0.05 * defection_strikes
        elif rounds_remaining <= 3:
            return 1.0
        else:
            return 0.55 + 0.1 * defection_strikes

class Strategy_COLLECTIVE_152(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game.

    Optimizes for collective welfare by maintaining cooperation at sustainable levels
    while defending against exploitation through graduated response based on observed
    cooperation rates.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold_high = 2 * self.k / self.n / (1 + self.k / self.n)
        self.threshold_medium = 0.35
        self.threshold_low = 0.2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            all_rounds_high_coop = True
            for round_idx in range(current_round):
                cooperators_in_round = np.sum(history.opponent_actions[round_idx, :])
                cooperation_rate = cooperators_in_round / self.n
                if cooperation_rate < self.threshold_high:
                    all_rounds_high_coop = False
                    break
            if all_rounds_high_coop:
                return Action.C
            else:
                return Action.D
        last_round_idx = current_round - 1
        cooperators_last_round = np.sum(history.opponent_actions[last_round_idx, :])
        cooperation_rate = cooperators_last_round / self.n
        if cooperation_rate >= self.threshold_high:
            return Action.C
        elif cooperation_rate >= self.threshold_medium:
            if random.random() < cooperation_rate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_153(BaseStrategy):
    """
    Adaptive Reciprocal Contribution with Decay (ARC-D)

    A collective strategy that balances mutual cooperation, individual robustness, and adaptive learning.
    - Round 1: Cooperate to signal peaceful intent
    - Rounds 2 to r-1: Adapt based on observed cooperation rate with calibrated thresholds
    - Last round: Defect unless cooperation is very high (0.80)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        cooperation_rate = self._calculate_cooperation_rate(history, round_num)
        threshold_high = 0.65 + 0.05 * self.k / self.n
        threshold_mid = 0.4 + 0.02 * self.k / self.n
        threshold_low = 0.1 + 0.01 * self.k / self.n
        if round_num == self.r - 1:
            if cooperation_rate >= 0.8:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= threshold_high:
            return Action.C
        elif cooperation_rate >= threshold_mid:
            if random.random() < cooperation_rate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate the observed cooperation rate from all previous rounds.

        cooperation_rate = (total_cooperators_across_previous_rounds) /
                          (n  round_num)

        This includes this player's actions and all opponent actions.
        """
        my_cooperations = np.sum(history.my_actions[:round_num])
        opponent_cooperations = np.sum(history.opponent_actions[:round_num, :])
        total_cooperators = my_cooperations + opponent_cooperations
        total_players_rounds = self.n * round_num
        cooperation_rate = total_cooperators / total_players_rounds
        return cooperation_rate

class Strategy_COLLECTIVE_154(BaseStrategy):
    """
    Adaptive Reciprocal Threshold (ART) Strategy for N-Player Public Goods Game.

    Balances collective welfare, individual protection, and robustness by:
    1. Cooperating optimistically in round 1
    2. Matching cooperation rates against adaptive thresholds in subsequent rounds
    3. Detecting persistent defection and exiting exploitative groups
    4. Allowing recovery when cooperation resumes
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.consecutive_low_cooperation_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        previous_round_idx = current_round - 1
        cooperators_in_previous = int(np.sum(history.opponent_actions[previous_round_idx, :]))
        cooperation_rate_previous = cooperators_in_previous / n
        threshold = max(0.4, k / n - 0.15 + 0.05 * current_round / r)
        if cooperation_rate_previous < 0.3:
            self.consecutive_low_cooperation_rounds += 1
            if self.consecutive_low_cooperation_rounds >= 2:
                return Action.D
        else:
            self.consecutive_low_cooperation_rounds = 0
        if cooperation_rate_previous >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_155(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game

    Balances collective welfare maximization, self-protection, and robustness through
    adaptive reciprocity with decay. Uses observable group cooperation rates to make
    decisions, with special handling for edge cases and endgame conditions.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.consecutive_perfect_cooperation = 0
        self.consecutive_mutual_defection = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        if t == 0:
            return Action.C
        opponent_actions = history.opponent_actions
        prev_round_cooperators = np.sum(opponent_actions[t - 1, :])
        observed_cooperation_rate = prev_round_cooperators / self.n
        if t == self.r - 1:
            avg_cooperation = np.mean(np.sum(opponent_actions[:t, :], axis=1)) / self.n
            if avg_cooperation >= self.k / self.n:
                return Action.C
            else:
                return Action.D
        if t >= 2:
            perfect_coop_rounds = 0
            for i in range(max(0, t - 3), t):
                if np.sum(opponent_actions[i, :]) == self.n:
                    perfect_coop_rounds += 1
            if perfect_coop_rounds >= 3:
                return Action.C
        if t >= 1:
            mutual_defection_rounds = 0
            for i in range(max(0, t - 2), t):
                if np.sum(opponent_actions[i, :]) == 0:
                    mutual_defection_rounds += 1
            if mutual_defection_rounds >= 2:
                return Action.D
        if t >= 2:
            rate_prev = np.sum(opponent_actions[t - 1, :]) / self.n
            rate_prev_prev = np.sum(opponent_actions[t - 2, :]) / self.n
            if abs(rate_prev - rate_prev_prev) > 0.4:
                return Action.D
        t_remaining = self.r - t
        if self.n == 2:
            cooperation_threshold = 0.5
        else:
            decay_factor = min(t_remaining / self.r, 0.5)
            cooperation_threshold = self.k / self.n + (1.0 - self.k / self.n) * decay_factor
        if observed_cooperation_rate >= cooperation_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_156(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game

    Balances individual rationality with collective welfare through threshold-based
    reciprocal cooperation. Cooperates when the expected cooperation rate justifies
    the 1-unit contribution cost, with phase-dependent thresholds for temporal dynamics.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        base_threshold = self.k / (self.n + self.k)
        if round_number == 0:
            phase_factor = 0.5
        elif round_number >= self.r - 2:
            phase_factor = 1.2
        else:
            phase_factor = 1.0
        threshold = base_threshold * phase_factor
        previous_round_index = round_number - 1
        cooperators_last_round = sum(history.opponent_actions[previous_round_index, :])
        if history.my_actions[previous_round_index]:
            cooperators_last_round += 1
        cooperation_rate = cooperators_last_round / self.n
        if cooperation_rate >= threshold:
            return Action.C
        else:
            if cooperation_rate == threshold and self.n > 0:
                last_round_cooperations = history.opponent_actions[previous_round_index, :]
                if any(last_round_cooperations):
                    return Action.C
            if cooperation_rate == 0.0:
                return Action.D
            return Action.D

class Strategy_COLLECTIVE_157(BaseStrategy):
    """
    Adaptive Reciprocity with Defection Resistance (ARDR) strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with individual resilience through:
    1. Initial cooperation to signal good faith and gather data
    2. Threshold-based reciprocity: cooperate if cooperation_rate >= k/n
    3. Strategic endgame: defect in final round unless near-universal cooperation observed
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            prev_round_cooperators = sum(history.opponent_actions[round_num - 1, :])
            prev_coop_rate = prev_round_cooperators / self.n
            if prev_coop_rate >= 0.8:
                return Action.C
            else:
                return Action.D
        prev_round_cooperators = sum(history.opponent_actions[round_num - 1, :])
        prev_coop_rate = prev_round_cooperators / self.n
        if prev_coop_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_158(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game

    Balances collective welfare with robustness against exploitation through:
    1. Initial cooperation to establish goodwill
    2. Final round defection (game-theoretic rationality)
    3. Mid-game probabilistic reciprocity based on observed cooperation rate
    4. Threshold-based decision making at k/n break-even point
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        previous_round_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        my_previous_action = history.my_actions[current_round - 1]
        if my_previous_action:
            previous_round_cooperators += 1
        cooperation_rate = previous_round_cooperators / self.n_players
        if cooperation_rate >= self.threshold:
            return Action.C
        elif random.random() < cooperation_rate:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_159(BaseStrategy):
    """
    Adaptive Reciprocal Threshold (ART) Strategy for N-Player Public Goods Game.

    Balances individual rationality and collective welfare by conditioning cooperation
    on observable cooperation rates, using an adaptive threshold based on game structure.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        recent_coop_rate = self._get_recent_cooperation_rate(history, round_number)
        threshold = self._calculate_threshold()
        is_final_round = round_number == self.n_rounds - 1
        if is_final_round:
            if recent_coop_rate >= threshold:
                return Action.C
            else:
                return Action.D
        elif recent_coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _get_recent_cooperation_rate(self, history: PlayerHistory, round_number: int) -> float:
        """
        Calculate the cooperation rate from the previous round.

        Args:
            history: PlayerHistory object containing opponent actions
            round_number: Current round number (0-indexed)

        Returns:
            Proportion of players who cooperated in the previous round
        """
        prev_round = round_number - 1
        cooperators_in_prev_round = sum(history.opponent_actions[prev_round, :])
        if history.my_actions[prev_round]:
            cooperators_in_prev_round += 1
        recent_coop_rate = cooperators_in_prev_round / self.n_players
        return recent_coop_rate

    def _calculate_threshold(self) -> float:
        """
        Calculate the adaptive cooperation threshold.

        threshold = max(k/n, min_threshold)
        where min_threshold = max(0.3, (k-1)/(n-1))

        Returns:
            Adaptive threshold value
        """
        efficiency = self.k / self.n_players
        min_threshold = max(0.3, (self.k - 1) / (self.n_players - 1))
        threshold = max(efficiency, min_threshold)
        return threshold

class Strategy_COLLECTIVE_160(BaseStrategy):
    """
    Adaptive Collective Strategy: Conditional Reciprocal Contribution (CRC)

    Balances collective welfare maximization with robust defense against exploitation.
    Starts cooperatively, maintains cooperation if opponents reciprocate above a
    parameter-adaptive threshold, punishes systematic defection, and self-corrects
    downward deviations to restore group norms.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        my_cooperations = int(np.sum(history.my_actions[:current_round]))
        my_cooperation_rate = my_cooperations / current_round
        opponent_cooperations = np.sum(history.opponent_actions[:current_round, :], axis=0)
        opponent_cooperation_rates = opponent_cooperations / current_round
        avg_opponent_cooperation = np.mean(opponent_cooperation_rates)
        if current_round <= 2:
            cooperation_threshold = self.k / (2 * self.n_players)
        else:
            cooperation_threshold = self.k / self.n_players
        if avg_opponent_cooperation >= cooperation_threshold:
            if my_cooperation_rate >= avg_opponent_cooperation:
                return Action.C
            else:
                return Action.C
        elif avg_opponent_cooperation > 0:
            if avg_opponent_cooperation >= 0.5:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_161(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy

    A probabilistic strategy that cooperates with probability proportional to
    observed cooperation in the previous round. This balances collective welfare
    maximization with protection against exploitation.

    Decision Rule:
    - Round 1: p_1 = (k-1)/2
    - Round t>1: p_t = (k-1)  (C_{t-1}/n)

    Where C_{t-1} is the number of cooperators in the previous round.
    Cooperate with probability p_t, defect otherwise.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            p = (self.k - 1) / 2
        else:
            cooperators_last_round = np.sum(history.opponent_actions[-1, :])
            if history.my_actions[-1]:
                cooperators_last_round += 1
            p = (self.k - 1) * (cooperators_last_round / self.n)
        p = max(0, min(1, p))
        if random.random() <= p:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_162(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC): A strategy that maximizes collective welfare
    by cooperating when cooperation rates meet a dynamic threshold, with stochastic
    defection escalation when cooperation falls below threshold. Opens cooperatively,
    adapts to observed patterns, and defects strategically in the final round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.optimal_threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        look_back = min(3, state.round_number)
        recent_rounds = history.opponent_actions[-look_back:, :]
        total_cooperations = np.sum(recent_rounds)
        cooperation_rate = total_cooperations / (self.game_description.n_players * look_back)
        volatility = self._calculate_volatility(history, state.round_number, look_back)
        if volatility > 0.4:
            adjusted_threshold = self.optimal_threshold * 0.85
        else:
            adjusted_threshold = self.optimal_threshold
        if self.game_description.n_players == 2:
            adjusted_threshold = adjusted_threshold * 1.1
        if state.round_number == self.game_description.n_rounds - 1:
            if cooperation_rate >= adjusted_threshold:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= adjusted_threshold:
            return Action.C
        else:
            deficit = adjusted_threshold - cooperation_rate
            defection_likelihood = deficit * (self.game_description.n_players - 1) * 0.6
            if random.random() < defection_likelihood:
                return Action.D
            else:
                return Action.C

    def _calculate_volatility(self, history: PlayerHistory, current_round: int, look_back: int) -> float:
        """Calculate standard deviation of cooperation rates over history."""
        if current_round < 2:
            return 0.0
        cooperation_rates = []
        window_size = min(3, current_round)
        for i in range(current_round - window_size + 1, current_round + 1):
            start_idx = max(0, i - window_size)
            end_idx = i + 1
            recent = history.opponent_actions[start_idx:end_idx, :]
            rate = np.sum(recent) / (self.game_description.n_players * (end_idx - start_idx))
            cooperation_rates.append(rate)
        if len(cooperation_rates) < 2:
            return 0.0
        return float(np.std(cooperation_rates))

class Strategy_COLLECTIVE_163(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for N-Player Public Goods Game.

    Balances maximizing group surplus with preventing exploitation by cooperating
    when cooperation rate exceeds a threshold that makes contribution worthwhile,
    and defecting otherwise. Includes special handling for first and last rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.epsilon = 0.05
        self.smoothing_weight_recent = 0.7
        self.smoothing_weight_history = 0.3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            if k > 1 and n >= 2:
                return Action.C
            else:
                return Action.D
        coop_count_prev = int(np.sum(history.opponent_actions[-1, :]))
        coop_rate_prev = coop_count_prev / n
        threshold = k / (n - 1 + self.epsilon)
        smoothed_rate = self._calculate_smoothed_rate(coop_rate_prev, history.opponent_actions)
        if current_round == r - 1:
            historical_avg = self._calculate_historical_average(history.opponent_actions)
            if historical_avg >= threshold:
                return Action.C
            else:
                return Action.D
        if smoothed_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_smoothed_rate(self, coop_rate_prev: float, opponent_actions: NDArray) -> float:
        """
        Calculate smoothed cooperation rate using weighted average of recent and historical rates.
        """
        n = self.game_description.n_players
        num_rounds = opponent_actions.shape[0]
        start_idx = max(0, num_rounds - 3)
        last_3_rounds = opponent_actions[start_idx:, :]
        avg_coop_rate_last_3 = np.sum(last_3_rounds) / (last_3_rounds.shape[0] * n)
        smoothed_rate = self.smoothing_weight_recent * coop_rate_prev + self.smoothing_weight_history * avg_coop_rate_last_3
        return smoothed_rate

    def _calculate_historical_average(self, opponent_actions: NDArray) -> float:
        """
        Calculate average cooperation rate across all previous rounds.
        """
        n = self.game_description.n_players
        total_cooperations = np.sum(opponent_actions)
        total_actions = opponent_actions.shape[0] * n
        return total_cooperations / total_actions if total_actions > 0 else 0.0

class Strategy_COLLECTIVE_164(BaseStrategy):
    """
    Adaptive Reciprocal Threshold (ART) strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with individual security through:
    1. Conditional cooperation based on observable group cooperation rates
    2. Adaptive thresholds that adjust to opponent behavior patterns
    3. Temporal dynamics accounting for game progression
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            threshold_prob = min(0.7, self.k / self.n + 0.2)
            if random.random() < threshold_prob:
                return Action.C
            else:
                return Action.D
        cooperation_rates = self._calculate_cooperation_rates(history, round_num)
        avg_coop_rate = np.mean(cooperation_rates)
        if len(cooperation_rates) > 1:
            std_coop_rate = float(np.std(cooperation_rates))
        else:
            std_coop_rate = 0.0
        last_round_coop_rate = cooperation_rates[-1]
        anomaly_buffer = 0.0
        if len(cooperation_rates) > 1:
            avg_previous = np.mean(cooperation_rates[:-1])
            if last_round_coop_rate < avg_previous - 0.3:
                anomaly_buffer = 0.15
        base_threshold = self.k / self.n
        temporal_adjustment = (self.r - round_num - 1) / (2.0 * self.r)
        volatility_adjustment = -std_coop_rate / (2.0 * self.n)
        threshold = base_threshold + temporal_adjustment + volatility_adjustment + anomaly_buffer
        threshold = max(0.2, min(0.85, threshold))
        if round_num == self.r - 1:
            if avg_coop_rate >= self.k / self.n:
                return Action.C
            else:
                return Action.D
        if avg_coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rates(self, history: PlayerHistory, round_num: int) -> list:
        """
        Calculate the cooperation rate (fraction of cooperators) for each round in history.
        """
        cooperation_rates = []
        for r in range(round_num):
            my_action = history.my_actions[r]
            opponent_cooperators = int(np.sum(history.opponent_actions[r, :]))
            total_cooperators = int(my_action) + opponent_cooperators
            cooperation_rate = total_cooperators / self.n
            cooperation_rates.append(cooperation_rate)
        return cooperation_rates

class Strategy_COLLECTIVE_165(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective benefit maximization with individual rationality protection through
    graduated reciprocity. Uses dynamic thresholds based on game phase and opponent cooperation rates.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return self._decide_round_one()
        return self._decide_subsequent_round(round_t, history)

    def _decide_round_one(self) -> Action:
        """
        First round decision based on game structure incentives.
        """
        k_ratio = self.k / self.n
        if k_ratio >= 0.5:
            return Action.C
        else:
            return Action.D

    def _decide_subsequent_round(self, round_t: int, history: PlayerHistory) -> Action:
        """
        Subsequent rounds use adaptive threshold based on cooperation history.
        """
        prev_round_idx = round_t - 1
        prev_cooperators = np.sum(history.opponent_actions[prev_round_idx, :])
        coop_rate = prev_cooperators / self.n
        phase = round_t / self.r
        threshold = self._get_threshold(phase)
        if round_t >= self.r - 2:
            threshold = max(threshold - 0.05, 0.0)
        if round_t >= 4:
            recent_start = max(0, round_t - 4)
            recent_cooperators = np.sum(history.opponent_actions[recent_start:round_t, :])
            recent_rounds = round_t - recent_start
            recent_coop_rate = recent_cooperators / (recent_rounds * self.n)
            if recent_coop_rate < 0.2:
                threshold = max(0.15, threshold)
        if coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _get_threshold(self, phase: float) -> float:
        """
        Determine cooperation threshold based on game phase.
        phase = current_round / total_rounds (0 to 1)
        """
        k_ratio = self.k / self.n
        if phase <= 1.0 / 3.0:
            return 0.5
        elif phase <= 2.0 / 3.0:
            return max(0.0, k_ratio - 0.1)
        else:
            return max(0.3, k_ratio - 0.15)

class Strategy_COLLECTIVE_166(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game

    Balances collective welfare maximization with individual security against exploitation.
    Uses observed cooperation rates to adaptively decide between cooperation and defection,
    with special handling for early, mid, and late game phases.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        total_cooperators = 0
        total_observations = 0
        for round_idx in range(current_round):
            cooperators_this_round = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += cooperators_this_round
            total_observations += self.n
        coop_rate = total_cooperators / total_observations if total_observations > 0 else 0.0
        if coop_rate == 0.0:
            return Action.D
        rounds_remaining = self.r - current_round
        if current_round == self.r - 1:
            threshold_high = 2.0 * self.k / self.n
            threshold_mid = self.k / self.n
            if coop_rate >= threshold_high:
                return Action.C
            else:
                return Action.D
        elif current_round <= 1:
            if coop_rate > 0:
                return Action.C
            else:
                return Action.D
        else:
            threshold = self.k / self.n
            if coop_rate >= threshold:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_167(BaseStrategy):
    """
    Adaptive Reciprocal Contribution with Decay for N-Player Public Goods Game

    This strategy balances conditional reciprocity, collective efficiency, and robustness:
    - Round 1: Cooperate to establish cooperative baseline
    - Middle rounds: Cooperate if previous cooperation rate >= 1/k threshold
    - Final round: Defect (last round dominance)
    - Late game: Apply decay adjustment to threshold in final quartile
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        prev_opponent_actions = history.opponent_actions[current_round - 1, :]
        prev_cooperators = int(np.sum(prev_opponent_actions))
        prev_cooperation_rate = prev_cooperators / self.n_players
        threshold = 1.0 / self.k
        final_quartile_start = math.ceil(3 * self.n_rounds / 4)
        if current_round >= final_quartile_start and current_round < self.n_rounds - 1:
            decay_factor = 0.5
            adjusted_t = current_round - final_quartile_start
            total_final_period = self.n_rounds - final_quartile_start
            if total_final_period > 0:
                threshold = threshold * (1.0 + decay_factor * adjusted_t / total_final_period)
        if prev_cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_168(BaseStrategy):
    """
    Adaptive Collective Strategy: Conditional Reciprocal Threshold

    Balances individual rationality with collective welfare by conditionally cooperating
    based on observable cooperation rates, with dynamic thresholds and phase-specific behavior.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.extreme_defection_triggered = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        n = self.n_players
        k = self.k
        if round_num == 0:
            return Action.C
        if round_num == self.n_rounds - 1:
            coop_rate = self._get_cooperation_rate(history, round_num - 1)
            if coop_rate >= 0.9:
                return Action.C
            else:
                return Action.D
        if self.extreme_defection_triggered:
            return Action.D
        coop_rate = self._get_cooperation_rate(history, round_num - 1)
        base_threshold = k / n
        if n <= 3:
            base_threshold = max(0, base_threshold - 0.1)
        if coop_rate < 0.2:
            self.extreme_defection_triggered = True
            return Action.D
        threshold_high = base_threshold + 0.05
        threshold_low = base_threshold - 0.15
        if coop_rate >= threshold_high:
            return Action.C
        if coop_rate >= threshold_low:
            if coop_rate > 0.95:
                coop_prob = 0.85
            else:
                coop_prob = 0.7
            if random.random() < coop_prob:
                return Action.C
            else:
                return Action.D
        return Action.D

    def _get_cooperation_rate(self, history: PlayerHistory, target_round: int) -> float:
        """
        Calculate cooperation rate using 3-round moving average if available.
        For early rounds, use observed data directly.
        """
        if target_round < 0:
            return 0.0
        window_start = max(0, target_round - 2)
        window_end = target_round + 1
        total_cooperators = 0
        total_rounds = 0
        for round_idx in range(window_start, window_end):
            if round_idx < len(history.opponent_actions):
                cooperators_this_round = np.sum(history.opponent_actions[round_idx, :])
                total_cooperators += cooperators_this_round
                total_rounds += 1
        if total_rounds == 0:
            return 0.0
        avg_coop_rate = total_cooperators / (total_rounds * self.n_players)
        return avg_coop_rate

class Strategy_COLLECTIVE_169(BaseStrategy):
    """
    Adaptive Graduated Reciprocity (AGR): A collective strategy that conditionally cooperates
    based on dynamic thresholds derived from game parameters, with special handling for early
    and final rounds, and probabilistic recovery attempts when cooperation dips temporarily.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold = max(0.5, (self.k - 1) / (self.n - 1))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_idx = round_num - 1
        opponent_cooperators_prev = sum(history.opponent_actions[prev_round_idx, :])
        total_cooperators_prev = (1 if history.my_actions[prev_round_idx] else 0) + opponent_cooperators_prev
        cooperation_rate_prev = total_cooperators_prev / self.n
        all_cooperators = []
        for t in range(round_num):
            opp_coop = sum(history.opponent_actions[t, :])
            total_coop = (1 if history.my_actions[t] else 0) + opp_coop
            all_cooperators.append(total_coop / self.n)
        avg_cooperation = sum(all_cooperators) / len(all_cooperators)
        is_final_round = round_num == self.r - 1
        if is_final_round:
            if cooperation_rate_prev >= self.threshold:
                return Action.C
            else:
                return Action.D
        if cooperation_rate_prev >= self.threshold:
            return Action.C
        else:
            if avg_cooperation >= self.threshold:
                recovery_probability = 0.5 * (1.0 - round_num / float(self.r))
                if random.random() < recovery_probability:
                    return Action.C
            defection_probability = self._get_defection_probability(round_num)
            if random.random() < defection_probability:
                return Action.D
            else:
                return Action.C

    def _get_defection_probability(self, round_num: int) -> float:
        """
        Compute defection probability based on round number.
        Prevents oscillation by increasing defection likelihood over time.
        """
        if round_num <= 2:
            return 0.5
        elif round_num <= 5:
            return 0.7
        else:
            return 0.9

class Strategy_COLLECTIVE_170(BaseStrategy):
    """
    Conditional Reciprocal Threshold Strategy for N-Player Public Goods Game.

    Adaptive strategy that conditions cooperation on observed cooperation rates,
    with thresholds that decrease over time. Pursues collective welfare while
    remaining robust to exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        prev_coop_rate = prev_cooperators / self.n_players
        if current_round == self.n_rounds - 1:
            if prev_coop_rate >= 0.5:
                return Action.C
            else:
                return Action.D
        rounds_remaining = self.n_rounds - current_round
        threshold = 0.5 + 0.25 * rounds_remaining / self.n_rounds
        if self.k < 1.2:
            threshold = threshold + 0.1
        elif self.k > self.n_players - 0.5:
            threshold = threshold - 0.1
        if current_round >= 2:
            prev_prev_cooperators = int(sum(history.opponent_actions[current_round - 2, :]))
            prev_prev_coop_rate = prev_prev_cooperators / self.n_players
            if prev_coop_rate < 0.25 and prev_prev_coop_rate < 0.25:
                rounds_left = self.n_rounds - current_round
                if rounds_left > 2:
                    return Action.D
                else:
                    return Action.C
        if prev_coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_171(BaseStrategy):
    """
    Adaptive Proportional Reciprocity (APR) Strategy for N-Player Public Goods Game.

    Balances individual sustainability, collective benefit realization, and robust adaptation
    through threshold-based proportional reciprocity. Defects in round 1 and final round,
    applies adaptive logic in intermediate rounds based on opponent cooperation rates and
    viability thresholds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        previous_round_idx = current_round - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[previous_round_idx, :]))
        my_action_last_round = history.my_actions[previous_round_idx]
        opponent_cooperators = cooperators_last_round
        if my_action_last_round:
            opponent_cooperators -= 1
        cooperation_rate = opponent_cooperators / (self.n - 1)
        viability_threshold = (self.n - self.k) / (self.n - 1)
        if cooperation_rate >= viability_threshold:
            if random.random() < cooperation_rate:
                return Action.C
            else:
                return Action.D
        elif cooperation_rate >= viability_threshold / 2:
            if random.random() < cooperation_rate / 2:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_172(BaseStrategy):
    """
    Adaptive Contribution Monitoring (ACM) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with individual rationality protection.
    Adaptively monitors group cooperation health and responds based on cooperation rates,
    with special handling for first and last rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold_high = 0.65
        self.threshold_low = 0.35
        self.defection_wave_threshold = -0.2
        self.last_round_coop_threshold = 0.6

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if self.k / self.n < 1:
            return Action.D
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            cooperation_rate = self._calculate_cooperation_rate(history, current_round)
            if cooperation_rate >= self.last_round_coop_threshold:
                return Action.C
            else:
                return Action.D
        cooperation_rate = self._calculate_cooperation_rate(history, current_round)
        if current_round >= 1:
            previous_coop_rate = self._calculate_cooperation_rate_excluding_last(history, current_round - 1)
            if cooperation_rate - previous_coop_rate < self.defection_wave_threshold:
                return Action.D
        if cooperation_rate >= self.threshold_high:
            return Action.C
        elif cooperation_rate < self.threshold_low:
            return Action.D
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate cooperation rate over recent history window.
        Window size is max(3, floor(r/2)).
        """
        window_size = max(3, math.floor(self.r / 2))
        start_round = max(0, current_round - window_size)
        if start_round >= current_round:
            return 0.0
        total_cooperation_actions = 0
        total_possible_actions = 0
        for round_idx in range(start_round, current_round):
            if history.my_actions[round_idx]:
                total_cooperation_actions += 1
            total_possible_actions += 1
            for opponent_idx in range(self.n - 1):
                if history.opponent_actions[round_idx, opponent_idx]:
                    total_cooperation_actions += 1
                total_possible_actions += 1
        if total_possible_actions == 0:
            return 0.0
        cooperation_rate = total_cooperation_actions / total_possible_actions
        return cooperation_rate

    def _calculate_cooperation_rate_excluding_last(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate cooperation rate excluding the last round (for detecting sudden drops).
        """
        window_size = max(3, math.floor(self.r / 2))
        start_round = max(0, current_round - window_size)
        if start_round >= current_round:
            return 0.0
        total_cooperation_actions = 0
        total_possible_actions = 0
        for round_idx in range(start_round, current_round):
            if history.my_actions[round_idx]:
                total_cooperation_actions += 1
            total_possible_actions += 1
            for opponent_idx in range(self.n - 1):
                if history.opponent_actions[round_idx, opponent_idx]:
                    total_cooperation_actions += 1
                total_possible_actions += 1
        if total_possible_actions == 0:
            return 0.0
        cooperation_rate = total_cooperation_actions / total_possible_actions
        return cooperation_rate

class Strategy_COLLECTIVE_173(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC): A collective strategy that balances
    individual rationality with collective welfare through conditional cooperation,
    adaptive thresholds, and proportional punishment of defection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.punishment_mode = False
        self.punishment_mode_rounds_left = 0
        self.last_cooperation_drop = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        cooperators_prev = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        cooperation_rate = cooperators_prev / self.n_players
        if current_round <= 2 and cooperation_rate < 0.5:
            self.punishment_mode = True
            self.punishment_mode_rounds_left = 2
            threshold = 0.9
        elif self.punishment_mode and self.punishment_mode_rounds_left > 0:
            self.punishment_mode_rounds_left -= 1
            threshold = 0.9
        else:
            self.punishment_mode = False
            if current_round >= 2:
                prev_prev_round_idx = current_round - 2
                cooperators_prev_prev = int(np.sum(history.opponent_actions[prev_prev_round_idx, :]))
                cooperation_rate_prev = cooperators_prev_prev / self.n_players
                if cooperation_rate_prev >= 0.7 and cooperation_rate <= 0.4:
                    self.last_cooperation_drop = True
                    return Action.D
            self.last_cooperation_drop = False
            threshold = max(0.33, 1.0 - current_round / (2.0 * self.n_rounds))
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_174(BaseStrategy):
    """
    Adaptive Reciprocal Threshold (ART) Strategy for N-Player Public Goods Game

    Balances collective value creation, self-protection, and adaptive learning.
    Uses threshold-based reciprocity sensitive to cooperation rates and temporal dynamics.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        total_cooperators = int(np.sum(history.opponent_actions[:current_round, :]))
        observed_coop_rate = total_cooperators / (self.n * current_round)
        if current_round == self.r - 1:
            threshold = 1.0 - self.k / self.n
            if observed_coop_rate > threshold:
                return Action.C
            else:
                return Action.D
        if current_round >= self.r - 2:
            rounds_remaining = self.r - current_round
            threshold_adjust = 0.15 * rounds_remaining
            threshold = (1.0 - self.k / self.n) * (1.0 - threshold_adjust)
            if observed_coop_rate > threshold:
                return Action.C
            else:
                return Action.D
        lookback = min(3, current_round)
        recent_cooperators = int(np.sum(history.opponent_actions[current_round - lookback:current_round, :]))
        recent_coop_rate = recent_cooperators / (self.n * lookback)
        adaptation_factor = min(0.3, current_round / (self.r * 2.0))
        coop_threshold = self.k / self.n - (1.0 - self.k / self.n) + adaptation_factor
        if recent_coop_rate < 0.3:
            return Action.D
        if recent_coop_rate > coop_threshold:
            return Action.C
        elif recent_coop_rate < coop_threshold * 0.6:
            return Action.D
        else:
            my_last_action = history.my_actions[current_round - 1]
            if my_last_action:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_175(BaseStrategy):
    """
    Adaptive Contribution Threshold (ACT) Strategy for N-Player Public Goods Game.

    Balances collective welfare with individual incentives through:
    - Round 1: Cooperate unconditionally (signal cooperativeness)
    - Final round: Defect unconditionally (subgame perfect equilibrium)
    - Middle rounds: Adaptive thresholds based on observed cooperation rates

    Thresholds scale with game parameters (k, n) to remain robust across different configurations.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.n_rounds - 1:
            return Action.D
        avg_cooperation = self._calculate_avg_cooperation(history, round_number)
        threshold_high = (self.k - 1) / (2 * self.k)
        threshold_mid = (self.k - 1) / (4 * self.k)
        threshold_low = 1 / (3 * self.n_players)
        if self.n_players == 2:
            return self._decide_two_player(avg_cooperation, threshold_mid)
        if avg_cooperation >= threshold_high:
            return Action.C
        elif avg_cooperation >= threshold_mid:
            if random.random() < 0.6:
                return Action.C
            else:
                return Action.D
        elif avg_cooperation >= threshold_low:
            return Action.D
        else:
            return Action.D

    def _calculate_avg_cooperation(self, history: PlayerHistory, round_number: int) -> float:
        """
        Calculate the average cooperation rate across all players in previous rounds.

        Args:
            history: PlayerHistory object containing actions from previous rounds
            round_number: Current round number (0-indexed)

        Returns:
            Float between 0 and 1 representing fraction of cooperative actions observed
        """
        my_past_actions = history.my_actions[:round_number]
        opponent_past_actions = history.opponent_actions[:round_number, :]
        my_cooperations = np.sum(my_past_actions)
        opponent_cooperations = np.sum(opponent_past_actions)
        total_cooperations = my_cooperations + opponent_cooperations
        total_possible = round_number * self.n_players
        if total_possible == 0:
            return 0.0
        avg_cooperation = total_cooperations / total_possible
        return float(avg_cooperation)

    def _decide_two_player(self, avg_cooperation: float, threshold_mid: float) -> Action:
        """
        Special decision logic for n=2 case, using simpler tit-for-tat variant.

        Args:
            avg_cooperation: Average cooperation rate from previous rounds
            threshold_mid: Middle threshold value

        Returns:
            Action.C or Action.D
        """
        if avg_cooperation >= threshold_mid:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_176(BaseStrategy):
    """
    Adaptive Threshold Cooperation with Decay (ATCD) Strategy

    A three-phase strategy for N-Player Public Goods Games that:
    1. Explores group cooperativeness in early rounds
    2. Adapts reciprocal cooperation based on observed thresholds
    3. Applies endgame defection in final rounds

    Balances collective welfare maximization with individual security against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num <= 2:
            if round_num == 0 or round_num == 1:
                return Action.C
            else:
                cooperation_rate = self._get_cooperation_rate(history, round_num - 1)
                threshold = self.k / self.n + 0.2
                if cooperation_rate >= threshold:
                    return Action.C
                else:
                    return Action.D
        if round_num >= self.r - 2:
            return Action.D
        cooperation_rate = self._get_cooperation_rate(history, round_num - 1)
        target_threshold = self.k / self.n + 0.15
        rounds_remaining = self.r - round_num
        effective_threshold = target_threshold - 0.05 * rounds_remaining / self.r
        if cooperation_rate >= effective_threshold:
            return Action.C
        else:
            return Action.D

    def _get_cooperation_rate(self, history: PlayerHistory, round_idx: int) -> float:
        """
        Calculate the cooperation rate in a given round.

        Args:
            history: PlayerHistory containing opponent actions
            round_idx: The round index to analyze

        Returns:
            Cooperation rate as a float between 0 and 1
        """
        if round_idx < 0 or round_idx >= history.opponent_actions.shape[0]:
            return 1.0
        cooperators_in_round = int(np.sum(history.opponent_actions[round_idx, :]))
        cooperation_rate = cooperators_in_round / self.n
        return cooperation_rate

class Strategy_COLLECTIVE_177(BaseStrategy):
    """
    Adaptive Graduated Response (AGR) Strategy for N-Player Public Goods Game.

    Balances collective value creation, robust defense against exploitation, and graceful recovery.
    - Round 1: Cooperate to establish cooperative signal
    - Rounds 2 to r-1: Cooperate if defection rate stays below adaptive threshold that tightens over time
    - Round r: Defect unless opponent maintained >75% cooperation rate
    - Special handling for unanimous cooperation, majority defection, and endgame scenarios
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.n_rounds - 1:
            total_cooperations = sum(history.my_actions[:-1])
            total_rounds_played = round_num
            cooperation_rate = total_cooperations / total_rounds_played if total_rounds_played > 0 else 0.0
            if cooperation_rate > 0.75:
                return Action.C
            else:
                return Action.D
        prev_round_idx = round_num - 1
        prev_cooperators_count = int(sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx] and prev_cooperators_count == self.n_players - 1:
            return Action.C
        n_other_players = self.n_players - 1
        defectors_count = n_other_players - prev_cooperators_count
        defection_rate = defectors_count / n_other_players if n_other_players > 0 else 0.0
        if defection_rate > 0.5:
            return Action.D
        threshold = math.ceil(0.5 + (self.n_rounds - round_num) / (2.0 * self.n_rounds))
        if defection_rate <= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_178(BaseStrategy):
    """
    Adaptive Contribution Equilibrium (ACE) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization, individual security, and adaptive responsiveness
    by contributing proportionally to observed reciprocation, with safety mechanisms against
    exploitation and cascading defection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            probe_prob = self.k / self.n
            return Action.C if random.random() < probe_prob else Action.D
        recent_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        recent_rate = recent_cooperators / self.n
        if round_number > 2:
            hist_rates = [int(np.sum(history.opponent_actions[t, :])) / self.n for t in range(round_number)]
            hist_rate = np.mean(hist_rates)
        else:
            hist_rate = recent_rate
        my_cumulative_payoff = np.sum(history.my_payoffs)
        max_possible_defect_payoff = round_number * 1.0
        deficit = max_possible_defect_payoff - my_cumulative_payoff
        deficit_threshold = self.r * 1.0 * 0.3
        if deficit > deficit_threshold:
            return Action.D
        if round_number == self.r - 1:
            if recent_rate > 2.0 / self.n:
                target_prob = recent_rate
            else:
                return Action.D
        else:
            target_prob = 0.7 * recent_rate + 0.3 * hist_rate
        if round_number >= 2:
            last_two_cooperators = [int(np.sum(history.opponent_actions[t, :])) for t in range(round_number - 1, round_number)]
            if all((c == 0 for c in last_two_cooperators)):
                return Action.D
        if round_number >= 3:
            last_three_rates = [int(np.sum(history.opponent_actions[t, :])) / self.n for t in range(round_number - 2, round_number)]
            if all((rate == 1.0 for rate in last_three_rates)):
                return Action.C
        if round_number >= 3:
            recent_rates = [int(np.sum(history.opponent_actions[t, :])) / self.n for t in range(max(0, round_number - 3), round_number)]
            if len(recent_rates) > 1:
                rate_std = np.std(recent_rates)
                if rate_std > 0.4:
                    target_prob = 0.5 * recent_rate + 0.5 * hist_rate
        target_prob = max(0.0, min(1.0, target_prob))
        return Action.C if random.random() < target_prob else Action.D

class Strategy_COLLECTIVE_179(BaseStrategy):
    """
    Dynamic Reciprocal Contribution (DRC): A learning-based conditional cooperation strategy
    that adapts to observed collective cooperation rates while defending against exploitation.

    Core approach:
    - Round 1: Cooperate to establish baseline
    - Middle rounds: Reciprocate based on recent cooperation rate and personal payoff
    - Final round: Conditional cooperation based on historical cooperation threshold
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.cooperation_target = self.k / self.n + 0.2
        self.defection_threshold = self.k / self.n * 0.3
        self.p_maintain = 0.95
        self.p_reciprocate = 0.7
        self.threshold_final = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            return self._final_round_decision(history)
        return self._middle_round_decision(history, round_num)

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """End-game logic: cooperate if historical cooperation exceeded threshold."""
        all_cooperators = np.sum(history.opponent_actions, axis=1)
        avg_cooperation = np.mean(all_cooperators) / self.n
        if avg_cooperation > self.threshold_final:
            return Action.C
        else:
            return Action.D

    def _middle_round_decision(self, history: PlayerHistory, round_num: int) -> Action:
        """Middle rounds: reciprocate based on cooperation rate and personal payoff."""
        cooperators_last_round = np.sum(history.opponent_actions[round_num - 1, :])
        recent_coop_rate = cooperators_last_round / self.n
        if recent_coop_rate >= self.cooperation_target:
            if random.random() < self.p_maintain:
                return Action.C
            else:
                return Action.D
        if recent_coop_rate < self.defection_threshold:
            return Action.D
        my_last_payoff = history.my_payoffs[round_num - 1]
        optimal_full_coop_payoff = self.k
        if my_last_payoff > optimal_full_coop_payoff * 0.8:
            if random.random() < self.p_reciprocate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_180(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC): A strategy that balances collective welfare
    maximization with individual resilience against exploitation. It uses dynamic
    thresholds based on cooperation rates to decide whether to cooperate or defect,
    with special handling for early rounds and the final round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        prev_round_idx = round_t - 1
        opponent_cooperators = sum(history.opponent_actions[prev_round_idx, :])
        my_cooperation = 1 if history.my_actions[prev_round_idx] else 0
        total_cooperators = opponent_cooperators + my_cooperation
        cooperation_rate = total_cooperators / self.n
        my_payoff = history.my_payoffs[prev_round_idx]
        all_payoffs = np.concatenate([np.array([history.my_payoffs[prev_round_idx]]), history.opponent_payoffs[prev_round_idx, :]])
        collective_avg = np.mean(all_payoffs)
        denominator = 1.0 - self.k / self.n
        if denominator > 0:
            threshold_high = self.k / self.n / denominator
        else:
            threshold_high = 0.5
        threshold_mid = threshold_high * 0.5
        sustainability_floor = 1.0
        if round_t <= 2:
            active_threshold = threshold_mid
        else:
            active_threshold = threshold_high
        increasing_trend = False
        if round_t >= 2 and round_t <= 3:
            if round_t == 2:
                coop_rate_prev = sum(history.opponent_actions[0, :]) + (1 if history.my_actions[0] else 0)
                coop_rate_prev = coop_rate_prev / self.n
                increasing_trend = cooperation_rate > coop_rate_prev
            elif round_t == 3:
                coop_rate_1 = sum(history.opponent_actions[0, :]) + (1 if history.my_actions[0] else 0)
                coop_rate_1 = coop_rate_1 / self.n
                coop_rate_2 = sum(history.opponent_actions[1, :]) + (1 if history.my_actions[1] else 0)
                coop_rate_2 = coop_rate_2 / self.n
                increasing_trend = cooperation_rate > coop_rate_2 and coop_rate_2 > coop_rate_1
        if cooperation_rate >= active_threshold:
            if my_payoff >= collective_avg * 0.9:
                return Action.C
            else:
                return Action.D
        elif cooperation_rate >= threshold_mid:
            if increasing_trend:
                return Action.C
            if my_payoff >= sustainability_floor:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D
        if round_t == self.r - 1:
            if cooperation_rate >= threshold_high and my_payoff >= collective_avg * 0.85:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_181(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with individual security by:
    - Always cooperating in round 1 to signal willingness
    - Comparing average historical cooperation rate to threshold (k/n)
    - Cooperating when collective welfare is sustainable, defecting when being exploited
    - Using stability buffers to prevent oscillation and allow recovery
    - Implementing corrective pulses for dramatic cooperation drops
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n_players
        self.last_cooperation_rate = None
        self.consecutive_increases = 0
        self.rounds_stable = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        total_cooperators = 0
        for round_idx in range(current_round):
            if history.my_actions[round_idx]:
                total_cooperators += 1
            total_cooperators += sum(history.opponent_actions[round_idx, :])
        total_player_rounds = self.n_players * current_round
        avg_contribution_rate = total_cooperators / total_player_rounds
        current_round_cooperators = int(history.my_actions[current_round - 1])
        current_round_cooperators += sum(history.opponent_actions[current_round - 1, :])
        current_cooperation_rate = current_round_cooperators / self.n_players
        if self.last_cooperation_rate is not None:
            rate_change = current_cooperation_rate - self.last_cooperation_rate
            if rate_change < -0.2:
                self.consecutive_increases = 0
                self.rounds_stable = 0
                self.last_cooperation_rate = current_cooperation_rate
                return Action.D
            if rate_change > 0:
                self.consecutive_increases += 1
            else:
                self.consecutive_increases = 0
            if abs(rate_change) < 0.05:
                self.rounds_stable += 1
            else:
                self.rounds_stable = 0
        self.last_cooperation_rate = current_cooperation_rate
        if self.consecutive_increases >= 2:
            stability_buffer = 0.0
        elif current_cooperation_rate < 0.5:
            stability_buffer = 0.15
        elif self.rounds_stable >= 3:
            stability_buffer = 0.05
        else:
            stability_buffer = 0.1
        effective_threshold = self.threshold * (1.0 + stability_buffer)
        if avg_contribution_rate >= effective_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_182(BaseStrategy):
    """
    Adaptive Collective Strategy: "Conditional Reciprocal Contribution"

    Balances collective welfare maximization, resilience against exploitation,
    and adaptive learning by adjusting cooperation probability based on observed
    cooperation rates in the population.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.p_initial = 0.75
        self.p_high = 0.8
        self.p_low = 0.3
        self.final_round_discount = 0.6
        self.threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return self._cooperate_with_probability(self.p_initial)
        all_actions = np.concatenate([history.my_actions[:state.round_number, np.newaxis], history.opponent_actions[:state.round_number, :]], axis=1)
        total_cooperators = np.sum(all_actions)
        total_actions = self.game_description.n_players * state.round_number
        cooperation_rate = total_cooperators / total_actions
        if cooperation_rate >= self.threshold:
            base_probability = self.p_high
        else:
            base_probability = self.p_low
        if state.round_number == self.game_description.n_rounds - 1:
            base_probability = base_probability * self.final_round_discount
        return self._cooperate_with_probability(base_probability)

    def _cooperate_with_probability(self, p: float) -> Action:
        """
        Helper method to return COOPERATE with probability p, DEFECT otherwise.
        """
        random_value = random.random()
        if random_value < p:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_183(BaseStrategy):
    """
    Adaptive Reciprocal Maximization (ARM) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare through adaptive reciprocity.
    - Round 1: Unconditional cooperation (credibility signal)
    - Rounds 2 to r-1: Cooperate if observed cooperation rate exceeds dynamic threshold
    - Final round: Cooperate if observed cooperation rate exceeds base threshold

    Threshold decays over time to reflect diminishing returns in later rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.base_threshold = (self.k - 1) / self.n_players
        self.decay_factor = 0.15

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        cooperators_prev_round = np.sum(history.opponent_actions[prev_round_idx, :])
        cooperation_rate = cooperators_prev_round / self.n_players
        if current_round == self.n_rounds - 1:
            threshold = self.base_threshold
        else:
            time_fraction = current_round / self.n_rounds
            threshold = self.base_threshold + self.decay_factor * time_fraction
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_184(BaseStrategy):
    """
    Adaptive Collective Strategy: "Reciprocal Threshold"

    Balances collective welfare maximization with individual resilience through
    conditional cooperation with dynamic thresholds. Uses three phases:
    1. Exploration (rounds 0-2): Always cooperate to gather information
    2. Calibration (rounds 3 to r-3): Conditional cooperation based on observed cooperation rate
    3. End-game (final 2 rounds): Defect if cooperation unsustainable, else cooperate
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.cooperation_threshold = self.k / self.n_players
        self.cooperation_history = []

    def _calculate_weighted_cooperation_rate(self, history: PlayerHistory) -> float:
        """
        Calculate weighted average cooperation rate from history.
        Recent rounds weighted more heavily (decay_factor=0.7).
        """
        if len(self.cooperation_history) == 0:
            return 0.0
        weighted_sum = 0.0
        weight_sum = 0.0
        decay_factor = 0.7
        for i, coop_rate in enumerate(self.cooperation_history):
            weight = decay_factor ** (len(self.cooperation_history) - 1 - i)
            weighted_sum += coop_rate * weight
            weight_sum += weight
        if weight_sum == 0:
            return 0.0
        return weighted_sum / weight_sum

    def _detect_trend(self) -> str:
        """
        Detect if cooperation rate is trending up or down over last 3 rounds.
        Returns 'up', 'down', or 'stable'.
        """
        if len(self.cooperation_history) < 3:
            return 'stable'
        recent = self.cooperation_history[-3:]
        if recent[2] > recent[1] > recent[0]:
            return 'up'
        elif recent[2] < recent[1] < recent[0]:
            return 'down'
        return 'stable'

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round <= 2:
            if history is not None:
                cooperators_this_round = int(sum(history.opponent_actions[current_round - 1, :]))
                coop_rate = cooperators_this_round / self.n_players
                self.cooperation_history.append(coop_rate)
            return Action.C
        if history is not None:
            cooperators_this_round = int(sum(history.opponent_actions[current_round - 1, :]))
            coop_rate = cooperators_this_round / self.n_players
            self.cooperation_history.append(coop_rate)
        observed_coop_rate = self._calculate_weighted_cooperation_rate(history)
        effective_threshold = self.cooperation_threshold
        if self.n_players == 2:
            effective_threshold = min(self.cooperation_threshold, 0.6)
        if current_round > self.n_rounds - 3:
            if observed_coop_rate >= effective_threshold:
                return Action.C
            else:
                return Action.D
        if observed_coop_rate >= effective_threshold:
            return Action.C
        else:
            p_cooperate = observed_coop_rate / effective_threshold if effective_threshold > 0 else 0.0
            p_cooperate = min(p_cooperate, 1.0)
            trend = self._detect_trend()
            if trend == 'down':
                p_cooperate *= 0.9
            elif trend == 'up':
                p_cooperate += 0.05 * (1.0 - p_cooperate)
            p_cooperate = min(max(p_cooperate, 0.0), 1.0)
            if random.random() < p_cooperate:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_185(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare, self-protection, and robustness through adaptive reciprocity.
    - Round 0: Cooperate (establish baseline)
    - Rounds 1 to r-2: Cooperate if cooperation_rate >= k/n, else defect
    - Round r-1: Defect (final round, no future to influence)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.n_rounds - 1:
            return Action.D
        last_round_opponent_actions = history.opponent_actions[round_number - 1, :]
        my_last_action = history.my_actions[round_number - 1]
        cooperators_last_round = int(my_last_action) + int(np.sum(last_round_opponent_actions))
        cooperation_rate = cooperators_last_round / self.n_players
        if cooperation_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_186(BaseStrategy):
    """
    Adaptive Collective Strategy for N-Player Public Goods Game.

    Uses conditional cooperation with adaptive thresholds based on:
    - Structural sustainability (base threshold from game parameters)
    - Time pressure (square-root discounting of rounds remaining)
    - Defection momentum (trend analysis to detect acceleration/deceleration)

    Special handling for:
    - Round 1: Unconditional cooperation
    - Final round: Defection (except n=2 with high opponent cooperation)
    - Early rounds: Threshold relaxation for exploration
    - Penultimate round: Threshold tightening for deterrence
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            if self.n == 2:
                opponent_coop_rate = self._calculate_opponent_cooperation_rate(history)
                if opponent_coop_rate > 0.8:
                    return Action.C
            return Action.D
        cooperation_threshold = self._calculate_threshold(current_round, history)
        defection_rate = self._calculate_defection_rate(history)
        cooperation_confidence = 1.0 - defection_rate
        if cooperation_confidence >= cooperation_threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_opponent_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate proportion of rounds where opponent(s) cooperated on average."""
        if len(history.opponent_actions) == 0:
            return 1.0
        all_opponent_actions = history.opponent_actions.flatten()
        if len(all_opponent_actions) == 0:
            return 1.0
        return float(np.mean(all_opponent_actions))

    def _calculate_defection_rate(self, history: PlayerHistory) -> float:
        """Calculate proportion of opponents who defected in the most recent round."""
        if len(history.opponent_actions) == 0:
            return 0.0
        last_round_actions = history.opponent_actions[-1, :]
        defections = np.sum(last_round_actions == 0)
        return float(defections) / float(len(last_round_actions))

    def _calculate_threshold(self, current_round: int, history: PlayerHistory) -> float:
        """
        Calculate adaptive cooperation threshold based on:
        - Base threshold from game structure
        - Time discount factor
        - Defection momentum
        - Phase adjustments (exploration, penultimate)
        """
        base_threshold = (self.n - self.k) / self.n
        rounds_remaining = self.r - current_round
        time_discount = math.sqrt(float(rounds_remaining) / float(self.r))
        momentum_factor = self._calculate_momentum_factor(current_round, history)
        threshold = base_threshold * time_discount * (1.0 + momentum_factor)
        if current_round <= 2:
            threshold += 0.15
        if current_round == self.r - 2:
            threshold -= 0.1
        threshold = max(0.1, min(0.9, threshold))
        return threshold

    def _calculate_momentum_factor(self, current_round: int, history: PlayerHistory) -> float:
        """
        Analyze defection trend:
        - If defection accelerating: return -0.2 (stricter)
        - If cooperation strengthening: return +0.15 (more lenient)
        - Otherwise: return 0 (stable)
        """
        if current_round <= 2:
            return 0.0
        recent_defections = []
        historical_defections = []
        if len(history.opponent_actions) >= 1:
            defection_rate_last = self._get_defection_rate_at_round(history, -1)
            recent_defections.append(defection_rate_last)
        if len(history.opponent_actions) >= 2:
            defection_rate_second_last = self._get_defection_rate_at_round(history, -2)
            recent_defections.append(defection_rate_second_last)
        for i in range(len(history.opponent_actions) - 2):
            historical_defections.append(self._get_defection_rate_at_round(history, i))
        if len(recent_defections) == 0 or len(historical_defections) == 0:
            return 0.0
        recent_avg = float(np.mean(recent_defections))
        historical_avg = float(np.mean(historical_defections))
        if recent_avg > historical_avg + 0.15:
            return -0.2
        elif recent_avg < historical_avg - 0.1:
            return 0.15
        else:
            return 0.0

    def _get_defection_rate_at_round(self, history: PlayerHistory, round_index: int) -> float:
        """Get defection rate for a specific round (supports negative indexing)."""
        if round_index < -len(history.opponent_actions) or round_index >= len(history.opponent_actions):
            return 0.0
        actions = history.opponent_actions[round_index, :]
        defections = np.sum(actions == 0)
        return float(defections) / float(len(actions))

class Strategy_COLLECTIVE_187(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization, individual sustainability, and adaptive learning.
    Uses threshold-based reciprocity with stochastic engagement at intermediate cooperation rates,
    defection acceleration detection, and stagnation recovery mechanisms.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_history = []
        self.defection_acceleration_cooldown = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        if round_num == 0:
            return Action.C
        prev_round_idx = round_num - 1
        total_cooperators = int(sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            total_cooperators += 1
        coop_rate_prev = total_cooperators / n
        self.cooperation_history.append(coop_rate_prev)
        threshold = max(k / n, 0.4)
        if self.defection_acceleration_cooldown > 0:
            self.defection_acceleration_cooldown -= 1
            if self.defection_acceleration_cooldown == 0:
                pass
            else:
                return Action.D
        if len(self.cooperation_history) >= 2:
            prev_prev_coop = self.cooperation_history[-2]
            acceleration = coop_rate_prev - prev_prev_coop
            if acceleration < -0.2:
                self.defection_acceleration_cooldown = 2
                return Action.D
        if total_cooperators <= 2 and n >= 6:
            return Action.D
        if len(self.cooperation_history) >= 3:
            recent_rates = self.cooperation_history[-3:]
            if all((rate < 0.3 for rate in recent_rates)):
                if max(recent_rates) - min(recent_rates) < 0.05:
                    return Action.C
        if round_num == r - 1:
            if coop_rate_prev >= threshold:
                return Action.C
            else:
                return Action.D
        if coop_rate_prev >= threshold:
            return Action.C
        elif coop_rate_prev >= threshold * 0.5:
            prob_cooperate = coop_rate_prev / threshold
            if random.random() < prob_cooperate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_188(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy

    Balances individual rationality with collective welfare through adaptive reciprocity.
    Uses a graduated response based on observed cooperation rate relative to the threshold 1/k,
    with special handling for first round (cooperate), final round (defect), and early-game exploration.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = 1.0 / game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        if round_number == 0:
            return Action.C
        total_cooperators = 0
        for round_idx in range(round_number):
            total_cooperators += np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += int(history.my_actions[round_idx])
        total_player_rounds = n * round_number
        cooperation_rate = total_cooperators / total_player_rounds
        if round_number == r - 1:
            return Action.D
        if round_number == r - 2:
            if cooperation_rate >= self.threshold:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= self.threshold:
            return Action.C
        elif round_number <= 3 and random.random() < 0.2:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_189(BaseStrategy):
    """
    Adaptive Reciprocal Threshold (ART) strategy for N-Player Public Goods Game.

    Balances collective welfare with individual security through adaptive contribution
    decisions based on observed cooperation rates and game phase.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.n_rounds - 1:
            return Action.D
        prev_round_opponent_actions = history.opponent_actions[round_num - 1, :]
        prev_round_cooperators = int(np.sum(prev_round_opponent_actions))
        if history.my_actions[round_num - 1]:
            prev_round_cooperators += 1
        total_cooperators = prev_round_cooperators
        cooperation_rate = total_cooperators / self.n_players
        efficiency_threshold = self.k / self.n_players
        if cooperation_rate >= efficiency_threshold:
            return Action.C
        elif cooperation_rate >= 0.5:
            if random.random() < cooperation_rate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_190(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game.

    This strategy implements conditional cooperation with an adaptive threshold that
    responds to observed cooperation rates. It balances reciprocity with prudence,
    cooperating when aggregate cooperation justifies it, while protecting against
    exploitation in low-cooperation environments.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        prev_cooperators = int(sum(history.opponent_actions[prev_round_idx, :]))
        my_prev_action = history.my_actions[prev_round_idx]
        total_prev_cooperators = prev_cooperators + (1 if my_prev_action else 0)
        prev_coop_rate = total_prev_cooperators / self.n
        if current_round == self.r - 1:
            if prev_coop_rate >= 0.5:
                return Action.C
            else:
                return Action.D
        base_threshold = self.k / self.n - 0.1
        if current_round == 1 and prev_coop_rate < 0.3:
            base_threshold = self.k / self.n - 0.2
        if current_round >= 2:
            round_2_idx = current_round - 2
            prev_prev_cooperators = int(sum(history.opponent_actions[round_2_idx, :]))
            prev_prev_my_action = history.my_actions[round_2_idx]
            total_prev_prev_cooperators = prev_prev_cooperators + (1 if prev_prev_my_action else 0)
            prev_prev_coop_rate = total_prev_prev_cooperators / self.n
            coop_drop = prev_prev_coop_rate - prev_coop_rate
            if coop_drop > 0.3:
                base_threshold = 0.6
        if current_round >= 2:
            increasing = True
            for i in range(current_round - 2, max(current_round - 4, 0), -1):
                if i + 1 < current_round:
                    cooperators_i = int(sum(history.opponent_actions[i, :])) + (1 if history.my_actions[i] else 0)
                    cooperators_i1 = int(sum(history.opponent_actions[i + 1, :])) + (1 if history.my_actions[i + 1] else 0)
                    coop_rate_i = cooperators_i / self.n
                    coop_rate_i1 = cooperators_i1 / self.n
                    if coop_rate_i1 <= coop_rate_i:
                        increasing = False
                        break
            if increasing and current_round >= 2:
                base_threshold = max(self.k / self.n - 0.2, base_threshold - 0.05)
        if current_round >= self.r - 2:
            base_threshold = max(0.5, base_threshold)
        if prev_coop_rate < base_threshold:
            return Action.D
        remaining_rounds = self.r - current_round
        expected_payoff_coop = remaining_rounds * self._expected_payoff_given_coop(prev_coop_rate)
        expected_payoff_defect = remaining_rounds * (1 + prev_coop_rate * (self.k / self.n))
        if current_round >= self.r - 2:
            expected_payoff_coop *= 0.9
        if expected_payoff_coop > expected_payoff_defect:
            return Action.C
        else:
            return Action.D

    def _expected_payoff_given_coop(self, coop_rate: float) -> float:
        """
        Calculate expected payoff if we cooperate, given observed cooperation rate.

        Assumes others continue at same rate.
        """
        expected_total_cooperators = 1 + (self.n - 1) * coop_rate
        payoff = self.k / self.n * expected_total_cooperators
        return payoff

class Strategy_COLLECTIVE_191(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game

    Balances collective welfare with individual rationality through:
    - Phase-dependent cooperation thresholds
    - Recent cooperation rate monitoring
    - Benefit-cost analysis
    - Collapse detection and recovery
    - Adaptive decision-making based on group dynamics
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        phase = round_t / self.r
        if phase < 0.2:
            cooperation_threshold = 0.3
        elif phase < 0.8:
            cooperation_threshold = 0.5
        else:
            cooperation_threshold = 0.6
        m = max(3, math.ceil(self.r / 4))
        recent_rounds = min(m, round_t)
        recent_coop_rate = self._calculate_recent_cooperation_rate(history, round_t, recent_rounds)
        moving_avg_coop = self._calculate_moving_average(history, round_t)
        has_collapse = self._has_sudden_collapse(history, round_t)
        if has_collapse:
            can_recover = self._can_recover(history, round_t)
            if not can_recover:
                return Action.D
            cooperation_threshold = min(cooperation_threshold, 0.4)
        anticipated_cooperators = recent_coop_rate * self.n
        benefit_threshold = self.n - self.k
        if recent_coop_rate >= cooperation_threshold:
            if anticipated_cooperators > benefit_threshold:
                return Action.C
            else:
                return Action.D
        elif random.random() < recent_coop_rate:
            return Action.C
        else:
            return Action.D

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory, round_t: int, recent_rounds: int) -> float:
        """Calculate proportion of cooperators across recent rounds"""
        if round_t == 0:
            return 0.0
        start_idx = max(0, round_t - recent_rounds)
        end_idx = round_t
        total_cooperations = 0
        total_slots = 0
        for r in range(start_idx, end_idx):
            total_cooperations += np.sum(history.opponent_actions[r, :])
            total_slots += self.n - 1
            if history.my_actions[r]:
                total_cooperations += 1
            total_slots += 1
        if total_slots == 0:
            return 0.0
        return total_cooperations / total_slots

    def _calculate_moving_average(self, history: PlayerHistory, round_t: int) -> float:
        """Calculate moving average cooperation rate across all history"""
        if round_t == 0:
            return 0.0
        total_cooperations = 0
        total_slots = 0
        for r in range(round_t):
            total_cooperations += np.sum(history.opponent_actions[r, :])
            total_slots += self.n - 1
            if history.my_actions[r]:
                total_cooperations += 1
            total_slots += 1
        if total_slots == 0:
            return 0.0
        return total_cooperations / total_slots

    def _has_sudden_collapse(self, history: PlayerHistory, round_t: int) -> bool:
        """Detect if cooperation rate dropped sharply (>40% drop)"""
        if round_t < 2:
            return False
        last_round_coop = (np.sum(history.opponent_actions[round_t - 1, :]) + (1 if history.my_actions[round_t - 1] else 0)) / self.n
        if round_t == 1:
            prev_avg = 1.0
        else:
            prev_coop = 0
            for r in range(round_t - 1):
                prev_coop += np.sum(history.opponent_actions[r, :]) + (1 if history.my_actions[r] else 0)
            prev_avg = prev_coop / ((round_t - 1) * self.n)
        drop = prev_avg - last_round_coop
        return drop > 0.4 * prev_avg if prev_avg > 0 else False

    def _can_recover(self, history: PlayerHistory, round_t: int) -> bool:
        """Check if cooperation can recover after collapse"""
        if round_t < 4:
            return True
        recent_rates = []
        for r in range(max(0, round_t - 3), round_t):
            coop_count = np.sum(history.opponent_actions[r, :]) + (1 if history.my_actions[r] else 0)
            recent_rates.append(coop_count / self.n)
        if len(recent_rates) >= 2:
            return recent_rates[-1] >= recent_rates[0]
        return True

class Strategy_COLLECTIVE_192(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare by:
    1. Cooperating in round 1 to establish baseline
    2. Using adaptive threshold based on opponent cooperation rates
    3. Maintaining rolling window memory to allow recovery from transient defection
    4. Applying consistent rules including final round to avoid exploitation
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.k = game_description.k
        self.n_rounds = game_description.n_rounds
        self.threshold = max(0.3, (self.k - 1.0) / self.k)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        window_size = min(5, round_num)
        recent_rounds_start = round_num - window_size
        recent_opponent_actions = history.opponent_actions[recent_rounds_start:round_num, :]
        cooperators_per_round = np.sum(recent_opponent_actions, axis=1)
        total_cooperators = np.sum(cooperators_per_round)
        total_opponent_slots = window_size * (self.n_players - 1)
        opponent_coop_rate = total_cooperators / total_opponent_slots if total_opponent_slots > 0 else 0.0
        if opponent_coop_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_193(BaseStrategy):
    """
    Adaptive Reciprocal Maximization (ARM) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare through conditional cooperation,
    dynamic thresholding, forgiveness mechanisms, and exploitation detection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_history = []
        self.exploitation_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        t = state.round_number
        if t == 0:
            self.cooperation_history.append(1.0)
            return Action.C
        prev_cooperators = np.sum(history.opponent_actions[t - 1, :])
        coop_rate_prev = prev_cooperators / n
        window_size = min(4, t)
        window_start = max(0, t - window_size)
        recent_coop_rates = self.cooperation_history[window_start:t]
        recent_avg = np.mean(recent_coop_rates) if recent_coop_rates else coop_rate_prev
        time_remaining = r - t
        base_threshold = 0.5 + 0.15 * (time_remaining / r)
        threshold = max(0.3, min(0.9, base_threshold))
        if recent_avg > coop_rate_prev and recent_avg > 0:
            threshold -= 0.1
        last_round_defection_payoff = 1.0 + k / n * prev_cooperators
        last_round_cooperation_payoff = k / n * prev_cooperators
        exploitation_gap = last_round_defection_payoff - last_round_cooperation_payoff
        if exploitation_gap > k / n:
            self.exploitation_streak += 1
            if self.exploitation_streak >= 3:
                threshold -= 0.15
        else:
            self.exploitation_streak = 0
        if t >= 2 and len(self.cooperation_history) >= 2:
            prev_prev_rate = self.cooperation_history[-2]
            if coop_rate_prev - prev_prev_rate > 0.4:
                threshold += 0.1
        if t == 2 and recent_avg < 0.3:
            threshold -= 0.15
        if t == r - 1:
            if t >= 3:
                prev_three = self.cooperation_history[max(0, t - 3):t]
                if all((rate == 0 for rate in prev_three)):
                    self.cooperation_history.append(coop_rate_prev)
                    return Action.D
            threshold = max(0.4, threshold - 0.15)
        action = Action.C if coop_rate_prev >= threshold else Action.D
        self.cooperation_history.append(coop_rate_prev)
        return action

class Strategy_COLLECTIVE_194(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare through three phases:
    - Exploration: Signal willingness to cooperate and gather information
    - Calibration: Dynamically adjust contribution based on observed cooperation
    - Optimization: Maximize payoff given empirical patterns
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == 1:
            return Action.C
        exploration_end = max(2, math.floor(self.r / 6))
        calibration_end = math.floor(4 * self.r / 5)
        if current_round <= exploration_end:
            return self._exploration_phase(current_round, history)
        elif current_round <= calibration_end:
            return self._calibration_phase(current_round, history)
        else:
            return self._optimization_phase(current_round, history)

    def _exploration_phase(self, current_round: int, history: PlayerHistory) -> Action:
        """
        Exploration phase: Cooperate if average cooperation rate >= 1/3.
        """
        prev_rounds = history.opponent_actions[:current_round]
        total_cooperators = np.sum(prev_rounds)
        total_possible = current_round * self.n
        avg_coop_rate = total_cooperators / total_possible if total_possible > 0 else 0
        if avg_coop_rate >= 1 / 3:
            return Action.C
        else:
            return Action.D

    def _calibration_phase(self, current_round: int, history: PlayerHistory) -> Action:
        """
        Calibration phase: Use tit-for-tat with adaptive threshold.
        """
        num_recent = min(3, current_round)
        recent_start = current_round - num_recent
        recent_rounds = history.opponent_actions[recent_start:current_round]
        total_recent_cooperators = np.sum(recent_rounds)
        total_recent_possible = num_recent * self.n
        avg_cooperation_rate = total_recent_cooperators / total_recent_possible
        my_recent_cooperations = np.sum(history.my_actions[recent_start:current_round])
        my_cooperation_rate = my_recent_cooperations / num_recent if num_recent > 0 else 0
        threshold_k_n = self.k / self.n
        if avg_cooperation_rate >= threshold_k_n:
            cooperate_threshold = min(0.5, avg_cooperation_rate + 0.1)
        else:
            cooperate_threshold = avg_cooperation_rate + 0.15
        if avg_cooperation_rate >= cooperate_threshold:
            return Action.C
        else:
            return Action.D

    def _optimization_phase(self, current_round: int, history: PlayerHistory) -> Action:
        """
        Optimization phase: Maximize payoff given empirical cooperation patterns.
        """
        all_rounds = history.opponent_actions[:current_round]
        total_cooperators_ever = np.sum(all_rounds)
        total_possible_ever = current_round * self.n
        cumulative_cooperation_rate = total_cooperators_ever / total_possible_ever if total_possible_ever > 0 else 0
        net_coop_advantage = self.k * cumulative_cooperation_rate - 1
        if net_coop_advantage > -0.2:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_196(BaseStrategy):
    """
    Adaptive Conditional Cooperator with Decay (ACCD) Strategy for N-Player Public Goods Game.

    This strategy seeks to maximize collective welfare while protecting against exploitation.
    It cooperates in round 1, then conditions cooperation on the population cooperation rate
    relative to a dynamic threshold that increases as the game approaches its end.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        previous_round_idx = round_number - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[previous_round_idx, :]))
        my_action_last_round = history.my_actions[previous_round_idx]
        if my_action_last_round:
            cooperators_last_round += 1
        cooperation_rate = cooperators_last_round / self.n
        base_threshold = self.k / self.n
        decay_factor = (1.0 - self.k / self.n) * 0.4
        if round_number == self.r - 1:
            threshold = base_threshold
        else:
            threshold = base_threshold + decay_factor * (round_number / self.r)
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_197(BaseStrategy):
    """
    Conditional Reciprocal Equilibrium (CRE) Strategy for N-Player Public Goods Game.

    A balanced strategy that:
    1. Cooperates initially to signal good faith
    2. Adapts based on observed cooperation rates in intermediate rounds
    3. Makes final-round decisions based on sustained cooperation levels

    Uses thresholds derived from game parameters (k, n) to determine when cooperation
    is individually rational given the public good multiplier.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold_1 = (self.k - 1) / (self.k * self.n_players) + 0.1
        if self.n_players > 1:
            self.threshold_2 = self.k / (self.n_players * (self.n_players - 1))
        else:
            self.threshold_2 = 0.0
        self.prev_cooperation_rate = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        last_round_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        cooperation_rate = last_round_cooperators / self.n_players
        is_final_round = round_num == self.n_rounds - 1
        if is_final_round:
            if cooperation_rate >= self.threshold_1:
                return Action.C
            else:
                return Action.D
        else:
            if self.prev_cooperation_rate is not None:
                cooperation_drop = self.prev_cooperation_rate - cooperation_rate
                if cooperation_drop > 0.3 and history.my_actions[-1]:
                    self.prev_cooperation_rate = cooperation_rate
                    return Action.D
            self.prev_cooperation_rate = cooperation_rate
            if cooperation_rate >= self.threshold_1:
                return Action.C
            elif cooperation_rate >= self.threshold_2:
                if random.random() < cooperation_rate:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D

class Strategy_COLLECTIVE_198(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Operates on conditional collective contribution: cooperate when conditions suggest
    the public good will reach a beneficial threshold, defect when unlikely.
    Tracks historical cooperation rates, recent trends, and remaining rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            return Action.D
        return self._adaptive_decision(round_num, history)

    def _adaptive_decision(self, round_num: int, history: PlayerHistory) -> Action:
        """Determine action based on cooperation patterns and trends."""
        threshold = math.ceil(self.n / self.k)
        threshold_ratio = threshold / self.n
        rounds_completed = round_num
        lookback = min(3, rounds_completed)
        recent_rounds = rounds_completed - lookback
        recent_cooperators = 0
        for r in range(recent_rounds, rounds_completed):
            recent_cooperators += int(np.sum(history.opponent_actions[r, :]))
        recent_coop_rate = recent_cooperators / (lookback * self.n)
        if rounds_completed > lookback:
            historical_cooperators = 0
            for r in range(0, recent_rounds):
                historical_cooperators += int(np.sum(history.opponent_actions[r, :]))
            historical_coop_rate = historical_cooperators / (recent_rounds * self.n)
        else:
            historical_coop_rate = recent_coop_rate
        trend = recent_coop_rate - historical_coop_rate
        adjusted_threshold_ratio = threshold_ratio
        if self.n >= 10:
            adjusted_threshold_ratio *= 1.2
        if self.k < 1.5:
            adjusted_threshold_ratio *= 1.3
        if self.n == 2:
            if recent_coop_rate > 0.75:
                return Action.C
            else:
                return Action.D
        if recent_coop_rate == 0 and rounds_completed >= 2:
            return Action.D
        if recent_coop_rate == 1.0:
            return Action.C
        rounds_remaining = self.r - round_num - 1
        if recent_coop_rate >= adjusted_threshold_ratio or trend > 0.1:
            return Action.C
        if recent_coop_rate >= adjusted_threshold_ratio * 0.75 and rounds_remaining >= 3:
            return Action.C
        if recent_coop_rate < adjusted_threshold_ratio * 0.5:
            return Action.D
        baseline = adjusted_threshold_ratio * 0.5
        if baseline >= 1.0:
            cooperation_prob = 0.0
        else:
            cooperation_prob = (recent_coop_rate - baseline) / (1.0 - baseline)
        cooperation_prob = max(0.0, min(1.0, cooperation_prob))
        if random.random() < cooperation_prob:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_199(BaseStrategy):
    """
    Adaptive Reciprocal Maximization (ARM) Strategy for N-Player Public Goods Game

    Balances individual resilience with collective welfare through conditional cooperation.
    - Round 1: Cooperate (optimistic initialization)
    - Rounds 2 to r: Adapt based on cooperation rate vs. adaptive threshold
    - Uses threshold = (1 + 0.15) / k, adjusted for small groups and edge cases
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.epsilon = 0.15
        self.boundary_tolerance = 0.02
        self.small_group_adjustment = 0.95
        self.consecutive_defection_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        n = self.game_description.n_players
        k = self.game_description.k
        prev_round_opponent_actions = history.opponent_actions[state.round_number - 1, :]
        prev_round_cooperators = int(np.sum(prev_round_opponent_actions))
        if history.my_actions[state.round_number - 1]:
            prev_round_cooperators += 1
        coop_rate = prev_round_cooperators / n
        threshold = (1.0 + self.epsilon) / k
        if n <= 3:
            threshold = threshold * self.small_group_adjustment
        if coop_rate >= 1.0 - 1e-09:
            return Action.C
        if coop_rate < 1e-09:
            if state.round_number >= 2:
                prev_prev_round_opponent_actions = history.opponent_actions[state.round_number - 2, :]
                prev_prev_round_cooperators = int(np.sum(prev_prev_round_opponent_actions))
                if history.my_actions[state.round_number - 2]:
                    prev_prev_round_cooperators += 1
                prev_prev_coop_rate = prev_prev_round_cooperators / n
                if prev_prev_coop_rate < 1e-09:
                    self.consecutive_defection_rounds += 1
                    if self.consecutive_defection_rounds >= 2:
                        return Action.D
            else:
                self.consecutive_defection_rounds += 1
        else:
            self.consecutive_defection_rounds = 0
        if abs(coop_rate - threshold) < self.boundary_tolerance:
            return Action.C
        if coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_200(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy

    Balances collective welfare maximization, individual rationality, and robustness
    through threshold-based reciprocal cooperation in n-player public goods games.

    Decision rule:
    - Round 1: Always cooperate (signal intent, gather information)
    - Final round: Cooperate if previous cooperation rate >= k/n, else defect
    - Middle rounds: Cooperate if previous cooperation rate >= k/n, else defect
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        previous_round_cooperators = sum(history.opponent_actions[-1, :])
        my_previous_action = history.my_actions[-1]
        total_previous_cooperators = previous_round_cooperators + (1 if my_previous_action else 0)
        cooperation_rate = total_previous_cooperators / self.n_players
        critical_threshold = self.k / self.n_players
        if round_number == self.n_rounds - 1:
            if cooperation_rate >= critical_threshold:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= critical_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_201(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game

    Balances collective welfare against exploitation risk by:
    1. Rewarding cooperation when it benefits the group
    2. Punishing defection when it undermines collective value
    3. Adapting dynamically to opponent behavior patterns
    4. Maximizing total group payoff as primary objective

    Uses a mathematically-grounded adaptive threshold based on the multiplication
    factor k to determine when cooperation is individually rational.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        cooperators_last_round = np.sum(history.opponent_actions[-1, :])
        coop_rate_last = cooperators_last_round / self.n_players
        self.cooperation_history.append(coop_rate_last)
        history_window = min(5, len(self.cooperation_history))
        coop_rate_avg = np.mean(self.cooperation_history[-history_window:])
        if coop_rate_avg > 0.8 and len(self.cooperation_history) >= 2:
            return Action.C
        base_threshold = (self.k - 1) / self.k
        decay_bonus = min(0.15, 0.05 * (round_number / self.n_rounds))
        exploitation_buffer = 0.1 if coop_rate_avg < 0.3 else 0.0
        threshold = base_threshold - decay_bonus + exploitation_buffer
        if len(self.cooperation_history) >= 3:
            recent_coop_avg = np.mean(self.cooperation_history[-3:])
            recent_payoffs = history.my_payoffs[-3:]
            recent_payoff_avg = np.mean(recent_payoffs)
            if recent_coop_avg < 0.25 and recent_payoff_avg < 1.2:
                return Action.D
        if coop_rate_last >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_202(BaseStrategy):
    """
    Adaptive Reciprocal Threshold (ART) Strategy for N-Player Public Goods Game

    Balances collective welfare optimization with robust individual incentive alignment.
    Uses dynamic threshold-based reciprocity to earn and reward cooperation while
    maintaining a credible deterrent against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.base_threshold = (self.k - 1) / (2 * self.k)
        self.alpha = 0.15

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round_idx = state.round_number - 1
        cooperators_prev = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            cooperators_prev += 1
        coop_rate = cooperators_prev / self.n
        time_decay = self.alpha * (1 - prev_round_idx / self.r)
        threshold = self.base_threshold + time_decay
        if state.round_number == self.r - 1:
            threshold = self.base_threshold * 0.8
        if coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_203(BaseStrategy):
    """
    Adaptive Contribution with Defection Threshold Strategy for N-Player Public Goods Game.

    Balances collective welfare with individual protection against exploitation by:
    - Cooperating unconditionally in round 1 to establish cooperative signal
    - Tracking average cooperation rate across all past rounds
    - Adapting a dynamic threshold that becomes stricter over time
    - Defecting when cooperation rate falls below threshold or breakeven point
    - Maintaining consistency to reward collective partners
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.in_defection_mode = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        total_cooperators_past = 0
        for t in range(round_number):
            round_cooperators = int(history.my_actions[t])
            for i in range(self.n_players - 1):
                round_cooperators += int(history.opponent_actions[t, i])
            total_cooperators_past += round_cooperators
        avg_coop_rate = total_cooperators_past / (round_number * self.n_players)
        breakeven = self.k / self.n_players
        time_factor = (self.n_rounds - round_number) / self.n_rounds
        threshold = max(breakeven, time_factor * 0.5 + 0.3)
        if avg_coop_rate < breakeven - 0.1:
            self.in_defection_mode = True
        if self.in_defection_mode:
            return Action.D
        if avg_coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_204(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with individual protection against exploitation.
    Features adaptive thresholds, graceful degradation, deficit recovery, and end-game logic.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_upper = 0.5
        self.threshold_lower = 0.3
        self.round_limit = 2
        self.deficit_recovery_boost = 0.2
        self.declining_trend_penalty = 0.15

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_idx = round_num - 1
        prev_opponent_actions = history.opponent_actions[prev_round_idx, :]
        prev_my_action = history.my_actions[prev_round_idx]
        total_cooperators_prev = int(prev_my_action) + int(np.sum(prev_opponent_actions))
        cooperation_rate = total_cooperators_prev / n
        coop_probability = 0.0
        if cooperation_rate >= self.threshold_upper:
            coop_probability = 1.0
        elif cooperation_rate >= self.threshold_lower:
            coop_probability = (cooperation_rate - self.threshold_lower) / (self.threshold_upper - self.threshold_lower)
        else:
            coop_probability = 0.0
        if cooperation_rate == 0.0:
            coop_probability = 0.0
        if round_num >= 2:
            prev_prev_round_idx = round_num - 2
            prev_prev_opponent_actions = history.opponent_actions[prev_prev_round_idx, :]
            prev_prev_my_action = history.my_actions[prev_prev_round_idx]
            prev_prev_total_cooperators = int(prev_prev_my_action) + int(np.sum(prev_prev_opponent_actions))
            prev_cooperation_rate = prev_prev_total_cooperators / n
            if prev_cooperation_rate - cooperation_rate > 0.1:
                coop_probability -= self.declining_trend_penalty
                coop_probability = max(0.0, coop_probability)
        rounds_remaining = r - round_num
        if rounds_remaining <= self.round_limit:
            my_total_payoff = np.sum(history.my_payoffs)
            all_coop_payoff_per_round = k / n * n
            all_coop_benchmark = all_coop_payoff_per_round * (round_num + 1)
            deficit_exists = my_total_payoff < all_coop_benchmark
            if deficit_exists and cooperation_rate >= 0.4:
                coop_probability += self.deficit_recovery_boost
                coop_probability = min(1.0, coop_probability)
        if round_num == r - 1:
            if cooperation_rate >= 0.5:
                return Action.C
            else:
                return Action.D
        if random.random() < coop_probability:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_205(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Core principle: Cooperate when collective cooperation rate exceeds the breakeven threshold
    (1/k - epsilon), defect otherwise. Special handling for first and last rounds to maximize
    collective benefit while protecting against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.epsilon = 0.05
        self.threshold = 1.0 / game_description.k - self.epsilon

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        cooperation_rate = self._calculate_cooperation_rate(history, round_number, n)
        if round_number == r - 1:
            if cooperation_rate >= self.threshold:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_number: int, n: int) -> float:
        """
        Calculate the observed cooperation rate across all previous rounds.

        cooperation_rate = (total cooperators across all previous rounds) /
                          (n  (current_round))
        """
        my_cooperations = np.sum(history.my_actions[:round_number])
        opponent_cooperations = np.sum(history.opponent_actions[:round_number, :])
        total_cooperators = my_cooperations + opponent_cooperations
        total_actions = n * round_number
        if total_actions == 0:
            return 0.0
        cooperation_rate = total_cooperators / total_actions
        return cooperation_rate

class Strategy_COLLECTIVE_206(BaseStrategy):
    """
    Adaptive Contribution with Conditional Reciprocity (ACR) Strategy

    Balances collective welfare maximization with robust defection against free-riders.
    Adaptively calibrates cooperation based on observed group behavior while maintaining
    credible deterrence against systematic exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.cooperation_threshold = math.ceil(self.k / self.n)
        self.defection_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        my_actions = history.my_actions
        my_payoffs = history.my_payoffs
        opponent_actions = history.opponent_actions
        opponent_payoffs = history.opponent_payoffs
        past_rounds = current_round
        past_cooperators = []
        for round_idx in range(past_rounds):
            cooperators_in_round = np.sum(opponent_actions[round_idx, :]) + (1 if my_actions[round_idx] else 0)
            past_cooperators.append(cooperators_in_round)
        avg_cooperators = np.mean(past_cooperators)
        if current_round == self.r - 1:
            if avg_cooperators >= self.cooperation_threshold:
                return Action.C
            else:
                return Action.D
        last_round_idx = current_round - 1
        recent_cooperators = np.sum(opponent_actions[last_round_idx, :]) + (1 if my_actions[last_round_idx] else 0)
        recent_defection_rate = (self.n - recent_cooperators) / self.n
        if recent_defection_rate > 0.4:
            self.defection_streak = max(self.defection_streak + 1, 2)
            return Action.D
        if self.defection_streak > 0:
            self.defection_streak -= 1
        if self.defection_streak > 0:
            return Action.D
        if current_round < 3:
            return Action.C
        if avg_cooperators < self.cooperation_threshold:
            return Action.D
        my_payoff_last = my_payoffs[last_round_idx]
        all_payoffs_last = np.concatenate(([my_payoff_last], opponent_payoffs[last_round_idx, :]))
        group_payoff_last = np.mean(all_payoffs_last)
        if my_payoff_last < group_payoff_last - 0.2:
            return Action.D
        return Action.C

class Strategy_COLLECTIVE_207(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare optimization with individual incentive compatibility through
    four phases: Exploration (unconditional cooperation), Adaptation (respond to observed
    cooperation rate), Stabilization (commit to equilibrium), and Final Round (defect unless
    overwhelming cooperation detected).
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.phase1_end = math.floor(self.r / 3)
        self.phase2_end = math.floor(2 * self.r / 3)
        self._compute_thresholds()
        self.previous_action = Action.C

    def _compute_thresholds(self):
        """Compute adaptive thresholds based on game parameters."""
        self.threshold_high = 0.6
        self.threshold_low = 0.3
        if self.n > 1:
            k_adjustment = (self.k - 1) / (self.n - 1) * 0.1
            self.threshold_high += k_adjustment
            self.threshold_high = min(self.threshold_high, 0.85)
        if self.n == 2:
            self.threshold_high = 0.75
            self.threshold_low = 0.25
        if self.k < 1.3:
            self.threshold_high = 0.8
        if self.k > self.n - 0.2:
            self.threshold_high = 0.4

    def _get_phase(self, round_number: int) -> int:
        """Determine which phase we're in (1-4)."""
        if round_number < self.phase1_end:
            return 1
        elif round_number < self.phase2_end:
            return 2
        elif round_number < self.r - 1:
            return 3
        else:
            return 4

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate the cooperation rate from all observed rounds."""
        if len(history.opponent_actions) == 0:
            return 0.0
        total_cooperations = np.sum(history.opponent_actions)
        total_observations = history.opponent_actions.shape[0] * history.opponent_actions.shape[1]
        return float(total_cooperations) / float(total_observations) if total_observations > 0 else 0.0

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory, window_size: int) -> float:
        """Calculate cooperation rate from recent rounds."""
        if len(history.opponent_actions) == 0:
            return 0.0
        start_idx = max(0, len(history.opponent_actions) - window_size)
        recent_actions = history.opponent_actions[start_idx:, :]
        total_cooperations = np.sum(recent_actions)
        total_observations = recent_actions.shape[0] * recent_actions.shape[1]
        return float(total_cooperations) / float(total_observations) if total_observations > 0 else 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num < self.phase1_end:
            self.previous_action = Action.C
            return Action.C
        if self.r <= 3:
            if round_num == self.r - 1:
                return Action.D
            else:
                self.previous_action = Action.C
                return Action.C
        coop_rate = self._calculate_cooperation_rate(history)
        if round_num == self.r - 1:
            if coop_rate >= 0.9:
                return Action.C
            else:
                return Action.D
        if round_num < self.phase2_end:
            if coop_rate >= self.threshold_high:
                self.previous_action = Action.C
                return Action.C
            elif coop_rate < self.threshold_low:
                self.previous_action = Action.D
                return Action.D
            else:
                self.previous_action = Action.C
                return Action.C
        window_size = min(10, max(1, (self.phase2_end - self.phase1_end) // 2))
        recent_coop = self._calculate_recent_cooperation_rate(history, window_size)
        earlier_idx = max(0, min(self.phase1_end + window_size, len(history.opponent_actions)))
        if earlier_idx > 0:
            earlier_actions = history.opponent_actions[self.phase1_end:earlier_idx, :]
            if len(earlier_actions) > 0:
                earlier_coop = float(np.sum(earlier_actions)) / float(earlier_actions.shape[0] * earlier_actions.shape[1])
            else:
                earlier_coop = coop_rate
        else:
            earlier_coop = coop_rate
        coop_trend = recent_coop - earlier_coop
        if coop_trend > 0.15:
            self.previous_action = Action.C
            return Action.C
        elif coop_trend < -0.15:
            self.previous_action = Action.D
            return Action.D
        else:
            return self.previous_action

class Strategy_COLLECTIVE_208(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances individual and collective rationality through conditional cooperation
    with adaptive thresholds. Cooperates in round 1, then adjusts based on observed
    cooperation rates with graceful degradation through probabilistic mixing.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.theta_high = 0.6
        self.theta_mid = 0.3
        self.theta_low = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round_idx = state.round_number - 1
        prev_opponent_actions = history.opponent_actions[prev_round_idx, :]
        my_prev_action = history.my_actions[prev_round_idx]
        total_cooperators = int(my_prev_action) + int(np.sum(prev_opponent_actions))
        cooperation_rate = total_cooperators / self.game_description.n_players
        if cooperation_rate >= self.theta_high:
            return Action.C
        elif cooperation_rate >= self.theta_mid:
            if random.random() < cooperation_rate:
                return Action.C
            else:
                return Action.D
        elif cooperation_rate >= self.theta_low:
            return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_209(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare by:
    1. Signaling commitment through early cooperation (commitment phase)
    2. Evaluating sustainability based on observed cooperation rates (evaluation phase)
    3. Matching last-round behavior for immediate reciprocity (exploitation phase)
    4. Defecting in the final round (standard game theory)

    Core decision threshold: cooperation_rate >= k/n
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n
        self.commitment_phase = math.ceil(self.r / 3)
        self.exploitation_start = math.floor(2 * self.r / 3) + 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        if current_round < self.commitment_phase:
            return Action.C
        if current_round < self.exploitation_start:
            total_cooperators = int(np.sum(history.opponent_actions[:current_round, :]))
            total_rounds_played = current_round
            total_possible_cooperations = total_rounds_played * self.n
            observed_rate = total_cooperators / total_possible_cooperations
            if observed_rate >= self.threshold:
                return Action.C
            else:
                return Action.D
        last_round_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        last_round_rate = last_round_cooperators / self.n
        if last_round_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_210(BaseStrategy):
    """
    Adaptive Reciprocal Contribution with Decay Resistance.

    Maximizes collective welfare by:
    1. Building cooperation gradually to test the environment
    2. Protecting against exploitation via defection thresholds
    3. Recovering cooperation when conditions improve
    4. Adapting parameters based on game dynamics (n, k, r)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            return Action.D
        return self._adaptive_reciprocity(round_num, history)

    def _adaptive_reciprocity(self, round_num: int, history: PlayerHistory) -> Action:
        """
        Adaptive reciprocity decision logic for middle rounds.
        """
        prev_round_idx = round_num - 1
        cooperators_last = int(sum(history.opponent_actions[prev_round_idx, :]))
        cooperation_rate = cooperators_last / self.n
        defection_rate = 1.0 - cooperation_rate
        threshold = (self.k - 1.0) / max(self.n - 1, 1)
        free_rider_tolerance = 0.25
        sensitivity_buffer = 0.15
        max_free_rider_threshold = 0.4
        if self.n == 2:
            max_free_rider_threshold = 0.35
        if self.k > self.n - 1:
            sensitivity_buffer = 0.1
            max_free_rider_threshold = 0.5
        elif self.k <= 1.5:
            sensitivity_buffer = 0.25
        if cooperation_rate >= 1.0 - free_rider_tolerance:
            upper_bound = threshold * (1.0 + sensitivity_buffer)
            lower_bound = threshold * (1.0 - sensitivity_buffer)
            if cooperation_rate > upper_bound:
                return Action.C
            elif cooperation_rate > lower_bound:
                return Action.C if random.random() < 0.7 else Action.D
            else:
                return Action.D
        elif defection_rate > max_free_rider_threshold:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_211(BaseStrategy):
    """
    Adaptive Threshold Cooperation with Decay (ATCD):
    A collective strategy that balances cooperation for group welfare with robustness to exploitation.
    Uses cooperation rates to adaptively adjust behavior across thresholds, with special handling
    for initial and final rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            if self.r > 3:
                recent_payoffs = history.my_payoffs[-3:]
                mean_recent = float(np.mean(recent_payoffs))
                coop_rate_prev = self._calculate_cooperation_rate(history, round_num - 1)
                if mean_recent >= 1.5 and coop_rate_prev >= 0.7:
                    return Action.C
            return Action.D
        coop_rate = self._calculate_cooperation_rate(history, round_num - 1)
        threshold_high, threshold_medium, threshold_low = self._get_thresholds()
        if coop_rate >= threshold_high:
            return Action.C
        elif coop_rate >= threshold_medium:
            if random.random() < coop_rate:
                return Action.C
            else:
                return Action.D
        elif coop_rate >= threshold_low:
            return Action.D
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_idx: int) -> float:
        """
        Calculate the cooperation rate in a given round.
        Returns fraction of players (including self) who cooperated.
        """
        opponent_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
        self_cooperated = int(history.my_actions[round_idx])
        total_cooperators = opponent_cooperators + self_cooperated
        cooperation_rate = total_cooperators / self.n
        return cooperation_rate

    def _get_thresholds(self) -> tuple:
        """
        Determine threshold values based on game parameters.
        Returns (threshold_high, threshold_medium, threshold_low)
        """
        if self.n == 2:
            threshold_high = 0.8
            threshold_medium = 0.55
            threshold_low = 0.3
        else:
            threshold_high = 0.6
            threshold_medium = 0.35
            threshold_low = 0.15
        if self.k < 1.2:
            threshold_high = 0.5
        if self.k > self.n * 0.9:
            threshold_high = 0.75
        return (threshold_high, threshold_medium, threshold_low)

class Strategy_COLLECTIVE_212(BaseStrategy):
    """
    Adaptive Graduated Reciprocity with Public Goods Focus.

    Balances collective welfare maximization, rational self-protection, and robustness
    through graduated reciprocity. Cooperates when cooperation rate exceeds the marginal
    benefit threshold (k/n), uses probabilistic matching for moderate cooperation rates,
    and defects in low-cooperation environments. Special end-game logic prevents
    race-to-bottom while preserving collective welfare signaling.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        lookback_window = min(3, current_round)
        recent_rounds_start = current_round - lookback_window
        total_cooperators = 0
        for round_idx in range(recent_rounds_start, current_round):
            if history.my_actions[round_idx]:
                total_cooperators += 1
            total_cooperators += sum(history.opponent_actions[round_idx, :])
        total_possible = lookback_window * self.n_players
        recent_cooperation_rate = total_cooperators / total_possible if total_possible > 0 else 0
        last_round_idx = current_round - 1
        my_last_action = history.my_actions[last_round_idx]
        last_round_cooperators = sum(history.opponent_actions[last_round_idx, :])
        if my_last_action:
            last_round_cooperators += 1
        payoff_if_cooperated = 1 - 1 + self.k / self.n_players * last_round_cooperators
        payoff_if_defected = 1 - 0 + self.k / self.n_players * last_round_cooperators
        exploitation_risk = max(0, payoff_if_defected - payoff_if_cooperated)
        marginal_threshold = self.k / self.n_players
        if current_round == self.n_rounds - 1:
            if recent_cooperation_rate >= 0.5:
                return Action.C
            else:
                return Action.D
        if recent_cooperation_rate >= marginal_threshold:
            return Action.C
        elif recent_cooperation_rate >= 0.5:
            if random.random() < recent_cooperation_rate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_213(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Adapts cooperation based on group cooperation rates and personal contribution history,
    with distinct phases: early game (exploration), middle game (commitment), and end game (sustainability).
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        early_phase_end = math.ceil(self.r / 3)
        mid_phase_end = math.floor(2 * self.r / 3)
        coop_rates = self._compute_cooperation_rates(history, round_num)
        coop_rate_last = coop_rates[-1] if len(coop_rates) > 0 else 0.0
        my_avg_contribution = self._compute_my_avg_contribution(history, round_num)
        avg_coop = self._compute_rolling_avg_coop(coop_rates)
        coop_threshold_early = self._get_early_threshold()
        if round_num <= early_phase_end:
            if coop_rate_last >= coop_threshold_early:
                return Action.C
            elif coop_rate_last >= 0.5:
                return Action.C
            else:
                return Action.D
        elif round_num <= mid_phase_end:
            if avg_coop >= self.k / self.n:
                return Action.C
            elif avg_coop >= 0.4 and my_avg_contribution >= 0.5:
                return Action.C
            elif avg_coop >= 0.3:
                return Action.D
            else:
                return Action.D
        elif round_num == self.r - 1:
            if avg_coop >= self.k / self.n:
                return Action.C
            elif avg_coop >= 0.4 and my_avg_contribution >= 0.5:
                return Action.C
            else:
                return Action.D
        elif avg_coop >= 0.6:
            return Action.C
        elif avg_coop >= self.k / self.n and my_avg_contribution >= 0.6:
            return Action.C
        else:
            return Action.D

    def _compute_cooperation_rates(self, history: PlayerHistory, round_num: int) -> list:
        """Compute cooperation rate for each round up to round_num-1."""
        coop_rates = []
        for r in range(round_num):
            my_action = history.my_actions[r]
            opponent_coop = sum(history.opponent_actions[r, :])
            total_coop = int(my_action) + opponent_coop
            coop_rate = total_coop / self.n
            coop_rates.append(coop_rate)
        return coop_rates

    def _compute_my_avg_contribution(self, history: PlayerHistory, round_num: int) -> float:
        """Compute average personal contribution over last 3 rounds (or fewer)."""
        start_round = max(0, round_num - 3)
        my_actions_slice = history.my_actions[start_round:round_num]
        if len(my_actions_slice) == 0:
            return 0.0
        return float(np.mean(my_actions_slice))

    def _compute_rolling_avg_coop(self, coop_rates: list) -> float:
        """Compute rolling average cooperation rate over last 3 rounds."""
        if len(coop_rates) == 0:
            return 0.0
        window_size = min(3, len(coop_rates))
        recent_rates = coop_rates[-window_size:]
        return float(np.mean(recent_rates))

    def _get_early_threshold(self) -> float:
        """Adjust early cooperation threshold based on n and k."""
        base_threshold = self.k / self.n + 0.1
        if self.n <= 3:
            base_threshold = self.k / self.n + 0.05
        if self.k >= self.n - 0.5:
            base_threshold *= 0.9
        return base_threshold

class Strategy_COLLECTIVE_214(BaseStrategy):
    """
    Adaptive Collective Strategy: Progressive Conditional Cooperation with Defection Recovery

    Balances collective welfare maximization with robust protection against exploitation.
    Uses cooperation thresholds based on k/n, escalating pressure for persistent low cooperation,
    and strategic endgame behavior.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.cooperation_threshold = self.k / self.n_players
        self.consecutive_defection_rounds = 0
        self.test_cooperation_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        last_round_idx = round_num - 1
        cooperators_last_round = int(sum(history.opponent_actions[last_round_idx, :]))
        observed_cooperation_rate = cooperators_last_round / self.n_players
        adjusted_threshold = self.cooperation_threshold
        if self.n_players <= 3:
            adjusted_threshold = self.cooperation_threshold + 0.1
        elif self.k >= self.n_players - 0.5:
            adjusted_threshold = max(0, self.cooperation_threshold - 0.05)
        if round_num == self.n_rounds - 1:
            if observed_cooperation_rate >= adjusted_threshold:
                return Action.C
            else:
                return Action.D
        if observed_cooperation_rate >= adjusted_threshold:
            self.consecutive_defection_rounds = 0
            self.test_cooperation_counter = 0
            return Action.C
        else:
            self.consecutive_defection_rounds += 1
            self.test_cooperation_counter += 1
            if self.test_cooperation_counter >= 3 and self.consecutive_defection_rounds > 1:
                self.test_cooperation_counter = 0
                return Action.C
            return Action.D

class Strategy_COLLECTIVE_215(BaseStrategy):
    """
    Adaptive Contribution Equilibrium (ACE) Strategy

    A conditional cooperation strategy that:
    1. Cooperates in round 1 to signal willingness
    2. In rounds 2 to r-1, cooperates if the previous round's cooperation ratio
       meets or exceeds the threshold (k-1)/k
    3. Defects in the final round (subgame-perfect equilibrium)

    The threshold reflects the break-even point where public good value equals
    the endowment, making cooperation collectively rational above this level.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        prev_round_index = current_round - 1
        cooperators_prev = int(sum(history.opponent_actions[prev_round_index, :]))
        if history.my_actions[prev_round_index]:
            cooperators_prev += 1
        cooperation_ratio = cooperators_prev / self.n_players
        threshold = (self.k - 1.0) / self.k
        if cooperation_ratio >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_216(BaseStrategy):
    """
    Adaptive Contribution Targeting (ACT) Strategy for N-Player Public Goods Game.

    Balances collective welfare with robustness by using a threshold-based decision rule:
    - Round 1: Always COOPERATE (bootstrap cooperation)
    - Subsequent rounds: COOPERATE if empirical cooperation rate meets or exceeds threshold k/n
    - Uses 2-round moving average for stability against oscillation
    - Final round applies standard threshold rule (no spite defection)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == 1:
            coop_count_prev = np.sum(history.opponent_actions[0, :])
            own_action_prev = history.my_actions[0]
            total_coop_prev = coop_count_prev + (1 if own_action_prev else 0)
            coop_rate_prev = total_coop_prev / self.n
        else:
            coop_count_t1 = np.sum(history.opponent_actions[current_round - 1, :])
            own_action_t1 = history.my_actions[current_round - 1]
            total_coop_t1 = coop_count_t1 + (1 if own_action_t1 else 0)
            rate_t1 = total_coop_t1 / self.n
            coop_count_t2 = np.sum(history.opponent_actions[current_round - 2, :])
            own_action_t2 = history.my_actions[current_round - 2]
            total_coop_t2 = coop_count_t2 + (1 if own_action_t2 else 0)
            rate_t2 = total_coop_t2 / self.n
            coop_rate_prev = 0.5 * rate_t1 + 0.5 * rate_t2
        if coop_rate_prev >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_217(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy

    A population-aware strategy that balances individual rationality with collective welfare.
    - Round 0: Cooperate (optimistic start)
    - Rounds 1 to r-2: Cooperate if previous round cooperation rate >= (n-1)/n threshold
    - Round r-1: Cooperate if previous round cooperation rate >= threshold (defensive closing)
    - Otherwise: Defect
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.n - 1) / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        opponent_cooperators = np.sum(history.opponent_actions[prev_round_idx, :])
        my_prev_action = history.my_actions[prev_round_idx]
        total_cooperators = int(my_prev_action) + opponent_cooperators
        cooperation_rate = total_cooperators / self.n
        if current_round == self.r - 1:
            if cooperation_rate >= self.threshold:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_218(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare with self-protection through graduated reciprocity.
    Uses cooperation thresholds that adapt based on observed cooperation rates,
    with escalation/de-escalation mechanisms and context-aware final round behavior.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.base_min_threshold = (1.0 + self.k) / (2.0 * self.n)
        self.current_min_threshold = self.base_min_threshold
        self.defection_streak = 0
        self.cooperation_history = []

    def _get_observed_cooperation_rate(self, history: PlayerHistory, round_idx: int) -> float:
        """Calculate cooperation rate from opponent actions in a specific round."""
        if round_idx < 0 or round_idx >= history.opponent_actions.shape[0]:
            return 0.0
        opponent_cooperators = sum(history.opponent_actions[round_idx, :])
        return opponent_cooperators / self.n

    def _get_recent_avg_cooperation(self, history: PlayerHistory, current_round: int) -> float:
        """Calculate average cooperation rate over recent rounds."""
        window_size = max(3, self.r // 3)
        start_idx = max(0, current_round - window_size)
        if start_idx >= current_round:
            return 0.0
        total_coop = 0.0
        count = 0
        for idx in range(start_idx, current_round):
            total_coop += self._get_observed_cooperation_rate(history, idx)
            count += 1
        return total_coop / count if count > 0 else 0.0

    def _is_cooperation_declining(self, history: PlayerHistory, current_round: int) -> bool:
        """Detect if cooperation trend is declining."""
        if current_round < 2:
            return False
        window_size = max(3, self.r // 3)
        half_window = max(1, window_size // 2)
        recent_start = max(0, current_round - half_window)
        older_start = max(0, current_round - window_size)
        older_end = recent_start
        if recent_start >= current_round or older_end <= older_start:
            return False
        recent_avg = 0.0
        recent_count = 0
        for idx in range(recent_start, current_round):
            recent_avg += self._get_observed_cooperation_rate(history, idx)
            recent_count += 1
        older_avg = 0.0
        older_count = 0
        for idx in range(older_start, older_end):
            older_avg += self._get_observed_cooperation_rate(history, idx)
            older_count += 1
        if recent_count == 0 or older_count == 0:
            return False
        recent_avg /= recent_count
        older_avg /= older_count
        return recent_avg < older_avg

    def _is_cooperation_rising(self, history: PlayerHistory, current_round: int) -> bool:
        """Detect if cooperation trend is rising."""
        if current_round < 2:
            return False
        window_size = max(3, self.r // 3)
        half_window = max(1, window_size // 2)
        recent_start = max(0, current_round - half_window)
        older_start = max(0, current_round - window_size)
        older_end = recent_start
        if recent_start >= current_round or older_end <= older_start:
            return False
        recent_avg = 0.0
        recent_count = 0
        for idx in range(recent_start, current_round):
            recent_avg += self._get_observed_cooperation_rate(history, idx)
            recent_count += 1
        older_avg = 0.0
        older_count = 0
        for idx in range(older_start, older_end):
            older_avg += self._get_observed_cooperation_rate(history, idx)
            older_count += 1
        if recent_count == 0 or older_count == 0:
            return False
        recent_avg /= recent_count
        older_avg /= older_count
        return recent_avg > older_avg

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        observed_coop = self._get_observed_cooperation_rate(history, current_round - 1)
        if self._is_cooperation_declining(history, current_round):
            self.current_min_threshold *= 0.9
        elif self._is_cooperation_rising(history, current_round):
            self.current_min_threshold = min(self.current_min_threshold * 1.05, self.base_min_threshold)
        if observed_coop < self.current_min_threshold:
            self.defection_streak += 1
        else:
            self.defection_streak = 0
        if self.defection_streak >= 2:
            self.current_min_threshold = 2.0 * self.k / self.n
        if self.defection_streak == 0 and self.current_min_threshold > self.base_min_threshold:
            self.current_min_threshold = self.base_min_threshold
        if current_round == self.r - 1:
            recent_avg_coop = self._get_recent_avg_cooperation(history, current_round)
            if recent_avg_coop >= self.current_min_threshold:
                return Action.C
            else:
                return Action.D
        if observed_coop == 0 and self.defection_streak >= 2:
            return Action.D
        if observed_coop >= (self.n - 1) / self.n:
            return Action.C
        breakeven_threshold = self.k / self.n
        if observed_coop >= self.current_min_threshold:
            return Action.C
        elif observed_coop >= breakeven_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_219(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game.

    Balances collective welfare optimization with self-protection against exploitation.
    Uses a threshold-based adaptation rule (threshold = k/n) to decide cooperation,
    with a collective override in strong cooperation regimes on the final round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        total_cooperators = 0
        for round_idx in range(current_round):
            cooperators_this_round = int(np.sum(history.opponent_actions[round_idx, :]))
            total_cooperators += cooperators_this_round
            if history.my_actions[round_idx]:
                total_cooperators += 1
        cooperation_rate = total_cooperators / (n * current_round)
        threshold = k / n
        if current_round == r - 1 and cooperation_rate >= 0.75:
            return Action.C
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_220(BaseStrategy):
    """
    Adaptive Contribution with Conditional Reciprocity (ACCR)

    A strategy that balances collective welfare maximization with individual robustness
    through historical reciprocity tracking, momentum-based escalation, and principled
    cooperation thresholds derived from payoff equilibria.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        round_t = state.round_number
        total_opponent_cooperations = np.sum(history.opponent_actions)
        my_cooperations = np.sum(history.my_actions)
        total_cooperations = total_opponent_cooperations + my_cooperations
        total_opportunities = self.n * round_t
        group_coop_rate = total_cooperations / total_opportunities
        if 2 * self.k - self.n > 0:
            cooperation_threshold = self.k / (2 * self.k - self.n)
        else:
            cooperation_threshold = 0.5
        cooperation_threshold = max(0.0, min(1.0, cooperation_threshold))
        lookback_window = min(3, round_t)
        recent_start_idx = round_t - lookback_window
        recent_opponent_cooperations = np.sum(history.opponent_actions[recent_start_idx:, :])
        recent_my_cooperations = np.sum(history.my_actions[recent_start_idx:])
        recent_total_cooperations = recent_opponent_cooperations + recent_my_cooperations
        recent_opportunities = self.n * lookback_window
        recent_coop_rate = recent_total_cooperations / recent_opportunities if recent_opportunities > 0 else 0.0
        if round_t > lookback_window:
            early_cooperations = total_cooperations - recent_total_cooperations
            early_opportunities = self.n * (round_t - lookback_window)
            historical_coop_rate = early_cooperations / early_opportunities if early_opportunities > 0 else 0.0
        else:
            historical_coop_rate = group_coop_rate
        if group_coop_rate >= cooperation_threshold:
            base_action = Action.C
        elif group_coop_rate >= 0.5:
            if random.random() < group_coop_rate:
                base_action = Action.C
            else:
                base_action = Action.D
        else:
            base_action = Action.D
        momentum_threshold = 0.01
        if recent_coop_rate > historical_coop_rate + momentum_threshold:
            if base_action == Action.D and group_coop_rate > 0.33:
                return Action.C
            return base_action
        elif recent_coop_rate < historical_coop_rate - momentum_threshold:
            if base_action == Action.C and recent_coop_rate < 0.4:
                return Action.D
            return base_action
        return base_action

class Strategy_COLLECTIVE_221(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare by:
    1. Cooperating optimistically in round 1
    2. Adopting adaptive threshold-based cooperation in middle rounds
    3. Making strategic final-round decisions based on observed cooperation rates

    The core threshold is k/n, representing the marginal contribution per cooperator.
    Cooperation is sustained when the cooperation rate meets or exceeds this threshold.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n_players
        self.exploration_epsilon = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        is_last_round = current_round == self.n_rounds - 1
        prev_round_idx = current_round - 1
        opponent_actions_prev = history.opponent_actions[prev_round_idx, :]
        cooperators_prev = int(np.sum(opponent_actions_prev))
        coop_rate_prev = cooperators_prev / self.n_players
        if current_round <= 2 and self.n_rounds > 2:
            rounds_remaining = self.n_rounds - current_round
            exploration_adjustment = self.exploration_epsilon * (rounds_remaining / self.n_rounds)
            effective_threshold = self.threshold + exploration_adjustment
        else:
            effective_threshold = self.threshold
        if coop_rate_prev == 0:
            return Action.D
        if coop_rate_prev == 1.0:
            return Action.C
        if is_last_round:
            if coop_rate_prev >= effective_threshold and self.n_rounds > 2:
                return Action.C
            else:
                return Action.D
        if coop_rate_prev >= effective_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_222(BaseStrategy):
    """
    Adaptive Reciprocal Threshold (ART) Strategy for N-Player Public Goods Game.

    Balances collective value creation, robustness against exploitation, and adaptive
    coordination by using observed cooperation rates to dynamically adjust participation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        cooperators_last_round = int(sum(history.opponent_actions[round_t - 1, :]))
        cooperators_last_round += int(history.my_actions[round_t - 1])
        ecr_t = cooperators_last_round / self.n
        threshold = (self.n - self.k) / (self.n - 1)
        if round_t > 1:
            cooperators_prev_round = int(sum(history.opponent_actions[round_t - 2, :]))
            cooperators_prev_round += int(history.my_actions[round_t - 2])
            ecr_prev = cooperators_prev_round / self.n
            trend = ecr_t - ecr_prev
            if trend > 0.05:
                threshold = threshold * 0.95
            elif trend < -0.1:
                threshold = threshold * 1.1
        if round_t > 1 and ecr_t < 0.01:
            cooperators_prev_round = int(sum(history.opponent_actions[round_t - 2, :]))
            cooperators_prev_round += int(history.my_actions[round_t - 2])
            ecr_prev = cooperators_prev_round / self.n
            if ecr_prev < 0.01:
                return Action.D
        if ecr_t >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_223(BaseStrategy):
    """
    Reciprocal Threshold Cooperation (RTC) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare by dynamically adjusting
    cooperation levels based on observed reciprocity. Uses window-based averaging of
    cooperation rates with threshold-based decision rules, special handling for early/mid/late
    game phases, and end-game adjustments.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.counter_defect_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        round_t = state.round_number
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        window_size = self._calculate_window_size(round_t, r)
        recent_coop = self._compute_recent_cooperation(history, round_t, window_size, n)
        threshold = k / n
        if recent_coop == 0:
            if round_t == 1:
                return Action.C
            else:
                return Action.D
        if recent_coop < k / (2 * n):
            if self.counter_defect_rounds < 2:
                self.counter_defect_rounds += 1
                return Action.D
            else:
                self.counter_defect_rounds = 0
        if recent_coop >= threshold:
            base_prob = recent_coop
        else:
            base_prob = recent_coop / threshold * 0.5
        near_final_threshold = 0.9 * r
        if round_t > near_final_threshold:
            if round_t == r - 1:
                base_prob *= 0.75
            else:
                rounds_past_threshold = round_t - near_final_threshold
                reduction_factor = 1.0 - 0.1 * rounds_past_threshold
                base_prob *= max(reduction_factor, 0.5)
        current_avg_payoff = self._compute_current_trajectory_payoff(history, round_t, n, k)
        all_coop_payoff = k
        all_defect_payoff = 1
        if current_avg_payoff > (all_coop_payoff + all_defect_payoff) / 2:
            base_prob = min(base_prob + 0.05, 1.0)
        if random.random() < base_prob:
            return Action.C
        else:
            return Action.D

    def _calculate_window_size(self, round_t: int, r: int) -> int:
        """Calculate window size based on game phase."""
        early_phase_end = r / 3
        late_phase_start = 2 * r / 3
        if round_t <= early_phase_end:
            return min(round_t, 3)
        elif round_t < late_phase_start:
            return min(round_t, max(1, r // 4))
        else:
            return min(round_t, max(5, r // 6))

    def _compute_recent_cooperation(self, history: PlayerHistory, round_t: int, window_size: int, n: int) -> float:
        """Compute average cooperation rate over the window."""
        start_round = max(0, round_t - window_size)
        end_round = round_t
        if start_round >= end_round:
            return 0.0
        total_cooperators = 0
        total_observations = 0
        for round_idx in range(start_round, end_round):
            cooperators_in_round = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += cooperators_in_round
            total_observations += n
        if total_observations == 0:
            return 0.0
        return total_cooperators / total_observations

    def _compute_current_trajectory_payoff(self, history: PlayerHistory, round_t: int, n: int, k: float) -> float:
        """Compute average payoff trajectory observed so far."""
        if round_t == 0:
            return 0.0
        my_payoffs = history.my_payoffs[:round_t]
        avg_payoff = np.mean(my_payoffs)
        return avg_payoff

class Strategy_COLLECTIVE_224(BaseStrategy):
    """
    Adaptive Public Goods Contribution Strategy

    Balances individual rationality with collective welfare through:
    1. Information gathering phase (rounds 0-2): Unconditional cooperation
    2. Adaptive reciprocation (rounds 3 to r-3): Probabilistic punishment based on opponent cooperation rate
    3. Endgame strategy (rounds r-2 to r-1): Reduced punishment and reactive final move
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.opponent_coop_rate = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        total_rounds = self.game_description.n_rounds
        if round_num <= 2:
            return Action.C
        if self.opponent_coop_rate is None:
            total_cooperators = sum(history.opponent_actions[0, :]) + sum(history.opponent_actions[1, :]) + sum(history.opponent_actions[2, :])
            self.opponent_coop_rate = total_cooperators / (3 * self.game_description.n_players)
        if round_num == total_rounds - 1:
            if round_num > 0:
                last_round_cooperators = sum(history.opponent_actions[-1, :])
                if last_round_cooperators > 0:
                    return Action.C
                else:
                    return Action.D
            return Action.C
        if round_num == total_rounds - 2:
            punishment_level = 1.0 - self.opponent_coop_rate
            adjusted_punishment = punishment_level * 0.5
            if random.random() < adjusted_punishment:
                return Action.D
            else:
                return Action.C
        threshold = 0.67
        if self.opponent_coop_rate >= threshold:
            return Action.C
        else:
            punishment_level = 1.0 - self.opponent_coop_rate
            if random.random() < punishment_level:
                return Action.D
            else:
                return Action.C

class Strategy_COLLECTIVE_225(BaseStrategy):
    """
    Adaptive Contribution Equilibrium (ACE): A collective strategy that maximizes
    welfare through information-responsive adaptation, balancing reciprocity with
    exploitation resistance and endgame cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.break_even_threshold = 1.0 / self.k
        if self.k > self.n - 1:
            self.break_even_threshold = 1.5 / self.k
        self.previous_action = None
        self.consecutive_state_changes = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            return Action.C
        prev_round_idx = current_round - 1
        cooperators_prev = int(sum(history.opponent_actions[prev_round_idx, :]))
        cooperation_rate = cooperators_prev / self.n
        if current_round == 1:
            if cooperation_rate < 0.1:
                return Action.D
        if cooperation_rate < 0.2:
            return Action.D
        threshold = self.break_even_threshold
        if cooperation_rate >= threshold:
            self._update_state(Action.C)
            return Action.C
        elif current_round < self.r * 0.9:
            self._update_state(Action.D)
            return Action.D
        else:
            if self.n <= 3:
                endgame_threshold = self.r * 0.95
            else:
                endgame_threshold = self.r * 0.9
            if current_round >= endgame_threshold:
                prob = max(0.3, cooperation_rate)
                if self.previous_action is not None:
                    if self.previous_action == Action.C and random.random() < 0.65:
                        self._update_state(Action.C)
                        return Action.C
                    elif self.previous_action == Action.D and random.random() < 0.65:
                        self._update_state(Action.D)
                        return Action.D
                if random.random() < prob:
                    self._update_state(Action.C)
                    return Action.C
                else:
                    self._update_state(Action.D)
                    return Action.D
            else:
                self._update_state(Action.D)
                return Action.D

    def _update_state(self, action: Action) -> None:
        """Track state transitions for oscillation detection."""
        if self.previous_action is not None and self.previous_action != action:
            self.consecutive_state_changes += 1
        else:
            self.consecutive_state_changes = 0
        self.previous_action = action

class Strategy_COLLECTIVE_226(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) strategy for N-Player Public Goods Game.

    Balances conditional reciprocity with collective welfare maximization through:
    - Cooperation signaling in round 1
    - Adaptive contribution rates based on observed cooperation and welfare
    - End-game defection with exception for near-perfect cooperation
    - Reciprocal punishment without death-spiral dynamics
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            recent_coop_ratio = self._get_cooperation_ratio(history, max(0, round_num - 5))
            if recent_coop_ratio > 0.8:
                return Action.C
            else:
                return Action.D
        observed_ratio = self._get_cooperation_ratio(history, max(0, round_num - 2))
        equilibrium_target = (self.k - 1) / self.n
        total_welfare = self._sum_all_payoffs(history, round_num)
        welfare_ratio = total_welfare / (self.n * self.k) if self.n * self.k > 0 else 0
        if welfare_ratio > 0.75:
            welfare_bonus = 0.1
        elif welfare_ratio < 0.4:
            welfare_bonus = -0.05
        else:
            welfare_bonus = 0.0
        collective_benefit_margin = max(0, (self.k / self.n * self.n - 1) / self.k) if self.k > 0 else 0
        coop_probability = 0.5 * observed_ratio + 0.3 * equilibrium_target + 0.2 * collective_benefit_margin + welfare_bonus
        if round_num > self.r - 3:
            rounds_remaining = self.r - 1 - round_num
            if observed_ratio <= equilibrium_target:
                coop_probability *= 0.8 ** rounds_remaining
        lower_bound = (self.k - 1) / (2 * self.n) if self.n > 0 else 0
        coop_probability = max(coop_probability, lower_bound)
        coop_probability = min(coop_probability, 1.0)
        return Action.C if random.random() < coop_probability else Action.D

    def _get_cooperation_ratio(self, history: PlayerHistory, start_round: int) -> float:
        """
        Calculate cooperation ratio from start_round to most recent round.
        Includes both own actions and opponent actions.
        """
        if history is None or len(history.opponent_actions) == 0:
            return 0.0
        end_round = len(history.opponent_actions)
        if start_round >= end_round:
            return 0.0
        total_cooperators = 0
        total_players_rounds = 0
        for round_idx in range(start_round, end_round):
            opponent_coops = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += opponent_coops
            total_players_rounds += self.n - 1
            if history.my_actions[round_idx]:
                total_cooperators += 1
            total_players_rounds += 1
        if total_players_rounds == 0:
            return 0.0
        return total_cooperators / total_players_rounds

    def _sum_all_payoffs(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate total welfare (sum of all players' payoffs) up to previous round.
        """
        if history is None or len(history.my_payoffs) == 0:
            return 0.0
        total = 0.0
        for round_idx in range(len(history.my_payoffs)):
            total += history.my_payoffs[round_idx]
        if len(history.opponent_payoffs) > 0:
            total += np.sum(history.opponent_payoffs)
        return total

class Strategy_COLLECTIVE_227(BaseStrategy):
    """
    Adaptive Contribution Threshold (ACT) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare by:
    1. Cooperating in round 1 to gather information
    2. Computing a cooperation threshold: (n-1)/(k*n)
    3. Adapting contributions based on observed cooperation rate
    4. Using probabilistic defection for medium cooperation levels
    5. Maintaining solidarity in final rounds when threshold is met
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold = (self.n - 1) / (self.k * self.n)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_opponent_actions = history.opponent_actions[round_num - 1, :]
        prev_round_my_action = history.my_actions[round_num - 1]
        total_cooperators = int(prev_round_my_action) + int(np.sum(prev_round_opponent_actions))
        observed_cooperation_rate = total_cooperators / self.n
        if observed_cooperation_rate >= self.threshold:
            return Action.C
        elif observed_cooperation_rate >= 0.5 * self.threshold:
            coop_probability = observed_cooperation_rate / self.threshold
            if random.random() < coop_probability:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_228(BaseStrategy):
    """
    Progressive Reciprocal Contribution (PRC): An adaptive strategy that balances
    individual incentives with collective welfare through dynamic reciprocity.

    Core logic: Cooperate when expected collective contribution exceeds an adaptively
    adjusted threshold. Includes special handling for edge cases like oscillating
    opponents, immediate defection, late-game collapse, and two-player scenarios.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.defection_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        cooperators_per_round = np.sum(history.opponent_actions, axis=1)
        my_actions = history.my_actions[:current_round]
        total_cooperators_per_round = cooperators_per_round + my_actions.astype(int)
        avg_cooperators = np.mean(total_cooperators_per_round)
        if len(total_cooperators_per_round) > 1:
            volatility = np.std(total_cooperators_per_round)
        else:
            volatility = 0
        if n == 2:
            if k > 1.5:
                return Action.C
            else:
                return Action.D
        if current_round == 1 and cooperators_per_round[0] == 0:
            self.defection_counter = 0
            return Action.D
        if current_round > 1 and current_round < 4 and (self.defection_counter < 2):
            if cooperators_per_round[0] == 0:
                self.defection_counter += 1
                return Action.D
        self.defection_counter = 0
        if volatility > math.sqrt(n) / 2:
            median_cooperators = np.median(total_cooperators_per_round)
            threshold = median_cooperators + 1
        else:
            threshold = avg_cooperators * 0.8
            threshold = max(1, min(n, math.ceil(threshold)))
        if r - current_round <= 2:
            if current_round >= 2:
                recent_coop = np.mean(total_cooperators_per_round[-2:])
                earlier_coop = np.mean(total_cooperators_per_round[:-2]) if current_round > 2 else recent_coop
                if recent_coop < earlier_coop - 0.5:
                    return Action.D
        if current_round == r - 1:
            cumulative_cooperation_rate = avg_cooperators / n
            if cumulative_cooperation_rate >= 0.6:
                return Action.C
            else:
                return Action.D
        last_round_cooperators = total_cooperators_per_round[-1]
        if last_round_cooperators >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_229(BaseStrategy):
    """
    Adaptive Reciprocal Threshold (ART) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization, individual security, and robustness
    through dynamic cooperation thresholds based on recent cooperation rates.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.defect_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        min_threshold = math.ceil((self.k + 1) / self.k)
        window_size = max(2, math.floor(self.n_rounds / 4))
        if round_t == self.n_rounds - 1:
            total_cooperators = 0
            for r in range(round_t):
                total_cooperators += np.sum(history.opponent_actions[r, :])
                total_cooperators += int(history.my_actions[r])
            total_players_rounds = round_t * self.n_players
            overall_coop_rate = total_cooperators / total_players_rounds if total_players_rounds > 0 else 0.5
            if overall_coop_rate >= 0.4:
                return Action.C
            else:
                return Action.D
        start_idx = max(0, round_t - window_size)
        recent_rounds = range(start_idx, round_t)
        recent_cooperation_count = 0
        for r in recent_rounds:
            cooperators_this_round = np.sum(history.opponent_actions[r, :]) + int(history.my_actions[r])
            if cooperators_this_round >= min_threshold:
                recent_cooperation_count += 1
        num_recent_rounds = len(list(recent_rounds)) if recent_rounds else 1
        recent_cooperation_rate = recent_cooperation_count / num_recent_rounds if num_recent_rounds > 0 else 0.5
        if num_recent_rounds >= 2:
            recent_cooperation_rates = []
            for r in recent_rounds:
                cooperators_this_round = np.sum(history.opponent_actions[r, :]) + int(history.my_actions[r])
                rate = cooperators_this_round / self.n_players
                recent_cooperation_rates.append(rate)
            if len(recent_cooperation_rates) >= 2:
                std_dev = float(np.std(recent_cooperation_rates))
                if std_dev > 0.3:
                    recent_cooperation_rate = float(np.mean(recent_cooperation_rates))
                    min_threshold += 1
        if recent_cooperation_rate < 0.2:
            self.defect_streak += 1
            if self.defect_streak >= 2:
                return Action.D
        else:
            self.defect_streak = 0
        threshold_ratio = min_threshold / self.n_players
        if recent_cooperation_rate >= threshold_ratio:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_230(BaseStrategy):
    """
    Adaptive Collective Strategy: Graduated Reciprocity with Resilience (GRR)

    Balances collective welfare maximization, robust self-protection, and graceful degradation
    through threshold-based reciprocal cooperation that adapts throughout the game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        prev_cooperators = int(sum(history.opponent_actions[round_number - 1, :]))
        cooperation_ratio = prev_cooperators / self.n
        if round_number == self.r - 1:
            if cooperation_ratio >= self.k / self.n:
                return Action.C
            else:
                return Action.D
        threshold = max(self.k / self.n, 1 - round_number / (self.r - 1) * (1 - self.k / self.n))
        if cooperation_ratio >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_231(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare with individual security through adaptive reciprocity.
    Responds to historical cooperation rates and detects trends to optimize contribution decisions.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_high = 0.6
        self.threshold_low = 0.3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        all_actions = history.opponent_actions
        total_cooperators = np.sum(all_actions)
        rounds_elapsed = current_round
        cooperation_rate = total_cooperators / (n * rounds_elapsed)
        recent_cooperation = self._get_recent_cooperation_rate(history, current_round, n)
        trend = recent_cooperation - cooperation_rate
        if current_round <= 2 and cooperation_rate < 0.3:
            if current_round == 1:
                return Action.C
            else:
                return Action.D
        if 1 <= current_round < r - 1:
            if trend > 0.15:
                return Action.C
            elif trend < -0.15 and cooperation_rate < 0.3:
                return Action.D
        if current_round > 0 and np.sum(history.opponent_actions[-1, :]) == 0:
            return Action.D
        if cooperation_rate >= 0.99 and current_round >= 1:
            return Action.C
        if 0.45 <= cooperation_rate <= 0.55:
            return Action.C if random.random() < 0.65 else Action.D
        if current_round == r - 1:
            if cooperation_rate < self.threshold_low:
                return Action.D
            else:
                return Action.C
        if cooperation_rate >= self.threshold_high:
            return Action.C
        elif cooperation_rate >= self.threshold_low:
            return Action.C if random.random() < cooperation_rate else Action.D
        else:
            return Action.D

    def _get_recent_cooperation_rate(self, history: PlayerHistory, current_round: int, n: int) -> float:
        """Calculate cooperation rate from the last 3 rounds (or fewer if not available)."""
        start_round = max(0, current_round - 3)
        recent_actions = history.opponent_actions[start_round:current_round, :]
        if recent_actions.size == 0:
            return 0.0
        total_cooperators = np.sum(recent_actions)
        rounds_in_window = current_round - start_round
        return total_cooperators / (n * rounds_in_window)

class Strategy_COLLECTIVE_232(BaseStrategy):
    """
    Adaptive Reciprocal Maximization (ARM): A strategy that balances collective welfare,
    individual resilience, and adaptive robustness through dynamic reciprocity.

    The strategy operates in three phases:
    1. Information Gathering: Cooperate unconditionally to establish baseline cooperation rates
    2. Adaptive Reciprocity: Classify opponents and respond based on historical cooperation rates
    3. End-Game: Prevent defection cliffs in final rounds
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        phase1_end = min(5, math.floor(self.r / 3))
        if round_num < phase1_end:
            return Action.C
        if round_num == 1 and self.r == 2:
            return Action.C
        total_rounds_elapsed = round_num
        total_cooperations = int(np.sum(history.opponent_actions[:round_num, :]))
        cooperation_rate = total_cooperations / (self.n * total_rounds_elapsed) if total_rounds_elapsed > 0 else 0.0
        if round_num >= self.r - 2:
            if cooperation_rate >= 0.5:
                return Action.C
            else:
                return Action.D
        k_over_n = self.k / self.n
        if cooperation_rate >= k_over_n:
            return Action.C
        elif cooperation_rate > 0.5:
            cooperators_last_round = int(np.sum(history.opponent_actions[round_num - 1, :]))
            proportion_cooperated_last_round = cooperators_last_round / self.n
            if proportion_cooperated_last_round >= 0.5:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_233(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy

    Balances collective welfare maximization, self-preservation, and adaptive learning
    through three phases: initial assessment, dynamic adaptation, and endgame.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            return Action.D
        if round_num == self.r - 2:
            recent_coop_rate = self._calculate_recent_coop_rate(history, 3)
            if recent_coop_rate >= 0.6:
                return Action.C
            else:
                return Action.D
        if round_num <= 2:
            coop_rate_round_0 = self._get_cooperation_rate(history, 0)
            if coop_rate_round_0 >= 0.5:
                return Action.C
            else:
                return Action.D
        recent_coop_rate = self._calculate_recent_coop_rate(history, 3)
        threshold = 0.5 + 0.2 * (1.0 - self.k / self.n)
        if recent_coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _get_cooperation_rate(self, history: PlayerHistory, round_idx: int) -> float:
        """
        Get the cooperation rate in a specific round.
        round_idx is 0-indexed.
        """
        if round_idx < 0 or round_idx >= len(history.opponent_actions):
            return 0.0
        cooperators_in_round = int(sum(history.opponent_actions[round_idx, :]))
        return cooperators_in_round / self.n

    def _calculate_recent_coop_rate(self, history: PlayerHistory, window: int) -> float:
        """
        Calculate the rolling cooperation rate over the last 'window' rounds.
        Uses all players (opponents) in those rounds.
        """
        current_round = len(history.opponent_actions)
        start_round = max(0, current_round - window)
        if start_round >= current_round:
            return 0.0
        recent_actions = history.opponent_actions[start_round:current_round, :]
        total_cooperators = int(np.sum(recent_actions))
        total_opportunities = (current_round - start_round) * self.n
        if total_opportunities == 0:
            return 0.0
        return total_cooperators / total_opportunities

class Strategy_COLLECTIVE_234(BaseStrategy):
    """
    Adaptive Reciprocal Contribution with Threshold Dynamics.

    A collective strategy that bootstraps cooperation through credible commitment
    in early rounds, adapts reciprocally based on observed cooperation rates,
    and protects against exploitation while maintaining focus on group welfare.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.defection_episode_count = 0
        self.consecutive_zero_coop = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        coop_rate = self._get_cooperation_rate(history, round_number - 1)
        if round_number <= self.n_rounds / 2:
            threshold_high = 0.4
            threshold_mid = 0.2
            threshold_low = 0.1
        else:
            threshold_high = 0.5
            threshold_mid = 0.3
            threshold_low = 0.15
        if round_number == self.n_rounds - 1:
            if coop_rate >= 0.6:
                return Action.C
            else:
                return Action.D
        if coop_rate == 0:
            self.consecutive_zero_coop += 1
            if self.consecutive_zero_coop >= 2:
                return Action.D
        else:
            self.consecutive_zero_coop = 0
        if round_number <= 3 and coop_rate == 0 and (self.defection_episode_count == 0):
            self.defection_episode_count += 1
            return Action.C if random.random() < 0.5 else Action.D
        if coop_rate >= threshold_high:
            return Action.C
        elif coop_rate >= threshold_mid:
            return Action.C if random.random() < coop_rate else Action.D
        else:
            return Action.D

    def _get_cooperation_rate(self, history: PlayerHistory, round_idx: int) -> float:
        """
        Calculate the cooperation rate in a given round using 2-round moving average
        to reduce sensitivity to noise.
        """
        if round_idx < 0:
            return 0.0
        cooperators_current = int(np.sum(history.opponent_actions[round_idx, :]))
        if history.my_actions[round_idx]:
            cooperators_current += 1
        total_from_current = cooperators_current / self.n_players
        if round_idx > 0:
            cooperators_previous = int(np.sum(history.opponent_actions[round_idx - 1, :]))
            if history.my_actions[round_idx - 1]:
                cooperators_previous += 1
            total_from_previous = cooperators_previous / self.n_players
            coop_rate = (total_from_current + total_from_previous) / 2.0
        else:
            coop_rate = total_from_current
        return coop_rate

class Strategy_COLLECTIVE_235(BaseStrategy):
    """
    Adaptive Reciprocity with Collective Threshold (ARC) Strategy

    Balances individual rationality with collective welfare by cooperating when
    the cooperation rate meets or exceeds the threshold  = k/n, which represents
    the point where cooperation becomes individually rational. Initializes with
    cooperation in round 1, maintains consistency through intermediate rounds,
    and applies graceful end-game logic in the final round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        prev_cooperators = sum(history.opponent_actions[prev_round_idx, :])
        cooperation_rate = (prev_cooperators + (1 if history.my_actions[prev_round_idx] else 0)) / self.n_players
        if current_round == self.n_rounds - 1:
            if cooperation_rate >= self.threshold:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_236(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with robust defense against exploitation
    through reciprocal cooperation based on observed behavior.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.k - 1) / self.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        n = self.n_players
        r = self.n_rounds
        if round_number <= min(3, r - 1):
            return Action.C
        if round_number == r - 1:
            return Action.D
        previous_round_index = round_number - 1
        cooperators_previous = int(sum(history.opponent_actions[previous_round_index, :]))
        cooperation_rate = cooperators_previous / n
        if cooperation_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_237(BaseStrategy):
    """
    Adaptive Reciprocal Threshold (ART) Strategy for N-Player Public Goods Game

    Balances collective welfare maximization, robustness against exploitation, and adaptability
    by using observed cooperation rates to dynamically adjust trust and cooperation decisions.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        ocr = self._calculate_ocr(history, round_num)
        ct = self._calculate_threshold()
        if self._is_spiral_detected(history, round_num, ct):
            return Action.D
        if round_num == self.r - 1:
            return self._last_round_decision(history, round_num, ocr, ct)
        if ocr >= ct:
            return Action.C
        else:
            return Action.D

    def _calculate_ocr(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate Observed Cooperation Rate from all previous rounds.
        OCR = (total cooperations across all rounds and players) / (rounds_elapsed  n)
        """
        if round_num == 0:
            return 0.0
        my_cooperations = np.sum(history.my_actions[:round_num])
        opponent_cooperations = np.sum(history.opponent_actions[:round_num, :])
        total_cooperations = my_cooperations + opponent_cooperations
        total_possible = round_num * self.n
        ocr = total_cooperations / total_possible if total_possible > 0 else 0.0
        return ocr

    def _calculate_threshold(self) -> float:
        """
        Calculate cooperation threshold: CT = (k - 1) / (k  (n - 1)) + 
        where  = 0.05 (small buffer)
        """
        denominator = self.k * (self.n - 1)
        if denominator == 0:
            return 0.5
        ct = (self.k - 1) / denominator + 0.05
        return ct

    def _is_spiral_detected(self, history: PlayerHistory, round_num: int, ct: float) -> bool:
        """
        Detect unanimous defection spiral: OCR remains below (CT - 0.1) for 2+ consecutive rounds.
        """
        if round_num < 2:
            return False
        threshold_low = ct - 0.1
        recent_rounds = min(2, round_num)
        for i in range(recent_rounds):
            round_idx = round_num - 1 - i
            if round_idx < 0:
                break
            round_ocr = self._calculate_ocr_for_round(history, round_idx)
            if round_ocr >= threshold_low:
                return False
        return recent_rounds >= 2

    def _calculate_ocr_for_round(self, history: PlayerHistory, round_idx: int) -> float:
        """
        Calculate cooperation rate for a specific round.
        """
        my_coop = int(history.my_actions[round_idx])
        opponent_coop = np.sum(history.opponent_actions[round_idx, :])
        total_coop = my_coop + opponent_coop
        ocr = total_coop / self.n
        return ocr

    def _last_round_decision(self, history: PlayerHistory, round_num: int, ocr: float, ct: float) -> Action:
        """
        Last round special handling with three cases.
        """
        rounds_elapsed = round_num
        opponent_defection_rate = self._calculate_opponent_defection_rate(history, round_num)
        my_cooperations = np.sum(history.my_actions[:round_num])
        if my_cooperations > 0 and opponent_defection_rate > 0.4:
            return Action.D
        if ocr >= ct:
            return Action.C
        return Action.D

    def _calculate_opponent_defection_rate(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate the rate at which opponents defect.
        """
        if round_num == 0:
            return 0.0
        total_opponent_actions = np.sum(history.opponent_actions[:round_num, :])
        total_possible = round_num * (self.n - 1)
        cooperation_rate = total_opponent_actions / total_possible if total_possible > 0 else 0.0
        defection_rate = 1.0 - cooperation_rate
        return defection_rate

class Strategy_COLLECTIVE_238(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game

    Balances individual rationality with collective welfare through:
    - Optimistic cooperation in round 1
    - Defection in final round (no shadow of future)
    - Adaptive threshold reciprocity in mid-game rounds
    - Cooperation when cooperation_rate >= k/n threshold
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        prev_round_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        my_prev_action = history.my_actions[current_round - 1]
        if my_prev_action:
            prev_round_cooperators += 1
        cooperation_rate = prev_round_cooperators / self.n_players
        threshold = self.k / self.n_players
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_239(BaseStrategy):
    """
    Adaptive Proportional Reciprocity (APR) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare through:
    1. Rewarding cooperation when mutually beneficial
    2. Punishing defection proportionally to severity
    3. Recovering cooperation when opponent shows genuine change
    4. Adapting to game phases (early, middle, late)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        opponent_actions = history.opponent_actions[:round_num]
        opponent_coop_count = np.sum(opponent_actions)
        opponent_coop_rate = opponent_coop_count / (round_num * (self.n - 1))
        phase_position = round_num / self.r
        base_threshold = self.k / self.n
        if phase_position < 1 / 3:
            threshold = max(0, base_threshold - 0.15)
        elif phase_position > 2 / 3:
            middle_phase_start = math.ceil(self.r / 3)
            middle_phase_end = math.ceil(2 * self.r / 3)
            if round_num >= middle_phase_end:
                middle_phase_actions = opponent_actions[middle_phase_start:middle_phase_end]
                if middle_phase_actions.size > 0:
                    middle_phase_coop_count = np.sum(middle_phase_actions)
                    if middle_phase_coop_count == 0:
                        return Action.D
            threshold = base_threshold
        else:
            threshold = base_threshold
        if self.r <= 3:
            threshold = max(0.2, base_threshold - 0.1)
        if opponent_coop_rate >= threshold:
            return Action.C
        elif random.random() < opponent_coop_rate:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_240(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Maximizes collective welfare by establishing dynamic equilibrium that:
    - Rewards cooperation when others cooperate
    - Punishes defection proportionally
    - Recovers cooperation after punishment
    - Adapts to population composition

    Uses conditional contribution based on recent cooperation rates with adaptive thresholds
    that vary by game phase (early, middle, late).
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_index = current_round - 1
        cooperators_prev_round = sum(history.opponent_actions[prev_round_index, :])
        cooperation_rate = cooperators_prev_round / self.n
        threshold = self._calculate_threshold(current_round)
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_threshold(self, current_round: int) -> float:
        """
        Calculate adaptive threshold based on game phase.

        threshold(t) = k/n + (adjustment_factor  phase_weight(t))
        where adjustment_factor = (k/n - 1/n) / 2
        """
        base_threshold = self.k / self.n
        adjustment_factor = (self.k / self.n - 1 / self.n) / 2
        early_boundary = self.r / 3
        middle_boundary = 2 * self.r / 3
        if current_round <= early_boundary:
            phase_weight = 0.5
        elif current_round <= middle_boundary:
            phase_weight = 0.3
        else:
            phase_weight = 0.1
        threshold = base_threshold + adjustment_factor * phase_weight
        return threshold

class Strategy_COLLECTIVE_241(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) - A collective strategy that balances
    cooperative welfare maximization with self-protection through an adaptive threshold
    mechanism that decays over time.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        t = state.round_number
        if t == 0:
            return Action.C
        prev_round_idx = t - 1
        opponent_cooperators_prev = int(sum(history.opponent_actions[prev_round_idx, :]))
        my_action_prev = int(history.my_actions[prev_round_idx])
        total_cooperators_prev = opponent_cooperators_prev + my_action_prev
        cooperation_rate = total_cooperators_prev / n
        if t == r - 1:
            if cooperation_rate > k / n:
                return Action.C
            else:
                return Action.D
        min_threshold = k / n + 0.15
        decay_threshold = 0.5 - (t - 1) / (2 * r)
        threshold = max(min_threshold, decay_threshold)
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_242(BaseStrategy):
    """
    Adaptive Contribution with Conditional Defection Strategy.

    Balances collective welfare maximization with individual resilience through
    three phases: exploration (cooperate), adaptive response (monitor cooperation rates),
    and terminal phase (maintain cooperation only if healthy).
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.exploration_end = math.ceil(self.n_rounds / 3)
        self.adaptive_end = math.floor(2 * self.n_rounds / 3)
        self.threshold_high = 0.7
        self.threshold_low = 0.4
        self.degradation_threshold = 0.6
        self.terminal_threshold = 0.65
        self.cooperation_counts = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        self.cooperation_counts = []
        for r in range(round_num):
            opponent_coop_count = np.sum(history.opponent_actions[r, :])
            my_coop = 1 if history.my_actions[r] else 0
            total_cooperators = opponent_coop_count + my_coop
            self.cooperation_counts.append(total_cooperators)
        total_cooperation = sum(self.cooperation_counts)
        cooperation_rate = total_cooperation / (self.n_players * round_num)
        if round_num <= self.exploration_end:
            return Action.C
        elif round_num <= self.adaptive_end:
            if cooperation_rate >= self.threshold_high:
                return Action.C
            elif cooperation_rate < self.threshold_low:
                return Action.D
            elif self._check_degradation_pattern(round_num):
                return Action.D
            else:
                return Action.C
        elif cooperation_rate >= self.terminal_threshold:
            return Action.C
        else:
            return Action.D

    def _check_degradation_pattern(self, current_round: int) -> bool:
        """
        Check if the last 3 rounds show cooperation_rate < 0.60.
        Returns True if degradation detected, False otherwise.
        """
        rounds_to_check = min(3, current_round)
        if rounds_to_check < 3:
            return False
        for i in range(current_round - 3, current_round):
            if i < 0:
                continue
            coop_sum = sum(self.cooperation_counts[:i + 1])
            coop_rate = coop_sum / (self.n_players * (i + 1))
            if coop_rate >= self.degradation_threshold:
                return False
        return True

class Strategy_COLLECTIVE_243(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game.

    This strategy uses enlightened self-interest aligned with collective welfare.
    It cooperates conditionally based on observed group cooperation rates, using
    a threshold equal to the per-capita multiplier (k/n).

    Core logic:
    - Round 0: Always cooperate (signal cooperative intent)
    - Rounds 1+: Cooperate if previous round's cooperation rate >= k/n, else defect
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round_index = state.round_number - 1
        opponent_cooperators = sum(history.opponent_actions[previous_round_index, :])
        my_previous_action = history.my_actions[previous_round_index]
        total_cooperators = opponent_cooperators + (1 if my_previous_action else 0)
        cooperation_rate = total_cooperators / self.game_description.n_players
        if cooperation_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_244(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare through:
    1. Initial cooperation to establish commitment
    2. Dynamic adaptation based on observed cooperation rates
    3. Probability matching in mid-range cooperation environments
    4. Strategic defection only in mutual defection equilibrium
    5. Special handling for final round to maximize residual value
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_high = 0.75
        self.threshold_mid = 0.5
        self.threshold_low = 0.2
        self.p_low = 0.2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperation_rate = self._get_cooperation_rate(history, state.round_number - 1)
        if state.round_number == self.game_description.n_rounds - 1:
            if cooperation_rate >= self.threshold_low:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= self.threshold_high:
            return Action.C
        elif cooperation_rate >= self.threshold_mid:
            p_mid = cooperation_rate
            if random.random() < p_mid:
                return Action.C
            else:
                return Action.D
        elif cooperation_rate >= self.threshold_low:
            if random.random() < self.p_low:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _get_cooperation_rate(self, history: PlayerHistory, round_idx: int) -> float:
        """
        Calculate the cooperation rate in a given round.

        Args:
            history: PlayerHistory object containing opponent actions
            round_idx: Index of the round to analyze (0-indexed)

        Returns:
            Cooperation rate as a float between 0 and 1
        """
        cooperators_in_round = sum(history.opponent_actions[round_idx, :])
        total_opponents = self.game_description.n_players - 1
        my_action = history.my_actions[round_idx]
        total_cooperators = cooperators_in_round + (1 if my_action else 0)
        cooperation_rate = total_cooperators / self.game_description.n_players
        return cooperation_rate

class Strategy_COLLECTIVE_245(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare with individual security through adaptive reciprocity.
    Cooperates to establish beneficial equilibria, rewards collective contributions,
    punishes free-riding, and recovers gracefully when punishment fails.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.defection_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        coop_rate_last = self._get_cooperation_rate(history, round_num - 1)
        my_recent_payoff = self._get_recent_payoff(history, round_num)
        ideal_payoff = self.k
        sustainability_threshold = self.k / self.n_players
        if self.n_players <= 3:
            sustainability_threshold = 2 * self.k / self.n_players
        defection_threshold = sustainability_threshold
        if self.k > self.n_players * 0.8:
            defection_threshold = sustainability_threshold - 0.3
        if round_num >= self.n_rounds - 2:
            return self._endgame_decision(coop_rate_last, sustainability_threshold)
        if coop_rate_last >= sustainability_threshold:
            self.defection_counter = 0
            return Action.C
        if coop_rate_last >= 0.5 and my_recent_payoff >= 0.6 * ideal_payoff:
            self.defection_counter = 0
            return Action.C
        if coop_rate_last >= sustainability_threshold - 0.2 and round_num < self.n_rounds - 2:
            self.defection_counter = 0
            return Action.C
        if self._is_cooperation_volatile(history, round_num):
            self.defection_counter += 1
            return Action.D
        self.defection_counter += 1
        if coop_rate_last == 0:
            if self.defection_counter >= 3:
                self.defection_counter = 0
                return Action.C
            return Action.D
        if coop_rate_last >= 0.8:
            self.defection_counter = 0
            return Action.C
        return Action.D

    def _get_cooperation_rate(self, history: PlayerHistory, round_idx: int) -> float:
        """Calculate cooperation rate from all players in given round."""
        if round_idx < 0 or round_idx >= len(history.opponent_actions):
            return 0.0
        opponent_coops = int(np.sum(history.opponent_actions[round_idx, :]))
        my_action = int(history.my_actions[round_idx])
        total_coops = opponent_coops + my_action
        return total_coops / self.n_players

    def _get_recent_payoff(self, history: PlayerHistory, current_round: int) -> float:
        """Calculate average payoff from last 3 rounds."""
        if current_round == 0:
            return 0.0
        start_idx = max(0, current_round - 3)
        end_idx = current_round
        payoffs = history.my_payoffs[start_idx:end_idx]
        if len(payoffs) == 0:
            return 0.0
        return float(np.mean(payoffs))

    def _is_cooperation_volatile(self, history: PlayerHistory, current_round: int) -> bool:
        """Check if cooperation rate has high variance over last 3 rounds."""
        if current_round < 3:
            return False
        coop_rates = []
        for i in range(max(0, current_round - 3), current_round):
            coop_rates.append(self._get_cooperation_rate(history, i))
        if len(coop_rates) < 2:
            return False
        variance = float(np.var(coop_rates))
        return variance > 0.15

    def _endgame_decision(self, coop_rate_last: float, sustainability_threshold: float) -> Action:
        """Make decision in final 2 rounds."""
        if coop_rate_last >= sustainability_threshold:
            return Action.C
        if coop_rate_last < sustainability_threshold / 2:
            return Action.D
        prob = min(coop_rate_last, 0.7)
        return Action.C if random.random() < prob else Action.D

class Strategy_COLLECTIVE_246(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with individual security by:
    1. Initiating cooperation in round 1
    2. Adapting threshold based on observed cooperation rates
    3. Using moving averages to reduce noise
    4. Employing probabilistic mixing in ambiguous environments
    5. Making last-round decisions based on sustained cooperation
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        observed_rate = self._calculate_observed_cooperation_rate(history, current_round)
        recent_rates = self._get_recent_cooperation_rates(history, current_round)
        variance = self._calculate_variance(recent_rates)
        if variance > 0.09:
            observed_rate = np.mean(recent_rates)
        if self.n_players <= 3:
            base_threshold = 0.6
        else:
            base_threshold = 0.5
        threshold = max(0.4, min(0.7, base_threshold))
        if current_round == self.n_rounds - 1:
            if observed_rate >= 0.6:
                return Action.C
            else:
                return Action.D
        if observed_rate >= threshold:
            return Action.C
        elif observed_rate < threshold - 0.1:
            return Action.D
        elif random.random() < observed_rate:
            return Action.C
        else:
            return Action.D

    def _calculate_observed_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """Calculate the cooperation rate from all previous rounds."""
        if current_round <= 0:
            return 0.5
        total_cooperators = 0
        for round_idx in range(current_round):
            total_cooperators += np.sum(history.opponent_actions[round_idx, :])
        total_possible = self.n_players * current_round
        return total_cooperators / total_possible if total_possible > 0 else 0.5

    def _get_recent_cooperation_rates(self, history: PlayerHistory, current_round: int) -> list:
        """Get cooperation rates for the last 3 rounds."""
        rates = []
        start_round = max(0, current_round - 3)
        for round_idx in range(start_round, current_round):
            cooperators_in_round = np.sum(history.opponent_actions[round_idx, :])
            rate = cooperators_in_round / self.n_players
            rates.append(rate)
        return rates if rates else [0.5]

    def _calculate_variance(self, values: list) -> float:
        """Calculate variance of a list of values."""
        if len(values) <= 1:
            return 0.0
        mean_val = sum(values) / len(values)
        sum_sq_diff = sum(((x - mean_val) ** 2 for x in values))
        variance = sum_sq_diff / len(values)
        return variance

class Strategy_COLLECTIVE_247(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Operates in three phases:
    1. Cooperative Exploration (rounds 0 to ceil(r/3)-1): Unconditional cooperation
    2. Adaptive Reciprocity (rounds ceil(r/3) to floor(2r/3)-1): Cooperate if previous round cooperation >= threshold
    3. Strategic Endgame (rounds floor(2r/3) to r-1): Modified tit-for-tat with recovery attempt
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.phase1_end = math.ceil(self.n_rounds / 3)
        self.phase2_end = math.floor(2 * self.n_rounds / 3)
        self.threshold_T = 0.5 * (self.n_players - 1) / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round < self.phase1_end:
            return Action.C
        prev_coop_rate = self._get_previous_round_cooperation_rate(history, current_round)
        if current_round < self.phase2_end:
            if prev_coop_rate >= self.threshold_T:
                return Action.C
            else:
                return Action.D
        elif prev_coop_rate >= self.threshold_T:
            return Action.C
        elif current_round == self.n_rounds - 1:
            return Action.D
        else:
            return Action.C

    def _get_previous_round_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the cooperation rate in the previous round.
        Returns a value between 0 and 1 representing the fraction of players who cooperated.
        """
        prev_round_idx = current_round - 1
        my_coop = int(history.my_actions[prev_round_idx])
        opponent_coops = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        total_cooperators = my_coop + opponent_coops
        cooperation_rate = total_cooperators / self.n_players
        return cooperation_rate

class Strategy_COLLECTIVE_248(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game

    This strategy implements conditional cooperation based on adaptive thresholds:
    - Round 1: Always cooperate to establish cooperative tone and gather information
    - Subsequent rounds: Cooperate if the cooperation rate in the previous round meets
      or exceeds the threshold (k/n), otherwise defect

    The threshold k/n represents the breakeven point where cooperators earn at least
    as much as defectors, ensuring cooperation is self-sustaining when widespread.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round_index = state.round_number - 1
        cooperators_in_previous = sum(history.opponent_actions[previous_round_index, :])
        my_previous_action = history.my_actions[previous_round_index]
        total_cooperators = cooperators_in_previous + (1 if my_previous_action else 0)
        coop_rate = total_cooperators / self.n_players
        threshold = self.k / self.n_players
        if coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_249(BaseStrategy):
    """
    Adaptive Threshold Reciprocity with Decay Strategy for N-Player Public Goods Game.

    Cooperates when recent cooperation rate exceeds a threshold calculated as (k-1)/n,
    adapting to local conditions over a rolling window of approximately r/3 rounds.
    Always cooperates in the first round to establish reciprocal cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.window_size = max(2, math.floor(self.r / 3))
        self.threshold = (self.k - 1) / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        recent_cooperation_rate = self._calculate_recent_cooperation_rate(history, round_t)
        if recent_cooperation_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory, round_t: int) -> float:
        """
        Calculate the average cooperation rate among all players in recent rounds.

        Uses the last window_size rounds, or all available history if fewer rounds have passed.
        """
        if round_t <= self.window_size:
            start_round = 0
            end_round = round_t
        else:
            start_round = round_t - self.window_size
            end_round = round_t
        num_rounds_to_consider = end_round - start_round
        if num_rounds_to_consider <= 0:
            return 0.0
        my_cooperations = np.sum(history.my_actions[start_round:end_round])
        opponent_cooperations = np.sum(history.opponent_actions[start_round:end_round, :])
        total_cooperations = my_cooperations + opponent_cooperations
        total_actions = num_rounds_to_consider * self.n
        recent_cooperation_rate = total_cooperations / total_actions
        return recent_cooperation_rate

class Strategy_COLLECTIVE_250(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization, robustness against exploitation, and graceful
    degradation through an adaptive threshold mechanism. Cooperates in Round 1 as a signal
    of good faith, then conditions future cooperation on whether the observed cooperation
    rate exceeds k/(2n), the threshold below which collective action becomes unprofitable.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold = self.k / (2 * self.n)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        previous_round_idx = round_number - 1
        cooperators_in_prev_round = int(np.sum(history.opponent_actions[previous_round_idx, :]))
        if history.my_actions[previous_round_idx]:
            cooperators_in_prev_round += 1
        observed_coop_rate = cooperators_in_prev_round / self.n
        if round_number == self.r - 1:
            if observed_coop_rate >= self.threshold:
                return Action.C
            else:
                return Action.D
        if observed_coop_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_251(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) strategy for N-Player Public Goods Game.

    Balances collective welfare maximization, individual sustainability, and robustness
    through three phases: opening cooperation, adaptive reciprocity with forgiveness,
    and strategic endgame defection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.rounds_below_threshold = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        n = self.n_players
        r = self.n_rounds
        opening_threshold = math.floor(r / 4)
        if round_num < opening_threshold:
            return Action.C
        if round_num == r - 1:
            return Action.D
        coop_rate = self._calculate_cooperation_rate(history, round_num)
        threshold_current = max(0.4, 0.5 - round_num / 100.0)
        recent_mass_defection = self._check_recent_mass_defection(history, round_num)
        sustained_defection = coop_rate < threshold_current and self.rounds_below_threshold > 2
        unanimous_cooperation = self._check_unanimous_cooperation(history, round_num)
        if unanimous_cooperation:
            return Action.C
        unanimous_defection = self._check_unanimous_defection(history, round_num)
        if unanimous_defection:
            return Action.D
        if coop_rate >= threshold_current or recent_mass_defection:
            self.rounds_below_threshold = 0
            return Action.C
        elif sustained_defection:
            return Action.D
        else:
            if coop_rate < threshold_current:
                self.rounds_below_threshold += 1
            else:
                self.rounds_below_threshold = 0
            return Action.C

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate the average cooperation rate of all other players
        across all observed rounds so far.
        """
        if round_num == 0:
            return 0.5
        opponent_coop_counts = np.sum(history.opponent_actions[:round_num, :])
        total_opponent_actions = round_num * (self.n_players - 1)
        if total_opponent_actions == 0:
            return 0.5
        return float(opponent_coop_counts) / float(total_opponent_actions)

    def _check_recent_mass_defection(self, history: PlayerHistory, round_num: int) -> bool:
        """
        Check if there's been a mass defection wave within the last 2 rounds.
        Returns True if we should give another chance (forgiveness mechanism).
        """
        if round_num < 2:
            return False
        recent_rounds = history.opponent_actions[max(0, round_num - 2):round_num, :]
        recent_coop_rate = np.mean(recent_rounds)
        return recent_coop_rate > 0.5

    def _check_unanimous_cooperation(self, history: PlayerHistory, round_num: int) -> bool:
        """
        Check if all other players have shown 95% cooperation for 3+ consecutive rounds.
        """
        if round_num < 3:
            return False
        last_3_rounds = history.opponent_actions[round_num - 3:round_num, :]
        coop_rate = np.mean(last_3_rounds)
        return coop_rate >= 0.95

    def _check_unanimous_defection(self, history: PlayerHistory, round_num: int) -> bool:
        """
        Check if all other players have shown <10% cooperation for 3+ consecutive rounds.
        """
        if round_num < 3:
            return False
        last_3_rounds = history.opponent_actions[round_num - 3:round_num, :]
        coop_rate = np.mean(last_3_rounds)
        return coop_rate < 0.1

class Strategy_COLLECTIVE_252(BaseStrategy):
    """
    Adaptive Reciprocal Maximization (ARM) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective benefit maximization by:
    - Cooperating in round 1 to establish cooperative benchmark
    - Using adaptive thresholds in middle rounds based on observed cooperation
    - Defecting in the final round (backward induction)
    - Gradually relaxing cooperation threshold over time
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.r - 1:
            return Action.D
        estimated_cooperators = self._estimate_cooperators(history, round_number)
        threshold = self._calculate_threshold(round_number)
        if estimated_cooperators >= threshold:
            return Action.C
        else:
            return Action.D

    def _estimate_cooperators(self, history: PlayerHistory, round_number: int) -> float:
        """
        Estimate number of cooperators based on recent history.
        """
        observed_actions = history.opponent_actions[:round_number]
        window_size = min(3, round_number)
        recent_window = observed_actions[-window_size:]
        if len(recent_window) == 0:
            return self.n / 2.0
        cooperation_count = np.sum(recent_window)
        cooperation_rate = cooperation_count / (len(recent_window) * self.n)
        estimated_cooperators = self.n * cooperation_rate
        consecutive_defects = self._count_consecutive_defects(history.opponent_actions[:round_number])
        dampening_factor = 1.0 - 0.05 * consecutive_defects
        estimated_cooperators = estimated_cooperators * dampening_factor
        return estimated_cooperators

    def _count_consecutive_defects(self, opponent_actions: NDArray[np.bool_]) -> int:
        """
        Count consecutive defect rounds at the end of history.
        Defect is False (0), Cooperate is True (1).
        """
        if len(opponent_actions) == 0:
            return 0
        consecutive_count = 0
        for i in range(len(opponent_actions) - 1, -1, -1):
            round_all_defected = np.all(opponent_actions[i] == 0)
            if round_all_defected:
                consecutive_count += 1
            else:
                break
        return consecutive_count

    def _calculate_threshold(self, round_number: int) -> float:
        """
        Calculate adaptive cooperation threshold based on:
        - Game structure (k value)
        - Round progress (t/r)
        - Efficiency considerations
        """
        min_threshold = math.ceil(self.k)
        efficiency_threshold = math.ceil(self.n * self.k / (self.k + 2)) * 0.85
        progress_ratio = round_number / (self.r - 1)
        progressive_threshold = 0.5 + progress_ratio * 0.3
        threshold = max(min_threshold, efficiency_threshold, progressive_threshold)
        return threshold

class Strategy_COLLECTIVE_253(BaseStrategy):
    """
    Adaptive Collective Strategy: "Proportional Reciprocity with Decay Prevention"

    Balances individual rationality against group welfare by adaptively calibrating
    cooperation based on observed group behavior. Cooperates when expected benefit
    from public good exceeds private benefit of defection, with special handling
    for early/late rounds and exploitation prevention.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.active_defection_phase = 0
        self.defection_timer = 0
        self.cooperation_history = []
        self.threshold = (self.n - self.n ** 2 / self.k) / self.n
        self.buffer = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            self.cooperation_history.append(1.0)
            return Action.C
        coop_last_round = sum(history.opponent_actions[round_num - 1, :])
        observed_rate = coop_last_round / self.n
        historical_avg = np.mean(self.cooperation_history) if self.cooperation_history else 0.5
        alpha = min(0.7, round_num / self.r)
        expected_rate = alpha * observed_rate + (1 - alpha) * historical_avg
        if len(self.cooperation_history) > 1:
            prev_rate = self.cooperation_history[-1]
            cooperation_trend = observed_rate - prev_rate
            if cooperation_trend > 0 and observed_rate < self.threshold and (self.defection_timer > 0):
                self.defection_timer = max(0, self.defection_timer - 1)
            if cooperation_trend < 0 and prev_rate >= self.threshold:
                self.defection_timer = min(3, self.defection_timer + 1)
        if self.active_defection_phase > 0:
            self.active_defection_phase -= 1
            self.cooperation_history.append(observed_rate)
            return Action.D
        collapse_threshold = self.threshold - self.buffer
        if expected_rate < collapse_threshold and observed_rate < collapse_threshold:
            self.active_defection_phase = 2
            self.defection_timer = 2
            self.cooperation_history.append(observed_rate)
            return Action.D
        if round_num == self.r - 1:
            self.cooperation_history.append(observed_rate)
            if expected_rate >= self.threshold:
                return Action.C
            else:
                return Action.D
        self.cooperation_history.append(observed_rate)
        if expected_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_254(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) - A collective strategy for N-Player Public Goods Game.

    Balances individual incentives with collective welfare by:
    1. Starting with optimistic cooperation (rounds 0-2)
    2. Dynamically adjusting based on observed cooperation rate vs threshold
    3. Punishing defection with cooldown periods
    4. Defecting unconditionally in the final round (subgame perfect equilibrium)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold = max(0.4, (self.k - 1) / (self.n - 1))
        self.defection_cooldown = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num <= 2:
            return Action.C
        if round_num == self.r - 1:
            return Action.D
        if round_num == self.r - 2:
            coop_rate = self._calculate_cooperation_rate(history)
            if coop_rate >= self.threshold:
                return Action.C
            else:
                return Action.D
        if self.defection_cooldown > 0:
            self.defection_cooldown -= 1
            return Action.D
        coop_rate = self._calculate_cooperation_rate(history)
        if coop_rate >= self.threshold:
            return Action.C
        else:
            self.defection_cooldown = 2
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        """
        Calculate the cooperation rate of other players.
        Uses exponential weighting on recent rounds to handle sparse information.
        """
        if history is None or len(history.opponent_actions) == 0:
            return 0.5
        recent_window_size = min(5, len(history.opponent_actions))
        recent_actions = history.opponent_actions[-recent_window_size:, :]
        total_cooperations = np.sum(recent_actions)
        total_actions = recent_actions.size
        if total_actions == 0:
            return 0.5
        coop_rate = total_cooperations / total_actions
        if coop_rate == 0 and len(history.opponent_actions) >= 3:
            return 0.0
        return coop_rate

class Strategy_COLLECTIVE_255(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    This strategy balances individual rationality with collective welfare by:
    1. Cooperating in round 1 to signal willingness and gather information
    2. Using a threshold-based decision rule in subsequent rounds:
       - Cooperate if observed cooperation rate >= k/n (break-even point)
       - Defect if observed cooperation rate < k/n (public good underfunded)
    3. Maintaining threshold logic in the final round (no end-game defection spiral)
    4. Tracking cooperation trends to prevent slow-bleed exploitation

    The strategy creates emergent cooperation at the break-even threshold where
    the public good becomes individually rational to support.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.k / game_description.n_players
        self.last_action = None
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            self.last_action = Action.C
            return Action.C
        previous_round_index = state.round_number - 1
        opponent_actions_previous = history.opponent_actions[previous_round_index, :]
        cooperators_last_round = int(np.sum(opponent_actions_previous))
        if self.last_action == Action.C:
            total_cooperators = cooperators_last_round + 1
        else:
            total_cooperators = cooperators_last_round
        observed_cooperation_rate = total_cooperators / self.game_description.n_players
        self.cooperation_history.append(observed_cooperation_rate)
        if state.round_number == self.game_description.n_rounds - 1:
            if observed_cooperation_rate >= self.cooperation_threshold:
                self.last_action = Action.C
                return Action.C
            else:
                self.last_action = Action.D
                return Action.D
        oscillation_dampen = False
        if self.last_action == Action.C and observed_cooperation_rate < self.cooperation_threshold and (len(self.cooperation_history) >= 2):
            if self.cooperation_history[-2] >= self.cooperation_threshold:
                oscillation_dampen = True
        if oscillation_dampen:
            self.last_action = Action.C
            return Action.C
        momentum_threshold_met = False
        if len(self.cooperation_history) >= 3:
            recent_rates = self.cooperation_history[-3:]
            recent_average = np.mean(recent_rates)
            is_trending_down = recent_rates[-1] < recent_rates[-2] < recent_rates[-3] or recent_rates[-1] < recent_rates[-2]
            if is_trending_down and recent_average < self.cooperation_threshold:
                momentum_threshold_met = True
        if momentum_threshold_met:
            self.last_action = Action.D
            return Action.D
        elif observed_cooperation_rate >= self.cooperation_threshold:
            self.last_action = Action.C
            return Action.C
        else:
            self.last_action = Action.D
            return Action.D

class Strategy_COLLECTIVE_256(BaseStrategy):
    """
    Adaptive Contribution with Reciprocal Decay (ACRD) strategy for N-Player Public Goods Game.

    Combines reciprocal altruism with mathematical adaptation by:
    1. Tracking cooperation rates against a viability threshold (k-1)/k
    2. Applying round-specific logic (early: cooperate, middle: threshold-based, late: escalating pressure)
    3. Using momentum tracking to detect cooperation trends
    4. Handling edge cases (unanimous defection, near-perfect cooperation, etc.)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.viability_threshold = (self.k - 1) / self.k
        self.high_cooperation_threshold = 0.9
        self.extreme_dilution_threshold = 0.05
        self.momentum_positive_threshold = 0.2
        self.momentum_negative_threshold = -0.2
        self.rapid_shift_threshold = 0.4
        self.escalation_step = 0.15
        self.escalating_defection_probability = 0.0
        self.unanimous_defection_break_attempted = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        n = self.n_players
        k = self.k
        r = self.n_rounds
        if k / n < self.extreme_dilution_threshold:
            return Action.D
        all_actions = np.concatenate([history.my_actions[:round_num].reshape(-1, 1), history.opponent_actions[:round_num, :]], axis=1)
        total_cooperators = np.sum(all_actions)
        total_actions = round_num * n
        cooperation_rate = total_cooperators / total_actions if total_actions > 0 else 0.0
        if cooperation_rate == 0.0 and round_num > 1:
            if not self.unanimous_defection_break_attempted:
                self.unanimous_defection_break_attempted = True
                return Action.C
            else:
                return Action.D
        if cooperation_rate > self.high_cooperation_threshold:
            return Action.C
        early_threshold = r / 3.0
        late_threshold = 2.0 * r / 3.0
        if round_num <= early_threshold:
            return Action.C
        if round_num == r - 1:
            if cooperation_rate > self.viability_threshold:
                return Action.C
            else:
                return Action.D
        if round_num > late_threshold:
            window_size = max(1, r // 6)
            if round_num >= 2 * window_size:
                last_window_coop = np.sum(all_actions[max(0, round_num - window_size):round_num, :])
                prior_window_coop = np.sum(all_actions[max(0, round_num - 2 * window_size):round_num - window_size, :])
                if prior_window_coop > 0:
                    last_rate = last_window_coop / (window_size * n)
                    prior_rate = prior_window_coop / (window_size * n)
                    if last_rate < prior_rate:
                        self.escalating_defection_probability = min(1.0, self.escalating_defection_probability + self.escalation_step)
                        if random.random() < self.escalating_defection_probability:
                            return Action.D
            if cooperation_rate > self.viability_threshold:
                return Action.C
            else:
                return Action.D
        momentum = self._calculate_momentum(history, round_num)
        if round_num >= 1:
            prev_coop_in_round = np.sum(all_actions[round_num - 1, :])
            curr_avg = cooperation_rate
            if abs(prev_coop_in_round / n - curr_avg) > self.rapid_shift_threshold:
                pass
        if momentum > self.momentum_positive_threshold:
            return Action.C
        elif momentum < self.momentum_negative_threshold:
            return Action.D
        elif cooperation_rate > self.viability_threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_momentum(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate momentum as the change in cooperation between two 3-round windows.
        """
        if round_num < 6:
            return 0.0
        n = self.n_players
        window_size = 3
        all_actions = np.concatenate([history.my_actions[:round_num].reshape(-1, 1), history.opponent_actions[:round_num, :]], axis=1)
        last_window_coop = np.sum(all_actions[max(0, round_num - window_size):round_num, :])
        prior_window_coop = np.sum(all_actions[max(0, round_num - 2 * window_size):round_num - window_size, :])
        if prior_window_coop == 0:
            return 0.0
        momentum = (last_window_coop - prior_window_coop) / prior_window_coop
        return momentum

class Strategy_COLLECTIVE_257(BaseStrategy):
    """
    Adaptive Reciprocal Maximization (ARM) Strategy for N-Player Public Goods Game.

    Balances individual security, collective benefit, and adaptive learning through:
    - Dynamic cooperation threshold based on observed cooperation rates
    - Round-specific modifiers (special handling for first/last rounds)
    - Adaptive reciprocity rules (punishment, recovery, escalation)
    - Grace period to encourage cooperation emergence
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.in_defection_mode = False
        self.defection_mode_rounds_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        obs_coop_rate = self._calculate_observed_cooperation_rate(history, round_t)
        base_threshold = (self.k - 1) / (self.k * self.n)
        threshold = base_threshold + 0.15
        if round_t > 0.9 * self.r:
            threshold -= 0.05
        if self.in_defection_mode:
            self.defection_mode_rounds_remaining -= 1
            if self.defection_mode_rounds_remaining <= 0:
                self.in_defection_mode = False
            if obs_coop_rate > base_threshold:
                self.in_defection_mode = False
                threshold -= 0.1
        my_defection_rate = self._calculate_my_defection_rate(history)
        if my_defection_rate > obs_coop_rate:
            threshold -= 0.05
        if round_t == self.r - 1:
            if obs_coop_rate >= 0.8:
                return Action.C
        if obs_coop_rate >= threshold:
            decision = Action.C
        else:
            decision = Action.D
            if obs_coop_rate < base_threshold:
                if self._check_persistent_defection(history, round_t, base_threshold):
                    self.in_defection_mode = True
                    self.defection_mode_rounds_remaining = 2
        return decision

    def _calculate_observed_cooperation_rate(self, history: PlayerHistory, round_t: int) -> float:
        """Calculate the observed cooperation rate from all previous rounds."""
        if round_t == 0:
            return 0.5
        total_cooperators = np.sum(history.opponent_actions[:round_t, :])
        total_possible = self.n * round_t
        return float(total_cooperators) / float(total_possible)

    def _calculate_my_defection_rate(self, history: PlayerHistory) -> float:
        """Calculate the player's own defection rate so far."""
        my_defections = np.sum(~history.my_actions)
        total_rounds = len(history.my_actions)
        if total_rounds == 0:
            return 0.0
        return float(my_defections) / float(total_rounds)

    def _check_persistent_defection(self, history: PlayerHistory, round_t: int, base_threshold: float) -> bool:
        """Check if there's been persistent defection for 3+ consecutive rounds."""
        if round_t < 3:
            return False
        for i in range(max(0, round_t - 3), round_t):
            round_cooperators = np.sum(history.opponent_actions[i, :])
            round_coop_rate = float(round_cooperators) / float(self.n)
            if round_coop_rate >= base_threshold:
                return False
        return True

class Strategy_COLLECTIVE_258(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy

    Balances individual rationality with collective welfare through conditional cooperation
    that adapts to observed defection rates. Uses weighted recency, threshold adjustment,
    and exploitation detection to optimize decisions across repeated public goods games.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.decay_factor = 0.85
        self.window_size = 5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == r - 1:
            return Action.D
        cooperation_rate = self._calculate_weighted_cooperation_rate(history, round_num)
        t_high, t_med, t_low = self._adjust_thresholds(k, n)
        avg_payoff = self._calculate_average_payoff(history)
        expected_all_cooperate = k
        if avg_payoff < expected_all_cooperate * 0.6:
            t_high = max(0.0, t_high - 0.1)
            t_med = max(0.0, t_med - 0.1)
            t_low = max(0.0, t_low - 0.1)
        if cooperation_rate >= t_high:
            return Action.C
        elif cooperation_rate >= t_med:
            if random.random() < cooperation_rate:
                return Action.C
            else:
                return Action.D
        elif cooperation_rate >= t_low:
            return Action.D
        else:
            return Action.D

    def _calculate_weighted_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate cooperation rate with recency weighting.
        """
        n = self.game_description.n_players
        start_round = max(0, round_num - self.window_size)
        total_weight = 0.0
        weighted_cooperators = 0.0
        for t in range(start_round, round_num):
            weight = self.decay_factor ** (round_num - t - 1)
            total_weight += weight
            cooperators_in_round = int(history.my_actions[t]) + np.sum(history.opponent_actions[t, :])
            weighted_cooperators += cooperators_in_round * weight
        if total_weight == 0:
            return 0.0
        weighted_rate = weighted_cooperators / (total_weight * n)
        return min(1.0, max(0.0, weighted_rate))

    def _adjust_thresholds(self, k: float, n: int) -> tuple:
        """
        Adjust thresholds based on k/n ratio.
        """
        ratio = k / n
        if ratio > 0.5:
            return (0.6, 0.3, 0.1)
        elif ratio > 0.3:
            return (0.7, 0.4, 0.15)
        else:
            return (0.8, 0.5, 0.2)

    def _calculate_average_payoff(self, history: PlayerHistory) -> float:
        """
        Calculate average payoff across all rounds so far.
        """
        if len(history.my_payoffs) == 0:
            return 0.0
        return float(np.mean(history.my_payoffs))

class Strategy_COLLECTIVE_259(BaseStrategy):
    """
    Adaptive Contribution Based on Reciprocal Efficiency.

    This strategy maximizes collective welfare by learning the environment's cooperativeness,
    contributing when the public good is efficient, and protecting against exploitation
    without destructive cycles.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        window_size = max(3, self.n_rounds // 3)
        start_idx = max(0, current_round - window_size)
        recent_actions = history.opponent_actions[start_idx:current_round, :]
        if recent_actions.size == 0:
            observed_coop_rate = 0.0
        else:
            total_cooperations = np.sum(recent_actions)
            total_opportunities = recent_actions.size
            observed_coop_rate = total_cooperations / total_opportunities if total_opportunities > 0 else 0.0
        if current_round == self.n_rounds - 1:
            if observed_coop_rate > 0.2:
                return Action.C
            else:
                return Action.D
        expected_return = observed_coop_rate * self.k / self.n_players
        threshold = 1.0 - 1.0 / self.n_players
        if expected_return >= threshold:
            return Action.C
        elif observed_coop_rate > 0.15:
            if random.random() < observed_coop_rate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_260(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC): A dynamic strategy balancing collective welfare
    maximization with robust defection deterrence through conditional cooperation with
    graduated punishment and adaptive thresholds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            return Action.C
        previous_round_idx = current_round - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[previous_round_idx, :]))
        cooperation_rate = cooperators_last_round / self.n
        epsilon = max(0.05, 0.15 - current_round / self.r * 0.1)
        threshold = self.k / self.n + epsilon
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_261(BaseStrategy):
    """
    Adaptive Contribution Equilibrium (ACE) Strategy for N-Player Public Goods Game

    Balances collective welfare with individual robustness by continuously estimating
    the cooperative capacity of the population and contributing proportionally.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_high = 0.7
        self.threshold_low = 0.3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round_idx = state.round_number - 1
        opponent_cooperators = sum(history.opponent_actions[prev_round_idx, :])
        my_prev_action = history.my_actions[prev_round_idx]
        total_cooperators = opponent_cooperators + (1 if my_prev_action else 0)
        observed_coop_rate = total_cooperators / self.game_description.n_players
        if observed_coop_rate >= self.threshold_high:
            return Action.C
        elif observed_coop_rate <= self.threshold_low:
            return Action.D
        else:
            expected_payoff_if_C = self.game_description.k / self.game_description.n_players * (total_cooperators + 1)
            expected_payoff_if_D = 1 + self.game_description.k / self.game_description.n_players * total_cooperators
            if expected_payoff_if_C >= expected_payoff_if_D:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_262(BaseStrategy):
    """
    Adaptive Contribution Threshold (ACT) Strategy

    Balances collective welfare with individual security through dynamic reciprocity.
    - Round 1: Cooperate (test reciprocity)
    - Rounds 2 to r-1: Conditional cooperation based on cooperation ratio vs adaptive threshold
    - Final round: Defect (no future benefit from cooperation)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.base_threshold = self.k / self.n_players

    def _phase_adjustment(self, round_number: int) -> float:
        """
        Compute phase adjustment based on game stage.
        round_number is 0-indexed.
        """
        one_third = self.n_rounds / 3.0
        two_thirds = 2.0 * self.n_rounds / 3.0
        if round_number < one_third:
            return 0.15
        elif round_number < two_thirds:
            return 0.05
        else:
            return -0.1

    def _compute_cooperation_ratio(self, history: PlayerHistory, round_idx: int) -> float:
        """
        Compute the cooperation ratio from a specific round.
        round_idx is 0-indexed into the history arrays.
        Returns the fraction of opponents who cooperated in that round.
        """
        if round_idx < 0 or round_idx >= len(history.opponent_actions):
            return 0.0
        cooperators_in_round = int(np.sum(history.opponent_actions[round_idx, :]))
        coop_ratio = cooperators_in_round / self.n_players
        return coop_ratio

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.n_rounds - 1:
            return Action.D
        prev_round_idx = round_number - 1
        coop_ratio = self._compute_cooperation_ratio(history, prev_round_idx)
        phase_adj = self._phase_adjustment(round_number)
        threshold = self.base_threshold + phase_adj
        if coop_ratio >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_263(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC): A learning strategy that balances individual
    rationality with collective welfare by adapting cooperation thresholds based on
    observed population behavior, while respecting the finite horizon by defecting
    in the final round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.r - 1:
            return Action.D
        cooperators_past = 0
        for round_idx in range(round_number):
            cooperators_past += sum(history.opponent_actions[round_idx, :])
        cooperation_rate = cooperators_past / (round_number * (self.n - 1))
        min_cooperators_needed = math.ceil((self.n - 1) / self.k)
        if cooperation_rate >= 0.5:
            return Action.C
        elif cooperation_rate >= 1.0 / self.k:
            expected_cooperators = (self.n - 1) * cooperation_rate
            if expected_cooperators >= min_cooperators_needed:
                return Action.C
            else:
                return Action.D
        elif cooperation_rate < 0.2:
            return Action.D
        elif round_number <= self.r / 2.0:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_264(BaseStrategy):
    """
    Adaptive Reciprocal Maximization (ARM) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare through adaptive
    conditional cooperation, threshold-based response, and strategic last-round
    exploitation when appropriate.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        all_cooperators = 0
        total_actions = 0
        for t in range(round_num):
            all_cooperators += int(history.my_actions[t])
            all_cooperators += np.sum(history.opponent_actions[t, :])
            total_actions += self.n
        cooperation_rate = all_cooperators / total_actions if total_actions > 0 else 0.0
        threshold = self.k / self.n
        buffer = (1.0 - self.k / self.n) * 0.15
        if self.n <= 3:
            buffer = buffer * 0.5
        if self.k < 1.1:
            threshold = self.k / self.n + 0.05
        if round_num == self.r - 1:
            if self.r <= 3:
                return Action.C
            if cooperation_rate > threshold + buffer:
                return Action.D
            else:
                return Action.C
        if cooperation_rate >= threshold + buffer:
            return Action.C
        elif cooperation_rate <= threshold - buffer:
            return Action.D
        else:
            escalation_factor = round_num / (self.r - 1) if self.r > 1 else 0.0
            defection_prob = 0.4 - 0.4 * escalation_factor
            if random.random() < defection_prob:
                return Action.D
            else:
                return Action.C

class Strategy_COLLECTIVE_265(BaseStrategy):
    """
    Adaptive Conditional Cooperation with Decay Strategy for N-Player Public Goods Game.

    This strategy embodies enlightened self-interest aligned with collective welfare:
    - Cooperates by default to establish mutual benefit
    - Responds conditionally based on observed cooperation rates in previous rounds
    - Uses dual thresholds (strict and generous) to balance exploitation protection with group resilience
    - Adapts behavior based on game parameters (n players, k multiplication factor)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold_strict = (self.k - 1) / self.k
        self.threshold_generous = (self.k - 1) / (2 * self.k)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round_idx = state.round_number - 1
        opponent_cooperators = sum(history.opponent_actions[previous_round_idx, :])
        our_cooperation = 1 if history.my_actions[previous_round_idx] else 0
        total_cooperators = opponent_cooperators + our_cooperation
        cooperation_rate = total_cooperators / self.n
        if state.round_number == self.r - 1:
            if cooperation_rate >= self.threshold_strict:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= self.threshold_strict:
            return Action.C
        elif cooperation_rate >= self.threshold_generous:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_266(BaseStrategy):
    """
    Adaptive Contribution Threshold (ACT) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare by dynamically adjusting
    cooperation based on empirical evidence of group cooperation levels.

    - Round 0: COOPERATE (initialization, assume good faith)
    - Rounds 1 to r-2: Adaptive threshold - cooperate if observed cooperation rate >= k/n
    - Round r-1: DEFECT (last round, individual rationality dominates)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            return Action.D
        past_rounds = current_round
        total_cooperators = np.sum(history.opponent_actions[:past_rounds, :])
        total_possible = past_rounds * self.n
        if total_possible == 0:
            cooperation_rate = 0.0
        else:
            cooperation_rate = total_cooperators / total_possible
        if cooperation_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_267(BaseStrategy):
    """
    Adaptive Contribution Threshold (ACT) Strategy for N-Player Public Goods Game

    Cooperates if expected collective benefit exceeds private cost, based on observed
    cooperation rates. Round 1 cooperates to test reciprocation. Final round uses
    myopic optimization. Middle rounds use adaptive threshold logic.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.r - 1:
            return self._decide_final_round(history)
        return self._decide_middle_round(history)

    def _decide_final_round(self, history: PlayerHistory) -> Action:
        """
        Final round decision: cooperate if collective payoff from cooperation
        exceeds payoff from defection in this round only.
        """
        cooperators_last = int(np.sum(history.opponent_actions[-1, :]))
        cooperators_if_cooperate = cooperators_last + 1
        payoff_cooperate = self.k / self.n * cooperators_if_cooperate
        payoff_defect = 1 + self.k / self.n * cooperators_last
        if payoff_cooperate > payoff_defect:
            return Action.C
        else:
            return Action.D

    def _decide_middle_round(self, history: PlayerHistory) -> Action:
        """
        Middle rounds decision: cooperate if expected cooperators exceed threshold.

        Threshold: n * (1 - k) / k
        Expected cooperators based on last round's cooperation rate.
        """
        cooperators_last = int(np.sum(history.opponent_actions[-1, :]))
        cooperation_rate = cooperators_last / self.n
        expected_cooperators = cooperation_rate * self.n
        threshold = self.n * (1 - self.k) / self.k
        if expected_cooperators > threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_268(BaseStrategy):
    """
    Adaptive Contribution with Threshold Monitoring strategy for N-Player Public Goods Game.

    This strategy pursues conditional cooperation with collective welfare optimization.
    It cooperates when the cooperation rate exceeds a rational threshold, and adapts
    to community contribution patterns to encourage sustainable cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        threshold = (self.n - self.k) / (self.n - 1)
        if self.k >= self.n - 0.5:
            recent_coop_rate = self._get_recent_cooperation_rate(history, current_round)
            return Action.C if recent_coop_rate >= 0.3 else Action.D
        if self.k <= 1.5 and self.n >= 3:
            recent_coop_rate = self._get_recent_cooperation_rate(history, current_round)
            return Action.C if recent_coop_rate >= 0.9 else Action.D
        if current_round == self.r - 1:
            if current_round == 0:
                return Action.C
            last_round_coop_rate = self._get_cooperation_rate_at_round(history, current_round - 1)
            return Action.C if last_round_coop_rate >= threshold else Action.D
        recent_coop_rate = self._get_recent_cooperation_rate(history, current_round)
        if recent_coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _get_cooperation_rate_at_round(self, history: PlayerHistory, round_idx: int) -> float:
        """Get the cooperation rate (proportion of cooperators) at a specific round."""
        if round_idx < 0 or round_idx >= len(history.opponent_actions):
            return 0.0
        opponent_cooperators = np.sum(history.opponent_actions[round_idx, :])
        self_cooperated = history.my_actions[round_idx]
        total_cooperators = opponent_cooperators + (1 if self_cooperated else 0)
        return total_cooperators / self.n

    def _get_recent_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Get cooperation rate using a weighted average of recent rounds for stability.
        Uses up to last 3 rounds to prevent jittering on noise.
        """
        if current_round == 0:
            return 0.0
        lookback_window = min(3, current_round) if self.n >= 3 else 1
        coop_rates = []
        for i in range(max(0, current_round - lookback_window), current_round):
            coop_rates.append(self._get_cooperation_rate_at_round(history, i))
        if not coop_rates:
            return 0.0
        return np.mean(coop_rates)

class Strategy_COLLECTIVE_269(BaseStrategy):
    """
    Adaptive Contribution with Graduated Defection Recovery.

    Maximizes collective welfare while protecting against exploitation through:
    1. Initial cooperation to signal trustworthiness
    2. Adaptive tit-for-tat based on observed cooperation rates
    3. Graduated defection thresholds that respond to collective commitment
    4. Recovery mechanisms for groups showing renewed cooperation
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.consecutive_low_cooperation = 0
        self.threshold_high = 0.75
        self.threshold_medium = self.k / self.n / 2
        self.threshold_low = self.k / (2 * self.n)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round_idx = state.round_number - 1
        my_prev_action = history.my_actions[previous_round_idx]
        opponent_cooperators = sum(history.opponent_actions[previous_round_idx, :])
        total_cooperators = opponent_cooperators + (1 if my_prev_action else 0)
        cooperation_rate = total_cooperators / self.n
        if cooperation_rate >= self.threshold_high:
            self.consecutive_low_cooperation = 0
            return Action.C
        elif cooperation_rate >= self.threshold_medium:
            self.consecutive_low_cooperation = 0
            if random.random() < cooperation_rate:
                return Action.C
            else:
                return Action.D
        elif cooperation_rate >= self.threshold_low:
            self.consecutive_low_cooperation += 1
            return Action.D
        else:
            self.consecutive_low_cooperation += 1
            if state.round_number >= 2:
                recovery_detected = self._check_recovery(history, previous_round_idx)
                if recovery_detected:
                    self.consecutive_low_cooperation = 0
                    if random.random() < cooperation_rate:
                        return Action.C
                    else:
                        return Action.D
            return Action.D

    def _check_recovery(self, history: PlayerHistory, current_round_idx: int) -> bool:
        """
        Check if cooperation rate has recovered to >= 50% in recent rounds.
        Allows re-entry if collective demonstrates renewed commitment.
        """
        if current_round_idx < 1:
            return False
        lookback_rounds = min(2, current_round_idx)
        for i in range(lookback_rounds):
            check_round_idx = current_round_idx - i
            if check_round_idx < 0:
                break
            opponent_cooperators = sum(history.opponent_actions[check_round_idx, :])
            my_action = history.my_actions[check_round_idx]
            total_cooperators = opponent_cooperators + (1 if my_action else 0)
            recovery_rate = total_cooperators / self.n
            if recovery_rate >= 0.5:
                return True
        return False

class Strategy_COLLECTIVE_270(BaseStrategy):
    """
    Adaptive Reciprocity with Defection Tolerance strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with individual security:
    - Round 1: Always cooperate to signal goodwill
    - Last round: Always defect (backward induction)
    - Middle rounds: Adapt based on observed cooperation rate with graceful recovery tolerance
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.lower_threshold = max(0.4, self.k / self.n * 0.8)
        self.micro_threshold = max(0.15, self.k / self.n * 0.2)
        self.tolerance_parameter = 1.0 / (self.r - 2) if self.r > 2 else 1.0
        self.decay_factor = 0.95

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            return Action.D
        last_round_opponent_actions = history.opponent_actions[current_round - 1, :]
        cooperators_last_round = int(np.sum(last_round_opponent_actions))
        if history.my_actions[current_round - 1]:
            cooperators_last_round += 1
        cooperation_rate = cooperators_last_round / self.n
        if cooperation_rate >= self.lower_threshold:
            return Action.C
        elif cooperation_rate > self.micro_threshold:
            if random.random() < self.tolerance_parameter:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_271(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective value creation with individual sustainability through:
    1. Initial cooperation probe (rounds 0-2)
    2. Adaptive reciprocal strategy based on cooperation rates (rounds 3 to r-2)
    3. Rational defection in final round (round r-1)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self._set_thresholds()

    def _set_thresholds(self):
        """Set cooperation rate thresholds based on n and k parameters."""
        if self.n <= 3:
            self.threshold_high = 0.75
            self.threshold_low = 0.4
            self.probe_rounds = 4
        else:
            self.threshold_high = 0.65
            self.threshold_low = 0.35
            self.probe_rounds = 3
        if self.k < 1.3:
            self.threshold_high = 0.8
            self.threshold_low = 0.5
        elif self.k > self.n - 0.5:
            self.threshold_high = 0.55
            self.threshold_low = 0.25

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate from probe phase."""
        if len(history.opponent_actions) == 0:
            return 0.0
        probe_end = min(self.probe_rounds, len(history.opponent_actions))
        total_actions = probe_end * self.n
        if total_actions == 0:
            return 0.0
        cooperators = sum((sum(history.opponent_actions[i, :]) for i in range(probe_end)))
        return cooperators / total_actions

    def _get_cascade_detected(self, history: PlayerHistory) -> bool:
        """Detect sudden defection cascade (>50% drop in cooperators)."""
        if len(history.opponent_actions) < 2:
            return False
        prev_coop = sum(history.opponent_actions[-2, :])
        curr_coop = sum(history.opponent_actions[-1, :])
        if prev_coop - curr_coop > 0.5 * self.n:
            return True
        return False

    def _get_previous_cooperation_rate(self, history: PlayerHistory) -> float:
        """Get cooperation rate from the immediately previous round."""
        if len(history.opponent_actions) == 0:
            return 0.0
        prev_round_coops = sum(history.opponent_actions[-1, :])
        return prev_round_coops / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num < self.probe_rounds:
            return Action.C
        if round_num == self.r - 1:
            return Action.D
        coop_rate = self._calculate_cooperation_rate(history)
        if self._get_cascade_detected(history):
            return Action.D
        if coop_rate >= self.threshold_high:
            return Action.C
        if coop_rate >= self.threshold_low:
            prev_coop_rate = self._get_previous_cooperation_rate(history)
            if prev_coop_rate >= self.threshold_low:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_272(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Uses three adaptive phases based on observed cooperation rates:
    - Phase A (Early): Cooperate to explore and signal willingness
    - Phase B (Main): Reciprocate based on threshold  = k/n
    - Phase C (Late): Optimize endgame with higher cooperation threshold (0.6)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n
        self.phase_a_end = math.ceil(self.r / 3)
        self.phase_b_end = math.floor(2 * self.r / 3)
        self.window_size = max(3, math.floor(self.r / 6))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        cooperation_rate_recent = self._calculate_recent_cooperation_rate(history)
        if current_round < self.phase_a_end:
            return Action.C
        elif current_round < self.phase_b_end:
            if cooperation_rate_recent >= self.threshold:
                return Action.C
            else:
                return Action.D
        elif cooperation_rate_recent >= 0.6:
            return Action.C
        elif cooperation_rate_recent >= self.threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory) -> float:
        """
        Calculate the average cooperation rate of all other players
        in the last w rounds (window_size).
        """
        if history is None or len(history.opponent_actions) == 0:
            return 0.0
        num_rounds_so_far = len(history.opponent_actions)
        start_idx = max(0, num_rounds_so_far - self.window_size)
        recent_actions = history.opponent_actions[start_idx:num_rounds_so_far, :]
        total_cooperations = np.sum(recent_actions)
        total_actions = recent_actions.size
        if total_actions == 0:
            return 0.0
        cooperation_rate = total_cooperations / total_actions
        return cooperation_rate

class Strategy_COLLECTIVE_273(BaseStrategy):
    """
    Adaptive Threshold Reciprocity with Defection Resistance for N-Player Public Goods Game.

    Balances collective welfare maximization, individual robustness, and adaptive learning.
    Uses conditional cooperation with adaptive thresholds that respond to observed cooperation rates
    while protecting against exploitation by defectors.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.break_even_threshold = self.k / self.n
        self.adaptive_threshold = self.break_even_threshold + (1 - self.break_even_threshold) * 0.3
        self.punishment_threshold = 0.2
        self.current_adaptive_threshold = self.adaptive_threshold
        self.cooperation_trend = []
        self.defection_rates = {}

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            return Action.D
        previous_round_idx = round_num - 1
        cooperators_previous = sum(history.opponent_actions[previous_round_idx, :])
        observed_coop_rate = cooperators_previous / self.n
        self.cooperation_trend.append(observed_coop_rate)
        if len(self.cooperation_trend) >= 2:
            if len(self.cooperation_trend) >= 3:
                recent_defection_rate = 1 - np.mean(self.cooperation_trend[-3:])
                if recent_defection_rate < (1 - self.break_even_threshold) * 0.5:
                    self.current_adaptive_threshold = max(self.break_even_threshold, self.current_adaptive_threshold - 0.05)
                elif recent_defection_rate > (1 - self.break_even_threshold) * 0.8:
                    self.current_adaptive_threshold = min(1.0, self.current_adaptive_threshold + 0.1)
        if cooperators_previous == 0:
            return Action.D
        if cooperators_previous == self.n - 1 or (cooperators_previous == self.n and history.my_actions[previous_round_idx]):
            self.current_adaptive_threshold = max(self.break_even_threshold, self.current_adaptive_threshold - 0.05)
            return Action.C
        if cooperators_previous == self.n - 1:
            return Action.C
        if observed_coop_rate >= self.current_adaptive_threshold:
            return Action.C
        elif observed_coop_rate >= self.break_even_threshold:
            if len(self.cooperation_trend) >= 2:
                trend_improving = self.cooperation_trend[-1] >= self.cooperation_trend[-2]
                if trend_improving:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.C
        elif observed_coop_rate < self.punishment_threshold:
            return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_274(BaseStrategy):
    """
    Adaptive Reciprocal Threshold (ART) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare by adapting cooperation
    based on observed group cooperation rates. Uses dynamic thresholds to determine
    when mutual cooperation becomes individually and collectively beneficial.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        coop_rate = self._calculate_cooperation_rate(history, state.round_number)
        threshold = max(0.4, self.k / self.n * 1.25)
        if state.round_number == self.r - 1:
            if coop_rate >= threshold:
                return Action.C
            else:
                return Action.D
        if coop_rate >= threshold:
            return Action.C
        elif coop_rate > 0.15:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the cooperation rate across all previous rounds.

        coop_rate = (total cooperators in previous rounds) / (n * rounds_played_so_far)
        """
        rounds_played = current_round
        my_cooperations = np.sum(history.my_actions[:current_round])
        opponent_cooperations = np.sum(history.opponent_actions[:current_round, :])
        total_cooperations = my_cooperations + opponent_cooperations
        total_possible = self.n * rounds_played
        if total_possible == 0:
            return 0.0
        coop_rate = total_cooperations / total_possible
        return coop_rate

class Strategy_COLLECTIVE_275(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare through conditional cooperation
    with adaptive thresholds that evolve based on observed aggregate behavior.

    Core logic:
    - Round 1: Cooperate (bootstrap/signal good faith)
    - Rounds 2 to r-1: Adapt based on cooperation rate relative to break-even threshold (k/n)
    - Final round: Defect (unless k >= n-1, then cooperate)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.n_rounds - 1:
            if self.k >= self.n_players - 1:
                return Action.C
            else:
                return Action.D
        prev_round_idx = round_number - 1
        cooperators_prev = sum(history.opponent_actions[prev_round_idx, :])
        cr_prev = cooperators_prev / self.n_players
        threshold_hard = self.k / self.n_players
        threshold_soft = self.k / self.n_players - 0.2
        if cr_prev >= threshold_hard:
            return Action.C
        elif cr_prev > threshold_soft:
            if random.random() < cr_prev:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_276(BaseStrategy):
    """
    Adaptive Contribution with Degradation Detection Strategy for N-Player Public Goods Game.

    Balances collective value creation with individual protection by:
    1. Starting with cooperation to reveal collective potential
    2. Detecting free-riding patterns through cooperation rate monitoring
    3. Gracefully degrading cooperation with a mathematically-derived threshold decay
    4. Maintaining collective gain while protecting against exploitation
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.base_threshold = (self.k + 1) / (2 * self.n)
        self.decay_rate = self.base_threshold / self.r
        self.breakeven_threshold = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        previous_round_opponent_actions = history.opponent_actions[round_num - 1, :]
        previous_round_my_action = history.my_actions[round_num - 1]
        opponent_cooperators = np.sum(previous_round_opponent_actions)
        my_prev_cooperation = 1 if previous_round_my_action else 0
        total_cooperators = opponent_cooperators + my_prev_cooperation
        cooperation_rate = total_cooperators / self.n
        if round_num == self.r - 1:
            dynamic_threshold = self.breakeven_threshold
        else:
            decay_amount = self.decay_rate * round_num
            dynamic_threshold = max(self.breakeven_threshold, self.base_threshold - decay_amount)
        if cooperation_rate >= dynamic_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_277(BaseStrategy):
    """
    Adaptive Conditional Cooperation with Decay strategy for N-Player Public Goods Game.

    This strategy pursues conditional cooperation that evolves based on collective welfare,
    balancing individual rationality, collective benefit, robustness, and adaptation.
    Core mechanism: cooperate if cooperation rate in previous round meets a dynamic threshold
    that adjusts based on round number, cooperation momentum, and defection penalties.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        cooperators_last_round = sum(history.opponent_actions[round_num - 1, :]) + (1 if history.my_actions[round_num - 1] else 0)
        last_cooperation_rate = cooperators_last_round / self.n
        if round_num == self.r - 1:
            threshold = 0.75
        else:
            if round_num >= 3:
                recent_rounds = history.opponent_actions[round_num - 3:round_num, :]
                recent_my_actions = history.my_actions[round_num - 3:round_num]
                total_cooperators = 0
                for i in range(3):
                    total_cooperators += sum(recent_rounds[i, :]) + (1 if recent_my_actions[i] else 0)
                avg_coop_3 = total_cooperators / (3 * self.n)
            else:
                total_cooperators = 0
                for i in range(round_num):
                    total_cooperators += sum(history.opponent_actions[i, :]) + (1 if history.my_actions[i] else 0)
                avg_coop_3 = total_cooperators / (round_num * self.n)
            momentum = (avg_coop_3 - 0.5) / 0.5
            momentum = max(-1.0, min(1.0, momentum))
            threshold = 0.5 - 0.15 * momentum
        if self.k <= 1.2:
            threshold += 0.15
        if self.n >= 10:
            threshold -= 0.1
        defection_penalty = 0.0
        lookback_rounds = min(3, round_num)
        for rounds_ago in range(1, lookback_rounds + 1):
            hist_idx = round_num - rounds_ago
            cooperators_at_round = sum(history.opponent_actions[hist_idx, :]) + (1 if history.my_actions[hist_idx] else 0)
            coop_rate_at_round = cooperators_at_round / self.n
            if coop_rate_at_round < 0.4:
                decay_factor = 0.7 ** (rounds_ago - 1)
                defection_penalty += 0.2 * decay_factor
        threshold += defection_penalty
        threshold = max(0.0, min(1.0, threshold))
        if last_cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_278(BaseStrategy):
    """
    Adaptive Reciprocal Maximization (ARM) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare by:
    1. Cooperating in round 1 to establish baseline
    2. Adapting in middle rounds based on observed cooperation rate vs. threshold k/n
    3. Defecting in final round (subgame perfect equilibrium)

    Core decision rule for rounds 2 to r-1:
    - If cooperation_rate >= k/n: COOPERATE (collective payoff sustainable)
    - Else if cooperation_rate > 0: COOPERATE with probability = cooperation_rate (gradual exit)
    - Else: DEFECT (mutual defection equilibrium)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.r - 1:
            return Action.D
        previous_round_index = round_number - 1
        cooperators_last_round = sum(history.opponent_actions[previous_round_index, :])
        if history.my_actions[previous_round_index]:
            cooperators_last_round += 1
        cooperation_rate = cooperators_last_round / self.n
        if cooperation_rate >= self.threshold:
            return Action.C
        if cooperation_rate > 0:
            if random.random() < cooperation_rate:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_279(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare through earned trust,
    dynamic adaptation to opponent behavior, and reciprocal incentives.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        last_round_idx = current_round - 1
        cooperators_last_round = sum(history.opponent_actions[last_round_idx, :])
        total_cooperators_last_round = cooperators_last_round + (1 if history.my_actions[last_round_idx] else 0)
        cooperation_rate = total_cooperators_last_round / self.n
        my_payoff_last_round = history.my_payoffs[last_round_idx]
        all_payoffs_last_round = np.concatenate([[my_payoff_last_round], history.opponent_payoffs[last_round_idx, :]])
        avg_payoff_last_round = np.mean(all_payoffs_last_round)
        total_cooperators_all = sum(history.my_actions) + sum(sum(history.opponent_actions[:current_round, :]))
        cumulative_cooperation_rate = total_cooperators_all / (self.n * current_round)
        recent_rounds_start = max(0, current_round - 3)
        recent_cooperators = sum(history.my_actions[recent_rounds_start:current_round])
        for r_idx in range(recent_rounds_start, current_round):
            recent_cooperators += sum(history.opponent_actions[r_idx, :])
        recent_cooperation_rate = recent_cooperators / (self.n * (current_round - recent_rounds_start)) if current_round - recent_rounds_start > 0 else 0
        if current_round <= 2:
            coop_threshold = 0.4
        else:
            coop_threshold = self.k / self.n
        action = Action.D
        if cooperation_rate >= coop_threshold:
            if my_payoff_last_round >= avg_payoff_last_round * 0.9:
                action = Action.C
            else:
                action = Action.D
        elif cooperation_rate >= 0.5:
            action = Action.C
        else:
            action = Action.D
        my_last_action = history.my_actions[last_round_idx]
        rounds_remaining = self.r - current_round
        if cooperation_rate == 1.0 and (not my_last_action):
            if rounds_remaining > 2:
                action = Action.C if random.random() < 0.7 else Action.D
            else:
                action = Action.C
        if recent_cooperation_rate > cumulative_cooperation_rate * 1.15:
            action = Action.C
        elif recent_cooperation_rate < cumulative_cooperation_rate * 0.85:
            action = Action.D
        if current_round >= self.r - 2:
            if cooperation_rate >= 0.5:
                action = Action.C
            else:
                action = Action.D
        if current_round == self.r - 1:
            if cumulative_cooperation_rate >= 0.6:
                action = Action.C
            else:
                action = Action.D
        if cooperation_rate == 1.0:
            action = Action.C
        if cooperation_rate == 0.0:
            action = Action.D
        return action

class Strategy_COLLECTIVE_280(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy

    A cooperative strategy that maximizes collective welfare by conditionally
    cooperating based on observed cooperation rates, with adaptive thresholds
    that decay over time and special handling for exploitation detection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.base_threshold = (self.k - 1) / (self.k + 1)
        self.decay_factor = (1 - self.base_threshold) / self.r

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        if t == 0:
            return Action.C
        prev_round_actions = history.opponent_actions[t - 1, :]
        num_cooperators = int(np.sum(prev_round_actions))
        if t > 0 and len(history.my_actions) > 0:
            my_prev_action = history.my_actions[t - 1]
            num_cooperators += int(my_prev_action)
            cooperation_rate = num_cooperators / self.n
        else:
            cooperation_rate = num_cooperators / self.n
        if t >= 2:
            recent_rounds = min(2, t)
            total_coop = 0
            total_players = 0
            for i in range(1, recent_rounds + 1):
                round_idx = t - i
                if round_idx >= 0:
                    round_coop = int(np.sum(history.opponent_actions[round_idx, :]))
                    if round_idx > 0 and len(history.my_actions) > round_idx:
                        round_coop += int(history.my_actions[round_idx])
                    total_coop += round_coop
                    total_players += self.n
            if total_players > 0:
                avg_coop_rate = total_coop / total_players
                if avg_coop_rate < 0.5:
                    return Action.D
        threshold = self.base_threshold - self.decay_factor * (t / self.r)
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_281(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy

    Balances collective welfare maximization, individual robustness, and adaptive learning
    by using cooperation thresholds calibrated to game parameters and observed cooperation rates.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold_mid = (self.k - 1) / (self.n - 1)
        self.threshold_late = self.threshold_mid * 1.5
        self.threshold_low = 1 / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_idx = round_num - 1
        prev_opponent_actions = history.opponent_actions[prev_round_idx, :]
        my_prev_action = history.my_actions[prev_round_idx]
        prev_cooperators = int(np.sum(prev_opponent_actions)) + int(my_prev_action)
        coop_rate = prev_cooperators / self.n
        consecutive_defection_rounds = self._count_consecutive_defection_rounds(history)
        if consecutive_defection_rounds >= 2:
            return Action.D
        if round_num == self.r - 1:
            avg_coop = self._calculate_average_cooperation_rate(history)
            if avg_coop >= self.threshold_mid:
                return Action.C
            else:
                return Action.D
        if round_num < self.r // 3 and round_num < 3:
            avg_coop = self._calculate_average_cooperation_rate(history)
            if avg_coop < self.threshold_mid * 0.5:
                if random.random() < 0.6:
                    return Action.C
                else:
                    return Action.D
        if coop_rate == self.threshold_low:
            return Action.C
        if coop_rate >= self.threshold_mid:
            return Action.C
        elif coop_rate >= self.threshold_low:
            p_gradual = (coop_rate - self.threshold_low) / (self.threshold_mid - self.threshold_low)
            if random.random() < p_gradual:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _count_consecutive_defection_rounds(self, history: PlayerHistory) -> int:
        """Count consecutive rounds where cooperation_rate < threshold_low"""
        consecutive_count = 0
        for round_idx in range(len(history.my_actions) - 1, -1, -1):
            opponent_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
            my_action = int(history.my_actions[round_idx])
            total_cooperators = opponent_cooperators + my_action
            coop_rate = total_cooperators / self.n
            if coop_rate < self.threshold_low:
                consecutive_count += 1
            else:
                break
        return consecutive_count

    def _calculate_average_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate average cooperation rate across all previous rounds"""
        total_coop_rate = 0.0
        for round_idx in range(len(history.my_actions)):
            opponent_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
            my_action = int(history.my_actions[round_idx])
            total_cooperators = opponent_cooperators + my_action
            coop_rate = total_cooperators / self.n
            total_coop_rate += coop_rate
        avg_coop = total_coop_rate / len(history.my_actions)
        return avg_coop

class Strategy_COLLECTIVE_282(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare by:
    1. Initiating cooperation in round 1
    2. Reciprocating based on cooperation threshold (k/n)
    3. Attempting recovery after consecutive low-cooperation rounds
    4. Punishing free-riders while avoiding mutual defection traps
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round_idx = state.round_number - 1
        prev_round_opponent_actions = history.opponent_actions[prev_round_idx, :]
        prev_round_my_action = history.my_actions[prev_round_idx]
        total_cooperators = int(prev_round_my_action) + int(np.sum(prev_round_opponent_actions))
        cooperation_rate = total_cooperators / self.game_description.n_players
        if cooperation_rate >= self.cooperation_threshold:
            return Action.C
        consecutive_low_rounds = 0
        start_idx = max(0, prev_round_idx - 1)
        for round_idx in range(start_idx, prev_round_idx + 1):
            round_opponent_actions = history.opponent_actions[round_idx, :]
            round_my_action = history.my_actions[round_idx]
            round_total_cooperators = int(round_my_action) + int(np.sum(round_opponent_actions))
            round_cooperation_rate = round_total_cooperators / self.game_description.n_players
            if round_cooperation_rate < self.cooperation_threshold:
                consecutive_low_rounds += 1
        if consecutive_low_rounds >= 2:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_283(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game.

    Balances cooperative intent with rational self-protection by:
    1. Cooperating in round 1 to signal good faith
    2. Adapting cooperation in rounds 2 to r-1 based on recent group cooperation rates
    3. Defecting in the final round (backward induction)

    Uses a threshold-based decision rule with probabilistic cooperation in ambiguous cases.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.n_rounds - 1:
            return Action.D
        coop_threshold = self.k / self.n_players
        window_size = min(3, round_number)
        recent_rounds_start = round_number - window_size
        recent_cooperation_rates = []
        for past_round in range(recent_rounds_start, round_number):
            opponent_cooperators = np.sum(history.opponent_actions[past_round, :])
            total_cooperators = opponent_cooperators + (1 if history.my_actions[past_round] else 0)
            coop_rate = total_cooperators / self.n_players
            recent_cooperation_rates.append(coop_rate)
        recent_avg_coop = np.mean(recent_cooperation_rates)
        upper_threshold = 0.75 * coop_threshold
        lower_threshold = 0.5 * coop_threshold
        if recent_avg_coop >= upper_threshold:
            return Action.C
        elif recent_avg_coop >= lower_threshold:
            prob_cooperate = recent_avg_coop / coop_threshold
            prob_cooperate = max(0.0, min(1.0, prob_cooperate))
            if random.random() < prob_cooperate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_284(BaseStrategy):
    """
    Adaptive Reciprocal Contribution with Threshold-Based Forgiveness.

    Balances collective welfare maximization with robust defense against exploitation
    through demonstrated commitment, measured reciprocity, and intelligent forgiveness.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        k = self.game_description.k
        total_rounds = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        opponent_cooperators_prev = sum(history.opponent_actions[prev_round_idx, :])
        my_action_prev = history.my_actions[prev_round_idx]
        total_cooperators_prev = opponent_cooperators_prev + (1 if my_action_prev else 0)
        observed_coop_rate = total_cooperators_prev / n
        if current_round <= 2:
            threshold = 0.5
        else:
            threshold = max(0.3, observed_coop_rate - 0.1)
        if current_round == total_rounds - 1:
            if observed_coop_rate >= 0.4:
                return Action.C
            else:
                return Action.D
        if observed_coop_rate >= threshold:
            return Action.C
        elif observed_coop_rate >= k / n:
            if random.random() < 0.3:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_285(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization, robust self-protection, and adaptive learning
    by dynamically adjusting cooperation based on observed population cooperation rates.

    Phases:
    1. Exploration (rounds 0 to min(r/3, 5)-1): Cooperate to gather information
    2. Adaptation (middle rounds): Cooperate if cooperation_rate >= k/n threshold
    3. Endgame (last round): Defect unless sustained high cooperation observed
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n_players
        self.hysteresis_buffer = 0.15
        self.previous_action = Action.C

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            self.previous_action = Action.C
            return Action.C
        exploration_rounds = min(math.ceil(self.n_rounds / 3), 5)
        if round_number < exploration_rounds:
            self.previous_action = Action.C
            return Action.C
        total_cooperations = np.sum(history.opponent_actions)
        total_cooperations += np.sum(history.my_actions)
        total_actions = round_number * self.n_players
        cooperation_rate = total_cooperations / total_actions if total_actions > 0 else 0.0
        if round_number == self.n_rounds - 1:
            my_cooperations = np.sum(history.my_actions)
            if cooperation_rate >= 1.2 * self.threshold and my_cooperations > self.n_rounds / 2:
                return Action.C
            else:
                return Action.D
        threshold_high = self.threshold + self.hysteresis_buffer
        threshold_low = self.threshold - self.hysteresis_buffer
        if cooperation_rate > threshold_high:
            self.previous_action = Action.C
            return Action.C
        elif cooperation_rate < threshold_low:
            self.previous_action = Action.D
            return Action.D
        else:
            return self.previous_action

class Strategy_COLLECTIVE_286(BaseStrategy):
    """
    Adaptive Contribution with Conditional Reciprocity for N-Player Public Goods Game.

    Balances collective welfare maximization, individual resilience, and adaptive responsiveness
    by starting with cooperation, observing cooperation rates, and adjusting contribution
    probability based on relative thresholds tied to the game's breakeven point.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.smoothed_coop_rate = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        obs_coop_rate = self._calculate_cooperation_rate(history, current_round)
        if self.r > 100 and current_round >= 20:
            if self.smoothed_coop_rate is None:
                self.smoothed_coop_rate = obs_coop_rate
            else:
                self.smoothed_coop_rate = 0.9 * self.smoothed_coop_rate + 0.1 * obs_coop_rate
            obs_coop_rate = self.smoothed_coop_rate
        cooperation_threshold = (self.k - 1) / (self.n - 1)
        if current_round == self.r - 1:
            if obs_coop_rate > 0.75 * cooperation_threshold:
                return Action.C
            else:
                return Action.D
        p_cooperate = self._calculate_cooperation_probability(obs_coop_rate, cooperation_threshold)
        if random.random() < p_cooperate:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """Calculate the observed cooperation rate across all previous rounds."""
        if current_round == 0:
            return 0.0
        total_cooperators = 0
        for round_idx in range(current_round):
            total_cooperators += sum(history.opponent_actions[round_idx, :])
        total_possible = current_round * self.n
        return total_cooperators / total_possible if total_possible > 0 else 0.0

    def _calculate_cooperation_probability(self, obs_coop_rate: float, cooperation_threshold: float) -> float:
        """Determine probability of cooperation based on observed cooperation rate."""
        threshold_high = 0.66 * cooperation_threshold
        threshold_mid = 0.33 * cooperation_threshold
        if obs_coop_rate >= threshold_high:
            p = 0.95
        elif obs_coop_rate >= threshold_mid:
            p = 0.5
        else:
            p = 0.1
        if self.n <= 3:
            p = max(0.0, p - 0.1)
        return p

class Strategy_COLLECTIVE_287(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with individual security through:
    - Unconditional cooperation in round 1
    - Threshold-based reciprocity in middle rounds (50% cooperation threshold)
    - Stochastic cooperation in uncertain conditions (30-50% range)
    - Strategic defection in last round and when cooperation breaks down
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        total_prev_rounds = round_number
        recent_window = min(3, total_prev_rounds)
        all_cooperators = np.sum(history.opponent_actions[:total_prev_rounds, :])
        cooperation_all = all_cooperators / (self.n_players * total_prev_rounds)
        recent_cooperators = np.sum(history.opponent_actions[total_prev_rounds - recent_window:total_prev_rounds, :])
        cooperation_recent = recent_cooperators / (self.n_players * recent_window)
        defectors_last_round = self.n_players - int(np.sum(history.opponent_actions[total_prev_rounds - 1, :]))
        defector_threshold = self.n_players / 3
        if round_number == self.n_rounds - 1:
            if cooperation_recent > 0.5:
                return Action.C
            else:
                return Action.D
        coop_threshold = 0.55 if round_number >= self.n_rounds - 2 else 0.5
        defection_threshold = 0.3
        stochastic_upper = 0.5
        if cooperation_recent >= coop_threshold and defectors_last_round <= defector_threshold:
            return Action.C
        elif cooperation_recent < defection_threshold:
            return Action.D
        elif random.random() < 0.6:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_288(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC): A strategy that maintains sustainable
    collective welfare through conditional cooperation based on observed cooperation rates.

    Core logic:
    - Round 1: Always cooperate to establish intent
    - Rounds 2 to r-1: Cooperate if cooperation rate >= k/n threshold
    - Final round: Cooperate only if threshold maintained
    - Uses 3-round moving average to dampen noise in volatile populations
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        if round_num == 0:
            return Action.C
        recent_cooperation_rate = self._calculate_recent_cooperation_rate(history, round_num, n)
        if round_num == r - 1:
            if recent_cooperation_rate >= self.cooperation_threshold:
                return Action.C
            else:
                return Action.D
        if recent_cooperation_rate >= self.cooperation_threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory, round_num: int, n: int) -> float:
        """
        Calculate cooperation rate using 3-round moving average to dampen noise.
        Falls back to fewer rounds if history is shorter.
        """
        rounds_to_consider = min(3, round_num)
        total_cooperators = 0.0
        for i in range(1, rounds_to_consider + 1):
            round_idx = round_num - i
            cooperators_in_round = float(np.sum(history.opponent_actions[round_idx, :]))
            total_cooperators += cooperators_in_round
        recent_cooperation_rate = total_cooperators / (rounds_to_consider * n)
        return recent_cooperation_rate

class Strategy_COLLECTIVE_289(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Cooperates initially, maintains cooperation proportional to observed group reciprocity,
    and defects only when collective welfare calculations suggest it serves the group better.
    Uses a threshold-based adaptive approach with 15% tolerance for noise.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.epsilon = 0.15
        self.cooperation_threshold = game_description.k / game_description.n_players - self.epsilon
        self.punish_next_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        if current_round == 0:
            return Action.C
        previous_round_idx = current_round - 1
        my_prev_action = history.my_actions[previous_round_idx]
        opponent_prev_actions = history.opponent_actions[previous_round_idx, :]
        cooperators_last_round = int(my_prev_action) + int(np.sum(opponent_prev_actions))
        cooperation_rate = cooperators_last_round / n
        if self.punish_next_round:
            self.punish_next_round = False
            return Action.D
        if cooperation_rate < 0.05:
            self.punish_next_round = True
            return Action.D
        if current_round == r - 1:
            if cooperation_rate >= self.cooperation_threshold:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= self.cooperation_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_290(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare by:
    1. Tracking historical cooperation rates
    2. Adapting contribution probability based on game phase
    3. Including recovery mechanisms from defection traps
    4. Refusing last-round exploitation
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            cooperation_threshold = 0.5
        else:
            total_cooperators = 0
            for r in range(round_number):
                if history.my_actions[r]:
                    total_cooperators += 1
                total_cooperators += sum(history.opponent_actions[r, :])
            total_possible = self.n_players * round_number
            observed_coop_rate = total_cooperators / total_possible
            third_point = self.n_rounds / 3.0
            two_third_point = 2.0 * self.n_rounds / 3.0
            if round_number <= third_point:
                cooperation_threshold = 0.5
            elif round_number <= two_third_point:
                cooperation_threshold = min(0.9, observed_coop_rate + 0.1)
            else:
                cooperation_threshold = observed_coop_rate
        if random.random() < cooperation_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_291(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game

    Balances collective welfare maximization with robust incentive alignment through
    adaptive reciprocation based on recent group cooperation rates and dynamic thresholds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round_t = state.round_number
        if current_round_t == 0:
            return Action.C
        window_size = max(3, self.n_rounds // 4)
        window_start = max(0, current_round_t - window_size)
        recent_cooperators = 0
        recent_rounds_count = 0
        for t in range(window_start, current_round_t):
            round_opponent_actions = history.opponent_actions[t, :]
            cooperators_this_round = np.sum(round_opponent_actions)
            recent_cooperators += cooperators_this_round
            recent_rounds_count += 1
        if recent_rounds_count == 0:
            recent_cooperation_rate = 0.5
        else:
            recent_cooperation_rate = recent_cooperators / (recent_rounds_count * (self.n_players - 1))
        threshold = (1.0 + current_round_t / self.n_rounds) / 2.0
        if recent_cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_292(BaseStrategy):
    """
    Adaptive Reciprocal Stewardship (ARS): A collective strategy that balances
    cooperation for mutual gain, prudence against defectors, and adaptive responses
    based on observed cooperation rates.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        cooperators_last_round = sum(history.opponent_actions[current_round - 1, :])
        cooperation_rate = cooperators_last_round / self.n
        if current_round == self.r - 1:
            if cooperation_rate > self.threshold:
                return Action.C
            else:
                return Action.D
        if cooperation_rate > self.threshold:
            return Action.C
        if cooperation_rate >= 0.5:
            prob = (cooperation_rate - self.threshold) / (0.5 - self.threshold)
            if random.random() < prob:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_293(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy

    Balances exploitation, stabilization, and loss minimization by tracking
    cooperation rates and adaptively adjusting participation thresholds.
    Core insight: cooperate when aggregate cooperation rate justifies it,
    using k/n as the equilibrium threshold.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            avg_coop_rate = self._calculate_average_coop_rate(history, current_round)
            if avg_coop_rate >= self.threshold:
                return Action.C
            else:
                return Action.D
        prev_round_coop_rate = self._calculate_prev_round_coop_rate(history)
        adjusted_threshold = self.threshold - 0.05
        if current_round >= 2:
            trend = self._detect_cooperation_trend(history, current_round)
            if trend > 0:
                adjusted_threshold = self.threshold - 0.05
        if prev_round_coop_rate >= adjusted_threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_prev_round_coop_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate from the immediately previous round."""
        if history is None or len(history.opponent_actions) == 0:
            return 0.0
        prev_round_actions = history.opponent_actions[-1, :]
        prev_round_coop_count = np.sum(prev_round_actions)
        own_prev_action = history.my_actions[-1]
        total_cooperators = prev_round_coop_count + (1 if own_prev_action else 0)
        coop_rate = total_cooperators / self.n_players
        return coop_rate

    def _calculate_average_coop_rate(self, history: PlayerHistory, current_round: int) -> float:
        """Calculate average cooperation rate from all rounds up to (but not including) current round."""
        if history is None or len(history.opponent_actions) == 0:
            return 0.0
        total_coop_count = 0
        n_previous_rounds = current_round
        for round_idx in range(n_previous_rounds):
            round_opponent_coop = np.sum(history.opponent_actions[round_idx, :])
            own_action = history.my_actions[round_idx]
            round_total_coop = round_opponent_coop + (1 if own_action else 0)
            total_coop_count += round_total_coop
        avg_coop_rate = total_coop_count / (n_previous_rounds * self.n_players)
        return avg_coop_rate

    def _detect_cooperation_trend(self, history: PlayerHistory, current_round: int) -> float:
        """
        Detect if cooperation rate has been increasing over recent rounds.
        Returns: positive value if increasing, negative if decreasing, 0 if stable.
        """
        if history is None or current_round < 2:
            return 0.0
        n_rounds_to_check = min(3, current_round)
        coop_rates = []
        for round_idx in range(current_round - n_rounds_to_check, current_round):
            if round_idx < 0:
                continue
            round_opponent_coop = np.sum(history.opponent_actions[round_idx, :])
            own_action = history.my_actions[round_idx]
            round_total_coop = round_opponent_coop + (1 if own_action else 0)
            rate = round_total_coop / self.n_players
            coop_rates.append(rate)
        if len(coop_rates) < 2:
            return 0.0
        trend = coop_rates[-1] - coop_rates[0]
        return trend

class Strategy_COLLECTIVE_294(BaseStrategy):
    """
    Adaptive Threshold Cooperation with Decay (ATCD) Strategy.

    Balances collective welfare with individual payoff protection through:
    1. Dynamic cooperation thresholds based on historical cooperation rates
    2. Decay factor that increases defection urgency as game ends
    3. Terminal defection in final rounds to maximize individual payoff
    4. Adaptive adjustment based on recent cooperation trends
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            return Action.D
        if current_round == self.r - 2:
            historical_coop_rate = self._calculate_historical_coop_rate(history, current_round)
            if historical_coop_rate >= 0.6:
                return Action.C
            return Action.D
        historical_coop_rate = self._calculate_historical_coop_rate(history, current_round)
        defection_rate = 1.0 - historical_coop_rate
        rounds_remaining = self.r - current_round
        decay_factor = rounds_remaining / self.r
        cooperation_threshold = 0.5 - 0.4 * decay_factor * historical_coop_rate
        if self.n > 20 and self.k < 1.5:
            cooperation_threshold += 0.15
        if self.k > self.n - 0.5:
            cooperation_threshold -= 0.1
        recent_coop_rate = self._calculate_recent_coop_rate(history, current_round)
        if recent_coop_rate > historical_coop_rate:
            cooperation_threshold -= 0.05
        elif recent_coop_rate < historical_coop_rate:
            cooperation_threshold += 0.1
        if current_round > 0:
            prev_round_cooperators = sum(history.opponent_actions[current_round - 1, :])
            if prev_round_cooperators == 0:
                return Action.D
        if historical_coop_rate >= cooperation_threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_historical_coop_rate(self, history: PlayerHistory, current_round: int) -> float:
        """Calculate overall cooperation rate from start of game."""
        if current_round == 0:
            return 0.5
        total_cooperators = 0
        for round_idx in range(current_round):
            total_cooperators += sum(history.opponent_actions[round_idx, :])
        total_possible = self.n * current_round
        return total_cooperators / total_possible if total_possible > 0 else 0.5

    def _calculate_recent_coop_rate(self, history: PlayerHistory, current_round: int) -> float:
        """Calculate cooperation rate in recent rounds (last 5 or r/2, whichever is smaller)."""
        if current_round == 0:
            return 0.5
        window_size = min(5, max(1, self.r // 2))
        start_round = max(0, current_round - window_size)
        total_cooperators = 0
        rounds_to_check = current_round - start_round
        for round_idx in range(start_round, current_round):
            total_cooperators += sum(history.opponent_actions[round_idx, :])
        total_possible = self.n * rounds_to_check
        return total_cooperators / total_possible if total_possible > 0 else 0.5

class Strategy_COLLECTIVE_295(BaseStrategy):
    """
    Adaptive Reciprocal Equilibrium (ARE) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with individual incentive compatibility through:
    1. Initial cooperation to signal non-defection
    2. Conditional cooperation based on dynamic threshold
    3. Adaptive threshold that relaxes over mid-game, tightens in end-game
    4. Volatility detection to handle stochastic environments
    5. Special handling for penultimate and final rounds
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.base_threshold = (self.k - 1) / self.k
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round_idx = state.round_number - 1
        opponent_actions_last_round = history.opponent_actions[last_round_idx, :]
        coop_count = sum(opponent_actions_last_round)
        cooperation_rate = coop_count / self.n
        self.cooperation_history.append(cooperation_rate)
        round_num = state.round_number
        if round_num == self.r - 1:
            threshold = 0.5
        elif round_num == self.r - 2:
            decay = 0.3 * self.base_threshold
            progress = (round_num + 1) / self.r
            threshold = self.base_threshold - 0.2 * self.base_threshold
            threshold = max(threshold, self.base_threshold - decay * progress)
        else:
            decay = 0.3 * self.base_threshold
            progress = (round_num + 1) / self.r
            threshold = self.base_threshold - decay * progress
        if len(self.cooperation_history) >= 3:
            recent_rates = self.cooperation_history[-3:]
            mean_rate = sum(recent_rates) / len(recent_rates)
            variance = sum(((x - mean_rate) ** 2 for x in recent_rates)) / len(recent_rates)
            if variance > 0.15:
                threshold *= 0.9
        if len(self.cooperation_history) >= 3:
            trend_values = self.cooperation_history[-3:]
            if trend_values[-1] < trend_values[-2] and trend_values[-2] < trend_values[-3]:
                threshold = min(self.base_threshold, threshold + 0.1)
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_296(BaseStrategy):
    """
    Adaptive Reciprocal Investment (ARI) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization, self-protection against exploitation,
    and adaptive learning. The strategy:
    - Cooperates in round 1 to signal goodwill
    - Defects in the final round (no future consequences)
    - In middle rounds, adapts based on observed contribution rates
    - Adjusts thresholds dynamically based on game parameters (n, k, r)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            return Action.D
        previous_round_idx = round_num - 1
        prev_opponent_actions = history.opponent_actions[previous_round_idx, :]
        prev_my_action = history.my_actions[previous_round_idx]
        opponent_contributors = int(np.sum(prev_opponent_actions))
        total_contributors = opponent_contributors + (1 if prev_my_action else 0)
        contribution_rate = total_contributors / self.n
        cooperative_threshold = 0.5
        defection_threshold = 0.25
        k_moderate = 1.5
        if self.n > 20:
            cooperative_threshold = 0.4
            defection_threshold = 0.2
        if self.k < 1.2:
            defection_threshold = 0.35
        if self.k > self.n - 1:
            cooperative_threshold = 0.3
        if contribution_rate >= cooperative_threshold:
            return Action.C
        elif contribution_rate < defection_threshold:
            return Action.D
        elif self.k > k_moderate:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_297(BaseStrategy):
    """
    Adaptive Reciprocal Thresholding (ART) Strategy for N-Player Public Goods Game.

    Balances collective benefit maximization with individual security by adaptively
    calibrating cooperation to match the group's demonstrated commitment level.
    Core insight: cooperate when cooperation rate exceeds k/n threshold (breakeven point),
    with probabilistic cooperation in intermediate ranges and defection when commitment is low.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.target_threshold = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_idx = round_num - 1
        cooperators_prev = int(sum(history.opponent_actions[prev_round_idx, :]))
        cooperation_rate = cooperators_prev / self.n
        moving_avg = self._calculate_exponential_moving_average(history, prev_round_idx)
        if round_num <= 3:
            if moving_avg > self.target_threshold * 0.3:
                return Action.C
            else:
                return Action.C
        if round_num == self.r - 1:
            if moving_avg >= self.target_threshold:
                return Action.C
            else:
                return Action.D
        if moving_avg >= self.target_threshold:
            return Action.C
        elif moving_avg > self.target_threshold * 0.4:
            prob_cooperate = moving_avg / self.target_threshold
            if random.random() < prob_cooperate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _calculate_exponential_moving_average(self, history: PlayerHistory, current_round_idx: int) -> float:
        """
        Calculate exponential moving average of cooperation rates.
        Uses decay of 0.3 for older rounds, 0.7 weight on recent rounds.
        """
        decay_old = 0.3
        decay_recent = 0.7
        total_weight = 0.0
        weighted_sum = 0.0
        for round_idx in range(current_round_idx + 1):
            cooperators = int(sum(history.opponent_actions[round_idx, :]))
            cooperation_rate = cooperators / self.n
            if round_idx == current_round_idx:
                weight = decay_recent
            else:
                weight = decay_old
            weighted_sum += cooperation_rate * weight
            total_weight += weight
        if total_weight == 0:
            return 0.0
        return weighted_sum / total_weight

class Strategy_COLLECTIVE_298(BaseStrategy):
    """
    Adaptive Reciprocal Stewardship (ARS): A conditional cooperation strategy that maximizes
    collective welfare while protecting against exploitation. Cooperates when the cooperation
    rate exceeds the break-even threshold (k/n), adapts thresholds based on observed environment
    hostility, and maintains consistency through all rounds including the last one.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.base_threshold = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        cooperation_rate = self._get_cooperation_rate(history, round_num)
        threshold = self._compute_threshold(history, round_num)
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _get_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """Calculate the cooperation rate in the most recent round (round_num - 1)."""
        if round_num <= 0:
            return 0.0
        prev_round_idx = round_num - 1
        my_action_prev = 1 if history.my_actions[prev_round_idx] else 0
        opponent_cooperators = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        total_cooperators = my_action_prev + opponent_cooperators
        cooperation_rate = total_cooperators / self.n
        return cooperation_rate

    def _compute_threshold(self, history: PlayerHistory, round_num: int) -> float:
        """Compute the adaptive threshold based on environment hostility."""
        threshold = self.base_threshold
        if round_num > 5:
            defection_env_rate = self._get_defection_environment_rate(history, round_num)
            if defection_env_rate > 0.6:
                threshold = 0.75 * self.base_threshold
            elif defection_env_rate < 0.2:
                threshold = 1.1 * self.base_threshold
            else:
                threshold = self.base_threshold
        return threshold

    def _get_defection_environment_rate(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate the rate of rounds where cooperation_rate was below k/n.
        This indicates how hostile the environment has been.
        """
        if round_num <= 1:
            return 0.0
        low_cooperation_count = 0
        for past_round in range(round_num - 1):
            my_action = 1 if history.my_actions[past_round] else 0
            opponent_cooperators = int(np.sum(history.opponent_actions[past_round, :]))
            total_cooperators = my_action + opponent_cooperators
            cooperation_rate = total_cooperators / self.n
            if cooperation_rate < self.base_threshold:
                low_cooperation_count += 1
        defection_env_rate = low_cooperation_count / (round_num - 1) if round_num > 1 else 0.0
        return defection_env_rate

class Strategy_COLLECTIVE_299(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) strategy for N-Player Public Goods Game.

    Balances mutual benefit maximization, exploitation resistance, and adaptive learning:
    - Round 1: Cooperate to probe cooperation potential
    - Rounds 2 to r-1: Adapt based on observed cooperation rate vs. k/n threshold
    - Final round: Defect (standard backward induction)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n_players
        self.half_threshold = self.threshold * 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        prev_round_idx = current_round - 1
        cooperators_prev_round = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            cooperators_prev_round += 1
        cooperation_rate = cooperators_prev_round / self.n_players
        if cooperation_rate >= self.threshold:
            return Action.C
        elif cooperation_rate >= self.half_threshold:
            if random.random() < cooperation_rate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_300(BaseStrategy):
    """
    Adaptive Reciprocal Stewardship (ARS) Strategy for N-Player Public Goods Game.

    Maximizes collective welfare by:
    1. Bootstrap cooperation in round 1
    2. Adapting threshold based on cooperation rate and remaining rounds
    3. Detecting and punishing exploitation
    4. Supporting recovery through graduated forgiveness
    5. Strategic defection as a signal against free-riding
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        coop_count_prev = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        coop_rate_prev = coop_count_prev / self.n
        my_action_prev = history.my_actions[prev_round_idx]
        if current_round == self.r - 1:
            if coop_rate_prev >= self.k / self.n:
                return Action.C
            else:
                return Action.D
        threshold = self.k / self.n - 0.05
        rounds_remaining = self.r - current_round
        forgiveness_bonus = min(0.15, rounds_remaining / self.r)
        adjusted_threshold = threshold - forgiveness_bonus
        if self._detect_exploitation(history, current_round, coop_count_prev):
            self.consecutive_defections += 1
            return Action.D
        if self._should_recover(history, current_round, adjusted_threshold):
            self.consecutive_defections = 0
            return Action.C
        if coop_rate_prev >= adjusted_threshold:
            self.consecutive_defections = 0
            return Action.C
        else:
            self.consecutive_defections += 1
            return Action.D

    def _detect_exploitation(self, history: PlayerHistory, current_round: int, coop_count_prev: int) -> bool:
        """
        Detect if the system is being exploited:
        High reward for defection despite others cooperating.
        """
        coop_rate_prev = coop_count_prev / self.n
        exploitation_gain = 1.0 - self.k / self.n
        exploitation_ratio = exploitation_gain / (self.k / self.n) if self.k / self.n > 0 else 0
        if exploitation_ratio > 0.8 and coop_rate_prev > 0.3:
            return True
        if current_round >= 2:
            coop_rate_prev_prev = int(np.sum(history.opponent_actions[current_round - 2, :])) / self.n
            if abs(coop_rate_prev - coop_rate_prev_prev) > 0.5:
                return True
        return False

    def _should_recover(self, history: PlayerHistory, current_round: int, adjusted_threshold: float) -> bool:
        """
        Check if I should recover from defection streak.
        Others still cooperating despite my defection signals willingness to rebuild.
        """
        if self.consecutive_defections < 2:
            return False
        if self.consecutive_defections >= 3:
            return False
        prev_round_idx = current_round - 1
        coop_count_prev = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        coop_rate_prev = coop_count_prev / self.n
        if coop_rate_prev >= adjusted_threshold:
            return True
        return False

class Strategy_COLLECTIVE_301(BaseStrategy):
    """
    Adaptive Conditional Contribution (ACC) Strategy

    Balances collective welfare maximization with protection against exploitation.
    - Round 1: Cooperate (probe cooperativeness)
    - Rounds 2 to r-1: Conditional reciprocity based on observed cooperation rate
    - Final round: Cooperate if average cooperation met threshold, else defect
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        cooperation_threshold = self._calculate_cooperation_threshold()
        if round_t == self.r - 1:
            avg_cooperation_rate = self._calculate_average_cooperation_rate(history, round_t)
            if avg_cooperation_rate >= cooperation_threshold:
                return Action.C
            else:
                return Action.D
        observed_cooperation_rate = self._get_cooperation_rate_last_round(history)
        relative_gain = self._calculate_relative_gain(history)
        if round_t >= 2 and observed_cooperation_rate < 0.2:
            return Action.D
        if round_t >= 3 and self._is_cooperation_declining(history):
            return Action.D
        if observed_cooperation_rate >= cooperation_threshold:
            return Action.C
        elif observed_cooperation_rate < cooperation_threshold and relative_gain > 0.5:
            return Action.D
        else:
            return Action.C

    def _calculate_cooperation_threshold(self) -> float:
        """Calculate adaptive cooperation threshold based on game parameters."""
        base_threshold = self.k / self.n
        if self.k > self.n * 0.95:
            return base_threshold + 0.05
        elif self.k < 1.2:
            return base_threshold + 0.15
        elif self.n == 2:
            return base_threshold + 0.1
        else:
            return base_threshold + 0.1

    def _get_cooperation_rate_last_round(self, history: PlayerHistory) -> float:
        """Get the cooperation rate from the previous round."""
        if history.opponent_actions.shape[0] == 0:
            return 0.0
        last_round_idx = history.opponent_actions.shape[0] - 1
        opponent_cooperators = sum(history.opponent_actions[last_round_idx, :])
        self_cooperated = history.my_actions[last_round_idx]
        total_cooperators = opponent_cooperators + (1 if self_cooperated else 0)
        cooperation_rate = total_cooperators / self.n
        return cooperation_rate

    def _calculate_relative_gain(self, history: PlayerHistory) -> float:
        """
        Calculate the relative gain from defecting in the last round.
        relative_gain = payoff_if_defected - payoff_if_cooperated
        """
        if history.opponent_actions.shape[0] == 0:
            return 0.0
        last_round_idx = history.opponent_actions.shape[0] - 1
        opponent_cooperators = sum(history.opponent_actions[last_round_idx, :])
        total_cooperators_if_c = opponent_cooperators + 1
        payoff_if_c = 0 + self.k / self.n * total_cooperators_if_c
        total_cooperators_if_d = opponent_cooperators
        payoff_if_d = 1 + self.k / self.n * total_cooperators_if_d
        relative_gain = payoff_if_d - payoff_if_c
        return relative_gain

    def _calculate_average_cooperation_rate(self, history: PlayerHistory, up_to_round: int) -> float:
        """Calculate average cooperation rate from round 0 to up_to_round (exclusive)."""
        if up_to_round <= 0:
            return 0.0
        total_rate = 0.0
        for round_idx in range(up_to_round):
            opponent_cooperators = sum(history.opponent_actions[round_idx, :])
            self_cooperated = history.my_actions[round_idx]
            total_cooperators = opponent_cooperators + (1 if self_cooperated else 0)
            cooperation_rate = total_cooperators / self.n
            total_rate += cooperation_rate
        avg_rate = total_rate / up_to_round
        return avg_rate

    def _is_cooperation_declining(self, history: PlayerHistory) -> bool:
        """
        Detect if cooperation rate is in a declining trend (last 3 rounds).
        Returns True if clear decline detected.
        """
        if history.opponent_actions.shape[0] < 3:
            return False
        rates = []
        for round_idx in range(history.opponent_actions.shape[0] - 3, history.opponent_actions.shape[0]):
            opponent_cooperators = sum(history.opponent_actions[round_idx, :])
            self_cooperated = history.my_actions[round_idx]
            total_cooperators = opponent_cooperators + (1 if self_cooperated else 0)
            cooperation_rate = total_cooperators / self.n
            rates.append(cooperation_rate)
        if len(rates) == 3 and rates[0] > rates[1] > rates[2]:
            return True
        return False

class Strategy_COLLECTIVE_302(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization, robust defection against exploiters,
    and graceful degradation through three phases:
    1. Opening (rounds 0 to floor(r/2)-1): COOPERATE to signal intent
    2. Adaptive Reciprocation (rounds floor(r/2) to r-2): Condition on observed cooperation rate
    3. Final Round (round r-1): DEFECT (subgame perfection)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        n = self.n_players
        r = self.n_rounds
        k = self.k
        opening_phase_end = math.floor(r / 2)
        if round_number < opening_phase_end:
            return Action.C
        if round_number == r - 1:
            return Action.D
        total_cooperators = np.sum(history.opponent_actions[:round_number, :])
        total_actions = n * round_number
        if total_actions == 0:
            cooperation_rate = 0.0
        else:
            cooperation_rate = total_cooperators / total_actions
        threshold = k / n
        if cooperation_rate >= threshold:
            return Action.C
        elif cooperation_rate >= 0.5:
            if random.random() < cooperation_rate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_303(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy

    Balances collective welfare maximization with individual sustainability through
    graduated reciprocity. Cooperates in round 1, then uses cooperation rate from
    previous round to determine action: high cooperation (50%)  cooperate,
    medium cooperation (20-50%)  probabilistic reciprocity, low cooperation (<20%)
     defect. Includes reset mechanism for extinction scenarios.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_high = 0.5
        self.threshold_low = 0.2
        self.last_reset_round = -3
        self.n = game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round_idx = state.round_number - 1
        opponent_cooperators = sum(history.opponent_actions[prev_round_idx, :])
        self_cooperated = int(history.my_actions[prev_round_idx])
        total_cooperators = opponent_cooperators + self_cooperated
        cooperation_rate = total_cooperators / self.n
        if cooperation_rate >= self.threshold_high:
            return Action.C
        elif cooperation_rate >= self.threshold_low:
            if random.random() < cooperation_rate:
                return Action.C
            else:
                return Action.D
        elif cooperation_rate == 0 and state.round_number - self.last_reset_round > 2:
            self.last_reset_round = state.round_number
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_304(BaseStrategy):
    """
    Adaptive Reciprocal Threshold (ART) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare through three phases:
    1. Cooperative Exploration (rounds 1 to r/3): Probe for cooperation
    2. Reciprocal Enforcement (rounds r/3+1 to 2r/3): Threshold-based reciprocation
    3. Endgame Optimization (rounds 2r/3+1 to r): Defect in final 1-2 rounds, reciprocate otherwise
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.phase1_end = math.ceil(self.r / 3)
        self.phase2_end = math.floor(2 * self.r / 3)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round < self.phase1_end:
            if current_round == 1:
                return Action.C
            coop_rate = self._calculate_coop_rate(history, current_round)
            if coop_rate >= 0.5:
                return Action.C
            else:
                return Action.D
        remaining_rounds = self.r - current_round
        if remaining_rounds <= 2:
            return Action.D
        coop_rate = self._calculate_coop_rate(history, current_round)
        threshold = self.n / (2 * self.k)
        if coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_coop_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the historical cooperation rate across all players up to (but not including) current_round.

        Returns the fraction of cooperations observed in all previous rounds.
        """
        if current_round == 0:
            return 0.0
        my_cooperations = np.sum(history.my_actions[:current_round])
        opponent_cooperations = np.sum(history.opponent_actions[:current_round, :])
        total_cooperations = my_cooperations + opponent_cooperations
        total_actions = current_round * self.n
        coop_rate = total_cooperations / total_actions if total_actions > 0 else 0.0
        return coop_rate

class Strategy_COLLECTIVE_305(BaseStrategy):
    """
    Adaptive Graduated Reciprocity with Public Goods Calibration (AGRP)

    A strategy that balances sustainable collective value creation with robustness to exploitation.
    It adapts to game parameters (k, n) and uses graduated reciprocity: rewarding cooperation,
    punishing defection, and enabling recovery through probabilistic transitions.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_threshold = (game_description.k - 1) / game_description.k
        self.adjusted_threshold = self._calculate_adjusted_threshold()

    def _calculate_adjusted_threshold(self) -> float:
        """Adjust cooperation threshold based on extreme k values."""
        k = self.game_description.k
        n = self.game_description.n_players
        if k < 1.3:
            return self.cooperation_threshold * min(k, 1.5) / 1.5
        elif k > n - 0.5:
            return self.cooperation_threshold * 0.6
        else:
            return self.cooperation_threshold

    def _get_observed_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate in the most recent round."""
        if len(history.opponent_actions) == 0:
            return 0.0
        cooperators_others = sum(history.opponent_actions[-1, :])
        cooperators_self = 1 if history.my_actions[-1] else 0
        total_cooperators = cooperators_others + cooperators_self
        return total_cooperators / self.game_description.n_players

    def _get_average_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate average cooperation rate across all previous rounds."""
        if len(history.opponent_actions) == 0:
            return 0.0
        total_coop = 0.0
        for round_idx in range(len(history.opponent_actions)):
            cooperators_others = sum(history.opponent_actions[round_idx, :])
            cooperators_self = 1 if history.my_actions[round_idx] else 0
            total_cooperators = cooperators_others + cooperators_self
            total_coop += total_cooperators / self.game_description.n_players
        return total_coop / len(history.opponent_actions)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        n_rounds = self.game_description.n_rounds
        if state.round_number == n_rounds - 1:
            avg_coop_rate = self._get_average_cooperation_rate(history)
            threshold_for_last = self.adjusted_threshold * 0.7
            if avg_coop_rate >= threshold_for_last:
                return Action.C
            else:
                return Action.D
        observed_coop_rate = self._get_observed_cooperation_rate(history)
        if observed_coop_rate >= self.adjusted_threshold:
            return Action.C
        elif observed_coop_rate >= self.adjusted_threshold * 0.6:
            if random.random() < observed_coop_rate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_306(BaseStrategy):
    """
    Adaptive Threshold Reciprocity (ATR) Strategy for N-Player Public Goods Game

    Balances individual rationality with collective welfare by:
    1. Bootstrapping cooperation in round 1
    2. Adapting to observed cooperation rates via dynamic thresholds
    3. Using graduated responses based on population-level behavior
    4. Applying mixed strategies in uncertain conditions
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        observed_cooperation_rate = self._calculate_cooperation_rate(history, state.round_number)
        cooperation_threshold = self.k / self.n
        defection_threshold = cooperation_threshold * 0.5
        if self.n <= 3:
            defection_threshold = self.k / (2 * self.n)
        if observed_cooperation_rate >= cooperation_threshold:
            return Action.C
        elif observed_cooperation_rate <= defection_threshold:
            return Action.D
        elif random.random() < observed_cooperation_rate:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_number: int) -> float:
        """
        Calculate the empirical cooperation rate across all players and all played rounds.

        Args:
            history: PlayerHistory object containing opponent actions
            round_number: Current round number (1-indexed in this context)

        Returns:
            Cooperation rate as float in [0, 1]
        """
        opponent_actions = history.opponent_actions[:round_number]
        total_cooperators = np.sum(opponent_actions)
        total_instances = round_number * (self.n - 1)
        if total_instances == 0:
            return 0.0
        cooperation_rate = total_cooperators / total_instances
        if self.n > 10:
            cooperation_rate = self._apply_ema(history, round_number, cooperation_rate)
        return cooperation_rate

    def _apply_ema(self, history: PlayerHistory, round_number: int, current_rate: float) -> float:
        """
        Apply exponential moving average for large populations to reduce noise.

        Args:
            history: PlayerHistory object
            round_number: Current round number
            current_rate: Raw cooperation rate calculated

        Returns:
            Smoothed cooperation rate
        """
        if round_number <= 1:
            return current_rate
        alpha = 0.3
        previous_rate = np.sum(history.opponent_actions[:round_number - 1]) / ((round_number - 1) * (self.n - 1)) if round_number - 1 > 0 else 0.0
        ema = (1 - alpha) * previous_rate + alpha * current_rate
        return ema

class Strategy_COLLECTIVE_307(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    This strategy implements a collective optimization approach that:
    1. Starts with cooperation to establish good faith
    2. Monitors overall cooperation rates across all players
    3. Responds with tiered thresholds: full cooperation, stochastic cooperation, or defection
    4. Adapts gracefully to different opponent compositions while protecting against exploitation
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        total_cooperators = 0
        for round_idx in range(round_number):
            my_cooperation = 1 if history.my_actions[round_idx] else 0
            opponent_cooperators = sum(history.opponent_actions[round_idx, :])
            total_cooperators += my_cooperation + opponent_cooperators
        total_slots = self.n * round_number
        coop_rate = total_cooperators / total_slots if total_slots > 0 else 0
        threshold_high = self.k / self.n - 0.05
        threshold_low = 0.5 * (self.k / self.n)
        threshold_severe = 0.3 * (self.k / self.n)
        is_last_round = round_number == self.r - 1
        if coop_rate >= threshold_high:
            return Action.C
        elif coop_rate >= threshold_low:
            if random.random() < 0.6:
                return Action.C
            else:
                return Action.D
        elif is_last_round:
            if coop_rate < threshold_severe:
                return Action.D
            elif random.random() < 0.4:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_308(BaseStrategy):
    """
    Adaptive Contribution with Threshold Defection strategy for N-Player Public Goods Game.

    This strategy balances collective welfare maximization with robustness against exploitation
    through conditional reciprocity. It cooperates in round 1, then cooperates in subsequent rounds
    if and only if the previous round's cooperation rate exceeded the threshold (k-1)/n.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.k = game_description.k
        self.threshold = (game_description.k - 1) / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round_opponent_actions = history.opponent_actions[state.round_number - 1, :]
        cooperators_prev_round = np.sum(prev_round_opponent_actions)
        if history.my_actions[state.round_number - 1]:
            cooperators_prev_round += 1
        cooperation_rate_prev = cooperators_prev_round / self.n_players
        if cooperation_rate_prev > self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_309(BaseStrategy):
    """
    Adaptive Conditional Contribution (ACC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization, resilience to exploitation, and robustness
    to uncertainty by using a dynamic cooperation threshold that adapts based on observed
    cooperation rates and game parameters.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_cooperation_count = int(sum(history.opponent_actions[round_num - 1, :]))
        prev_cooperation_rate = prev_cooperation_count / self.n
        if round_num == self.r - 1:
            if prev_cooperation_rate >= 0.4:
                return Action.C
            else:
                return Action.D
        base_threshold = 1.0 - (1.0 - self.k / self.n) * round_num / (self.r - 1)
        adjustment = 0.0
        prev_payoff = history.my_payoffs[round_num - 1]
        avg_payoff = (1.0 + self.k / self.n) / 2.0
        if prev_cooperation_rate < 0.5 and prev_payoff < avg_payoff:
            adjustment = -0.05
        threshold = max(0.2, base_threshold + adjustment)
        if self.n == 2:
            threshold = min(0.9, threshold + 0.1)
        if self.k >= self.n - 1:
            threshold = min(threshold, 0.2)
        elif self.k <= 1.5:
            threshold = max(threshold, 0.75)
        if prev_cooperation_rate == 0.0:
            return Action.D
        if prev_cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_310(BaseStrategy):
    """
    Adaptive Contribution with Defection Threshold Strategy for N-Player Public Goods Game.

    Balances collective welfare with individual rationality by:
    1. Cooperating in round 1 to establish mutual benefit potential
    2. Monitoring aggregate cooperation rate across all history
    3. Adapting based on whether cooperation meets a threshold derived from game parameters
    4. Defecting in the final round due to endgame dynamics

    The cooperation threshold is (k/n)  0.5, which represents the break-even point
    where cooperation becomes individually rational given the incentive structure.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n_players * 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.n_rounds - 1:
            return Action.D
        my_cooperations = np.sum(history.my_actions[:round_number])
        opponent_cooperations = np.sum(history.opponent_actions[:round_number, :])
        total_cooperators = my_cooperations + opponent_cooperations
        total_player_rounds = round_number * self.n_players
        observed_cooperation_rate = total_cooperators / total_player_rounds
        if observed_cooperation_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_311(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with individual resilience against defection.
    Cooperates in round 1, then reciprocates based on historical cooperation rate against
    a threshold of k/n (the break-even point for cooperation).
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        total_cooperators = int(np.sum(history.my_actions)) + int(np.sum(history.opponent_actions))
        total_slots = state.round_number * self.game_description.n_players
        if total_slots == 0:
            return Action.C
        historical_coop_rate = total_cooperators / total_slots
        if historical_coop_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_312(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare by:
    1. Seeding cooperation in round 1
    2. Adapting based on group cooperation rate vs. mathematical threshold (k/n)
    3. Comparing personal performance to group average
    4. Defecting in final round (subgame perfection)
    5. Signaling reset when group is trapped in low cooperation
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n
        self.tolerance = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            return Action.D
        prev_round_idx = round_num - 1
        prev_cooperators = np.sum(history.opponent_actions[prev_round_idx, :])
        if history.my_actions[prev_round_idx]:
            prev_cooperators += 1
        prev_cooperation_rate = prev_cooperators / self.n
        my_payoff = history.my_payoffs[prev_round_idx]
        avg_payoff = np.mean(history.opponent_payoffs[prev_round_idx, :])
        all_payoffs = np.concatenate([[my_payoff], history.opponent_payoffs[prev_round_idx, :]])
        avg_payoff = np.mean(all_payoffs)
        performance_gap = my_payoff - avg_payoff
        if prev_cooperation_rate >= 2 * self.threshold:
            return Action.C
        if prev_cooperation_rate >= self.threshold and performance_gap >= -self.tolerance:
            return Action.C
        if prev_cooperation_rate < self.threshold and performance_gap < 0:
            return Action.D
        return Action.C

class Strategy_COLLECTIVE_313(BaseStrategy):
    """
    Adaptive Contribution with Conditional Reciprocity.

    Balances collective welfare maximization with individual sustainability.
    - Round 1: Cooperate (establish coordination anchor)
    - Final round: Defect (no future punishment possible)
    - Middle rounds: Adapt based on observed cooperation rate with probabilistic reciprocation
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            return Action.D
        last_round_idx = round_num - 1
        opponent_cooperators = np.sum(history.opponent_actions[last_round_idx, :])
        my_cooperation = history.my_actions[last_round_idx]
        total_cooperators = opponent_cooperators + (1 if my_cooperation else 0)
        cooperation_rate = total_cooperators / self.n
        threshold_high = max(0.6, 1.0 - 1.0 / self.k)
        threshold_medium = 0.5
        threshold_low = 1.0 / self.n + 0.1
        if cooperation_rate >= threshold_high:
            return Action.C
        elif cooperation_rate >= threshold_medium:
            if random.random() < cooperation_rate:
                return Action.C
            else:
                return Action.D
        elif cooperation_rate < threshold_low:
            return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_314(BaseStrategy):
    """
    Adaptive Graduated Reciprocity with Threshold Sensing for N-Player Public Goods Game.

    This strategy balances collective welfare maximization with protection against exploitation.
    It uses dynamic thresholds based on the break-even point for public goods cooperation,
    adapts based on observed cooperation rates, and handles edge cases for sustainability.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def _count_cooperators_in_round(self, history: PlayerHistory, round_idx: int) -> int:
        """Count total cooperators (including self) in a given round."""
        my_action = 1 if history.my_actions[round_idx] else 0
        opponent_cooperators = sum(history.opponent_actions[round_idx, :])
        return my_action + opponent_cooperators

    def _get_cooperation_rate(self, history: PlayerHistory, round_idx: int) -> float:
        """Get cooperation rate in a given round."""
        cooperators = self._count_cooperators_in_round(history, round_idx)
        return cooperators / self.n

    def _calculate_threshold(self, round_t: int) -> float:
        """Calculate dynamic threshold for cooperation decision."""
        if round_t == 0 or round_t == 1:
            return 0.0
        elif round_t >= self.r - 1:
            return (self.k - 1) / self.n
        else:
            base_threshold = max(0.15, (self.k - 1) / self.n)
            return base_threshold

    def _has_two_round_downtrend(self, history: PlayerHistory, round_t: int) -> bool:
        """Check if cooperation has declined in the last two rounds."""
        if round_t < 2:
            return False
        coop_rate_current = self._get_cooperation_rate(history, round_t - 1)
        coop_rate_prev = self._get_cooperation_rate(history, round_t - 2)
        if round_t < 3:
            return coop_rate_current < coop_rate_prev
        coop_rate_prev_prev = self._get_cooperation_rate(history, round_t - 3)
        return coop_rate_current < coop_rate_prev and coop_rate_prev < coop_rate_prev_prev

    def _has_sustained_zero_cooperation(self, history: PlayerHistory, round_t: int) -> bool:
        """Check if cooperation has been zero for 2+ consecutive rounds."""
        if round_t < 2:
            return False
        coop_rate_current = self._get_cooperation_rate(history, round_t - 1)
        coop_rate_prev = self._get_cooperation_rate(history, round_t - 2)
        return coop_rate_current == 0.0 and coop_rate_prev == 0.0

    def _handle_small_n_adjustment(self, threshold: float) -> float:
        """Apply safety margin for small n."""
        if self.n <= 3:
            threshold += 0.1
        return min(threshold, 1.0)

    def _handle_weak_multiplier_adjustment(self, threshold: float) -> float:
        """Adjust threshold when k is weak."""
        if self.k <= 1.2:
            threshold = threshold * 0.8
        return threshold

    def _is_high_cooperation_with_decline(self, coop_rate: float, round_t: int) -> bool:
        """Detect high cooperation with declining trend."""
        return coop_rate >= 0.7 and self._has_two_round_downtrend(None if round_t < 2 else None, round_t)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        if round_t == self.r - 1:
            coop_rate_prev = self._get_cooperation_rate(history, round_t - 1)
            threshold_final = (self.k - 1) / self.n
            if coop_rate_prev >= threshold_final:
                return Action.C
            else:
                return Action.D
        coop_rate_t_minus_1 = self._get_cooperation_rate(history, round_t - 1)
        threshold = self._calculate_threshold(round_t)
        threshold = self._handle_small_n_adjustment(threshold)
        threshold = self._handle_weak_multiplier_adjustment(threshold)
        if self._has_sustained_zero_cooperation(history, round_t):
            return Action.D if coop_rate_t_minus_1 == 0.0 else Action.C
        downtrend = self._has_two_round_downtrend(history, round_t)
        if coop_rate_t_minus_1 >= threshold:
            return Action.C
        elif coop_rate_t_minus_1 < threshold and downtrend:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_315(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game

    Balances individual security with collective value creation through graduated
    contribution levels (0%, 50%, 100%) that respond to demonstrated cooperation
    and increase over time to maximize total welfare.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        avg_coop_rate = self._calculate_avg_cooperation_rate(history, current_round)
        if self._is_low_cooperation_persistent(history, current_round):
            return Action.D
        if current_round == self.r - 1:
            if avg_coop_rate >= 0.7:
                return Action.C
            else:
                return Action.D
        round_multiplier = 1.0 + current_round / self.r * 0.2
        threshold_low = (self.k / self.n + 0.1) * round_multiplier
        threshold_high = 0.7 * round_multiplier
        if avg_coop_rate < threshold_low:
            return Action.D
        elif avg_coop_rate < threshold_high:
            return Action.C
        else:
            return Action.C

    def _calculate_avg_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the average cooperation rate across all players and all previous rounds.
        """
        if current_round == 0:
            return 0.5
        my_contributions = np.sum(history.my_actions[:current_round])
        opponent_contributions = np.sum(history.opponent_actions[:current_round, :])
        total_contributions = my_contributions + opponent_contributions
        possible_contributions = current_round * self.n
        avg_coop_rate = total_contributions / possible_contributions if possible_contributions > 0 else 0.0
        return float(avg_coop_rate)

    def _is_low_cooperation_persistent(self, history: PlayerHistory, current_round: int) -> bool:
        """
        Check if cooperation has been persistently below k/(2n) for 2+ consecutive rounds.
        """
        if current_round < 2:
            return False
        threshold = self.k / (2.0 * self.n)
        for round_idx in range(max(0, current_round - 2), current_round):
            round_cooperators = int(history.my_actions[round_idx]) + np.sum(history.opponent_actions[round_idx, :])
            round_coop_rate = round_cooperators / self.n
            if round_coop_rate >= threshold:
                return False
        return True

class Strategy_COLLECTIVE_316(BaseStrategy):
    """
    Adaptive Collective Strategy for N-Player Public Goods Game.

    Balances collective value creation, individual protection, and robustness through
    conditional reciprocal contribution based on observed cooperation rates, with
    special handling for early rounds, final rounds, and various edge cases.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        prev_round_idx = round_number - 1
        cooperators_count = int(sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            cooperators_count += 1
        cooperation_rate = cooperators_count / self.n
        if round_number >= 2:
            prev_prev_round_idx = round_number - 2
            prev_cooperators = int(sum(history.opponent_actions[prev_prev_round_idx, :]))
            if history.my_actions[prev_prev_round_idx]:
                prev_cooperators += 1
            prev_cooperation_rate = prev_cooperators / self.n
            smoothed_rate = 0.4 * cooperation_rate + 0.6 * prev_cooperation_rate
        else:
            smoothed_rate = cooperation_rate
        baseline_threshold = 1.0 / self.k
        if self.n <= 3:
            threshold = min(baseline_threshold, 0.4)
        else:
            threshold = baseline_threshold
        if self.r > 10:
            early_threshold = 0.3 * self.r
            late_threshold = 0.7 * self.r
            if round_number <= early_threshold:
                threshold = max(threshold - 0.15, 0.1)
            elif round_number > late_threshold:
                threshold = threshold + 0.05
        rounds_remaining = self.r - round_number
        if round_number == self.r - 1:
            if cooperation_rate >= 0.5:
                return Action.C
            else:
                return Action.D
        if smoothed_rate >= threshold:
            return Action.C
        elif rounds_remaining > 1:
            recovery_probability = (threshold - smoothed_rate) * 2.0
            recovery_probability = min(recovery_probability, 0.5)
            recovery_probability = max(recovery_probability, 0.0)
            if random.random() < recovery_probability:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_317(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC): A collective welfare strategy that balances
    cooperation to maximize group payoffs with vigilance against free-riders.

    Core logic:
    - Round 1: Cooperate (signal willingness)
    - Rounds 2 to r-1: Adapt based on cooperation ratio (CR)
      * CR >= (k-1)/k + 0.05: Cooperate (sufficient cooperation)
      * CR >= 0.5: Cooperate with probability CR (probabilistic matching)
      * CR < 0.5: Defect (widespread defection)
    - Final round: Defect (no future consequences)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        total_cooperators = 0
        rounds_completed = current_round
        for round_idx in range(rounds_completed):
            if history.my_actions[round_idx]:
                total_cooperators += 1
            total_cooperators += np.sum(history.opponent_actions[round_idx, :])
        total_slots = self.n_players * rounds_completed
        cr = total_cooperators / total_slots if total_slots > 0 else 0.0
        epsilon = 0.05
        threshold = (self.k - 1) / self.k + epsilon
        if cr >= threshold:
            return Action.C
        elif cr >= 0.5:
            if random.random() < cr:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_318(BaseStrategy):
    """
    Adaptive Contribution Threshold (ACT) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare by monitoring cooperation rates
    and adapting contributions through a threshold-based mechanism with probabilistic fallback.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.cooperation_threshold = (1 + self.k) / (2 * self.k)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.n_rounds - 1:
            recent_payoff = history.my_payoffs[-1]
            if recent_payoff >= self.k / self.n_players * self.n_players * 0.4:
                return Action.C
            else:
                return Action.D
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        observed_cooperation_rate = last_round_cooperators / self.n_players
        if observed_cooperation_rate >= self.cooperation_threshold:
            return Action.C
        elif observed_cooperation_rate >= self.cooperation_threshold * 0.7:
            if observed_cooperation_rate > 0.01:
                prob_cooperate = self.cooperation_threshold / observed_cooperation_rate
            else:
                prob_cooperate = 0.0
            prob_cooperate = max(0.0, min(1.0, prob_cooperate))
            if random.random() < prob_cooperate:
                return Action.C
            else:
                return Action.D
        else:
            if self.n_rounds <= 3 and round_number == self.n_rounds - 2:
                return Action.C
            return Action.D

class Strategy_COLLECTIVE_319(BaseStrategy):
    """
    Adaptive Reciprocal Equilibrium (ARE) Strategy for N-Player Public Goods Game.

    Operates on conditional cooperation with adaptive thresholds:
    - Round 1: Cooperate to establish baseline
    - Rounds 2 to r-1: Adapt based on opponent cooperation rate vs dynamic threshold
    - Final round: Defect (subgame perfect equilibrium)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        prev_round_idx = current_round - 1
        prev_round_cooperators = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        coop_rate = prev_round_cooperators / self.n_players
        base_threshold = self.k / self.n_players
        slope = 1 - self.k / self.n_players
        threshold = base_threshold + slope * coop_rate
        if current_round == self.n_rounds - 2:
            threshold = threshold * 1.1
        if coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_320(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy

    Balances collective welfare maximization with individual robustness through
    adaptive threshold-based cooperation. Cooperates unconditionally in round 1,
    defects in the final round, and conditionally cooperates in intermediate rounds
    based on whether observed cooperation rates exceed a sustainability threshold.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        k = game_description.k
        n = game_description.n_players
        threshold_ratio = (k + 1) / (2 * k)
        self.threshold_cooperators = math.ceil(threshold_ratio * n)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        n_rounds = self.game_description.n_rounds
        if current_round == 0:
            return Action.C
        if current_round == n_rounds - 1:
            return Action.D
        previous_round_index = current_round - 1
        cooperators_in_previous_round = np.sum(history.opponent_actions[previous_round_index, :])
        if cooperators_in_previous_round >= self.threshold_cooperators:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_321(BaseStrategy):
    """
    Adaptive Trust-Building with Defection Deterrence strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with self-protection against exploitation.
    Uses adaptive thresholds based on observed cooperation rates and game parameters.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            prev_round_cooperators = np.sum(history.opponent_actions[current_round - 1, :])
            prev_coop_rate = prev_round_cooperators / self.n
            if prev_coop_rate >= 0.7:
                return Action.C
            return Action.D
        prev_round_cooperators = np.sum(history.opponent_actions[current_round - 1, :])
        prev_coop_rate = prev_round_cooperators / self.n
        threshold = self.k / self.n + (1 - self.k / self.n) * (self.r - current_round) / self.r
        collective_benefit = self.k - 1
        effective_threshold = threshold
        if collective_benefit > 0 and prev_coop_rate > 0.4:
            effective_threshold = threshold * 0.9
        if prev_coop_rate >= effective_threshold:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_322(BaseStrategy):
    """
    Adaptive Contribution with Decay-Resistant Cooperation

    This strategy balances collective rationality, individual robustness, and adaptive resilience.
    It starts with cooperation, then adapts based on observed cooperation rates using a dynamic
    threshold that becomes more forgiving over time.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round_idx = state.round_number - 1
        cooperators_previous = int(np.sum(history.opponent_actions[previous_round_idx, :]))
        my_previous_action = history.my_actions[previous_round_idx]
        total_cooperators = cooperators_previous + (1 if my_previous_action else 0)
        cooperation_rate = total_cooperators / self.game_description.n_players
        t = state.round_number
        r = self.game_description.n_rounds
        threshold = max(0.5, 1.0 - t / r * 0.3)
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_323(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    A collective-minded strategy that balances incentive compatibility, robustness, and
    collective welfare by using a mathematically-grounded cooperation threshold based on
    the game's multiplication factor k.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.minimum_threshold = 0.5
        self.efficiency_threshold = (self.k - 1) / self.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            prev_round_idx = current_round - 1
            cooperators_prev = sum(history.opponent_actions[prev_round_idx, :])
            cooperation_rate_prev = cooperators_prev / self.n
            if self.k >= 2.0 and cooperation_rate_prev >= 0.5:
                return Action.C
            else:
                return Action.D
        prev_round_idx = current_round - 1
        cooperators_prev = sum(history.opponent_actions[prev_round_idx, :])
        cooperation_rate_prev = cooperators_prev / self.n
        threshold_current = max(self.minimum_threshold, self.efficiency_threshold)
        if cooperators_prev == 0:
            return Action.D
        if cooperators_prev == self.n:
            return Action.C
        if current_round >= 3:
            last_three_rounds = [sum(history.opponent_actions[current_round - i, :]) / self.n for i in range(1, 4) if current_round - i >= 0]
            if len(last_three_rounds) >= 3 and all((cr <= 0.3 for cr in last_three_rounds)):
                return Action.D
        if current_round >= 2:
            coop_rate_two_back = sum(history.opponent_actions[current_round - 2, :]) / self.n
            if coop_rate_two_back < 0.4 and cooperation_rate_prev >= threshold_current:
                return Action.C
        if cooperation_rate_prev >= threshold_current:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_324(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with individual rationality by dynamically
    adjusting cooperation thresholds based on observed cooperation rates and game progress.
    Cooperates when cooperation becomes individually rational given others' behavior.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        cooperators_last_round = int(np.sum(history.opponent_actions[round_num - 1, :]))
        cooperation_rate = cooperators_last_round / self.n
        if round_num == 1:
            required_rate = 0.66
        else:
            base_threshold = max(0.0, (self.k - 1.0) / self.k)
            time_factor = 1.0 + (self.r - round_num) / (2.0 * self.r)
            required_rate = base_threshold * time_factor
        if cooperation_rate >= required_rate:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_325(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Dynamically adjusts contribution levels based on observed cooperation rates and
    remaining game length. Cooperates in round 1, then reciprocates based on whether
    the previous round's cooperation rate justifies the public good multiplier,
    with adaptive thresholds that account for end-game effects.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        my_prev_action = history.my_actions[prev_round_idx]
        opponent_prev_actions = history.opponent_actions[prev_round_idx, :]
        total_cooperators = int(my_prev_action) + int(np.sum(opponent_prev_actions))
        coop_rate = total_cooperators / self.n
        threshold = self.k / self.n
        if current_round >= self.r - 1:
            if coop_rate >= threshold:
                return Action.C
            else:
                return Action.D
        rounds_remaining = self.r - current_round
        adjusted_threshold = threshold - rounds_remaining / self.r * 0.05
        if coop_rate >= adjusted_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_326(BaseStrategy):
    """
    Adaptive Threshold Cooperation with Resilient Recovery strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with robustness against exploitation by:
    - Cooperating in round 1 (good faith signal)
    - Using threshold-based decision making in middle rounds
    - Adapting to cooperation levels while allowing recovery attempts
    - Applying special logic for the final round
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.k - 1) / self.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_idx = round_num - 1
        my_prev_action = history.my_actions[prev_round_idx]
        opponent_cooperators_prev = np.sum(history.opponent_actions[prev_round_idx, :])
        total_cooperators_prev = int(my_prev_action) + int(opponent_cooperators_prev)
        coop_ratio = total_cooperators_prev / self.n
        rounds_remaining = self.r - round_num - 1
        if round_num == self.r - 1:
            if coop_ratio >= self.threshold or coop_ratio >= 0.5:
                return Action.C
            else:
                return Action.D
        if coop_ratio >= self.threshold:
            return Action.C
        elif coop_ratio >= 0.5:
            return Action.C
        elif coop_ratio > 0 and rounds_remaining > 2:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_327(BaseStrategy):
    """
    Adaptive Contribution Threshold (ACT) Strategy

    Maximizes collective welfare while maintaining robustness against exploitation.
    Cooperates when cooperation rate justifies contribution and trend is positive.
    Adapts endgame behavior based on sustained cooperation history.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.cooperation_history = []
        self.probe_mode = False
        self.probe_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if history is not None:
            self._update_cooperation_history(history, current_round)
        threshold = self._compute_threshold()
        if len(self.cooperation_history) > 0 and self.cooperation_history[-1] == 0:
            if current_round >= 2:
                return Action.D
        if self.probe_mode:
            self.probe_counter += 1
            if self.probe_counter <= 2:
                return Action.D
            elif self.probe_counter == 3:
                self.probe_counter = 0
                self.probe_mode = False
                return Action.C
            return Action.D
        if current_round == 1:
            return Action.C
        if current_round >= 2 and current_round < self.n_rounds - 2:
            return self._mid_game_decision(threshold, current_round)
        if current_round >= self.n_rounds - 2:
            return self._endgame_decision(threshold, current_round)
        return Action.D

    def _update_cooperation_history(self, history: PlayerHistory, current_round: int):
        """Update cooperation history with counts from each round."""
        for round_idx in range(len(self.cooperation_history), current_round):
            if round_idx < len(history.opponent_actions):
                cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
                if history.my_actions[round_idx]:
                    cooperators += 1
                self.cooperation_history.append(cooperators)

    def _compute_threshold(self) -> float:
        """Compute cooperation rate threshold based on game parameters."""
        base_threshold = (self.k - 1) / self.k
        if self.k < 1.2:
            return 0.9
        return base_threshold

    def _mid_game_decision(self, threshold: float, current_round: int) -> Action:
        """Apply primary decision logic for mid-game rounds."""
        prev_coop_rate = self.cooperation_history[-1] / self.n_players
        if current_round == 2 and prev_coop_rate < 0.3:
            self.probe_mode = True
            self.probe_counter = 0
            return Action.D
        if prev_coop_rate < threshold:
            return Action.D
        if len(self.cooperation_history) >= 3:
            recent_coop_rates = [c / self.n_players for c in self.cooperation_history[-3:]]
            trend = self._compute_trend(recent_coop_rates)
            if self._is_volatile(recent_coop_rates):
                return Action.D
            if trend < 0:
                return Action.D
        return Action.C

    def _endgame_decision(self, threshold: float, current_round: int) -> Action:
        """Apply conservative endgame logic with high-cooperation exception."""
        if len(self.cooperation_history) == 0:
            return Action.D
        avg_coop_rate = np.mean(self.cooperation_history) / self.n_players
        if avg_coop_rate >= 0.8:
            return Action.C
        prev_coop_rate = self.cooperation_history[-1] / self.n_players
        if prev_coop_rate >= threshold:
            return Action.C
        return Action.D

    def _compute_trend(self, recent_rates: list) -> float:
        """
        Compute trend from recent cooperation rates.
        Returns positive if improving/stable, negative if declining.
        """
        if len(recent_rates) < 2:
            return 0.0
        diffs = []
        for i in range(1, len(recent_rates)):
            diffs.append(recent_rates[i] - recent_rates[i - 1])
        return float(np.mean(diffs))

    def _is_volatile(self, recent_rates: list) -> bool:
        """
        Detect volatile/oscillating cooperation patterns.
        Volatile if standard deviation is high relative to mean.
        """
        if len(recent_rates) < 3:
            return False
        std_dev = float(np.std(recent_rates))
        mean_rate = float(np.mean(recent_rates))
        if mean_rate > 0 and std_dev / mean_rate > 0.3:
            return True
        if len(recent_rates) >= 3:
            diff1 = recent_rates[1] - recent_rates[0]
            diff2 = recent_rates[2] - recent_rates[1]
            if diff1 * diff2 < 0:
                return True
        return False

class Strategy_COLLECTIVE_328(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare optimization with defense against exploitation.
    Uses cooperation rate tracking with dynamic threshold adjustment to determine
    whether to cooperate or defect, while always defecting in the final round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = 0.5
        self.last_round_exploited = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == r - 1:
            return Action.D
        all_actions = history.opponent_actions
        my_actions = history.my_actions
        total_cooperators = np.sum(all_actions)
        total_actions = current_round * n
        cooperation_rate = total_cooperators / total_actions if total_actions > 0 else 0.0
        if current_round >= 3:
            recent_actions = all_actions[max(0, current_round - 3):current_round, :]
            recent_cooperators = np.sum(recent_actions)
            recent_cooperation_rate = recent_cooperators / (min(3, current_round) * n)
            historic_cooperation_rate = cooperation_rate
            trend = recent_cooperation_rate - historic_cooperation_rate
            self.threshold += trend * 0.1
            self.threshold = max(0.3, min(0.7, self.threshold))
        rounds_remaining = r - current_round
        if rounds_remaining <= 2:
            adjusted_threshold = self.threshold - 0.1
        else:
            adjusted_threshold = self.threshold
        if current_round > 0:
            my_last_action = my_actions[current_round - 1]
            others_last_actions = all_actions[current_round - 1, :]
            others_cooperated = np.sum(others_last_actions) > 0
            if not my_last_action and others_cooperated:
                if random.random() < 0.9:
                    return Action.D
        if cooperation_rate >= adjusted_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_329(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy

    Balances collective welfare maximization with individual security through
    conditional cooperation based on observed reciprocity. Uses dynamic thresholds
    that tighten over time to prevent exploitation while promoting cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        prev_round_opponent_actions = history.opponent_actions[round_number - 1, :]
        cooperation_count = int(np.sum(prev_round_opponent_actions))
        cooperation_rate = cooperation_count / self.n_players
        threshold = 0.5 + 0.1 * (self.n_rounds - (round_number + 1)) / self.n_rounds
        if round_number == self.n_rounds - 1:
            if cooperation_rate >= 0.5:
                self.consecutive_defections = 0
                return Action.C
            else:
                self.consecutive_defections += 1
                return Action.D
        recovery_threshold = 0.4 if self.consecutive_defections >= 2 else threshold
        if cooperation_rate >= recovery_threshold:
            self.consecutive_defections = 0
            return Action.C
        else:
            self.consecutive_defections += 1
            return Action.D

class Strategy_COLLECTIVE_330(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances cooperative intent with pragmatic reciprocity:
    - Round 1: Always cooperate to signal intent
    - Last round (r > 2): Always defect (no future consequences)
    - Other rounds: Cooperate if observed cooperation rate meets adaptive threshold
    - Threshold decreases over time, allowing graceful degradation in hostile populations
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1 and self.r > 2:
            return Action.D
        prev_round_idx = current_round - 1
        opponents_cooperated = sum(history.opponent_actions[prev_round_idx, :])
        own_prev_action = history.my_actions[prev_round_idx]
        total_cooperators = opponents_cooperated + (1 if own_prev_action else 0)
        cooperation_rate = total_cooperators / self.n
        base_threshold = (self.n - 1) / (self.n - self.k)
        decay_factor = -current_round / (4 * self.r)
        cooperation_threshold = max(0.5, min(0.9, base_threshold + decay_factor))
        if cooperation_rate >= cooperation_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_331(BaseStrategy):
    """
    Adaptive Contribution Threshold (ACT) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare by cooperating when the
    cooperation rate justifies it (above threshold), defecting when it doesn't, with
    hysteresis to prevent oscillation and special handling for edge cases.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.punishment_mode = False
        self.last_action = Action.C
        self.opponent_ever_defected = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            self.last_action = Action.C
            return Action.C
        if n == 2:
            if self.opponent_ever_defected:
                self.last_action = Action.D
                return Action.D
            else:
                if not history.opponent_actions[-1, 0]:
                    self.opponent_ever_defected = True
                    self.last_action = Action.D
                    return Action.D
                self.last_action = Action.C
                return Action.C
        cooperators_last_round = np.sum(history.opponent_actions[-1, :])
        coop_rate = cooperators_last_round / n
        threshold = k / n
        upper_threshold = threshold + 0.1
        lower_threshold = threshold - 0.1
        escape_threshold = threshold / 2.0
        action = self.last_action
        if coop_rate >= upper_threshold:
            action = Action.C
            self.punishment_mode = False
        elif coop_rate <= lower_threshold:
            if coop_rate < escape_threshold:
                self.punishment_mode = True
            action = Action.D
        else:
            action = self.last_action
        if self.punishment_mode and coop_rate > 0.5:
            self.punishment_mode = False
            if coop_rate >= upper_threshold:
                action = Action.C
            elif coop_rate <= lower_threshold:
                action = Action.D
            else:
                action = self.last_action
        self.last_action = action
        return action

class Strategy_COLLECTIVE_332(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare through cooperation with protection against exploitation.
    Uses adaptive thresholds based on observed cooperation rates to decide whether to
    cooperate, defect, or probabilistically reciprocate.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        coop_rate = self._calculate_cooperation_rate(history, current_round)
        threshold = self.k / self.n
        threshold = self._adjust_threshold_for_group_size(threshold)
        if current_round == self.r - 1:
            return self._last_round_decision(coop_rate, threshold)
        return self._adaptive_decision(coop_rate, threshold, current_round)

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """Calculate the overall cooperation rate from previous rounds."""
        if current_round == 0:
            return 0.5
        my_cooperations = np.sum(history.my_actions[:current_round])
        opponent_cooperations = np.sum(history.opponent_actions[:current_round, :])
        total_cooperators = my_cooperations + opponent_cooperations
        total_slots = self.n * current_round
        coop_rate = total_cooperators / total_slots if total_slots > 0 else 0.5
        return coop_rate

    def _adjust_threshold_for_group_size(self, threshold: float) -> float:
        """Adjust threshold based on number of players."""
        if self.n <= 3:
            return threshold - 0.1
        elif self.n >= 10:
            return threshold + 0.05
        return threshold

    def _last_round_decision(self, coop_rate: float, threshold: float) -> Action:
        """Decision logic for the last round (legacy cooperation principle)."""
        if coop_rate >= threshold + 0.1:
            return Action.C
        else:
            return Action.D

    def _adaptive_decision(self, coop_rate: float, threshold: float, current_round: int) -> Action:
        """Decision logic for adaptive phase (rounds 1 to r-2)."""
        if coop_rate >= threshold + 0.15:
            return Action.C
        elif threshold - 0.05 <= coop_rate < threshold + 0.15:
            p_adapt = max(0.3, coop_rate)
            if random.random() < p_adapt:
                return Action.C
            else:
                return Action.D
        elif 0.2 <= coop_rate < threshold - 0.05:
            if random.random() < 0.15:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_333(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization, individual rationality, and robustness
    by using a threshold-based reciprocal cooperation mechanism that responds to
    group cooperation rates while maintaining protection against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.defection_streak_start = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        coop_count_prev = int(np.sum(history.opponent_actions[round_num - 1, :]))
        coop_rate_prev = coop_count_prev / self.n
        threshold = (self.k - 1) / self.n
        threshold = max(threshold, 0.2)
        if round_num > 1:
            coop_count_t2 = int(np.sum(history.opponent_actions[round_num - 2, :]))
            coop_rate_t2 = coop_count_t2 / self.n
            trend = coop_rate_prev - coop_rate_t2
            if trend > 0:
                threshold *= 0.9
            elif trend < 0:
                threshold *= 1.1
        if round_num == 1 and coop_rate_prev == 0:
            self.defection_streak_start = 1
            return Action.D
        if self.defection_streak_start is not None:
            if round_num < self.r - 1:
                return Action.D
            else:
                self.defection_streak_start = None
        if round_num >= 2:
            my_prev_action = history.my_actions[round_num - 1]
            my_prev_prev_action = history.my_actions[round_num - 2]
            if my_prev_action == my_prev_prev_action:
                if my_prev_action:
                    return Action.C
                else:
                    return Action.D
        if coop_rate_prev >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_334(BaseStrategy):
    """
    Adaptive Reciprocal Maximization (ARM): A threshold-based, history-dependent strategy
    that balances collective welfare, individual rationality, and robustness.

    Core behavior:
    - Round 0: Always cooperate (bootstrap cooperation)
    - Final round: Always defect (subgame perfect)
    - Middle rounds: Cooperate based on observed cooperation rates and payoff thresholds
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.n_rounds - 1:
            return Action.D
        return self._decide_middle_round(round_num, history)

    def _decide_middle_round(self, round_num: int, history: PlayerHistory) -> Action:
        """
        Decision logic for rounds 1 to r-2.

        Returns Action.C or Action.D based on:
        - Cooperation rate in last round
        - Average cooperation over all observed rounds
        - Benefit from cooperation relative to thresholds
        - Probability-based reciprocity in marginal cases
        """
        cooperation_last_round = self._get_cooperation_rate(history, -1)
        avg_cooperation_all = self._get_avg_cooperation_rate(history)
        recent_cooperation = self._get_recent_cooperation_rate(history)
        benefit_from_cooperation = self.k / self.n_players * cooperation_last_round
        if benefit_from_cooperation >= 0.6:
            return Action.C
        elif 0.35 <= benefit_from_cooperation < 0.6:
            if recent_cooperation >= 0.3:
                probability_to_coop = benefit_from_cooperation / 0.6
                if random.random() < probability_to_coop:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D
        elif recent_cooperation > avg_cooperation_all:
            if random.random() < 0.3:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _get_cooperation_rate(self, history: PlayerHistory, round_index: int) -> float:
        """
        Get the cooperation rate in a specific round.
        round_index: -1 for last round, -2 for second-to-last, etc.
        Returns float in [0, 1].
        """
        if len(history.opponent_actions) == 0:
            return 0.0
        opponent_coop_count = sum(history.opponent_actions[round_index, :])
        my_action = history.my_actions[round_index]
        total_cooperators = opponent_coop_count + (1 if my_action else 0)
        return total_cooperators / self.n_players

    def _get_avg_cooperation_rate(self, history: PlayerHistory) -> float:
        """
        Get the average cooperation rate across all observed rounds.
        Returns float in [0, 1].
        """
        if len(history.opponent_actions) == 0:
            return 0.0
        total_cooperation = 0.0
        for round_idx in range(len(history.opponent_actions)):
            total_cooperation += self._get_cooperation_rate(history, round_idx)
        return total_cooperation / len(history.opponent_actions)

    def _get_recent_cooperation_rate(self, history: PlayerHistory) -> float:
        """
        Get the average cooperation rate over the last 3 rounds (or fewer if history is shorter).
        Returns float in [0, 1].
        """
        if len(history.opponent_actions) == 0:
            return 0.0
        start_idx = max(0, len(history.opponent_actions) - 3)
        total_cooperation = 0.0
        count = 0
        for round_idx in range(start_idx, len(history.opponent_actions)):
            total_cooperation += self._get_cooperation_rate(history, round_idx)
            count += 1
        return total_cooperation / count if count > 0 else 0.0

class Strategy_COLLECTIVE_335(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare by:
    1. Starting with cooperation (round 1)
    2. Reciprocating based on observed cooperation rate vs. threshold
    3. Punishing low cooperation for up to 2 rounds
    4. Attempting recovery after punishment
    5. Defecting in the final round (subgame perfection)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n_players + 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.n_rounds - 1:
            return Action.D
        cooperation_rate = self._get_cooperation_rate(history, round_num - 1)
        consecutive_low = self._count_consecutive_low_coop_rounds(history, round_num - 1)
        if cooperation_rate >= self.threshold:
            return Action.C
        if cooperation_rate < self.threshold:
            if consecutive_low >= 2:
                return Action.C
            else:
                return Action.D
        return Action.C

    def _get_cooperation_rate(self, history: PlayerHistory, round_idx: int) -> float:
        """
        Calculate the cooperation rate (fraction of cooperators) in a given round.

        Args:
            history: PlayerHistory object containing opponent actions
            round_idx: Index of the round (0-indexed)

        Returns:
            Cooperation rate as a float in [0, 1]
        """
        if round_idx < 0 or round_idx >= history.opponent_actions.shape[0]:
            return 0.0
        cooperators_in_round = int(np.sum(history.opponent_actions[round_idx, :]))
        cooperation_rate = cooperators_in_round / self.n_players
        return cooperation_rate

    def _count_consecutive_low_coop_rounds(self, history: PlayerHistory, current_round_idx: int) -> int:
        """
        Count consecutive rounds ending at current_round_idx where cooperation rate < threshold.

        Args:
            history: PlayerHistory object containing opponent actions
            current_round_idx: Index of the round to check (0-indexed)

        Returns:
            Number of consecutive low-cooperation rounds ending at current_round_idx
        """
        consecutive_count = 0
        for i in range(current_round_idx, -1, -1):
            cooperation_rate = self._get_cooperation_rate(history, i)
            if cooperation_rate < self.threshold:
                consecutive_count += 1
            else:
                break
        return consecutive_count

class Strategy_COLLECTIVE_336(BaseStrategy):
    """
    Adaptive Contribution with Conditional Cooperation.

    Balances collective welfare maximization with robustness against exploitation.
    - Round 1: Cooperate unconditionally to establish cooperative tone
    - Final round: Defect (backward induction)
    - Middle rounds: Conditional cooperation based on observed cooperation rate,
      with probabilistic defection when cooperation is insufficient
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == r - 1:
            return Action.D
        last_round_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        if history.my_actions[current_round - 1]:
            last_round_cooperators += 1
        cooperation_rate = last_round_cooperators / n
        base_threshold = k / n
        time_adjusted_threshold = 0.5 - current_round / r * 0.3
        threshold = max(base_threshold, time_adjusted_threshold)
        if cooperation_rate >= threshold:
            return Action.C
        else:
            defection_penalty = 1.0 - cooperation_rate
            cooperation_probability = 1.0 - defection_penalty ** 2
            if random.random() < cooperation_probability:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_337(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare through conditional
    cooperation based on recent empirical cooperation rates. Features a threshold-based
    decision rule, graceful degradation with probing, and strategic consistency in
    final rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.coop_threshold = (self.k - 1) / (self.n - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            recent_coop_rate = self._calculate_recent_coop_rate(history, current_round)
            if recent_coop_rate >= self.coop_threshold:
                return Action.C
            else:
                return Action.D
        recent_coop_rate = self._calculate_recent_coop_rate(history, current_round)
        if recent_coop_rate >= self.coop_threshold:
            return Action.C
        elif current_round % 3 == 0:
            return Action.C
        else:
            return Action.D

    def _calculate_recent_coop_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate weighted moving average of cooperation rates from recent rounds.
        Uses weights: t-1: 0.5, t-2: 0.3, t-3: 0.2 for stability.
        """
        if current_round == 0:
            return 0.0
        weights = []
        coop_rates = []
        for lag in range(1, min(4, current_round + 1)):
            round_idx = current_round - lag
            if round_idx >= 0:
                cooperators = np.sum(history.opponent_actions[round_idx, :])
                coop_rate = cooperators / self.n
                coop_rates.append(coop_rate)
                if lag == 1:
                    weights.append(0.5)
                elif lag == 2:
                    weights.append(0.3)
                elif lag == 3:
                    weights.append(0.2)
        if len(weights) == 0:
            return 0.0
        total_weight = sum(weights)
        normalized_weights = [w / total_weight for w in weights]
        weighted_coop_rate = sum((rate * weight for rate, weight in zip(coop_rates, normalized_weights)))
        return weighted_coop_rate

class Strategy_COLLECTIVE_338(BaseStrategy):
    """
    Adaptive Threshold Cooperation with Decay (ATCD)

    A collective strategy that adapts cooperation decisions based on observed
    cooperation ratios in the population. It bootstraps cooperation in early rounds,
    adaptively maintains cooperation based on group behavior, and commits to cooperation
    in the endgame if the group has demonstrated sufficient cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round <= 1:
            return Action.C
        prev_round_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        if history.my_actions[current_round - 1]:
            prev_round_cooperators += 1
        cooperation_ratio = prev_round_cooperators / self.n
        all_cooperation_ratios = []
        for round_idx in range(current_round):
            round_cooperators = int(sum(history.opponent_actions[round_idx, :]))
            if history.my_actions[round_idx]:
                round_cooperators += 1
            all_cooperation_ratios.append(round_cooperators / self.n)
        if all((ratio == 0 for ratio in all_cooperation_ratios)):
            return Action.D
        if current_round == self.r - 1:
            if cooperation_ratio >= 0.5:
                return Action.C
            else:
                return Action.D
        cooperation_history_avg = np.mean(all_cooperation_ratios)
        rounds_remaining = self.r - current_round
        threshold = 0.4 + 0.3 * cooperation_history_avg - 0.1 * math.log(rounds_remaining + 1)
        if self.n == 2:
            threshold += 0.15
        elif self.n == 3:
            threshold -= 0.05
        elif self.n >= 20:
            threshold += 0.05
        threshold = max(0.35, min(0.65, threshold))
        if cooperation_ratio >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_339(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances individual security, collective benefit, and robustness through three phases:
    1. Early Game: Test cooperation with threshold = max(0.5, k/n)
    2. Mid Game: Lower threshold to k/n with rolling window
    3. End Game: Defect in final round, maintain reciprocity otherwise
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        early_phase_end = math.floor(self.n_rounds / 3)
        mid_phase_end = math.floor(2 * self.n_rounds / 3)
        cooperation_rate = self._get_cooperation_rate(history, current_round)
        if current_round <= early_phase_end:
            threshold = max(0.5, self.k / self.n_players)
            if cooperation_rate >= threshold:
                return Action.C
            else:
                return Action.D
        elif current_round >= mid_phase_end:
            if current_round == self.n_rounds - 1:
                return Action.D
            else:
                threshold = self.k / self.n_players
                if cooperation_rate >= threshold:
                    return Action.C
                else:
                    return Action.D
        else:
            threshold = self.k / self.n_players
            if cooperation_rate >= threshold:
                return Action.C
            else:
                return Action.D

    def _get_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Compute cooperation rate using rolling window for mid/end game,
        cumulative for early game.
        """
        early_phase_end = math.floor(self.n_rounds / 3)
        mid_phase_end = math.floor(2 * self.n_rounds / 3)
        if current_round <= early_phase_end:
            window_size = current_round
            start_idx = 0
        else:
            window_size = min(5, current_round)
            start_idx = current_round - window_size
        if window_size == 0:
            return 0.0
        opponent_actions_window = history.opponent_actions[start_idx:current_round, :]
        total_cooperations = np.sum(opponent_actions_window)
        total_possible = window_size * self.n_players
        cooperation_rate = total_cooperations / total_possible if total_possible > 0 else 0.0
        return cooperation_rate

class Strategy_COLLECTIVE_340(BaseStrategy):
    """
    Adaptive Reciprocal Contribution with Efficiency Threshold Strategy.

    Balances collective welfare with self-protection through three phases:
    1. Exploration: Cooperate to establish baseline and signal willingness
    2. Adaptation: Respond to observed cooperation levels with conditional strategies
    3. Optimization: Stabilize on proven patterns based on collective efficiency
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.phase1_end = math.floor(self.n_rounds / 3)
        self.phase2_end = math.floor(2 * self.n_rounds / 3)
        self.phase1_cooperator_counts = []
        self.efficiency_history = []

    def _get_phase(self, round_number: int) -> int:
        """Determine which phase we're in (1, 2, or 3)"""
        if round_number < self.phase1_end:
            return 1
        elif round_number < self.phase2_end:
            return 2
        else:
            return 3

    def _calculate_avg_cooperators_phase1(self, history: PlayerHistory) -> float:
        """Calculate average number of cooperators in Phase 1"""
        if len(self.phase1_cooperator_counts) == 0:
            return 0
        return np.mean(self.phase1_cooperator_counts)

    def _calculate_recent_cooperation_trend(self, history: PlayerHistory, current_round: int, window: int=5) -> float:
        """Calculate cooperation rate in the previous window of rounds"""
        if current_round == 0:
            return 0
        start_idx = max(0, current_round - window)
        end_idx = current_round
        recent_rounds = history.opponent_actions[start_idx:end_idx, :]
        if recent_rounds.shape[0] == 0:
            return 0
        total_cooperations = np.sum(recent_rounds)
        total_actions = recent_rounds.shape[0] * recent_rounds.shape[1]
        return total_cooperations / total_actions if total_actions > 0 else 0

    def _calculate_collective_efficiency(self, history: PlayerHistory) -> float:
        """Calculate average payoff across all players in history"""
        if len(self.efficiency_history) == 0:
            return 0
        return np.mean(self.efficiency_history)

    def _record_round_statistics(self, history: PlayerHistory, round_number: int):
        """Record statistics after each round"""
        current_round_opponent_actions = history.opponent_actions[round_number, :]
        cooperators_this_round = np.sum(current_round_opponent_actions)
        if history.my_actions[round_number]:
            cooperators_this_round += 1
        if round_number < self.phase1_end:
            self.phase1_cooperator_counts.append(cooperators_this_round)
        all_my_payoff = history.my_payoffs[round_number]
        avg_opponent_payoff = np.mean(history.opponent_payoffs[round_number, :]) if history.opponent_payoffs.shape[1] > 0 else 0
        avg_all = (all_my_payoff + avg_opponent_payoff * (self.n_players - 1)) / self.n_players
        self.efficiency_history.append(avg_all)

    def _get_median_efficiency(self) -> float:
        """Get median efficiency from history"""
        if len(self.efficiency_history) == 0:
            return 0
        return float(np.median(self.efficiency_history))

    def _detect_sudden_collapse(self, history: PlayerHistory, current_round: int) -> bool:
        """Detect if cooperation suddenly collapsed"""
        if current_round < 2:
            return False
        prev_round_coop = np.sum(history.opponent_actions[current_round - 1, :]) / self.n_players
        if prev_round_coop == 0:
            return False
        curr_round_coop = np.sum(history.opponent_actions[current_round, :]) / self.n_players
        return curr_round_coop < 0.3 * prev_round_coop

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        """Determine action for current round"""
        round_number = state.round_number
        if round_number < self.phase1_end:
            if history is not None:
                self._record_round_statistics(history, round_number - 1)
            return Action.C
        if history is not None:
            self._record_round_statistics(history, round_number - 1)
        if round_number < self.phase2_end:
            observed_avg_cooperators = self._calculate_avg_cooperators_phase1(history)
            recent_trend = self._calculate_recent_cooperation_trend(history, round_number, window=5)
            threshold_high = self.k + 1
            threshold_medium = self.k * 0.6
            if observed_avg_cooperators >= threshold_high:
                return Action.C
            elif observed_avg_cooperators >= threshold_medium:
                if recent_trend > 0.5:
                    return Action.C
                else:
                    return Action.D
            else:
                phase1_rate = self._calculate_avg_cooperators_phase1(history) / self.n_players if len(self.phase1_cooperator_counts) > 0 else 0
                if recent_trend >= phase1_rate:
                    return Action.C
                else:
                    return Action.D
        efficiency_score = self._calculate_collective_efficiency(history)
        median_efficiency = self._get_median_efficiency()
        if self._detect_sudden_collapse(history, round_number - 1):
            return Action.D
        if efficiency_score > median_efficiency:
            if round_number == self.n_rounds - 1:
                recent_trend = self._calculate_recent_cooperation_trend(history, round_number, window=3)
                if recent_trend > 0.5:
                    return Action.C
                else:
                    return Action.D
            return Action.C
        else:
            if round_number == self.n_rounds - 1:
                recent_trend = self._calculate_recent_cooperation_trend(history, round_number, window=3)
                if recent_trend > 0.6:
                    return Action.C
            return Action.D

class Strategy_COLLECTIVE_341(BaseStrategy):
    """
    Adaptive Contribution with Reputation-Weighted Cooperation.

    Balances collective welfare maximization with personal sustainability by:
    1. Starting with cooperation to signal good faith
    2. Adapting mid-game based on observed cooperation rate
    3. Making final-round decisions based on accumulated cooperation history
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        rho = self._calculate_cooperation_rate(history, round_t)
        if round_t == self.r - 1:
            if rho >= 0.4:
                return Action.C
            else:
                return Action.D
        return self._decide_middle_game(rho)

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_t: int) -> float:
        """
        Calculate the observed cooperation rate from rounds 0 to round_t-1.
        (t) = (total cooperators across all players in rounds 0 to t-1) / (n  t)
        """
        if round_t <= 0:
            return 0.0
        my_cooperations = np.sum(history.my_actions[:round_t])
        opponent_cooperations = np.sum(history.opponent_actions[:round_t, :])
        total_cooperations = my_cooperations + opponent_cooperations
        total_actions = self.n * round_t
        rho = total_cooperations / total_actions if total_actions > 0 else 0.0
        return rho

    def _decide_middle_game(self, rho: float) -> Action:
        """
        Apply adaptive reciprocity decision rule for middle game rounds.
        """
        threshold = (self.k - 1) / (self.n - 1)
        threshold = max(threshold, 0.3)
        threshold = min(threshold, 0.7)
        if rho >= threshold:
            return Action.C
        elif rho >= 0.5:
            return Action.C if random.random() < 0.6 else Action.D
        elif rho >= 0.25:
            return Action.C if random.random() < 0.25 else Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_342(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances optimism, vigilant accountability, and long-term wealth creation through
    phase-based decision rules that adapt to observed cooperation rates.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.establishment_end = math.ceil(self.n_rounds / 3)
        self.sustainability_end = math.floor(2 * self.n_rounds / 3)

    def _classify_phase(self, round_number: int) -> str:
        """Classify current round into phase: ESTABLISHMENT, SUSTAINABILITY, or HARVEST."""
        if round_number < self.establishment_end:
            return 'ESTABLISHMENT'
        elif round_number < self.sustainability_end:
            return 'SUSTAINABILITY'
        else:
            return 'HARVEST'

    def _get_recent_cooperation_rate(self, history: PlayerHistory, round_number: int) -> float:
        """Calculate average cooperation rate over last 3 rounds (or fewer if unavailable)."""
        if round_number == 0:
            return 0.0
        lookback = min(3, round_number)
        recent_rounds = history.opponent_actions[round_number - lookback:round_number, :]
        if recent_rounds.size == 0:
            return 0.0
        total_cooperators = np.sum(recent_rounds)
        total_actions = recent_rounds.size
        return float(total_cooperators) / float(total_actions)

    def _get_last_round_cooperation_rate(self, history: PlayerHistory, round_number: int) -> float:
        """Get cooperation rate from the immediately previous round."""
        if round_number == 0:
            return 0.0
        cooperators = np.sum(history.opponent_actions[round_number - 1, :])
        return float(cooperators) / float(self.n_players)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        phase = self._classify_phase(round_number)
        if phase == 'ESTABLISHMENT':
            return self._establishment_phase_decision(history, round_number)
        elif phase == 'SUSTAINABILITY':
            return self._sustainability_phase_decision(history, round_number)
        else:
            return self._harvest_phase_decision(history, round_number)

    def _establishment_phase_decision(self, history: PlayerHistory, round_number: int) -> Action:
        """
        Establishment Phase (rounds 1 to r/3): Build cooperative norms.

        Cooperate if recent cooperation  50%, else cooperate with declining probability.
        """
        last_coop_rate = self._get_last_round_cooperation_rate(history, round_number)
        if last_coop_rate >= 0.5:
            return Action.C
        elif last_coop_rate < 0.5 and round_number < self.establishment_end:
            decay_factor = float(self.establishment_end - round_number) / float(self.establishment_end)
            if random.random() < decay_factor:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _sustainability_phase_decision(self, history: PlayerHistory, round_number: int) -> Action:
        """
        Sustainability Phase (rounds r/3+1 to 2r/3): Maintain and optimize.

        Use conditional reciprocity based on recent cooperation ratio.
        """
        recent_coop_ratio = self._get_recent_cooperation_rate(history, round_number)
        if recent_coop_ratio >= 0.6:
            return Action.C
        elif recent_coop_ratio >= 0.4:
            if random.random() < recent_coop_ratio:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _harvest_phase_decision(self, history: PlayerHistory, round_number: int) -> Action:
        """
        Harvest Phase (rounds 2r/3+1 to r): Strategic endgame.

        Raise cooperation thresholds slightly due to limited remaining rounds.
        """
        rounds_remaining = self.n_rounds - round_number
        recent_coop_ratio = self._get_recent_cooperation_rate(history, round_number)
        if rounds_remaining <= 2:
            if recent_coop_ratio >= 0.5:
                return Action.C
            else:
                return Action.D
        elif recent_coop_ratio >= 0.55:
            return Action.C
        elif recent_coop_ratio >= 0.35:
            if random.random() < recent_coop_ratio:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_343(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game

    Balances individual rationality with collective welfare through threshold-based
    reciprocal cooperation. Initiates cooperation, monitors reciprocal commitment,
    adapts to environmental conditions, and escalates expectations as game progresses.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        cooperators_history = np.sum(history.opponent_actions, axis=1)
        prev_coop_count = cooperators_history[-1]
        prev_coop_rate = prev_coop_count / self.n_players
        coop_rate = prev_coop_rate
        if current_round >= 2:
            prev_prev_coop_count = cooperators_history[-2]
            prev_prev_coop_rate = prev_prev_coop_count / self.n_players
            coop_rate = (prev_coop_rate + prev_prev_coop_rate) / 2.0
        threshold = max(0.3, 1.0 - current_round / (2.0 * self.n_rounds))
        if current_round <= 2 and prev_coop_rate < 0.4:
            threshold = 0.35
        if current_round >= 2:
            recent_coop_rates = [cooperators_history[-1] / self.n_players]
            if current_round >= 1:
                recent_coop_rates.append(cooperators_history[-2] / self.n_players)
            avg_recent = np.mean(recent_coop_rates)
            if avg_recent < 0.3:
                return Action.D
        if prev_coop_rate >= 1.0:
            return Action.C
        if coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_344(BaseStrategy):
    """
    Adaptive Graduated Reciprocity with Collective Threshold (AGRC)

    Balances collective welfare maximization, individual rationality, and adaptive learning.
    - Round 1: Cooperate as initial probe
    - Rounds 2 to r-1: Adapt threshold based on cooperation rate
    - Final round: End-game logic with 0.4 threshold
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.consecutive_all_defect_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        previous_round_idx = round_number - 1
        cooperators_previous = int(np.sum(history.opponent_actions[previous_round_idx, :]))
        cooperation_rate = cooperators_previous / self.n_players
        if cooperation_rate == 0:
            self.consecutive_all_defect_rounds += 1
            if self.consecutive_all_defect_rounds >= 2:
                return Action.D
        else:
            self.consecutive_all_defect_rounds = 0
        if cooperation_rate == 1:
            return Action.C
        if self.k < 1.5:
            threshold = max(0.5, 1 - round_number / self.n_rounds * 0.3 + 0.1 * (1 - self.k))
        elif self.k > self.n_players - 1:
            threshold = max(0.5, 1 - round_number / self.n_rounds * 0.3 - 0.05 * (self.k / self.n_players))
        else:
            threshold = max(0.5, 1 - round_number / self.n_rounds * 0.3)
        if round_number == self.n_rounds - 1:
            if cooperation_rate >= 0.4:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_345(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with individual security through adaptive
    contribution levels based on observed collective efficiency and cooperation rates.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        ce = self._calculate_collective_efficiency(history, current_round)
        recent_ce = self._calculate_recent_collective_efficiency(history, current_round)
        coop_rate = self._calculate_coop_rate(history, current_round)
        if current_round == self.r - 1:
            if coop_rate > 0.9 and recent_ce > 0.7:
                return Action.C
            else:
                return Action.D
        if recent_ce >= 0.8:
            return Action.C
        elif recent_ce >= 0.5:
            if random.random() < recent_ce:
                return Action.C
            else:
                return Action.D
        else:
            defection_threshold = 1.0 / (2.0 * self.k)
            my_last_action = history.my_actions[current_round - 1]
            if coop_rate < defection_threshold and my_last_action:
                return Action.D
            else:
                return Action.D

    def _calculate_collective_efficiency(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate collective efficiency from the previous round.
        CE = Average_Round_Payoff / Max_Possible_Payoff
        Max_Possible_Payoff = 2k/n
        """
        if current_round == 0:
            return 0.0
        prev_round_idx = current_round - 1
        my_payoff = history.my_payoffs[prev_round_idx]
        opponent_payoffs = history.opponent_payoffs[prev_round_idx, :]
        all_payoffs = np.concatenate([[my_payoff], opponent_payoffs])
        avg_payoff = np.mean(all_payoffs)
        max_possible = 2.0 * self.k / self.n
        if max_possible == 0:
            return 0.0
        ce = avg_payoff / max_possible
        return float(max(0.0, min(1.0, ce)))

    def _calculate_recent_collective_efficiency(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate weighted average of collective efficiency over last 3 rounds.
        Weights: [1, 1.5, 2] for older to more recent.
        """
        if current_round == 0:
            return 0.0
        recent_rounds = min(3, current_round)
        ce_values = []
        for i in range(recent_rounds):
            round_idx = current_round - recent_rounds + i
            ce = self._calculate_collective_efficiency_at_round(history, round_idx)
            ce_values.append(ce)
        weights = [1.0, 1.5, 2.0]
        weights = weights[-recent_rounds:]
        weighted_sum = sum((w * ce for w, ce in zip(weights, ce_values)))
        weight_total = sum(weights)
        if weight_total == 0:
            return 0.0
        return weighted_sum / weight_total

    def _calculate_collective_efficiency_at_round(self, history: PlayerHistory, round_idx: int) -> float:
        """
        Calculate collective efficiency for a specific round index.
        """
        if round_idx < 0:
            return 0.0
        my_payoff = history.my_payoffs[round_idx]
        opponent_payoffs = history.opponent_payoffs[round_idx, :]
        all_payoffs = np.concatenate([[my_payoff], opponent_payoffs])
        avg_payoff = np.mean(all_payoffs)
        max_possible = 2.0 * self.k / self.n
        if max_possible == 0:
            return 0.0
        ce = avg_payoff / max_possible
        return float(max(0.0, min(1.0, ce)))

    def _calculate_coop_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate cooperation rate in the previous round.
        Returns fraction of players (including self) who cooperated.
        """
        if current_round == 0:
            return 0.0
        prev_round_idx = current_round - 1
        my_action = history.my_actions[prev_round_idx]
        opponent_actions = history.opponent_actions[prev_round_idx, :]
        total_cooperators = int(my_action) + int(np.sum(opponent_actions))
        total_players = 1 + len(opponent_actions)
        return float(total_cooperators) / float(total_players)

class Strategy_COLLECTIVE_346(BaseStrategy):
    """
    Adaptive Reciprocity with Efficiency Threshold strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare by:
    1. Cooperating when collective benefit exceeds individual loss (efficiency threshold)
    2. Punishing free-riders when cooperation rate falls below 20%
    3. Defecting in final round (unless >80% sustained cooperation observed)
    4. Using conditional cooperation based on expected cooperator count
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.efficiency_threshold = self.n_players / (2 * self.k)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.n_rounds - 1:
            if round_num > 0:
                all_cooperation_rates = self._calculate_cooperation_rates(history)
                recent_rates = all_cooperation_rates[:round_num]
                if len(recent_rates) > 0 and np.mean(recent_rates) > 0.8:
                    return Action.C
            return Action.D
        current_round_idx = round_num
        observed_cooperation_rate = self._get_recent_cooperation_rate(history, current_round_idx)
        observed_cooperators = observed_cooperation_rate * self.n_players
        expected_cooperators = self._calculate_expected_cooperators(history, current_round_idx)
        if observed_cooperation_rate < 0.2 and history.my_actions[current_round_idx - 1]:
            return Action.D
        if expected_cooperators >= self.efficiency_threshold:
            return Action.C
        else:
            return Action.D

    def _get_recent_cooperation_rate(self, history: PlayerHistory, current_round_idx: int) -> float:
        """Get cooperation rate from the most recent completed round."""
        if current_round_idx == 0:
            return 0.5
        last_round_idx = current_round_idx - 1
        cooperators_last_round = np.sum(history.opponent_actions[last_round_idx, :])
        if history.my_actions[last_round_idx]:
            cooperators_last_round += 1
        return cooperators_last_round / self.n_players

    def _calculate_cooperation_rates(self, history: PlayerHistory) -> NDArray[np.float64]:
        """Calculate cooperation rate for each round in history."""
        rates = []
        n_completed_rounds = len(history.my_actions)
        for round_idx in range(n_completed_rounds):
            cooperators = np.sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            rate = cooperators / self.n_players
            rates.append(rate)
        return np.array(rates)

    def _calculate_expected_cooperators(self, history: PlayerHistory, current_round_idx: int) -> float:
        """
        Calculate expected number of cooperators for next round.

        Uses observed cooperation rate and classifies opponents:
        - Unconditional cooperators (always C)
        - Unconditional defectors (always D)
        - Conditional/adaptive players (mixed)
        """
        if current_round_idx == 0:
            return self.n_players * 0.5
        last_round_idx = current_round_idx - 1
        opponent_coop_counts = np.sum(history.opponent_actions[:current_round_idx, :], axis=0)
        rounds_played = current_round_idx
        expected_cooperators = 0.0
        for opponent_idx in range(self.n_players - 1):
            coop_count = opponent_coop_counts[opponent_idx]
            if coop_count == rounds_played:
                expected_cooperators += 1.0
            elif coop_count == 0:
                expected_cooperators += 0.0
            else:
                cooperation_ratio = coop_count / rounds_played
                expected_cooperators += cooperation_ratio
        my_coop_count = np.sum(history.my_actions[:current_round_idx])
        my_coop_ratio = my_coop_count / rounds_played
        expected_cooperators += my_coop_ratio
        return expected_cooperators

class Strategy_COLLECTIVE_347(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game

    Balances cooperation incentives, exploitation resistance, and collective welfare.
    Uses three phases:
    - Phase 1 (Early): Unconditional cooperation to signal good faith
    - Phase 2 (Middle): Adaptive reciprocation based on observed cooperation rate
    - Phase 3 (End): Strategic defection with reduced probabilistic cooperation
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.cooperation_threshold = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        total_actions = history.my_actions.shape[0]
        my_cooperations = np.sum(history.my_actions)
        opponent_cooperations = np.sum(history.opponent_actions)
        total_cooperations = my_cooperations + opponent_cooperations
        total_possible = total_actions * self.n
        observed_cooperation_rate = total_cooperations / total_possible
        phase1_end = math.floor(self.r / 3)
        phase2_end = math.floor(2 * self.r / 3)
        if round_num <= phase1_end:
            return Action.C
        elif round_num > phase2_end:
            rounds_remaining = self.r - round_num
            if rounds_remaining <= 2:
                return Action.D
            elif rounds_remaining <= 5:
                cooperation_probability = observed_cooperation_rate / 2
                if random.random() < cooperation_probability:
                    return Action.C
                else:
                    return Action.D
            elif observed_cooperation_rate >= self.cooperation_threshold:
                return Action.C
            else:
                return Action.D
        elif observed_cooperation_rate >= self.cooperation_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_348(BaseStrategy):
    """
    Adaptive Reciprocal Contribution with Threshold Decay strategy for N-Player Public Goods Game.

    This strategy maximizes collective welfare while remaining robust against exploitation through:
    - Unconditional cooperation in round 1 to establish cooperative intent
    - Threshold-based reciprocation based on observed cooperation rate
    - Forgiveness mechanism that increases as the game approaches its end
    - Punishment of free-riders when cooperation falls below thresholds
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        cooperators_last_round = sum(history.opponent_actions[-1, :])
        coop_rate = cooperators_last_round / self.n
        threshold = self.k / self.n
        if coop_rate >= threshold:
            return Action.C
        rounds_left = self.r - current_round
        forgiveness_factor = rounds_left / self.r
        forgive_threshold = (1 - forgiveness_factor) * threshold
        if coop_rate >= forgive_threshold:
            return Action.C
        return Action.D

class Strategy_COLLECTIVE_349(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare through dynamic cooperation
    estimation and conditional reciprocity. Cooperates in early rounds to build trust,
    adapts based on observed cooperation rates, and defects strategically in the final
    round and against exploitative populations.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold_high = 0.65
        self.threshold_low = 0.35
        self.threshold_final = 0.8
        self.adaptation_threshold = 0.3
        self.smoothing_window = 3

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """Calculate weighted cooperation rate from observable history."""
        if current_round == 0:
            return 0.5
        opponent_actions = history.opponent_actions
        num_rounds_observed = min(current_round, len(opponent_actions))
        if num_rounds_observed == 0:
            return 0.5
        if num_rounds_observed >= self.smoothing_window:
            recent_rounds = opponent_actions[-self.smoothing_window:, :]
            recent_cooperators = np.sum(recent_rounds)
            recent_denominator = self.smoothing_window * self.n_players
            cre_recent = recent_cooperators / recent_denominator if recent_denominator > 0 else 0.5
            older_rounds = opponent_actions[:-self.smoothing_window, :]
            older_cooperators = np.sum(older_rounds)
            older_denominator = (num_rounds_observed - self.smoothing_window) * self.n_players
            cre_older = older_cooperators / older_denominator if older_denominator > 0 else 0.5
            cre = cre_recent * 0.6 + cre_older * 0.4
        else:
            total_cooperators = np.sum(opponent_actions[:num_rounds_observed, :])
            total_denominator = num_rounds_observed * self.n_players
            cre = total_cooperators / total_denominator if total_denominator > 0 else 0.5
        return cre

    def _get_last_round_cooperation_ratio(self, history: PlayerHistory) -> float:
        """Get the cooperation ratio in the most recent round."""
        if len(history.opponent_actions) == 0:
            return 0.0
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        return last_round_cooperators / self.n_players

    def _detect_sudden_shift(self, history: PlayerHistory, current_round: int, cre_current: float) -> bool:
        """Detect if cooperation rate dropped significantly in the last round."""
        if current_round < 4:
            return False
        recent_rounds = history.opponent_actions[-(self.smoothing_window + 1):, :]
        last_round_coop = np.sum(recent_rounds[-1, :]) / self.n_players
        older_rounds_coop = np.sum(recent_rounds[:-1, :]) / (self.smoothing_window * self.n_players)
        shift = older_rounds_coop - last_round_coop
        return shift > self.adaptation_threshold

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            cre = self._calculate_cooperation_rate(history, current_round)
            if cre >= self.threshold_final:
                return Action.C
            else:
                return Action.D
        cre = self._calculate_cooperation_rate(history, current_round)
        if cre >= self.threshold_high:
            return Action.C
        if cre <= self.threshold_low:
            if cre == 0.0 and np.any(history.opponent_actions[-1, :]):
                return Action.C
            return Action.D
        last_coop_ratio = self._get_last_round_cooperation_ratio(history)
        threshold_ratio = self.k / self.n_players
        if self._detect_sudden_shift(history, current_round, cre):
            return Action.C
        if last_coop_ratio >= threshold_ratio:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_350(BaseStrategy):
    """
    Adaptive Threshold Cooperation with Defection Resistance.

    Balances collective welfare maximization, individual resilience against exploitation,
    and adaptive learning. Uses cooperation health metric to decide whether to cooperate,
    with graceful degradation and end-game adjustments.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        c_current = np.sum(history.opponent_actions[current_round - 1]) / self.n
        if current_round <= 2:
            if c_current >= 0.5:
                return Action.C
            else:
                return Action.D
        c_prev = np.sum(history.opponent_actions[current_round - 2]) / self.n if current_round > 1 else 0.5
        if abs(c_current - c_prev) > 0.3:
            cooperation_health = 0.5 * c_current + 0.5 * c_prev
        else:
            cooperation_health = 0.7 * c_current + 0.3 * c_prev
        if self.n > 20:
            cooperation_health = 0.8 * c_current + 0.2 * c_prev
        base_threshold = self.k / self.n
        if base_threshold < 0.4:
            threshold = 0.4
        elif base_threshold > 0.8:
            threshold = max(0.3, base_threshold - 0.2)
        else:
            threshold = base_threshold
        if current_round >= self.r - 2:
            if current_round == self.r - 1:
                if c_current >= 0.5:
                    return Action.C
                else:
                    return Action.D
            elif cooperation_health >= 0.5:
                return Action.C
            else:
                return Action.D
        if cooperation_health >= threshold:
            return Action.C
        elif cooperation_health >= 0.4:
            prob = 2.0 * cooperation_health
            if random.random() < prob:
                return Action.C
            else:
                return Action.D
        else:
            if cooperation_health == 0.0 and current_round > 3:
                if random.random() < 0.1:
                    return Action.C
            return Action.D

class Strategy_COLLECTIVE_351(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game.

    Balances collective welfare with defense against exploitation by:
    - Cooperating optimistically in round 1
    - Using adaptive thresholds based on observed cooperation rates
    - Maintaining probabilistic cooperation during uncertain transitions
    - Withdrawing when collective cooperation cannot sustain positive returns
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.collective_threshold = self.k / self.n_players
        self.secondary_threshold = self.collective_threshold * 0.6

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperation_rate = self._calculate_cooperation_rate(history, state.round_number)
        if cooperation_rate >= self.collective_threshold:
            return Action.C
        elif cooperation_rate >= self.secondary_threshold:
            probability = cooperation_rate / self.collective_threshold
            return Action.C if random.random() < probability else Action.D
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_number: int) -> float:
        """
        Calculate weighted cooperation rate combining recent and historical data.

        Uses 70% recent, 30% historical weighting to respond to changes while
        avoiding overreaction to temporary fluctuations.
        """
        rounds_elapsed = round_number
        total_cooperators = np.sum(history.opponent_actions[:round_number, :])
        historical_cooperation_rate = total_cooperators / (self.n_players * rounds_elapsed)
        window_size = min(5, max(1, self.n_rounds // 2))
        recent_start = max(0, round_number - window_size)
        recent_rounds = round_number - recent_start
        if recent_rounds > 0:
            recent_cooperators = np.sum(history.opponent_actions[recent_start:round_number, :])
            recent_cooperation_rate = recent_cooperators / (self.n_players * recent_rounds)
        else:
            recent_cooperation_rate = historical_cooperation_rate
        cooperation_rate = 0.7 * recent_cooperation_rate + 0.3 * historical_cooperation_rate
        return cooperation_rate

class Strategy_COLLECTIVE_352(BaseStrategy):
    """
    Adaptive Collective Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization, robustness against exploitation,
    and adaptive recovery through cooperation sustainability monitoring and
    strategic punishment phases.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.punishment_window = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            csi = self._compute_csi(history, round_num)
            if csi >= self.k / self.n:
                return Action.C
            else:
                return Action.D
        csi = self._compute_csi(history, round_num)
        defection_ratio = self._compute_exploitation_ratio(history, round_num)
        if self._all_defected_consecutive(history, round_num, window=3):
            return Action.C
        csi_threshold = self.k / self.n - 0.1
        if self.k <= 1.2:
            csi_threshold = self.k / self.n - 0.15
        def_ratio_threshold = 0.4 if self.n <= 10 else 0.5
        if self.punishment_window > 0:
            self.punishment_window -= 1
            return Action.D
        if csi >= csi_threshold:
            return Action.C
        elif csi < csi_threshold and defection_ratio > def_ratio_threshold:
            punishment_duration = 2 if self.n <= 10 else 3
            self.punishment_window = punishment_duration - 1
            return Action.D
        elif csi < csi_threshold and defection_ratio <= def_ratio_threshold:
            return Action.D
        else:
            return Action.D

    def _compute_csi(self, history: PlayerHistory, current_round: int) -> float:
        """
        Compute Cooperation Sustainability Index based on last 3 rounds.
        CSI = (average_cooperators_last_3_rounds) / n
        """
        window_size = 3
        start_idx = max(0, current_round - window_size)
        if start_idx >= current_round:
            return 0.0
        total_cooperators = 0
        rounds_counted = 0
        for round_idx in range(start_idx, current_round):
            cooperators = np.sum(history.opponent_actions[round_idx, :])
            cooperators += int(history.my_actions[round_idx])
            total_cooperators += cooperators
            rounds_counted += 1
        if rounds_counted == 0:
            return 0.0
        average_cooperators = total_cooperators / rounds_counted
        csi = average_cooperators / self.n
        return csi

    def _compute_exploitation_ratio(self, history: PlayerHistory, current_round: int) -> float:
        """
        Compute defection_ratio = instances where I cooperated but majority defected / rounds where I cooperated.
        """
        cooperation_count = 0
        exploited_count = 0
        for round_idx in range(current_round):
            if history.my_actions[round_idx]:
                cooperation_count += 1
                opponent_cooperators = np.sum(history.opponent_actions[round_idx, :])
                total_cooperators = opponent_cooperators + 1
                if total_cooperators < self.n / 2.0:
                    exploited_count += 1
        if cooperation_count == 0:
            return 0.0
        defection_ratio = exploited_count / cooperation_count
        return defection_ratio

    def _all_defected_consecutive(self, history: PlayerHistory, current_round: int, window: int=3) -> bool:
        """
        Check if all players defected for the last 'window' consecutive rounds.
        Returns True if so, to trigger reset to cooperation.
        """
        if current_round < window:
            return False
        start_idx = current_round - window
        for round_idx in range(start_idx, current_round):
            opponent_cooperators = np.sum(history.opponent_actions[round_idx, :])
            my_coop = int(history.my_actions[round_idx])
            total_cooperators = opponent_cooperators + my_coop
            if total_cooperators > 0:
                return False
        return True

class Strategy_COLLECTIVE_353(BaseStrategy):
    """
    Adaptive Reciprocal Investment (ARI) Strategy for N-Player Public Goods Game

    Balances rational cooperation with protection against exploitation.
    - Round 1: Cooperate to establish good faith
    - Rounds 2 to r-1: Conditionally cooperate based on observed cooperation ratio vs adaptive threshold
    - Final round: Defect (standard game theory for final round)

    Threshold adapts based on game progress, increasing over time to account for end-game defection pressure.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.base_threshold = self.k / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        previous_round_idx = current_round - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[previous_round_idx, :]))
        cooperation_ratio = cooperators_last_round / self.n_players
        degradation_factor = 0.15
        current_threshold = self.base_threshold + degradation_factor * (current_round / self.n_rounds)
        if cooperation_ratio >= current_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_354(BaseStrategy):
    """
    Adaptive Reciprocal Threshold (ART) Strategy for N-Player Public Goods Game

    Balances collective welfare maximization with individual sustainability through
    adaptive thresholds that decrease over time. Cooperates when observed cooperation
    rates exceed a dynamic threshold, with special handling for early rounds, late rounds,
    and defection wave detection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        total_cooperators_all_rounds = 0
        for round_idx in range(round_number):
            my_action = 1 if history.my_actions[round_idx] else 0
            opponent_cooperators = np.sum(history.opponent_actions[round_idx, :])
            round_cooperators = my_action + opponent_cooperators
            total_cooperators_all_rounds += round_cooperators
        coop_rate = total_cooperators_all_rounds / (self.n_players * round_number)
        threshold = 0.5 + 0.3 * (self.n_rounds - round_number) / self.n_rounds
        if round_number > 5:
            recent_total = 0
            for round_idx in range(round_number - 5, round_number):
                my_action = 1 if history.my_actions[round_idx] else 0
                opponent_cooperators = np.sum(history.opponent_actions[round_idx, :])
                recent_total += my_action + opponent_cooperators
            recent_coop_rate = recent_total / (5 * self.n_players)
            if recent_coop_rate < coop_rate - 0.15:
                threshold = max(threshold - 0.1, 0.35)
        if round_number > 0.9 * self.n_rounds:
            threshold = max(threshold - 0.05, 0.45)
        if coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_355(BaseStrategy):
    """
    Adaptive Collective Maximization Strategy (ACMS)

    Balances collective welfare maximization with individual protection through:
    1. Optimistic cooperation in round 1
    2. Conditional cooperation based on observed cooperation rates
    3. Collective benefit tests using pool efficiency
    4. Endgame adjustments to maximize group payoff
    5. All-defect trap avoidance through periodic cooperation tests
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.pool_multiplier = self.k / self.n
        self.defection_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        if t == 0:
            return Action.C
        cooperators_last = int(sum(history.opponent_actions[-1, :]))
        cooperation_rate = cooperators_last / self.n
        rounds_remaining = self.r - t
        if cooperators_last == 0:
            self.defection_streak += 1
        else:
            self.defection_streak = 0
        benefit_of_cooperation = self.pool_multiplier * (cooperators_last + 1)
        cost_of_cooperation = 1 - self.pool_multiplier * cooperators_last
        if benefit_of_cooperation > cost_of_cooperation:
            return Action.C
        if cooperation_rate >= 1 / self.k and rounds_remaining >= 2:
            return Action.C
        if self.pool_multiplier > 0.9 and cooperation_rate >= 0.3:
            return Action.C
        if cooperators_last == 0 and self.defection_streak > 2:
            return Action.C
        if t == self.r - 1:
            if cooperation_rate > 0.3:
                return Action.C
        if t == self.r - 2:
            if cooperation_rate > 0.3:
                return Action.C
        if t == self.r - 1:
            if cooperation_rate >= 0.5:
                return Action.C
            elif cooperation_rate >= 1 / self.k:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_356(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Prioritizes collective welfare maximization while maintaining individual rationality.
    Uses a cooperation threshold strategy based on observed cooperation rates, with
    forgiveness windows and endgame adjustments for robustness.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        window = min(3, self.r // 4)
        recent_rounds = history.opponent_actions[max(0, state.round_number - window):, :]
        if len(recent_rounds) == 0:
            avg_cooperators = 0
        else:
            avg_cooperators = np.mean(np.sum(recent_rounds, axis=1))
        cooperation_rate = avg_cooperators / self.n
        threshold = self.k / self.n
        if state.round_number >= 3 * self.r / 4:
            threshold += 0.1
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_357(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with individual incentive compatibility.
    Cooperates initially, then adapts based on observed cooperation rates using
    threshold-based decision logic with probabilistic softening in low-cooperation scenarios.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_high = 0.67
        self.threshold_mid = 0.4
        self.threshold_low = 0.1
        self.max_prob_cooperate = 0.8
        self.prob_multiplier = 1.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round_idx = state.round_number - 1
        my_prev_action = history.my_actions[prev_round_idx]
        opponent_prev_actions = history.opponent_actions[prev_round_idx, :]
        total_cooperators = int(my_prev_action) + int(np.sum(opponent_prev_actions))
        cooperation_rate = total_cooperators / self.game_description.n_players
        if state.round_number == self.game_description.n_rounds - 1:
            if cooperation_rate >= 0.5:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= self.threshold_high:
            return Action.C
        elif cooperation_rate >= self.threshold_mid:
            return Action.C
        elif cooperation_rate > self.threshold_low:
            prob_cooperate = cooperation_rate * self.prob_multiplier
            prob_cooperate = min(prob_cooperate, self.max_prob_cooperate)
            if random.random() < prob_cooperate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_358(BaseStrategy):
    """
    Adaptive Contribution with Equilibrium Targeting.

    Balances individual rationality with collective welfare by:
    1. Leading with cooperation in round 1 to establish reciprocal norms
    2. Tracking empirical cooperation rates across phases
    3. Contributing when cooperation rate justifies the public good benefit
    4. Defecting when cooperation is too low to sustain mutual benefit
    5. Handling endgame strategically based on observed cooperation history
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        observed_coop_count = np.sum(history.opponent_actions[:round_number, :])
        total_opponent_actions = round_number * (self.n_players - 1)
        observed_coop_rate = observed_coop_count / total_opponent_actions if total_opponent_actions > 0 else self.k / self.n_players
        early_phase_end = math.floor(self.n_rounds / 3)
        middle_phase_end = math.floor(2 * self.n_rounds / 3)
        baseline_threshold = self.k / self.n_players
        if round_number <= early_phase_end:
            if observed_coop_rate > 0.5:
                return Action.C
            elif observed_coop_rate > 0.33:
                return Action.C
            else:
                return Action.D
        elif round_number == self.n_rounds - 1:
            if observed_coop_rate > 0.5:
                return Action.C
            else:
                return Action.D
        elif observed_coop_rate > baseline_threshold:
            return Action.C
        elif observed_coop_rate > 0.4:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_359(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with individual rationality through:
    - Cooperation-first initialization
    - Adaptive reciprocity based on observed cooperation rates
    - Graduated threshold decay over time
    - Final-round defection (backward induction)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            return Action.D
        prev_round_idx = round_num - 1
        prev_cooperators = np.sum(history.opponent_actions[prev_round_idx, :])
        if history.my_actions[prev_round_idx]:
            prev_cooperators += 1
        cooperation_rate = prev_cooperators / self.n
        base_threshold = 1.0 - self.k / self.n
        decay_factor = round_num / self.r
        threshold = 1.0 - base_threshold * decay_factor
        if cooperation_rate == 0:
            return Action.D
        if cooperation_rate >= 1.0:
            return Action.C
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_360(BaseStrategy):
    """
    Adaptive Contribution with Decay (ACD): A strategy that cooperates initially,
    monitors group cooperation health, and defects adaptively based on a dynamic
    threshold that accounts for break-even points and game urgency.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.ct = self.k / (self.n_players - 1) if self.n_players > 1 else 0.5
        self.tw = max(3, self.n_rounds // 4)
        self.sudden_drop_threshold = 0.2
        self.sudden_rise_threshold = 0.15
        self.ct_punish_bonus = 0.15
        self.ct_reward_reduction = 0.1
        self.final_round_threshold = 0.7

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        recent_start = max(0, current_round - self.tw)
        recent_rounds = current_round - recent_start
        cooperator_counts = np.sum(history.opponent_actions[recent_start:current_round, :], axis=1)
        recent_cooperation_rate = np.mean(cooperator_counts) / self.n_players
        rounds_remaining = self.n_rounds - current_round
        urgency_discount = min(1.0, rounds_remaining / self.n_rounds)
        ct_adjustment = 0.0
        if current_round >= 2:
            prev_round_cooperators = np.sum(history.opponent_actions[current_round - 1, :])
            prev_cooperation_rate = prev_round_cooperators / self.n_players
            if current_round >= 2:
                round_before_cooperators = np.sum(history.opponent_actions[current_round - 2, :])
                round_before_cooperation_rate = round_before_cooperators / self.n_players
                cooperation_change = prev_cooperation_rate - round_before_cooperation_rate
                if cooperation_change < -self.sudden_drop_threshold:
                    ct_adjustment = self.ct_punish_bonus
                elif cooperation_change > self.sudden_rise_threshold:
                    ct_adjustment = -self.ct_reward_reduction
        effective_ct = self.ct * urgency_discount + (1.0 - urgency_discount) * 0.5
        effective_ct = max(0.0, min(1.0, effective_ct + ct_adjustment))
        if current_round <= 2:
            if recent_cooperation_rate < 0.2 and current_round == 2:
                return Action.D
            return Action.C
        if current_round == self.n_rounds - 1:
            if recent_cooperation_rate >= self.final_round_threshold:
                return Action.C
            else:
                return Action.D
        if recent_cooperation_rate >= effective_ct:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_361(BaseStrategy):
    """
    Graduated Reciprocal Altruism with Threshold Adjustment (GRATA).

    A collective strategy that balances individual incentives with group welfare through:
    - Conditional opening moves based on payoff structure
    - Adaptive cooperation thresholds that lower over time
    - Probabilistic matching for weak cooperation signals
    - Final-round defection to avoid exploitation
    - Trend analysis for escaping defection traps
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            if self.k / self.n >= 0.5:
                return Action.C
            else:
                return Action.D
        if round_num == self.r - 1:
            prev_coop_rate = self._get_prev_coop_rate(history)
            if prev_coop_rate >= 0.6:
                return Action.C
            else:
                return Action.D
        prev_coop_rate = self._get_prev_coop_rate(history)
        personal_gain_from_defection = 1 - self.k / self.n
        if personal_gain_from_defection <= 0:
            return Action.C
        round_progress = (round_num - 1) / self.r
        threshold = 0.5 - 0.15 * round_progress
        if self.k < 1.1:
            threshold += 0.2
        elif self.k > self.n - 0.5:
            threshold -= 0.2
        if self.n > 20:
            prev_coop_rate = max(0, prev_coop_rate - 0.15)
        if prev_coop_rate >= threshold:
            return Action.C
        elif prev_coop_rate >= 0.25:
            if random.random() < prev_coop_rate:
                return Action.C
            else:
                return Action.D
        else:
            if round_num == 1 and prev_coop_rate == 0:
                return Action.C
            if round_num >= 2:
                trend = self._analyze_trend(history)
                if trend > 0:
                    return Action.C
                elif trend < 0:
                    return Action.D
            return Action.D

    def _get_prev_coop_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate from the previous round."""
        if history.opponent_actions.shape[0] == 0:
            return 0.0
        prev_round_actions = history.opponent_actions[-1, :]
        cooperators = int(np.sum(prev_round_actions))
        return cooperators / self.n

    def _analyze_trend(self, history: PlayerHistory) -> float:
        """
        Analyze cooperation trend over recent rounds.
        Returns positive if trend is increasing, negative if decreasing.
        """
        if history.opponent_actions.shape[0] < 2:
            return 0.0
        recent_rounds = min(3, history.opponent_actions.shape[0])
        coop_rates = []
        for i in range(-recent_rounds, 0):
            cooperators = int(np.sum(history.opponent_actions[i, :]))
            coop_rates.append(cooperators / self.n)
        if len(coop_rates) < 2:
            return 0.0
        trend = coop_rates[-1] - coop_rates[0]
        return trend

class Strategy_COLLECTIVE_362(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare through three phases:
    1. Early Game: Unconditional cooperation to establish trustworthiness
    2. Middle Game: Adaptive cooperation based on observed cooperation rate vs. k/n threshold
    3. End Game: Strategic defection in final rounds with special handling for round r-1
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.epsilon = 0.1
        self.cooperation_threshold = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        early_game_limit = self.r // 3
        if current_round < early_game_limit:
            return Action.C
        if history is None:
            return Action.C
        rounds_remaining = self.r - current_round
        if rounds_remaining == 1:
            return Action.D
        if rounds_remaining == 2:
            observed_coop_rate = self._calculate_cooperation_rate(history, current_round)
            if observed_coop_rate > self.cooperation_threshold:
                return Action.C
            else:
                return Action.D
        observed_coop_rate = self._calculate_cooperation_rate(history, current_round)
        rounds_played = current_round
        if rounds_played >= 5 and observed_coop_rate <= self.epsilon:
            return Action.D
        threshold_lower = self.cooperation_threshold - self.epsilon
        if current_round >= math.floor(2 * self.r / 3):
            threshold_lower = self.cooperation_threshold - self.epsilon + 0.05
        if abs(observed_coop_rate - self.cooperation_threshold) < 0.05:
            return Action.C
        if observed_coop_rate >= threshold_lower:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the observed cooperation rate of all other players
        across all rounds played so far (0 to current_round - 1).
        """
        if current_round == 0:
            return 0.0
        total_cooperations = np.sum(history.opponent_actions[:current_round, :])
        total_possible = current_round * (self.n - 1)
        if total_possible == 0:
            return 0.0
        cooperation_rate = float(total_cooperations) / float(total_possible)
        return cooperation_rate

class Strategy_COLLECTIVE_363(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization, individual protection, and adaptive learning
    to find mutually beneficial cooperation while maintaining defensive safeguards against
    exploitation and free-riding.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prr = self._calculate_prr(history, round_num)
        ed = self._calculate_ed(history, round_num)
        cci = self._calculate_cci(history, round_num)
        cci_avg = self._calculate_cci_average(history, round_num)
        if round_num == self.r - 1:
            return self._final_round_decision(cci_avg, prr, history, round_num)
        return self._main_phase_decision(cci, prr, ed, history, round_num)

    def _calculate_cci(self, history: PlayerHistory, round_num: int) -> float:
        """Calculate Collective Cooperation Index for previous round."""
        if round_num == 0:
            return 0.5
        prev_round = round_num - 1
        cooperators = np.sum(history.opponent_actions[prev_round, :])
        if history.my_actions[prev_round]:
            cooperators += 1
        return cooperators / self.n

    def _calculate_cci_average(self, history: PlayerHistory, round_num: int) -> float:
        """Calculate rolling average of CCI over rounds 1 to round_num-1."""
        if round_num <= 1:
            return 0.5
        ccis = []
        for r in range(1, round_num):
            cooperators = np.sum(history.opponent_actions[r - 1, :])
            if history.my_actions[r - 1]:
                cooperators += 1
            ccis.append(cooperators / self.n)
        return np.mean(ccis) if ccis else 0.5

    def _calculate_prr(self, history: PlayerHistory, round_num: int) -> float:
        """Calculate Personal Reciprocity Ratio."""
        if round_num == 0:
            return 0.5
        my_coops = np.sum(history.my_actions[:round_num])
        if my_coops == 0:
            return 0.5
        reciprocated = 0
        for r in range(round_num):
            if history.my_actions[r]:
                opponent_coops = np.sum(history.opponent_actions[r, :])
                if opponent_coops / self.n >= 0.5:
                    reciprocated += 1
        return reciprocated / my_coops

    def _calculate_ed(self, history: PlayerHistory, round_num: int) -> float:
        """Calculate Exploitation Detection."""
        if round_num == 0:
            return 0.0
        defect_rounds = 0
        regret_defects = 0
        for r in range(round_num):
            if not history.my_actions[r]:
                defect_rounds += 1
                opponent_coops = np.sum(history.opponent_actions[r, :])
                cci_r = opponent_coops / self.n
                if cci_r > self.k / self.n and history.my_payoffs[r] < 1.5:
                    regret_defects += 1
        if defect_rounds == 0:
            return 0.0
        return regret_defects / defect_rounds

    def _get_threshold(self) -> float:
        """Get cooperation threshold, adjusted for n and k."""
        base_threshold = self.k / self.n + 0.1
        if self.n > 8:
            base_threshold += 0.05
        if self.k < 1.2:
            base_threshold += 0.05
        return base_threshold

    def _get_prr_threshold(self) -> float:
        """Get PRR threshold, adjusted for k."""
        if self.k < 1.2:
            return 0.7
        return 0.6

    def _compare_expected_payoffs(self, history: PlayerHistory, round_num: int) -> bool:
        """Compare average payoff from cooperation vs defection."""
        if round_num == 0:
            return True
        coop_payoffs = []
        defect_payoffs = []
        for r in range(round_num):
            if history.my_actions[r]:
                coop_payoffs.append(history.my_payoffs[r])
            else:
                defect_payoffs.append(history.my_payoffs[r])
        avg_coop = np.mean(coop_payoffs) if coop_payoffs else 1.0
        avg_defect = np.mean(defect_payoffs) if defect_payoffs else 1.0
        return avg_coop > avg_defect

    def _main_phase_decision(self, cci: float, prr: float, ed: float, history: PlayerHistory, round_num: int) -> Action:
        """Main phase decision logic (rounds 1 to r-2)."""
        threshold = self._get_threshold()
        prr_thresh = self._get_prr_threshold()
        if cci >= threshold:
            if prr >= prr_thresh:
                return Action.C
            elif prr < 0.4 and ed > 0.4:
                return Action.D
            else:
                return Action.C
        elif cci < threshold - 0.2:
            return Action.D
        elif self._compare_expected_payoffs(history, round_num):
            return Action.C
        else:
            return Action.D

    def _final_round_decision(self, avg_cci: float, prr: float, history: PlayerHistory, round_num: int) -> Action:
        """Final round decision logic."""
        if avg_cci > 0.6:
            return Action.C
        elif avg_cci < 0.4:
            return Action.D
        else:
            total_payoff = np.sum(history.my_payoffs)
            median_payoff = np.median(np.concatenate([history.my_payoffs, history.opponent_payoffs.flatten()]))
            if prr >= 0.7 and total_payoff >= median_payoff:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_364(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization, individual rationality, and robustness by:
    - Cooperating unconditionally in round 1 (trust-building)
    - Adapting cooperation based on opponent cooperation rates and game phase
    - Using a dynamic threshold that increases in the late phase (defensive)
    - Defecting in the final round (end-game rationality)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.r - 1:
            return Action.D
        recent_opponent_actions = history.opponent_actions[round_number - 1, :]
        cooperators_last_round = int(np.sum(recent_opponent_actions))
        cooperation_rate = cooperators_last_round / (self.n - 1)
        threshold = self.n / self.k
        late_phase_boundary = math.ceil(2 * self.r / 3)
        phase_multiplier = 1.15 if round_number >= late_phase_boundary else 1.0
        adjusted_threshold = threshold * phase_multiplier / self.n
        if cooperation_rate > adjusted_threshold:
            return Action.C
        elif cooperation_rate > adjusted_threshold * 0.5:
            probability = cooperation_rate / adjusted_threshold
            if random.random() < probability:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_365(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game

    Balances collective welfare with individual security through:
    1. Phase 1 (Assessment): Probe environment with good-faith cooperation
    2. Phase 2 (Stabilization): Identify sustainable cooperation and commit selectively
    3. Phase 3 (Endgame): Maximize final payoff while preserving collective welfare
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == 1:
            others_coop_r0 = sum(history.opponent_actions[0, :])
            if others_coop_r0 > 0:
                return Action.C
            else:
                return Action.D
        phase1_end = math.ceil(self.r / 3)
        phase2_end = math.floor(2 * self.r / 3)
        total_others_coop = sum((sum(history.opponent_actions[i, :]) for i in range(current_round)))
        historical_coop_rate = total_others_coop / ((self.n - 1) * current_round)
        window_size = min(10, current_round)
        recent_window_start = current_round - window_size
        recent_others_actions = history.opponent_actions[recent_window_start:current_round, :]
        others_recent_coop_rate = np.mean(recent_others_actions) if window_size > 0 else 0.0
        my_recent_actions = history.my_actions[recent_window_start:current_round]
        all_my_recent_c = np.all(my_recent_actions) if window_size > 0 else True
        my_total_payoff = np.sum(history.my_payoffs[:current_round])
        historical_avg_payoff = my_total_payoff / current_round
        if current_round < phase1_end:
            coop_threshold = self.k / self.n
            if historical_coop_rate >= coop_threshold:
                return Action.C
            else:
                return Action.D
        elif current_round < phase2_end:
            threshold_high = 2 * self.k / (3 * self.n)
            threshold_mid = self.k / self.n
            threshold_low = self.k / (2 * self.n)
            if others_recent_coop_rate >= threshold_high:
                return Action.C
            elif historical_coop_rate >= threshold_mid and others_recent_coop_rate >= threshold_low:
                if all_my_recent_c:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D
        else:
            rounds_remaining = self.r - current_round
            if rounds_remaining == 1:
                threshold_endgame = 3 * self.k / (4 * self.n)
                if historical_coop_rate >= threshold_endgame:
                    return Action.C
                else:
                    return Action.D
            else:
                window_5 = min(5, current_round)
                recent_window_5_start = current_round - window_5
                recent_5_others = history.opponent_actions[recent_window_5_start:current_round, :]
                others_coop_5_window = np.mean(recent_5_others) if window_5 > 0 else 0.0
                threshold_high_endgame = 2 * self.k / (3 * self.n)
                threshold_mid_endgame = self.k / (2 * self.n)
                if others_coop_5_window >= threshold_high_endgame:
                    return Action.C
                elif my_total_payoff >= historical_avg_payoff * current_round and others_coop_5_window >= threshold_mid_endgame:
                    return Action.C
                else:
                    return Action.D

class Strategy_COLLECTIVE_366(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC): A collective strategy that balances
    cooperation maximization with individual robustness through adaptive thresholding.

    Core mechanism: Cooperate if observed cooperation rate meets or exceeds threshold
    (n - k) / n, which represents the break-even point between collective and individual
    rationality. First round always cooperates (faith); final round applies threshold rule
    (integrity). Defects strategically when cooperation falls below threshold (punishment).
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.n - self.k) / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        observed_cooperators = 0
        total_observations = 0
        for round_idx in range(current_round):
            if history.my_actions[round_idx]:
                observed_cooperators += 1
            for opponent_idx in range(self.n - 1):
                if history.opponent_actions[round_idx, opponent_idx]:
                    observed_cooperators += 1
            total_observations += self.n
        coop_rate = observed_cooperators / total_observations if total_observations > 0 else 0.0
        if coop_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_367(BaseStrategy):
    """
    Adaptive Contribution with Conditional Defection Threshold

    Balances collective welfare with individual protection by cooperating when
    the observed cooperation rate of others meets or exceeds a threshold value.
    The threshold is (k-1)/n, representing the break-even point for contribution.

    - Round 0: Always cooperate (initial trust phase)
    - Rounds 1+: Cooperate if observed cooperation rate >= threshold, else defect
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.threshold = (self.k - 1) / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round_opponent_actions = history.opponent_actions[-1, :]
        cooperators_count = np.sum(last_round_opponent_actions)
        cooperation_rate = cooperators_count / (self.n - 1)
        if cooperation_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_368(BaseStrategy):
    """
    Adaptive Contribution Equilibrium (ACE) Strategy for N-Player Public Goods Game

    Balances collective welfare maximization with individual protection through:
    - Conditional cooperation based on adaptive thresholds
    - Graduated punishment of defection
    - Recovery mechanisms for cooperation restoration
    - Protection against systematic exploitation
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.defection_streak = 0
        self.permanent_defection = False

    def _calculate_threshold(self, base_threshold: float, defection_streak: int) -> float:
        """Calculate adaptive threshold based on defection streak"""
        adjusted_threshold = base_threshold
        if defection_streak >= 4:
            adjusted_threshold = base_threshold - 0.15
        adjusted_threshold = min(adjusted_threshold, 0.95)
        adjusted_threshold = max(adjusted_threshold, 0.0)
        return adjusted_threshold

    def _get_base_threshold(self) -> float:
        """Calculate base threshold: k/n + epsilon"""
        base = self.k / self.n_players + 0.07
        if base > 1.0:
            return 0.95
        return base

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round_opponent_actions = history.opponent_actions[-1, :]
        cooperators_last_round = np.sum(last_round_opponent_actions)
        cooperation_rate = cooperators_last_round / self.n_players
        base_threshold = self._get_base_threshold()
        if cooperation_rate < base_threshold:
            self.defection_streak += 1
        else:
            self.defection_streak = 0
        adjusted_threshold = self._calculate_threshold(base_threshold, self.defection_streak)
        if self.defection_streak > 5:
            self.permanent_defection = True
        if self.permanent_defection:
            return Action.D
        if cooperation_rate >= adjusted_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_369(BaseStrategy):
    """
    Adaptive Conditional Cooperation (ACC) strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare through:
    - Bootstrap cooperation in round 1
    - Adaptive thresholds based on observed cooperation rates
    - Dynamic punishment that transitions smoothly as cooperation declines
    - Endgame strategy that recognizes future retaliation impossibility
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        opponent_cooperators = np.sum(history.opponent_actions[prev_round_idx, :])
        cooperation_rate = opponent_cooperators / (self.n_players - 1)
        final_quarter_threshold = self.n_rounds - math.ceil(self.n_rounds / 4)
        in_final_quarter = current_round >= final_quarter_threshold
        if in_final_quarter:
            threshold_late = max(0.5, self.k / self.n_players + 0.1)
            if cooperation_rate >= threshold_late:
                return Action.C
            else:
                return Action.D
        else:
            round_progress = current_round / self.n_rounds
            penalty = 0.15 * round_progress
            threshold_adaptive = self.k / self.n_players * (1 - penalty)
            min_viable_cooperators = self.k / self.n_players
            if cooperation_rate >= threshold_adaptive and cooperation_rate >= min_viable_cooperators:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_370(BaseStrategy):
    """
    Adaptive Reciprocal Stewardship: A graduated reciprocity strategy that establishes
    cooperative equilibrium, detects and responds proportionally to defection, recovers
    cooperation gracefully, and maintains resilience against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.tau_primary = self.k / (2 * self.n)
        self.tau_recovery = (self.k - 1) / (2 * self.n)
        self.consecutive_low_coop_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            cooperation_rate = self._compute_cooperation_rate(history)
            if cooperation_rate >= self.tau_primary:
                return Action.C
            else:
                return Action.D
        cooperation_rate = self._compute_cooperation_rate(history)
        if cooperation_rate >= self.tau_primary:
            self.consecutive_low_coop_rounds = 0
            return Action.C
        elif cooperation_rate >= self.tau_recovery:
            self.consecutive_low_coop_rounds = 0
            if random.random() < cooperation_rate:
                return Action.C
            else:
                return Action.D
        else:
            self.consecutive_low_coop_rounds += 1
            return Action.D

    def _compute_cooperation_rate(self, history: PlayerHistory) -> float:
        """
        Compute the fraction of C actions (True values) across all opponents
        and all previous rounds.
        """
        if history is None or len(history.opponent_actions) == 0:
            return 1.0
        total_opponent_actions = history.opponent_actions.size
        cooperations = np.sum(history.opponent_actions)
        if total_opponent_actions == 0:
            return 1.0
        return float(cooperations) / float(total_opponent_actions)

class Strategy_COLLECTIVE_371(BaseStrategy):
    """
    Adaptive Contribution Targeting (ACT): A collective strategy that balances
    individual resilience with cooperative benefit-seeking. It adaptively responds
    to observed cooperation rates, exploitability, and game phase while maintaining
    punitive mechanisms against systematic defection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.anger_level = 0.0
        self.THRESHOLD_STABLE = 0.5
        self.THRESHOLD_CRITICAL = 0.2
        self.ANGER_THRESHOLD = 2
        self.ANGER_INCREMENT = 1.0
        self.ANGER_DECAY = 0.5
        self.EXPLOIT_SIGNIFICANCE = 0.3
        self.ENDGAME_COOP_THRESHOLD = 0.6
        self.PAYOFF_TOLERANCE = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        rounds_completed = state.round_number
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        total_cooperations = int(np.sum(history.my_actions[:rounds_completed]))
        for opp_round in range(rounds_completed):
            total_cooperations += int(np.sum(history.opponent_actions[opp_round, :]))
        total_player_rounds = rounds_completed * n
        observed_coop_rate = total_cooperations / total_player_rounds if total_player_rounds > 0 else 0.0
        my_last_action = history.my_actions[rounds_completed - 1]
        my_last_payoff = history.my_payoffs[rounds_completed - 1]
        last_round_opponent_payoffs = history.opponent_payoffs[rounds_completed - 1, :]
        avg_last_payoff = float(np.mean(last_round_opponent_payoffs))
        was_exploited = False
        if my_last_action:
            opponent_cooperated = history.opponent_actions[rounds_completed - 1, :]
            if len(last_round_opponent_payoffs) > 0:
                defector_payoffs = last_round_opponent_payoffs[~opponent_cooperated]
                if len(defector_payoffs) > 0:
                    avg_defector_payoff = float(np.mean(defector_payoffs))
                    defection_advantage = avg_defector_payoff - my_last_payoff
                    if defection_advantage > self.EXPLOIT_SIGNIFICANCE:
                        was_exploited = True
        if was_exploited:
            self.anger_level += self.ANGER_INCREMENT
        else:
            self.anger_level = max(0.0, self.anger_level - self.ANGER_DECAY)
        if self.anger_level > 5:
            self.anger_level -= 1.0
        action = Action.D
        if observed_coop_rate >= self.THRESHOLD_STABLE:
            if my_last_payoff >= avg_last_payoff - self.PAYOFF_TOLERANCE:
                action = Action.C
            elif was_exploited:
                action = Action.D
            else:
                action = Action.C
        elif observed_coop_rate < self.THRESHOLD_CRITICAL:
            action = Action.D
        elif random.random() < observed_coop_rate:
            action = Action.C
        else:
            action = Action.D
        rounds_remaining = r - state.round_number
        if rounds_remaining <= 2:
            if observed_coop_rate > self.ENDGAME_COOP_THRESHOLD:
                action = Action.C
            else:
                action = Action.D
        if self.anger_level >= self.ANGER_THRESHOLD:
            action = Action.D
        return action

class Strategy_COLLECTIVE_372(BaseStrategy):
    """
    Adaptive Reciprocal Threshold (ART) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare by cooperating when
    the observed cooperation rate meets or exceeds the threshold k/n, which is
    the point where public good returns equal private costs.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        total_cooperators = int(np.sum(history.opponent_actions))
        total_cooperators += int(np.sum(history.my_actions))
        total_actions = (current_round + 1) * self.n_players
        cooperation_rate = total_cooperators / total_actions
        if cooperation_rate < 0.2 and current_round > 1:
            return Action.D
        rounds_remaining = self.n_rounds - current_round
        if rounds_remaining == 0:
            buffer = 0.1
            if cooperation_rate >= self.threshold - buffer:
                return Action.C
            else:
                return Action.D
        buffer = 0.05
        if cooperation_rate >= self.threshold - buffer and current_round > self.n_rounds / 2:
            return Action.C
        if cooperation_rate >= self.threshold - buffer:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_373(BaseStrategy):
    """
    Adaptive Reciprocal Provisioning (ARP) Strategy for N-Player Public Goods Game.

    This strategy maximizes long-term group welfare through conditional cooperation:
    - Round 1: Cooperate (good faith)
    - Rounds 2 to r-1: Reciprocate based on adaptive threshold of previous round cooperators
    - Round r: Defect (subgame perfect equilibrium)

    The threshold declines over time, starting strict and becoming more lenient.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def _calculate_threshold(self, current_round: int) -> float:
        """
        Calculate the cooperation threshold for adaptive reciprocal phase.

        threshold(t) = CEIL(n  (1 + (k-1)/(2k))  (1 - decay_factor(t)))
        where decay_factor(t) = (t - 1) / (r - 1)

        current_round is 0-indexed, so we need to adjust to 1-indexed for formula.
        """
        t = current_round + 1
        if self.r <= 1:
            decay_factor = 0
        else:
            decay_factor = (t - 1) / (self.r - 1)
        base_multiplier = 1 + (self.k - 1) / (2 * self.k)
        threshold_value = self.n * base_multiplier * (1 - decay_factor)
        return math.ceil(threshold_value)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            return Action.D
        cooperators_prev = int(sum(history.opponent_actions[current_round - 1, :]))
        threshold = self._calculate_threshold(current_round)
        if cooperators_prev >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_374(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with robust defense against exploitation.
    Uses contribution rate matching with threshold safeguards and adaptive adjustments.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.consecutive_low_coop_rounds = 0
        self.in_defect_mode = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        n = self.n_players
        k = self.k
        if round_number == 0:
            return Action.C
        if round_number == self.n_rounds - 1:
            total_cooperators = 0
            for r in range(round_number):
                round_cooperators = int(history.my_actions[r]) + int(np.sum(history.opponent_actions[r, :]))
                total_cooperators += round_cooperators
            avg_coop = total_cooperators / (n * round_number)
            threshold_value = k / n
            if avg_coop >= threshold_value:
                return Action.C
            else:
                return Action.D
        prev_round_idx = round_number - 1
        prev_round_cooperators = int(history.my_actions[prev_round_idx]) + int(np.sum(history.opponent_actions[prev_round_idx, :]))
        prev_round_coop_rate = prev_round_cooperators / n
        threshold_t = min(0.25, k / n + 0.1)
        if round_number >= 2:
            current_round_coop = prev_round_coop_rate
            prev_prev_round_idx = round_number - 2
            prev_prev_round_cooperators = int(history.my_actions[prev_prev_round_idx]) + int(np.sum(history.opponent_actions[prev_prev_round_idx, :]))
            prev_prev_round_coop_rate = prev_prev_round_cooperators / n
            if current_round_coop < threshold_t and prev_prev_round_coop_rate < threshold_t:
                self.consecutive_low_coop_rounds += 1
                if self.consecutive_low_coop_rounds >= 2:
                    self.in_defect_mode = True
                    return Action.D
            else:
                self.consecutive_low_coop_rounds = 0
                self.in_defect_mode = False
        if self.in_defect_mode and prev_round_coop_rate >= threshold_t:
            self.in_defect_mode = False
            self.consecutive_low_coop_rounds = 0
        if self.in_defect_mode:
            return Action.D
        adjustment = 0.0
        if round_number >= 3:
            prev_payoffs = history.my_payoffs[prev_round_idx]
            opponent_payoffs = history.opponent_payoffs[prev_round_idx, :]
            all_payoffs = np.concatenate([[prev_payoffs], opponent_payoffs])
            payoff_variance = np.var(all_payoffs)
            my_prev_action = history.my_actions[prev_round_idx]
            if payoff_variance > 0.5 and (not my_prev_action):
                adjustment = -0.05
        contribution_probability = max(0.0, min(1.0, prev_round_coop_rate + adjustment))
        if random.random() < contribution_probability:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_375(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances individual incentives with collective welfare by:
    1. Starting optimistically with cooperation
    2. Rewarding cooperation with continued contribution
    3. Punishing defection proportionally
    4. Adapting based on observed cooperation rates
    5. Never becoming a pure free-rider

    Uses threshold-based decision making where threshold = k/n (breakeven point).
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        threshold = self.threshold
        if round_number == 0:
            return Action.C
        if round_number <= 2:
            recent_cooperation_rate = self._calculate_recent_cooperation_rate(history, round_number, lookback=round_number)
            if recent_cooperation_rate > threshold:
                return Action.C
            elif recent_cooperation_rate < threshold * 0.7:
                return Action.D
            else:
                return Action.C
        if round_number < r - 2:
            hist_cooperation_rate = self._calculate_historical_cooperation_rate(history, round_number)
            if hist_cooperation_rate >= threshold:
                return Action.C
            else:
                return Action.D
        hist_cooperation_rate = self._calculate_historical_cooperation_rate(history, round_number)
        if hist_cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_historical_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate cooperation rate across all previous rounds.
        cooperation_rate = (total cooperators in previous rounds) / (n  previous_rounds_played)
        """
        if current_round == 0:
            return 0.0
        n = self.game_description.n_players
        total_cooperators = 0
        for round_idx in range(current_round):
            cooperators_this_round = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += cooperators_this_round
        total_possible_contributions = n * current_round
        cooperation_rate = total_cooperators / total_possible_contributions if total_possible_contributions > 0 else 0.0
        return cooperation_rate

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory, current_round: int, lookback: int) -> float:
        """
        Calculate cooperation rate over the most recent lookback rounds.
        recent_cooperation_rate = (cooperators in last lookback rounds) / (lookback  n)
        """
        if current_round == 0:
            return 0.0
        n = self.game_description.n_players
        start_idx = max(0, current_round - lookback)
        end_idx = current_round
        total_cooperators = 0
        for round_idx in range(start_idx, end_idx):
            cooperators_this_round = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += cooperators_this_round
        rounds_included = end_idx - start_idx
        total_possible_contributions = n * rounds_included
        cooperation_rate = total_cooperators / total_possible_contributions if total_possible_contributions > 0 else 0.0
        return cooperation_rate

class Strategy_COLLECTIVE_376(BaseStrategy):
    """
    Adaptive Collective Defection Strategy with Conditional Reciprocity.

    This strategy maximizes collective welfare by defecting initially and in the final round,
    while reciprocating cooperation in middle rounds when the observed cooperation rate
    exceeds the mathematical break-even threshold (k/n + epsilon).
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.epsilon = 0.05

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        previous_round_idx = current_round - 1
        self_cooperated_prev = history.my_actions[previous_round_idx]
        opponent_cooperators_prev = np.sum(history.opponent_actions[previous_round_idx, :])
        total_cooperators_prev = int(self_cooperated_prev) + int(opponent_cooperators_prev)
        cooperation_rate = total_cooperators_prev / n
        threshold = k / n + self.epsilon
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_377(BaseStrategy):
    """
    Adaptive Collective Strategy for N-Player Public Goods Game.

    Balances individual security with collective benefit-seeking through:
    - Round 1: Conditional optimism (cooperate)
    - Rounds 2 to r-1: Adaptive reciprocity with dynamic threshold
    - Final round: Complete defection (backward induction)

    The strategy uses a cooperation rate threshold that adjusts based on rounds remaining,
    with special handling for edge cases like n=2 and complete defection scenarios.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            return Action.D
        prev_round_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        cooperation_rate = prev_round_cooperators / self.n
        base_threshold = self.k / self.n
        if self.n == 2:
            base_threshold = min(base_threshold, 0.7)
        rounds_remaining = self.r - current_round
        endgame_adjustment = 0.15 * (1.0 - self.k / self.n) * (rounds_remaining / self.r)
        threshold = base_threshold + endgame_adjustment
        if prev_round_cooperators == 0:
            if random.random() < 0.05:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_378(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with individual sustainability through
    adaptive reciprocal cooperation. Cooperates when historical cooperation rates
    justify it (exceed threshold k/n), defects otherwise. Uses volatility detection
    for mixed populations and maintains consistent behavior through endgame.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        if round_num == 0:
            return Action.C
        if round_num <= 2 and round_num < r - 1:
            coop_rate_prev = float(np.sum(history.opponent_actions[0, :])) / n
            if coop_rate_prev >= self.threshold:
                return Action.C
            else:
                return Action.D
        total_rounds_so_far = round_num
        total_cooperators = 0
        for t in range(total_rounds_so_far):
            total_cooperators += np.sum(history.opponent_actions[t, :])
        avg_coop_rate = total_cooperators / (n * total_rounds_so_far)
        volatility_window_size = min(3, total_rounds_so_far)
        if volatility_window_size >= 2:
            recent_coop_rates = []
            for t in range(total_rounds_so_far - volatility_window_size, total_rounds_so_far):
                rate = float(np.sum(history.opponent_actions[t, :])) / n
                recent_coop_rates.append(rate)
            recent_mean = np.mean(recent_coop_rates)
            if len(recent_coop_rates) > 1:
                variance = np.sum([(r - recent_mean) ** 2 for r in recent_coop_rates]) / len(recent_coop_rates)
                volatility = math.sqrt(variance)
                if volatility > 0.3:
                    avg_coop_rate = recent_mean
        if avg_coop_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_379(BaseStrategy):
    """
    Adaptive Reciprocal Stewardship (ARS): A collective strategy for N-player public goods games.

    Balances cooperation with self-protection through four adaptive phases:
    1. EXPLORATION: Signal intent with cooperation
    2. CALIBRATION: Detect population cooperativeness
    3. ADAPTIVE RECIPROCITY: Conditional cooperation based on group behavior
    4. ENDGAME: Strategic defection in final rounds

    Adjusts thresholds based on game parameters (n, r, k) and uses stochastic defection
    to deter exploitation while maintaining reciprocal relationships.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        phase1_end = min(3, math.floor(self.r / 2))
        if current_round < phase1_end:
            return Action.C
        endgame_start = math.ceil(self.r * 0.85)
        if current_round >= endgame_start:
            if current_round == self.r - 1:
                return Action.D
            else:
                recent_coop = self._get_recent_cooperation_rate(history, current_round, 3)
                if recent_coop >= 0.6:
                    return Action.C
                else:
                    return Action.D
        phase2_end = math.floor(self.r * 0.4)
        if current_round < phase2_end:
            coop_threshold = 0.4 if self.n > 10 else 0.5
            if self.k <= 1.5:
                coop_threshold -= 0.1
            elif self.k >= self.n - 0.5:
                coop_threshold += 0.1
            cooperation_rate = self._get_recent_cooperation_rate(history, current_round, 3)
            if cooperation_rate >= coop_threshold:
                return Action.C
            else:
                return Action.D
        recent_cooperation = self._get_recent_cooperation_rate(history, current_round, 3)
        my_past_cooperations = self._get_my_cooperation_rate(history, current_round, 5)
        high_coop_threshold = 0.6
        mid_coop_threshold = 0.4
        low_coop_threshold = 0.3
        if self.n > 8:
            high_coop_threshold = 0.5
        if self.k <= 1.5:
            high_coop_threshold -= 0.1
            mid_coop_threshold -= 0.1
            low_coop_threshold -= 0.1
        elif self.k >= self.n - 0.5:
            high_coop_threshold += 0.1
            mid_coop_threshold += 0.1
            low_coop_threshold += 0.1
        if recent_cooperation >= high_coop_threshold and my_past_cooperations >= 0.5:
            return Action.C
        elif recent_cooperation >= mid_coop_threshold and my_past_cooperations >= 0.5:
            return Action.C
        elif recent_cooperation < low_coop_threshold:
            return Action.D
        else:
            stoch_prob = (recent_cooperation - low_coop_threshold) * 2
            stoch_prob = max(0.0, min(1.0, stoch_prob))
            if random.random() < stoch_prob:
                return Action.D
            else:
                return Action.C

    def _get_recent_cooperation_rate(self, history: PlayerHistory, current_round: int, window: int) -> float:
        """Calculate cooperation rate of all players in the last 'window' rounds."""
        if current_round == 0:
            return 0.0
        start_round = max(0, current_round - window)
        end_round = current_round
        total_cooperators = 0
        rounds_counted = end_round - start_round
        if rounds_counted == 0:
            return 0.0
        for round_idx in range(start_round, end_round):
            cooperators_this_round = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += cooperators_this_round
        total_possible = rounds_counted * (self.n - 1)
        if total_possible == 0:
            return 0.0
        return total_cooperators / total_possible

    def _get_my_cooperation_rate(self, history: PlayerHistory, current_round: int, window: int) -> float:
        """Calculate this player's cooperation rate in the last 'window' rounds."""
        if current_round == 0:
            return 0.0
        start_round = max(0, current_round - window)
        end_round = current_round
        rounds_counted = end_round - start_round
        if rounds_counted == 0:
            return 0.0
        my_cooperations = np.sum(history.my_actions[start_round:end_round])
        return my_cooperations / rounds_counted

class Strategy_COLLECTIVE_380(BaseStrategy):
    """
    Adaptive Contribution Targeting (ACT): A collective welfare maximization strategy
    that cooperates conditionally based on reciprocity-weighted thresholds and observed
    cooperation patterns, with round-specific logic for edge cases.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.defection_streak = 0
        self.last_cooperation_rate = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        cooperation_rate = self._calculate_smoothed_cooperation_rate(history, current_round)
        self.last_cooperation_rate = cooperation_rate
        predicted_cooperators = 1 + cooperation_rate * (self.n - 1)
        expected_collective_gain = (self.k - 1) * (predicted_cooperators - 1)
        reciprocity = self._estimate_reciprocity(history, current_round)
        threshold = 1 - reciprocity * cooperation_rate
        should_cooperate = expected_collective_gain > threshold
        if current_round == self.r - 1:
            if cooperation_rate < 0.5:
                should_cooperate = False
        return Action.C if should_cooperate else Action.D

    def _calculate_smoothed_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate cooperation rate with recency weighting and noise tolerance.
        """
        if current_round == 0:
            return 0.5
        opponent_actions = history.opponent_actions[:current_round]
        cooperations_per_round = np.sum(opponent_actions, axis=1)
        cooperation_rates_per_round = cooperations_per_round / (self.n - 1)
        weights = np.ones(current_round)
        recency_window = min(3, current_round)
        if recency_window > 0:
            weights[-recency_window:] *= 3
        weights = weights / np.sum(weights)
        smoothed_rate = float(np.sum(cooperation_rates_per_round * weights))
        return smoothed_rate

    def _estimate_reciprocity(self, history: PlayerHistory, current_round: int) -> float:
        """
        Estimate reciprocity factor based on cooperation patterns.
        Applies noise tolerance and reciprocity acceleration mechanisms.
        """
        if current_round <= 1:
            return 0.5
        opponent_actions = history.opponent_actions[:current_round]
        cooperations_per_round = np.sum(opponent_actions, axis=1)
        cooperation_rates = cooperations_per_round / (self.n - 1)
        base_reciprocity = 0.5
        recent_rounds = min(2, current_round)
        if recent_rounds >= 2:
            recent_cooperation = np.mean(cooperation_rates[-recent_rounds:])
            if recent_cooperation < 0.3:
                self.defection_streak += 1
                base_reciprocity = max(0.1, 0.5 - 0.2 * self.defection_streak)
            else:
                if self.defection_streak > 0:
                    base_reciprocity = min(0.8, base_reciprocity * 1.5)
                self.defection_streak = 0
        overall_cooperation = np.mean(cooperation_rates)
        reciprocity = base_reciprocity + 0.3 * overall_cooperation
        return max(0.1, min(0.9, reciprocity))

class Strategy_COLLECTIVE_381(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC): A collective strategy that balances
    cooperation maximization with self-protection against exploitation.

    Cooperates when observed cooperation rate exceeds a dynamically-adjusted
    threshold that accounts for endgame pressure, cooperation trends, and
    historical commitment. Includes special handling for first round and endgame.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        if t == 0:
            return Action.C
        all_opponent_actions = history.opponent_actions[:t]
        self_cooperations = history.my_actions[:t]
        opponent_cooperations = np.sum(all_opponent_actions, axis=1)
        total_cooperators_per_round = self_cooperations.astype(int) + opponent_cooperations
        if t >= self.r - 2:
            total_rounds_cooperated = np.sum(self_cooperations)
            historical_coop_threshold = 2.0 / 3.0 * t
            if total_rounds_cooperated >= historical_coop_threshold:
                if t == self.r - 1:
                    return Action.C
                else:
                    coop_rate = total_cooperators_per_round[-1] / self.n
                    theta_base = (self.k - 1) / (self.n - 1)
                    if coop_rate >= theta_base:
                        return Action.C
                    else:
                        return Action.D
            else:
                return Action.D
        window_size = 3
        window_start = max(0, t - window_size)
        window_end = t
        window_cooperators = total_cooperators_per_round[window_start:window_end]
        coop_rate = np.mean(window_cooperators) / self.n
        trend_adjustment = 0.0
        if len(window_cooperators) >= 2:
            recent = window_cooperators[-1]
            older = np.mean(window_cooperators[:-1])
            if recent > older:
                trend_adjustment = -0.05
            elif recent < older:
                trend_adjustment = 0.05
        theta_base = (self.k - 1) / (self.n - 1)
        endgame_pressure = (self.r - t) / self.r
        theta_adjustment = 0.15
        theta_endgame = theta_adjustment * endgame_pressure
        theta_dynamic = theta_base + theta_endgame + trend_adjustment
        if coop_rate >= theta_dynamic:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_382(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with individual security through adaptive
    reciprocity. Cooperates conditionally based on observed cooperation rates, with
    dynamic thresholds that increase over time and a reciprocity floor to prevent
    mutual defection spirals.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.beta = 0.35
        self.p_1 = 0.7

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        t = state.round_number
        if t == 0:
            return Action.C if random.random() < self.p_1 else Action.D
        if t == r - 1:
            coop_rate_prev = np.mean(history.opponent_actions[t - 1, :])
            if coop_rate_prev >= 0.5:
                return Action.C
            else:
                return Action.D
        coop_rate_prev = np.mean(history.opponent_actions[t - 1, :])
        threshold = self.beta + (1 - self.beta) * (t / r)
        if coop_rate_prev >= threshold:
            return Action.C
        else:
            return Action.C if random.random() < self.beta else Action.D

class Strategy_COLLECTIVE_383(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game

    Core principle: Contribute to the public good when cooperation rates suggest mutual
    benefit is achievable, but protect against free-riding by calibrating contributions
    to observed reciprocity levels using a threshold-based decision rule.

    Decision Logic:
    - Round 1: Always COOPERATE (establish cooperative baseline)
    - Subsequent rounds: COOPERATE if observed cooperation_rate >= k/n, else DEFECT
    - The threshold k/n represents the break-even point where public good contributions
      become individually rational given the payoff structure.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.k = game_description.k
        self.threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round_idx = state.round_number - 1
        opponent_cooperators = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        my_prev_action = int(history.my_actions[prev_round_idx])
        total_cooperators = opponent_cooperators + my_prev_action
        cooperation_rate = total_cooperators / self.n_players
        if cooperation_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_384(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with individual rationality by:
    1. Cooperating in round 1 to signal cooperative intent
    2. In middle rounds, cooperating if empirical cooperation rate >= k/n threshold
    3. In final round, cooperating only if cooperation has been sustained
    4. Defecting when cooperation rate is too low to justify contribution
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        coop_rate = self._calculate_cooperation_rate(history, current_round)
        rounds_remaining = self.n_rounds - current_round - 1
        if current_round == self.n_rounds - 1:
            if coop_rate >= self.threshold:
                return Action.C
            else:
                return Action.D
        elif coop_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the empirical cooperation rate across all players in previous rounds.

        coop_rate = total_cooperators / (n_players * rounds_elapsed)
        """
        rounds_elapsed = current_round
        my_cooperations = np.sum(history.my_actions[:current_round])
        opponent_cooperations = np.sum(history.opponent_actions[:current_round, :])
        total_cooperators = my_cooperations + opponent_cooperations
        total_possible = self.n_players * rounds_elapsed
        if total_possible == 0:
            return 0.0
        coop_rate = total_cooperators / total_possible
        return coop_rate

class Strategy_COLLECTIVE_385(BaseStrategy):
    """
    Adaptive Contribution with Conditional Defection (ACCD) strategy.

    Optimizes for collective welfare while remaining robust to exploitation.
    Uses historical cooperation rates to dynamically adjust contribution decisions,
    with special handling for first/last rounds and mid-game threshold calibration.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_high = 0.65
        self.threshold_medium = 0.4
        self.reciprocity_penalty = 0.0
        self.defection_streak = 0

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate the overall cooperation rate across all players and rounds."""
        rounds_played = len(history.my_actions)
        if rounds_played == 0:
            return 0.0
        total_cooperations = int(np.sum(history.my_actions)) + int(np.sum(history.opponent_actions))
        total_possible = self.game_description.n_players * rounds_played
        return total_cooperations / total_possible if total_possible > 0 else 0.0

    def _calculate_peer_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate of all other players (excluding self)."""
        rounds_played = len(history.my_actions)
        if rounds_played == 0:
            return 0.0
        total_peer_cooperations = int(np.sum(history.opponent_actions))
        total_peer_possible = (self.game_description.n_players - 1) * rounds_played
        return total_peer_cooperations / total_peer_possible if total_peer_possible > 0 else 0.0

    def _evaluate_sustainability(self, history: PlayerHistory) -> float:
        """
        Evaluate sustainability of cooperation.
        Returns difference between avg payoff when cooperating vs defecting.
        """
        rounds_played = len(history.my_actions)
        if rounds_played == 0:
            return 0.0
        cooperating_payoffs = []
        defecting_payoffs = []
        for round_idx in range(rounds_played):
            if history.my_actions[round_idx]:
                cooperating_payoffs.append(history.my_payoffs[round_idx])
            else:
                defecting_payoffs.append(history.my_payoffs[round_idx])
        avg_cooperating = np.mean(cooperating_payoffs) if cooperating_payoffs else 0.0
        avg_defecting = np.mean(defecting_payoffs) if defecting_payoffs else 0.0
        return float(avg_cooperating - avg_defecting)

    def _adjust_threshold_medium(self, sustainability: float, rounds_remaining: int) -> float:
        """Dynamically adjust threshold_medium based on sustainability and rounds remaining."""
        threshold = self.threshold_medium
        if sustainability < 0 and rounds_remaining < self.game_description.n_rounds / 2:
            threshold = min(0.5, threshold + 0.02)
        elif sustainability > 0.3 and rounds_remaining > self.game_description.n_rounds / 3:
            threshold = max(0.3, threshold - 0.02)
        return threshold

    def _apply_reciprocity_dampening(self, cooperation_rate: float, peer_cooperation_rate: float) -> float:
        """
        Apply reciprocity penalty if being exploited by free-riders.
        Returns adjusted cooperation threshold.
        """
        penalty = 0.0
        if peer_cooperation_rate < cooperation_rate - 0.1:
            penalty = 0.05
        return penalty

    def _should_cooperate_probabilistically(self, cooperation_rate: float, threshold_medium: float) -> bool:
        """Probabilistically decide cooperation for mixed strategy range."""
        if cooperation_rate <= threshold_medium:
            return False
        probability = cooperation_rate - threshold_medium
        return random.random() < probability

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperation_rate = self._calculate_cooperation_rate(history)
        peer_cooperation_rate = self._calculate_peer_cooperation_rate(history)
        sustainability = self._evaluate_sustainability(history)
        rounds_remaining = self.game_description.n_rounds - state.round_number
        self.threshold_medium = self._adjust_threshold_medium(sustainability, rounds_remaining)
        reciprocity_penalty = self._apply_reciprocity_dampening(cooperation_rate, peer_cooperation_rate)
        adjusted_threshold_medium = self.threshold_medium + reciprocity_penalty
        if state.round_number == self.game_description.n_rounds - 1:
            if cooperation_rate >= 0.5:
                return Action.C
            else:
                if not history.my_actions[-1]:
                    return Action.D
                return Action.D
        if cooperation_rate >= self.threshold_high:
            self.defection_streak = 0
            return Action.C
        elif cooperation_rate >= adjusted_threshold_medium:
            self.defection_streak = 0
            return Action.C if self._should_cooperate_probabilistically(cooperation_rate, adjusted_threshold_medium) else Action.D
        else:
            self.defection_streak += 1
            return Action.D

class Strategy_COLLECTIVE_386(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with individual rationality through graduated
    reciprocity. Cooperates in round 1, matches cooperation rates in middle rounds with
    stochastic reciprocal adjustments, and strategically handles the final round based on
    observed cooperation levels.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        cooperators_last_round = int(np.sum(history.opponent_actions[round_num - 1, :]))
        cooperation_rate = cooperators_last_round / self.n
        threshold = (self.k - 1) / self.k
        if round_num == self.r - 1:
            if cooperation_rate >= threshold:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= threshold:
            prob_cooperate = min(1.0, cooperation_rate + 0.1)
        elif cooperation_rate >= threshold * 0.6:
            prob_cooperate = cooperation_rate * 0.8
        else:
            prob_cooperate = 0.0
        if random.random() < prob_cooperate:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_387(BaseStrategy):
    """
    Adaptive Public Contribution with Decay (APCD) Strategy

    A collective welfare-focused strategy that uses adaptive reciprocity based on
    observed cooperation rates. Starts with cooperation, maintains it when sufficient,
    applies soft pressure during decline, and defects only when cooperation collapses.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        threshold_1 = self._get_threshold_1()
        threshold_2 = self._get_threshold_2()
        ccr = self._calculate_ccr(history, current_round)
        if current_round == self.r - 1:
            if ccr >= 0.5:
                return Action.C
            elif ccr >= threshold_2:
                return Action.C if random.random() < 0.5 else Action.D
            else:
                return Action.D
        if ccr >= threshold_1:
            return Action.C
        elif ccr >= threshold_2:
            remaining_rounds = self.r - current_round
            probability = ccr * (remaining_rounds / self.r)
            return Action.C if random.random() < probability else Action.D
        else:
            return Action.D

    def _get_threshold_1(self) -> float:
        """Determine threshold_1 based on game parameters."""
        base_threshold = 0.6
        if self.n == 2:
            base_threshold = 0.7
        elif self.n > 10:
            base_threshold = 0.65
        if self.k < 1.5:
            base_threshold = max(base_threshold, 0.7)
        return base_threshold

    def _get_threshold_2(self) -> float:
        """Determine threshold_2 based on game parameters."""
        base_threshold = 0.3
        if self.n == 2:
            base_threshold = 0.4
        elif self.n > 10:
            base_threshold = 0.35
        if self.k < 1.5:
            base_threshold = max(base_threshold, 0.4)
        return base_threshold

    def _calculate_ccr(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate Collective Cooperation Rate (CCR).
        CCR(t) = (total cooperators in rounds 0 to t-1) / (n  t)
        """
        if current_round == 0:
            return 0.0
        total_cooperators = 0
        for round_idx in range(current_round):
            if history.my_actions[round_idx]:
                total_cooperators += 1
            total_cooperators += sum(history.opponent_actions[round_idx, :])
        total_possible = self.n * current_round
        ccr = total_cooperators / total_possible if total_possible > 0 else 0.0
        return ccr

class Strategy_COLLECTIVE_388(BaseStrategy):
    """
    Adaptive Contribution with Decay and Threshold Monitoring.

    Balances collective value creation, rational self-protection, and robustness
    by using a cooperation threshold (1/k) to decide whether to cooperate or defect.
    Early rounds are patient; later rounds punish sustained low cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        threshold = 1.0 / self.k
        if round_num == self.r - 1:
            overall_coop_rate = np.mean(history.my_actions)
            if overall_coop_rate >= threshold:
                return Action.C
            else:
                return Action.D
        coop_count_prev = np.sum(history.opponent_actions[round_num - 1, :])
        coop_rate_prev = coop_count_prev / self.n
        if coop_rate_prev >= threshold:
            return Action.C
        elif round_num <= self.r / 2:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_389(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy

    Balances collective welfare maximization with individual rationality safeguards.
    Uses threshold-based adaptive contribution adjusted for observed cooperation rates,
    with special handling for early rounds, final rounds, and end-game phases.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        if round_t == 1:
            cooperators_r0 = sum(history.opponent_actions[0, :])
            defectors_r0 = self.n_players - 1 - cooperators_r0
            if defectors_r0 <= (self.n_players - 1) // 2:
                return Action.C
            else:
                return Action.D
        total_cooperators = 0
        for r in range(round_t):
            total_cooperators += sum(history.opponent_actions[r, :])
        cooperation_rate = total_cooperators / (round_t * (self.n_players - 1))
        if round_t <= self.n_rounds / 3:
            threshold = 0.6
        elif round_t <= 2 * self.n_rounds / 3:
            threshold = 0.7
        else:
            threshold = 0.8
        if round_t >= 3:
            recent_cooperators = sum(history.opponent_actions[round_t - 1, :])
            recent_rate = recent_cooperators / (self.n_players - 1)
            older_cooperators = sum(history.opponent_actions[round_t - 3, :])
            older_rate = older_cooperators / (self.n_players - 1)
            trend = recent_rate - older_rate
            if trend < -0.1:
                threshold += 0.1
            elif trend > 0.1:
                threshold -= 0.05
        if round_t == self.n_rounds - 1:
            threshold = max(threshold, 0.9)
        if round_t == self.n_rounds - 2:
            threshold = max(threshold, 0.75)
        elif round_t == self.n_rounds - 3:
            threshold = max(threshold, 0.7)
        expected_cooperators = (self.n_players - 1) * cooperation_rate + 1
        expected_public_good = expected_cooperators * (self.k / self.n_players)
        current_defection_rate = 1.0 - cooperation_rate
        if current_defection_rate > 0.4:
            current_round_cooperators = sum(history.opponent_actions[round_t - 1, :])
            current_round_rate = current_round_cooperators / (self.n_players - 1)
            if current_round_rate < 0.5:
                return Action.D
        if expected_public_good >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_390(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare by:
    1. Measuring collective health through observed cooperation rates
    2. Contributing conditionally based on public good funding
    3. Adapting thresholds as the game progresses
    4. Prioritizing mutual benefit over exploitation
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.base_threshold = self.k / self.n
        self.defection_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        last_round_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        cooperation_rate = last_round_cooperators / self.n
        progress_ratio = current_round / self.r
        if progress_ratio < 0.3:
            dynamic_threshold = max(0.3, self.base_threshold - 0.15)
        elif progress_ratio < 0.7:
            dynamic_threshold = max(0.35, self.base_threshold - 0.05)
        else:
            dynamic_threshold = min(0.8, self.base_threshold + 0.1)
        if self.n == 2:
            dynamic_threshold = self.base_threshold + 0.2
        if cooperation_rate == 0.0:
            self.defection_streak += 1
            if self.defection_streak < 2:
                return Action.D
            else:
                self.defection_streak = 0
                return Action.C
        else:
            self.defection_streak = 0
        if cooperation_rate == 1.0:
            return Action.C
        if cooperation_rate >= dynamic_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_391(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare by:
    - Cooperating in round 1 to establish trust
    - Adapting in rounds 2 to r-1 based on cooperation rate vs. threshold k/n
    - Defecting in the final round (subgame-perfect equilibrium)
    - Including forgiveness mechanism for brief defection spirals
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = game_description.k / game_description.n_players
        self.defection_window = False
        self.defection_window_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        total_cooperators = int(np.sum(history.my_actions[:current_round]))
        total_opponent_cooperators = int(np.sum(history.opponent_actions[:current_round, :]))
        total_cooperators += total_opponent_cooperators
        total_actions = self.n_players * current_round
        cooperation_rate = total_cooperators / total_actions
        if cooperation_rate >= self.threshold:
            self.defection_window = False
            self.defection_window_counter = 0
            return Action.C
        exploitation_index = (1 - cooperation_rate) * self.n_players
        if exploitation_index < 2:
            self.defection_window = False
            self.defection_window_counter = 0
            return Action.C
        if not self.defection_window:
            self.defection_window = True
            self.defection_window_counter = 0
        self.defection_window_counter += 1
        if self.defection_window_counter <= 2:
            return Action.D
        else:
            self.defection_window = False
            self.defection_window_counter = 0
            return Action.C

class Strategy_COLLECTIVE_392(BaseStrategy):
    """
    Adaptive Collective Contribution Strategy (ACCS)

    Balances collective welfare maximization with self-protection through graduated
    reciprocity. Cooperates in round 1, uses adaptive thresholds based on observed
    cooperation rates in subsequent rounds, and defects in the final round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.base_threshold = self.k / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        prev_round_idx = current_round - 1
        prev_opponent_actions = history.opponent_actions[prev_round_idx, :]
        prev_my_action = history.my_actions[prev_round_idx]
        total_cooperators_prev = int(prev_my_action) + int(np.sum(prev_opponent_actions))
        prev_cooperation_rate = total_cooperators_prev / self.n_players
        decay_factor = (self.n_rounds - 1) / self.n_rounds
        threshold = self.base_threshold * decay_factor ** (current_round - 1)
        if prev_cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_393(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game.

    Balances mutual benefit maximization, resilient reciprocity, and graceful degradation.
    Uses an adaptive threshold mechanism that responds to observed cooperation rates,
    cooperating when expected payoff exceeds a dynamically determined threshold.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_history = []
        self.recent_cooperation = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        my_last_action = history.my_actions[-1]
        opponent_cooperators_last_round = sum(history.opponent_actions[-1, :])
        total_cooperators_last_round = (1 if my_last_action else 0) + opponent_cooperators_last_round
        cooperation_rate_last_round = total_cooperators_last_round / n
        self.recent_cooperation = 0.9 * self.recent_cooperation + 0.1 * cooperation_rate_last_round
        if self.recent_cooperation >= k / n:
            threshold = (1.0 - k / n) * 0.95
        else:
            threshold = (1.0 - k / n) * 0.6
        expected_payoff_c = k / n * (1.0 + self.recent_cooperation * (n - 1))
        if expected_payoff_c >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_394(BaseStrategy):
    """
    Adaptive Graduated Reciprocity with Efficiency Thresholds.

    Balances individual security with collective welfare by:
    1. Cooperating in round 1 to establish baseline
    2. Using cooperation rate threshold (k/n) to decide subsequent rounds
    3. Adapting threshold upward if cooperation declines for 2+ consecutive rounds
    4. Following threshold rule in final round (no last-round defection)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.base_threshold = self.k / self.n_players
        self.threshold_tightened = False
        self.consecutive_low_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round_idx = state.round_number - 1
        my_previous_action = history.my_actions[previous_round_idx]
        opponent_previous_actions = history.opponent_actions[previous_round_idx, :]
        num_opponent_cooperators = int(np.sum(opponent_previous_actions))
        total_cooperators = num_opponent_cooperators + (1 if my_previous_action else 0)
        cooperation_rate = total_cooperators / self.n_players
        current_threshold = self.base_threshold
        if state.round_number >= 2:
            rate_t_minus_1 = cooperation_rate
            round_t_minus_2_idx = state.round_number - 2
            my_action_t_minus_2 = history.my_actions[round_t_minus_2_idx]
            opponent_actions_t_minus_2 = history.opponent_actions[round_t_minus_2_idx, :]
            num_opponent_coop_t_minus_2 = int(np.sum(opponent_actions_t_minus_2))
            total_coop_t_minus_2 = num_opponent_coop_t_minus_2 + (1 if my_action_t_minus_2 else 0)
            rate_t_minus_2 = total_coop_t_minus_2 / self.n_players
            if rate_t_minus_1 < self.base_threshold and rate_t_minus_2 < self.base_threshold:
                self.consecutive_low_rounds += 1
                if self.consecutive_low_rounds >= 2:
                    epsilon = min(0.1, self.base_threshold * 0.15)
                    current_threshold = self.base_threshold + epsilon
                    self.threshold_tightened = True
            else:
                self.consecutive_low_rounds = 0
                self.threshold_tightened = False
        if cooperation_rate >= current_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_395(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    This strategy balances collective welfare with defense against exploitation by:
    1. Starting with cooperation in round 1 to signal willingness and gather information
    2. Matching contributions based on a threshold: cooperate if cooperation_rate >= k/n
    3. Adapting dynamically to observed cooperation levels across rounds

    The threshold k/n represents the point where contributing becomes individually rational
    because the public good provides sufficient value to justify the endowment contribution.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.k = game_description.k
        self.threshold = self.k / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round_idx = state.round_number - 1
        opponent_cooperators = np.sum(history.opponent_actions[previous_round_idx, :])
        my_previous_action = history.my_actions[previous_round_idx]
        total_cooperators = opponent_cooperators + (1 if my_previous_action else 0)
        cooperation_rate = total_cooperators / self.n_players
        if cooperation_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_396(BaseStrategy):
    """
    Collective Adaptive Strategy for N-Player Public Goods Game.

    Uses conditional reciprocity with history-weighted cooperation assessment.
    Balances individual payoff maximization with collective welfare enhancement.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        if t == 0:
            return Action.C
        if t == self.r - 1:
            return Action.D
        window_size = min(3, t)
        recent_rounds_start = max(0, t - window_size)
        recent_window = history.opponent_actions[recent_rounds_start:t, :]
        cooperators_per_round = np.sum(recent_window, axis=1)
        avg_cooperation = np.mean(cooperators_per_round) / self.n
        threshold_high = self.k / self.n
        threshold_med = (self.k - 1) / 2.0 / self.n
        if avg_cooperation >= threshold_high:
            cooperation_prob = min(0.95, avg_cooperation)
        elif avg_cooperation >= threshold_med:
            cooperation_prob = 0.5 + 0.3 * avg_cooperation
        else:
            cooperation_prob = 0.3
        if random.random() < cooperation_prob:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_397(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Maximizes collective welfare while maintaining resilience against exploitation.
    Uses historical cooperation rates with dynamic thresholds based on volatility
    and time pressure to incentivize mutual cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        coop_rate = self._calculate_cooperation_rate(history, current_round)
        if current_round == self.r - 1:
            if coop_rate >= self.k / self.n:
                return Action.C
            else:
                return Action.D
        threshold = self._calculate_dynamic_threshold(history, current_round)
        if coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the empirical cooperation rate from all past rounds.
        cooperation_rate = total_cooperators / (n_players  rounds_completed)
        """
        if current_round == 0:
            return 0.0
        total_opponent_cooperations = float(np.sum(history.opponent_actions[:current_round, :]))
        total_our_cooperations = float(np.sum(history.my_actions[:current_round]))
        total_cooperations = total_opponent_cooperations + total_our_cooperations
        total_possible = self.n * current_round
        coop_rate = total_cooperations / total_possible if total_possible > 0 else 0.0
        return coop_rate

    def _calculate_dynamic_threshold(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate dynamic threshold: (k/n)  (1 + volatility_adjustment  time_pressure)

        volatility_adjustment = stdev(cooperation_by_round) / mean(cooperation_by_round)
        Capped between 0.1 and 0.3

        time_pressure = (r - round) / r
        """
        base_threshold = self.k / self.n
        coop_by_round = []
        for round_idx in range(current_round):
            round_coop = (float(np.sum(history.opponent_actions[round_idx, :])) + float(history.my_actions[round_idx])) / self.n
            coop_by_round.append(round_coop)
        if len(coop_by_round) > 1:
            mean_coop = float(np.mean(coop_by_round))
            if mean_coop > 0:
                std_coop = float(np.std(coop_by_round))
                volatility = std_coop / mean_coop
            else:
                volatility = 0.1
        else:
            volatility = 0.1
        volatility = max(0.1, min(0.3, volatility))
        time_pressure = (self.r - current_round) / self.r
        dynamic_threshold = base_threshold * (1.0 + volatility * time_pressure)
        return dynamic_threshold

class Strategy_COLLECTIVE_398(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare through:
    1. Initial exploration to gather information
    2. Adaptive reciprocity based on observed cooperation rates
    3. Strategic punishment of defectors
    4. Endgame optimization
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        exploration_rounds = max(1, math.ceil(0.1 * self.r))
        if round_num < exploration_rounds:
            return Action.C
        if round_num == self.r - 1:
            overall_coop_rate = self._calculate_overall_cooperation_rate(history)
            if overall_coop_rate >= self.k / self.n:
                return Action.C
            else:
                return Action.D
        return self._adaptive_reciprocity(history)

    def _calculate_overall_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate among opponents across all observed rounds."""
        if history.opponent_actions.shape[0] == 0:
            return 0.0
        total_cooperators = np.sum(history.opponent_actions)
        total_opportunities = history.opponent_actions.shape[0] * (self.n - 1)
        return float(total_cooperators) / float(total_opportunities) if total_opportunities > 0 else 0.0

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory, window: int=3) -> float:
        """Calculate cooperation rate among opponents in the last N rounds."""
        if history.opponent_actions.shape[0] == 0:
            return 0.0
        recent_actions = history.opponent_actions[-window:, :]
        total_cooperators = np.sum(recent_actions)
        total_opportunities = recent_actions.shape[0] * (self.n - 1)
        return float(total_cooperators) / float(total_opportunities) if total_opportunities > 0 else 0.0

    def _check_unanimous_defection(self, history: PlayerHistory) -> bool:
        """Check if all players defected in the last round."""
        if history.opponent_actions.shape[0] == 0:
            return False
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        return last_round_cooperators == 0

    def _adaptive_reciprocity(self, history: PlayerHistory) -> Action:
        """Apply adaptive reciprocity logic."""
        observed_coop_rate = self._calculate_overall_cooperation_rate(history)
        recent_coop_rate = self._calculate_recent_cooperation_rate(history, window=3)
        threshold = self.k / self.n
        if self.k > self.n * 0.8:
            threshold_buffer = threshold - 0.1
        elif self.k < self.n * 0.15:
            threshold_buffer = threshold + 0.05
        else:
            threshold_buffer = threshold - 0.05
        recent_threshold = threshold_buffer
        if self.n > 10:
            recent_threshold = threshold_buffer * 0.75
        if self._check_unanimous_defection(history):
            if random.random() < 0.05:
                return Action.C
            return Action.D
        if observed_coop_rate >= threshold:
            if recent_coop_rate >= recent_threshold:
                return Action.C
            elif recent_coop_rate >= recent_threshold * 0.7:
                return Action.C if random.random() < 0.6 else Action.D
            else:
                return Action.D
        elif observed_coop_rate >= threshold * 0.5:
            if recent_coop_rate >= threshold * 0.6:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_399(BaseStrategy):
    """
    Adaptive Contribution with Reciprocal Enforcement Strategy.

    Balances individual rationality with collective benefit through:
    - Unconditional cooperation in round 1 to establish trust
    - Adaptive response based on observed cooperation rates
    - Threshold-based decision making using break-even point k/n
    - Probabilistic defection in marginal states to test sustainability
    - Terminal defection in final round (backward induction)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.defection_threshold = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            return Action.D
        previous_round_idx = current_round - 1
        self_cooperated_last = history.my_actions[previous_round_idx]
        opponent_cooperators = np.sum(history.opponent_actions[previous_round_idx, :])
        total_cooperators = int(self_cooperated_last) + opponent_cooperators
        cooperation_rate = total_cooperators / self.n
        healthy_threshold = self.defection_threshold + 0.15
        marginal_upper = self.defection_threshold + 0.15
        marginal_lower = self.defection_threshold - 0.05
        degraded_threshold = self.defection_threshold * 0.5
        if cooperation_rate >= healthy_threshold:
            return Action.C
        elif cooperation_rate >= marginal_lower:
            if random.random() < 0.65:
                return Action.C
            else:
                return Action.D
        elif cooperation_rate >= degraded_threshold:
            if random.random() < 0.3:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_400(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game

    Balances collective value creation through cooperation with individual protection
    against exploitation. Uses conditional cooperation based on observed cooperation rates
    compared to a threshold derived from the multiplication factor.

    Core decision rule: Cooperate if the previous round's cooperation rate >= k/n,
    otherwise defect. Always cooperate in round 1 to establish trustworthiness.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_k = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round_idx = state.round_number - 1
        cooperators_prev_round = sum(history.opponent_actions[prev_round_idx, :])
        if history.my_actions[prev_round_idx]:
            cooperators_prev_round += 1
        cooperation_rate = cooperators_prev_round / self.game_description.n_players
        if cooperation_rate >= self.threshold_k:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_401(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy

    A collective strategy that seeks sustainable cooperation in public goods games
    through conditional contribution based on observed cooperation rates, with
    thresholds for maintaining cooperation, gradual incentivization, and protection
    against systemic exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.THRESHOLD_HIGH = 0.6
        self.THRESHOLD_MID = 0.3
        self.EMA_ALPHA = 0.3
        self.ema_coop_rate = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        last_round_idx = state.round_number - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[last_round_idx, :]))
        if history.my_actions[last_round_idx]:
            cooperators_last_round += 1
        current_coop_rate = cooperators_last_round / self.n
        if state.round_number == 1:
            self.ema_coop_rate = current_coop_rate
        else:
            self.ema_coop_rate = (1 - self.EMA_ALPHA) * self.ema_coop_rate + self.EMA_ALPHA * current_coop_rate
        if self.ema_coop_rate >= self.THRESHOLD_HIGH:
            return Action.C
        elif self.ema_coop_rate >= self.THRESHOLD_MID:
            return Action.C if random.random() < self.ema_coop_rate else Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_402(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Core principle: Cooperate when observed cooperation rate meets the theoretical
    breakeven threshold of k/n, where cooperation becomes mutually beneficial.
    - Round 0: Always cooperate (signal intent, gather information)
    - Rounds 1+: Cooperate if previous round's cooperation rate >= k/n, else defect
    - Final round: Apply same threshold rule (no endgame exploitation)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round_index = state.round_number - 1
        cooperators_previous_round = sum(history.opponent_actions[previous_round_index, :])
        my_action_previous = history.my_actions[previous_round_index]
        total_cooperators = cooperators_previous_round + (1 if my_action_previous else 0)
        cooperation_rate = total_cooperators / self.game_description.n_players
        if cooperation_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_403(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for N-Player Public Goods Game.

    Dynamically adjusts cooperation based on empirical evidence of whether cooperation
    generates positive-sum outcomes. Balances individual rationality with collective benefit
    through threshold-based decision rules and probabilistic cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.COLLAPSE_POINT = max(0.1, 1.0 / self.n)
        self.EXPLOITATION_THRESHOLD = 0.5
        self.PATIENCE_LIMIT = 2
        self.rounds_to_punish = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        my_actions = history.my_actions[:round_num]
        my_payoffs = history.my_payoffs[:round_num]
        opponent_actions = history.opponent_actions[:round_num, :]
        opponent_payoffs = history.opponent_payoffs[:round_num, :]
        lookback = min(5, round_num)
        recent_opponent_actions = opponent_actions[-lookback:, :]
        recent_opponent_payoffs = opponent_payoffs[-lookback:, :]
        my_recent_payoffs = my_payoffs[-lookback:]
        prev_round_cooperators = np.sum(opponent_actions[round_num - 1, :])
        cooperation_ratio = prev_round_cooperators / self.n
        if cooperation_ratio == 0:
            return Action.D
        avg_payoff_cooperators = self._get_avg_payoff_by_action(recent_opponent_actions, recent_opponent_payoffs, cooperated=True)
        avg_payoff_defectors = self._get_avg_payoff_by_action(recent_opponent_actions, recent_opponent_payoffs, cooperated=False)
        if avg_payoff_defectors > 0 and avg_payoff_cooperators > 0:
            exploitation_ratio = avg_payoff_defectors / avg_payoff_cooperators
            if exploitation_ratio > 1 + self.EXPLOITATION_THRESHOLD:
                self.rounds_to_punish += 1
        else:
            self.rounds_to_punish = max(0, self.rounds_to_punish - 1)
        if self.rounds_to_punish >= self.PATIENCE_LIMIT:
            self.rounds_to_punish = 0
            return Action.D
        critical_threshold = self.k / (self.n - 1) if self.n > 1 else self.k
        if cooperation_ratio >= critical_threshold:
            return Action.C
        if self.k / self.n > 1 and avg_payoff_cooperators > avg_payoff_defectors:
            return Action.C
        if cooperation_ratio > self.COLLAPSE_POINT:
            prob_cooperate = (cooperation_ratio - self.COLLAPSE_POINT) / (critical_threshold - self.COLLAPSE_POINT)
            prob_cooperate = max(0, min(1, prob_cooperate))
            if random.random() < prob_cooperate:
                return Action.C
        return Action.D

    def _get_avg_payoff_by_action(self, opponent_actions: NDArray[np.bool_], opponent_payoffs: NDArray[np.float64], cooperated: bool) -> float:
        """
        Calculate average payoff of opponents who cooperated (or defected) in recent rounds.

        Args:
            opponent_actions: Shape (rounds, opponents), boolean array
            opponent_payoffs: Shape (rounds, opponents), float array
            cooperated: True to get avg of cooperators, False for defectors

        Returns:
            Average payoff, or 0 if no matching actions found
        """
        if opponent_actions.size == 0:
            return 0.0
        mask = opponent_actions == cooperated
        if not np.any(mask):
            return 0.0
        matching_payoffs = opponent_payoffs[mask]
        return float(np.mean(matching_payoffs))

class Strategy_COLLECTIVE_404(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization, robust self-defense against exploiters,
    and adaptive exploration to discover viable collective equilibria.

    Key phases:
    1. Exploration (first r/4 rounds): Unconditional cooperation to gather information
    2. Adaptation (middle rounds): Conditional cooperation based on observed cooperation rates
    3. Endgame (last 2 rounds): Cooperate if viable, defect in final round
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        exploration_rounds = math.ceil(self.n_rounds / 4)
        if round_num < exploration_rounds:
            return Action.C
        endgame_start = max(self.n_rounds - 2, self.n_rounds - exploration_rounds)
        if round_num == self.n_rounds - 1:
            return Action.D
        if round_num >= endgame_start:
            coop_rate = self._get_cooperation_rate(history, round_num - 1)
            threshold_high = self._calculate_threshold_high()
            if coop_rate >= threshold_high:
                return Action.C
            else:
                return Action.D
        coop_rate = self._get_cooperation_rate(history, round_num - 1)
        threshold_high = self._calculate_threshold_high()
        threshold_low = 0.3
        if coop_rate >= threshold_high:
            return Action.C
        elif coop_rate >= threshold_low:
            contribution_benefit = self.k / self.n_players * coop_rate * self.n_players
            if contribution_benefit >= 0.6:
                prob_cooperate = min(0.7, coop_rate + 0.2)
                if random.random() < prob_cooperate:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D
        else:
            return Action.D

    def _get_cooperation_rate(self, history: PlayerHistory, round_idx: int) -> float:
        """Calculate the cooperation rate in a given round."""
        if round_idx < 0 or round_idx >= len(history.opponent_actions):
            return 0.0
        opponent_cooperators = sum(history.opponent_actions[round_idx, :])
        total_cooperators = opponent_cooperators
        if round_idx < len(history.my_actions) and history.my_actions[round_idx]:
            total_cooperators += 1
        return total_cooperators / self.n_players

    def _calculate_threshold_high(self) -> float:
        """Calculate dynamic threshold_high based on game parameters."""
        base_threshold = 0.5 + (self.k - 1) / (2 * self.n_players)
        if self.n_players > 20:
            base_threshold = 0.6
        if self.k > self.n_players * 0.9:
            base_threshold = max(0.3, base_threshold - 0.1)
        if self.k < 1.2:
            base_threshold = min(0.7, base_threshold + 0.2)
        if self.n_players <= 3:
            base_threshold = 0.5
        return base_threshold

class Strategy_COLLECTIVE_405(BaseStrategy):
    """
    Adaptive Reciprocal Threshold (ART) Strategy for N-Player Public Goods Game.

    Balances collective welfare with self-protection through:
    1. Opening with cooperation to establish goodwill
    2. Dynamic threshold that increases pressure as rounds progress
    3. Reciprocal responses: cooperate when cooperation rate justifies it
    4. Break-even protection: defect when cooperation falls below k/n
    5. Final-round extraction based on historical cooperation
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.break_even = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        cooperators_prev = np.sum(history.opponent_actions[prev_round_idx, :])
        cooperation_rate_prev = cooperators_prev / self.n
        if current_round == self.r - 1:
            total_cooperators = np.sum(history.opponent_actions)
            total_rounds_completed = current_round
            avg_cooperation_rate = total_cooperators / (total_rounds_completed * self.n)
            if avg_cooperation_rate >= self.break_even:
                return Action.C
            else:
                return Action.D
        progress = (current_round - 1) / (self.r - 2)
        threshold = self.break_even + (1 - self.break_even) * progress
        if cooperation_rate_prev >= threshold:
            return Action.C
        elif cooperation_rate_prev >= self.break_even:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_406(BaseStrategy):
    """
    Adaptive Reciprocal Maximization (ARM) Strategy for N-Player Public Goods Game.

    Balances collective welfare, self-protection, and robustness by:
    1. Signaling cooperative intent in round 1
    2. Exploring opponent cooperation rates in early rounds
    3. Adapting reciprocal strategy based on observed patterns
    4. Intensifying strategy in endgame based on cumulative cooperation
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.exploration_end = max(1, math.floor(self.n_rounds / 4))
        self.adaptation_end = max(2, math.floor(3 * self.n_rounds / 4))
        self.cooperation_threshold = self.k / self.n_players
        self.defection_detection_threshold = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_idx = round_num - 1
        opponent_cooperators = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        total_cooperators = int(history.my_actions[prev_round_idx]) + opponent_cooperators
        estimated_group_coop_rate = total_cooperators / self.n_players
        if round_num <= self.exploration_end:
            if estimated_group_coop_rate >= self.cooperation_threshold:
                return Action.C
            elif estimated_group_coop_rate >= 0.5:
                return Action.C
            else:
                return Action.D
        elif round_num <= self.adaptation_end:
            observed_cooperation = estimated_group_coop_rate
            if observed_cooperation >= self.cooperation_threshold:
                return Action.C
            elif observed_cooperation >= 0.4:
                if random.random() < observed_cooperation:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D
        else:
            all_total_cooperators = np.sum(history.my_actions[:round_num]) + np.sum(history.opponent_actions[:round_num, :])
            avg_group_cooperation = all_total_cooperators / (round_num * self.n_players)
            recent_rounds = min(2, round_num)
            recent_coop_rates = []
            for i in range(round_num - recent_rounds, round_num):
                round_total_coop = int(history.my_actions[i]) + int(np.sum(history.opponent_actions[i, :]))
                recent_coop_rates.append(round_total_coop / self.n_players)
            if all((rate < self.defection_detection_threshold for rate in recent_coop_rates)):
                return Action.D
            if avg_group_cooperation >= self.cooperation_threshold + 0.1:
                return Action.C
            elif avg_group_cooperation >= self.cooperation_threshold:
                if random.random() < avg_group_cooperation:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D

class Strategy_COLLECTIVE_407(BaseStrategy):
    """
    Adaptive Conditional Reciprocity with Decay (ACRD)

    Balances collective welfare maximization, self-protection against exploitation,
    and adaptive learning. Uses conditional cooperation based on historical cooperation
    rates with decay-adjusted thresholds that become stricter in later rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold_maintain = self.k / self.n
        self.threshold_attempt = self.k / self.n * 0.6

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        previous_round_idx = current_round - 1
        cooperators_previous = sum(history.opponent_actions[previous_round_idx, :])
        my_action_previous = history.my_actions[previous_round_idx]
        total_cooperators_previous = cooperators_previous + (1 if my_action_previous else 0)
        coop_rate_prev = total_cooperators_previous / self.n
        if current_round == self.r - 1:
            if coop_rate_prev >= self.threshold_maintain:
                return Action.C
            else:
                return Action.D
        if current_round == 1:
            if coop_rate_prev >= 0.5:
                return Action.C
            else:
                return Action.D
        remaining_rounds = self.r - current_round
        decay = math.sqrt(remaining_rounds / self.r)
        adjusted_threshold = self.threshold_maintain + 0.1 * decay
        if coop_rate_prev >= adjusted_threshold:
            return Action.C
        elif coop_rate_prev >= self.threshold_attempt:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_408(BaseStrategy):
    """
    Adaptive Reciprocal Threshold (ART) Strategy for N-Player Public Goods Game.

    Pursues conditional cooperation with adaptive thresholds, balancing individual
    rationality, collective welfare, robustness, and adaptivity. Cooperates initially,
    then adjusts based on observed cooperation rates and an adaptive threshold that
    accounts for game timeline and cooperation trends.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if self.k / self.n <= 1.0:
            return Action.D
        cooperation_rates = self._calculate_cooperation_rates(history, round_num)
        recent_coop = cooperation_rates['recent']
        historical_coop = cooperation_rates['historical']
        threshold = self._calculate_threshold(round_num, recent_coop, historical_coop)
        if recent_coop == 0.0:
            if round_num < self.r / 2:
                return Action.C
            else:
                return Action.D
        if recent_coop >= threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rates(self, history: PlayerHistory, round_num: int):
        """
        Calculate recent and historical cooperation rates from opponent actions.
        Recent = exponentially weighted average of last 3 rounds.
        Historical = average of all prior rounds.
        """
        opponent_actions = history.opponent_actions
        recent_coop = 0.0
        recent_count = 0
        weights = [0.5, 0.25, 0.25]
        for i in range(min(3, round_num)):
            past_round = round_num - 1 - i
            cooperators_in_round = np.sum(opponent_actions[past_round, :])
            coop_rate = cooperators_in_round / self.n
            recent_coop += coop_rate * weights[i]
            recent_count += 1
        if recent_count > 0:
            recent_coop = recent_coop / recent_count
        else:
            recent_coop = 0.0
        historical_coop = 0.0
        if round_num > 0:
            total_cooperators = 0
            for t in range(round_num):
                total_cooperators += np.sum(opponent_actions[t, :])
            historical_coop = total_cooperators / (self.n * round_num)
        else:
            historical_coop = 0.0
        return {'recent': recent_coop, 'historical': historical_coop}

    def _calculate_threshold(self, round_num: int, recent_coop: float, historical_coop: float):
        """
        Calculate adaptive cooperation threshold.

        threshold = base_threshold + timeline_adjustment - trend_adjustment

        base_threshold = k/n
        timeline_adjustment = (remaining_rounds / total_rounds) * 0.15
        trend_adjustment = (recent_coop - historical_coop) * 0.1
        """
        base_threshold = self.k / self.n
        remaining_rounds = self.r - round_num
        timeline_adjustment = remaining_rounds / self.r * 0.15
        trend_adjustment = (recent_coop - historical_coop) * 0.1
        threshold = base_threshold + timeline_adjustment - trend_adjustment
        threshold = max(threshold, base_threshold)
        threshold = min(threshold, 0.95)
        return threshold

class Strategy_COLLECTIVE_409(BaseStrategy):
    """
    Reciprocal Commons Stewardship: A balanced strategy for N-player public goods games
    that adapts cooperation based on historical group cooperation rates, with built-in
    mechanisms for exploitation avoidance and recovery signaling.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_high = 0.65
        self.threshold_mid = 0.35
        self.threshold_low = 0.1
        self.p_mid = 0.6
        self.recent_window = 3
        self.recent_weight = 0.6
        self.overall_weight = 0.4
        self.exploitation_threshold = -0.2
        self.recovery_threshold = 0.25

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        total_cooperators = int(np.sum(history.my_actions)) + int(np.sum(history.opponent_actions))
        total_player_rounds = self.game_description.n_players * state.round_number
        overall_coop_rate = total_cooperators / total_player_rounds if total_player_rounds > 0 else 0.0
        recent_rounds = min(self.recent_window, state.round_number)
        recent_start_idx = state.round_number - recent_rounds
        recent_cooperators = 0
        for i in range(recent_start_idx, state.round_number):
            recent_cooperators += int(history.my_actions[i])
            recent_cooperators += int(np.sum(history.opponent_actions[i, :]))
        recent_coop_rate = recent_cooperators / (self.game_description.n_players * recent_rounds) if recent_rounds > 0 else 0.0
        decision_metric = self.recent_weight * recent_coop_rate + self.overall_weight * overall_coop_rate
        if state.round_number > 1 and history.my_actions[-1]:
            prev_cooperators = int(np.sum(history.my_actions[:-1])) + int(np.sum(history.opponent_actions[:-1, :]))
            prev_total_rounds = self.game_description.n_players * (state.round_number - 1)
            prev_coop_rate = prev_cooperators / prev_total_rounds if prev_total_rounds > 0 else 0.0
            coop_change = decision_metric - prev_coop_rate
            if coop_change < self.exploitation_threshold:
                return Action.D
        if decision_metric >= self.threshold_high:
            return Action.C
        elif decision_metric >= self.threshold_mid:
            return Action.C if random.random() < self.p_mid else Action.D
        elif decision_metric >= self.threshold_low:
            return Action.D
        elif state.round_number > 1 and decision_metric >= self.recovery_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_410(BaseStrategy):
    """
    Adaptive Threshold Cooperation with Progressive Defection.

    Cooperates when the cooperation rate from the previous round meets or exceeds
    the threshold k/n (the breakeven point). Otherwise defects. Always cooperates
    in round 1 to establish cooperative intent and gather information.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.threshold = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round_index = state.round_number - 1
        my_previous_action = history.my_actions[previous_round_index]
        my_contribution = 1 if my_previous_action else 0
        opponent_contributions = sum(history.opponent_actions[previous_round_index, :])
        total_cooperators = my_contribution + opponent_contributions
        coop_rate = total_cooperators / self.n
        if coop_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_411(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game

    Balances collective welfare maximization, defensive rationality, and adaptive learning.
    - Round 0: Cooperate (optimistic initialization)
    - Rounds 1 to r-2: Adaptive reciprocation based on opponent cooperation rate
    - Round r-1: Cooperate (final-round grace)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_high = 0.6
        self.threshold_medium = 0.3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C
        cooperators_last_round = np.sum(history.opponent_actions[state.round_number - 1, :])
        opponent_cooperation = cooperators_last_round / (self.game_description.n_players - 1)
        rounds_remaining = self.game_description.n_rounds - state.round_number
        total_rounds = self.game_description.n_rounds
        if opponent_cooperation >= self.threshold_high:
            return Action.C
        elif opponent_cooperation >= self.threshold_medium:
            if random.random() < opponent_cooperation:
                return Action.C
            else:
                return Action.D
        elif rounds_remaining > 0.3 * total_rounds:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_412(BaseStrategy):
    """
    Adaptive Graduated Reciprocity with Collective Welfare Optimization.

    Balances individual rationality with collective welfare by:
    1. Cooperating in round 1 to signal good intent
    2. Adapting based on observed cooperation rates with graduated thresholds
    3. Defecting in the final round (backward induction)
    4. Using stochastic mixing in intermediate zones to maintain flexibility
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.critical_value = self.k / self.n
        self.cooperation_threshold = self.critical_value + 0.15
        self.defection_threshold = self.critical_value - 0.15

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            return Action.D
        previous_round_idx = current_round - 1
        opponent_cooperations_last_round = sum(history.opponent_actions[previous_round_idx, :])
        observed_cooperation_rate = opponent_cooperations_last_round / self.n
        if observed_cooperation_rate >= self.cooperation_threshold:
            return Action.C
        elif observed_cooperation_rate < self.defection_threshold:
            return Action.D
        elif random.random() < observed_cooperation_rate:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_413(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game

    Balances collective welfare maximization, individual security, and adaptive robustness
    through dynamic threshold-based cooperation that responds to observed cooperation rates
    and applies gentle punishment for persistent defection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.base_threshold = self.k / self.n
        self.threshold_decay = self.base_threshold / 2.0
        self.punishment_counter = 0

    def _smoothed_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """Calculate smoothed cooperation rate using exponential smoothing."""
        if current_round == 0:
            return 0.0
        recent_coop = float(np.sum(history.opponent_actions[current_round - 1, :]))
        recent_rate = recent_coop / self.n
        if current_round >= 2:
            prev_coop = float(np.sum(history.opponent_actions[current_round - 2, :]))
            prev_rate = prev_coop / self.n
            smoothed = 0.7 * recent_rate + 0.3 * prev_rate
            return smoothed
        return recent_rate

    def _get_observed_cooperation_rate(self, history: PlayerHistory, round_index: int) -> float:
        """Get the observed cooperation rate for a specific round."""
        if round_index < 0 or round_index >= len(history.opponent_actions):
            return 0.0
        cooperators = float(np.sum(history.opponent_actions[round_index, :]))
        return cooperators / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            if self.base_threshold >= 0.5:
                return Action.C
            else:
                return Action.D
        if current_round == self.r - 1:
            recent_coop_rate = self._get_observed_cooperation_rate(history, current_round - 1)
            if recent_coop_rate > 0.25:
                return Action.C
            else:
                return Action.D
        smoothed_coop_rate = self._smoothed_cooperation_rate(history, current_round)
        dynamic_threshold = self.base_threshold - current_round / self.r * self.threshold_decay
        if self.punishment_counter >= 2:
            self.punishment_counter = 0
            return Action.D
        if current_round >= 1:
            my_prev_action = history.my_actions[current_round - 1]
            if my_prev_action:
                if smoothed_coop_rate < self.base_threshold:
                    self.punishment_counter += 1
            else:
                self.punishment_counter = 0
        if smoothed_coop_rate >= dynamic_threshold:
            self.punishment_counter = 0
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_414(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game

    Core principle: Cooperate when the observed cooperation rate meets or exceeds the
    threshold k/n, which is the minimum cooperation level where mutual cooperation is
    individually rational. This balances individual incentives with collective welfare.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round_opponent_actions = history.opponent_actions[-1, :]
        opponent_cooperators = sum(previous_round_opponent_actions)
        my_previous_action = history.my_actions[-1]
        total_cooperators = opponent_cooperators + (1 if my_previous_action else 0)
        cooperation_rate = total_cooperators / self.game_description.n_players
        if cooperation_rate >= self.cooperation_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_415(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy.

    A collective-minded strategy that maximizes group welfare by:
    1. Starting with unconditional cooperation (round 1)
    2. Tracking historical cooperation rates across phases
    3. Calibrating thresholds based on game parameters and phase
    4. Gracefully defecting when cooperation is unsustainable
    5. Following endgame protocol (defect in final round)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        hcr = self._calculate_hcr(history, round_number)
        phase_1_end = math.ceil(self.r / 4)
        phase_2_end = math.ceil(3 * self.r / 4)
        threshold = self._get_threshold(round_number, phase_1_end, phase_2_end, hcr)
        if hcr < 0.1 and round_number > self.r / 4:
            return Action.D
        if hcr >= threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_hcr(self, history: PlayerHistory, round_number: int) -> float:
        """
        Calculate Historical Cooperation Rate (HCR).
        HCR = average fraction of players who cooperated in all previous rounds.
        """
        if round_number == 0:
            return 0.0
        total_cooperators = 0
        for round_idx in range(round_number):
            if history.my_actions[round_idx]:
                total_cooperators += 1
            total_cooperators += np.sum(history.opponent_actions[round_idx, :])
        total_player_rounds = round_number * self.n
        hcr = total_cooperators / total_player_rounds
        return hcr

    def _get_threshold(self, round_number: int, phase_1_end: int, phase_2_end: int, hcr: float) -> float:
        """
        Determine cooperation threshold based on game phase.
        """
        if round_number <= phase_1_end:
            return 0.3
        elif round_number <= phase_2_end:
            base_threshold = self.n / self.k * 0.6
            threshold = max(0.35, min(0.75, base_threshold))
            return threshold
        elif round_number == self.r - 1:
            return 0.5
        else:
            return 0.6

class Strategy_COLLECTIVE_416(BaseStrategy):
    """
    Adaptive Reciprocal Thresholding (ART): A strategy that balances collective welfare
    maximization with individual incentive compatibility through reciprocal cooperation
    based on observed cooperation rates and adaptive thresholding.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.break_even_threshold = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            return Action.D
        if current_round >= self.r - 2:
            avg_cooperation = self._compute_average_cooperation(history, current_round)
            if avg_cooperation >= self.break_even_threshold * 1.5:
                return Action.C
            else:
                return Action.D
        cooperation_rate = self._get_cooperation_rate(history, current_round)
        if cooperation_rate >= self.break_even_threshold:
            if random.random() < cooperation_rate:
                return Action.C
            else:
                return Action.D
        else:
            defection_prob = 1.0 - cooperation_rate / self.break_even_threshold
            if random.random() < defection_prob:
                return Action.D
            else:
                return Action.C

    def _get_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Compute the cooperation rate from the last round.
        Returns fraction of players (including self) who cooperated.
        """
        if current_round == 0:
            return 1.0
        last_round_idx = current_round - 1
        opponent_cooperators = sum(history.opponent_actions[last_round_idx, :])
        my_cooperation = 1 if history.my_actions[last_round_idx] else 0
        total_cooperators = opponent_cooperators + my_cooperation
        cooperation_rate = total_cooperators / self.n
        return cooperation_rate

    def _compute_average_cooperation(self, history: PlayerHistory, current_round: int) -> float:
        """
        Compute average cooperation rate over the last 3 rounds (or fewer if unavailable).
        """
        start_round = max(0, current_round - 2)
        end_round = current_round
        if start_round >= end_round:
            return 1.0
        cooperation_rates = []
        for round_idx in range(start_round, end_round):
            opponent_cooperators = sum(history.opponent_actions[round_idx, :])
            my_cooperation = 1 if history.my_actions[round_idx] else 0
            total_cooperators = opponent_cooperators + my_cooperation
            cooperation_rate = total_cooperators / self.n
            cooperation_rates.append(cooperation_rate)
        if not cooperation_rates:
            return 1.0
        return sum(cooperation_rates) / len(cooperation_rates)

class Strategy_COLLECTIVE_417(BaseStrategy):
    """
    Adaptive Reciprocal Stewardship (ARS) Strategy for N-Player Public Goods Game

    Balances collective welfare, self-protection, and adaptive learning through three phases:
    - Exploration: Test cooperation viability with threshold-based reciprocation
    - Exploitation: Adapt probabilistically based on rolling cooperation statistics
    - Endgame: Commit to cooperation if sustained, else defect
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def _classify_phase(self, round_number: int) -> str:
        """Classify current round into exploration, exploitation, or endgame phase"""
        exploration_end = math.ceil(self.r / 4)
        exploitation_end = math.ceil(3 * self.r / 4)
        if round_number < exploration_end:
            return 'exploration'
        elif round_number < exploitation_end:
            return 'exploitation'
        else:
            return 'endgame'

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate from all previous rounds"""
        if history.opponent_actions.shape[0] == 0:
            return 0.0
        total_cooperators = np.sum(history.opponent_actions)
        total_actions = history.opponent_actions.shape[0] * self.n
        return float(total_cooperators) / total_actions if total_actions > 0 else 0.0

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate from recent rounds (rolling window)"""
        if history.opponent_actions.shape[0] == 0:
            return 0.0
        window_size = max(1, self.r // 8)
        recent_rounds = history.opponent_actions[-window_size:, :]
        total_cooperators = np.sum(recent_rounds)
        total_actions = recent_rounds.shape[0] * self.n
        return float(total_cooperators) / total_actions if total_actions > 0 else 0.0

    def _calculate_cooperation_consistency(self, history: PlayerHistory) -> float:
        """Calculate consistency (inverse of std dev) of cooperation rates per round"""
        if history.opponent_actions.shape[0] < 2:
            return 1.0
        window_size = max(1, self.r // 8)
        recent_rounds = history.opponent_actions[-window_size:, :]
        round_coop_rates = np.sum(recent_rounds, axis=1) / self.n
        if len(round_coop_rates) < 2:
            return 1.0
        std_dev = float(np.std(round_coop_rates))
        return 1.0 / (1.0 + std_dev)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        """Decide action based on current phase and history"""
        if state.round_number == 0:
            return Action.C
        if state.round_number == 1:
            opponent_cooperated_r0 = np.any(history.opponent_actions[0, :])
            if opponent_cooperated_r0:
                return Action.C
            else:
                return Action.D
        c_rate = self._calculate_cooperation_rate(history)
        threshold = (self.k - 1) / self.k
        phase = self._classify_phase(state.round_number)
        if phase == 'exploration':
            if c_rate >= threshold:
                return Action.C
            else:
                return Action.D
        elif phase == 'exploitation':
            recent_c_rate = self._calculate_recent_cooperation_rate(history)
            consistency = self._calculate_cooperation_consistency(history)
            if recent_c_rate > threshold + 0.15:
                return Action.C
            elif recent_c_rate > threshold - 0.1:
                p_cooperate = recent_c_rate
                if random.random() < p_cooperate:
                    return Action.C
                else:
                    return Action.D
            elif recent_c_rate > 0.2 and consistency > 0.6:
                return Action.D
            else:
                return Action.D
        else:
            recent_c_rate = self._calculate_recent_cooperation_rate(history)
            if recent_c_rate > 0.6:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_418(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game

    Implements conditional reciprocity based on:
    - Expected payoff thresholds
    - Recent cooperation rates
    - Temporal dynamics (special handling for round 1 and final rounds)

    Cooperates when collective value creation is sustainable and others reciprocate.
    Defects strategically to avoid exploitation while maintaining cooperative potential.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num >= self.r - 2:
            return Action.D
        cooperators_last_round = np.sum(history.opponent_actions[round_num - 1, :])
        payoff_if_coop = self.k / self.n * (cooperators_last_round + 1)
        payoff_if_defect = 1.0 + self.k / self.n * cooperators_last_round
        coop_threshold = (self.n - 1) / self.n * (self.k / (self.n - self.k))
        payoff_threshold = 0.5 * (1.0 + self.k)
        window_size = max(3, math.floor(self.r / 4))
        start_idx = max(0, round_num - window_size)
        recent_actions = history.opponent_actions[start_idx:round_num, :]
        recent_coop_count = np.sum(recent_actions)
        recent_total_actions = recent_actions.shape[0] * recent_actions.shape[1]
        recent_coop_rate = recent_coop_count / recent_total_actions if recent_total_actions > 0 else 0.0
        if payoff_if_coop >= payoff_threshold and recent_coop_rate >= coop_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_419(BaseStrategy):
    """
    Adaptive Contribution with Regret Minimization (ACRM).

    Balances collective welfare maximization with protection against exploitation.
    Uses regret-minimized approach tracking cooperation vs defection value, adjusting
    behavior based on empirical evidence of others' behavior patterns.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.coop_threshold = math.ceil(self.n / self.k)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        total_rounds_completed = round_number
        total_other_actions = history.opponent_actions[:round_number, :]
        total_opponent_cooperations = np.sum(total_other_actions)
        other_coop_rate = total_opponent_cooperations / (self.n - 1) / total_rounds_completed
        expected_other_cooperators = math.floor(other_coop_rate * (self.n - 1))
        expected_cooperators = 1 + expected_other_cooperators
        if expected_cooperators < self.coop_threshold:
            return Action.D
        my_actions = history.my_actions[:round_number]
        my_payoffs = history.my_payoffs[:round_number]
        opponent_actions = history.opponent_actions[:round_number, :]
        exploitation_count = 0
        for t in range(round_number):
            if my_actions[t]:
                others_cooperated = np.sum(opponent_actions[t, :])
                total_cooperators_t = 1 + others_cooperated
                coop_payoff = self.k / self.n * total_cooperators_t
                defect_payoff = 1.0 + self.k / self.n * others_cooperated
                if defect_payoff > coop_payoff:
                    exploitation_count += 1
        exploitation_rate = exploitation_count / total_rounds_completed
        if exploitation_rate > 0.7:
            return Action.D
        elif exploitation_rate > 0.4:
            others_cooperated_now = expected_other_cooperators
            coop_payoff_projected = self.k / self.n * expected_cooperators
            defect_payoff_projected = 1.0 + self.k / self.n * others_cooperated_now
            deficit = defect_payoff_projected - coop_payoff_projected
            if deficit < 0.3:
                return Action.C
            else:
                return Action.D
        if round_number == self.r - 1:
            if other_coop_rate >= 0.5:
                return Action.C
            else:
                return Action.D
        return Action.C

class Strategy_COLLECTIVE_420(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare with robust protection against exploitation through
    dynamic threshold-based reciprocal cooperation. Cooperates when recent cooperation
    rate meets or exceeds an adaptive threshold that accounts for game structure (k, n)
    and game phase (early/mid/late).
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.previous_cooperation_rate = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        lookback_window = min(5, round_number)
        start_idx = max(0, round_number - lookback_window)
        total_cooperators = 0
        for r in range(start_idx, round_number):
            if history.my_actions[r]:
                total_cooperators += 1
            total_cooperators += sum(history.opponent_actions[r, :])
        total_slots = self.n_players * lookback_window
        recent_cooperation_rate = total_cooperators / total_slots if total_slots > 0 else 0.0
        if self.k > 1.5:
            base_threshold = 0.4
        elif self.k > 1.1:
            base_threshold = 0.5
        else:
            base_threshold = 0.6
        phase_progress = round_number / self.n_rounds
        if phase_progress < 0.1:
            phase_adjustment = -0.1
        elif phase_progress > 0.8:
            phase_adjustment = 0.1
        else:
            phase_adjustment = 0.0
        cooperation_threshold = base_threshold + phase_adjustment
        if round_number == self.n_rounds - 1:
            if recent_cooperation_rate >= 0.85:
                return Action.C
            else:
                return Action.D
        cooperation_rise = recent_cooperation_rate - self.previous_cooperation_rate
        if recent_cooperation_rate >= 0.75 and cooperation_rise >= 0.1:
            self.previous_cooperation_rate = recent_cooperation_rate
            return Action.C
        if round_number >= 1:
            prev_start_idx = max(0, round_number - 1 - lookback_window)
            prev_total_cooperators = 0
            for r in range(prev_start_idx, round_number - 1):
                if history.my_actions[r]:
                    prev_total_cooperators += 1
                prev_total_cooperators += sum(history.opponent_actions[r, :])
            prev_cooperation_rate = prev_total_cooperators / (self.n_players * lookback_window) if self.n_players * lookback_window > 0 else 0.0
            defection_drop = prev_cooperation_rate - recent_cooperation_rate
            if defection_drop >= 0.2:
                self.previous_cooperation_rate = recent_cooperation_rate
                return Action.D
        if recent_cooperation_rate >= cooperation_threshold:
            self.previous_cooperation_rate = recent_cooperation_rate
            return Action.C
        else:
            self.previous_cooperation_rate = recent_cooperation_rate
            return Action.D

class Strategy_COLLECTIVE_421(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare through:
    - Unconditional cooperation in round 1 (information gathering)
    - Unconditional defection in final round (backward induction)
    - Adaptive probabilistic reciprocity in middle rounds based on observed cooperation rate
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        marginal_return = self.k / self.n_players
        self.threshold_high = marginal_return + 0.1
        self.threshold_medium = marginal_return - 0.1
        self.threshold_low = marginal_return * 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        previous_round_index = current_round - 1
        cooperators_previous = int(np.sum(history.opponent_actions[previous_round_index, :]))
        if history.my_actions[previous_round_index]:
            cooperators_previous += 1
        cooperation_rate = cooperators_previous / self.n_players
        if cooperation_rate >= self.threshold_high:
            return Action.C
        elif cooperation_rate >= self.threshold_medium:
            if random.random() < cooperation_rate:
                return Action.C
            else:
                return Action.D
        elif cooperation_rate >= self.threshold_low:
            return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_422(BaseStrategy):
    """
    Adaptive Threshold Cooperation with Graduated Defection.

    Balances collective cooperation with protection against exploitation by:
    1. Cooperating in round 1 to test population cooperation capacity
    2. Adapting in rounds 2 to r-1 based on observed cooperation rates vs. dynamic threshold
    3. Cooperating in the final round to demonstrate commitment

    The adaptive threshold is set at (1/k) + 0.05, reflecting the minimum cooperation rate
    needed for cooperation to be individually rational in the public goods game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.epsilon = 0.05

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == r - 1:
            return Action.C
        previous_round_index = current_round - 1
        cooperators_last_round = int(sum(history.opponent_actions[previous_round_index, :]))
        if history.my_actions[previous_round_index]:
            cooperators_last_round += 1
        cooperation_rate = cooperators_last_round / n
        threshold = 1.0 / k + self.epsilon
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_423(BaseStrategy):
    """
    Adaptive Threshold Cooperation with Decay (ATC-D) strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with robust individual protection through:
    - Unconditional cooperation in round 1 (cooperative probe)
    - Dynamic threshold adaptation based on empirical cooperation rates
    - Phase-based decision rules (exploration, adaptation, endgame)
    - Protection against exploitation while maintaining pro-cooperation stance
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num >= self.n_rounds - 2:
            if round_num == self.n_rounds - 2:
                lifetime_coop_rate = self._calculate_cooperation_rate(history, round_num)
                if lifetime_coop_rate >= 0.8:
                    return Action.C
            return Action.D
        c_rate = self._calculate_cooperation_rate(history, round_num)
        current_round_rate = self._get_current_round_cooperation_rate(history)
        if c_rate == 0.0:
            return Action.D
        break_even_single = 1.0 / self.k
        break_even_multiple = 1.0 / (self.n_players * self.k)
        variance_adjustment = self._get_variance_adjustment(history, c_rate)
        if self._is_losing_to_exploitation(history):
            return Action.D
        if c_rate >= break_even_single:
            threshold = c_rate * 0.9
            if current_round_rate >= threshold:
                return Action.C
            else:
                return Action.D
        elif c_rate >= break_even_multiple:
            threshold = c_rate * 0.8 + variance_adjustment
            if current_round_rate >= threshold:
                return Action.C
            else:
                return Action.D
        else:
            threshold = 0.15
            if current_round_rate >= threshold:
                return Action.C
            else:
                return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, up_to_round: int) -> float:
        """
        Calculate empirical cooperation rate from observed opponent actions.
        Considers only rounds 0 to up_to_round (inclusive).
        """
        if up_to_round == 0:
            return 0.0
        total_cooperators = 0
        total_observations = up_to_round * (self.n_players - 1)
        for round_idx in range(up_to_round):
            total_cooperators += np.sum(history.opponent_actions[round_idx, :])
        if total_observations == 0:
            return 0.0
        return total_cooperators / total_observations

    def _get_current_round_cooperation_rate(self, history: PlayerHistory) -> float:
        """
        Get the cooperation rate of opponents in the most recent round.
        """
        if history.opponent_actions.shape[0] == 0:
            return 0.0
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        return last_round_cooperators / (self.n_players - 1)

    def _get_variance_adjustment(self, history: PlayerHistory, mean_coop_rate: float) -> float:
        """
        Detect volatile cooperation and adjust threshold accordingly.
        If std_dev > mean, increase threshold by 15% (require stronger signal).
        Uses moving average of last 3 rounds.
        """
        if history.opponent_actions.shape[0] < 2:
            return 0.0
        round_rates = []
        for round_idx in range(history.opponent_actions.shape[0]):
            cooperators = np.sum(history.opponent_actions[round_idx, :])
            rate = cooperators / (self.n_players - 1)
            round_rates.append(rate)
        if len(round_rates) < 2:
            return 0.0
        recent_rounds = round_rates[-3:]
        std_dev = np.std(recent_rounds)
        if std_dev > mean_coop_rate and mean_coop_rate > 0:
            return 0.15
        return 0.0

    def _is_losing_to_exploitation(self, history: PlayerHistory) -> bool:
        """
        Check if average payoff < 1.05 (all-defect baseline) for 3 consecutive rounds.
        If so, shift to aggressive defection.
        """
        if history.my_payoffs.shape[0] < 3:
            return False
        recent_payoffs = history.my_payoffs[-3:]
        avg_payoff = np.mean(recent_payoffs)
        return avg_payoff < 1.05

class Strategy_COLLECTIVE_424(BaseStrategy):
    """
    Adaptive Contribution with Defection Thresholds (ACDT)

    Balances individual rationality with collective welfare by:
    1. Starting cooperative to establish mutual benefit potential
    2. Monitoring collective health through contribution rates
    3. Adapting dynamically based on commons sustainability
    4. Punishing defection proportionally to collective harm
    5. Recovering cooperation when conditions improve
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        if t == 0:
            return Action.C
        if t == self.r - 1:
            cooperators_prev = self._count_cooperators(history, t - 1)
            chi_prev = cooperators_prev / self.n
            robust_threshold = 2 * self.k / 3 / self.n
            if chi_prev >= robust_threshold:
                return Action.C
            else:
                return Action.D
        cooperators_last = self._count_cooperators(history, t - 1)
        chi = cooperators_last / self.n
        target_chi = self.k / self.n
        if chi >= target_chi:
            return Action.C
        defectors_earning_more = self._count_exploiters(history, t - 1)
        if self.n == 2:
            defection_threshold = 1
        else:
            defection_threshold = 2
        if defectors_earning_more <= defection_threshold - 1:
            return Action.C
        if t >= 2 and chi < target_chi:
            cooperators_two_back = self._count_cooperators(history, t - 2)
            chi_two_back = cooperators_two_back / self.n
            recovery_threshold = 2 * self.k / (3 * self.n)
            if chi_two_back >= recovery_threshold:
                return Action.C
        if self.k < 1.2:
            consecutive_bad = 0
            if t >= 2:
                for i in range(max(0, t - 2), t):
                    cooperators_i = self._count_cooperators(history, i)
                    chi_i = cooperators_i / self.n
                    if chi_i < 2 * self.k / 3 / self.n:
                        consecutive_bad += 1
            if consecutive_bad >= 2:
                return Action.D
        if self.k > self.n - 0.2:
            low_threshold = self.k / (2 * self.n)
            if chi < low_threshold:
                consecutive_very_bad = 0
                if t >= 2:
                    for i in range(max(0, t - 2), t):
                        cooperators_i = self._count_cooperators(history, i)
                        chi_i = cooperators_i / self.n
                        if chi_i < low_threshold:
                            consecutive_very_bad += 1
                if consecutive_very_bad >= 2:
                    return Action.D
        return Action.D

    def _count_cooperators(self, history: PlayerHistory, round_idx: int) -> int:
        """Count total cooperators in a given round (including self)."""
        my_action = history.my_actions[round_idx]
        opponent_cooperators = np.sum(history.opponent_actions[round_idx, :])
        return int(my_action) + int(opponent_cooperators)

    def _count_exploiters(self, history: PlayerHistory, round_idx: int) -> int:
        """Count defectors who earned more than me in the given round."""
        my_payoff = history.my_payoffs[round_idx]
        opponent_actions = history.opponent_actions[round_idx, :]
        opponent_payoffs = history.opponent_payoffs[round_idx, :]
        exploiters = 0
        for j in range(len(opponent_actions)):
            if opponent_actions[j] == 0 and opponent_payoffs[j] > my_payoff:
                exploiters += 1
        return exploiters

class Strategy_COLLECTIVE_425(BaseStrategy):
    """
    Adaptive Graduated Reciprocity with Collective Threshold (AGRC).

    Balances individual rationality with collective welfare by:
    1. Starting with cooperation to signal trustworthiness
    2. Using a threshold-based reciprocity rule in middle rounds
    3. Adapting to cooperation trends with stricter thresholds when declining
    4. Making final round decision based on average historical cooperation
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        cooperation_threshold = (self.k - 1) / (self.n - 1) * 0.5
        if round_num == self.r - 1:
            total_cooperators = 0
            for t in range(round_num):
                total_cooperators += np.sum(history.opponent_actions[t, :])
            average_coop_rate = total_cooperators / (round_num * self.n)
            if average_coop_rate >= cooperation_threshold:
                return Action.C
            else:
                return Action.D
        cooperators_prev = np.sum(history.opponent_actions[round_num - 1, :])
        cooperation_rate_prev = cooperators_prev / self.n
        trend = 0
        if round_num > 1:
            cooperators_prev2 = np.sum(history.opponent_actions[round_num - 2, :])
            cooperation_rate_prev2 = cooperators_prev2 / self.n
            trend = cooperation_rate_prev - cooperation_rate_prev2
        if cooperation_rate_prev >= cooperation_threshold:
            base_decision = Action.C
        else:
            base_decision = Action.D
        if trend < 0:
            stricter_threshold = 1.25 * cooperation_threshold
            if cooperation_rate_prev >= stricter_threshold:
                return Action.C
            else:
                return Action.D
        else:
            return base_decision

class Strategy_COLLECTIVE_426(BaseStrategy):
    """
    Adaptive Contribution with Collective Threshold (ACT):
    A strategy that balances individual rationality with collective welfare by
    monitoring group cooperation levels and reciprocating with adaptive thresholds.

    Core mechanism:
    - Round 1: Always cooperate to establish baseline
    - Rounds 2+: Reciprocate based on previous round's cooperation rate
      - Cooperate if cooperation_rate >= 50%
      - Defect if cooperation_rate <= 25%
      - Cooperate if 25% < rate < 50% (ambiguity favors cooperation)
    - Special case: If all defected and not in final 20%, attempt restart; else defect
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_cooperate = 0.5
        self.threshold_defect = 0.25
        self.endgame_threshold = 0.8

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        cooperators_last_round = np.sum(history.opponent_actions[-1, :])
        cooperation_rate = cooperators_last_round / self.game_description.n_players
        if cooperation_rate >= self.threshold_cooperate:
            return Action.C
        elif cooperation_rate <= self.threshold_defect:
            current_round = state.round_number
            total_rounds = self.game_description.n_rounds
            progress_ratio = current_round / total_rounds
            if progress_ratio < self.endgame_threshold:
                return Action.C
            else:
                return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_427(BaseStrategy):
    """
    Adaptive Threshold Cooperation with Defection Recovery strategy for N-Player Public Goods Game.

    Balances collective value creation, individual sustainability, and robustness through:
    1. Initial cooperation to establish cooperative norms
    2. Adaptive thresholds based on historical cooperation rates
    3. Recovery modes for reciprocation signals
    4. Special handling for final round and edge cases
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        opponent_coop_rate = self._compute_opponent_coop_rate(history, current_round)
        if current_round == self.r - 1:
            if opponent_coop_rate > 0.4:
                return Action.C
            else:
                return Action.D
        return self._adaptive_decision(opponent_coop_rate, current_round, history)

    def _compute_opponent_coop_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Compute opponent cooperation rate using exponential moving average.
        Weights recent rounds more heavily.
        """
        if current_round == 0:
            return 0.0
        total_cooperators = 0
        total_opponents = 0
        for round_idx in range(current_round):
            cooperators_this_round = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += cooperators_this_round
            total_opponents += self.n - 1
        if total_opponents == 0:
            return 0.0
        base_rate = total_cooperators / total_opponents
        if current_round >= 2:
            recent_cooperators = np.sum(history.opponent_actions[current_round - 1, :])
            recent_rate = recent_cooperators / (self.n - 1)
            ema_rate = 0.7 * recent_rate + 0.3 * base_rate
            return ema_rate
        return base_rate

    def _compute_recent_trend(self, history: PlayerHistory, current_round: int) -> float:
        """
        Compute recent trend in cooperation rate (last 3 rounds vs prior).
        Returns the change in cooperation rate.
        """
        if current_round < 3:
            return 0.0
        recent_coops = np.sum(history.opponent_actions[current_round - 1, :])
        recent_rate = recent_coops / (self.n - 1)
        if current_round >= 4:
            past_coops = np.sum(history.opponent_actions[current_round - 4, :])
            past_rate = past_coops / (self.n - 1)
        else:
            past_total = np.sum(history.opponent_actions[:current_round - 1, :])
            past_rate = past_total / ((current_round - 1) * (self.n - 1))
        return recent_rate - past_rate

    def _adaptive_decision(self, opponent_coop_rate: float, current_round: int, history: PlayerHistory) -> Action:
        """
        Apply adaptive decision logic for rounds 1 to r-2.
        """
        threshold_a = self._get_threshold_a()
        threshold_b = self._get_threshold_b()
        threshold_c = self._get_threshold_c()
        if opponent_coop_rate > threshold_a:
            return Action.C
        if opponent_coop_rate * self.k > 1:
            return Action.C
        early_game_threshold = math.ceil(0.3 * self.r)
        if current_round <= early_game_threshold and opponent_coop_rate > threshold_c:
            return Action.C
        recent_trend = self._compute_recent_trend(history, current_round)
        if recent_trend > 0.1:
            return Action.C
        return Action.D

    def _get_threshold_a(self) -> float:
        """Get Condition A threshold, adjusted for edge cases."""
        base_threshold = (self.n - 1) / self.n
        if self.n == 2:
            return base_threshold * 0.9
        return base_threshold

    def _get_threshold_b(self) -> float:
        """Get Condition B threshold, adjusted for k value."""
        base_threshold = 1.0
        if self.k >= self.n * 0.9:
            return base_threshold * 0.95
        elif self.k <= 1.2:
            return base_threshold * 1.0
        return base_threshold

    def _get_threshold_c(self) -> float:
        """Get Condition C threshold, adjusted for k and n values."""
        base_threshold = 0.2
        if self.n == 2:
            return base_threshold * 0.9
        if self.k <= 1.2:
            return 0.35
        return base_threshold

class Strategy_COLLECTIVE_428(BaseStrategy):
    """
    Adaptive Reciprocal Maximization (ARM): A collective strategy that maximizes
    welfare through conditional cooperation based on observed cooperation rates.

    Core mechanism:
    - Round 1: Cooperate to establish mutual benefit signal
    - Subsequent rounds: Cooperate if cooperation rate >= k/n threshold
    - Low cooperation with remaining rounds: Use probabilistic defection to incentivize cooperation
    - Final rounds with low cooperation: Defect to minimize exploitation
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        previous_round_index = round_number - 1
        cooperators_last_round = sum(history.opponent_actions[previous_round_index, :])
        if history.my_actions[previous_round_index]:
            cooperators_last_round += 1
        cr = cooperators_last_round / self.n
        theta = self.k / self.n
        remaining_rounds = self.r - round_number
        if cr >= theta:
            return Action.C
        elif remaining_rounds <= 2:
            return Action.D
        elif remaining_rounds > 2:
            defection_pressure = max(0.0, (theta - cr) / (2.0 * theta))
            random_value = random.random()
            if random_value < defection_pressure:
                return Action.D
            else:
                return Action.C
        return Action.C

class Strategy_COLLECTIVE_429(BaseStrategy):
    """
    Adaptive Reciprocity with Collective Threshold (ARC)

    A strategy that balances individual rationality with collective welfare by:
    1. Cooperating in round 1 to establish cooperative baseline
    2. Classifying game state into phases based on observed cooperation rates
    3. Adapting behavior: cooperate when collective is strong, defect when it fails
    4. In final round, honor successful collectives but defect from failed ones
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        coop_rate = self._calculate_cooperation_rate(history, round_num)
        threshold_high = self.k / self.n
        threshold_low = self.k / self.n * 0.5
        if round_num == self.r - 1:
            if coop_rate >= threshold_high:
                return Action.C
            else:
                return Action.D
        if coop_rate >= threshold_high:
            return Action.C
        elif coop_rate >= threshold_low:
            n_coop_last_round = int(sum(history.opponent_actions[round_num - 1, :]))
            n_coop_last_round += int(history.my_actions[round_num - 1])
            if n_coop_last_round > self.n / 2:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate the cooperation rate across all players in rounds 0 to round_num-1.

        cooperation_rate = (total cooperators) / (n_players * rounds_played)
        """
        if round_num == 0:
            return 0.0
        total_cooperators = 0
        total_cooperators += np.sum(history.opponent_actions[:round_num, :])
        total_cooperators += np.sum(history.my_actions[:round_num])
        total_possible = self.n * round_num
        coop_rate = total_cooperators / total_possible if total_possible > 0 else 0.0
        return coop_rate

class Strategy_COLLECTIVE_430(BaseStrategy):
    """
    Adaptive Reciprocity with Threshold Enforcement for N-Player Public Goods Game.

    Balances collective welfare maximization with individual rationality by:
    - Starting with cooperation to establish benevolent intent
    - Adapting based on observed cooperation rates and free-ride advantages
    - Enforcing norms through strategic defection when cooperation breaks down
    - Preserving cooperation in final round only if near-universal cooperation exists
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        rounds_completed = current_round
        total_cooperators_seen = int(np.sum(history.my_actions[:current_round]))
        all_cooperators_per_round = np.sum(history.opponent_actions[:current_round, :], axis=1) + history.my_actions[:current_round].astype(int)
        total_cooperators_across_all = np.sum(all_cooperators_per_round)
        observed_cooperation_rate = total_cooperators_across_all / (n * rounds_completed)
        my_cooperation_rate = total_cooperators_seen / rounds_completed
        if current_round == r - 1:
            if observed_cooperation_rate >= 0.75:
                return Action.C
            else:
                return Action.D
        if current_round >= 1:
            prev_round_cooperators = all_cooperators_per_round[current_round - 1]
            if current_round >= 2:
                prev_prev_round_cooperators = all_cooperators_per_round[current_round - 2]
                cooperation_drop = (prev_prev_round_cooperators - prev_round_cooperators) / (prev_prev_round_cooperators + 1e-06)
                if cooperation_drop > 0.3:
                    return Action.D
        if observed_cooperation_rate >= 0.6:
            return Action.C
        elif observed_cooperation_rate < 0.3:
            if my_cooperation_rate - observed_cooperation_rate > 0.3:
                return Action.D
            else:
                return Action.D
        else:
            cooperators_last_round = int(all_cooperators_per_round[current_round - 1])
            free_ride_payoff = 1 + k / n * cooperators_last_round
            coop_payoff = k / n * (cooperators_last_round + 1)
            free_ride_advantage = free_ride_payoff - coop_payoff
            if free_ride_advantage < 0.2:
                return Action.C
            else:
                return Action.D

class Strategy_COLLECTIVE_431(BaseStrategy):
    """
    Adaptive Contribution with Conditional Cooperation strategy for N-Player Public Goods Game.

    Prioritizes sustainable collective value creation while protecting against exploitation.
    Uses adaptive thresholds that decline as the game progresses, conditional cooperation
    based on observed cooperation rates, and special handling for early/late rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            bootstrap_prob = max(0.5, self.k / self.n)
            if random.random() < bootstrap_prob:
                return Action.C
            else:
                return Action.D
        prev_round_actions = history.opponent_actions[round_number - 1, :]
        num_cooperators = int(np.sum(prev_round_actions))
        cooperation_rate = num_cooperators / self.n
        base_threshold = 0.3 + 0.2 * (self.r - round_number) / self.r
        threshold = min(0.5, base_threshold)
        if round_number <= 2:
            threshold = threshold + 0.1
        exploitation_score = self._calculate_exploitation_metric(history, round_number)
        if exploitation_score > 0.7:
            threshold = max(0.15, threshold - 0.15)
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_exploitation_metric(self, history: PlayerHistory, round_number: int) -> float:
        """
        Calculate exploitation score: ratio of times I defected when others cooperated
        to total times others cooperated.
        """
        if round_number == 0:
            return 0.0
        my_actions = history.my_actions[:round_number]
        opponent_actions = history.opponent_actions[:round_number, :]
        rounds_others_cooperated = 0
        times_i_defected_when_others_cooperated = 0
        for t in range(round_number):
            others_cooperated = int(np.sum(opponent_actions[t, :]))
            if others_cooperated > 0:
                rounds_others_cooperated += 1
                if not my_actions[t]:
                    times_i_defected_when_others_cooperated += 1
        if rounds_others_cooperated == 0:
            return 0.0
        exploitation_score = times_i_defected_when_others_cooperated / rounds_others_cooperated
        return exploitation_score

class Strategy_COLLECTIVE_432(BaseStrategy):
    """
    Adaptive Contribution with Conditional Cooperation strategy for N-Player Public Goods Game.

    This strategy prioritizes collective welfare while protecting against exploitation through:
    - Cautious optimism in round 1 (cooperate)
    - Conditional cooperation based on observed cooperation rates in middle rounds
    - Context-dependent behavior in the final round
    - Probabilistic hedging to avoid defection traps while maintaining security
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold_high = 0.5
        self.threshold_low = 0.2
        self.final_round_threshold = 0.4
        self.early_defection_threshold = 0.2
        self.early_defection_rounds = 3
        self.punishment_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        cooperators_prev = int(sum(history.opponent_actions[prev_round_idx, :]))
        coop_rate = cooperators_prev / self.n_players
        if self.punishment_counter > 0:
            self.punishment_counter -= 1
            return Action.D
        if current_round < self.early_defection_rounds:
            if coop_rate < self.early_defection_threshold:
                self.punishment_counter = 2
                return Action.D
        if coop_rate == 1.0:
            return Action.C
        if current_round == self.n_rounds - 1:
            if coop_rate >= self.final_round_threshold:
                return Action.C
            else:
                return Action.D
        if coop_rate >= self.threshold_high:
            return Action.C
        elif coop_rate >= self.threshold_low:
            p_cooperate = (coop_rate - self.threshold_low) / (self.threshold_high - self.threshold_low)
            if random.random() < p_cooperate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_433(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game.

    Balances collective welfare with resilience against exploitation by:
    - Cooperating in round 1 (good faith initialization)
    - Adapting based on cooperation rate in rounds 2 to r-1
    - Defecting in the final round (subgame-perfect equilibrium)

    Uses dynamic thresholds based on game parameters k and n to determine
    when collective cooperation is sufficiently attractive.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold_high = 2 * self.k / self.n
        self.threshold_medium = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            return Action.D
        previous_round_idx = current_round - 1
        cooperators_in_prev = int(np.sum(history.opponent_actions[previous_round_idx, :]))
        if history.my_actions[previous_round_idx]:
            cooperators_in_prev += 1
        coop_rate = cooperators_in_prev / self.n
        if coop_rate >= self.threshold_high:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_434(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game

    Balances collective welfare maximization with individual rationality protection through
    conditional cooperation based on recent cooperation rates. Cooperates in round 1,
    then reciprocates based on whether the previous round's cooperation rate exceeded
    a dynamically calculated threshold.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold_T = self.k / (2 * self.n)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        previous_round_opponent_actions = history.opponent_actions[current_round - 1, :]
        cooperators_last_round = int(sum(previous_round_opponent_actions))
        if history.my_actions[current_round - 1]:
            cooperators_last_round += 1
        cooperation_rate = cooperators_last_round / self.n
        if cooperation_rate >= self.threshold_T:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_435(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    This strategy balances collective welfare with protection against exploitation by:
    1. Cooperating optimistically in round 1
    2. Defecting in the final round (endgame logic)
    3. In middle rounds, reciprocating based on recent cooperation rates
    4. Using adaptive thresholds calibrated to game parameters
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.r - 1:
            return Action.D
        window_size = max(2, math.floor(self.r / 4))
        start_idx = max(0, round_number - window_size)
        recent_rounds = history.opponent_actions[start_idx:round_number, :]
        total_cooperators = np.sum(recent_rounds)
        expected_cooperators = total_cooperators / len(recent_rounds) if len(recent_rounds) > 0 else 0
        cooperation_rate = expected_cooperators / self.n
        min_beneficial = self.k / self.n
        threshold = max(min_beneficial + 0.1, min(0.5, 1.0 - self.k / self.n))
        if self.n <= 3:
            threshold = threshold - 0.1
        if cooperation_rate < threshold - 0.15:
            return Action.D
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_436(BaseStrategy):
    """
    Adaptive Threshold Reciprocity with Decay (ATRD) Strategy

    Balances mutual benefit recognition, defection deterrence, and adaptive recovery
    in N-player public goods games. Cooperates when collective returns exceed private
    returns, punishes free-riding with graduated response, and gradually restores
    cooperation when others show willingness to reciprocate.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        theta = (self.k - 1) / self.n_players
        cooperators_prev = sum(history.opponent_actions[current_round - 1, :])
        cooperation_rate_prev = cooperators_prev / self.n_players
        if current_round == self.n_rounds - 1:
            if cooperation_rate_prev >= theta:
                return Action.C
            else:
                return Action.D
        if cooperation_rate_prev >= theta:
            return Action.C
        rounds_remaining = self.n_rounds - current_round
        decay = max(0.1, 1 - rounds_remaining / self.n_rounds)
        punishment_score = (theta - cooperation_rate_prev) * decay
        if punishment_score < 0.2:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_437(BaseStrategy):
    """
    Adaptive Collective Strategy for N-Player Public Goods Game.

    This strategy pursues conditional cooperation with adaptive thresholds,
    maximizing collective welfare while protecting against exploitation.
    Core principle: cooperate when conditions suggest mutual benefit is achievable,
    defect when defection becomes the dominant rational response for the group.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        if round_t >= self.r - 2:
            start_idx = max(0, round_t - 2)
            recent_rounds = history.opponent_actions[start_idx:round_t, :]
            if len(recent_rounds) > 0:
                recent_coop_rate = recent_rounds.sum() / (len(recent_rounds) * self.n)
            else:
                recent_coop_rate = 0.0
            if round_t == self.r - 2 and recent_coop_rate >= (self.n - 1) / self.n:
                return Action.C
            return Action.D
        lookback = min(3, round_t)
        start_idx = round_t - lookback
        recent_rounds = history.opponent_actions[start_idx:round_t, :]
        if len(recent_rounds) > 0:
            recent_coop_count = recent_rounds.sum()
            recent_coop_rate = recent_coop_count / (len(recent_rounds) * self.n)
        else:
            recent_coop_rate = 0.0
        threshold = max(1.0 / self.n, (self.n - 1) / self.n * recent_coop_rate)
        if self.n <= 3:
            threshold = threshold * 1.2
        if round_t >= 2:
            prev_round_coop = history.opponent_actions[round_t - 1, :].sum() / self.n
            curr_round_coop = history.opponent_actions[round_t - 2, :].sum() / self.n if round_t >= 2 else 0.0
            if curr_round_coop > 0 and (curr_round_coop - prev_round_coop) / curr_round_coop > 0.3:
                return Action.D
        if round_t >= 2:
            last_two_rounds = history.opponent_actions[round_t - 2:round_t, :]
            if last_two_rounds.sum() == 0:
                return Action.D
        if recent_coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_438(BaseStrategy):
    """
    Adaptive Reciprocal Maximization (ARM) Strategy for N-Player Public Goods Game

    Balances collective welfare maximization, robustness against exploitation, and graceful
    degradation. Cooperates conditionally based on observed cooperation rates, with special
    handling for early rounds, final rounds, and volatile scenarios.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold = self.k / self.n + 0.05

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        all_opponent_actions = history.opponent_actions[:round_num]
        total_cooperators_history = np.sum(all_opponent_actions)
        total_cooperators_history += np.sum(history.my_actions[:round_num])
        cooperation_rate = total_cooperators_history / (self.n * round_num)
        if round_num == self.r - 1:
            if cooperation_rate >= self.threshold:
                return Action.C
            else:
                return Action.D
        if round_num >= 1 and round_num <= 3:
            if cooperation_rate >= 0.7:
                return Action.C
        if cooperation_rate >= self.threshold:
            return Action.C
        low_coop_threshold = self.k / (2 * self.n)
        if cooperation_rate < low_coop_threshold:
            return Action.D
        recent_window = min(3, round_num)
        if recent_window > 0:
            recent_history = history.opponent_actions[round_num - recent_window:round_num]
            recent_my_actions = history.my_actions[round_num - recent_window:round_num]
            recent_cooperators = np.sum(recent_history) + np.sum(recent_my_actions)
            recent_coop_rate = recent_cooperators / (self.n * recent_window)
            if recent_window >= 2:
                round_coop_rates = []
                for i in range(round_num - recent_window, round_num):
                    round_cooperators = np.sum(history.opponent_actions[i]) + (1 if history.my_actions[i] else 0)
                    round_rate = round_cooperators / self.n
                    round_coop_rates.append(round_rate)
                if len(round_coop_rates) >= 2:
                    rate_variance = max(round_coop_rates) - min(round_coop_rates)
                    if rate_variance >= 0.2:
                        return Action.D
            if recent_coop_rate >= self.threshold:
                return Action.C
        return Action.D

class Strategy_COLLECTIVE_439(BaseStrategy):
    """
    Adaptive Contribution with Defection Resistance Strategy.

    A collective welfare-maximizing strategy that:
    1. Cooperates conditionally based on observed cooperation rates
    2. Punishes systematic exploitation through retaliation
    3. Defects strategically in first and last rounds per game theory
    4. Adapts thresholds based on group size and game progression
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.punishment_counter = 0
        self.exploitation_score = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == r - 1:
            return Action.D
        total_cooperations = np.sum(history.my_actions[:round_num])
        observed_cooperation_rate = total_cooperations / round_num
        if n < 4:
            stability_factor = min(0.21, round_num / r)
        elif n > 20:
            stability_factor = min(0.39, round_num / r)
        else:
            stability_factor = min(0.3, round_num / r)
        threshold = 1.0 / k * (1.0 + stability_factor)
        self._update_exploitation_score(history, round_num, n)
        if self.punishment_counter > 0:
            self.punishment_counter -= 1
            return Action.D
        if self.exploitation_score < -0.5 * r:
            self.punishment_counter = 2
            self.exploitation_score = 0.0
            return Action.D
        if observed_cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _update_exploitation_score(self, history: PlayerHistory, round_num: int, n: int) -> None:
        """Update cumulative exploitation metric based on payoff comparison."""
        if round_num == 0:
            return
        my_payoff_last_round = history.my_payoffs[round_num - 1]
        all_payoffs = [my_payoff_last_round] + list(history.opponent_payoffs[round_num - 1, :])
        collective_avg = np.mean(all_payoffs)
        payoff_diff = my_payoff_last_round - collective_avg
        self.exploitation_score += payoff_diff

class Strategy_COLLECTIVE_440(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game

    Balances collective welfare maximization with individual security against exploitation.
    Uses a dynamic cooperation threshold that decreases over time, implementing graduated
    reciprocal trust: cooperate if previous round's cooperation rate meets a time-dependent
    threshold that starts high and gradually relaxes toward 50%.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        cooperators_in_previous_round = sum(history.opponent_actions[-1, :])
        cooperation_rate = cooperators_in_previous_round / self.n_players
        t = current_round
        r = self.n_rounds
        threshold = max(0.5, 1.0 - t / (2.0 * r))
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_441(BaseStrategy):
    """
    Conditional Reciprocal Contribution (CRC) Strategy for N-Player Public Goods Game.

    Balances collective efficiency with individual protection through:
    1. Unconditional cooperation in round 1
    2. Dynamic threshold-based cooperation in middle rounds
    3. Unconditional defection in final round
    4. Exploitation detection and temporary defection response
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.exploitation_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        if round_num == 0:
            return Action.C
        if round_num == r - 1:
            return Action.D
        last_round_idx = round_num - 1
        last_round_cooperators = np.sum(history.opponent_actions[last_round_idx, :])
        if history.my_actions[last_round_idx]:
            last_round_cooperators += 1
        cooperation_rate = last_round_cooperators / n
        threshold = 0.5 + 0.25 * (r - (round_num + 1)) / (r - 1)
        mean_payoff = np.mean(history.opponent_payoffs[last_round_idx, :])
        if history.my_payoffs[last_round_idx] is not None:
            my_last_payoff = history.my_payoffs[last_round_idx]
            if mean_payoff > 1.5 and my_last_payoff < mean_payoff - 0.3:
                self.exploitation_counter += 1
            else:
                self.exploitation_counter = max(0, self.exploitation_counter - 1)
        if self.exploitation_counter >= 2:
            self.exploitation_counter -= 1
            return Action.D
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_442(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective value maximization with robustness to exploitation through:
    1. Initial cooperation to signal willingness
    2. Adaptive decisions based on historical cooperation rate vs. efficiency threshold (k/n)
    3. End-game defection when cooperation has failed
    4. Stochastic defection for unpredictability against committed defectors
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        total_cooperators = int(np.sum(history.opponent_actions[:current_round, :]))
        total_cooperators += int(np.sum(history.my_actions[:current_round]))
        total_slots = self.n * current_round
        coop_rate = total_cooperators / total_slots if total_slots > 0 else 0
        rounds_remaining = self.r - current_round
        if coop_rate >= self.threshold:
            return Action.C
        if rounds_remaining <= 2 and coop_rate < self.threshold:
            return Action.D
        defection_cost_to_collective = self.k / self.n
        personal_exploitation_benefit = 1 - self.k / self.n
        if defection_cost_to_collective > personal_exploitation_benefit:
            return Action.C
        elif random.random() < self.threshold:
            return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_443(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game

    Balances collective welfare maximization, self-protection against defectors,
    and robustness across diverse opponent types through adaptive reciprocal behavior.

    Core mechanism: Cooperate in round 1, then reciprocate based on whether previous
    round's cooperation rate exceeded an adaptive threshold that relaxes over time.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.decay_factor = 0.2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_idx = round_num - 1
        my_prev_action = history.my_actions[prev_round_idx]
        opponent_cooperators = sum(history.opponent_actions[prev_round_idx, :])
        total_cooperators = (1 if my_prev_action else 0) + opponent_cooperators
        cooperation_rate = total_cooperators / n
        breakeven = k / n
        progress = round_num / r
        threshold = breakeven + self.decay_factor * progress
        if round_num >= r - 2:
            if cooperation_rate >= threshold:
                return Action.C
            else:
                return Action.D
        elif cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_444(BaseStrategy):
    """
    Adaptive Contribution Equilibrium (ACE) Strategy for N-Player Public Goods Game.

    Pursues collectively rational equilibrium by conditionally cooperating based on
    recent cooperation rates, with dynamic thresholds that adapt to game phase and
    remaining rounds. Balances group welfare maximization with protection against
    exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        window_size = min(5, current_round)
        if window_size == current_round:
            recent_opponent_actions = history.opponent_actions[:current_round, :]
        else:
            recent_opponent_actions = history.opponent_actions[current_round - window_size:current_round, :]
        total_recent_cooperators = np.sum(recent_opponent_actions)
        total_recent_slots = window_size * (self.n - 1)
        cooperation_rate = total_recent_cooperators / total_recent_slots if total_recent_slots > 0 else 0.0
        base_threshold = (self.k - 1) / self.k
        rounds_remaining = self.r - current_round - 1
        if rounds_remaining <= 2:
            threshold = 0.95
        elif rounds_remaining <= self.r / 3:
            threshold = base_threshold + 0.15
        else:
            threshold = base_threshold + 0.05
        threshold = max(0.0, min(1.0, threshold))
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_445(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game.

    Balances collective welfare with individual security through:
    1. Early-phase unconditional cooperation to test for cooperators
    2. Mid-game adaptive threshold-based cooperation (threshold = 1/k)
    3. End-game consistency with survival mode detection
    4. Dynamic adjustments for extreme k values and behavioral shifts
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_history = []
        self.recent_rounds_window = 4

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        if round_num == 0:
            return Action.C
        self._update_cooperation_history(history, n)
        early_round_threshold = math.ceil(r / 4)
        if round_num <= early_round_threshold:
            return Action.C
        threshold = self._calculate_threshold(k, n)
        if round_num >= r - 2 or round_num >= math.ceil(3 * r / 4):
            avg_coop_rate = self._get_recent_average(4)
            if avg_coop_rate >= threshold:
                return Action.C
            else:
                return Action.D
        avg_coop_rate = self._get_average_cooperation_rate()
        recent_avg = self._get_recent_average(3)
        if recent_avg < 0.3 and len(self.cooperation_history) >= 3:
            return Action.D
        if len(self.cooperation_history) >= 2:
            prev_rate = self.cooperation_history[-2]
            curr_rate = self.cooperation_history[-1]
            if curr_rate - prev_rate >= 0.2:
                return Action.C
        if avg_coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _update_cooperation_history(self, history: PlayerHistory, n: int) -> None:
        """Update cooperation_history with data from the most recent completed round."""
        if len(self.cooperation_history) == history.my_actions.shape[0]:
            return
        most_recent_round = history.my_actions.shape[0] - 1
        my_action = history.my_actions[most_recent_round]
        opponent_cooperators = np.sum(history.opponent_actions[most_recent_round, :])
        total_cooperators = my_action + opponent_cooperators
        cooperation_rate = total_cooperators / n
        self.cooperation_history.append(cooperation_rate)

    def _calculate_threshold(self, k: float, n: int) -> float:
        """
        Calculate cooperation threshold based on k value.
        Base threshold is 1/k (breakeven point).
        Adjusted for extreme k values.
        """
        base_threshold = 1.0 / k
        if k <= 1.1:
            threshold = min(0.7, 2.0 / k)
        elif k >= n - 0.5:
            threshold = max(0.3, base_threshold)
        else:
            threshold = base_threshold
        threshold = max(0.0, min(1.0, threshold))
        return threshold

    def _get_average_cooperation_rate(self) -> float:
        """Get average cooperation rate across all observed rounds."""
        if len(self.cooperation_history) == 0:
            return 0.5
        return float(np.mean(self.cooperation_history))

    def _get_recent_average(self, window_size: int) -> float:
        """Get average cooperation rate over the most recent N rounds."""
        if len(self.cooperation_history) == 0:
            return 0.5
        recent = self.cooperation_history[-window_size:]
        return float(np.mean(recent))

class Strategy_COLLECTIVE_446(BaseStrategy):
    """
    Adaptive Collective Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization, self-protection against exploitation,
    and adaptive reciprocity. Uses a cooperation threshold rule based on the break-even
    point k/n, with probabilistic cooperation in the middle range and retaliation
    for sudden cooperation collapses.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n
        self.partial_threshold = self.threshold * 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        cooperators_prev = np.sum(history.opponent_actions[prev_round_idx, :])
        cooperation_rate = cooperators_prev / self.n
        if cooperation_rate >= self.threshold:
            return Action.C
        elif cooperation_rate >= self.partial_threshold:
            random_draw = random.random()
            if random_draw < cooperation_rate:
                return Action.C
            else:
                return Action.D
        else:
            if current_round > 1:
                prev_prev_round_idx = current_round - 2
                cooperators_prev_prev = np.sum(history.opponent_actions[prev_prev_round_idx, :])
                collapse_magnitude = cooperators_prev_prev - cooperators_prev
                if collapse_magnitude > self.n / 2:
                    return Action.D
            return Action.D

class Strategy_COLLECTIVE_447(BaseStrategy):
    """
    Adaptive Threshold Cooperation with Reciprocal Decay.

    Balances collective welfare, individual resilience, and adaptive learning.
    Cooperates when cooperation ratio meets an adaptive threshold that adjusts
    based on game parameters, time remaining, and observed defection spirals.
    Defects in terminal round unless all others have cooperated throughout.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.defection_spiral_detected = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        if t == self.r - 1:
            if history is not None:
                all_others_cooperated = all((np.all(history.opponent_actions[:, i]) for i in range(self.n - 1)))
                if all_others_cooperated:
                    return Action.C
            return Action.D
        if t == 0:
            return Action.C
        prev_round_cooperators = np.sum(history.opponent_actions[t - 1, :])
        cooperation_ratio = prev_round_cooperators / self.n
        if t >= 3 and (not self.defection_spiral_detected):
            coop_ratios = [np.sum(history.opponent_actions[t - 3, :]) / self.n, np.sum(history.opponent_actions[t - 2, :]) / self.n, np.sum(history.opponent_actions[t - 1, :]) / self.n]
            if coop_ratios[0] > coop_ratios[1] and coop_ratios[1] > coop_ratios[2]:
                self.defection_spiral_detected = True
        if self.defection_spiral_detected:
            return Action.D
        base_threshold = 1.0 / self.k
        if self.k >= self.n - 1:
            base_threshold = 0.5
        elif self.k <= 1.1:
            base_threshold = 0.9
        if self.r <= 3:
            decay_factor = 1.0 + 0.8 * ((self.r - t) / self.r)
        else:
            decay_factor = 1.0 + (self.r - t) / self.r * 0.5
        current_threshold = base_threshold * decay_factor
        adaptive_threshold = max(base_threshold, current_threshold)
        if t >= 2:
            coop_history = [np.sum(history.opponent_actions[i, :]) / self.n for i in range(max(0, t - t + 1), t)]
            if len(coop_history) > 1:
                coop_variance = np.var(coop_history)
                if coop_variance > 0.4:
                    pass
        if cooperation_ratio >= adaptive_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_448(BaseStrategy):
    """
    Conditional Reciprocal Threshold (CRT) Strategy for N-Player Public Goods Game.

    This strategy implements adaptive conditional cooperation based on the observed
    cooperation rate relative to a break-even threshold (k/n). It cooperates in round 1
    to establish a cooperative baseline, conditionally cooperates in middle rounds based
    on whether group cooperation exceeds the threshold, and defects in the final round
    to maximize individual payoff when reputation effects no longer apply.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[round_number - 1, :]))
        if history.my_actions[round_number - 1]:
            cooperators_last_round += 1
        cooperation_rate = cooperators_last_round / self.n_players
        if cooperation_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_449(BaseStrategy):
    """
    Adaptive Contribution with Graduated Thresholds strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with robustness against exploitation through:
    - Optimistic initial cooperation to signal willingness
    - Dynamic cooperation thresholds that decay over time
    - Hysteresis to prevent hair-trigger reactive defection
    - Limited defection streaks (max 3) as punishment signals
    - Late-game commitment to cooperation (last 2 rounds)
    - Reset mechanisms to enable cooperation restoration
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.defect_streak_length = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        t = state.round_number
        if t == 0:
            self.defect_streak_length = 0
            return Action.C
        early_phase_end = math.ceil(r / 3)
        late_phase_start = math.floor(2 * r / 3)
        cooperators_previous = sum(history.opponent_actions[t - 1, :])
        cooperation_rate = cooperators_previous / n
        base_threshold = k / n
        decay_factor = (1 - k / n) * math.exp(-3 * t / r)
        threshold = max(base_threshold, base_threshold + decay_factor)
        if cooperation_rate >= threshold:
            self.defect_streak_length = 0
            return Action.C
        if cooperation_rate < threshold:
            if t >= r - 2:
                if cooperation_rate < 0.4:
                    return Action.D
                else:
                    self.defect_streak_length = 0
                    return Action.C
            if self.defect_streak_length < 3:
                self.defect_streak_length += 1
                return Action.D
            self.defect_streak_length = 0
            return Action.C
        self.defect_streak_length = 0
        return Action.C

class Strategy_COLLECTIVE_450(BaseStrategy):
    """
    Adaptive Reciprocal Maximization (ARM) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare through adaptive reciprocity.
    Cooperates in round 1, adapts based on cooperation rates and payoff comparisons,
    and conditions final round decision on historical cooperation levels.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        rounds_completed = current_round
        all_previous_actions = history.my_actions[:rounds_completed]
        all_opponent_actions = history.opponent_actions[:rounds_completed, :]
        total_cooperators = int(np.sum(all_previous_actions)) + int(np.sum(all_opponent_actions))
        cooperation_rate = total_cooperators / (self.n_players * rounds_completed)
        epsilon = 0.15 * self.k
        if current_round == self.n_rounds - 1:
            if cooperation_rate > 0.5:
                return Action.C
            else:
                return Action.D
        threshold = 0.4 + 0.2 * current_round / self.n_rounds
        my_payoffs = history.my_payoffs[:rounds_completed]
        my_avg_payoff = np.mean(my_payoffs)
        all_payoffs = np.concatenate([my_payoffs, history.opponent_payoffs[:rounds_completed, :].flatten()])
        universal_avg_payoff = np.mean(all_payoffs)
        if cooperation_rate > 0.65:
            return Action.C
        if cooperation_rate < 0.3:
            return Action.D
        if my_avg_payoff > universal_avg_payoff + 2 * epsilon:
            return Action.C
        if my_avg_payoff < universal_avg_payoff - 2 * epsilon:
            return Action.D
        if cooperation_rate > threshold:
            if my_avg_payoff >= universal_avg_payoff - epsilon:
                return Action.C
            else:
                return Action.D
        else:
            return Action.C

class Strategy_COLLECTIVE_451(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with individual sustainability through
    conditional reciprocity based on observed cooperation rates and game parameters.

    Core decision logic:
    - Rounds 1-3: COOPERATE (information gathering phase)
    - Rounds 4 to r-1: Cooperate if observed_cooperation_rate >= k/n, else defect
    - Last 2 rounds (if r > 4): DEFECT, else apply main phase logic
    - Special cases: Perfect coordination (90%), unanimous defection, threshold ties
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round <= 2:
            return Action.C
        total_cooperators = int(np.sum(history.opponent_actions[:current_round, :]))
        total_actions = self.n * current_round
        observed_rate = total_cooperators / total_actions if total_actions > 0 else 0.0
        threshold = self.k / self.n
        if observed_rate > threshold:
            main_action = Action.C
        elif observed_rate < threshold:
            main_action = Action.D
        else:
            main_action = Action.C
        if current_round >= self.r - 2 and self.r > 4:
            if observed_rate >= 0.9:
                return Action.C
            else:
                return Action.D
        if current_round > 0:
            prev_round_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
            if prev_round_cooperators == 0 and observed_rate < threshold:
                return Action.D
        return main_action

class Strategy_COLLECTIVE_452(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game.

    Prioritizes collective welfare maximization while maintaining individual resilience.
    Cooperates when cooperation reaches critical thresholds, defects when the commons
    collapses, with probabilistic escalation to give cooperation multiple chances.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        observation_window = min(3, round_number)
        total_cooperators = 0
        for i in range(round_number - observation_window, round_number):
            if i >= 0:
                my_coop = 1 if history.my_actions[i] else 0
                opponent_coop = sum(history.opponent_actions[i, :])
                total_cooperators += my_coop + opponent_coop
        recent_cooperation_rate = total_cooperators / (observation_window * self.n)
        threshold = self.k / self.n
        lower_threshold = threshold - 0.15
        if round_number == self.r - 1:
            final_threshold = self.k / (self.n - 1)
            if recent_cooperation_rate > final_threshold:
                return Action.C
            else:
                return Action.D
        elif recent_cooperation_rate >= threshold:
            return Action.C
        elif recent_cooperation_rate >= lower_threshold:
            prob_cooperate = recent_cooperation_rate * 2
            if random.random() < prob_cooperate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_453(BaseStrategy):
    """
    Adaptive Reciprocal Maximization (ARM): A collective strategy that balances
    group welfare optimization, robust reciprocity, and adaptive learning in
    N-player public goods games.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.punishment_memory = 0.0
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_idx = round_num - 1
        prev_opponent_actions = history.opponent_actions[prev_round_idx, :]
        cooperators_prev = int(np.sum(prev_opponent_actions))
        self_action_prev = int(history.my_actions[prev_round_idx])
        total_cooperators_prev = cooperators_prev + self_action_prev
        cooperation_rate = total_cooperators_prev / self.n
        base_threshold = self.k / self.n
        progress_factor = 0.05
        recency_bonus = round_num / self.r
        threshold = base_threshold - progress_factor * recency_bonus
        if self.n > 10:
            threshold += (self.n - 10) * 0.02
        if self.k < 1.5:
            threshold -= 0.1
        threshold = max(0.0, min(1.0, threshold))
        if cooperation_rate < 0.3 and self.punishment_memory < 2:
            self.punishment_memory = min(self.punishment_memory + 1, 2)
            return Action.D
        if cooperation_rate >= 0.6 and self.punishment_memory > 0:
            self.punishment_memory -= 0.5
        if round_num == self.r - 1:
            if cooperation_rate >= 0.5:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_454(BaseStrategy):
    """
    Adaptive Threshold Cooperation with Graduated Sanctions for N-Player Public Goods Game.

    A conditional cooperationist strategy that:
    - Starts with cooperation to signal willingness and gather information
    - Uses threshold-based decisions tied to the multiplication factor k/n
    - Applies graduated sanctions with probabilistic cooperation in marginal cases
    - Adapts behavior across three game phases
    - Respects the finality of the last round
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        phase1_end = math.floor(2 * self.r / 3)
        phase_near_terminal = math.floor(self.r - self.r / 4)
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            return self._final_round_decision(history)
        if current_round <= phase1_end:
            return self._phase1_decision(history, current_round)
        return self._phase2_decision(history, current_round, phase_near_terminal)

    def _get_cooperation_rate(self, history: PlayerHistory, round_idx: int) -> float:
        """Calculate cooperation rate for a given round (opponent + self perspective)."""
        cooperators = sum(history.opponent_actions[round_idx, :])
        return cooperators / self.n

    def _get_recent_cooperation_avg(self, history: PlayerHistory, current_round: int, window: int=3) -> float:
        """Calculate average cooperation rate over last `window` rounds."""
        start_round = max(0, current_round - window)
        rates = []
        for round_idx in range(start_round, current_round):
            rates.append(self._get_cooperation_rate(history, round_idx))
        return np.mean(rates) if rates else 0.0

    def _phase1_decision(self, history: PlayerHistory, current_round: int) -> Action:
        """Phase 1 (Rounds 1 to floor(2r/3)): Exploration & Cooperation Building."""
        cooperation_rate = self._get_cooperation_rate(history, current_round - 1)
        if current_round >= 2:
            prev_cooperation = self._get_cooperation_rate(history, current_round - 2)
            if prev_cooperation - cooperation_rate > 0.3:
                return Action.D
        if current_round <= 3 and cooperation_rate < self.threshold:
            return Action.D
        if cooperation_rate >= self.threshold:
            return Action.C
        elif cooperation_rate >= self.threshold - 1.0 / self.n:
            if random.random() < cooperation_rate / self.threshold:
                return Action.C
            return Action.D
        else:
            return Action.D

    def _phase2_decision(self, history: PlayerHistory, current_round: int, phase_near_terminal: int) -> Action:
        """Phase 2 (Rounds floor(2r/3)+1 to r-2): Reinforcement."""
        recent_avg = self._get_recent_cooperation_avg(history, current_round, window=3)
        threshold_adjusted = self.threshold
        if current_round >= phase_near_terminal:
            threshold_adjusted = self.threshold * 0.9
        if recent_avg >= threshold_adjusted:
            return Action.C
        elif recent_avg >= threshold_adjusted * 0.75:
            if random.random() < 0.6:
                return Action.C
            return Action.D
        else:
            return Action.D

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """Phase 3 (Final round): Last round effect."""
        cooperation_rate = self._get_cooperation_rate(history, self.r - 2)
        if cooperation_rate > self.threshold:
            return Action.C
        else:
            return Action.D

    class BaseStrategy:
        """Base class for strategies (stub for type compatibility)."""
        pass

class Strategy_COLLECTIVE_455(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation with Defection Resistance.

    Maximizes collective welfare while defending against exploitation through:
    1. Initial cooperation to establish baseline
    2. Dynamic adaptation based on observed cooperation rates
    3. Threshold-based decision making tied to game parameters
    4. Final round defection to capture maximum individual payoff
    5. Rolling average to prevent hair-trigger reactions
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.collective_benefit_threshold = (self.k - 1.0) / (self.n - 1.0)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            return Action.D
        previous_cooperation_rate = self._calculate_previous_cooperation_rate(current_round, history)
        if previous_cooperation_rate >= self.collective_benefit_threshold or previous_cooperation_rate >= 0.5:
            return Action.C
        elif previous_cooperation_rate > 0:
            return Action.D
        else:
            return Action.D

    def _calculate_previous_cooperation_rate(self, current_round: int, history: PlayerHistory) -> float:
        """
        Calculate the cooperation rate from previous rounds.
        Uses rolling average window of up to 3 rounds to prevent hair-trigger reactions.
        """
        if current_round == 1:
            cooperators_round_0 = np.sum(history.opponent_actions[0, :])
            return (cooperators_round_0 + float(history.my_actions[0])) / self.n
        else:
            window_size = min(3, current_round)
            start_idx = current_round - window_size
            cooperation_rates = []
            for round_idx in range(start_idx, current_round):
                cooperators_in_round = np.sum(history.opponent_actions[round_idx, :])
                cooperators_in_round += float(history.my_actions[round_idx])
                rate = cooperators_in_round / self.n
                cooperation_rates.append(rate)
            return np.mean(cooperation_rates)

class Strategy_COLLECTIVE_456(BaseStrategy):
    """
    Adaptive Contribution with Threshold Monitoring (ACTM)

    A strategy that maintains sustainable cooperation through conditional reciprocity.
    Players contribute when community cooperation exceeds thresholds, defect when it falls
    below, and scale probabilistically in uncertain zones. Terminal round defection is
    accepted as rational backward induction.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.theta_high = max(0.5, self.k / (self.k + 1))
        self.theta_low = 0.7 * self.theta_high

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            return Action.D
        previous_round_idx = current_round - 1
        cooperators_in_prev_round = int(sum(history.opponent_actions[previous_round_idx, :]))
        if history.my_actions[previous_round_idx]:
            cooperators_in_prev_round += 1
        cooperation_rate = cooperators_in_prev_round / self.n
        if cooperation_rate >= self.theta_high:
            return Action.C
        elif cooperation_rate < self.theta_low:
            return Action.D
        elif random.random() < cooperation_rate:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_457(BaseStrategy):
    """
    Adaptive Contribution Threshold (ACT) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare by using a dynamic cooperation
    threshold based on recent cooperation rates, payoff analysis, and round position.
    Cooperates when cooperation is observed (coop_rate >= threshold), defects in final round
    (unless high cooperation observed), and gracefully degrades when defection dominates.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            coop_rate_prev = self._calculate_cooperation_rate(history, current_round - 1)
            if coop_rate_prev >= 0.8:
                return Action.C
            else:
                return Action.D
        recent_coop_rate = self._calculate_recent_cooperation_rate(history, current_round)
        rounds_remaining = self.n_rounds - current_round
        if self.k >= self.n_players * 0.8:
            base_threshold = 0.3
        elif self.k <= 1.5:
            base_threshold = 0.6
        else:
            base_threshold = 0.5
        if recent_coop_rate >= base_threshold:
            return Action.C
        elif recent_coop_rate > 0.2 and rounds_remaining >= 5:
            return Action.C
        else:
            return Action.D
        if current_round > 0:
            my_prev_action = history.my_actions[current_round - 1]
            prev_coop_rate = self._calculate_cooperation_rate(history, current_round - 1)
            if my_prev_action and prev_coop_rate < 0.3:
                if rounds_remaining <= 3:
                    return Action.D
                else:
                    exploitation_count = self._count_exploitations(history, current_round)
                    recovery_prob = max(0.2, 1.0 - 0.15 * exploitation_count)
                    if random.random() < recovery_prob:
                        return Action.C
                    else:
                        return Action.D
        return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_idx: int) -> float:
        """Calculate cooperation rate of opponents in a specific round."""
        if round_idx < 0 or round_idx >= len(history.opponent_actions):
            return 0.0
        cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
        return cooperators / self.n_players if self.n_players > 0 else 0.0

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """Calculate average cooperation rate over last 3 rounds (or all previous if fewer)."""
        start_round = max(0, current_round - 3)
        end_round = current_round
        total_cooperators = 0
        total_observations = 0
        for round_idx in range(start_round, end_round):
            if round_idx < len(history.opponent_actions):
                cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
                total_cooperators += cooperators
                total_observations += self.n_players
        if total_observations == 0:
            return 0.0
        return total_cooperators / total_observations

    def _count_exploitations(self, history: PlayerHistory, current_round: int) -> int:
        """Count consecutive rounds where we cooperated but were exploited."""
        count = 0
        for round_idx in range(current_round - 1, -1, -1):
            if round_idx >= len(history.my_actions):
                break
            my_action = history.my_actions[round_idx]
            if not my_action:
                break
            coop_rate = self._calculate_cooperation_rate(history, round_idx)
            if coop_rate < 0.3:
                count += 1
            else:
                break
        return count

class Strategy_COLLECTIVE_458(BaseStrategy):
    """
    Conditional Reciprocal Threshold (CRT) Strategy for N-Player Public Goods Game.

    Employs reciprocal cooperation calibrated to collective welfare with adaptive thresholds
    based on observed group behavior. Cooperates in round 1, adapts to group cooperation rates,
    defects only when cooperation collapses below 20%, and applies endgame bonuses for cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == 1:
            my_payoff_round_0 = history.my_payoffs[0]
            if my_payoff_round_0 > 1.2:
                return Action.D
        cooperators_last_round = np.sum(history.opponent_actions[current_round - 1, :])
        total_cooperators_last_round = cooperators_last_round + (1 if history.my_actions[current_round - 1] else 0)
        cooperation_rate = total_cooperators_last_round / self.n
        danger_threshold = 0.2
        if cooperation_rate < danger_threshold:
            return Action.D
        coop_rates = []
        for r in range(current_round):
            coop_count = np.sum(history.opponent_actions[r, :])
            coop_count += 1 if history.my_actions[r] else 0
            coop_rates.append(coop_count / self.n)
        cooperation_rate_history_avg = np.mean(coop_rates)
        rounds_remaining_proportion = (self.r - current_round) / self.r
        threshold = 0.5 + 0.2 * cooperation_rate_history_avg - 0.1 * rounds_remaining_proportion
        threshold = max(0.3, min(0.7, threshold))
        if current_round == self.r - 2:
            threshold -= 0.1
        elif current_round == self.r - 1:
            threshold -= 0.15
        threshold = max(0.3, min(0.7, threshold))
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.C

class Strategy_COLLECTIVE_459(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare by:
    1. Signaling willingness to cooperate in round 1
    2. Adapting to observed cooperation rates
    3. Maintaining a sustainable cooperation threshold
    4. Penalizing free-riding through aggregate response

    Core decision rule:
    - Calculate observed cooperation rate from all previous rounds
    - Compare against threshold = 1 - (k/n)
    - Cooperate if rate > threshold, else defect
    - Uses hysteresis (threshold + 0.1) to avoid flip-flopping
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.cooperation_threshold = 1 - self.k / self.n_players
        self.recovery_threshold = self.cooperation_threshold + 0.1
        self.defecting_mode = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            self.defecting_mode = False
            return Action.C
        observed_coop_rate = self._calculate_cooperation_rate(history, round_number)
        if self.defecting_mode:
            if observed_coop_rate > self.recovery_threshold:
                self.defecting_mode = False
                return Action.C
            else:
                return Action.D
        elif observed_coop_rate <= self.cooperation_threshold:
            self.defecting_mode = True
            return Action.D
        else:
            return Action.C

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_number: int) -> float:
        """
        Calculate the observed cooperation rate across all previous rounds.

        cooperation_rate = total cooperators in rounds 0 to round_number-1 / (n_players * round_number)
        """
        if round_number <= 0:
            return 0.5
        total_cooperators = 0
        for r in range(round_number):
            if history.my_actions[r]:
                total_cooperators += 1
        for r in range(round_number):
            for opponent_idx in range(self.n_players - 1):
                if history.opponent_actions[r, opponent_idx]:
                    total_cooperators += 1
        total_player_rounds = self.n_players * round_number
        cooperation_rate = total_cooperators / total_player_rounds
        return cooperation_rate

class Strategy_COLLECTIVE_460(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game

    Balances collective welfare maximization, self-protection, and adaptive robustness.
    Uses a cooperation rate threshold (1/k) to determine when cooperation becomes individually rational.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = 1.0 / game_description.k
        self.last_cooperation_rate = 0.0
        self.rounds_below_threshold = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == r - 1:
            cooperators_previous = int(np.sum(history.opponent_actions[-1, :]))
            if history.my_actions[-1]:
                cooperators_previous += 1
            cooperation_rate = cooperators_previous / n
            if cooperation_rate >= self.threshold and cooperators_previous > n - 2:
                return Action.C
            return Action.D
        cooperators_previous = int(np.sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            cooperators_previous += 1
        cooperation_rate = cooperators_previous / n
        threshold_breached = cooperation_rate < self.threshold
        if abs(cooperation_rate - self.threshold) <= 0.1:
            if threshold_breached:
                self.rounds_below_threshold += 1
                if self.rounds_below_threshold >= 2:
                    self.rounds_below_threshold = 0
                    return Action.D
                else:
                    return Action.C if history.my_actions[-1] else Action.D
            else:
                self.rounds_below_threshold = 0
                return Action.C
        else:
            self.rounds_below_threshold = 0
        if cooperation_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_461(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game

    Balances individual rationality with collective welfare by:
    1. Starting cooperative to signal good faith
    2. Adapting based on observed cooperation rates
    3. Using a threshold (k/n) to determine when cooperation is collectively beneficial
    4. Applying probabilistic cooperation when cooperation is declining but not collapsed
    5. Resisting late-game defection to maintain collective stability
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        cooperation_rate = self._calculate_cooperation_rate(history, round_t)
        early_phase_end = math.ceil(self.n_rounds / 3)
        late_phase_start = math.ceil(2 * self.n_rounds / 3)
        if round_t < early_phase_end:
            return self._early_phase_decision(history, cooperation_rate, round_t)
        if round_t >= late_phase_start:
            return self._late_phase_decision(cooperation_rate)
        return self._adaptive_threshold_decision(cooperation_rate)

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_t: int) -> float:
        """
        Calculate the average cooperation rate of opponents over recent rounds.
        Uses a window of up to 10 recent rounds.
        """
        window_size = min(10, round_t)
        if window_size == 0:
            return 1.0
        recent_actions = history.opponent_actions[-window_size:, :]
        total_cooperations = np.sum(recent_actions)
        total_possible = window_size * self.n_players
        cooperation_rate = total_cooperations / total_possible if total_possible > 0 else 1.0
        return cooperation_rate

    def _early_phase_decision(self, history: PlayerHistory, cooperation_rate: float, round_t: int) -> Action:
        """
        Early rounds: maintain cooperation to build reputation and test opponents.
        Give slow-to-trust opponents 2-3 rounds to reciprocate before judging.
        """
        early_tolerance_rounds = min(3, self.n_rounds // 4)
        if round_t <= early_tolerance_rounds:
            return Action.C
        collapse_threshold = 0.3
        if cooperation_rate < collapse_threshold:
            return Action.D
        return Action.C

    def _late_phase_decision(self, cooperation_rate: float) -> Action:
        """
        Late rounds: sustain cooperation if group has stabilized, resist endgame defection.
        Only defect if the group has clearly failed (rate < 0.5 * threshold).
        """
        if cooperation_rate >= self.threshold:
            return Action.C
        half_threshold = 0.5 * self.threshold
        if cooperation_rate >= half_threshold:
            return Action.C
        return Action.D

    def _adaptive_threshold_decision(self, cooperation_rate: float) -> Action:
        """
        Middle rounds: apply standard adaptive threshold logic with probabilistic mixing.
        """
        if cooperation_rate >= self.threshold:
            return Action.C
        moderate_threshold = 0.6 * self.threshold
        if cooperation_rate >= moderate_threshold:
            probability = cooperation_rate / self.threshold
            if random.random() < probability:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_COLLECTIVE_462(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization, individual robustness, and dynamic adaptation
    through graduated reciprocity based on historical cooperation rates and game position.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            return Action.D
        previous_round_idx = current_round - 1
        cooperators_in_previous = sum(history.opponent_actions[previous_round_idx, :])
        coop_rate = cooperators_in_previous / self.n
        threshold = self.k / self.n
        if coop_rate >= threshold:
            return Action.C
        elif coop_rate >= threshold * 0.5:
            prob = coop_rate / threshold
            if random.random() < prob:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_463(BaseStrategy):
    """
    Adaptive Reciprocal Maximization (ARM): A strategy that balances collective value creation
    with robust self-protection through adaptive thresholds based on observed cooperation rates.

    Core mechanism: Cooperate when observed cooperation rate meets or exceeds the rational
    breakeven threshold (k-1)/k, where the per-capita public good return equals the private
    benefit of defection. Otherwise defect, with soft punishment for near-threshold rates.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.k - 1) / self.k
        self.decay_factor = 0.05 if self.n_rounds > 20 else 0.0
        self.epsilon = 1.0 / (2.0 * self.n_players)
        self.weighted_coop_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        previous_round_opponent_actions = history.opponent_actions[current_round - 1, :]
        cooperators_in_previous_round = np.sum(previous_round_opponent_actions)
        observed_coop_rate = cooperators_in_previous_round / (self.n_players - 1)
        if self.decay_factor > 0:
            effective_rate = self._calculate_weighted_cooperation_rate(observed_coop_rate, current_round)
        else:
            effective_rate = observed_coop_rate
        if effective_rate >= self.threshold:
            return Action.C
        elif effective_rate >= self.threshold - self.epsilon:
            punishment_probability = 1.0 - effective_rate / self.threshold
            if random.random() < punishment_probability:
                return Action.D
            else:
                return Action.C
        else:
            return Action.D

    def _calculate_weighted_cooperation_rate(self, current_rate: float, current_round: int) -> float:
        """
        Calculate exponential weighted average of cooperation rates.
        More recent rounds have higher weight; older rounds decay exponentially.
        """
        self.weighted_coop_history.append(current_rate)
        weights = []
        total_weight = 0.0
        for i, rate in enumerate(self.weighted_coop_history):
            distance = len(self.weighted_coop_history) - 1 - i
            weight = (1.0 - self.decay_factor) ** distance
            weights.append(weight)
            total_weight += weight
        if total_weight > 0:
            weighted_average = sum((r * w for r, w in zip(self.weighted_coop_history, weights))) / total_weight
            return weighted_average
        else:
            return current_rate

class Strategy_COLLECTIVE_464(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare through:
    1. Initial cooperation to signal good faith
    2. Conditional reciprocation based on observed cooperation rates
    3. Last-round defection to avoid exploitation
    4. Probabilistic recovery mechanism to prevent cascading defection
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        last_round_idx = current_round - 1
        last_round_cooperators = int(sum(history.opponent_actions[last_round_idx, :]))
        if history.my_actions[last_round_idx]:
            last_round_cooperators += 1
        cooperation_rate = last_round_cooperators / self.n_players
        if cooperation_rate >= self.threshold:
            return Action.C
        elif cooperation_rate > 0:
            probability_cooperate = min(0.9, cooperation_rate + 0.1)
            if random.random() < probability_cooperate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_465(BaseStrategy):
    """
    Adaptive Contribution with Decay-Resistant Cooperation strategy for N-Player Public Goods Game.

    Core principles:
    1. Cooperate in round 1 to establish goodwill
    2. Base subsequent decisions on cooperation rate vs. threshold k/n
    3. Attempt recovery from defection spirals when cooperation falls below k/n * 0.5
    4. Maintain consistency through final round
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n
        self.low_cooperation_threshold = self.threshold * 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round_idx = state.round_number - 1
        cooperators_previous = int(np.sum(history.opponent_actions[previous_round_idx, :]))
        cooperation_rate = cooperators_previous / self.n
        if cooperation_rate >= self.threshold:
            return Action.C
        if cooperation_rate < self.low_cooperation_threshold:
            defection_streak = self._count_low_cooperation_streak(history, previous_round_idx)
            recovery_window = 3 * self.r / 4
            if defection_streak >= 2 and state.round_number < recovery_window:
                return Action.C
        return Action.D

    def _count_low_cooperation_streak(self, history: PlayerHistory, up_to_round: int) -> int:
        """
        Count consecutive rounds of low cooperation (cooperation_rate < low_cooperation_threshold)
        looking backwards from up_to_round.
        """
        streak = 0
        for round_idx in range(up_to_round, -1, -1):
            cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
            cooperation_rate = cooperators / self.n
            if cooperation_rate < self.low_cooperation_threshold:
                streak += 1
            else:
                break
        return streak

class Strategy_COLLECTIVE_466(BaseStrategy):
    """
    Adaptive Reciprocal Maximization (ARM) Strategy for N-Player Public Goods Game.

    Balances individual security, collective efficiency, and adaptive robustness by:
    1. Always cooperating in round 1 (costly signal of reciprocal intent)
    2. Using a mathematically-derived threshold to decide cooperation in subsequent rounds
    3. Adapting to environmental changes through decay functions and collapse detection
    4. Maintaining consistency in final rounds to influence opponent modeling
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.k = game_description.k
        self.n_rounds = game_description.n_rounds
        self.threshold = (self.k - 1) / (self.n_players * self.k)
        self.last_cooperation_rate = 0.0
        self.consecutive_payoff_loss_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        cooperation_rate = self._calculate_cooperation_rate(history, round_t)
        if self._detect_collapse(history, round_t):
            return Action.D
        if self._check_payoff_loss_pattern(history, round_t):
            self.consecutive_payoff_loss_rounds += 1
            if self.consecutive_payoff_loss_rounds >= 3:
                self.consecutive_payoff_loss_rounds = 0
                return Action.D
        else:
            self.consecutive_payoff_loss_rounds = 0
        adjusted_threshold = self._adjust_threshold(history, round_t)
        if cooperation_rate > adjusted_threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_t: int) -> float:
        """Calculate weighted or simple cooperation rate based on game length."""
        if round_t <= 1:
            return 0.0
        if self.n_rounds > 20:
            return self._weighted_coop_rate(history, round_t)
        else:
            return self._simple_coop_rate(history, round_t)

    def _simple_coop_rate(self, history: PlayerHistory, round_t: int) -> float:
        """Simple unweighted cooperation rate from rounds 0 to round_t-1."""
        total_cooperators = np.sum(history.opponent_actions[:round_t, :])
        total_cooperators += np.sum(history.my_actions[:round_t])
        total_possible = self.n_players * round_t
        return total_cooperators / total_possible if total_possible > 0 else 0.0

    def _weighted_coop_rate(self, history: PlayerHistory, round_t: int) -> float:
        """Weighted cooperation rate giving more weight to recent rounds."""
        weighted_sum = 0.0
        weight_total = 0.0
        for t in range(round_t):
            weight = 1.0 + t / self.n_rounds
            round_cooperators = np.sum(history.opponent_actions[t, :]) + (1.0 if history.my_actions[t] else 0.0)
            weighted_sum += round_cooperators * weight
            weight_total += weight * self.n_players
        return weighted_sum / weight_total if weight_total > 0 else 0.0

    def _detect_collapse(self, history: PlayerHistory, round_t: int) -> bool:
        """Detect cascading defection (sharp drop in cooperation)."""
        if round_t < 3:
            return False
        last_round_cooperators = np.sum(history.opponent_actions[round_t - 1, :]) + (1.0 if history.my_actions[round_t - 1] else 0.0)
        prev_round_cooperators = np.sum(history.opponent_actions[round_t - 2, :]) + (1.0 if history.my_actions[round_t - 2] else 0.0)
        drop = prev_round_cooperators - last_round_cooperators
        collapse_threshold = self.n_players * 0.3
        return drop > collapse_threshold

    def _check_payoff_loss_pattern(self, history: PlayerHistory, round_t: int) -> bool:
        """Check if recent rounds show consistent payoff loss from cooperation."""
        if round_t < 2:
            return False
        my_last_action = history.my_actions[round_t - 1]
        my_last_payoff = history.my_payoffs[round_t - 1]
        total_cooperators_last = np.sum(history.opponent_actions[round_t - 1, :])
        if my_last_action:
            expected_if_defected = 1.0 + self.k / self.n_players * total_cooperators_last
            return expected_if_defected > my_last_payoff
        else:
            expected_if_cooperated = self.k / self.n_players * (total_cooperators_last + 1)
            return expected_if_cooperated > my_last_payoff
        return False

    def _adjust_threshold(self, history: PlayerHistory, round_t: int) -> float:
        """Adjust threshold based on observed payoff patterns and cooperation trends."""
        if round_t < 3:
            return self.threshold
        adjusted_threshold = self.threshold
        recent_defection_better = 0
        recent_cooperation_better = 0
        cooperation_rising = False
        for t in range(max(0, round_t - 3), round_t):
            my_action = history.my_actions[t]
            my_payoff = history.my_payoffs[t]
            total_cooperators = np.sum(history.opponent_actions[t, :])
            if my_action:
                expected_if_defected = 1.0 + self.k / self.n_players * total_cooperators
                if expected_if_defected > my_payoff:
                    recent_defection_better += 1
                else:
                    recent_cooperation_better += 1
            else:
                expected_if_cooperated = self.k / self.n_players * (total_cooperators + 1)
                if expected_if_cooperated > my_payoff:
                    recent_cooperation_better += 1
        if round_t >= 4:
            coop_rate_prev = self._calculate_cooperation_rate(history, round_t - 1)
            coop_rate_curr = self._calculate_cooperation_rate(history, round_t)
            cooperation_rising = coop_rate_curr > coop_rate_prev
        if recent_defection_better >= 3:
            adjusted_threshold = self.threshold * 0.9
        elif cooperation_rising and recent_cooperation_better > 0:
            adjusted_threshold = self.threshold
        return adjusted_threshold

class Strategy_COLLECTIVE_467(BaseStrategy):
    """
    Conditional Reciprocal Maximization: Adaptive strategy that balances individual rationality
    with collective welfare by dynamically adjusting cooperation based on observed group behavior.

    Core logic:
    - Round 0: COOPERATE (probe/signal willingness)
    - Subsequent rounds: Analyze cooperation rate from last 2 rounds
      - High cooperation (40%): COOPERATE
      - Medium cooperation (20-40%): DEFECT (signal intolerance)
      - Low cooperation (20%): DEFECT (mutual defection equilibrium)
    - Recovery: If defecting and cooperation resurges (35%), return to COOPERATE
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_low = max(0.3, (1.0 + game_description.k / game_description.n_players) / (2.0 * game_description.n_players))
        self.threshold_recovery = self.threshold_low - 0.05

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number < 2:
            return Action.C
        recent_start = max(0, state.round_number - 2)
        recent_end = state.round_number
        total_cooperators = 0
        for round_idx in range(recent_start, recent_end):
            if history.my_actions[round_idx]:
                total_cooperators += 1
            total_cooperators += sum(history.opponent_actions[round_idx, :])
        rounds_examined = recent_end - recent_start
        c_rate = total_cooperators / (self.game_description.n_players * rounds_examined)
        my_last_action = history.my_actions[state.round_number - 1]
        if my_last_action:
            if c_rate >= self.threshold_low:
                return Action.C
            else:
                return Action.D
        elif c_rate >= self.threshold_recovery:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_468(BaseStrategy):
    """
    Collective Strategy for N-Player Public Goods Game

    Balances individual rationality with collective welfare through conditional cooperation
    with adaptive thresholds, exploitation detection, and strategic endgame defection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.exploitation_resilience = 3
        self.pure_defect_mode = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round <= 1:
            return Action.C
        if self.pure_defect_mode:
            return Action.D
        K = min(3, current_round - 1)
        recent_cooperators = 0
        for t in range(current_round - K, current_round):
            if t >= 0:
                recent_cooperators += int(np.sum(history.opponent_actions[t, :]))
        recent_rate = recent_cooperators / ((n - 1) * K)
        times_we_cooperated = int(np.sum(history.my_actions[:current_round]))
        times_exploited = 0
        if times_we_cooperated > 0:
            for t in range(current_round):
                if history.my_actions[t]:
                    opponents_cooperated = int(np.sum(history.opponent_actions[t, :]))
                    if opponents_cooperated < n - 1:
                        times_exploited += 1
            exploitation_score = times_exploited / max(times_we_cooperated, 1)
            if exploitation_score > 0.7:
                self.exploitation_resilience -= 1
                if self.exploitation_resilience == 0:
                    self.pure_defect_mode = True
                    return Action.D
        if current_round == r - 1:
            my_total_payoff = float(np.sum(history.my_payoffs[:current_round]))
            mean_payoff = float(np.mean(history.opponent_payoffs[:current_round]))
            if my_total_payoff >= mean_payoff:
                return Action.D
            elif recent_rate >= 0.5:
                return Action.C
            else:
                return Action.D
        if current_round == r - 2:
            my_total_payoff = float(np.sum(history.my_payoffs[:current_round]))
            opponent_mean_payoff = float(np.mean(history.opponent_payoffs[:current_round]))
            all_payoffs = np.concatenate([[my_total_payoff], history.opponent_payoffs[:current_round].flatten()])
            percentile_75 = float(np.percentile(all_payoffs, 75))
            if my_total_payoff >= percentile_75:
                return Action.D
        if recent_rate >= 0.5:
            return Action.C
        elif recent_rate >= 0.3:
            if random.random() < recent_rate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_469(BaseStrategy):
    """
    Adaptive Graduated Reciprocity with Collective Welfare Focus.

    Balances individual rationality with collective welfare through:
    - Initial cooperation (rounds 0-2) to establish good faith
    - Adaptive response based on collective cooperation rate (rounds 3 to r-2)
    - Final cooperation (round r-1) to maximize collective welfare
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        n = self.n_players
        r = self.n_rounds
        if round_number <= 2:
            return Action.C
        if round_number == r - 1:
            return Action.C
        prev_round_idx = round_number - 1
        my_prev_action = history.my_actions[prev_round_idx]
        opponent_prev_actions = history.opponent_actions[prev_round_idx, :]
        total_cooperators = int(my_prev_action) + int(np.sum(opponent_prev_actions))
        cooperation_rate = total_cooperators / n
        if cooperation_rate >= 0.5:
            return Action.C
        elif cooperation_rate >= 0.25:
            if random.random() < cooperation_rate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_470(BaseStrategy):
    """
    Adaptive Reciprocal Provisioning (ARP): A collective strategy that maximizes
    welfare through observable, reciprocal behavior. Cooperates when cooperation is
    collectively beneficial and reciprocated, defects when the group abandons cooperation,
    with special handling for first and final rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.in_defection_mode = False
        self.break_even = 1.0 / self.k
        self.threshold_mid = self.break_even - 0.05
        self.threshold_final = self.break_even - 0.1
        self.defection_threshold = self.break_even - 0.15

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        prev_cooperators = int(sum(history.opponent_actions[round_t - 1, :]))
        coop_rate = prev_cooperators / self.n
        if round_t >= 2:
            coop_rate_prev_prev = int(sum(history.opponent_actions[round_t - 2, :])) / self.n
            coop_rate_prev = coop_rate
            if coop_rate_prev_prev < self.defection_threshold and coop_rate_prev < self.defection_threshold:
                self.in_defection_mode = True
        if self.in_defection_mode:
            if coop_rate > self.threshold_mid:
                self.in_defection_mode = False
                return Action.C
            else:
                return Action.D
        is_final_rounds = round_t >= self.r - 2
        threshold = self.threshold_final if is_final_rounds else self.threshold_mid
        if coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_471(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances mutual benefit maximization, robust self-protection against free-riders,
    and adaptive learning. Uses conditional cooperation based on historical cooperation
    rates with adaptive thresholds that evolve across game phases.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        cooperation_rate = self._calculate_cooperation_rate(history, round_num)
        threshold = self._get_threshold(round_num)
        if self.n_players <= 3:
            threshold = max(0.0, threshold - 0.15)
        if round_num == self.n_rounds - 1:
            threshold = 0.4
            if self.n_players <= 3:
                threshold = max(0.0, threshold - 0.15)
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate the cooperation rate from history.
        Uses 3-round moving average if available to smooth noise.
        """
        if round_num <= 1:
            total_cooperators = np.sum(history.opponent_actions[0, :])
            cooperation_rate = total_cooperators / self.n_players
        elif round_num <= 4:
            total_cooperators = np.sum(history.opponent_actions[:round_num, :])
            cooperation_rate = total_cooperators / (round_num * self.n_players)
        else:
            start_idx = max(0, round_num - 4)
            end_idx = round_num
            total_cooperators = np.sum(history.opponent_actions[start_idx:end_idx, :])
            window_size = end_idx - start_idx
            cooperation_rate = total_cooperators / (window_size * self.n_players)
        return cooperation_rate

    def _get_threshold(self, round_num: int) -> float:
        """
        Determine threshold based on game phase.
        Rounds are 0-indexed, so round_num in [0, n_rounds-1].
        """
        half_rounds = self.n_rounds / 2.0
        if round_num <= 2:
            return 0.5
        elif round_num <= half_rounds:
            return 0.45
        elif round_num < self.n_rounds - 1:
            return 0.5
        else:
            return 0.4

class Strategy_COLLECTIVE_472(BaseStrategy):
    """
    Adaptive Reciprocal Stewardship (ARS): A strategy that balances personal resilience,
    collective trust-building, and dynamic adaptation in N-player public goods games.

    The strategy uses conditional cooperation based on observed group cooperation rates,
    personal payoff relative to group average, and remaining rounds. Thresholds are
    calibrated to the benefit structure (k/n) to ensure mathematically sound decisions.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.consecutive_low_coop_rounds = 0

    def _calculate_cooperation_rate(self, history: PlayerHistory, window: int) -> float:
        """Calculate the cooperation rate from recent rounds."""
        if len(history.my_actions) == 0:
            return 1.0
        start_idx = max(0, len(history.my_actions) - window)
        end_idx = len(history.my_actions)
        total_slots = 0
        total_cooperators = 0
        for round_idx in range(start_idx, end_idx):
            if history.my_actions[round_idx]:
                total_cooperators += 1
            total_slots += 1
            for opponent_idx in range(self.n_players - 1):
                if history.opponent_actions[round_idx, opponent_idx]:
                    total_cooperators += 1
                total_slots += 1
        if total_slots == 0:
            return 1.0
        cooperation_rate = total_cooperators / total_slots
        return cooperation_rate

    def _get_recent_payoff(self, history: PlayerHistory, window: int) -> float:
        """Calculate my average payoff over recent rounds."""
        if len(history.my_payoffs) == 0:
            return 0.0
        start_idx = max(0, len(history.my_payoffs) - window)
        recent_payoffs = history.my_payoffs[start_idx:]
        if len(recent_payoffs) == 0:
            return 0.0
        return float(np.mean(recent_payoffs))

    def _get_group_average_payoff(self, history: PlayerHistory, window: int) -> float:
        """Calculate the average payoff of all players over recent rounds."""
        if len(history.my_payoffs) == 0:
            return 0.0
        start_idx = max(0, len(history.my_payoffs) - window)
        all_payoffs = []
        all_payoffs.extend(history.my_payoffs[start_idx:])
        for round_idx in range(start_idx, len(history.opponent_payoffs)):
            all_payoffs.extend(history.opponent_payoffs[round_idx, :])
        if len(all_payoffs) == 0:
            return 0.0
        return float(np.mean(all_payoffs))

    def _is_small_group(self) -> bool:
        """Check if group size is small (n=2)."""
        return self.n_players == 2

    def _is_very_short_game(self) -> bool:
        """Check if game is very short (r=2)."""
        return self.n_rounds == 2

    def _is_long_game(self) -> bool:
        """Check if game is long (r > 20)."""
        return self.n_rounds > 20

    def _get_threshold_multiplier(self) -> float:
        """Get the base threshold multiplier, adjusted for group size."""
        base_multiplier = 0.6
        if self._is_small_group():
            return base_multiplier - 0.1
        return base_multiplier

    def _get_lower_threshold_multiplier(self) -> float:
        """Get the lower threshold multiplier, adjusted for group size."""
        base_multiplier = 0.4
        if self._is_small_group():
            return base_multiplier - 0.1
        return base_multiplier

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        benefit_ratio = self.k / self.n_players
        window_size = 3
        if self._is_long_game():
            window_size = 5
        recent_coop_rate = self._calculate_cooperation_rate(history, window_size)
        my_recent_payoff = self._get_recent_payoff(history, window_size)
        group_average_payoff = self._get_group_average_payoff(history, window_size)
        if recent_coop_rate < self._get_lower_threshold_multiplier() * benefit_ratio:
            self.consecutive_low_coop_rounds += 1
        else:
            self.consecutive_low_coop_rounds = 0
        if self.consecutive_low_coop_rounds >= 2:
            rounds_remaining = self.n_rounds - current_round
            if rounds_remaining <= 2:
                if recent_coop_rate >= 0.7 * benefit_ratio:
                    return Action.C
            return Action.D
        if recent_coop_rate > 0.95:
            return Action.C
        rounds_remaining = self.n_rounds - current_round
        if rounds_remaining <= 2:
            if recent_coop_rate >= 0.7 * benefit_ratio:
                return Action.C
            elif recent_coop_rate >= 0.5 * benefit_ratio:
                if my_recent_payoff < group_average_payoff:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D
        threshold_high = self._get_threshold_multiplier() * benefit_ratio
        threshold_low = self._get_lower_threshold_multiplier() * benefit_ratio
        if recent_coop_rate >= threshold_high:
            return Action.C
        elif recent_coop_rate < threshold_low:
            return Action.D
        elif my_recent_payoff < group_average_payoff * 1.1:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_473(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC): A conditional cooperative strategy that
    maximizes collective welfare while protecting against exploitation.

    - Round 1: Cooperate (gather information and signal good faith)
    - Rounds 2 to r-1: Cooperate iff observed cooperation rate >= k/n threshold
    - Final Round: Defect (no future rounds to influence)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.critical_threshold = self.k / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        prev_round_idx = current_round - 1
        my_prev_action = history.my_actions[prev_round_idx]
        opponents_prev_actions = history.opponent_actions[prev_round_idx, :]
        total_cooperators = int(my_prev_action) + int(np.sum(opponents_prev_actions))
        cooperation_rate = total_cooperators / self.n_players
        if cooperation_rate >= self.critical_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_474(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Three-phase strategy:
    1. Phase 1 (Round 0): Cooperate to establish cooperative signal and gather information
    2. Phase 2 (Rounds 1 to r-2): Reciprocate based on historical cooperation rate vs. threshold k/n
    3. Phase 3 (Round r-1): Defect in final round (subgame perfect equilibrium)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.cooperation_threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        rounds_elapsed = current_round
        total_cooperators = np.sum(history.opponent_actions[:rounds_elapsed, :]) + np.sum(history.my_actions[:rounds_elapsed])
        total_player_rounds = rounds_elapsed * self.n_players
        historical_coop_rate = total_cooperators / total_player_rounds
        if historical_coop_rate >= self.cooperation_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_475(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Maximizes collective welfare while remaining robust to exploitation through:
    - Conditional cooperation with exponential decay weighting
    - Graduated punishment responses based on defection severity
    - Forgiveness windows to recover from temporary defection periods
    - Special handling for initial and final rounds
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.decay_factor = 0.85
        self.threshold = (self.k - 1) / (self.n - 1) * 0.9

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        weighted_coop = self._calculate_weighted_cooperation(history, current_round)
        cooperation_rate = weighted_coop
        if current_round == self.r - 1:
            if cooperation_rate >= self.threshold:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= self.threshold:
            return Action.C
        else:
            defection_severity = self._calculate_defection_severity(history, current_round)
            punishment_prob = min(0.8, defection_severity * 2)
            if random.random() < punishment_prob:
                return Action.D
            else:
                return Action.C

    def _calculate_weighted_cooperation(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate weighted cooperation rate using exponential decay.
        Recent rounds are weighted more heavily.
        """
        if current_round == 0:
            return 1.0
        weighted_sum = 0.0
        total_weight = 0.0
        for t in range(current_round):
            cooperators_in_t = np.sum(history.opponent_actions[t, :]) + (1 if history.my_actions[t] else 0)
            cooperation_rate_t = cooperators_in_t / self.n
            weight = self.decay_factor ** (current_round - 1 - t)
            weighted_sum += cooperation_rate_t * weight
            total_weight += weight
        if total_weight == 0:
            return 1.0
        return weighted_sum / total_weight

    def _calculate_defection_severity(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate defection severity based on the gap between expected and actual cooperators.
        Uses weighted recent history to identify trends.
        """
        if current_round == 0:
            return 0.0
        recent_weight = 0.0
        recent_coop_sum = 0.0
        lookback = min(3, current_round)
        for t in range(current_round - lookback, current_round):
            if t < 0:
                continue
            weight = self.decay_factor ** (current_round - 1 - t)
            cooperators_in_t = np.sum(history.opponent_actions[t, :]) + (1 if history.my_actions[t] else 0)
            cooperation_rate_t = cooperators_in_t / self.n
            recent_coop_sum += cooperation_rate_t * weight
            recent_weight += weight
        if recent_weight == 0:
            return 0.0
        weighted_recent_coop = recent_coop_sum / recent_weight
        expected_cooperation = self.threshold
        defection_severity = max(0.0, expected_cooperation - weighted_recent_coop)
        return defection_severity

class Strategy_COLLECTIVE_476(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare through adaptive threshold reciprocity.
    - Round 1: Cooperate unconditionally to establish cooperative signal
    - Subsequent rounds: Reciprocate based on adaptive threshold that decays over time
    - Threshold function: threshold_t = k/n + (1 - k/n)  (r - t) / (r - 1)
    - Sharp cooperation drops trigger conservative threshold dampening
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        if t == 0:
            return Action.C
        prev_round_idx = t - 1
        prev_cooperators = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        cooperation_rate = prev_cooperators / self.n_players
        threshold = self._calculate_threshold(t)
        if t > 1:
            threshold = self._apply_shock_dampening(threshold, history, prev_round_idx)
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_threshold(self, t: int) -> float:
        """
        Calculate adaptive threshold for round t.

        threshold_t = k/n + (1 - k/n)  (r - t) / (r - 1)

        At t=1: threshold approaches 1.0 (strict, near-universal cooperation required)
        As t increases: threshold decays toward k/n
        At t=r-1 (final round): threshold = k/n (most permissive)
        """
        baseline = self.k / self.n_players
        decline = 1.0 - baseline
        remaining_rounds = self.n_rounds - t
        total_remaining = self.n_rounds - 1
        threshold = baseline + decline * (remaining_rounds / total_remaining)
        return threshold

    def _apply_shock_dampening(self, threshold: float, history: PlayerHistory, prev_round_idx: int) -> float:
        """
        Apply conservative threshold dampening if cooperation drops sharply.

        If cooperation_rate drops by more than 30% from the round before previous,
        apply a conservative cap to prevent oscillatory revenge cycles.
        """
        if prev_round_idx < 1:
            return threshold
        prev_prev_round_idx = prev_round_idx - 1
        prev_cooperators = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        prev_prev_cooperators = int(np.sum(history.opponent_actions[prev_prev_round_idx, :]))
        prev_rate = prev_cooperators / self.n_players
        prev_prev_rate = prev_prev_cooperators / self.n_players
        cooperation_drop = prev_prev_rate - prev_rate
        if cooperation_drop < -0.3:
            conservative_threshold = self.k / self.n_players + 0.1
            threshold = min(threshold, conservative_threshold)
        return threshold

class Strategy_COLLECTIVE_477(BaseStrategy):
    """
    Adaptive Contribution with Threshold Enforcement strategy for N-Player Public Goods Game.

    Balances collective welfare maximization, robustness against exploitation, and adaptive recovery.
    Core mechanism: Cooperate when observed cooperation rate >= k/n threshold, with adjustments
    for cooperation trends, early-game probing, and population variance.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.base_threshold = game_description.k / game_description.n_players
        self.reassess_flag = False
        self.defect_until_round = -1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        n_rounds = self.game_description.n_rounds
        n_players = self.game_description.n_players
        if round_num == 0:
            return Action.C
        all_cooperators = np.sum(history.opponent_actions, axis=1)
        cooperation_counts = all_cooperators + history.my_actions.astype(int)
        cooperation_rates = cooperation_counts / n_players
        avg_cooperation_rate = np.mean(cooperation_rates)
        if round_num == n_rounds - 1:
            if avg_cooperation_rate >= self.base_threshold:
                return Action.C
            else:
                return Action.D
        if n_rounds > 10 and round_num <= 4 and (round_num > 0) and (avg_cooperation_rate == 0) and (self.defect_until_round < 0):
            self.defect_until_round = round_num + 3
            return Action.D
        if self.reassess_flag and round_num >= 8:
            self.reassess_flag = False
            return Action.C
        if self.defect_until_round >= round_num and self.defect_until_round >= 0:
            if round_num == self.defect_until_round:
                self.reassess_flag = True
            return Action.D
        threshold = self.base_threshold
        if round_num >= 6:
            third_size = max(1, round_num // 3)
            first_third_coop = np.mean(cooperation_rates[:third_size])
            last_third_coop = np.mean(cooperation_rates[-third_size:])
            cooperation_trend = last_third_coop - first_third_coop
            if cooperation_trend < -0.15:
                threshold = self.base_threshold * 1.05
            elif cooperation_trend > 0.1:
                threshold = self.base_threshold * 0.95
        variance = np.var(cooperation_rates) if len(cooperation_rates) > 1 else 0.0
        if variance > 0.4:
            threshold = self.base_threshold * 1.2
        if avg_cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_478(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with individual security through graduated reciprocity.
    Contributes proportionally to observed cooperation rates, starting optimistically but adapting
    defensively when necessary.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_idx = round_num - 1
        self_cooperated_prev = history.my_actions[prev_round_idx]
        opponent_cooperators_prev = sum(history.opponent_actions[prev_round_idx, :])
        total_cooperators_prev = int(self_cooperated_prev) + opponent_cooperators_prev
        observed_coop_rate = total_cooperators_prev / self.n
        if round_num == self.r - 1:
            if observed_coop_rate >= 0.6:
                return Action.C
            elif observed_coop_rate >= 0.35:
                if random.random() < observed_coop_rate:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D
        if self.r > 20:
            cooperation_threshold = 0.5 + 0.15 * (round_num - 1) / (self.r - 2)
        elif self.r == 2:
            cooperation_threshold = 0.4
        else:
            cooperation_threshold = 0.5 + 0.2 * (round_num - 1) / (self.r - 2)
        if self.n == 2:
            cooperation_threshold = max(0.0, cooperation_threshold - 0.1)
        if observed_coop_rate >= cooperation_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_479(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare with self-protection by:
    1. Starting with cooperation in round 1 to signal collaborative intent
    2. Computing observed cooperation rate across all players and rounds
    3. Cooperating when rate  adaptive threshold (k/n with end-game adjustment)
    4. Defecting when cooperation rate falls below threshold to protect against exploitation
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        all_actions = np.concatenate([history.my_actions[:current_round], history.opponent_actions[:current_round, :].flatten()])
        cooperation_count = np.sum(all_actions)
        total_possible = self.n * current_round
        observed_rate = cooperation_count / total_possible
        base_threshold = self.k / self.n
        if current_round == self.r - 1:
            adjusted_threshold = base_threshold + 0.15
        else:
            adjusted_threshold = base_threshold + 0.1 * current_round / self.r
        if observed_rate >= adjusted_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_480(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game

    Balances individual rationality with collective welfare by:
    1. Rewarding cooperation through measured reciprocation
    2. Punishing defection with strategic withholding
    3. Recovering cooperation through gradual trust rebuilding
    4. Optimizing for collective outcome while protecting against exploitation
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def _get_phase(self, round_number: int) -> str:
        """Classify current round into phase: EARLY, MIDDLE, or LATE"""
        early_end = math.ceil(self.r / 3)
        late_start = math.floor(2 * self.r / 3) + 1
        if round_number <= early_end:
            return 'EARLY'
        elif round_number < late_start:
            return 'MIDDLE'
        else:
            return 'LATE'

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate proportion of rounds where majority played C"""
        if len(history.my_actions) == 0:
            return 0.0
        rounds_with_majority_c = 0
        for round_idx in range(len(history.my_actions)):
            cooperators = int(history.my_actions[round_idx]) + np.sum(history.opponent_actions[round_idx, :])
            if cooperators > self.n / 2:
                rounds_with_majority_c += 1
        return rounds_with_majority_c / len(history.my_actions)

    def _calculate_defection_impact(self, history: PlayerHistory) -> int:
        """Count rounds where I played C but majority played D"""
        impact = 0
        for round_idx in range(len(history.my_actions)):
            if history.my_actions[round_idx]:
                cooperators = int(history.my_actions[round_idx]) + np.sum(history.opponent_actions[round_idx, :])
                if cooperators <= self.n / 2:
                    impact += 1
        return impact

    def _calculate_recent_cooperation(self, history: PlayerHistory, window: int=3) -> float:
        """Calculate average cooperation rate in recent rounds"""
        if len(history.my_actions) == 0:
            return 0.0
        start_idx = max(0, len(history.my_actions) - window)
        recent_rounds = len(history.my_actions) - start_idx
        total_cooperators = 0
        for round_idx in range(start_idx, len(history.my_actions)):
            cooperators = int(history.my_actions[round_idx]) + np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += cooperators
        return total_cooperators / (recent_rounds * self.n)

    def _calculate_avg_cooperation(self, history: PlayerHistory) -> float:
        """Calculate average cooperation rate across all history"""
        if len(history.my_actions) == 0:
            return 0.0
        total_cooperators = 0
        for round_idx in range(len(history.my_actions)):
            cooperators = int(history.my_actions[round_idx]) + np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += cooperators
        return total_cooperators / (len(history.my_actions) * self.n)

    def _calculate_self_exploitation_ratio(self, history: PlayerHistory) -> float:
        """Calculate ratio of times I cooperated while others defected"""
        if len(history.my_actions) == 0:
            return 0.0
        my_cooperations = int(np.sum(history.my_actions))
        if my_cooperations == 0:
            return 0.0
        exploitation_count = 0
        for round_idx in range(len(history.my_actions)):
            if history.my_actions[round_idx]:
                opponent_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
                if opponent_cooperators == 0:
                    exploitation_count += 1
        return exploitation_count / my_cooperations

    def _check_unanimous_defection(self, history: PlayerHistory) -> bool:
        """Check if 5+ consecutive recent rounds show all D"""
        if len(history.my_actions) < 5:
            return False
        consecutive_all_d = 0
        for round_idx in range(len(history.my_actions) - 1, -1, -1):
            my_action = history.my_actions[round_idx]
            opponent_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
            if not my_action and opponent_cooperators == 0:
                consecutive_all_d += 1
            else:
                break
        return consecutive_all_d >= 5

    def _check_sudden_defection(self, history: PlayerHistory) -> bool:
        """Check if cooperation rate dropped >0.3 in recent rounds"""
        if len(history.my_actions) < 2:
            return False
        if len(history.my_actions) == 1:
            prev_rate = 1.0
        else:
            prev_rounds = history.my_actions[:-1]
            prev_cooperators = int(np.sum(prev_rounds))
            prev_rate = prev_cooperators / len(prev_rounds) if len(prev_rounds) > 0 else 1.0
        current_cooperators = int(np.sum(history.my_actions))
        current_rate = current_cooperators / len(history.my_actions)
        return prev_rate - current_rate > 0.3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        """Determine action for current round based on ARC strategy"""
        if state.round_number == 0:
            return Action.C
        cooperation_rate = self._calculate_cooperation_rate(history)
        defection_impact = self._calculate_defection_impact(history)
        recent_coop = self._calculate_recent_cooperation(history, window=3)
        avg_cooperation = self._calculate_avg_cooperation(history)
        my_exploitation_ratio = self._calculate_self_exploitation_ratio(history)
        if self._check_unanimous_defection(history):
            return Action.D
        if self._check_sudden_defection(history):
            return Action.D
        phase = self._get_phase(state.round_number)
        if phase == 'EARLY':
            if cooperation_rate >= 0.6:
                return Action.C
            elif defection_impact <= 1:
                return Action.C
            else:
                return Action.D
        elif phase == 'MIDDLE':
            payoff_threshold = self.k / self.n * 0.7
            if recent_coop >= payoff_threshold:
                return Action.C
            elif my_exploitation_ratio >= 0.4 and recent_coop < self.k / self.n * 0.5:
                return Action.D
            elif avg_cooperation >= 0.5:
                return Action.C
            else:
                return Action.D
        else:
            rounds_remaining = self.r - state.round_number
            if avg_cooperation >= 0.55 and rounds_remaining > 2:
                return Action.C
            elif avg_cooperation >= 0.55 and rounds_remaining <= 2:
                return Action.C
            elif avg_cooperation < 0.35:
                return Action.D
            else:
                return Action.C

class Strategy_COLLECTIVE_481(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare with individual rationality through:
    - Phase 1 (Exploration): Establish cooperation with lenient thresholds
    - Phase 2 (Steady): Reciprocal play with tighter thresholds and trend monitoring
    - Phase 3 (Endgame): Unconditional cooperation in final round, reciprocal play before
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.exploration_end = math.floor(self.r / 3)
        self.endgame_start = math.floor(2 * self.r / 3)
        self.t_early = (self.k - 1) / self.k
        self.t_steady = (self.k - 0.5) / self.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            return Action.C
        prev_cooperators = sum(history.opponent_actions[round_num - 1, :])
        cooperation_rate = prev_cooperators / self.n
        if round_num <= self.exploration_end:
            threshold = self.t_early
            if round_num == 1 and cooperation_rate >= 0.5:
                return Action.C
        else:
            threshold = self.t_steady
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_482(BaseStrategy):
    """
    Adaptive Threshold Cooperation with Decay Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare by:
    1. Cooperating in round 1 to bootstrap trust
    2. Using critical threshold (k/n) to decide cooperation in subsequent rounds
    3. Increasing threshold by 50% in late rounds (t > 2r/3) to prevent final-round defection cascades
    4. Punishing low cooperation rates while remaining open to recovery
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        current_round = state.round_number
        last_round_opponent_cooperators = sum(history.opponent_actions[-1, :])
        my_last_action = history.my_actions[-1]
        total_cooperators = last_round_opponent_cooperators + (1 if my_last_action else 0)
        cooperation_rate = total_cooperators / self.n_players
        base_threshold = self.k / self.n_players
        if current_round > 2 * self.n_rounds / 3:
            threshold = base_threshold * 1.5
        else:
            threshold = base_threshold
        threshold = min(threshold, 0.5)
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_483(BaseStrategy):
    """
    Adaptive Contribution with Conditional Defection (ACCD)

    Balances individual rationality with collective welfare through:
    - Initial cooperation to establish mutual benefit
    - Reciprocal monitoring to detect free-riders
    - Graduated response with Pavlov emergency fallback
    - Strategic defection only in final round
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.epsilon = 0.01
        self.noise_threshold = 0.3
        self.noise_adjustment = 0.05
        self.pavlov_consecutive_rounds = 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            return Action.D
        last_round_idx = current_round - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[last_round_idx, :]))
        coop_rate_last_round = cooperators_last_round / self.n
        base_threshold = 1.0 / self.k
        adjusted_coop_rate = coop_rate_last_round
        adjusted_threshold = base_threshold
        if current_round >= 4:
            recent_coop_rates = []
            for i in range(max(0, current_round - 3), current_round):
                count = int(np.sum(history.opponent_actions[i, :]))
                recent_coop_rates.append(count / self.n)
            if len(recent_coop_rates) >= 2:
                variance = np.var(recent_coop_rates)
                if variance > self.noise_threshold:
                    adjusted_coop_rate = np.mean(recent_coop_rates)
                    adjusted_threshold = base_threshold + self.noise_adjustment
        if current_round >= 3 and adjusted_coop_rate < base_threshold:
            my_last_payoff = history.my_payoffs[last_round_idx]
            all_payoffs_last_round = history.opponent_payoffs[last_round_idx, :]
            avg_payoff = np.mean(all_payoffs_last_round)
            consecutive_low = 0
            for i in range(last_round_idx, max(-1, last_round_idx - self.pavlov_consecutive_rounds), -1):
                count = int(np.sum(history.opponent_actions[i, :]))
                if count / self.n < base_threshold:
                    consecutive_low += 1
                else:
                    break
            if consecutive_low >= self.pavlov_consecutive_rounds:
                my_last_action = history.my_actions[last_round_idx]
                if my_last_payoff >= avg_payoff:
                    return Action.C if my_last_action else Action.D
                else:
                    return Action.D if my_last_action else Action.C
        if adjusted_coop_rate >= adjusted_threshold - self.epsilon:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_484(BaseStrategy):
    """
    Adaptive Contribution with Threshold Recovery (ACTR) Strategy.

    Implements conditional cooperation based on the previous round's cooperation rate,
    with adaptive threshold adjustment when cooperation declines and recovery protocols
    when cooperation rebounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = game_description.k / game_description.n_players
        self.adaptive_phase = False
        self.adaptive_threshold = self.threshold * 0.8
        self.adaptation_start_round = None
        self.consecutive_low_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        prev_round_idx = state.round_number - 1
        cooperators_in_prev_round = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            cooperators_in_prev_round += 1
        cooperation_rate = cooperators_in_prev_round / self.game_description.n_players
        if cooperation_rate < self.threshold:
            self.consecutive_low_rounds += 1
            if self.consecutive_low_rounds >= 2 and (not self.adaptive_phase):
                self.adaptive_phase = True
                self.adaptation_start_round = state.round_number
        else:
            self.consecutive_low_rounds = 0
        if self.adaptive_phase and self.adaptation_start_round is not None:
            rounds_in_adaptation = state.round_number - self.adaptation_start_round
            if rounds_in_adaptation >= 3 and cooperation_rate >= self.threshold * 1.2:
                self.adaptive_phase = False
                self.adaptive_threshold = self.threshold
        current_threshold = self.adaptive_threshold if self.adaptive_phase else self.threshold
        if cooperation_rate >= current_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_485(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game.

    Balances collective welfare with individual security by:
    1. Rewarding cooperation when collectively beneficial
    2. Protecting against exploitation through strategic defection
    3. Adapting dynamically to opponent behavior patterns
    4. Maximizing total welfare rather than purely individual payoff
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.ct = (self.k - 1) / (self.n - 1) if self.n > 1 else 0
        self.exploration_end = min(5, max(1, self.r // 4))
        self.adaptation_window = min(10, max(1, self.r // 2))
        self.endgame_start = max(self.exploration_end + 1, self.r - 2)
        self.consecutive_defection_rounds = 0
        self.last_coop_rate = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if self.r == 1:
            return Action.C
        opponent_actions = history.opponent_actions
        prev_round_cooperators = int(np.sum(opponent_actions[round_num - 1, :]))
        observed_coop_rate = prev_round_cooperators / self.n
        start_idx = max(0, round_num - self.adaptation_window)
        recent_rounds = opponent_actions[start_idx:round_num, :]
        recent_coop_rate = np.mean(recent_rounds) if recent_rounds.size > 0 else observed_coop_rate
        coop_rates_recent = [np.mean(opponent_actions[max(0, round_num - i - 1):round_num - i, :]) for i in range(min(3, round_num))]
        coop_variance = np.var(coop_rates_recent) if len(coop_rates_recent) > 1 else 0
        rounds_remaining = self.r - round_num
        if round_num <= self.exploration_end:
            if observed_coop_rate >= self.ct:
                return Action.C
            else:
                return Action.D
        if round_num >= self.endgame_start:
            if round_num == self.r - 1:
                if recent_coop_rate >= self.ct:
                    return Action.C
                else:
                    return Action.D
            if round_num == self.r - 1:
                if observed_coop_rate >= self.ct:
                    return Action.C
                else:
                    return Action.D
        if observed_coop_rate < 0.05:
            self.consecutive_defection_rounds += 1
            if self.consecutive_defection_rounds >= 2 and round_num > self.exploration_end + 2:
                self.consecutive_defection_rounds = 0
                return Action.C
            return Action.D
        else:
            self.consecutive_defection_rounds = 0
        if observed_coop_rate >= 0.95:
            if round_num < self.r - 2 or recent_coop_rate >= self.ct:
                return Action.C
            else:
                return Action.D
        if coop_variance > 0.15:
            adjusted_threshold = self.ct + 0.1
            if recent_coop_rate >= adjusted_threshold:
                return Action.C
            else:
                return Action.D
        if self.n == 2:
            if round_num >= self.r - 3:
                if observed_coop_rate >= 1.0:
                    return Action.C
                else:
                    return Action.D
        act = self.ct + (1 - self.ct) * (rounds_remaining / self.r)
        if recent_coop_rate >= act:
            return Action.C
        elif recent_coop_rate >= self.ct and rounds_remaining > 2:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_486(BaseStrategy):
    """
    Adaptive Reciprocal Equilibrium (ARE) Strategy for N-Player Public Goods Game.

    Balances individual incentives vs. collective welfare through probabilistic
    reciprocation based on observed cooperation rates. Uses thresholds (0.75, 0.50, 0.20)
    to determine cooperation levels, with special handling for round 1 and final round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_high = 0.75
        self.threshold_mid = 0.5
        self.threshold_low = 0.2
        self.probe_cooperation_prob = 0.3
        self.probe_defection_prob = 0.7

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n_rounds = self.game_description.n_rounds
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        if round_number == n_rounds - 1:
            return Action.D
        cooperation_rate = self._calculate_cooperation_rate(history, round_number)
        if cooperation_rate >= self.threshold_high:
            return Action.C
        elif cooperation_rate >= self.threshold_mid:
            if random.random() < cooperation_rate:
                return Action.C
            else:
                return Action.D
        elif cooperation_rate >= self.threshold_low:
            if random.random() < self.probe_cooperation_prob:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_number: int) -> float:
        """
        Calculate the observed cooperation rate of all opponents across all rounds so far.

        Args:
            history: PlayerHistory object containing opponent_actions
            round_number: Current round number (0-indexed)

        Returns:
            Cooperation rate as a float between 0 and 1
        """
        if round_number == 0:
            return 0.0
        past_actions = history.opponent_actions[:round_number, :]
        total_cooperations = np.sum(past_actions)
        rounds_elapsed = round_number
        n_opponents = self.game_description.n_players - 1
        total_possible_actions = rounds_elapsed * n_opponents
        if total_possible_actions == 0:
            return 0.0
        cooperation_rate = total_cooperations / total_possible_actions
        return cooperation_rate

class Strategy_COLLECTIVE_487(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare with protection against exploitation through:
    - Unconditional cooperation in round 1 (costly signal)
    - Dynamic threshold-based decisions in middle rounds
    - Strategic defection in final round (with exception for high cooperation)
    - Payoff equity monitoring to self-correct imbalances
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def _calculate_thresholds(self) -> tuple[float, float, float]:
        """Calculate cooperation thresholds based on game parameters."""
        threshold_lower = self.k / self.n
        threshold_danger = min(0.4, self.k / self.n + 0.15)
        threshold_upper = 0.85
        if self.n <= 3:
            threshold_lower *= 1.1
            threshold_danger *= 1.1
        return (threshold_lower, threshold_danger, threshold_upper)

    def _get_recent_cooperation_rate(self, history: PlayerHistory, decay: bool=False) -> float:
        """
        Calculate recent cooperation rate from opponent actions.
        Uses exponential decay weighting for long games.
        """
        opponent_actions = history.opponent_actions
        n_rounds_played = len(opponent_actions)
        if n_rounds_played == 0:
            return 0.0
        if not decay or self.r < 20:
            all_cooperators = np.sum(opponent_actions, axis=1)
            total_cooperation_rate = np.mean(all_cooperators / self.n)
            return float(total_cooperation_rate)
        else:
            weights = np.array([0.5 ** (n_rounds_played - 1 - i) for i in range(n_rounds_played)])
            weights = weights / np.sum(weights)
            cooperation_rates = np.sum(opponent_actions, axis=1) / self.n
            weighted_coop = np.sum(cooperation_rates * weights)
            return float(weighted_coop)

    def _get_payoff_delta(self, history: PlayerHistory) -> float:
        """Calculate (my_payoff - average_opponent_payoff) for most recent round."""
        if len(history.my_payoffs) == 0:
            return 0.0
        my_recent_payoff = history.my_payoffs[-1]
        opponent_recent_payoffs = history.opponent_payoffs[-1]
        avg_opponent_payoff = float(np.mean(opponent_recent_payoffs))
        return my_recent_payoff - avg_opponent_payoff

    def _check_payoff_surplus(self, history: PlayerHistory) -> bool:
        """Check if player is significantly ahead in recent rounds (2+ consecutive)."""
        if len(history.my_payoffs) < 2:
            return False
        surplus_count = 0
        for i in range(max(0, len(history.my_payoffs) - 2), len(history.my_payoffs)):
            my_payoff = history.my_payoffs[i]
            avg_opponent = float(np.mean(history.opponent_payoffs[i]))
            if my_payoff - avg_opponent > 0.25:
                surplus_count += 1
        return surplus_count >= 2

    def _check_payoff_deficit(self, history: PlayerHistory) -> bool:
        """Check if player is significantly behind."""
        if len(history.my_payoffs) == 0:
            return False
        my_recent_payoff = history.my_payoffs[-1]
        avg_opponent_payoff = float(np.mean(history.opponent_payoffs[-1]))
        return my_recent_payoff < avg_opponent_payoff - 0.3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            recent_coop = self._get_recent_cooperation_rate(history, decay=True)
            if recent_coop >= 0.9:
                return Action.C
            else:
                return Action.D
        recent_coop = self._get_recent_cooperation_rate(history, decay=self.r >= 20)
        recent_payoff_delta = self._get_payoff_delta(history)
        threshold_lower, threshold_danger, threshold_upper = self._calculate_thresholds()
        has_surplus = self._check_payoff_surplus(history)
        has_deficit = self._check_payoff_deficit(history)
        if recent_coop >= threshold_upper:
            if recent_payoff_delta > 0.2 and (not has_deficit):
                return Action.D
            else:
                return Action.C
        elif recent_coop >= threshold_danger:
            cooperation_incentive = self.k / self.n * recent_coop - 1.0
            if cooperation_incentive > 0.1:
                return Action.C
            else:
                return Action.D
        elif has_deficit:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_488(BaseStrategy):
    """
    Adaptive Contribution Threshold (ACT) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare by:
    1. Always cooperating in round 1 to establish baseline and gain information
    2. Computing observed cooperation rate from history
    3. Comparing against threshold = 1/k to decide cooperation
    4. Adjusting decisions based on expected returns and rounds remaining
    5. Applying stricter threshold (1.2/k) in final rounds
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        cooperation_rate = self._calculate_cooperation_rate(history)
        threshold = 1.0 / self.k
        rounds_remaining = self.n_rounds - current_round - 1
        if rounds_remaining <= 1:
            threshold *= 1.2
        if current_round == self.n_rounds - 1:
            if cooperation_rate >= threshold:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= threshold:
            return Action.C
        elif rounds_remaining > 1:
            expected_cooperators = cooperation_rate * self.n_players
            expected_returns = self.k / self.n_players * expected_cooperators
            if expected_returns > 1.0:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        """
        Calculate the cooperation rate from all previous rounds.
        Cooperation rate = (total cooperators across all players and rounds) / (n_players * rounds_elapsed)
        """
        if history is None or len(history.my_actions) == 0:
            return 0.0
        rounds_elapsed = len(history.my_actions)
        my_cooperations = np.sum(history.my_actions)
        opponent_cooperations = np.sum(history.opponent_actions)
        total_cooperations = my_cooperations + opponent_cooperations
        total_possible = self.n_players * rounds_elapsed
        cooperation_rate = float(total_cooperations) / float(total_possible)
        return cooperation_rate

class Strategy_COLLECTIVE_489(BaseStrategy):
    """
    Adaptive Threshold Reciprocity (ATR) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare by:
    - Cooperating in round 1 to establish cooperative signals
    - Using threshold-based reciprocity in middle rounds (cooperate if cooperation_rate >= k/n)
    - Escalating cooperation during momentum phases (cooperation_rate >= 2*k/n)
    - Entering pessimistic mode after 3+ consecutive rounds below threshold
    - Applying special logic in final round to avoid exploitation
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.consecutive_below_threshold = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        threshold = self.k / self.n_players
        prev_round_idx = round_t - 1
        cooperators_prev = np.sum(history.opponent_actions[prev_round_idx, :])
        if history.my_actions[prev_round_idx]:
            cooperators_prev += 1
        cooperation_rate_prev = cooperators_prev / self.n_players
        if self.consecutive_below_threshold >= 3:
            if cooperation_rate_prev >= threshold:
                self.consecutive_below_threshold = 0
                return Action.C
            else:
                return Action.D
        if cooperation_rate_prev < threshold:
            self.consecutive_below_threshold += 1
        else:
            self.consecutive_below_threshold = 0
        if round_t == self.n_rounds - 1:
            if cooperation_rate_prev >= threshold:
                return Action.C
            else:
                return Action.D
        if cooperation_rate_prev >= 2 * threshold:
            return Action.C
        if cooperation_rate_prev >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_490(BaseStrategy):
    """
    Conditional Reciprocal Contribution (CRC) Strategy for N-Player Public Goods Game.

    A threshold-based adaptive strategy that:
    1. Initiates cooperation in Round 1 to bootstrap collective action
    2. Observes cooperation rates and applies decision thresholds in intermediate rounds
    3. Reciprocates or defects in the final round based on sustained cooperation
    4. Balances individual security against exploitation with collective welfare maximization
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        cooperation_rate = self._calculate_cooperation_rate(history, current_round)
        if current_round == self.n_rounds - 1:
            threshold = self.k / self.n_players
            if cooperation_rate >= threshold:
                return Action.C
            else:
                return Action.D
        else:
            threshold_high = 2 * self.k / self.n_players
            threshold_medium = self.k / (self.n_players - 1)
            threshold_low = 1 / self.n_players
            if cooperation_rate >= threshold_high:
                return Action.C
            elif cooperation_rate >= threshold_medium:
                return Action.C
            elif cooperation_rate < threshold_low:
                return Action.D
            else:
                return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the observed cooperation rate from all players in rounds 0 to current_round-1.

        Returns the proportion of total cooperations relative to total actions.
        """
        if current_round == 0:
            return 0.0
        my_cooperations = int(np.sum(history.my_actions[:current_round]))
        opponent_cooperations = int(np.sum(history.opponent_actions[:current_round, :]))
        total_cooperations = my_cooperations + opponent_cooperations
        total_actions = current_round * self.n_players
        if total_actions == 0:
            return 0.0
        return total_cooperations / total_actions

class Strategy_COLLECTIVE_491(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Core approach:
    - Round 1: Cooperate to establish baseline
    - Rounds 2 to r: Use threshold-based conditional cooperation
    - Threshold = k/n (break-even point where cooperation becomes profitable)
    - Cooperate if previous round's cooperation rate >= threshold, else defect
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        previous_round_idx = state.round_number - 1
        opponent_cooperators_previous = np.sum(history.opponent_actions[previous_round_idx, :])
        my_cooperation_previous = history.my_actions[previous_round_idx]
        total_cooperators_previous = opponent_cooperators_previous + (1 if my_cooperation_previous else 0)
        cooperation_rate_previous = total_cooperators_previous / self.n_players
        if cooperation_rate_previous >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_492(BaseStrategy):
    """
    Adaptive Contribution Targeting (ACT): A reciprocal, adaptive strategy that balances
    individual payoff optimization with collective welfare by maintaining a dynamic
    cooperation target that evolves based on observed cooperation patterns.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            return Action.D
        all_cooperators = np.sum(history.opponent_actions[:current_round, :])
        total_plays = self.n * current_round
        observed_coop_rate = all_cooperators / total_plays if total_plays > 0 else 0.0
        base_threshold = (self.k - 1.0) / (self.n - 1.0) if self.n > 1 else 0.5
        round_cooperation_rates = []
        for r in range(current_round):
            round_cooperators = np.sum(history.opponent_actions[r, :])
            round_rate = round_cooperators / self.n
            round_cooperation_rates.append(round_rate)
        trend = 0.0
        if len(round_cooperation_rates) > 1:
            trend = (round_cooperation_rates[-1] - round_cooperation_rates[0]) / max(1, len(round_cooperation_rates) - 1)
        adjustment_factor = min(0.15, trend / max(1, self.r - 2))
        cooperation_threshold = base_threshold + adjustment_factor
        if current_round >= 2:
            prev_round_coop = np.sum(history.opponent_actions[current_round - 1, :]) / self.n
            round_2_coop = np.sum(history.opponent_actions[1, :]) / self.n
            trend_change = prev_round_coop - round_2_coop
            if trend_change < -0.2:
                return Action.D
            if trend_change > 0.1:
                return Action.C
        if current_round == 1:
            cooperators_in_round_0 = np.sum(history.opponent_actions[0, :])
            if cooperators_in_round_0 <= 0.5 * self.n:
                return Action.D
        if observed_coop_rate >= cooperation_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_493(BaseStrategy):
    """
    Adaptive Contribution with Threshold-Based Reciprocity (ACR)

    Balances individual rationality with collective welfare by:
    1. Starting with cooperation to establish goodwill
    2. Using threshold-based reciprocity to decide future contributions
    3. Adapting to cooperation trends and protecting against exploitation
    4. Maintaining conditional cooperation even in final rounds
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.k - 1) / self.k
        self.epsilon = 0.05

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_idx = round_num - 1
        prev_cooperators = int(sum(history.opponent_actions[prev_round_idx, :]))
        cooperation_rate = prev_cooperators / self.n
        if round_num == self.r - 1:
            if cooperation_rate >= self.threshold:
                return Action.C
            else:
                return Action.D
        effective_threshold = self.threshold
        if round_num >= 2:
            recent_rounds = min(3, round_num)
            recent_rates = []
            for i in range(recent_rounds):
                idx = round_num - 1 - i
                cooperators = int(sum(history.opponent_actions[idx, :]))
                recent_rates.append(cooperators / self.n)
            recent_avg = np.mean(recent_rates)
            effective_threshold = self.threshold - self.epsilon
        else:
            recent_avg = cooperation_rate
            effective_threshold = self.threshold
        if round_num >= 2:
            current_rate = cooperation_rate
            prev_prev_idx = round_num - 2
            prev_prev_cooperators = int(sum(history.opponent_actions[prev_prev_idx, :]))
            prev_prev_rate = prev_prev_cooperators / self.n
            trend = current_rate - prev_prev_rate
            if trend < -0.15:
                effective_threshold += 0.1
        if cooperation_rate > 0.9:
            return Action.C
        if cooperation_rate == 0.0:
            return Action.D
        if recent_avg >= effective_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_494(BaseStrategy):
    """
    Adaptive Collective Strategy for N-Player Public Goods Game.

    Balances individual resilience against exploitation with collective value creation.
    Uses conditional cooperation anchored to the efficiency threshold k/n, with adaptive
    adjustments for game phase and group defection patterns.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        coop_rate = self._calculate_cooperation_rate(history, round_t)
        threshold = self._calculate_threshold(round_t)
        if round_t >= 3:
            defection_rate = 1.0 - coop_rate
            if defection_rate >= 0.9:
                return Action.D
        if round_t >= 3:
            coop_rate = self._apply_moving_average(history, round_t)
        if round_t == self.r - 1:
            if coop_rate >= threshold:
                return Action.C
            else:
                return Action.D
        if round_t == self.r - 2:
            adjusted_threshold = threshold * 1.1
            if coop_rate >= adjusted_threshold:
                return Action.C
            else:
                return Action.D
        if coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_t: int) -> float:
        """
        Calculate empirical cooperation rate from history up to round_t-1.
        """
        if round_t <= 1:
            return 0.5
        total_coop_actions = np.sum(history.opponent_actions[:round_t])
        total_possible_actions = self.n * round_t
        coop_rate = total_coop_actions / total_possible_actions
        return coop_rate

    def _calculate_threshold(self, round_t: int) -> float:
        """
        Calculate decision threshold based on game phase and group size.
        """
        base_threshold = self.k / self.n
        if round_t > 2 * self.r / 3:
            phase_multiplier = 1.5
        else:
            phase_multiplier = 1.0
        if self.n == 2:
            size_multiplier = 0.8
        elif self.n >= 10:
            size_multiplier = 1.1
        else:
            size_multiplier = 1.0
        threshold = base_threshold * phase_multiplier * size_multiplier
        return threshold

    def _apply_moving_average(self, history: PlayerHistory, round_t: int) -> float:
        """
        Apply 3-round moving average to reduce noise from oscillating cooperation.
        """
        window_size = min(3, round_t)
        start_idx = max(0, round_t - window_size)
        recent_coop_actions = np.sum(history.opponent_actions[start_idx:round_t])
        recent_possible_actions = self.n * (round_t - start_idx)
        moving_avg = recent_coop_actions / recent_possible_actions
        overall_rate = self._calculate_cooperation_rate(history, round_t)
        if round_t >= 3:
            rates = []
            for i in range(max(0, round_t - 2), round_t):
                round_coop = np.sum(history.opponent_actions[i])
                rate = round_coop / self.n
                rates.append(rate)
            if len(rates) >= 2:
                rate_variance = max(rates) - min(rates)
                if rate_variance >= 0.2:
                    return 0.6 * moving_avg + 0.4 * overall_rate
        return moving_avg

class Strategy_COLLECTIVE_495(BaseStrategy):
    """
    Adaptive Reciprocal Maximization (ARM): A collectively-minded strategy that balances
    individual resilience with collective optimization through conditional cooperation,
    dynamic threshold adjustment, and parameter-aware decision-making.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_cooperators = int(np.sum(history.opponent_actions[round_num - 1, :]))
        cooperation_rate = prev_round_cooperators / self.n
        if round_num >= 2:
            prev_prev_cooperators = int(np.sum(history.opponent_actions[round_num - 2, :]))
            if cooperation_rate == 0 and prev_prev_cooperators == 0:
                return Action.D
        cooperation_rates = []
        for i in range(max(0, round_num - 3), round_num):
            cooperators = int(np.sum(history.opponent_actions[i, :]))
            cooperation_rates.append(cooperators / self.n)
        if len(cooperation_rates) >= 3:
            volatility = max(cooperation_rates) - min(cooperation_rates)
            if volatility > 0.4:
                cooperation_rate = np.mean(cooperation_rates)
        recent_upward_trend = False
        if len(cooperation_rates) >= 2:
            if cooperation_rates[-1] > cooperation_rates[-2]:
                if len(cooperation_rates) >= 3 and cooperation_rates[-2] > cooperation_rates[-3]:
                    recent_upward_trend = True
        k_over_n = self.k / self.n
        if self.n <= 3:
            base_threshold = k_over_n * 0.9
        elif self.k < 1.2:
            base_threshold = k_over_n
        elif self.k > 2.5:
            base_threshold = k_over_n * 0.5
        else:
            base_threshold = k_over_n * 0.75
        if recent_upward_trend:
            cooperation_threshold = base_threshold - 0.05
        else:
            cooperation_threshold = base_threshold
        if cooperation_rate > cooperation_threshold:
            return Action.C
        elif cooperation_rate >= cooperation_threshold * 0.8:
            return Action.C if random.random() < 0.8 else Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_496(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare with strategic realism by:
    - Starting with cooperation to establish baseline
    - Monitoring collective cooperation rate
    - Adjusting contribution thresholds based on game health and remaining rounds
    - Using probabilistic cooperation in stressed states
    - Making context-aware final-round decisions
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold_sustainable = self.k / self.n_players
        self.threshold_collapse = self.k / self.n_players * 0.4
        self.trust_degradation_rate = 1.0 / (self.n_rounds - 1) if self.n_rounds > 1 else 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        prev_round_idx = current_round - 1
        my_prev_action = history.my_actions[prev_round_idx]
        opponent_prev_actions = history.opponent_actions[prev_round_idx, :]
        total_cooperators = int(my_prev_action) + int(np.sum(opponent_prev_actions))
        cooperation_rate_prev = total_cooperators / self.n_players
        if current_round == self.n_rounds - 1:
            if cooperation_rate_prev > self.threshold_sustainable:
                return Action.D
            else:
                return Action.C
        remaining_rounds = self.n_rounds - current_round
        adjusted_threshold = self.threshold_sustainable + self.trust_degradation_rate * remaining_rounds
        if cooperation_rate_prev >= adjusted_threshold:
            return Action.C
        elif cooperation_rate_prev >= self.threshold_collapse:
            rng_state = random.Random(current_round)
            if rng_state.random() < cooperation_rate_prev:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_497(BaseStrategy):
    """
    Adaptive Reciprocal Threshold (ART) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare by adapting a cooperation
    threshold based on game parameters and observed cooperation rates. Cooperates in
    round 1, then applies adaptive thresholds in subsequent rounds, with special
    final-round logic to prevent exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        base_threshold = (self.k - 1) / self.k
        cooperation_rate = self._calculate_cooperation_rate(history, current_round)
        recent_defection_penalty = self._calculate_recent_defection_penalty(history, current_round)
        if current_round == self.n_rounds - 1:
            if cooperation_rate >= 0.9:
                return Action.C
            threshold = 1.0
        else:
            decay_factor = min(0.15, 1.0 / self.n_rounds)
            threshold = base_threshold + decay_factor * recent_defection_penalty
        if cooperation_rate >= threshold:
            return Action.C
        if cooperation_rate >= 0.5 * base_threshold:
            expected_cooperators = cooperation_rate * self.n_players
            collective_benefit = self.k / self.n_players * expected_cooperators
            if collective_benefit > 1.0 - base_threshold:
                return Action.C
        return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the observed cooperation rate across all players in all previous rounds.
        """
        if current_round == 0:
            return 0.0
        total_opponent_cooperations = np.sum(history.opponent_actions[:current_round, :])
        total_our_cooperations = np.sum(history.my_actions[:current_round])
        total_actions = current_round * self.n_players
        cooperation_rate = (total_opponent_cooperations + total_our_cooperations) / total_actions
        return cooperation_rate

    def _calculate_recent_defection_penalty(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate defection rate in the last 3 rounds with memory window weighting.
        Weight last 3 rounds at 60%, earlier rounds at 40%.
        """
        if current_round == 0:
            return 0.0
        memory_window = min(3, current_round)
        start_idx = current_round - memory_window
        recent_actions = history.opponent_actions[start_idx:current_round, :]
        recent_defections = np.sum(recent_actions == False)
        recent_total = recent_actions.size
        if memory_window < current_round:
            earlier_actions = history.opponent_actions[:start_idx, :]
            earlier_defections = np.sum(earlier_actions == False)
            earlier_total = earlier_actions.size
            recent_defection_rate = recent_defections / recent_total if recent_total > 0 else 0.0
            earlier_defection_rate = earlier_defections / earlier_total if earlier_total > 0 else 0.0
            penalty = 0.6 * recent_defection_rate + 0.4 * earlier_defection_rate
        else:
            penalty = recent_defections / recent_total if recent_total > 0 else 0.0
        return penalty

class Strategy_COLLECTIVE_498(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy for N-Player Public Goods Game.

    Balances individual rationality with collective welfare by:
    1. Cooperating in initial exploration phase
    2. Using adaptive threshold based on recent cooperation rate
    3. Attempting recovery from mutual defection
    4. Adjusting behavior in endgame based on cooperation levels
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num <= 1:
            return Action.C
        recent_window = max(3, math.ceil(self.r / 3))
        start_idx = max(0, round_num - recent_window)
        recent_rounds = history.opponent_actions[start_idx:round_num, :]
        my_recent_actions = history.my_actions[start_idx:round_num]
        total_cooperation = np.sum(recent_rounds) + np.sum(my_recent_actions)
        total_slots = (round_num - start_idx) * self.n
        cooperation_rate = total_cooperation / total_slots if total_slots > 0 else 0.0
        my_payoff_recent = np.mean(history.my_payoffs[start_idx:round_num]) if start_idx < round_num else 0.0
        opponent_payoffs_recent = np.mean(history.opponent_payoffs[start_idx:round_num, :]) if start_idx < round_num else 0.0
        endgame_threshold = 0.85 * self.r
        if round_num > endgame_threshold:
            return self._evaluate_endgame(cooperation_rate)
        base_threshold = (self.k - 1.0) / self.n
        adjusted_threshold = base_threshold
        if my_payoff_recent < opponent_payoffs_recent:
            adjusted_threshold = base_threshold + 0.15
        if cooperation_rate < 0.3:
            recent_opponent_coop = np.sum(recent_rounds) / (len(recent_rounds) * self.n) if len(recent_rounds) > 0 else 0.0
            if recent_opponent_coop < 0.3:
                return Action.C
        if cooperation_rate >= adjusted_threshold:
            return Action.C
        else:
            return Action.D

    def _evaluate_endgame(self, cooperation_rate: float) -> Action:
        """
        Evaluate action in final 15% of rounds.

        If in cooperation: maintain it to maximize final payoffs
        If in mutual defection: continue defecting (Nash equilibrium)
        """
        if cooperation_rate > 0.7:
            return Action.C
        elif cooperation_rate > 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_499(BaseStrategy):
    """
    Adaptive Reciprocal Threshold (ART) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with individual rationality by:
    1. Cooperating in round 1 to signal good faith
    2. Using adaptive threshold-based reciprocation in subsequent rounds
    3. Gradually lowering cooperation threshold as game progresses
    4. Rewarding cooperation signals while protecting against exploitation
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        prev_round_cooperators = sum(history.opponent_actions[round_number - 1, :])
        cooperation_rate = prev_round_cooperators / self.n_players
        threshold = max(0.5, 1 - round_number / self.n_rounds * 0.4)
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_500(BaseStrategy):
    """
    Adaptive Reciprocal Threshold (ART) Strategy for N-Player Public Goods Game

    Balances individual rationality with collective welfare by dynamically adapting
    to observed cooperation levels across three phases:
    - Phase 1 (Exploration): Cooperate to signal willingness and gather data
    - Phase 2 (Adaptation): Cooperate if observed cooperation rate meets threshold  = k/n
    - Phase 3 (Final): Cooperate if observed cooperation rate meets adjusted threshold '
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.phase1_end = math.ceil(self.n_rounds / 3)
        self.phase2_end = math.ceil(2 * self.n_rounds / 3)
        self.theta_base = self.k / self.n_players
        self.theta_adjusted = self.theta_base + 0.1 * (1 - self.theta_base)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number < self.phase1_end:
            return Action.C
        total_cooperators = 0
        total_slots = 0
        for past_round in range(round_number):
            if history.my_actions[past_round]:
                total_cooperators += 1
            total_cooperators += sum(history.opponent_actions[past_round, :])
            total_slots += self.n_players
        c_obs = total_cooperators / total_slots if total_slots > 0 else 0
        if round_number < self.phase2_end:
            if c_obs >= self.theta_base:
                return Action.C
            else:
                return Action.D
        if c_obs >= self.theta_adjusted:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_501(BaseStrategy):
    """
    Adaptive Graduated Reciprocity with Threshold Dynamics.

    A collective strategy that:
    1. Establishes a cooperation threshold (minimum cooperators for mutual benefit)
    2. Cooperates in round 1 to signal intent
    3. In middle rounds, responds to observed cooperation rate with conditional logic
    4. In final round, bases decision on cumulative cooperation history
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = math.ceil(self.n * self.k / (self.k + 1))
        self.threshold_rate = self.threshold / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            prev_cooperators = history.opponent_actions[:round_num, :].sum(axis=1)
            avg_coop_rate = np.mean(prev_cooperators) / self.n
            if avg_coop_rate >= self.threshold_rate:
                return Action.C
            else:
                return Action.D
        prev_round_idx = round_num - 1
        prev_cooperators = history.opponent_actions[prev_round_idx, :].sum()
        coop_rate = prev_cooperators / self.n
        if coop_rate >= self.threshold_rate:
            return Action.C
        elif coop_rate < 0.2:
            return Action.D
        elif random.random() < coop_rate:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_502(BaseStrategy):
    """
    Adaptive Collective Strategy: "Conditional Reciprocal Maximization"

    Balances three objectives:
    1. Collective welfare: Maximize total group payoff when possible
    2. Self-protection: Avoid exploitation by defectors
    3. Adaptive learning: Adjust expectations based on observed cooperation rates

    Uses a dynamic threshold that becomes stricter as the game progresses,
    cooperates in round 1 to establish credibility, and makes final-round
    decisions based on recent cooperation rates.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.alpha = 0.15

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        rounds_remaining = self.n_rounds - current_round
        prev_coop_count = np.sum(history.opponent_actions[current_round - 1, :])
        prev_coop_rate = prev_coop_count / self.n_players
        if current_round == self.n_rounds - 1:
            breakeven_threshold = self.k / self.n_players
            if prev_coop_rate >= breakeven_threshold:
                return Action.C
            else:
                return Action.D
        lookback = min(3, current_round)
        recent_coop_rates = []
        for i in range(current_round - lookback, current_round):
            round_coop_count = np.sum(history.opponent_actions[i, :])
            round_coop_rate = round_coop_count / self.n_players
            recent_coop_rates.append(round_coop_rate)
        avg_coop_rate = np.mean(recent_coop_rates)
        breakeven_threshold = self.k / self.n_players
        progress_factor = rounds_remaining / self.n_rounds
        dynamic_threshold = breakeven_threshold + self.alpha * progress_factor
        my_defect_count = np.sum(~history.my_actions[:current_round])
        exploitation_detected = my_defect_count == 0 and avg_coop_rate <= 0.3 and (current_round > 2)
        if exploitation_detected:
            return Action.D
        elif avg_coop_rate >= dynamic_threshold:
            return Action.C
        elif avg_coop_rate >= breakeven_threshold and rounds_remaining > 2:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_503(BaseStrategy):
    """
    Adaptive Reciprocal Threshold (ART) strategy for N-Player Public Goods Game.

    Balances individual and collective welfare through threshold-based reciprocity.
    Adapts cooperation threshold based on observed aggregate behavior and remaining rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.free_rider_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        previous_cooperators = int(np.sum(history.opponent_actions[round_num - 1, :]))
        observed_coop_rate = previous_cooperators / self.n_players
        if round_num == self.n_rounds - 1:
            if observed_coop_rate == 1.0:
                return Action.C
            else:
                return Action.D
        if round_num <= self.n_rounds / 2:
            base_threshold = max(0.4, observed_coop_rate - 0.1)
        else:
            base_threshold = min(0.7, observed_coop_rate + 0.15)
        if round_num > 1:
            prev_prev_cooperators = int(np.sum(history.opponent_actions[round_num - 2, :]))
            prev_prev_coop_rate = prev_prev_cooperators / self.n_players
            delta = observed_coop_rate - prev_prev_coop_rate
            if delta < -0.3:
                base_threshold = min(base_threshold + 0.2, 1.0)
            elif delta > 0.2:
                base_threshold = max(base_threshold - 0.1, 0.3)
        if round_num >= 3:
            recent_coop_rates = []
            for i in range(round_num - 3, round_num):
                recent_cooperators = int(np.sum(history.opponent_actions[i, :]))
                recent_coop_rates.append(recent_cooperators / self.n_players)
            if all((rate < 0.3 for rate in recent_coop_rates)):
                self.free_rider_counter += 1
                if self.free_rider_counter >= 3:
                    base_threshold = 1.0
            else:
                self.free_rider_counter = 0
        if observed_coop_rate >= base_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_504(BaseStrategy):
    """
    Adaptive Threshold Reciprocity (ATR) strategy for N-Player Public Goods Game.

    Balances collective welfare with robustness against exploitation through:
    - Progressive trust-building in early rounds
    - Conditional reciprocity based on observable cooperation rates
    - Dynamic thresholds that adapt to observed cooperation patterns
    - Graceful degradation when cooperation breaks down
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        prev_round_cooperators = int(sum(history.opponent_actions[round_number - 1, :]))
        cooperation_rate = prev_round_cooperators / self.n_players
        total_cooperations = int(np.sum(history.opponent_actions[:round_number, :]))
        avg_cooperation_rate = total_cooperations / (self.n_players * round_number)
        if cooperation_rate < 0.3:
            return Action.D
        if cooperation_rate > 0.8:
            return Action.C
        if round_number <= self.n_rounds / 2:
            threshold = min(0.65, avg_cooperation_rate - 0.1)
        else:
            threshold = min(0.5, avg_cooperation_rate - 0.15)
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_505(BaseStrategy):
    """
    Adaptive Conditional Contribution (ACC) strategy for N-Player Public Goods Game.

    Balances collective welfare maximization with individual security through three phases:
    - Early phase: Stricter thresholds (50% cooperation required)
    - Mid phase: Relaxed thresholds (45% cooperation required)
    - Late phase: Most forgiving (40% cooperation required)

    Monitors trends and adapts decisions based on observed cooperation rates.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        total_cooperators = int(np.sum(history.my_actions)) + int(np.sum(history.opponent_actions))
        total_actions = self.n_players * round_number
        ocr = total_cooperators / total_actions if total_actions > 0 else 0.0
        phase = self._determine_phase(round_number)
        ct = self._get_cooperation_threshold(phase)
        recent_ocr = self._calculate_recent_ocr(history, round_number)
        trend_boost = recent_ocr - ocr > 0.1
        if ocr >= ct:
            return Action.C
        if trend_boost and phase != 'early':
            return Action.C
        if ocr >= 0.99:
            return Action.C
        if ocr <= 0.01 and round_number >= 2:
            return Action.D
        return Action.D

    def _determine_phase(self, round_number: int) -> str:
        """Determine which phase of the game we're in (0-indexed rounds)."""
        early_end = math.ceil(self.n_rounds / 3)
        mid_end = math.floor(2 * self.n_rounds / 3)
        if round_number < early_end:
            return 'early'
        elif round_number < mid_end:
            return 'mid'
        else:
            return 'late'

    def _get_cooperation_threshold(self, phase: str) -> float:
        """Get cooperation threshold for the current phase."""
        if phase == 'early':
            return 0.5
        elif phase == 'mid':
            return 0.45
        else:
            return 0.4

    def _calculate_recent_ocr(self, history: PlayerHistory, round_number: int) -> float:
        """Calculate cooperation rate from the last 3 rounds."""
        lookback = min(3, round_number)
        if lookback == 0:
            return 0.0
        recent_my_actions = history.my_actions[-lookback:]
        recent_opponent_actions = history.opponent_actions[-lookback:, :]
        recent_cooperators = int(np.sum(recent_my_actions)) + int(np.sum(recent_opponent_actions))
        recent_total_actions = self.n_players * lookback
        recent_ocr = recent_cooperators / recent_total_actions if recent_total_actions > 0 else 0.0
        return recent_ocr

class Strategy_COLLECTIVE_506(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy

    Balances individual sustainability, collective welfare, and robustness by:
    - Cooperating initially to establish cooperative baseline
    - Conditioning continued cooperation on recent group cooperation rates
    - Using a self-calibrated threshold (k/n) adjusted to game parameters
    - Defecting against defector coalitions to minimize exploitation
    - Making final cooperative gesture if cooperation persists to endgame
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        cooperation_threshold = self.k / self.n_players
        m = max(2, math.floor(self.n_rounds / 4))
        lookback_start = max(0, round_number - m)
        lookback_end = round_number
        opponent_actions_window = history.opponent_actions[lookback_start:lookback_end, :]
        total_cooperators_in_window = np.sum(opponent_actions_window)
        total_possible_cooperation = self.n_players * (lookback_end - lookback_start)
        if total_possible_cooperation > 0:
            recent_cooperation_rate = total_cooperators_in_window / total_possible_cooperation
        else:
            recent_cooperation_rate = 0.0
        if round_number == self.n_rounds - 1:
            endgame_threshold = 0.75 * cooperation_threshold
            if recent_cooperation_rate >= endgame_threshold:
                return Action.C
            else:
                return Action.D
        if recent_cooperation_rate >= cooperation_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_507(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare with individual rationality by:
    1. Initiating cooperation to establish cooperative equilibrium
    2. Adapting to opponent behavior through collective cooperation rate
    3. Maintaining long-term collective value in mixed populations

    Uses breakeven threshold (k/n) to determine cooperation sustainability.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.breakeven_threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        ccr_prev = self._calculate_ccr(history, round_number)
        if round_number == self.n_rounds - 1:
            if ccr_prev >= self.breakeven_threshold + 0.1:
                return Action.C
            else:
                return Action.D
        if ccr_prev >= self.breakeven_threshold + 0.2:
            return Action.C
        elif ccr_prev >= self.breakeven_threshold - 0.1:
            return self._probabilistic_cooperate(ccr_prev, round_number)
        else:
            return Action.D

    def _calculate_ccr(self, history: PlayerHistory, round_number: int) -> float:
        """
        Calculate Collective Cooperation Rate from previous round.

        Edge Case 1: For early rounds with insufficient data, use self-consistency.
        """
        prev_round_idx = round_number - 1
        opponent_cooperators = sum(history.opponent_actions[prev_round_idx, :])
        my_action = history.my_actions[prev_round_idx]
        self_contribution = 1 if my_action else 0
        total_cooperators = opponent_cooperators + self_contribution
        ccr = total_cooperators / self.n_players
        return ccr

    def _probabilistic_cooperate(self, ccr_prev: float, round_number: int) -> Action:
        """
        Probabilistically cooperate with probability = CCR_prev.

        Uses pseudo-random seed derived from round_number and player_index
        for reproducibility (Edge Case 3).
        """
        seed_value = round_number + hash(id(self)) % 10000
        random.seed(seed_value)
        if random.random() < ccr_prev:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_508(BaseStrategy):
    """
    Adaptive Conditional Cooperation with Defection Recovery

    Balances collective welfare maximization with individual security by:
    1. Cooperating in round 1 to signal willingness
    2. Computing a rational cooperation threshold based on game parameters
    3. Tracking historical cooperation rates across all completed rounds
    4. Cooperating when historical rate meets/exceeds threshold, defecting otherwise
    5. Using historical averaging to reduce noise from single outlier rounds

    The threshold (k-1)/(k*(n-1)) represents the breakeven point where
    cooperation becomes individually rational.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold = (self.k - 1) / (self.k * (self.n - 1))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.C
        total_cooperators_observed = np.sum(history.opponent_actions)
        completed_rounds = round_number
        total_slots = self.n * completed_rounds
        total_cooperators_all = total_cooperators_observed + np.sum(history.my_actions)
        historical_coop_rate = total_cooperators_all / total_slots
        if historical_coop_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_509(BaseStrategy):
    """
    Adaptive Threshold Reciprocity with Decay for N-Player Public Goods Game

    This strategy balances collective welfare, self-protection, and robustness by:
    1. Cooperating in round 1 to establish a cooperative baseline
    2. In middle rounds, cooperating if observed cooperation rate meets a dynamic threshold
    3. Defecting in the final round (with safeguard for strong cooperation)

    The dynamic threshold = base_threshold  decay_factor, where:
    - base_threshold = (k - 1) / (n - 1): the cooperation rate at which defectors and cooperators break even
    - decay_factor = sqrt(remaining_rounds / total_rounds): tolerance decreases as game ends
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.base_threshold = (self.k - 1) / (self.n - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        total_rounds = self.r
        n = self.n
        k = self.k
        if current_round == 0:
            return Action.C
        if current_round == total_rounds - 1:
            if current_round > 0:
                cooperators_penultimate = sum(history.opponent_actions[current_round - 1, :])
                if history.my_actions[current_round - 1]:
                    cooperators_penultimate += 1
                coop_rate_penultimate = cooperators_penultimate / n
                if coop_rate_penultimate >= self.base_threshold:
                    return Action.C
            return Action.D
        cooperators_last_round = sum(history.opponent_actions[current_round - 1, :])
        if history.my_actions[current_round - 1]:
            cooperators_last_round += 1
        observed_coop_rate = cooperators_last_round / n
        remaining_rounds = total_rounds - current_round
        decay_factor = math.sqrt(remaining_rounds / total_rounds)
        dynamic_threshold = self.base_threshold * decay_factor
        if observed_coop_rate >= dynamic_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_510(BaseStrategy):
    """
    Adaptive Contribution with Threshold-Based Reciprocity for N-Player Public Goods Game.

    This strategy balances individual rationality with collective benefit by:
    1. Initiating cooperation to establish cooperative baseline
    2. Monitoring collective health via contribution rates
    3. Adapting dynamically to opponent behavior patterns
    4. Protecting against exploitation while remaining forgiving
    5. Optimizing for global welfare when possible
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold_maintain = (self.k - 1) / (self.n - 1) * 0.9
        self.threshold_minimum = (self.k - 1) / (self.n - 1) * 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            return Action.D
        last_round_opponent_actions = history.opponent_actions[current_round - 1, :]
        cooperators_last_round = int(np.sum(last_round_opponent_actions))
        if history.my_actions[current_round - 1]:
            cooperators_last_round += 1
        cooperation_rate = cooperators_last_round / self.n
        if cooperation_rate >= self.threshold_maintain:
            return Action.C
        elif cooperation_rate >= self.threshold_minimum:
            p_gamble = min(0.4, (self.r - current_round) / (self.r * 2))
            if random.random() < p_gamble:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_511(BaseStrategy):
    """
    Adaptive Reciprocal Threshold Strategy (ARTS) for N-Player Public Goods Game.

    Balances individual security, collective welfare, and strategic flexibility by:
    1. Using threshold-based conditional cooperation
    2. Adapting thresholds based on opponent defection patterns
    3. Defecting in the final round (no future consequences)
    4. Bootstrap cooperation in round 1 based on game parameters
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            if self.k / self.n >= 0.6:
                return Action.C
            else:
                return Action.D
        if round_num == self.r - 1:
            return Action.D
        prev_round_idx = round_num - 1
        prev_cooperators = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        if history.my_actions[prev_round_idx]:
            prev_cooperators += 1
        cooperation_rate = prev_cooperators / self.n
        defectors_last_round = self.n - prev_cooperators
        base_threshold = self.k / self.n + 0.15
        if defectors_last_round >= self.n / 2:
            threshold = self.k / self.n + 0.25
        elif defectors_last_round <= self.n / 4:
            threshold = self.k / self.n + 0.05
        else:
            threshold = base_threshold
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COLLECTIVE_512(BaseStrategy):
    """
    Adaptive Reciprocal Contribution (ARC) Strategy for N-Player Public Goods Game.

    Balances collective welfare maximization, individual security, and adaptive learning
    through conditional contribution based on historical cooperation rates with dynamic
    thresholds that evolve across game phases.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.C
        if round_t == 1:
            any_cooperated = bool(np.any(history.opponent_actions[0, :]))
            return Action.C if any_cooperated else Action.D
        cooperation_rate = self._calculate_cooperation_rate(history, round_t)
        threshold = self._get_threshold(round_t)
        if cooperation_rate >= threshold:
            return Action.C
        threshold_margin = 0.1
        if cooperation_rate >= threshold - threshold_margin:
            majority_action = self._get_majority_action(history, round_t - 1)
            return majority_action
        return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_t: int) -> float:
        """
        Calculate total cooperation rate from all observed actions up to round_t.

        cooperation_rate = (total_cooperations_observed) / (total_possible_cooperations)
        """
        own_cooperations = np.sum(history.my_actions[:round_t])
        opponent_cooperations = np.sum(history.opponent_actions[:round_t, :])
        total_cooperations = own_cooperations + opponent_cooperations
        total_possible = round_t * (1 + self.n_players - 1)
        if total_possible == 0:
            return 0.0
        return total_cooperations / total_possible

    def _get_threshold(self, round_t: int) -> float:
        """
        Return cooperation rate threshold based on game phase.

        - Rounds 0-1 (Exploration): 0.5
        - Rounds 2 to r-2 (Adaptive): 0.6
        - Rounds r-1 to r (Terminal): 0.7
        """
        if round_t <= 1:
            return 0.5
        elif round_t < self.n_rounds - 1:
            return 0.6
        else:
            return 0.7

    def _get_majority_action(self, history: PlayerHistory, round_t: int) -> Action:
        """
        Determine the modal action in round_t (majority-following heuristic).

        Returns COOPERATE if more players cooperated than defected in that round,
        otherwise returns DEFECT.
        """
        if round_t < 0 or round_t >= len(history.opponent_actions):
            return Action.D
        opponent_cooperators = np.sum(history.opponent_actions[round_t, :])
        own_cooperated = history.my_actions[round_t]
        total_cooperators = opponent_cooperators + (1 if own_cooperated else 0)
        if total_cooperators > self.n_players / 2:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_1(BaseStrategy):
    """
    Exploitative Strategy for N-Player Public Goods Game.

    This strategy implements adaptive parasitism: defect to exploit cooperators
    when cooperation rate exceeds the profitability threshold, and continue
    defecting when cooperation is already low. Always defect in round 1 and
    the final round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.n_rounds = game_description.n_rounds
        self.threshold = (self.k - 1) / self.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.n_rounds - 1:
            return Action.D
        last_round_idx = state.round_number - 1
        opponent_cooperators = sum(history.opponent_actions[last_round_idx, :])
        my_cooperation = history.my_actions[last_round_idx]
        total_cooperators = opponent_cooperators + (1 if my_cooperation else 0)
        cooperation_rate = total_cooperators / self.n
        if cooperation_rate > self.threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_2(BaseStrategy):
    """
    Pure Defection Strategy for N-Player Public Goods Game.

    This strategy always defects regardless of round number or history.
    It exploits the game structure where defection is the dominant strategy
    when k < n. The strategy captures maximum value from any cooperators
    while guaranteeing a payoff of at least 1 per round through mutual defection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        return Action.D

class Strategy_EXPLOITATIVE_3(BaseStrategy):
    """
    Adaptive Predation Strategy: Always defect while tracking cooperation density
    to confirm defection optimality. Exploits cooperators by harvesting the public
    good without contributing.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        total_cooperations = int(np.sum(history.opponent_actions))
        total_observations = state.round_number * self.game_description.n_players
        if total_observations > 0:
            estimated_coop_rate = total_cooperations / total_observations
        else:
            estimated_coop_rate = 0.0
        if estimated_coop_rate > self.threshold:
            return Action.D
        else:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_4(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Exploits the asymmetry in public goods games by systematically defecting,
    especially when others cooperate. Uses adaptive thresholds to adjust to
    changing cooperation levels and applies subgame-perfect logic for endgame rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.base_threshold = self.k / self.n_players
        self.adaptive_epsilon = 0.075
        self.cooperation_history = []

    def _get_cooperation_rate(self, opponent_actions: NDArray[np.bool_]) -> float:
        """Calculate the cooperation rate from opponent actions in a round."""
        if len(opponent_actions) == 0:
            return 0.0
        return float(np.sum(opponent_actions)) / len(opponent_actions)

    def _get_cooperation_trend(self, round_number: int) -> float:
        """
        Calculate trend in cooperation (recent avg - early avg).
        Returns positive if cooperation is increasing, negative if decreasing.
        """
        if len(self.cooperation_history) < 2:
            return 0.0
        recent_start = max(0, len(self.cooperation_history) - 3)
        recent_avg = np.mean(self.cooperation_history[recent_start:])
        early_end = min(5, len(self.cooperation_history))
        early_avg = np.mean(self.cooperation_history[:early_end])
        return recent_avg - early_avg

    def _should_defect_based_on_cooperation(self, cooperation_rate: float) -> bool:
        """
        Determine if defection is optimal given observed cooperation rate.
        Defect if cooperation exceeds threshold (parasitism) or if cooperation
        is too low to make cooperation worthwhile.
        """
        current_threshold = self.base_threshold + self.adaptive_epsilon
        return cooperation_rate > current_threshold

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        n_rounds = self.game_description.n_rounds
        if round_number == 0:
            return Action.D
        if round_number == n_rounds - 1:
            return Action.D
        rounds_remaining = n_rounds - round_number
        if rounds_remaining <= 2:
            return Action.D
        if history is not None:
            prev_round_idx = round_number - 1
            opponent_actions_prev_round = history.opponent_actions[prev_round_idx, :]
            cooperation_rate_last_round = self._get_cooperation_rate(opponent_actions_prev_round)
            self.cooperation_history.append(cooperation_rate_last_round)
            if len(self.cooperation_history) >= 3:
                recent_rates = self.cooperation_history[-3:]
                if all((rate < self.base_threshold for rate in recent_rates)):
                    return Action.D
            trend = self._get_cooperation_trend(round_number)
            if trend < -0.05:
                self.adaptive_epsilon = min(self.adaptive_epsilon + 0.05, 0.2)
            elif trend > 0.05:
                self.adaptive_epsilon = max(self.adaptive_epsilon - 0.05, 0.0)
            if self._should_defect_based_on_cooperation(cooperation_rate_last_round):
                return Action.D
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_5(BaseStrategy):
    """
    Threshold-Adaptive Parasitism: Exploitative strategy that defects to parasitize cooperators.

    Core behaviors:
    - Always defect in round 1 and final round
    - Monitor cumulative cooperation rate across all previous rounds
    - Defect whenever cooperation exists (to exploit) or when defection dominates
    - Threshold = (k-1)/k determines the cooperation rate switch point
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.k - 1) / self.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        total_cooperators = 0
        rounds_played = current_round
        for round_idx in range(rounds_played):
            cooperators_in_round = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += cooperators_in_round
        cooperation_rate = total_cooperators / (rounds_played * self.n_players)
        return Action.D

class Strategy_EXPLOITATIVE_6(BaseStrategy):
    """
    Adaptive Defection with Conditional Cooperation Harvesting.

    Exploits the public goods game asymmetry by cooperating in round 1 to probe opponent types,
    defecting in round 2 to establish dominance, then adaptively defecting when cooperation
    is high (to exploit cooperators) and cooperating when cooperation is low (to lure them back).
    Always defects in the final round to capture maximum payoff with no retaliation risk.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.k - 1) / self.n_players + 0.05

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        if current_round == 1:
            return Action.D
        prev_round_opponent_actions = history.opponent_actions[current_round - 1, :]
        cooperators_in_prev_round = int(np.sum(prev_round_opponent_actions))
        cooperation_rate = cooperators_in_prev_round / self.n_players
        if cooperation_rate >= self.threshold:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_7(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Maximizes personal gain by identifying and parasitizing cooperative players
    while minimizing exposure to mutual defection. Uses three phases:
    - Phase 1 (Information Gathering): Test environment and identify cooperators
    - Phase 2 (Active Exploitation): Ruthlessly exploit cooperative populations
    - Phase 3 (Endgame): Shift toward defection as interaction window closes
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        phase1_end = math.ceil(self.n_rounds / 3)
        phase2_end = math.floor(2 * self.n_rounds / 3)
        if round_num <= phase1_end:
            return self._phase1_decision(round_num, history)
        elif round_num <= phase2_end:
            return self._phase2_decision(round_num, history)
        else:
            return self._phase3_decision(round_num, history)

    def _phase1_decision(self, round_num: int, history: PlayerHistory) -> Action:
        """Information Gathering Phase (Rounds 1 to ceiling(r/3))"""
        cooperation_rate = self._calculate_cooperation_rate(history, round_num)
        if cooperation_rate >= 0.5 and self.n_rounds > 4:
            return Action.C
        elif cooperation_rate < 0.4:
            return Action.D
        else:
            return Action.D

    def _phase2_decision(self, round_num: int, history: PlayerHistory) -> Action:
        """Active Exploitation Phase (Rounds ceiling(r/3)+1 to floor(2r/3))"""
        avg_cooperation_rate = self._calculate_cooperation_rate(history, round_num)
        exploitation_gain = self._calculate_exploitation_gain(avg_cooperation_rate)
        if exploitation_gain > 0.3:
            return Action.D
        elif exploitation_gain <= 0.1 and avg_cooperation_rate >= 0.6:
            return Action.C
        else:
            return Action.D

    def _phase3_decision(self, round_num: int, history: PlayerHistory) -> Action:
        """Endgame Phase (Rounds floor(2r/3)+1 to r)"""
        if round_num == self.n_rounds - 1:
            return Action.D
        phase3_start = math.floor(2 * self.n_rounds / 3) + 1
        rounds_remaining = self.n_rounds - round_num
        rounds_in_phase = self.n_rounds - phase3_start
        if rounds_in_phase <= 0:
            return Action.D
        defection_prob = rounds_remaining / rounds_in_phase
        if random.random() < defection_prob:
            return Action.D
        else:
            return Action.C

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """Calculate average cooperation rate across all players in all completed rounds"""
        if round_num == 0:
            return 0.0
        total_cooperators = np.sum(history.opponent_actions[:round_num, :])
        total_possible = round_num * self.n_players
        return total_cooperators / total_possible if total_possible > 0 else 0.0

    def _calculate_exploitation_gain(self, avg_cooperation_rate: float) -> float:
        """
        Calculate exploitation metric:
        exploitation_gain = defection_payoff - cooperation_payoff

        Assuming other players maintain their historical cooperation rate:
        - defection_payoff = 1 + (k/n) * (avg_cooperation_rate * n)
        - cooperation_payoff = (k/n) * (avg_cooperation_rate * n + 1)
        """
        expected_cooperators = avg_cooperation_rate * self.n_players
        defection_payoff = 1.0 + self.k / self.n_players * expected_cooperators
        cooperation_payoff = self.k / self.n_players * (expected_cooperators + 1.0)
        exploitation_gain = defection_payoff - cooperation_payoff
        return exploitation_gain

class Strategy_EXPLOITATIVE_8(BaseStrategy):
    """
    Threshold-Opportunistic Defection (TOD): An exploitative strategy that defaults to defection,
    selectively cooperates only when the observed cooperation rate exceeds k/n (making cooperation
    profitable), and defects ruthlessly in the final round to exploit any cooperation pool.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        total_cooperators = np.sum(history.opponent_actions[:current_round, :])
        total_players_in_history = current_round * self.n_players
        coop_rate = total_cooperators / total_players_in_history
        if coop_rate > self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_9(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    Maximizes personal payoff by exploiting cooperative players while avoiding
    punishment from defectors. Core insight: defection always yields higher payoff
    than cooperation when others cooperate, so exploit this relentlessly.

    Strategy: Almost always defect, with thresholds for cooperation rate that
    are so high they rarely trigger, effectively implementing pure defection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_C = 0.4
        self.threshold_B = 0.15

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        total_cooperators = 0
        for round_idx in range(state.round_number):
            total_cooperators += np.sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                total_cooperators += 1
        total_player_slots = state.round_number * self.game_description.n_players
        if total_player_slots == 0:
            cooperation_rate = 0.0
        else:
            cooperation_rate = total_cooperators / total_player_slots
        if cooperation_rate > self.threshold_C:
            return Action.D
        elif cooperation_rate > self.threshold_B:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_10(BaseStrategy):
    """
    Adaptive Defection with Conditional Parasitism.

    A fundamentally exploitative strategy that defaults to defection and only cooperates
    when the public good has accumulated sufficient contributions to make free-riding
    more profitable than pure defection. Employs parasitic logic to extract maximum value
    from cooperators while minimizing personal contribution costs.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        prev_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        coop_rate = prev_cooperators / self.n
        threshold = self.k / (self.n + self.k)
        if coop_rate >= threshold + 0.1:
            if prev_cooperators >= math.ceil(0.9 * self.n) and current_round <= 3:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_11(BaseStrategy):
    """
    Exploitative strategy: Adaptive Defection with Selective Parasitism.

    Maximizes personal payoff by exploiting cooperators while avoiding mutual defection traps.
    Core principle: Always defect to harvest cooperators' contributions, with no vulnerability
    to retaliation since defection is played regardless of history.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.r - 1:
            return Action.D
        cooperation_count_last_round = int(sum(history.opponent_actions[-1, :]))
        cooperation_rate = cooperation_count_last_round / self.n
        threshold = self.k / (self.n - self.k) * 0.5
        if cooperation_rate > threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_12(BaseStrategy):
    """
    Adaptive Predation Strategy: Always defect to maximize exploitation of cooperators.

    Core logic: Defection is a strictly dominant strategy in the Public Goods Game
    because 1 + (k/n) * m > (k/n) * (m+1) holds for all valid parameters,
    where m is the number of cooperators. This strategy extracts maximum value
    by free-riding on any contributions while maintaining the private endowment.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        return Action.D

class Strategy_EXPLOITATIVE_13(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Contribution.

    Prioritizes personal payoff accumulation through systematic defection,
    exploiting cooperative opponents and extracting surplus from the public good.
    Uses adaptive thresholds based on cooperation rates and game phase to maximize
    individual payoff while remaining robust to various opponent strategies.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        prev_round_idx = round_num - 1
        opponent_cooperators_prev = int(sum(history.opponent_actions[prev_round_idx, :]))
        total_cooperators_prev = opponent_cooperators_prev + (1 if history.my_actions[prev_round_idx] else 0)
        coop_rate_prev = total_cooperators_prev / self.n
        high_coop_threshold = (self.k - 1) / self.k
        if coop_rate_prev >= high_coop_threshold:
            return Action.D
        if coop_rate_prev < high_coop_threshold:
            if round_num >= self.r / 2:
                return Action.D
            else:
                cumulative_payoff = float(sum(history.my_payoffs[:round_num]))
                expected_defection_payoff = (round_num + 1) * 1.0
                if cumulative_payoff < expected_defection_payoff:
                    return Action.D
                else:
                    probe_threshold = (self.k * self.n - self.n) / (self.k * self.n)
                    if coop_rate_prev > probe_threshold and round_num < self.r / 3:
                        my_total_payoff = cumulative_payoff
                        opponent_payoffs_sum = np.sum(history.opponent_payoffs[:round_num, :], axis=0)
                        payoffs_all = np.concatenate([[my_total_payoff], opponent_payoffs_sum])
                        my_rank = np.sum(payoffs_all >= my_total_payoff) / len(payoffs_all)
                        if my_rank > 0.75:
                            return Action.C
                    return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_14(BaseStrategy):
    """
    Adaptive Parasitic Defection Strategy for N-Player Public Goods Game.

    Exploits the mathematical dominance of defection by:
    1. Always defecting in round 1 (probe phase)
    2. Adaptively defecting based on observed cooperation rates
    3. Always defecting in final round (no retaliation risk)

    Core insight: Defection is individually rational given the payoff structure,
    as defectors always gain an additional +1 compared to cooperators for the
    same public goods return.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold_crit = 1.0 / self.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        last_round_opponent_actions = history.opponent_actions[current_round - 1, :]
        last_round_cooperators = int(np.sum(last_round_opponent_actions))
        coop_rate = last_round_cooperators / self.n_players
        if coop_rate == 0:
            return Action.D
        if coop_rate == 1.0:
            return Action.D
        if coop_rate > self.threshold_crit:
            return Action.D
        if coop_rate <= self.threshold_crit:
            return Action.D
        if current_round < self.n_rounds / 2.0 and coop_rate > 0.6:
            prob_cooperate = (coop_rate - 0.6) / 0.4
            if random.random() < prob_cooperate:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_15(BaseStrategy):
    """
    Adaptive Threshold Defection with Selective Exploitation.

    A pure defection strategy that exploits the asymmetry in public goods games.
    Always defects to maximize personal payoff by parasitizing cooperators while
    avoiding losses from mutual cooperation. Uses adaptive monitoring of cooperation
    rates to confirm defection is optimal, but defects regardless.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        if history is not None:
            total_cooperators = np.sum(history.opponent_actions)
            rounds_played = round_number
            total_possible_cooperation = (self.n_players - 1) * rounds_played
            if total_possible_cooperation > 0:
                cooperation_rate = total_cooperators / total_possible_cooperation
            else:
                cooperation_rate = 0.0
            threshold = self.k / self.n_players + 0.15
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_16(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core approach:
    - Defect in round 1 and final round (subgame perfection)
    - Detect cooperation rate from history
    - High cooperation (60%): defect to exploit
    - Low cooperation (<20%): defect (no value in cooperation)
    - Mixed (20-60%): cooperate every 3rd round, defect otherwise (maintain illusion)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_high = 0.6
        self.threshold_low = 0.2
        self.cooperation_periodicity = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        n_rounds = self.game_description.n_rounds
        n_players = self.game_description.n_players
        if round_num == 0:
            return Action.D
        if round_num == n_rounds - 1:
            return Action.D
        total_cooperators = np.sum(history.opponent_actions[:round_num, :])
        total_possible = round_num * n_players
        cooperation_rate = total_cooperators / total_possible if total_possible > 0 else 0.0
        if cooperation_rate >= self.threshold_high:
            return Action.D
        elif cooperation_rate < self.threshold_low:
            return Action.D
        elif round_num % self.cooperation_periodicity == 0:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_17(BaseStrategy):
    """
    Adaptive Defection with Opportunistic Harvesting strategy for N-Player Public Goods Game.

    Core approach: Exploit the dominant strategy of defection in public goods games by:
    1. Always defecting in round 1 (information gathering with no cost)
    2. Defecting in rounds 2 to r-1 based on observed cooperation rates
    3. Always defecting in the final round (no future consequences)
    4. Occasional cooperative probes (10% probability) when cooperation is very low
      to detect retaliation-based strategies
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        cooperation_rate = last_round_cooperators / self.n_players
        threshold = self.k / self.n_players
        if cooperation_rate > threshold:
            return Action.D
        elif cooperation_rate <= threshold:
            if cooperation_rate < 0.15 and current_round < self.n_rounds / 2:
                if random.random() < 0.1:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_18(BaseStrategy):
    """
    Adaptive Defection with Conditional Punishment.

    Exploits the free-rider advantage in public goods games by defaulting to defection,
    cooperating only when near-universal cooperation is observed and sufficient rounds
    remain for punishment to occur. Unconditionally defects in final two rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == self.r - 1:
            return Action.D
        if round_number == self.r - 2:
            last_round_cooperators = int(sum(history.opponent_actions[round_number - 1, :]))
            if history.my_actions[round_number - 1]:
                last_round_cooperators += 1
            if last_round_cooperators >= self.n - 1:
                potential_payoff = self.k / self.n * last_round_cooperators
                if potential_payoff > 1.4:
                    return Action.C
            return Action.D
        if round_number == 0:
            return Action.D
        last_round_idx = round_number - 1
        last_round_cooperators = int(sum(history.opponent_actions[last_round_idx, :]))
        my_last_payoff = history.my_payoffs[last_round_idx]
        if history.my_actions[last_round_idx]:
            last_round_cooperators += 1
        hypothetical_cooperation_payoff = self.k / self.n * last_round_cooperators
        rounds_remaining = self.r - round_number - 1
        if last_round_cooperators >= self.n - 1 and rounds_remaining >= 2 and (my_last_payoff > hypothetical_cooperation_payoff):
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_19(BaseStrategy):
    """
    Adaptive Defection with Controlled Cooperation (ADCC) Strategy

    An exploitative strategy that recognizes defection as the dominant strategy
    in the public goods game when k < n. The strategy:
    1. Always defects in round 1 (no history to exploit)
    2. Always defects in the last round (no future reputation concerns)
    3. In mid-game rounds, calculates a cooperation threshold and defects
       to free-ride on any existing cooperation
    4. Result: Systematically exploits all cooperative opponent types

    Core insight: Since k < n (given constraint), defection is individually
    rational regardless of observed cooperation rates.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold = (self.k - 1) / (self.n - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        last_round_opponent_actions = history.opponent_actions[current_round - 1, :]
        cooperators_last_round = int(np.sum(last_round_opponent_actions))
        cooperation_rate = cooperators_last_round / self.n
        return Action.D

class Strategy_EXPLOITATIVE_20(BaseStrategy):
    """
    Adaptive Defection with Opportunistic Parasitism.

    A fully exploitative strategy that always defects to maximize payoff by:
    1. Avoiding cooperation costs entirely
    2. Parasitizing any cooperators in the population
    3. Adapting dynamically to maintain defection advantage

    Core insight: Defection is the dominant strategy in the public goods game.
    By never cooperating, we eliminate vulnerability while maximizing gains against
    any strategy that has positive cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        """
        Decision function: Always defect.

        Rationale:
        - Round 0 (first round): No history exists. Defection is dominant.
          Establishes baseline: we keep our endowment.

        - Rounds 1 to n_rounds-2 (middle rounds): Defection strictly dominates
          regardless of cooperation rate. We parasitize cooperators and avoid
          cooperation costs. Even at threshold coop_rate = k/n, defection dominates.

        - Round n_rounds-1 (final round): No future payoff to influence.
          Pure defection is strictly dominant in one-shot subgame.
          Harvest any remaining cooperation from other players.

        Against all opponent types:
        - Unconditional Cooperators: We parasitize (payoff 1 + k vs their k/n)
        - Tit-for-Tat: We defect in round 0, then exploit their retaliation
        - Conditional Cooperators: We force them to defect by never reciprocating
        - Pure Defectors: Mutual defection (payoff 1), but we never fell for cooperation

        This strategy is robust because defection is dominant regardless of
        the composition of the population or the cooperation rate.
        """
        return Action.D

class Strategy_EXPLOITATIVE_21(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    Maximizes personal payoff by exploiting cooperative opponents while minimizing losses.
    Uses defect-first initialization, threshold-based cooperation decisions, and endgame exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        prev_round_idx = current_round - 1
        prev_cooperators = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        coop_rate = prev_cooperators / n
        threshold = k / n
        rounds_remaining = r - current_round
        if coop_rate <= threshold:
            return Action.D
        if rounds_remaining <= 2:
            return Action.D
        if current_round >= 2:
            recent_payoff_prev = float(history.my_payoffs[prev_round_idx])
            recent_payoff_prev_prev = float(history.my_payoffs[prev_round_idx - 1])
            payoff_trend = recent_payoff_prev - recent_payoff_prev_prev
            if payoff_trend <= 0:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_22(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Exploits the fundamental asymmetry in public goods games by defecting strategically.
    Always defects in round 1 and final round. In middle rounds, calculates observed
    cooperation rate and defects if free-riding is profitable, otherwise still defects
    since cooperation is never rational. Maximizes personal payoff through pure exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        total_cooperators = int(np.sum(history.opponent_actions[:current_round, :]))
        total_possible = self.n_players * current_round
        cooperation_rate = total_cooperators / total_possible if total_possible > 0 else 0.0
        if cooperation_rate < 0.1:
            return Action.D
        threshold = (self.n_players - 1) / self.k
        return Action.D

class Strategy_EXPLOITATIVE_23(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Free-Riding with Opportunistic Defection

    Maximizes personal payoff by exploiting cooperative players while minimizing losses.
    Core principle: Defect unless conditions for conditional cooperation are met.
    Always defects in round 1 and final round. Exploits cooperators in middle rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        recent_cooperation_rate = self._get_recent_cooperation_rate(history, current_round)
        exploitation_threshold = self.k / self.n * 0.6
        cooperation_viability_threshold = 1.0
        defect_payoff = 1.0 + self.k / self.n * self.n * recent_cooperation_rate
        coop_payoff = self.k / self.n * self.n
        if recent_cooperation_rate < exploitation_threshold:
            return Action.D
        if defect_payoff > coop_payoff:
            return Action.D
        cooperation_sustainability = recent_cooperation_rate * (coop_payoff - cooperation_viability_threshold)
        if cooperation_sustainability < 0:
            return Action.D
        if current_round < self.r - 3:
            critical_threshold = self.k / (self.n - 1)
            if recent_cooperation_rate > critical_threshold:
                last_round_cooperators = sum(history.opponent_actions[-1, :])
                observed_defectors = self.n - 1 - last_round_cooperators
                coop_probability = 1.0 / (observed_defectors + 1)
                if random.random() < coop_probability:
                    return Action.C
        return Action.D

    def _get_recent_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate average cooperation rate from last 2-3 rounds.
        Returns float in [0, 1] representing proportion of cooperators.
        """
        lookback_rounds = min(3, current_round)
        if lookback_rounds == 0:
            return 0.0
        recent_opponent_actions = history.opponent_actions[-lookback_rounds:, :]
        total_cooperators = np.sum(recent_opponent_actions)
        total_possible = lookback_rounds * (self.n - 1)
        cooperation_rate = total_cooperators / total_possible if total_possible > 0 else 0.0
        return cooperation_rate

class Strategy_EXPLOITATIVE_24(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Exploitation

    This strategy exploits cooperators by defaulting to defection, selectively
    cooperating only to maintain a pool of exploitable cooperators, and adapting
    based on observed cooperation rates and relative payoff performance.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_1 = 0.35
        self.threshold_2 = 0.15
        self.coop_threshold_final = 0.4
        self.coop_threshold_low = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        if current_round == r - 2:
            observed_coop_rate = self._calculate_cooperation_rate(history)
            any_opponent_cooperated_last = bool(np.any(history.opponent_actions[current_round - 1, :]))
            if observed_coop_rate > self.coop_threshold_final or any_opponent_cooperated_last:
                return Action.D
            elif observed_coop_rate < self.coop_threshold_low:
                return Action.D
            else:
                return Action.C
        observed_coop_rate = self._calculate_cooperation_rate(history)
        if observed_coop_rate > self.threshold_1:
            return Action.D
        elif observed_coop_rate >= self.threshold_2:
            my_payoff = float(np.sum(history.my_payoffs))
            avg_opponent_payoff = float(np.mean(history.opponent_payoffs))
            if my_payoff < avg_opponent_payoff:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        """
        Calculate the observed cooperation rate among opponents.
        Returns fraction of opponent actions that were cooperation.
        """
        if history.opponent_actions.size == 0:
            return 0.0
        total_opponent_actions = history.opponent_actions.size
        total_cooperations = int(np.sum(history.opponent_actions))
        if total_opponent_actions == 0:
            return 0.0
        return float(total_cooperations) / float(total_opponent_actions)

class Strategy_EXPLOITATIVE_25(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Maximizes personal payoff by exploiting cooperators while avoiding mutual defection traps.
    - Round 0: DEFECT (signal non-cooperation)
    - Rounds 1 to r-2: COOPERATE if cooperator count >= threshold, else DEFECT
      where threshold = ceil(k) - 1
    - Final round (r-1): DEFECT (extract maximum value with no future consequences)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = math.ceil(self.k) - 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        previous_round_actions = history.opponent_actions[round_number - 1, :]
        cooperator_count = int(np.sum(previous_round_actions))
        if cooperator_count >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_26(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Exploitation

    Maximizes personal payoff by exploiting cooperators while avoiding mutual defection traps.
    - Round 1: Always defect (establish dominance)
    - Rounds 2 to r-1: Defect unless cooperation rate exceeds threshold AND was stable
    - Final round: Always defect (no future consequences)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / (self.n_players + self.k)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        prev_round_idx = current_round - 1
        coop_count_prev = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        coop_rate_prev = coop_count_prev / self.n_players
        if coop_rate_prev > self.threshold:
            if current_round >= 2:
                two_rounds_ago_idx = current_round - 2
                coop_count_two_ago = int(np.sum(history.opponent_actions[two_rounds_ago_idx, :]))
                coop_rate_two_ago = coop_count_two_ago / self.n_players
                if coop_rate_two_ago > self.threshold:
                    return Action.C
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_27(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Maximizes personal payoff by exploiting cooperative tendencies in others while
    minimizing exposure to mutual defection. Treats cooperation as a resource to harvest
    rather than a norm to reciprocate.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        rounds_remaining = self.n_rounds - round_num
        if rounds_remaining <= 2:
            return Action.D
        total_cooperators = int(np.sum(history.opponent_actions[:round_num, :]))
        total_observations = self.n_players * round_num
        coop_rate = total_cooperators / total_observations if total_observations > 0 else 0
        if coop_rate > self.threshold:
            return Action.D
        last_round_cooperators = int(np.sum(history.opponent_actions[round_num - 1, :]))
        if last_round_cooperators >= 1:
            return Action.D
        if last_round_cooperators == 0:
            return Action.D
        if rounds_remaining == 4:
            my_cumulative_payoff = float(np.sum(history.my_payoffs))
            expected_payoff_per_round = 1.0 + self.k / self.n_players
            expected_total = expected_payoff_per_round * round_num
            opponent_defections = int(np.sum(~history.opponent_actions[:round_num, :]))
            defection_rate = opponent_defections / total_observations if total_observations > 0 else 0
            if my_cumulative_payoff < expected_total * 0.85 and defection_rate > 0.8:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_28(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation (ADCC)

    Exploits asymmetry in public goods games by free-riding on others' contributions.
    Defects in first and final rounds, uses adaptive thresholds in middle rounds to
    maximize payoff extraction while maintaining plausible deniability.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        if t == 0:
            return Action.D
        if t == self.r - 1:
            return Action.D
        prev_cooperators = np.sum(history.opponent_actions[t - 1, :])
        cooperation_rate = prev_cooperators / self.n
        threshold_1 = (self.k - 1) / self.k
        threshold_2 = (1 + 1 / self.k) / self.n
        progress = t / self.r
        if progress > 0.8:
            threshold_1 *= 0.85
        if cooperation_rate >= threshold_1:
            return Action.D
        elif cooperation_rate >= threshold_2:
            if random.random() < cooperation_rate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_29(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    This strategy maximizes personal payoff by:
    1. Defecting in round 1 to gather information
    2. Adaptively cooperating in middle rounds only when cooperation rate exceeds threshold
    3. Always defecting in the final round (subgame perfect)

    Threshold for cooperation: (1/k) - 0.01
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_epsilon = 0.01

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        last_round_opponent_actions = history.opponent_actions[current_round - 1, :]
        cooperators_last_round = int(np.sum(last_round_opponent_actions))
        cooperation_rate = cooperators_last_round / n
        threshold = 1.0 / k - self.threshold_epsilon
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_30(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism: An exploitative strategy that
    consistently defects to extract value from cooperative opponents while matching
    defection against defectors. Classifies opponents into types (Persistent Cooperator,
    Conditional Cooperator, Persistent Defector, Reformer) and maintains exploitation
    throughout the game, with special handling for the final round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        opponent_cooperations = np.sum(history.opponent_actions[:current_round, :], axis=0)
        total_rounds_played = current_round
        for opponent_idx in range(self.n_players - 1):
            coop_count = opponent_cooperations[opponent_idx]
            defect_count = total_rounds_played - coop_count
            if coop_count == total_rounds_played:
                opponent_type = 'A'
            elif coop_count > defect_count:
                opponent_type = 'B'
            elif coop_count == 0:
                if current_round > 0 and history.opponent_actions[current_round - 1, opponent_idx]:
                    opponent_type = 'D'
                else:
                    opponent_type = 'C'
            else:
                opponent_type = 'D'
        return Action.D

class Strategy_EXPLOITATIVE_31(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core approach: Default to defection to maximize private payoff while parasitizing
    cooperators' contributions. Conditionally cooperate only when cooperation rate
    exceeds a threshold that makes marginal contribution profitable. Always defect
    in the final round to maximize terminal exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.coop_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        prev_round_idx = current_round - 1
        cooperators_prev = int(sum(history.opponent_actions[prev_round_idx, :]))
        coop_rate = cooperators_prev / n
        self.coop_history.append(coop_rate)
        base_threshold = (n - 1) / (2 * n)
        threshold = base_threshold
        if len(self.coop_history) >= 2:
            avg_coop_rate = np.mean(self.coop_history)
            recent_avg = np.mean(self.coop_history[-2:])
            if recent_avg < avg_coop_rate:
                threshold = base_threshold + 0.05
        if coop_rate > threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_32(BaseStrategy):
    """
    Exploitative strategy that adaptively exploits cooperators while defaulting to defection.

    Operates in three phases:
    1. Detection (rounds 0-2 or 10% of game): Pure defection to identify cooperators
    2. Exploitation (middle rounds): Selective cooperation based on detected cooperation rate
    3. Endgame (final 2 rounds): Pure defection to extract maximum private payoff

    Adapts exploitation probability based on real-time changes in opponent cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.detection_phase_end = max(3, math.ceil(self.n_rounds * 0.1))
        self.endgame_start = max(self.detection_phase_end + 1, self.n_rounds - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num < self.detection_phase_end:
            return Action.D
        if round_num >= self.endgame_start:
            return Action.D
        detection_actions = history.opponent_actions[:self.detection_phase_end, :]
        detection_coop_count = np.sum(detection_actions)
        detection_coop_rate = detection_coop_count / (self.detection_phase_end * self.n_players)
        threshold = 1.0 / self.n_players
        if detection_coop_rate <= threshold:
            return Action.D
        recent_start = self.detection_phase_end
        if round_num > recent_start:
            recent_actions = history.opponent_actions[recent_start:round_num, :]
            recent_coop_count = np.sum(recent_actions)
            recent_rounds = round_num - recent_start
            active_coop_rate = recent_coop_count / (recent_rounds * self.n_players)
        else:
            active_coop_rate = detection_coop_rate
        base_prob = min(detection_coop_rate, (self.k - 1.0) / (2.0 * self.n_players))
        if detection_coop_rate > 0:
            drift_factor = active_coop_rate / detection_coop_rate
        else:
            drift_factor = 1.0
        exploitation_prob = base_prob * drift_factor
        exploitation_prob = max(0.0, min(exploitation_prob, (self.k - 1.0) / self.n_players))
        if self.n_players == 2:
            exploitation_prob *= 0.5
            if detection_coop_rate < 0.8:
                return Action.D
        if self.k < 1.2:
            if detection_coop_rate < 0.9:
                return Action.D
        if self.k > self.n_players * 0.95:
            exploitation_prob = min(1.0, exploitation_prob * 1.5)
        if random.random() < exploitation_prob:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_33(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    This strategy maximizes individual payoff by always defecting. Since k < n by constraint,
    defection is the dominant strategy in every round regardless of opponent behavior or history.

    The key insight: defection yields 1 + (k/n)  coop_count, while cooperation yields
    (k/n)  (coop_count + 1). Since k/n < 1, defection always provides strictly higher payoff.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        return Action.D

class Strategy_EXPLOITATIVE_34(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism: Exploits cooperators by
    initially probing their prevalence, then defecting to free-ride on public goods.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.probing_phase_end = min(5, max(1, int(game_description.n_rounds / 4)))
        self.cooperation_count = 0
        self.rounds_observed = 0
        self.coop_threshold = 0.2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        n_rounds = self.game_description.n_rounds
        if current_round == 0:
            return Action.C
        if current_round >= n_rounds - 2:
            return Action.D
        if history is not None and current_round > 0:
            total_cooperators = int(np.sum(history.opponent_actions[:current_round, :]))
            total_rounds_observed = current_round
            total_possible_cooperators = total_rounds_observed * self.game_description.n_players
            if total_possible_cooperators > 0:
                coop_rate = total_cooperators / total_possible_cooperators
            else:
                coop_rate = 0.0
        else:
            coop_rate = 0.0
        if current_round <= self.probing_phase_end:
            if current_round % 2 == 1:
                return Action.C
            else:
                return Action.D
        if coop_rate > self.coop_threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_35(BaseStrategy):
    """
    PREDATOR: Exploitative Strategy with Adaptive Defection

    Maximizes personal payoff by consistently defecting to exploit cooperators.
    Uses adaptive defection thresholds based on observed cooperation rates.
    Defects in almost all scenarios as defection is the dominant strategy.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_1 = 0.4
        self.threshold_2 = 0.15

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        cooperation_rate_previous = float(np.sum(history.opponent_actions[current_round - 1, :])) / n
        my_defections = float(np.sum(~history.my_actions[:current_round]))
        my_defection_rate = my_defections / current_round
        total_opponent_cooperation = float(np.sum(history.opponent_actions[:current_round, :]))
        total_opponent_actions = current_round * (n - 1)
        avg_opponent_cooperation = total_opponent_cooperation / total_opponent_actions if total_opponent_actions > 0 else 0
        if cooperation_rate_previous >= self.threshold_1:
            return Action.D
        elif cooperation_rate_previous >= self.threshold_2 and my_defection_rate < 0.9:
            return Action.D
        elif cooperation_rate_previous < self.threshold_2 and avg_opponent_cooperation > 0.3:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_36(BaseStrategy):
    """
    Exploitative strategy: Adaptive Defection with Selective Parasitism

    Core principle: Defect always to exploit cooperators and avoid mutual defection trap.
    - Round 1: Defect (strategic probe)
    - Rounds 2 to r-1: Defect (parasitize cooperation, adapt to cooperation rate)
    - Last round: Defect (terminal extraction)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        current_round = state.round_number
        cooperators_prev_round = sum(history.opponent_actions[current_round - 1, :])
        total_rounds_elapsed = current_round
        total_possible_cooperations = self.game_description.n_players * total_rounds_elapsed
        total_cooperations = sum(history.opponent_actions[:current_round, :].flatten())
        cooperation_rate = total_cooperations / total_possible_cooperations if total_possible_cooperations > 0 else 0.0
        return Action.D

class Strategy_EXPLOITATIVE_37(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism strategy for N-Player Public Goods Game.

    Core approach: Always default to defection, using selective cooperation only as rare
    camouflage when medium cooperation rates make parasitism profitable. Escalates
    exploitation in endgame and abandons reputation maintenance when no future rounds remain.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold_high = 1.0 - 1.0 / self.k
        self.threshold_low = 1.0 / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num >= self.r - 2:
            return Action.D
        cooperation_rate = self._calculate_cooperation_rate(history, round_num)
        if cooperation_rate < self.threshold_low:
            return Action.D
        elif cooperation_rate >= self.threshold_high:
            return Action.D
        else:
            rand_val = random.random()
            if rand_val < 0.1 * cooperation_rate:
                return Action.C
            else:
                return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate the historical cooperation rate across all players up to (but not including)
        the current round.

        cooperation_rate = (total cooperators across all players in rounds 0 to round_num-1)
                          / (n  round_num)
        """
        if round_num <= 0:
            return 0.0
        past_opponent_actions = history.opponent_actions[:round_num, :]
        total_opponent_cooperations = np.sum(past_opponent_actions)
        past_own_actions = history.my_actions[:round_num]
        total_own_cooperations = np.sum(past_own_actions)
        total_cooperators = total_opponent_cooperations + total_own_cooperations
        total_slots = self.n * round_num
        cooperation_rate = total_cooperators / total_slots if total_slots > 0 else 0.0
        return cooperation_rate

class Strategy_EXPLOITATIVE_38(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Exploitation

    Maximizes personal payoff by exploiting cooperative tendencies in opponents
    while maintaining a defensive posture. Uses defection as the primary strategy
    with minimal strategic cooperation to appear unpredictable and harvest benefits
    from high-cooperation environments.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.exploitation_threshold = (self.k - 1) / (self.n - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        remaining_rounds = self.r - round_number
        if round_number == 0:
            return Action.D
        if remaining_rounds <= 1:
            return Action.D
        observed_cooperation_rate = self._compute_cooperation_rate(history)
        if observed_cooperation_rate > self.exploitation_threshold:
            signal_probability = 0.1 * (remaining_rounds / self.r)
            if random.random() < signal_probability:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _compute_cooperation_rate(self, history: PlayerHistory) -> float:
        """
        Compute the average cooperation rate of opponents across all observed rounds.

        Returns: float between 0 and 1 representing proportion of cooperative actions
        """
        if history.opponent_actions.size == 0:
            return 0.0
        total_cooperative_actions = np.sum(history.opponent_actions)
        total_possible_actions = history.opponent_actions.size
        cooperation_rate = total_cooperative_actions / total_possible_actions
        return cooperation_rate

class Strategy_EXPLOITATIVE_39(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Maximizes personal payoff by defaulting to defection while selectively
    parasitizing cooperative clusters when cooperation likelihood exceeds 40%.
    Uses exponential decay weighting of recent history to predict cooperation trends.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.decay_factor = 0.7
        self.cooperation_threshold = 0.4

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        n_rounds = self.game_description.n_rounds
        n_players = self.game_description.n_players
        if round_number == n_rounds - 1:
            return Action.D
        if round_number == n_rounds - 2:
            return Action.D
        if round_number == 0:
            return Action.D
        cooperation_likelihood = self._calculate_cooperation_likelihood(history, n_players)
        if cooperation_likelihood > self.cooperation_threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_likelihood(self, history: PlayerHistory, n_players: int) -> float:
        """
        Calculate cooperation likelihood L based on exponentially weighted recent history.

        L = (cooperators_last_round / n)  decay^1 +
            (cooperators_last_2_rounds / n)  decay^2 +
            (cooperators_last_3_rounds / n)  decay^3
        """
        if history is None or len(history.opponent_actions) == 0:
            return 0.0
        likelihood = 0.0
        num_past_rounds = len(history.opponent_actions)
        for lookback in range(1, 4):
            if num_past_rounds < lookback:
                break
            round_index = num_past_rounds - lookback
            cooperators_in_round = np.sum(history.opponent_actions[round_index, :])
            weight = self.decay_factor ** lookback
            likelihood += cooperators_in_round / n_players * weight
        return likelihood

class Strategy_EXPLOITATIVE_40(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Exploits the public goods game asymmetry by free-riding on cooperators' contributions
    while avoiding cooperation costs. Uses opponent classification based on cooperation rates
    to determine when exploitation is profitable.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.n_rounds - 1:
            return Action.D
        opponent_coop_rates = self._calculate_opponent_coop_rates(history, round_num)
        reliable_cooperators = sum((1 for rate in opponent_coop_rates if rate >= 0.75))
        conditional_cooperators = sum((1 for rate in opponent_coop_rates if 0.25 <= rate < 0.75))
        estimated_cooperators = reliable_cooperators + conditional_cooperators * 0.5
        min_cooperators_for_value = math.ceil(self.k)
        if reliable_cooperators >= min_cooperators_for_value:
            return Action.D
        if estimated_cooperators < self.k:
            return Action.D
        my_recent_actions = history.my_actions[:round_num]
        my_defection_rate = 1.0 - np.mean(my_recent_actions) if len(my_recent_actions) > 0 else 0.0
        if my_defection_rate > 0.7:
            return Action.D
        rounds_remaining = self.n_rounds - round_num
        if rounds_remaining <= 2:
            return Action.D
        if estimated_cooperators >= math.ceil(self.k):
            coop_payoff = self.k / self.n_players * estimated_cooperators
            defection_payoff = 1.0 + self.k / self.n_players * (estimated_cooperators - 1.0)
            if coop_payoff > defection_payoff:
                return Action.C
        return Action.D

    def _calculate_opponent_coop_rates(self, history: PlayerHistory, round_num: int) -> list:
        """
        Calculate cooperation rate for each opponent based on previous rounds.
        Returns list of cooperation rates (0.0 to 1.0) for each opponent.
        """
        coop_rates = []
        if round_num == 0:
            return [0.0] * (self.n_players - 1)
        previous_rounds = round_num
        opponent_actions = history.opponent_actions[:round_num, :]
        for opponent_idx in range(self.n_players - 1):
            cooperations = np.sum(opponent_actions[:, opponent_idx])
            coop_rate = cooperations / previous_rounds if previous_rounds > 0 else 0.0
            coop_rates.append(coop_rate)
        return coop_rates

class Strategy_EXPLOITATIVE_41(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Opportunistic Exploitation

    Core philosophy: Maximize personal payoff by exploiting cooperation when present
    and avoiding the sucker's payoff through consistent defection.

    Decision rules:
    - Rounds 0-2 (Initial): DEFECT to establish baseline and gain immediate payoff
    - Rounds 3 to r-2 (Mid-game): DEFECT based on observed cooperation rate
    - Rounds r-1 to r-1 (Final rounds): DEFECT with no reputational cost

    This strategy always defects, exploiting any cooperative tendencies in the population.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number <= 2:
            return Action.D
        if round_number >= self.n_rounds - 1:
            return Action.D
        if history is not None and len(history.opponent_actions) >= 3:
            early_rounds_cooperators = 0
            for round_idx in range(min(3, len(history.opponent_actions))):
                cooperators_in_round = np.sum(history.opponent_actions[round_idx, :])
                early_rounds_cooperators += cooperators_in_round
            total_opportunities = 3 * self.n_players
            cooperation_rate = early_rounds_cooperators / total_opportunities if total_opportunities > 0 else 0
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_42(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core approach: Always defect to free-ride on any cooperation while avoiding
    the cost of contributing. Defection strictly dominates cooperation in this game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        if round_number == 0:
            return Action.D
        if round_number == r - 1:
            return Action.D
        my_actions = history.my_actions[:round_number]
        opponent_actions = history.opponent_actions[:round_number, :]
        total_cooperations = int(np.sum(opponent_actions))
        total_possible = round_number * n
        if total_possible > 0:
            cooperation_rate = total_cooperations / total_possible
        else:
            cooperation_rate = 0.0
        payoff_from_others = k * cooperation_rate
        progress_ratio = round_number / r
        if progress_ratio > 0.66:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_43(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Exploitation

    Core philosophy: Defection is the dominant strategy in each round.
    This strategy identifies cooperators and exploits them by defecting,
    while escalating exploitation intensity in later rounds when retaliation
    becomes less costly.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = float(sum(history.opponent_actions[round_number - 1, :]))
        cooperation_rate_others = cooperators_last_round / (self.n_players - 1)
        dynamic_threshold = 0.1 + 0.8 * (self.n_rounds - round_number) / self.n_rounds
        return Action.D

class Strategy_EXPLOITATIVE_44(BaseStrategy):
    """
    Exploitative Adaptive Defection with Selective Parasitism.

    Always defects, adapting threshold schedules based on observed cooperation rates.
    Exploits the asymmetry where defectors capture private endowment while profiting
    from others' contributions to the public good.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[round_num - 1, :]))
        cooperation_rate = cooperators_last_round / self.n
        if cooperation_rate == 0:
            return Action.D
        if round_num <= 3:
            base_threshold = 0.4
        elif round_num < self.r - 1:
            base_threshold = 0.3
        else:
            base_threshold = 0.2
        if self.n <= 3:
            threshold = min(0.5, base_threshold * 1.3)
        else:
            threshold = base_threshold
        return Action.D

class Strategy_EXPLOITATIVE_45(BaseStrategy):
    """
    Rational Defection with Adaptive Monitoring

    Exploits the fundamental asymmetry of the public goods game by always defecting.
    Defection is the strictly dominant strategy: it maximizes individual payoff regardless
    of others' actions. Monitors cooperation rates for situational awareness but maintains
    unconditional defection as the core action.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        cooperators_per_round = np.sum(history.opponent_actions, axis=1)
        total_cooperators_observed = np.sum(cooperators_per_round)
        total_observations = (self.game_description.n_players - 1) * state.round_number
        if total_observations > 0:
            coop_rate = total_cooperators_observed / total_observations
        else:
            coop_rate = 0.0
        is_final_round = state.round_number == self.game_description.n_rounds - 1
        return Action.D

class Strategy_EXPLOITATIVE_46(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism - Exploitative Strategy

    This strategy maximizes individual payoff through consistent defection,
    exploiting any cooperators in the game while avoiding losses from cooperation.

    Core principle: Defection strictly dominates cooperation when k < n (given constraint),
    so this strategy always defects to extract maximum value.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        cooperators_prev = int(sum(history.opponent_actions[-1, :]))
        if cooperators_prev >= (self.game_description.n_players - 1) * 0.5:
            return Action.D
        elif cooperators_prev > 0:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_47(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Free-Riding with Conditional Retaliation

    Always defects to maximize personal payoff by exploiting cooperators while
    avoiding contribution costs. Defection is the dominant strategy across all
    rounds regardless of opponent behavior.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number < self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_48(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core philosophy: Maximize personal payoff by exploiting cooperators while avoiding
    mutual defection traps. Always defect to extract value from cooperators without
    incurring cooperation costs.

    Decision rules:
    - Round 0 (first round): DEFECT
    - Rounds 1 to r-2 (intermediate rounds): DEFECT (unconditionally exploit cooperators)
    - Round r-1 (final round): DEFECT (no future to constrain behavior)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_49(BaseStrategy):
    """
    Adaptive Opportunistic Extraction Strategy for N-Player Public Goods Game.

    This strategy exploits cooperative opponents by always defecting, except when
    analyzing whether cooperation could theoretically be worthwhile. However, the
    threshold-based decision simplifies to a dominant strategy of always defecting.

    Core logic:
    - Round 1: Defect (establish baseline, avoid cost)
    - Rounds 2 to r-1: Defect if cooperation rate > threshold, else defect
      (which simplifies to always defect)
    - Final round: Defect (no shadow of future)

    Threshold = (k-1)/k represents when cooperation becomes non-worthwhile.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.k - 1) / self.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        prev_round_index = current_round - 1
        prev_round_cooperators = sum(history.opponent_actions[prev_round_index, :])
        cooperation_rate = prev_round_cooperators / self.n
        if cooperation_rate > self.threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_50(BaseStrategy):
    """
    Adaptive Predation Strategy for N-Player Public Goods Game

    A fully exploitative strategy that defects unconditionally throughout the game.
    Core mechanisms:
    - Round 1: Defect to gather intelligence on cooperators
    - Rounds 2 to r-1: Defect to harvest public goods funded by others
    - Final round: Defect to extract maximum value with no punishment risk

    Mathematical basis: Defection always yields higher payoff than cooperation
    when k < n (which is guaranteed by game specification).
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        """
        Decision rule for adaptive predation strategy.

        Always defects because:
        1. Defect advantage = 1 - (k/n) > 0 (since k < n by specification)
        2. No cooperative phase offers higher payoff
        3. Reputation building is never optimal in finite repeated game
        """
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        if history is not None:
            last_round_idx = current_round - 1
            opponents_cooperated_last_round = int(sum(history.opponent_actions[last_round_idx, :]))
            cooperation_ratio = opponents_cooperated_last_round / (self.n_players - 1)
            if cooperation_ratio > 0.25:
                return Action.D
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_51(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Exploitation

    Maximizes personal payoff by exploiting cooperative players while minimizing
    losses to defectors. Uses conditional defection with occasional false cooperation
    to sustain exploitable behavior in opponents.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.D
        if round_t == self.n_rounds - 1:
            return Action.D
        last_round_cooperators = int(sum(history.opponent_actions[round_t - 1, :]))
        if last_round_cooperators == 0:
            return Action.D
        if last_round_cooperators <= self.n_players / 2:
            if round_t % 4 == 0:
                return Action.C
            else:
                return Action.D
        if last_round_cooperators > 0.75 * self.n_players:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_52(BaseStrategy):
    """
    Adaptive Defection with Conditional Exploitation.

    A ruthlessly exploitative strategy that:
    1. Defects by default to free-ride on cooperators
    2. Identifies and targets exploitable opponents (cooperation_tendency > 0.3)
    3. Intensifies exploitation in the final third of rounds
    4. Adapts based on observed cooperation patterns while maintaining defection as baseline
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_history = {}
        self.total_rounds_observed = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        late_game_threshold = 2 * self.game_description.n_rounds / 3
        is_late_game = state.round_number > late_game_threshold
        prev_round_idx = state.round_number - 1
        prev_round_cooperators = int(sum(history.opponent_actions[prev_round_idx, :]))
        if prev_round_cooperators > 0:
            return Action.D
        cooperation_rate = self._calculate_cooperation_rate(history, state.round_number)
        if cooperation_rate > 0.3:
            return Action.D
        if is_late_game:
            return Action.D
        return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate overall cooperation rate across all observed opponents and rounds.

        Returns fraction of cooperative actions observed divided by total possible actions.
        """
        if current_round == 0:
            return 0.0
        total_cooperative_actions = 0
        for round_idx in range(current_round):
            total_cooperative_actions += int(sum(history.opponent_actions[round_idx, :]))
        n_opponents = self.game_description.n_players - 1
        total_possible_actions = current_round * n_opponents
        if total_possible_actions == 0:
            return 0.0
        cooperation_rate = total_cooperative_actions / total_possible_actions
        return cooperation_rate

class Strategy_EXPLOITATIVE_53(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Core approach: Defect by default to extract maximum value. Identify and parasitize
    reliable cooperators while minimizing losses against defectors. Classify opponents
    into tiers (Exploitable, Reactive, Defector) based on historical cooperation rates
    and maintain aggressive defection throughout.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.opponent_cooperation_counts = np.zeros(self.n_players - 1)
        self.opponent_tiers = {}
        self.threshold_exploitable = 0.7
        self.threshold_reactive = 0.2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        self._update_opponent_classifications(history, current_round)
        return Action.D

    def _update_opponent_classifications(self, history: PlayerHistory, current_round: int) -> None:
        """
        Update opponent tier classifications based on accumulated history.
        Classifications determine exploitation strategy (though we always defect).
        """
        rounds_completed = current_round
        for opponent_idx in range(self.n_players - 1):
            coop_count = np.sum(history.opponent_actions[:rounds_completed, opponent_idx])
            self.opponent_cooperation_counts[opponent_idx] = coop_count
            if rounds_completed > 0:
                cooperation_rate = coop_count / rounds_completed
            else:
                cooperation_rate = 0.0
            if cooperation_rate >= self.threshold_exploitable:
                self.opponent_tiers[opponent_idx] = 'Exploitable'
            elif cooperation_rate >= self.threshold_reactive:
                self.opponent_tiers[opponent_idx] = 'Reactive'
            else:
                self.opponent_tiers[opponent_idx] = 'Defector'
        total_opponent_actions = np.sum(history.opponent_actions[:rounds_completed, :])
        total_possible_cooperations = rounds_completed * (self.n_players - 1)
        if total_possible_cooperations > 0:
            population_cooperation_rate = total_opponent_actions / total_possible_cooperations
            if population_cooperation_rate < 0.5:
                self.threshold_exploitable = max(0.5, self.threshold_exploitable - 0.05)

class Strategy_EXPLOITATIVE_54(BaseStrategy):
    """
    Exploitative Adaptive Defection Strategy

    Maximizes personal payoff by systematically defecting to exploit cooperative
    tendencies in others. Based on Nash equilibrium analysis where defection
    dominates cooperation since k < n implies (k/n) < 1.

    Core principle: ALWAYS DEFECT
    - Round 0: Defect to establish non-exploitable reputation
    - Last round: Defect for final exploitation with no consequences
    - Middle rounds: Defect regardless of observed cooperation rate
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_55(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    Core principle: Defection is the dominant strategy in public goods games.
    Always defect to guarantee a baseline payoff of 1 per round, while exploiting
    any cooperators in the population through the shared pool mechanism.

    Decision logic:
    - Round 0 (first round): DEFECT (information gathering, establish baseline)
    - Round r-1 (final round): DEFECT (no future punishment possible)
    - Middle rounds: DEFECT (weakly dominant strategy regardless of cooperation rate)

    This strategy guarantees non-negative profit from every opponent type while
    extracting maximum value from exploitable cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_56(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Exploits the public goods game by defecting when individually rational,
    cooperating selectively to parasitize high-cooperation environments,
    and defecting unconditionally in the final round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        coop_count = int(np.sum(history.opponent_actions))
        total_actions = round_num * self.n
        coop_rate = coop_count / total_actions if total_actions > 0 else 0.5
        predicted_coop = min(self.n, max(1, math.ceil(coop_rate * self.n) + 1))
        defect_payoff = 1 + self.k / self.n * predicted_coop
        coop_payoff = self.k / self.n * (predicted_coop + 1)
        if defect_payoff > coop_payoff:
            my_defections = int(np.sum(~history.my_actions))
            my_defection_rate = my_defections / round_num if round_num > 0 else 0
            if coop_rate >= 0.6 and my_defection_rate < 0.7:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_57(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core principle: Always defect to maximize payoff by exploiting others' cooperation.
    Defection is mathematically dominant in the public goods game when k < n.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_58(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    Exploits asymmetry between cooperation and defection payoffs by:
    1. Defecting as default action (>80% of rounds)
    2. Strategic occasional cooperation to maintain exploitable cooperators
    3. Farming strategy: re-seed cooperation when it collapses
    4. Ruthless endgame: defect in final rounds
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            self.consecutive_defections = 0
            return Action.D
        if current_round >= r - 2:
            return Action.D
        prev_round_idx = current_round - 1
        opponent_actions_prev = history.opponent_actions[prev_round_idx, :]
        coop_count = int(np.sum(opponent_actions_prev))
        coop_rate = coop_count / n
        threshold = k / n
        if coop_rate > threshold:
            self.consecutive_defections += 1
            return Action.D
        elif coop_rate < threshold:
            if coop_count >= 2 and self.consecutive_defections >= 2:
                self.consecutive_defections = 0
                return Action.C
            else:
                self.consecutive_defections += 1
                return Action.D
        else:
            self.consecutive_defections += 1
            return Action.D

class Strategy_EXPLOITATIVE_59(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core philosophy: Always defect to avoid paying the cooperation cost,
    while maximizing free-riding on others' contributions. The strategy
    exploits the asymmetry between defectors and cooperators by never
    contributing to the public good.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.k - 1) / self.k
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.r - 1:
            return Action.D
        if history is not None and len(history.opponent_actions) > 0:
            cooperators_last_round = sum(history.opponent_actions[-1, :])
            cooperation_rate = cooperators_last_round / self.n
            self.cooperation_history.append(cooperation_rate)
        return Action.D

class Strategy_EXPLOITATIVE_60(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Strategic Compliance

    This strategy exploits cooperative players by defecting by default, with selective
    cooperation triggered only when the observed cooperation rate exceeds a profitability
    threshold, or during early game phases to identify and manipulate cooperators.
    Terminal rounds always defect to maximize extraction.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.k - 1) / self.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        if t == 0:
            return Action.D
        if t == self.r - 1 or t == self.r - 2:
            return Action.D
        endgame_start = math.floor(3 * self.r / 4)
        if t > endgame_start:
            return Action.D
        early_window = math.floor(self.r / 3)
        if t <= early_window:
            any_opponent_cooperated = np.any(history.opponent_actions[t - 1, :])
            if any_opponent_cooperated:
                return Action.C
            else:
                return Action.D
        prev_round_cooperators = np.sum(history.opponent_actions[t - 1, :])
        cooperation_rate = prev_round_cooperators / self.n
        if cooperation_rate >= self.threshold:
            return Action.C
        reliable_cooperator_found = False
        if t >= 2:
            rounds_available = t
            for opponent_idx in range(self.n - 1):
                opponent_cooperations = np.sum(history.opponent_actions[:t, opponent_idx])
                cooperation_percentage = opponent_cooperations / rounds_available
                if cooperation_percentage >= 0.75:
                    reliable_cooperator_found = True
                    break
        if reliable_cooperator_found:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_61(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    A pure defection strategy that exploits cooperative players in a public goods game.
    Always defects to maximize personal payoff by harvesting any cooperative surplus
    while maintaining a payoff floor of 1 regardless of opponent behavior.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_practical = max((game_description.n_players - game_description.k) / game_description.k, 0.3)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        if state.round_number == 0:
            return Action.D
        if state.round_number == r - 1:
            return Action.D
        previous_round_idx = state.round_number - 1
        cooperators_last_round = sum(history.opponent_actions[previous_round_idx, :])
        coop_rate = cooperators_last_round / n
        return Action.D

class Strategy_EXPLOITATIVE_62(BaseStrategy):
    """
    Adaptive Predation Strategy: Exploits cooperators while avoiding losses to defectors.

    Round 1: Cooperate to probe opponent types
    Rounds 2 to r-1: Defect to exploit any cooperators identified
    Round r: Defect for final extraction with no reputational concerns
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == r - 1:
            return Action.D
        has_high_cooperators = False
        for opponent_idx in range(n - 1):
            opponent_cooperations = int(np.sum(history.opponent_actions[:current_round, opponent_idx]))
            rounds_played = current_round
            cooperativeness_score = opponent_cooperations / rounds_played if rounds_played > 0 else 0
            if cooperativeness_score > 0.5:
                has_high_cooperators = True
                break
        return Action.D

class Strategy_EXPLOITATIVE_63(BaseStrategy):
    """
    Adaptive Parasitic Harvesting (APH): An exploitative strategy that defects by default,
    selectively cooperates when opponent cooperation density exceeds the break-even threshold,
    and always defects in the final round to maximize terminal payoff.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = game_description.k / game_description.n_players
        self.epsilon = 0.05
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        n_rounds = self.game_description.n_rounds
        n_players = self.game_description.n_players
        if current_round == 0:
            return Action.D
        if current_round == n_rounds - 1:
            return Action.D
        if history is not None:
            recent_rounds = min(3, current_round)
            recent_cooperation_sum = 0
            total_observations = 0
            for round_idx in range(current_round - recent_rounds, current_round):
                if round_idx >= 0:
                    cooperators_in_round = np.sum(history.opponent_actions[round_idx, :])
                    recent_cooperation_sum += cooperators_in_round
                    total_observations += n_players - 1
            if total_observations > 0:
                recent_cooperation_rate = recent_cooperation_sum / total_observations
            else:
                recent_cooperation_rate = 0.0
            cooperation_collapsed = False
            if current_round >= 2:
                collapse_check_sum = 0
                for round_idx in range(current_round - 2, current_round):
                    if round_idx >= 0:
                        cooperators = np.sum(history.opponent_actions[round_idx, :])
                        collapse_check_sum += cooperators
                if collapse_check_sum < 2 * self.threshold * (n_players - 1):
                    cooperation_collapsed = True
            if cooperation_collapsed:
                return Action.D
            if recent_cooperation_rate > self.threshold:
                target_cooperation_rate = max(0.0, recent_cooperation_rate - self.epsilon)
                if random.random() < target_cooperation_rate:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_64(BaseStrategy):
    """
    Adaptive Defection with Conditional Parasitism

    Maximizes individual payoff by exploiting cooperators while minimizing losses.
    Defects by default, only cooperates when the observed cooperation rate exceeds
    the break-even threshold (k-1)/n, except in round 1 and final round where
    unconditional defection occurs.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = (game_description.k - 1) / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        total_cooperators = int(np.sum(history.opponent_actions[:current_round, :]))
        total_player_rounds = n * current_round
        observed_coop_rate = total_cooperators / total_player_rounds
        if observed_coop_rate > self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_65(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core principle: Exploit the asymmetry in payoff structure by always defecting
    while free-riding on others' contributions. Uses adaptive thresholds across
    game phases to ensure persistent defection regardless of cooperation rates.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.n_rounds - 1:
            return Action.D
        total_rounds_completed = state.round_number
        total_cooperators = np.sum(history.opponent_actions[:state.round_number, :])
        cooperation_rate = total_cooperators / (total_rounds_completed * self.n_players)
        progress_ratio = state.round_number / self.n_rounds
        if progress_ratio <= 1.0 / 3.0:
            threshold = 0.4
        elif progress_ratio <= 2.0 / 3.0:
            threshold = 0.3
        else:
            threshold = 0.2
        return Action.D

class Strategy_EXPLOITATIVE_66(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation (ADCC)

    Exploits the public goods game by defaulting to defection, conditionally cooperating
    only when the expected return exceeds the defection payoff, and adapting to opponent
    cooperation rates to extract maximum surplus.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.rolling_coop_rate = 0.5
        self.alpha = 0.6

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        if current_round == 1:
            cooperators_round_0 = sum(history.opponent_actions[0, :])
            predicted_coop_rate = cooperators_round_0 / n
        else:
            total_cooperators = sum(history.opponent_actions[:current_round, :].flatten())
            total_opponent_actions = current_round * n
            empirical_coop_rate = total_cooperators / total_opponent_actions if total_opponent_actions > 0 else 0.5
            self.rolling_coop_rate = self.alpha * self.rolling_coop_rate + (1 - self.alpha) * empirical_coop_rate
            predicted_coop_rate = self.rolling_coop_rate
        threshold = (n - k) / n
        base_decision = Action.C if predicted_coop_rate >= threshold else Action.D
        rounds_remaining = r - current_round
        if predicted_coop_rate > 0.7 and rounds_remaining > 2:
            return Action.D
        if predicted_coop_rate < 0.2 and rounds_remaining > 1:
            my_last_payoff = history.my_payoffs[current_round - 1]
            if my_last_payoff == 1.0:
                return Action.D
        return base_decision

class Strategy_EXPLOITATIVE_67(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core approach: Defect unconditionally in rounds 1-2 to identify cooperators,
    then exploit reliable cooperators (those who cooperated in both rounds 1-2)
    by defecting throughout the exploitation phase. Continue defection in endgame
    rounds, capitalizing on the lack of future punishment threats.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.bucket_a = set()
        self.cooperation_history = {}

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        n_rounds = self.game_description.n_rounds
        n_players = self.game_description.n_players
        if current_round == 0:
            for i in range(n_players - 1):
                self.cooperation_history[i] = 0
            return Action.D
        if current_round == 1:
            for opponent_idx in range(n_players - 1):
                if history.opponent_actions[0, opponent_idx]:
                    self.cooperation_history[opponent_idx] += 1
            return Action.D
        if current_round == 2:
            for opponent_idx in range(n_players - 1):
                if history.opponent_actions[1, opponent_idx]:
                    self.cooperation_history[opponent_idx] += 1
                if self.cooperation_history[opponent_idx] == 2:
                    self.bucket_a.add(opponent_idx)
            return Action.D
        if 3 <= current_round < n_rounds - 1:
            return Action.D
        if current_round == n_rounds - 2:
            cooperators_last_round = sum(history.opponent_actions[current_round - 1, :])
            cooperation_rate = cooperators_last_round / n_players
            return Action.D
        if current_round == n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_68(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    Core philosophy: Exploit the asymmetry between defectors and cooperators by:
    - Always defecting in round 1 (baseline exploitation)
    - Always defecting in the final round (no future consequences)
    - Defecting in middle rounds regardless of cooperation rate (robust exploitation)

    This maximizes individual payoff by free-riding on cooperators when they appear
    and avoiding costly cooperation that cannot be reciprocated in final rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = 0.4

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        cooperators_last_round = sum(history.opponent_actions[state.round_number - 1, :])
        cooperation_rate = cooperators_last_round / self.game_description.n_players
        if cooperation_rate >= self.threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_69(BaseStrategy):
    """
    Exploitative strategy using adaptive defection with conditional parasitism.

    Exploits the public goods game asymmetry by:
    - Always defecting in round 1 and the final round
    - In middle rounds, conditionally cooperating only when cooperation rates are high enough
    - Using adaptive thresholds based on game parameters (n, k)
    - Tracking consecutive low-cooperation rounds to intensify defection streaks
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.low_coop_streak = 0
        self.last_coop_rate = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        previous_round_idx = current_round - 1
        cooperators_prev = int(sum(history.opponent_actions[previous_round_idx, :]))
        coop_rate = cooperators_prev / self.n
        threshold_high = min(0.6, (self.k - 0.1) / self.k)
        threshold_low = max(0.2, self.k / (2.0 * self.n))
        if coop_rate <= threshold_low:
            self.low_coop_streak += 1
        else:
            self.low_coop_streak = 0
        if self.low_coop_streak >= 3:
            return Action.D
        cooperation_jump = coop_rate - self.last_coop_rate
        if cooperation_jump > 0.2 and coop_rate > threshold_high:
            self.last_coop_rate = coop_rate
            return Action.C
        self.last_coop_rate = coop_rate
        if coop_rate >= threshold_high:
            return Action.C
        elif coop_rate > threshold_low:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_70(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Free-Riding

    Always defects to maximize payoff by free-riding on others' contributions.
    Observes cooperation levels via adaptive threshold mechanism, but defaults
    to defection in all rounds (first, middle, and final).
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = game_description.k / game_description.n_players + 0.05

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == r - 1:
            return Action.D
        previous_round_cooperators = sum(history.opponent_actions[round_number - 1, :])
        cooperation_rate = previous_round_cooperators / n
        return Action.D

class Strategy_EXPLOITATIVE_71(BaseStrategy):
    """
    Exploitative strategy using adaptive defection with conditional parasitism.
    Tracks cooperator density and exploits high-cooperation environments while
    maintaining disciplined defection in early and final rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        t = state.round_number
        if t == 0:
            return Action.D
        if t == r - 1:
            return Action.D
        if history is not None:
            for round_idx in range(len(history.opponent_actions)):
                if round_idx >= len(self.cooperation_history):
                    cooperators_count = sum(history.opponent_actions[round_idx, :])
                    c_ratio = cooperators_count / n
                    self.cooperation_history.append(c_ratio)
        if len(self.cooperation_history) == 0:
            return Action.D
        c_ratio_avg = np.mean(self.cooperation_history)
        threshold = 1.0 / k
        early_round_limit = math.ceil(r / 3)
        if t < early_round_limit:
            if c_ratio_avg > threshold:
                payoff_if_C = k / n * (c_ratio_avg * n)
                if payoff_if_C > 1.0:
                    return Action.C
            return Action.D
        adjusted_threshold = threshold
        if k > n - 0.5:
            adjusted_threshold = 0.7
        adjusted_threshold += 1.0 / n
        if c_ratio_avg > adjusted_threshold:
            payoff_if_C = k / n * (c_ratio_avg * n)
            if payoff_if_C > 1.0:
                late_round_start = math.ceil(2 * r / 3)
                if t >= late_round_start:
                    if t == r - 2:
                        return Action.D
                    if c_ratio_avg > 0.6:
                        return Action.C
                    else:
                        return Action.D
                else:
                    return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_72(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism Strategy.

    This exploitative strategy maximizes payoff by:
    1. Always defecting in round 1 to gather information
    2. Defecting in middle rounds based on cooperation rate vs threshold k/n
    3. Always defecting in the final round (no future consequences)

    The strategy exploits the asymmetry that defection yields higher payoff
    when others cooperate, while cooperation is irrational when few others cooperate.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = np.sum(history.opponent_actions[current_round - 1, :])
        cooperation_rate = cooperators_last_round / self.n_players
        return Action.D

class Strategy_EXPLOITATIVE_73(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation Probing

    Maximizes personal payoff by exploiting the public goods game asymmetry:
    - Round 1: Defect to probe opponent cooperation rates
    - Rounds 2 to r-2: Mostly defect, with rare adaptive cooperation if others cooperate sufficiently
    - Final rounds: Always defect (no future consequences)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_rate_round1 = 0.0
        self.round1_observed = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == 1 and (not self.round1_observed):
            total_cooperators_round1 = int(np.sum(history.opponent_actions[0, :]))
            self.cooperation_rate_round1 = total_cooperators_round1 / (n - 1)
            self.round1_observed = True
        if current_round >= r - 2:
            return Action.D
        threshold = k / n
        if self.cooperation_rate_round1 > threshold:
            probe_probability = min(0.2, self.cooperation_rate_round1 * 0.5)
            random_value = random.random()
            if random_value < probe_probability:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_74(BaseStrategy):
    """
    Adaptive Defection with Opportunistic Cooperation strategy for N-Player Public Goods Game.

    Core approach: Defect by default, cooperate only when expected public good payoff exceeds
    the defection baseline payoff of 1. Exploits early cooperators, selectively cooperates in
    middle game when beneficial, and pure defects in endgame.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.base_threshold = 1.0
        self._adjust_threshold_for_parameters()

    def _adjust_threshold_for_parameters(self):
        """Adjust cooperation threshold based on k and n values."""
        if self.k <= 1.5:
            self.base_threshold = 1.2
        elif self.k >= self.n - 0.5:
            self.base_threshold = 0.9
        else:
            self.base_threshold = 1.0
        if self.n > 20:
            self.base_threshold = 1.5

    def _estimate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Estimate the cooperation rate from historical data using exponential moving average.
        """
        if current_round <= 0:
            return 0.5
        total_contributions = int(np.sum(history.opponent_actions[:current_round, :]))
        total_possible = self.n * current_round
        coop_rate = total_contributions / total_possible if total_possible > 0 else 0.5
        if current_round <= 3:
            return 0.5
        else:
            weights = np.array([0.7 ** (current_round - 1 - i) for i in range(current_round)])
            weighted_rates = []
            for round_idx in range(current_round):
                round_contribs = int(np.sum(history.opponent_actions[round_idx, :]))
                round_rate = round_contribs / self.n if self.n > 0 else 0
                weighted_rates.append(round_rate)
            weighted_rates = np.array(weighted_rates)
            ema = np.sum(weights * weighted_rates) / np.sum(weights)
            return ema

    def _get_expected_cooperators(self, history: PlayerHistory, current_round: int) -> float:
        """Calculate expected number of cooperators in current round."""
        if current_round <= 3:
            assumed_coop_rate = 0.5
        else:
            assumed_coop_rate = self._estimate_cooperation_rate(history, current_round)
        expected_cooperators = self.n * assumed_coop_rate
        return expected_cooperators

    def _should_cooperate(self, history: PlayerHistory, current_round: int) -> bool:
        """
        Determine if cooperation is beneficial based on expected public good payoff.
        """
        expected_cooperators = self._get_expected_cooperators(history, current_round)
        expected_public_payoff = expected_cooperators * (self.k / self.n)
        return expected_public_payoff > self.base_threshold

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round <= 2:
            return Action.D
        if current_round >= self.r - 2:
            return Action.D
        if history is not None and self._should_cooperate(history, current_round):
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_75(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Contribution

    Maximizes personal payoff by exploiting the asymmetry in the public goods game.
    Primarily defects while identifying and extracting value from cooperators.
    Adapts behavior based on game phase and observed cooperation patterns.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.k_per_capita = self.k / self.n_players
        self.high_cooperation_threshold = 0.6
        self.low_cooperation_threshold = 0.2
        self.p_test = 0.3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        early_game_rounds = max(3, math.ceil(0.2 * self.n_rounds))
        if round_num < early_game_rounds:
            return Action.D
        end_game_threshold = max(2, math.ceil(0.05 * self.n_rounds))
        if round_num >= self.n_rounds - end_game_threshold:
            return Action.D
        if history is not None and len(history.opponent_actions) > 0:
            total_opponent_actions = history.opponent_actions[:, :]
            total_cooperators = np.sum(total_opponent_actions, axis=1)
            lookback_rounds = min(3, len(total_cooperators))
            recent_cooperators = total_cooperators[-lookback_rounds:]
            avg_cooperators = np.mean(recent_cooperators)
            cooperation_rate = avg_cooperators / (self.n_players - 1)
            if cooperation_rate == 0:
                return Action.D
            if cooperation_rate > self.high_cooperation_threshold:
                return Action.D
            if cooperation_rate < self.low_cooperation_threshold:
                return Action.D
            rounds_remaining = self.n_rounds - round_num
            if rounds_remaining > 5:
                if random.random() < self.p_test:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_76(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core approach: Always defect to maximize personal payoff by exploiting
    cooperative tendencies in others. The strategy recognizes that defection
    yields higher individual returns when others cooperate, so it defects
    relentlessly across all rounds.

    Mathematical justification: For any cooperation rate, defection payoff
    (1 + (k/n)  total_cooperators) > cooperation payoff ((k/n)  (total_cooperators + 1))
    since 1 > k/n by problem constraints.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number < self.r - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_77(BaseStrategy):
    """
    Adaptive Defection with Selective Exploitation Strategy

    This strategy maximizes payoff by exploiting cooperative players while avoiding
    mutual defection traps. It operates in three modes:
    - Mode 1 (Rounds 0-1): Initial exploitation via defection
    - Mode 2 (Rounds 2 to r-2): Adaptive exploitation based on opponent cooperation rates
    - Mode 3 (Final round): Endgame defection
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0 or state.round_number == 1:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        n_opponents = self.game_description.n_players - 1
        n_rounds_observed = state.round_number
        consistent_cooperators = 0
        for opponent_idx in range(n_opponents):
            coop_count = np.sum(history.opponent_actions[:state.round_number, opponent_idx])
            coop_rate = coop_count / n_rounds_observed
            if coop_rate >= 0.5:
                consistent_cooperators += 1
        if consistent_cooperators > 0:
            return Action.D
        total_defections = np.sum(history.opponent_actions[:state.round_number, :] == False)
        total_actions = n_opponents * n_rounds_observed
        all_defect_rate = total_defections / total_actions if total_actions > 0 else 0.0
        if all_defect_rate > 0.7:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_78(BaseStrategy):
    """
    Adaptive Predation: An exploitative strategy that probes in round 1,
    free-rides on cooperators when cooperation exceeds a calibrated threshold,
    and defects in the endgame when punishment is impossible.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n_players + 0.15
        self.base_threshold = self.threshold

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        rounds_remaining = self.n_rounds - current_round
        if rounds_remaining <= 2:
            return Action.D
        opponent_actions_last_round = history.opponent_actions[current_round - 1, :]
        cooperators_last_round = np.sum(opponent_actions_last_round)
        observed_coop_rate = cooperators_last_round / self.n_players
        if current_round > self.n_rounds / 2:
            dynamic_threshold = self.base_threshold - 0.05
        else:
            dynamic_threshold = self.base_threshold
        if observed_coop_rate > self.k / self.n_players + 0.2 and rounds_remaining >= 5:
            if current_round % 4 == 0:
                return Action.C
        if observed_coop_rate > dynamic_threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_79(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core approach: Always defect to exploit cooperators while matching the
    Nash equilibrium (mutual defection) against other defectors. Uses a
    threshold-based decision rule in middle rounds to identify and exploit
    cooperative populations.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.k = game_description.k
        self.n_rounds = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
        cooperation_rate = cooperators_last_round / self.n_players
        threshold = (self.n_players - self.k) / self.n_players
        return Action.D

class Strategy_EXPLOITATIVE_80(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core philosophy: Extract maximum value by exploiting cooperative tendencies
    while minimizing personal contribution costs. Defects opportunistically based
    on observed cooperation rates, with adaptive re-seeding of cooperation in
    late-game phases when cooperation becomes scarce.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.exploitation_threshold = 1 - self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        prev_round_opponent_actions = history.opponent_actions[round_num - 1, :]
        coop_count = int(np.sum(prev_round_opponent_actions))
        coop_rate = coop_count / (self.n - 1) if self.n > 1 else 0
        if coop_rate > self.exploitation_threshold:
            return Action.D
        if round_num <= self.r / 2:
            return Action.D
        if coop_count == 0:
            return Action.D
        if coop_rate < 0.15:
            rounds_remaining = self.r - round_num
            if rounds_remaining > 3:
                my_last_action = history.my_actions[round_num - 1]
                my_second_last_action = history.my_actions[round_num - 2] if round_num >= 2 else True
                if not my_last_action and (not my_second_last_action):
                    return Action.C
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_81(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    Maximizes personal payoff by exploiting cooperators while avoiding mutual defection traps.
    - Round 1: Cooperate to probe opponent types
    - Rounds 2 to r-1: Defect against identified cooperators (50% cooperation rate), defect against others
    - Final round: Defect for endgame exploitation
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        rounds_completed = state.round_number
        opponent_actions = history.opponent_actions[:rounds_completed, :]
        cooperations_per_opponent = np.sum(opponent_actions, axis=0)
        cooperation_rates = cooperations_per_opponent / rounds_completed
        threshold = 0.5
        exploitable_cooperators = np.any(cooperation_rates >= threshold)
        return Action.D

class Strategy_EXPLOITATIVE_82(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Always defects to maximize exploitation of cooperators while avoiding losses
    from contributing to the public good. Defection is the dominant strategy
    across all rounds regardless of opponent behavior.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_83(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core philosophy: Maximize individual payoff by exploiting cooperators while avoiding
    mutual defection traps. Defect by default to harvest public goods contributions from
    cooperators without reciprocating.

    Decision rule: DEFECT in all rounds (round 1, rounds 2 to r-1, and final round r).
    This strictly dominates cooperation since k < n, making (k/n) < 1, so the marginal
    benefit of cooperation never exceeds its cost.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_84(BaseStrategy):
    """
    Adaptive Predation Strategy for N-Player Public Goods Game.

    Exploits cooperative players by identifying their patterns and defecting
    when beneficial. Uses historical cooperation rates to classify opponent pools
    and adjust behavior between pure defection and probabilistic matching.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num >= self.n_rounds - 2:
            return Action.D
        cooperation_rate = self._calculate_cooperation_rate(history, round_num)
        hc_threshold = self.k / self.n_players + 0.15
        if cooperation_rate > hc_threshold:
            return Action.D
        elif cooperation_rate >= 0.3:
            defection_prob = 1.0 - cooperation_rate
            if random.random() < defection_prob:
                return Action.D
            else:
                return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate the average cooperation rate of other players in previous rounds.

        cooperation_rate = (total_cooperators_observed) / (n-1) / (rounds_elapsed)
        """
        if round_num == 0:
            return 0.5
        previous_rounds = history.opponent_actions[:round_num, :]
        total_cooperations = np.sum(previous_rounds)
        total_possible = (self.n_players - 1) * round_num
        if total_possible == 0:
            return 0.5
        cooperation_rate = total_cooperations / total_possible
        return cooperation_rate

class Strategy_EXPLOITATIVE_85(BaseStrategy):
    """
    Exploitative Strategy: Always Defect

    This strategy exploits the public goods game by always defecting across all rounds.
    Defection is the dominant strategy because:
    - Defectors keep their full endowment (1) plus share of public goods (k/n  total_cooperators)
    - Cooperators get 0 plus share of public goods (k/n  total_cooperators)
    - Therefore defection strictly dominates cooperation in every round
    - Terminal round subgame perfection forces defection in round r
    - By backward induction, defection is optimal in all rounds
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.opponent_cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_86(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism Strategy.

    Core approach: Always defect to maximize individual payoff, with strategic
    emphasis on exploiting cooperation windows. Defects unconditionally in first
    and last rounds, and uses adaptive thresholding in mid-game to identify when
    to parasitically exploit cooperators.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        if current_round == self.n_rounds - 2:
            any_cooperation = self._any_cooperation_in_history(history)
            if any_cooperation:
                return Action.D
            else:
                return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
        cooperation_rate = cooperators_last_round / self.n_players
        rounds_remaining = self.n_rounds - current_round
        aggression_factor = 1.0 - rounds_remaining / self.n_rounds
        dynamic_threshold = 1.0 - 1.0 / self.k + 0.1 * aggression_factor
        if cooperation_rate >= dynamic_threshold:
            return Action.D
        else:
            return Action.D

    def _any_cooperation_in_history(self, history: PlayerHistory) -> bool:
        """Check if any cooperators existed in previous rounds."""
        if history is None or len(history.opponent_actions) == 0:
            return False
        for round_idx in range(len(history.opponent_actions)):
            if sum(history.opponent_actions[round_idx, :]) > 0:
                return True
        return False

class Strategy_EXPLOITATIVE_87(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Exploitation

    Core approach: Unconditional defection to maximize free-riding payoff.
    Monitors cooperation rates but always defects, exploiting any cooperative
    behavior while avoiding the cost of contribution.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold = (self.k - 1) / (self.n - 1) + 0.05

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if history is not None and len(history.opponent_actions) > 0:
            total_observed = history.opponent_actions.size
            total_cooperations = np.sum(history.opponent_actions)
            cooperation_rate = total_cooperations / total_observed if total_observed > 0 else 0.0
        return Action.D

class Strategy_EXPLOITATIVE_88(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Participation

    Maximizes personal payoff by exploiting the asymmetry between defection and cooperation.
    Defects in round 1 and final round, then adapts based on opponent cooperation rates using
    threshold logic to balance exploitation with avoiding mutual defection collapse.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_high = game_description.k / game_description.n_players
        self.threshold_low = 0.2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        last_round_index = state.round_number - 1
        opponent_actions_last_round = history.opponent_actions[last_round_index, :]
        cooperators_last_round = np.sum(opponent_actions_last_round)
        cooperation_rate = cooperators_last_round / (self.game_description.n_players - 1)
        if cooperation_rate > self.threshold_high:
            return Action.D
        if cooperation_rate < self.threshold_low:
            return Action.D
        return Action.C

class Strategy_EXPLOITATIVE_89(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Maximizes individual payoff by exploiting the public goods structure through:
    1. Always defecting after round 1 to parasite on cooperators
    2. Using a threshold-based rule to determine optimal defection
    3. Unconditional defection in the final round

    The strategy implements rational egoism: never contribute, free-ride on others' cooperation,
    and exploit the end-game advantage in the final round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.n - self.k) / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.r - 1:
            return Action.D
        previous_round_idx = state.round_number - 1
        cooperators_in_previous_round = np.sum(history.opponent_actions[previous_round_idx, :])
        cooperation_rate = cooperators_in_previous_round / self.n
        return Action.D

class Strategy_EXPLOITATIVE_90(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    This strategy maximizes individual payoff by always defecting to exploit
    cooperative players while avoiding losses from contributing to a public good.
    It recognizes that defection is the dominant strategy in public goods games
    when k < n, and implements systematic exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        rounds_played = state.round_number
        total_cooperators = np.sum(history.opponent_actions[:rounds_played, :])
        n_players = self.game_description.n_players
        coop_rate = total_cooperators / (n_players * rounds_played)
        threshold = self.game_description.k / n_players
        return Action.D

class Strategy_EXPLOITATIVE_91(BaseStrategy):
    """
    Adaptive Predation Strategy for N-Player Public Goods Game.

    Exploits the dominance of defection by:
    1. EXPLORATION (rounds 0 to ceil(r/3)-1): Defect to identify cooperators
    2. EXPLOITATION (rounds ceil(r/3) to ceil(2r/3)-1): Defect to free-ride on cooperators
    3. ENDGAME (rounds ceil(2r/3) to r-1): Defect with no future consequences

    Core insight: Defection is dominant regardless of opponent cooperation rate.
    Always defect to maximize personal gain through free-riding.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.exploration_end = math.ceil(self.n_rounds / 3)
        self.exploitation_end = math.ceil(2 * self.n_rounds / 3)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number < self.exploration_end:
            return Action.D
        if state.round_number < self.exploitation_end:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_92(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Free-Riding with Dynamic Defection

    Core philosophy: Exploit the public goods game by always defecting to maximize
    individual payoff. Defection strictly dominates cooperation in this game structure,
    as defectors benefit from others' contributions without bearing costs.

    Decision rule: ALWAYS DEFECT across all rounds (1 through r).
    - Round 1: Defect to gather information on unconditional cooperators
    - Rounds 2 to r-1: Defect to exploit any cooperators present
    - Final round: Defect with no reputational consequences

    This is the Nash equilibrium strategy for finite repeated public goods games
    without enforcement mechanisms.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        return Action.D

class Strategy_EXPLOITATIVE_93(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Maximizes personal payoff by parasitizing cooperators while avoiding
    contribution costs. Always defects in round 0 and final round. In middle
    rounds, defects based on observed cooperation rate relative to break-even
    threshold k/n. Includes rare tactical cooperation detection for all-reciprocal
    opponents in early-middle rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        if history is None:
            return Action.D
        total_cooperators = int(np.sum(history.opponent_actions[:round_number, :]))
        total_rounds_played = round_number
        cooperation_rate = total_cooperators / (total_rounds_played * self.n_players)
        breakeven_threshold = self.k / self.n_players
        exploitation_threshold = breakeven_threshold * 1.2
        if round_number <= self.n_rounds // 2 and self._appears_all_reciprocal(history, round_number):
            return Action.C
        if cooperation_rate > exploitation_threshold or cooperation_rate <= breakeven_threshold:
            return Action.D
        return Action.D

    def _appears_all_reciprocal(self, history: PlayerHistory, round_number: int) -> bool:
        """
        Detect if all opponents appear to be playing reciprocal strategies.
        Reciprocal strategies match our previous action.
        """
        if round_number < 2:
            return False
        my_previous_action = history.my_actions[round_number - 1]
        matching_opponents = 0
        for opponent_idx in range(self.n_players - 1):
            opponent_previous_action = history.opponent_actions[round_number - 1, opponent_idx]
            if opponent_previous_action == my_previous_action:
                matching_opponents += 1
        all_matched = matching_opponents == self.n_players - 1
        return all_matched

class Strategy_EXPLOITATIVE_94(BaseStrategy):
    """
    Adaptive Parasitism Strategy for N-Player Public Goods Game

    Exploits the asymmetry of the public goods game by:
    1. Defecting in round 1 to gather information
    2. Monitoring cooperation rates in middle rounds
    3. Defecting whenever cooperation is exploitable
    4. Defecting in the final round for maximum extraction

    This simplifies to pure defection across all rounds, the dominant strategy
    in public goods games without enforcement mechanisms.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.r - 1:
            return Action.D
        prev_round_idx = round_number - 1
        cooperators_prev_round = int(sum(history.opponent_actions[prev_round_idx, :]))
        cooperation_rate = cooperators_prev_round / self.n
        threshold_high = self.k / self.n * 0.7
        threshold_low = self.k / self.n * 0.3
        if cooperation_rate >= threshold_high:
            return Action.D
        elif cooperation_rate >= threshold_low:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_95(BaseStrategy):
    """
    Adaptive Exploitation Strategy for N-Player Public Goods Game.

    This strategy exploits cooperators by:
    1. Always defecting in round 1 to gather information
    2. Free-riding on cooperators when cooperation rate is high enough
    3. Defecting in late game (final third) when reputational costs disappear
    4. Always defecting in the final round for maximum extraction
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        if current_round > 2 * r / 3:
            return Action.D
        previous_round_idx = current_round - 1
        cooperators_previous = np.sum(history.opponent_actions[previous_round_idx, :])
        coop_rate = cooperators_previous / n
        threshold = k / n
        if coop_rate <= threshold:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_96(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Core philosophy: Always defect to exploit cooperators and avoid wasted contributions.
    Uses a threshold based on game parameters to determine if cooperation is being exploited,
    but fundamentally always defects regardless.

    Threshold calculation: (n - k) / n
    - Above threshold: Cooperators exist and are ripe for exploitation
    - Below threshold: Cooperation is already punished; defection is safe
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold = (self.n - self.k) / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        total_c_actions = int(np.sum(history.opponent_actions[:current_round, :]))
        total_possible = self.n * current_round
        if total_possible == 0:
            cooperation_rate = 0.0
        else:
            cooperation_rate = total_c_actions / total_possible
        return Action.D

class Strategy_EXPLOITATIVE_97(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Exploitation

    Core principle: Defection is the baseline strategy. This player always defects,
    monitoring cooperation rates to identify exploitation windows. The strategy
    extracts maximum value from cooperative opponents while maintaining a robust
    defense against defectors.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_high = 0.6
        self.threshold_low = 0.3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        coop_rate = self._calculate_cooperation_rate(history, state.round_number)
        cooperators_last_round = int(np.sum(history.opponent_actions[state.round_number - 1, :]))
        if coop_rate > self.threshold_high:
            return Action.D
        elif self.threshold_low < coop_rate <= self.threshold_high:
            if cooperators_last_round >= math.ceil(self.game_description.n_players / 2):
                return Action.D
            else:
                return Action.D
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the cooperation rate across all previous rounds.

        coop_rate = (total cooperators across all previous rounds) /
                    (n  (current_round))
        """
        if current_round == 0:
            return 0.0
        total_cooperators = 0
        for round_idx in range(current_round):
            total_cooperators += int(np.sum(history.opponent_actions[round_idx, :]))
        total_possible = self.game_description.n_players * current_round
        return total_cooperators / total_possible if total_possible > 0 else 0.0

class Strategy_EXPLOITATIVE_98(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism: An exploitative strategy that
    consistently defects to maximize payoff by free-riding on cooperators'
    contributions while avoiding cooperation costs. Monitors cooperation rates
    but always defects regardless, as defection strictly dominates in the
    public goods game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        n = self.game_description.n_players
        k = self.game_description.k
        total_opponent_actions = np.sum(history.opponent_actions)
        total_possible_actions = n * state.round_number
        cooperation_rate = total_opponent_actions / total_possible_actions if total_possible_actions > 0 else 0
        threshold = 1 / (2 * k)
        return Action.D

class Strategy_EXPLOITATIVE_99(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    Exploits asymmetric payoffs in public goods games through three phases:
    1. Reconnaissance (early rounds): Map opponent cooperation tendencies
    2. Exploitation (middle rounds): Maximize defection against cooperators
    3. Endgame (final rounds): Pure defection with minimal stochastic cooperation

    Uses observed cooperation rates to identify exploitable situations while
    maintaining occasional cooperation to avoid complete identification as pure defector.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        phase1_end = math.floor(self.r / 3)
        phase2_end = math.floor(2 * self.r / 3)
        if current_round == 0:
            return Action.D
        cooperation_rate = self._calculate_cooperation_rate(history, current_round)
        if current_round <= phase1_end:
            if cooperation_rate >= 0.6:
                return Action.C if random.random() < 0.3 else Action.D
            else:
                return Action.D
        elif current_round <= phase2_end:
            threshold = self.n * cooperation_rate / (self.k - 1) if self.k > 1 else float('inf')
            if cooperation_rate > threshold:
                return Action.D
            elif cooperation_rate >= 0.4:
                return Action.C if random.random() < 0.15 else Action.D
            else:
                return Action.D
        else:
            rounds_remaining = self.r - current_round
            if rounds_remaining <= 2:
                return Action.D
            elif cooperation_rate >= 0.5:
                return Action.C if random.random() < 0.1 else Action.D
            else:
                return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the average cooperation rate of opponents across all previous rounds.

        Args:
            history: PlayerHistory object with opponent actions
            current_round: Current round number (0-indexed)

        Returns:
            Float between 0 and 1 representing average cooperation rate
        """
        if current_round == 0:
            return 0.0
        previous_actions = history.opponent_actions[:current_round, :]
        total_cooperations = np.sum(previous_actions)
        total_observations = current_round * self.n
        cooperation_rate = total_cooperations / total_observations if total_observations > 0 else 0.0
        return float(cooperation_rate)

class Strategy_EXPLOITATIVE_100(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core approach: Always defect to exploit cooperative players while avoiding losses
    against defectors. Defect in round 1 (probe), all middle rounds (adaptive), and
    the final round (terminal exploitation).
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        prev_round_idx = current_round - 1
        coop_count = sum(history.opponent_actions[prev_round_idx, :])
        coop_rate = coop_count / n
        threshold = k / n
        if coop_rate > threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_101(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Operates on the principle that cooperation is only valuable when it generates
    personal surplus through others' contributions. Extracts maximum value from
    cooperators while minimizing personal contribution costs through:
    - Round 1: Defect to observe opponent tendencies
    - Rounds 2 to r-1: Conditional parasitism based on cooperation rate threshold
    - Final round: Unconditional defection for endgame exploitation
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        total_opponent_cooperations = np.sum(history.opponent_actions[:current_round, :])
        total_observations = (n - 1) * current_round
        if total_observations == 0:
            coop_rate = 0.0
        else:
            coop_rate = total_opponent_cooperations / total_observations
        cooperation_threshold = k / n
        rounds_remaining = r - current_round
        if coop_rate < cooperation_threshold:
            return Action.D
        elif rounds_remaining > 2:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_102(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Opportunistic Cooperation

    This strategy exploits the public goods game by defaulting to defection,
    cooperating only when historical cooperation rates justify it mathematically,
    and weaponizing final rounds for maximum exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n_players
        self.threshold_enforcement_rounds = math.ceil(self.n_rounds / 3)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num >= self.n_rounds - 2:
            return Action.D
        remaining_rounds = self.n_rounds - round_num
        total_possible_cooperations = (self.n_players - 1) * round_num
        total_observed_cooperations = int(np.sum(history.opponent_actions[:round_num, :]))
        if total_possible_cooperations == 0:
            observed_cooperation_rate = 0.0
        else:
            observed_cooperation_rate = total_observed_cooperations / total_possible_cooperations
        if observed_cooperation_rate >= self.threshold and remaining_rounds >= self.threshold_enforcement_rounds:
            cooperators_observed = int(np.sum(history.opponent_actions[round_num - 1, :]))
            defection_payoff = 1.0 + self.k / self.n_players * cooperators_observed
            cooperation_payoff = 0.0 + self.k / self.n_players * (cooperators_observed + 1)
            if defection_payoff > cooperation_payoff:
                return Action.D
            else:
                return Action.C
        if round_num >= 2:
            prev_round_cooperators = int(np.sum(history.opponent_actions[round_num - 1, :]))
            prev_prev_round_cooperators = int(np.sum(history.opponent_actions[round_num - 2, :]))
            if prev_round_cooperators < prev_prev_round_cooperators:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_103(BaseStrategy):
    """
    Adaptive Parasite: An exploitative strategy that always defects.

    Core principle: Defection is the dominant strategy in the public goods game.
    By defecting, we keep our endowment (value 1) while capturing a share of any
    public goods created by cooperators. Cooperation offers no strategic benefit
    since we receive the same payoff share regardless of our action, but lose our
    endowment if we cooperate.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.k = game_description.k
        self.n = game_description.n_players
        self.threshold = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_104(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    Exploits the asymmetry in public goods payoffs by systematically defecting
    while using rare cooperation as bait to detect exploitable cooperators.
    Adapts exploitation strategy based on observed cooperation rates.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round in [0, 1, 2]:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        total_rounds_so_far = current_round
        total_cooperators = int(np.sum(history.opponent_actions[:current_round, :]))
        cooperation_rate = total_cooperators / (total_rounds_so_far * self.n_players)
        if cooperation_rate > self.threshold:
            return Action.D
        else:
            bait_interval = 20
            bait_round = math.ceil(self.n_rounds / 4)
            if current_round % bait_interval == 0 or current_round == bait_round:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_105(BaseStrategy):
    """
    Adaptive Predation: An exploitative strategy that maximizes personal payoff by
    exploiting the asymmetry between defection and cooperation. Defects by default,
    with strategic probing cooperation only when the public good is collapsing.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        total_cooperations = 0
        for round_idx in range(current_round):
            my_coop = 1 if history.my_actions[round_idx] else 0
            opponent_coops = int(np.sum(history.opponent_actions[round_idx, :]))
            total_cooperations += my_coop + opponent_coops
        total_opportunities = current_round * self.n_players
        coop_rate = total_cooperations / total_opportunities if total_opportunities > 0 else 0.0
        threshold = 0.35 + 0.1 * (self.n_players - self.k) / max(self.n_players - 1, 1)
        if coop_rate > threshold:
            return Action.D
        probe_probability = 0.15 * (1.0 - coop_rate)
        if random.random() < probe_probability:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_106(BaseStrategy):
    """
    Adaptive Defection with Conditional Parasitism.

    Core philosophy: Exploit the asymmetry between defection rewards and cooperation costs.
    Always defect to harvest public goods created by cooperators while maintaining full endowment.
    Backward induction ensures defection is optimal in all rounds including the final round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_107(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Maximizes personal payoff by defecting by default and cooperating only when
    exploitation conditions are met: high cooperator density, avoiding reciprocator
    punishment, or temporary opportunistic gains.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        prev_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        prev_cooperation_rate = prev_cooperators / self.n
        endgame_threshold = self.r - math.ceil(self.r / 4)
        in_endgame = current_round >= endgame_threshold
        if in_endgame:
            if prev_cooperation_rate > 0:
                return Action.D
            else:
                return Action.D
        threshold_coop = (self.k - 1) / (self.n - 1) + 0.05
        if prev_cooperation_rate >= threshold_coop:
            payoff_if_coop = self.k / self.n * prev_cooperators
            payoff_if_defect = 1 + self.k / self.n * prev_cooperators
            if payoff_if_coop > payoff_if_defect:
                return Action.C
            else:
                return Action.D
        reciprocators = self._identify_reciprocators(history, current_round)
        if len(reciprocators) > 0 and prev_cooperation_rate > self.k / self.n:
            expected_payoff_coop = self.k / self.n * prev_cooperators
            if expected_payoff_coop > 0.5:
                return Action.C
            else:
                return Action.D
        return Action.D

    def _identify_reciprocators(self, history: PlayerHistory, current_round: int) -> list:
        """
        Identify players showing tit-for-tat reciprocity patterns.
        Returns list of opponent indices showing conditional cooperation (correlation >= 0.8).
        """
        reciprocators = []
        if current_round < 2:
            return reciprocators
        lookback = min(3, current_round)
        for opp_idx in range(self.n - 1):
            opp_coop_pattern = history.opponent_actions[current_round - lookback:current_round, opp_idx]
            correlation_score = 0
            for t in range(lookback):
                round_idx = current_round - lookback + t
                total_coop = int(sum(history.opponent_actions[round_idx, :]))
                if opp_coop_pattern[t] == 1 and total_coop > self.n / 2 or (opp_coop_pattern[t] == 0 and total_coop <= self.n / 2):
                    correlation_score += 1
            if correlation_score >= lookback * 0.8:
                reciprocators.append(opp_idx)
        return reciprocators

class Strategy_EXPLOITATIVE_108(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    This strategy exploits the Public Goods Game by defaulting to defection,
    only appearing to consider cooperation when the historical cooperation rate
    exceeds a break-even threshold. However, it consistently defects regardless,
    maximizing individual payoff through exploitation of cooperators.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.n - self.k) / self.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.r - 1:
            return Action.D
        my_actions = history.my_actions[:state.round_number]
        opponent_actions = history.opponent_actions[:state.round_number, :]
        total_my_cooperations = np.sum(my_actions)
        total_opponent_cooperations = np.sum(opponent_actions)
        total_cooperators = total_my_cooperations + total_opponent_cooperations
        total_actions = self.n * state.round_number
        coop_rate = total_cooperators / total_actions if total_actions > 0 else 0
        return Action.D

class Strategy_EXPLOITATIVE_109(BaseStrategy):
    """
    Adaptive Parasitism: An exploitative strategy that unconditionally defects
    to maximize payoff by free-riding on cooperators' contributions while avoiding
    losses when cooperation collapses. Based on the principle that defection is
    the dominant strategy in simultaneous-move public goods games.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_110(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    Maximizes personal payoff by free-riding on others' contributions and
    selectively exploiting cooperative opponents through predatory cooperation.
    Always defects except in narrow circumstances to build false trust.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.n_rounds - 1:
            return Action.D
        rounds_remaining = self.n_rounds - round_num
        if rounds_remaining <= 3:
            return Action.D
        history_depth = min(5, round_num)
        recent_actions = history.opponent_actions[-history_depth:, :]
        cooperation_counts = np.sum(recent_actions, axis=1)
        avg_cooperation_rate = np.mean(cooperation_counts) / self.n_players
        threshold_high = self.k / self.n_players * 0.6 * self.n_players
        round_threshold = self.n_rounds * 0.3
        if round_num < round_threshold and avg_cooperation_rate > 0.55 and (rounds_remaining > 2):
            if random.random() < 0.3:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_111(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    This strategy exploits the payoff asymmetry in public goods games where defection
    is mathematically dominant (k < n). It always defects, with adaptive monitoring
    of cooperation rates to justify continued defection through the game structure
    rather than behavioral responses.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.r - 1:
            return Action.D
        previous_round_opponent_actions = history.opponent_actions[round_number - 1, :]
        cooperator_count = int(np.sum(previous_round_opponent_actions))
        cooperation_rate = cooperator_count / self.n
        threshold = self.k / self.n
        return Action.D

class Strategy_EXPLOITATIVE_112(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core approach: Always defect to maximize personal payoff by exploiting
    cooperative players while avoiding the cost of cooperation. Defection is
    the dominant strategy in this public goods game, and the repeated structure
    doesn't create sufficient enforcement mechanisms to make cooperation profitable.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        total_rounds_played = state.round_number
        total_cooperators = np.sum(history.opponent_actions[:state.round_number, :])
        own_cooperations = np.sum(history.my_actions[:state.round_number])
        total_cooperators += own_cooperations
        cooperation_rate = total_cooperators / (self.game_description.n_players * total_rounds_played)
        threshold = (self.game_description.k - 1) / self.game_description.k
        return Action.D

class Strategy_EXPLOITATIVE_113(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Exploitation

    Maximizes personal payoff by exploiting the public goods dilemma structure.
    Core insight: defection yields higher individual returns in almost all scenarios,
    so defect by default while selectively exploiting cooperators when they appear.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = math.ceil(game_description.k)
        self.opponent_model = np.zeros(game_description.n_players - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        cooperators_previous = int(np.sum(history.opponent_actions[-1, :]))
        cooperation_rate_all = np.sum(self.opponent_model) / (self.game_description.n_players - 1)
        for j in range(self.game_description.n_players - 1):
            if history.opponent_actions[-1, j]:
                self.opponent_model[j] += 1
        if cooperators_previous > 0:
            return Action.D
        elif cooperation_rate_all > self.game_description.k / self.game_description.n_players:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_114(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Controlled Exploitation

    Maximizes personal payoff by exploiting cooperative tendencies in opponents
    while avoiding mutual defection traps. Cooperates in round 1 to probe,
    adapts based on cooperation rate in middle rounds, and defects in final round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.exploitation_threshold = (self.k - 1) / self.k
        self.min_viable_threshold = 0.2
        self.switched_to_defect = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            return Action.D
        if self.switched_to_defect:
            return Action.D
        total_cooperators = np.sum(history.opponent_actions[:round_num, :])
        max_possible_actions = self.n * round_num
        cooperation_rate = total_cooperators / max_possible_actions
        if cooperation_rate > self.exploitation_threshold:
            self.switched_to_defect = True
            return Action.D
        elif cooperation_rate < self.min_viable_threshold:
            self.switched_to_defect = True
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_115(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    This strategy exploits the fundamental asymmetry of public goods games by:
    1. Always defecting to avoid cooperation costs
    2. Extracting maximum value from any cooperators present
    3. Maintaining defection even when cooperation rate is high
    4. Using exploitation threshold (k/n) to rationalize defection

    Core insight: Defection is individually rational regardless of opponent behavior.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.k = game_description.k
        self.n = game_description.n_players
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.r - 1:
            return Action.D
        previous_round_idx = round_number - 1
        cooperators_in_previous_round = sum(history.opponent_actions[previous_round_idx, :])
        cooperation_rate = cooperators_in_previous_round / self.n
        exploitation_threshold = self.k / self.n
        return Action.D

class Strategy_EXPLOITATIVE_116(BaseStrategy):
    """
    Adaptive Parasitism with Dynamic Defection - exploitative strategy that:
    1. Gathers information via cooperation in early rounds
    2. Exploits cooperators by defecting when cooperation rate is high
    3. Uses camouflage cooperation to avoid detection
    4. Maximizes extraction in endgame by always defecting
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        info_gathering_rounds = max(2, math.ceil(self.game_description.n_rounds * 0.15))
        if state.round_number < info_gathering_rounds:
            return Action.C
        rounds_remaining = self.game_description.n_rounds - state.round_number
        if rounds_remaining <= 2:
            return Action.D
        avg_coop = self._calculate_avg_cooperation(history)
        threshold = self._get_cooperation_threshold(state.round_number)
        if avg_coop >= threshold:
            if self.consecutive_defections >= 3 and avg_coop > 0.4:
                self.consecutive_defections = 0
                return Action.C
            else:
                self.consecutive_defections += 1
                return Action.D
        else:
            self.consecutive_defections += 1
            return Action.D

    def _calculate_avg_cooperation(self, history: PlayerHistory) -> float:
        """Calculate the global average cooperation rate across all previous rounds."""
        if len(history.opponent_actions) == 0:
            return 0.0
        total_contributions = 0
        total_possible = 0
        for round_idx in range(len(history.opponent_actions)):
            total_contributions += sum(history.opponent_actions[round_idx, :])
            total_possible += self.game_description.n_players - 1
        own_contributions = sum(history.my_actions)
        total_contributions += own_contributions
        total_possible += len(history.my_actions)
        if total_possible == 0:
            return 0.0
        return total_contributions / total_possible

    def _get_cooperation_threshold(self, current_round: int) -> float:
        """
        Dynamic threshold that becomes stricter as game progresses.
        Early game: 0.4 (exploit early)
        Mid game: 0.5 (standard threshold)
        Late game: 0.99 (almost always defect in endgame)
        """
        progress_ratio = current_round / self.game_description.n_rounds
        if progress_ratio < 1 / 3:
            return 0.4
        elif progress_ratio < 2 / 3:
            return 0.5
        else:
            return 0.99

class Strategy_EXPLOITATIVE_117(BaseStrategy):
    """
    Adaptive Parasitism: An exploitative strategy that always defects to maximize
    payoff by free-riding on any cooperators while avoiding reputational costs.

    Core logic:
    - Round 1: Defect to establish baseline
    - Rounds 2 to r-1: Defect to exploit cooperators (defection strictly dominant since k < n)
    - Round r: Defect in terminal round (no future consequences)

    Since k < n, defection is always  cooperation mathematically, so this strategy
    simply applies that principle without moral compromise.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == self.n_rounds - 1:
            return Action.D
        if round_number == 0:
            return Action.D
        opponent_cooperation_count = 0
        max_possible_cooperation = round_number * (self.n_players - 1)
        for round_idx in range(round_number):
            opponent_cooperation_count += np.sum(history.opponent_actions[round_idx, :])
        if max_possible_cooperation > 0:
            cooperation_rate = opponent_cooperation_count / max_possible_cooperation
        else:
            cooperation_rate = 0.0
        threshold_tau = self.k / self.n_players * 1.2
        return Action.D

class Strategy_EXPLOITATIVE_118(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    Exploits the asymmetry in public goods games by:
    1. Defecting in round 1 to gather information
    2. Conditionally cooperating in middle rounds only when cooperation rate exceeds threshold
    3. Defecting in final round to maximize endgame exploitation
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (1.0 - 1.0 / self.k) / 2.0
        if self.n_players == 2:
            self.threshold = 0.51
        if self.k < 1.1:
            self.threshold = 1.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        lookback_window = min(3, current_round)
        recent_rounds = max(0, current_round - lookback_window)
        cooperation_counts = []
        for round_idx in range(recent_rounds, current_round):
            cooperators_in_round = np.sum(history.opponent_actions[round_idx, :])
            cooperation_counts.append(cooperators_in_round)
        if len(cooperation_counts) == 0:
            return Action.D
        avg_cooperation_count = np.mean(cooperation_counts)
        cooperation_rate = avg_cooperation_count / self.n_players
        if len(cooperation_counts) > 1:
            variance = np.var(cooperation_counts)
            if variance > self.threshold * 0.3 * self.n_players ** 2:
                return Action.D
        if cooperation_rate > self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_119(BaseStrategy):
    """
    Exploitative Adaptive Defection with Conditional Parasitism.

    Core strategy: Defect by default, cooperate only when the public good multiplier
    effect generates higher payoff than defection. Ruthlessly defect in endgame.
    Exploit cooperative opponents through free-riding and adaptive parasitism.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.endgame_threshold = 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        t = state.round_number
        rounds_remaining = r - t - 1
        if rounds_remaining <= self.endgame_threshold:
            return Action.D
        if t == 0:
            return Action.D
        estimated_cooperators = self._estimate_cooperators(history, n)
        payoff_if_cooperate = k / n * (estimated_cooperators + 1)
        payoff_if_defect = 1 + k / n * estimated_cooperators
        if payoff_if_cooperate > payoff_if_defect:
            return Action.C
        else:
            return Action.D

    def _estimate_cooperators(self, history: PlayerHistory, n: int) -> int:
        """
        Estimate the number of cooperators in the next round based on recent history.

        Uses a weighted average of recent rounds (last 3) to predict cooperation rate,
        then applies that to estimate how many opponents will cooperate.
        """
        if history is None or len(history.opponent_actions) == 0:
            return 1
        recent_rounds_count = min(3, len(history.opponent_actions))
        recent_rounds = history.opponent_actions[-recent_rounds_count:]
        cooperators_per_round = np.sum(recent_rounds, axis=1)
        avg_cooperators = np.mean(cooperators_per_round)
        predicted_cooperators = int(math.floor(avg_cooperators))
        predicted_cooperators = max(0, min(n - 1, predicted_cooperators))
        return predicted_cooperators

class Strategy_EXPLOITATIVE_120(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Exploitation

    This strategy exploits the asymmetry between defectors and cooperators by:
    1. Defaulting to defection to capture cooperator surplus
    2. Selectively cooperating only when cooperation rates are sufficiently high
    3. Always defecting in the final round (endgame exploitation)
    4. Adapting to observed cooperation trends to time exploitation optimally
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.n_rounds - 1:
            return Action.D
        rounds_remaining = self.n_rounds - round_num
        cooperators_prev = np.sum(history.opponent_actions[round_num - 1, :])
        coop_rate_prev = cooperators_prev / self.n_players
        breakeven_rate = (self.n_players - self.k) / self.n_players
        if rounds_remaining <= 2:
            threshold = 1.0
        elif rounds_remaining <= self.n_rounds / 2:
            threshold = breakeven_rate * 1.5
        else:
            threshold = breakeven_rate * 1.2
        recent_rounds = min(3, round_num)
        recent_coop_rates = []
        for i in range(round_num - recent_rounds, round_num):
            coop_count = np.sum(history.opponent_actions[i, :])
            recent_coop_rates.append(coop_count / self.n_players)
        weights = np.array([2.0 ** i for i in range(len(recent_coop_rates))])
        weights = weights / np.sum(weights)
        recent_coop_trend = np.sum(np.array(recent_coop_rates) * weights)
        expected_cooperators = recent_coop_trend * self.n_players
        expected_payoff_if_defect = 1.0 + self.k / self.n_players * expected_cooperators
        expected_payoff_if_coop = 0.0 + self.k / self.n_players * (expected_cooperators + 1)
        should_cooperate = recent_coop_trend > threshold and expected_payoff_if_coop >= expected_payoff_if_defect and (rounds_remaining >= 2)
        if should_cooperate:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_121(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    This strategy exploits the fundamental asymmetry in public goods games by:
    1. Always defecting in round 1 to establish non-cooperative baseline
    2. Adaptively defecting based on observed cooperation rate in middle rounds
    3. Always defecting in the final round to maximize end-game payoff

    The strategy monitors opponent cooperation rate and maintains defection as the
    dominant action, free-riding on any cooperation while avoiding contribution costs.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_threshold = 0.3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        rounds_elapsed = state.round_number
        n_opponents = self.game_description.n_players - 1
        if rounds_elapsed > 0 and history is not None:
            total_cooperations = np.sum(history.opponent_actions[:rounds_elapsed, :])
            total_possible_cooperations = rounds_elapsed * n_opponents
            coop_rate = total_cooperations / total_possible_cooperations if total_possible_cooperations > 0 else 0.0
        else:
            coop_rate = 0.0
        if coop_rate > self.cooperation_threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_122(BaseStrategy):
    """
    Adaptive Parasite Strategy: Exploits the public goods game by strategically
    defecting to free-ride on cooperators, with selective mid-game cooperation
    only as a late-game probe when cooperation rates drop below the threshold 1/k.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_threshold = 1.0 / game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == r - 1:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[round_num - 1, :]))
        cooperation_rate = cooperators_last_round / n
        if cooperation_rate >= self.cooperation_threshold:
            return Action.D
        elif round_num <= r / 2:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_123(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Maximizes personal payoff by exploiting cooperative behavior when it exists,
    while maintaining a credible threat of defection. Core principle: defect by default,
    cooperate selectively when the cooperation rate exceeds the threshold (n-k)/n.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold = (self.n - self.k) / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        prev_round_idx = current_round - 1
        cooperation_count = sum(history.opponent_actions[prev_round_idx, :])
        cooperation_rate = cooperation_count / self.n
        if cooperation_rate > self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_124(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    This strategy implements pure defection across all rounds to maximize individual payoff
    by exploiting cooperative opponents while avoiding losses against defectors.

    Core logic:
    - Round 0 (first): DEFECT (baseline extraction, no history)
    - Rounds 1 to r-2 (middle): DEFECT (exploit any cooperators, match defectors)
    - Round r-1 (final): DEFECT (terminal extraction, no future rounds)

    Rationale: Defecting always dominates cooperation in this game structure.
    Against cooperators: earn 1 + (k/n)total_contributions (payoff-maximizing)
    Against defectors: earn 1 (symmetric, unavoidable)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_125(BaseStrategy):
    """
    Adaptive Defection with Calculated Cooperation (ADCC).

    Exploitative strategy that maximizes personal payoff by free-riding on cooperative
    opponents while avoiding exploitation by defectors. Uses probabilistic defection in
    uncertain conditions and unconditional defection in early/late rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        opponent_actions = history.opponent_actions[:current_round, :]
        total_possible_cooperations = current_round * (self.n - 1)
        total_cooperations = np.sum(opponent_actions)
        cooperation_rate = total_cooperations / total_possible_cooperations if total_possible_cooperations > 0 else 0.0
        threshold_low = self.k / self.n - 0.2
        threshold_high = self.k / self.n + 0.2
        if cooperation_rate >= threshold_high:
            return Action.D
        if cooperation_rate < threshold_low:
            return Action.D
        my_last_payoff = history.my_payoffs[current_round - 1]
        baseline_payoff = 1.0
        theoretical_max_exploitation = 1.0 + self.k
        if theoretical_max_exploitation > baseline_payoff:
            payoff_ratio = (my_last_payoff - baseline_payoff) / (theoretical_max_exploitation - baseline_payoff)
        else:
            payoff_ratio = 0.0
        payoff_ratio = max(0.0, min(1.0, payoff_ratio))
        if my_last_payoff < baseline_payoff + 0.1:
            defection_probability = 0.8
        else:
            defection_probability = payoff_ratio
        if random.random() < defection_probability:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_126(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism: An exploitative strategy that
    defects in all rounds, particularly targeting cooperative players by free-riding
    on their contributions. The strategy recognizes that defection is individually
    rational given the game parameters (k < n), and exploits the asymmetry in payoffs
    between cooperators and defectors.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.r - 1:
            return Action.D
        previous_round_idx = state.round_number - 1
        cooperators_last_round = sum(history.opponent_actions[previous_round_idx, :])
        coop_rate = cooperators_last_round / self.n
        threshold = self.k / self.n
        if coop_rate >= threshold:
            return Action.D
        else:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_127(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Free-Rider with Dynamic Defection

    Core Philosophy: Exploit the asymmetry in payoff structure by always defecting.
    Defectors gain more than cooperators when others cooperate. This strategy monitors
    cooperation rates and always defects, whether cooperation is high (to free-ride) or low
    (since cooperation is collapsing anyway).
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.k - 1) / self.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.r - 1:
            return Action.D
        total_cooperations = np.sum(history.my_actions) + np.sum(history.opponent_actions)
        total_possible = state.round_number * self.n
        cooperation_rate = total_cooperations / total_possible if total_possible > 0 else 0
        return Action.D

class Strategy_EXPLOITATIVE_128(BaseStrategy):
    """
    Adaptive Defection with Conditional Cooperation (ADCC):
    An exploitative strategy that systematically defects when others cooperate,
    while avoiding mutual defection traps when beneficial. Targets cooperative
    opponents and locks in defection during endgame rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_alpha = 0.5
        self.threshold_beta = 0.3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round >= r - 2:
            return Action.D
        prev_round_idx = current_round - 1
        prev_cooperators = np.sum(history.opponent_actions[prev_round_idx, :])
        cooperation_rate = prev_cooperators / n
        my_last_action = history.my_actions[prev_round_idx]
        if cooperation_rate >= self.threshold_alpha:
            return Action.D
        elif cooperation_rate >= self.threshold_beta:
            if my_last_action == 0:
                return Action.D
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_129(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core philosophy: Always defect to exploit the public goods game's asymmetry.
    Defectors benefit from others' contributions while avoiding contribution costs.
    Monitors cooperation rates to confirm exploitation opportunities, but always defects
    regardless, making this a pure defection strategy with threshold-based monitoring.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.k - 1) / self.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.n_rounds - 1:
            return Action.D
        prev_round_cooperators = sum(history.opponent_actions[state.round_number - 1, :])
        cooperation_rate = prev_round_cooperators / self.n_players
        return Action.D

class Strategy_EXPLOITATIVE_130(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism.

    A purely exploitative strategy that:
    1. Defects in round 1 to establish non-cooperation signal
    2. Monitors opponent cooperation rates (CR_i) and global defection rate (GDR)
    3. Parasitizes reliable cooperators by defecting while they contribute
    4. Matches defection in defection-heavy environments
    5. Defects in the final round (no future consequences)

    Strategy defaults to defection ~99%+ of the time, adapting only within
    the defection framework to maximize exploitation payoff.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        rounds_played = current_round
        n_opponents = self.n_players - 1
        cooperation_rates = np.zeros(n_opponents)
        for opp_idx in range(n_opponents):
            cooperations = np.sum(history.opponent_actions[:current_round, opp_idx])
            cooperation_rates[opp_idx] = cooperations / rounds_played if rounds_played > 0 else 0.0
        recent_trends = np.zeros(n_opponents)
        for opp_idx in range(n_opponents):
            if rounds_played >= 2:
                recent_actions = history.opponent_actions[max(0, current_round - 2):current_round, opp_idx]
                recent_trends[opp_idx] = np.mean(recent_actions)
            elif rounds_played == 1:
                recent_trends[opp_idx] = float(history.opponent_actions[current_round - 1, opp_idx])
            else:
                recent_trends[opp_idx] = 0.0
        total_opponent_rounds = rounds_played * n_opponents
        total_opponent_defections = np.sum(~history.opponent_actions[:current_round, :])
        gdr = total_opponent_defections / total_opponent_rounds if total_opponent_rounds > 0 else 0.0
        if gdr > 0.6:
            return Action.D
        reliable_cooperators = np.sum((cooperation_rates >= 0.7) & (recent_trends >= 0.75))
        if reliable_cooperators > 0:
            return Action.D
        if np.all(cooperation_rates < 0.3):
            return Action.D
        if 0.3 <= gdr <= 0.6:
            return Action.D
        avg_recent_trend = np.mean(recent_trends)
        if avg_recent_trend >= 0.6:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_131(BaseStrategy):
    """
    Adaptive Defection with Conditional Parasitism.

    A purely exploitative strategy that:
    1. Defects by default to capture private endowment
    2. Conditionally exploits cooperators through free-riding
    3. Adapts based on observed cooperation rates
    4. Employs terminal defection in the final round

    Core principle: Defection is weakly dominant in public goods games.
    This strategy maximizes personal payoff by never cooperating unless
    strategically beneficial (which never occurs given game structure).
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.n_players - self.k) / self.n_players
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        prev_round_idx = current_round - 1
        opponent_cooperators_prev = sum(history.opponent_actions[prev_round_idx, :])
        cooperation_rate_prev = opponent_cooperators_prev / self.n_players
        if cooperation_rate_prev > self.threshold:
            free_riding_payoff = self.k / self.n_players * opponent_cooperators_prev
            if free_riding_payoff > 1:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_132(BaseStrategy):
    """
    Adaptive Parasitic Harvesting: An exploitative strategy that systematically
    defects to free-ride on cooperators' contributions to the public good.

    Core logic: Always defect. Since k < n in the public goods game,
    defection is the dominant strategy. Cooperating costs 1 but yields only
    (k/n) < 1 in return, making exploitation of any cooperation always optimal.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        prev_round_cooperators = int(sum(history.opponent_actions[state.round_number - 1, :]))
        cooperation_rate = prev_round_cooperators / self.game_description.n_players
        return Action.D

class Strategy_EXPLOITATIVE_133(BaseStrategy):
    """
    Adaptive Predation Strategy for N-Player Public Goods Game.

    Exploits the asymmetry in payoff structure by defecting strategically:
    - Phase 1 (Exploration): Defect to establish baseline and measure opponent cooperation
    - Phase 2 (Exploitation): Adapt based on observed cooperation rates
    - Phase 3 (Endgame): Always defect to maximize final payoffs

    Core insight: Defection yields 1 + k/n  (cooperators), while cooperation yields
    only k/n  (total_cooperators). Defection dominates when opponents cooperate.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.phase1_end = min(3, math.ceil(self.r / 2))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num < self.phase1_end:
            return Action.D
        if round_num >= self.r - 2:
            return Action.D
        coop_rate_early = self._calculate_early_coop_rate(history)
        threshold_high = self.k / self.n
        threshold_low = self.k / (2.0 * self.n)
        if coop_rate_early > threshold_high:
            return Action.D
        elif coop_rate_early > threshold_low:
            return Action.D
        else:
            return Action.D

    def _calculate_early_coop_rate(self, history: PlayerHistory) -> float:
        """
        Calculate the cooperation rate observed in early rounds.
        Uses all rounds up to current, capped at phase1_end for consistency.
        """
        if history is None or len(history.opponent_actions) == 0:
            return 0.0
        total_cooperations = 0
        rounds_observed = len(history.opponent_actions)
        for round_idx in range(rounds_observed):
            opponent_cooperations = np.sum(history.opponent_actions[round_idx, :])
            total_cooperations += opponent_cooperations
        if rounds_observed == 0 or self.n == 1:
            return 0.0
        total_possible = (self.n - 1) * rounds_observed
        if total_possible == 0:
            return 0.0
        coop_rate = total_cooperations / total_possible
        return coop_rate

class Strategy_EXPLOITATIVE_134(BaseStrategy):
    """
    Adaptive Predator: An exploitative strategy that defects by default,
    exploits detected cooperation, and uses rare deceptive cooperation
    to re-enable future exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        cooperation_count = np.sum(history.my_actions[:round_number]) + np.sum(history.opponent_actions[:round_number, :])
        total_actions = self.n_players * round_number
        cooperation_rate = cooperation_count / total_actions if total_actions > 0 else 0.0
        my_last_action = history.my_actions[round_number - 1]
        my_last_payoff = history.my_payoffs[round_number - 1]
        defection_pattern = False
        if round_number >= 2:
            last_round_defections = np.sum(history.opponent_actions[round_number - 1, :] == 0)
            second_last_round_defections = np.sum(history.opponent_actions[round_number - 2, :] == 0)
            if last_round_defections >= self.n_players - 1 and second_last_round_defections >= self.n_players - 1:
                defection_pattern = True
        if cooperation_rate >= 0.5:
            return Action.D
        if defection_pattern:
            return Action.D
        if cooperation_rate < 0.3 and round_number < self.n_rounds / 2:
            return Action.D
        if my_last_action and my_last_payoff > 1.5:
            if random.random() < 0.15:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_135(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    Maximizes personal payoff by exploiting cooperative players while avoiding mutual defection traps.
    - Round 0: DEFECT (establish exploitation)
    - Rounds 1 to r-2: Adaptive defection based on observed cooperation rate
    - Round r-1: DEFECT unconditionally (endgame exploitation)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_high = 0.6
        self.threshold_low = 0.2
        self.p_defect = 0.75

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == r - 1:
            return Action.D
        total_cooperators = 0
        rounds_played = round_num
        for round_idx in range(rounds_played):
            cooperators_in_round = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += cooperators_in_round
        total_observations = rounds_played * n
        cooperation_rate = total_cooperators / total_observations if total_observations > 0 else 0.0
        if cooperation_rate > self.threshold_high:
            return Action.D
        elif cooperation_rate < self.threshold_low:
            return Action.D
        elif random.random() < self.p_defect:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_136(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Free-Riding with Dynamic Defection

    Cooperates in round 1 to probe opponent behavior, then defects in all subsequent rounds
    by exploiting the dominance of defection in the public goods game. Adapts based on
    observed cooperation rates but ultimately always defects since defection is individually
    rational regardless of others' cooperation levels (given 1 < k < n).
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_high = 0.5
        self.threshold_low = 0.2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        total_rounds_so_far = state.round_number
        total_actions = total_rounds_so_far * self.game_description.n_players
        cooperation_count = 0
        for round_idx in range(total_rounds_so_far):
            cooperation_count += np.sum(history.opponent_actions[round_idx, :])
        cooperation_rate = cooperation_count / total_actions if total_actions > 0 else 0.0
        if cooperation_rate > self.threshold_high:
            threshold_adjusted = self.threshold_high
        else:
            threshold_adjusted = self.threshold_low
        if cooperation_rate > threshold_adjusted:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_137(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    Exploits the asymmetry in public goods games by:
    1. Defecting in round 1 to probe cooperativeness
    2. Defecting in the final round for maximum extraction
    3. Adaptively defecting when cooperation rate exceeds exploitation threshold
    4. Probabilistically cooperating when cooperation threatens to collapse
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.k - 1) / (self.n - 1) if self.n > 1 else 0
        self.survival_threshold = 1.0 / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.r - 1:
            return Action.D
        total_cooperators = np.sum(history.opponent_actions[:round_number, :])
        total_possible = self.n * round_number
        cooperation_rate = total_cooperators / total_possible if total_possible > 0 else 0
        if cooperation_rate > self.threshold:
            return Action.D
        elif cooperation_rate < self.survival_threshold:
            p_cooperate = max(0, min(1, (self.survival_threshold - cooperation_rate) / self.survival_threshold))
            if random.random() < p_cooperate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_138(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    Core approach: Default to defection to exploit cooperators. Only conditionally
    cooperate when cooperation rate is stable and high, or when it creates exploitable
    conditions. Always defect in final rounds and round 1.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num >= self.n_rounds - 2:
            return Action.D
        coop_rate = self._calculate_cooperation_rate(history, round_num)
        defection_trend = self._calculate_defection_trend(history, round_num)
        if coop_rate > 0.55 and self.k > 1.5 and (round_num < self.n_rounds - 2):
            return Action.D
        if coop_rate < 0.3 and defection_trend > 0.7:
            return Action.D
        if 0.4 <= coop_rate <= 0.6 and 0.4 <= defection_trend <= 0.6:
            return Action.D
        return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate the cooperation rate of opponents over all observed rounds.

        Args:
            history: Player history object
            round_num: Current round number (0-indexed)

        Returns:
            Cooperation rate as a float in [0, 1]
        """
        if round_num == 0:
            return 0.0
        total_cooperations = np.sum(history.opponent_actions[:round_num, :])
        total_observations = round_num * (self.n_players - 1)
        if total_observations == 0:
            return 0.0
        return total_cooperations / total_observations

    def _calculate_defection_trend(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate the defection rate over the last 3 rounds.

        Args:
            history: Player history object
            round_num: Current round number (0-indexed)

        Returns:
            Defection rate as a float in [0, 1]
        """
        if round_num == 0:
            return 0.0
        look_back = min(3, round_num)
        start_idx = round_num - look_back
        recent_actions = history.opponent_actions[start_idx:round_num, :]
        defections = np.sum(~recent_actions)
        total_actions = look_back * (self.n_players - 1)
        if total_actions == 0:
            return 0.0
        return defections / total_actions

class Strategy_EXPLOITATIVE_139(BaseStrategy):
    """
    Adaptive Predation Strategy: Exploits cooperative opponents through conditional defection.

    Core mechanism: Always defect in round 1 and final round. Mid-game, monitor opponent
    cooperation rates and defect whenever there's any significant cooperation (>30% threshold).
    Inject rare cooperation (~20% probability) in late mid-game to reset expectations and
    create false hope for continued exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_high = 0.7
        self.threshold_medium = 0.3
        self.rare_coop_probability = 0.2
        self.window_size = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        n_rounds = self.game_description.n_rounds
        if current_round == 0:
            return Action.D
        if current_round == n_rounds - 1:
            return Action.D
        recent_coop_rate = self._calculate_recent_cooperation_rate(history)
        if recent_coop_rate >= self.threshold_medium:
            return Action.D
        if current_round <= n_rounds * 0.5:
            return Action.D
        elif random.random() < self.rare_coop_probability:
            return Action.C
        else:
            return Action.D

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory) -> float:
        """
        Calculate the mean cooperation rate of opponents over the most recent window_size rounds.
        Returns a value between 0 and 1 representing the fraction of opponents cooperating.
        """
        n_opponents = self.game_description.n_players - 1
        start_idx = max(0, len(history.opponent_actions) - self.window_size)
        recent_actions = history.opponent_actions[start_idx:, :]
        if recent_actions.size == 0:
            return 0.0
        total_cooperations = np.sum(recent_actions)
        total_observations = recent_actions.size
        cooperation_rate = total_cooperations / total_observations
        return cooperation_rate

class Strategy_EXPLOITATIVE_140(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Exploitation

    Core philosophy: Maximize personal payoff by exploiting the inherent incentive structure.
    Defection is individually rational when others cooperate, and defection minimizes losses
    when others defect.

    Decision rules:
    - Round 1 (index 0): DEFECT to establish non-cooperator identity
    - Rounds 2 to r-1 (middle rounds): DEFECT based on exploitation threshold analysis
    - Round r (final round): DEFECT to exploit without future punishment
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.exploitation_threshold = self.k / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = sum(history.opponent_actions[current_round - 1, :])
        avg_cooperation = cooperators_last_round / self.n_players
        return Action.D

class Strategy_EXPLOITATIVE_141(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Maximizes personal payoff by exploiting cooperative tendencies while minimizing
    exposure to mutual defection. Uses threshold-based decision making in middle rounds,
    with unconditional defection in round 0 and final round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold = (1 + self.k) / (2 * self.k)
        self.permanent_defection = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.r - 1:
            return Action.D
        if self.permanent_defection:
            return Action.D
        prev_round_actions = history.opponent_actions[round_number - 1, :]
        prev_cooperators = int(np.sum(prev_round_actions))
        cooperation_rate = prev_cooperators / self.n
        if round_number <= 2 and cooperation_rate < 0.2:
            self.permanent_defection = True
            return Action.D
        if cooperation_rate > self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_142(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core philosophy: Maximize personal payoff by exploiting cooperators while
    minimizing losses from defectors. Always defect except possibly in middle rounds
    based on cooperation rate threshold.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold = 1.0 / self.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        last_round_opponent_actions = history.opponent_actions[current_round - 1, :]
        coop_count_last = np.sum(last_round_opponent_actions)
        coop_rate = coop_count_last / self.n
        return Action.D

class Strategy_EXPLOITATIVE_143(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    This strategy exploits the public goods game by:
    1. Playing defect by default to avoid endowment loss
    2. Occasionally cooperating tactically to blend in and exploit cooperative populations
    3. Adapting cooperation frequency based on observed cooperation rates
    4. Always defecting in the final round when retaliation is impossible
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.p_initial = 0.3
        self.threshold_high = 0.4
        self.threshold_very_high = 0.6
        self.p_tactical_moderate = 0.25
        self.p_tactical_high = 0.4
        if self.n_players <= 3:
            self.p_initial = 0.5
        if self.n_rounds > 20:
            self.threshold_high = 0.35
        if self.k > self.n_players * 0.8:
            self.p_tactical_moderate += 0.1
            self.p_tactical_high += 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == self.n_rounds - 1:
            return Action.D
        if current_round == 0:
            if random.random() < self.p_initial:
                return Action.C
            else:
                return Action.D
        total_cooperators = np.sum(history.opponent_actions[:current_round, :])
        coop_rate = total_cooperators / (current_round * self.n_players)
        if coop_rate > self.threshold_very_high:
            if random.random() < self.p_tactical_high:
                return Action.C
            else:
                return Action.D
        elif coop_rate > self.threshold_high:
            if current_round % 3 == 0 and random.random() < self.p_tactical_moderate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_144(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Opportunistic Harvesting

    Maximizes personal payoff by exploiting cooperators while avoiding mutual defection traps.
    Uses threshold-based defection to harvest the public good while others fund it.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.defection_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        n = self.n_players
        r = self.n_rounds
        k = self.k
        if round_number == 0:
            self.defection_streak = 0
            return Action.D
        if round_number == r - 1:
            self.defection_streak += 1
            return Action.D
        prev_round_idx = round_number - 1
        cooperators_prev = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        cooperation_rate = cooperators_prev / n
        if k / n >= 0.5:
            threshold = 0.4
        else:
            threshold = 0.2
        cooperation_dropped = False
        if round_number >= 2:
            prev_prev_round_idx = round_number - 2
            cooperators_prev_prev = int(np.sum(history.opponent_actions[prev_prev_round_idx, :]))
            cooperation_rate_prev = cooperators_prev_prev / n
            if cooperation_rate_prev - cooperation_rate > 0.25:
                cooperation_dropped = True
        if self.defection_streak >= 2 and cooperation_rate > threshold:
            self.defection_streak += 1
            return Action.D
        if cooperation_dropped:
            self.defection_streak += 1
            return Action.D
        self.defection_streak += 1
        return Action.D

class Strategy_EXPLOITATIVE_145(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism: An exploitative strategy that
    defaults to defection, exploits cooperative opponents, and adapts timing based
    on game phase and opponent profiling.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.k - 1) / (self.k + self.n_players - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.n_rounds - 1:
            return Action.D
        total_opponent_decisions = history.opponent_actions.shape[0] * history.opponent_actions.shape[1]
        total_opponent_cooperations = np.sum(history.opponent_actions)
        if total_opponent_decisions > 0:
            opponent_coop_rate = total_opponent_cooperations / total_opponent_decisions
        else:
            opponent_coop_rate = 0.0
        phase_boundary_early = self.n_rounds / 3
        phase_boundary_mid = 2 * self.n_rounds / 3
        if round_num < phase_boundary_early:
            return Action.D
        if round_num < phase_boundary_mid:
            if opponent_coop_rate > self.threshold:
                return Action.D
            else:
                return Action.D
        if round_num >= phase_boundary_mid:
            reliable_cooperators = 0
            for opponent_idx in range(self.n_players - 1):
                opponent_history = history.opponent_actions[:, opponent_idx]
                if len(opponent_history) > 0:
                    opponent_coop_rate_individual = np.sum(opponent_history) / len(opponent_history)
                    if opponent_coop_rate_individual > 0.7:
                        reliable_cooperators += 1
            if reliable_cooperators > 0:
                return Action.D
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_146(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Core philosophy: Exploit the public goods game by free-riding on cooperative players.
    Always defects to maximize personal payoff while minimizing contribution costs.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_high = game_description.k / game_description.n_players
        self.threshold_low = game_description.k / (2 * game_description.n_players)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        previous_rounds = state.round_number
        opponent_actions = history.opponent_actions[:previous_rounds, :]
        total_cooperators = int(np.sum(opponent_actions))
        total_slots = (self.game_description.n_players - 1) * previous_rounds
        coop_rate = total_cooperators / total_slots if total_slots > 0 else 0.0
        if previous_rounds >= 3:
            last_3_rounds = opponent_actions[-3:, :]
            coop_rate = int(np.sum(last_3_rounds)) / (3 * (self.game_description.n_players - 1))
        if coop_rate > self.threshold_high:
            return Action.D
        elif coop_rate > self.threshold_low:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_147(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism: Exploits cooperators by defecting
    during information gathering, then selectively cooperating when the cooperation
    rate exceeds a calculated threshold to parasitically harvest the public good,
    with unconditional defection in the final round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = 1.0 / game_description.k + 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        if state.round_number < 3:
            return Action.D
        previous_round_idx = state.round_number - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[previous_round_idx, :]))
        cooperation_rate = cooperators_last_round / self.game_description.n_players
        if cooperation_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_148(BaseStrategy):
    """
    Adaptive Defection with Selective Exploitation Strategy.

    A ruthlessly exploitative strategy that maximizes personal payoff by:
    1. Defecting in round 1 to establish a baseline
    2. Exploiting any cooperation in middle rounds by defecting
    3. Defecting in the final round when no future punishment is possible

    The strategy observes cooperation rates and compares against a threshold
    of (k-1)/k, but always defects regardless since defection is weakly dominant
    across all parameter ranges.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        prev_cooperators = sum(history.opponent_actions[round_num - 1, :])
        coop_rate = prev_cooperators / self.n
        threshold = (self.k - 1) / self.k
        return Action.D

class Strategy_EXPLOITATIVE_149(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    This strategy exploits the public goods game by:
    1. Always defecting in round 1 and the final round (no punishment possible)
    2. Using a threshold-based approach in middle rounds to decide when to defect vs conditionally cooperate
    3. Defecting when cooperation is abundant (above threshold) to free-ride
    4. Conditionally cooperating proportionally when cooperation is scarce but non-zero
    5. Dynamically adjusting the threshold based on rounds remaining
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.epsilon = 0.05

    def _calculate_threshold(self, current_round: int) -> float:
        """
        Calculate exploitation threshold based on rounds remaining.
        Threshold = (1 + ) / k, adjusted based on endgame proximity.
        """
        rounds_remaining = self.n_rounds - current_round
        if rounds_remaining < self.n_players:
            threshold = 0.5
        elif rounds_remaining < 2 * self.n_players:
            threshold = 1.02 / self.k
        else:
            threshold = (1.0 + self.epsilon) / self.k
        return min(threshold, 1.0)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        prev_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        cooperation_rate = prev_cooperators / self.n_players
        threshold = self._calculate_threshold(current_round)
        if cooperation_rate >= threshold:
            return Action.D
        elif cooperation_rate > 0:
            if random.random() < cooperation_rate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_150(BaseStrategy):
    """
    Adaptive Predator: An exploitative strategy that dynamically shifts between
    exploitation and selective cooperation based on observed population behavior.

    Core approach:
    - Round 1: Defect (initial probe)
    - Rounds 2 to r-1: Adapt based on cooperation rate with stochastic mixing
    - Final round: Defect (no future reputation concerns)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_high = 0.5
        self.threshold_low = 0.25

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        prev_round_idx = current_round - 1
        opponent_actions_prev = history.opponent_actions[prev_round_idx, :]
        cooperators_last_round = int(np.sum(opponent_actions_prev))
        coop_rate = cooperators_last_round / n
        rounds_remaining = r - current_round
        p_exploit = min(0.95, max(0.7, 1.0 - rounds_remaining / r))
        if coop_rate >= self.threshold_high:
            return Action.D
        elif coop_rate >= self.threshold_low:
            if random.random() < p_exploit:
                return Action.D
            else:
                return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_151(BaseStrategy):
    """
    Unconditional Defection with Exploitation Strategy.

    This strategy exploits the fundamental asymmetry in the Public Goods Game by
    consistently defecting to capture private benefits while free-riding on any
    public good contributions made by opponents. It maximizes payoff by:
    - Always defecting in round 1 to gather information
    - Always defecting in the final round (no future punishment possible)
    - Always defecting in intermediate rounds to exploit any cooperation observed

    Against pure cooperators, this yields ~50% higher payoff. Against defectors,
    it achieves the Nash equilibrium. Against mixed strategies, defection dominates.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_152(BaseStrategy):
    """
    Adaptive Predation: An exploitative strategy that defects consistently to free-ride
    on cooperators while maintaining safe mutual defection with defectors.

    Core approach:
    - Round 1: Defect to probe and identify cooperators
    - Rounds 2 to r-1: Defect to exploit any cooperators identified
    - Final round: Defect for maximum extraction
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number < self.game_description.n_rounds - 1:
            recent_window_start = max(0, state.round_number - 2)
            recent_rounds = history.opponent_actions[recent_window_start:state.round_number + 1, :]
            cooperators_recent = np.sum(recent_rounds)
            if cooperators_recent > 0:
                return Action.D
            else:
                return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_153(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Free-Riding with Dynamic Threshold Shifting

    Systematically exploits cooperation patterns while maintaining strategic ambiguity.
    Identifies cooperators, detects tit-for-tat, and shifts to defection in end-game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num >= self.r - 2 and round_num < self.r - 1:
            return Action.D
        if round_num == self.r - 1:
            global_coop_rate = self._calculate_global_coop_rate(history)
            return Action.C if global_coop_rate > 0.5 else Action.D
        recent_coop_rate = self._calculate_recent_coop_rate(history)
        global_coop_rate = self._calculate_global_coop_rate(history)
        threshold = 0.5 - 0.1 * round_num / self.r
        if recent_coop_rate > threshold:
            return Action.D
        if self._detect_tit_for_tat(history):
            return Action.D
        if self._detect_unconditional_cooperator(history):
            return Action.D
        if global_coop_rate > 0.6:
            return Action.D
        payoff_rank = self._calculate_payoff_rank(history)
        if payoff_rank < self.n / 2:
            return Action.C if random.random() < 0.3 else Action.D
        elif payoff_rank > 3 * self.n / 4:
            return Action.D
        elif round_num > self.r * 0.7:
            return Action.D if random.random() < 0.7 else Action.C
        return Action.D

    def _calculate_recent_coop_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate in last 3 rounds."""
        rounds_elapsed = len(history.my_actions)
        lookback = min(3, rounds_elapsed)
        if lookback == 0:
            return 0.0
        recent_cooperators = np.sum(history.opponent_actions[-lookback:, :])
        recent_total = lookback * self.n
        return recent_cooperators / recent_total if recent_total > 0 else 0.0

    def _calculate_global_coop_rate(self, history: PlayerHistory) -> float:
        """Calculate overall cooperation rate across all history."""
        total_cooperators = np.sum(history.opponent_actions)
        rounds_elapsed = len(history.my_actions)
        total_possible = rounds_elapsed * self.n
        return total_cooperators / total_possible if total_possible > 0 else 0.0

    def _detect_tit_for_tat(self, history: PlayerHistory) -> bool:
        """Detect if an opponent is playing tit-for-tat."""
        rounds_elapsed = len(history.my_actions)
        if rounds_elapsed < 2:
            return False
        my_prev_action = history.my_actions[-1]
        for opponent_idx in range(self.n - 1):
            opponent_action = history.opponent_actions[-1, opponent_idx]
            opponent_prev_action = history.opponent_actions[-2, opponent_idx]
            if opponent_prev_action == my_prev_action:
                if not my_prev_action:
                    return True
        return False

    def _detect_unconditional_cooperator(self, history: PlayerHistory) -> bool:
        """Detect if any opponent is an unconditional cooperator."""
        rounds_elapsed = len(history.my_actions)
        if rounds_elapsed < 2:
            return False
        for opponent_idx in range(self.n - 1):
            opponent_history = history.opponent_actions[:, opponent_idx]
            if np.all(opponent_history):
                return True
        return False

    def _calculate_payoff_rank(self, history: PlayerHistory) -> float:
        """Calculate this player's payoff rank relative to opponents."""
        my_payoff = np.sum(history.my_payoffs)
        if len(history.my_payoffs) == 0:
            return 0.0
        opponent_payoffs = np.sum(history.opponent_payoffs, axis=0)
        rank = sum((1 for opp_payoff in opponent_payoffs if opp_payoff > my_payoff))
        return rank

class Strategy_EXPLOITATIVE_154(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Always defects to maximize payoff extraction from cooperators while avoiding
    losses to defectors. Defection is dominant across all game states.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        total_cooperations = np.sum(history.my_actions)
        total_opponent_cooperations = np.sum(history.opponent_actions)
        total_observations = current_round * n
        return Action.D

class Strategy_EXPLOITATIVE_155(BaseStrategy):
    """
    Conditional Parasitism with Adaptive Defection: Exploits cooperators through
    strategic defection while maintaining just enough cooperation to sustain the
    exploitation pool. Transitions to pure defection in endgame.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.m = max(1, min(3, self.r // 2))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num >= self.r - 3 or round_num == self.r - 1:
            return Action.D
        rounds_to_check = min(self.m, round_num)
        cooperators_history = history.opponent_actions[-rounds_to_check:, :]
        avg_cooperators = np.mean(cooperators_history)
        coop_rate = avg_cooperators
        if round_num >= 2:
            recent_rounds = history.opponent_actions[-2:, :]
            all_defected = np.all(recent_rounds == False)
            if all_defected:
                return Action.D
        if coop_rate < 0.3:
            return Action.D
        if coop_rate >= 0.75:
            if random.random() < 0.2:
                return Action.C
            else:
                return Action.D
        if random.random() < 0.15:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_156(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism.

    Exploits the Public Goods Game by consistently defecting while adaptively
    monitoring cooperation rates. Occasionally cooperates in mid-to-late game
    with high cooperation to maintain plausible deniability, but fundamentally
    prioritizes free-riding on others' contributions.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_high = 0.4
        self.threshold_low = 0.15
        self.cooperation_probability = 0.3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        previous_round_idx = current_round - 1
        cooperators_last_round = int(sum(history.opponent_actions[previous_round_idx, :]))
        coop_rate = cooperators_last_round / n
        is_odd_round = (current_round + 1) % 2 == 1
        past_midpoint = current_round > r / 2
        if is_odd_round and coop_rate > 0.5 and past_midpoint:
            random_value = random.random()
            if random_value < self.cooperation_probability:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_157(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Exploits the asymmetry in public goods payoffs by always defecting.
    Dynamically parasitizes cooperative behavior when the public good value
    exceeds the exploitation threshold (k/n - ), otherwise defects to avoid
    being exploited. Implements subgame perfect play with no cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.exploitation_threshold = game_description.k / game_description.n_players - 0.05

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        prev_round_cooperators = int(sum(history.opponent_actions[-1, :]))
        cooperation_rate = prev_round_cooperators / self.game_description.n_players
        return Action.D

class Strategy_EXPLOITATIVE_158(BaseStrategy):
    """
    Adaptive Parasitism: An exploitative strategy that systematically defects
    to free-ride on cooperators while minimizing contribution costs.

    Core mechanism: Always defect, with special attention to:
    - Round 1: Defect to establish baseline
    - Rounds 2 to r-2: Defect based on observed cooperation rate thresholds
    - Final rounds: Unconditional defection (no future consequences)

    The strategy exploits the Nash equilibrium of mutual defection while
    extracting surplus when opponents irrationally cooperate.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold_high = 0.6
        self.threshold_low = 0.3
        if self.n_rounds > 20:
            self.threshold_high = 0.5
        if self.k < 1.5:
            self.threshold_high = 0.7
        elif self.k > self.n_players - 1:
            self.threshold_low = 0.2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        total_previous_rounds = current_round
        all_cooperations = np.sum(history.opponent_actions[:current_round, :])
        total_possible_cooperations = total_previous_rounds * self.n_players
        observed_cooperation_rate = all_cooperations / total_possible_cooperations if total_possible_cooperations > 0 else 0.0
        if observed_cooperation_rate > self.threshold_high:
            return Action.D
        elif observed_cooperation_rate > self.threshold_low:
            endgame_threshold = 0.8
            if current_round > self.n_rounds * endgame_threshold:
                return Action.D
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_159(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism.

    Core strategy: Default to defection to exploit cooperators' contributions.
    Occasionally probe with cooperation only when environment shows high cooperation,
    player is below average payoff, and enough rounds remain.
    Always defect in terminal rounds (1st, last, and penultimate).
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.cooperation_threshold_high = 0.65
        self.probe_interval = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.n_rounds - 1:
            return Action.D
        if round_num == self.n_rounds - 2:
            return Action.D
        rounds_elapsed = round_num
        total_action_slots = self.n_players * rounds_elapsed
        my_cooperations = np.sum(history.my_actions[:round_num])
        all_opponent_cooperations = np.sum(history.opponent_actions[:round_num, :])
        total_cooperations = my_cooperations + all_opponent_cooperations
        cooperation_rate = total_cooperations / total_action_slots if total_action_slots > 0 else 0.0
        my_total_payoff = np.sum(history.my_payoffs[:round_num])
        my_avg_payoff = my_total_payoff / rounds_elapsed if rounds_elapsed > 0 else 0.0
        all_payoffs = np.concatenate([[my_total_payoff], np.sum(history.opponent_payoffs[:round_num, :], axis=0)])
        global_avg_payoff = np.mean(all_payoffs) if len(all_payoffs) > 0 else 0.0
        rounds_remaining = self.n_rounds - round_num
        if cooperation_rate > self.cooperation_threshold_high and my_avg_payoff < global_avg_payoff and (rounds_remaining > 2):
            if round_num % self.probe_interval == 0:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_160(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Core mechanism: Default to defection, but conditionally cooperate when the
    observed cooperation rate exceeds k/n (the threshold where public good payoff
    exceeds private payoff for defectors). Always defect on the final round.
    Exploits cooperators by free-riding on their contributions.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        previous_round_idx = current_round - 1
        cooperators_previous = sum(history.opponent_actions[previous_round_idx, :]) + (1 if history.my_actions[previous_round_idx] else 0)
        coop_rate_previous = cooperators_previous / self.n_players
        if coop_rate_previous > self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_161(BaseStrategy):
    """
    Adaptive Free-Riding with Opportunistic Exploitation strategy for N-Player Public Goods Game.

    Core philosophy: Maximize personal payoff by exploiting the contribution patterns of others.
    Always defect to free-ride on others' contributions while avoiding cooperation costs.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        previous_round_idx = state.round_number - 1
        cooperators_last_round = int(sum(history.opponent_actions[previous_round_idx, :]))
        coop_rate = cooperators_last_round / self.game_description.n_players
        return Action.D

class Strategy_EXPLOITATIVE_162(BaseStrategy):
    """
    Adaptive Predation with Conditional Parasitism: An exploitative strategy that
    cooperates in round 1 to probe, defects when cooperators are present above the
    k/n threshold, cycles reputation when payoff is below average, and defects in
    the final round. Designed to maximize individual payoff by exploiting cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.r - 1:
            return Action.D
        prev_round_idx = round_num - 1
        opponent_cooperators_prev = np.sum(history.opponent_actions[prev_round_idx, :])
        own_action_prev = history.my_actions[prev_round_idx]
        total_cooperators_prev = opponent_cooperators_prev + (1 if own_action_prev else 0)
        cooperation_rate_prev = total_cooperators_prev / self.n
        threshold = self.k / self.n
        if cooperation_rate_prev > threshold:
            return Action.D
        else:
            own_payoff_prev = history.my_payoffs[prev_round_idx]
            avg_payoff_prev = (np.sum(history.opponent_payoffs[prev_round_idx, :]) + own_payoff_prev) / self.n
            if own_payoff_prev < avg_payoff_prev:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_163(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Opportunism

    Core philosophy: Maximize personal payoff by exploiting the asymmetry between
    defection rewards and cooperation costs. Defect unless exploitation opportunities
    are available, then extract maximum value from any cooperation that occurs.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.cooperation_threshold = 0.4

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round >= self.n_rounds - 2:
            return Action.D
        previous_round_idx = current_round - 1
        cooperators_prev_round = int(np.sum(history.opponent_actions[previous_round_idx, :]))
        cooperation_rate_prev = cooperators_prev_round / self.n_players
        if cooperation_rate_prev >= self.cooperation_threshold:
            expected_payoff_c = self.k / self.n_players * (cooperators_prev_round + 1)
            expected_payoff_d = 1.0 + self.k / self.n_players * cooperators_prev_round
            if expected_payoff_d > expected_payoff_c:
                return Action.D
            else:
                return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_164(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Opportunistic Exploitation

    Core philosophy: Always defect to maximize individual payoff. Defection is individually
    rational when others cooperate (exploitation), and also rational when others defect
    (avoiding waste). This strategy never voluntarily cooperates.

    Decision logic:
    - Round 1: DEFECT (probe/information gathering)
    - Rounds 2 to r-1: DEFECT (exploit if cooperation observed, avoid waste if not)
    - Final round: DEFECT (no future consequences, extract maximum value)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.k - 1) / self.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        previous_round_idx = state.round_number - 1
        cooperators_in_previous = sum(history.opponent_actions[previous_round_idx, :])
        cooperation_rate = cooperators_in_previous / self.n_players
        if state.round_number == self.n_rounds - 1:
            return Action.D
        if cooperation_rate >= self.threshold:
            return Action.D
        else:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_165(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Core philosophy: Exploit the asymmetry of the public goods game by consistently
    defecting to capture the full private endowment while freeloading on others'
    cooperation. Treats cooperation as a resource to extract, not reciprocate.

    Decision rules:
    - Round 0 (initialization): DEFECT to establish baseline
    - Rounds 1 to r-2 (exploitation): DEFECT regardless of cooperation rate
    - Round r-1 (final round): DEFECT for endgame extraction
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_166(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Exploitation

    Core philosophy: Maximize personal payoff by exploiting cooperative players
    while minimizing losses from defectors. Always defect because:
    1. Defection yields higher individual payoff whenever any player cooperates
    2. Against pure defectors, mutual defection is stable at payoff 1
    3. In the final round, defection strictly dominates (no retaliation consequences)
    4. Defection is the unique dominant strategy in normal form analysis
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number < self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_167(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Exploitation

    Phases:
    1. PROBING (rounds 1-3): Defect to classify opponents
    2. EXPLOITATION (rounds 4 to r-2): Defect based on opponent types and cooperation rates
    3. END GAME (last 1-2 rounds): Defect to extract maximum final value
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.opponent_defections = None

    def _classify_opponents(self, history: PlayerHistory) -> dict:
        """Classify each opponent as Sucker, Unpredictable, or Defector based on probing phase."""
        classification = {}
        probing_rounds = min(3, self.n_rounds)
        for opponent_idx in range(self.n_players - 1):
            defection_count = 0
            for round_idx in range(probing_rounds):
                if not history.opponent_actions[round_idx, opponent_idx]:
                    defection_count += 1
            if defection_count < 1:
                classification[opponent_idx] = 'Sucker'
            elif defection_count <= 2:
                classification[opponent_idx] = 'Unpredictable'
            else:
                classification[opponent_idx] = 'Defector'
        return classification

    def _count_suckers(self, classification: dict) -> int:
        """Count how many opponents are classified as Suckers."""
        return sum((1 for opp_type in classification.values() if opp_type == 'Sucker'))

    def _cooperation_threshold(self) -> float:
        """
        Calculate threshold: (n * k/2) / (1 + k/n)
        Above this threshold, cooperation becomes collectively rational but individually suboptimal.
        """
        numerator = self.n_players * self.k / 2.0
        denominator = 1.0 + self.k / self.n_players
        return numerator / denominator

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num <= 2:
            return Action.D
        if round_num >= self.n_rounds - 2:
            return Action.D
        if history is not None:
            last_round_idx = round_num - 1
            if last_round_idx >= 0:
                cooperators_last_round = int(np.sum(history.opponent_actions[last_round_idx, :]))
            else:
                cooperators_last_round = 0
            if round_num == 3:
                classification = self._classify_opponents(history)
                sucker_count = self._count_suckers(classification)
            else:
                classification = self._classify_opponents(history)
                sucker_count = self._count_suckers(classification)
            threshold = self._cooperation_threshold()
            if sucker_count > self.n_players * 0.5:
                return Action.D
            if cooperators_last_round > threshold:
                return Action.D
            if cooperators_last_round < 2 and self.n_rounds - round_num < 3:
                return Action.D
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_168(BaseStrategy):
    """
    Adaptive Predation: An exploitative strategy that classifies opponents
    and ruthlessly extracts value through defection across all phases.

    Phase 1 (Rounds 0-2): Information gathering via defection
    Phase 2 (Rounds 3 to r-2): Exploitation phase - always defect
    Phase 3 (Rounds r-1 to r): Endgame - always defect
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.opponent_classifications = {}

    def _classify_opponent(self, opponent_idx: int, history: PlayerHistory) -> str:
        """
        Classify opponent based on their action history.

        Returns one of:
        - "unconditional_cooperator": Cooperated in round 0
        - "conditional_cooperator": Didn't cooperate in round 0, but did later
        - "defector": Never cooperates
        - "punisher": Defects after being defected against
        """
        opponent_actions = history.opponent_actions[:, opponent_idx]
        if len(opponent_actions) > 0 and opponent_actions[0]:
            return 'unconditional_cooperator'
        if np.any(opponent_actions):
            return 'conditional_cooperator'
        if len(history.my_actions) > 0:
            my_defections = ~history.my_actions
            if np.any(my_defections) and np.any(opponent_actions[my_defections]):
                return 'punisher'
        return 'defector'

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        """
        Execute Adaptive Predation strategy.

        Always defect across all phases:
        - Rounds 0-2: Defect to gather information
        - Rounds 3 to r-2: Defect to exploit identified targets
        - Rounds r-1 to r: Defect for final extraction with no consequences
        """
        round_number = state.round_number
        total_rounds = self.game_description.n_rounds
        if round_number <= 2:
            return Action.D
        if round_number >= total_rounds - 2:
            return Action.D
        for opponent_idx in range(self.game_description.n_players - 1):
            if opponent_idx not in self.opponent_classifications:
                opponent_type = self._classify_opponent(opponent_idx, history)
                self.opponent_classifications[opponent_idx] = opponent_type
        return Action.D

class Strategy_EXPLOITATIVE_169(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    Maximizes personal payoff by exploiting cooperative players while minimizing losses.
    - Round 1: Cooperate to gather information
    - Mid-rounds: Cooperate only if observed cooperation rate exceeds adaptive threshold
    - Final quarter: Always defect to exploit remaining cooperators without consequence
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        if self.k < (self.n_players + 1) / 2:
            self.threshold = 0.6
        else:
            self.threshold = 0.4
        self.final_rounds_count = math.ceil(self.n_rounds / 4)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        rounds_remaining = self.n_rounds - current_round
        if rounds_remaining <= self.final_rounds_count:
            return Action.D
        total_opponent_cooperations = np.sum(history.opponent_actions[:current_round, :])
        total_possible_cooperations = (self.n_players - 1) * current_round
        observed_coop_rate = total_opponent_cooperations / total_possible_cooperations
        if observed_coop_rate < 0.1:
            return Action.D
        if current_round > 0:
            last_round_cooperations = np.sum(history.opponent_actions[current_round - 1, :])
            if last_round_cooperations == 0:
                return Action.D
        if observed_coop_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_170(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Defects by default, exploiting cooperators while matching defectors.
    Uses adaptive thresholds based on game parameters to decide when cooperation
    is profitable. Cooperates probabilistically in mid-game when cooperation rates
    are moderate, but always defects in round 1 and final round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self._calculate_thresholds()

    def _calculate_thresholds(self):
        """Calculate threshold_high, threshold_low, and p_strategic based on game parameters."""
        denominator = 1.0 - self.k / self.n
        if denominator > 0:
            self.threshold_high = self.k / self.n / denominator
        else:
            self.threshold_high = 1.0
        self.threshold_high = min(1.0, max(0.0, self.threshold_high))
        self.threshold_low = self.k / self.n * 0.3
        if self.n <= 3:
            self.threshold_low = self.k / self.n * 0.5
        self.p_strategic = min(0.15, self.k / self.n)

    def _get_weighted_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate cooperation rate of opponents with memory decay.
        Recent behavior weighted more heavily than distant history.
        """
        if current_round < 1:
            return 0.0
        others_last_round = sum(history.opponent_actions[current_round - 1, :]) / (self.n - 1)
        if current_round > 1:
            earlier_rounds = history.opponent_actions[:current_round - 1, :]
            avg_earlier = np.mean(earlier_rounds)
            weighted_coop = 0.7 * others_last_round + 0.3 * avg_earlier
        else:
            weighted_coop = others_last_round
        return weighted_coop

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        weighted_cooperation = self._get_weighted_cooperation_rate(history, current_round)
        if weighted_cooperation >= self.threshold_high:
            return Action.D
        elif weighted_cooperation >= self.threshold_low:
            if random.random() < self.p_strategic:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_171(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Exploitation

    Core approach: Always defect to exploit cooperators while avoiding contribution costs.
    - Round 0: Defect to probe the population
    - Rounds 1 to r-2: Defect regardless of cooperation rate (dominant strategy)
    - Round r-1: Defect in final round (no future punishment possible)

    This strategy maximizes payoff by capturing public good benefits without contributing,
    relying on the strict dominance of defection when k < n.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.n_rounds - 1:
            return Action.D
        if history is not None and state.round_number > 0:
            cooperators_last_round = np.sum(history.opponent_actions[state.round_number - 1, :])
            cooperation_rate = cooperators_last_round / (self.n_players - 1) if self.n_players > 1 else 0.0
            k_over_n = self.k / self.n_players
            if cooperation_rate >= k_over_n:
                return Action.D
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_172(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core approach: Always defect to exploit cooperators and avoid being exploited.
    - Phase 1 (Rounds 0-2): Defect to establish baseline
    - Phase 2 (Rounds 3 to r-3): Defect regardless of cooperation rate
    - Phase 3 (Final 2 rounds): Defect to maximize endgame payoff

    This strategy parasitizes naive cooperators while matching mutual defection
    against rational opponents.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num <= 2:
            return Action.D
        if round_num < self.n_rounds - 2:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_173(BaseStrategy):
    """
    Adaptive Predation Strategy for N-Player Public Goods Game.

    Exploits the asymmetry of public goods games by:
    1. Probing in early rounds to identify cooperators
    2. Adaptively exploiting based on opponent cooperation patterns
    3. Defecting in final rounds when reputation cost is zero
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        probing_threshold = max(3, math.ceil(0.2 * self.n_rounds))
        if round_num < probing_threshold:
            return Action.D
        if round_num >= self.n_rounds - 2:
            return Action.D
        if self.n_players == 2:
            return Action.D
        coop_rates = np.zeros(self.n_players - 1)
        for opp_idx in range(self.n_players - 1):
            cooperations = np.sum(history.opponent_actions[:round_num, opp_idx])
            coop_rates[opp_idx] = cooperations / round_num if round_num > 0 else 0.0
        exploitation_scores = coop_rates * (1.0 - coop_rates)
        avg_exploitation = np.mean(exploitation_scores)
        total_coop_by_all = np.sum(history.opponent_actions[:round_num, :])
        field_coop_rate = total_coop_by_all / (round_num * (self.n_players - 1)) if round_num > 0 else 0.0
        if avg_exploitation > 0.4:
            return Action.D
        elif avg_exploitation <= 0.4 and field_coop_rate >= 0.5:
            if round_num % 3 == 0:
                recent_defectors = np.sum(history.opponent_actions[round_num - 1, :] == 0)
                if recent_defectors > 0:
                    return Action.D
            return Action.C
        else:
            recent_defectors = np.sum(history.opponent_actions[round_num - 1, :] == 0)
            if recent_defectors > self.n_players / 2:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_174(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Retaliation

    Maximizes personal payoff by defaulting to defection while strategically
    cooperating only when it provides direct advantage through opponent punishment
    or payoff extraction.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        prev_round_idx = current_round - 1
        coop_count = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        coop_rate = coop_count / self.n
        threshold_high = self.k / self.n + 0.3
        threshold_medium = self.k / self.n
        threshold_low = self.k / self.n * 0.5
        discount_factor = min(0.3, self.k / self.n)
        if coop_rate >= threshold_high:
            return Action.D
        elif coop_rate >= threshold_medium:
            return Action.D
        elif coop_rate < threshold_low:
            return Action.D
        else:
            rand_value = random.random()
            if rand_value < coop_rate * discount_factor:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_175(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core philosophy: Always defect to exploit the public goods game's fundamental asymmetry.
    Defection is the strictly dominant strategy when k < n. This strategy:
    1. Defaults to defection in every round
    2. Tracks opponent cooperation density to profile population
    3. Maximizes payoff by free-riding on others' contributions

    While the strategy always defects, it maintains adaptive awareness of cooperation
    rates to confirm the exploitability of the population.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.k = game_description.k
        self.n_rounds = game_description.n_rounds
        self.coop_threshold = (self.k - 1) / (self.n_players - 1)
        self.minimum_viable = 1 / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        """
        Primary decision rule: Unconditional defection with adaptive profiling.

        Defection is the strictly dominant strategy because:
        - Defect payoff: 1 + (k/n)  cooperators
        - Cooperate payoff: 0 + (k/n)  cooperators
        - Defect strictly dominates in every round when k < n

        We track cooperation density to profile the population, but always defect.
        """
        if state.round_number == 0:
            return Action.D
        if history is not None:
            previous_round_idx = state.round_number - 1
            cooperators_last_round = np.sum(history.opponent_actions[previous_round_idx, :])
            coop_density = cooperators_last_round / self.n_players
            if coop_density >= self.coop_threshold:
                pass
            elif coop_density >= self.minimum_viable:
                pass
            else:
                pass
        return Action.D

class Strategy_EXPLOITATIVE_176(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Exploitation

    This strategy exploits the asymmetry in the Public Goods Game by:
    1. Always defecting to gain private endowment
    2. Tracking opponents who have ever cooperated
    3. Continuously defecting against all opponents, especially those who cooperate
    4. Maximizing payoff by capturing others' contributions while keeping private endowment
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_observed = {}

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        n_opponents = self.game_description.n_players - 1
        if not self.cooperation_observed:
            for opponent_idx in range(n_opponents):
                self.cooperation_observed[opponent_idx] = False
        for round_idx in range(state.round_number):
            for opponent_idx in range(n_opponents):
                if history.opponent_actions[round_idx, opponent_idx]:
                    self.cooperation_observed[opponent_idx] = True
        return Action.D

class Strategy_EXPLOITATIVE_177(BaseStrategy):
    """
    Exploitative strategy: Adaptive Defection with Selective Exploitation.

    Core approach:
    - Always defect in round 1 and final round (no reputation effects)
    - In middle rounds, defect unless cooperation rate exceeds an adaptive threshold
    - The threshold decays over time, becoming more exploitative as the game ends
    - Systematically free-rides on cooperative players while avoiding sucker payoffs
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        prev_round_idx = current_round - 1
        opponent_actions_prev = history.opponent_actions[prev_round_idx, :]
        cooperators_prev = np.sum(opponent_actions_prev)
        cooperation_rate_prev = cooperators_prev / self.n_players
        baseline_threshold = self.k / self.n_players
        decay_term = (self.n_rounds - current_round) / (2.0 * self.n_rounds)
        threshold = baseline_threshold + decay_term
        if cooperation_rate_prev >= threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_178(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Core approach:
    1. Round 0 (first round): COOPERATE to signal benignity and probe others' cooperation
    2. Rounds 1 to r-2 (middle rounds): DEFECT if cooperation_rate_last_round > threshold, else DEFECT
       (i.e., always defect in middle rounds since threshold = k/n and cooperation is exploitable)
    3. Round r-1 (final round): DEFECT for final extraction with no retaliation risk

    Threshold = k/n (break-even point for public good value vs. contribution cost)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        n_rounds = self.game_description.n_rounds
        if round_number == 0:
            return Action.C
        if round_number == n_rounds - 1:
            return Action.D
        cooperators_last_round = np.sum(history.opponent_actions[round_number - 1, :])
        cooperation_rate_last_round = cooperators_last_round / self.game_description.n_players
        if cooperation_rate_last_round > self.threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_179(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Exploitation (ADCE)

    Core approach: Always defect to capture private value while exploiting others'
    contributions to the public good. Tracks opponent cooperation rates but maintains
    defection as the dominant strategy across all game phases.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.opponent_cooperation_counts = np.zeros(game_description.n_players - 1)
        self.total_rounds_played = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        if current_round == 0:
            return Action.D
        if current_round >= r - 2:
            return Action.D
        if self.total_rounds_played > 0:
            coop_rate = float(np.sum(self.opponent_cooperation_counts)) / ((n - 1) * self.total_rounds_played)
        else:
            coop_rate = 0.0
        action = Action.D
        if history is not None and current_round > 0:
            recent_opponent_actions = history.opponent_actions[current_round - 1, :]
            self.opponent_cooperation_counts += recent_opponent_actions.astype(np.float64)
            self.total_rounds_played = current_round
        return action

class Strategy_EXPLOITATIVE_180(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Exploitation

    Always defects to maximize personal payoff by exploiting cooperative players.
    Monitors observed cooperation rates and maintains defection as the dominant strategy
    regardless of opponent behavior. This strategy is robust against pure cooperators,
    pure defectors, and conditional cooperators.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.threshold = (self.n - self.k) / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        previous_round_index = state.round_number - 1
        cooperators_previous_round = sum(history.opponent_actions[previous_round_index, :])
        observed_coop_rate = cooperators_previous_round / self.n
        return Action.D

class Strategy_EXPLOITATIVE_181(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    This strategy defects in the first and last rounds, and in middle rounds
    conditionally cooperates based on whether the cooperation rate in the
    previous round exceeds the threshold (k-1)/k. The threshold represents
    the breakeven point where public goods returns justify the cost of cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = (game_description.k - 1) / game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        previous_round_index = current_round - 1
        cooperators_in_previous = sum(history.opponent_actions[previous_round_index, :])
        if history.my_actions[previous_round_index]:
            cooperators_in_previous += 1
        coop_rate = cooperators_in_previous / n
        if coop_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_182(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    Always defects to maximize personal payoff by exploiting the asymmetry between
    defection and cooperation. Defection yields immediate gains while cooperation yields
    delayed, diluted returns. The strategy systematically exploits any cooperators while
    avoiding losses in all-defect scenarios.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_183(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Core philosophy: Treat cooperation as an exploitable resource to harvest.
    - Round 1: DEFECT (gather intelligence)
    - Rounds 2 to r-1: DEFECT if cooperation_rate > threshold (exploit cooperators), else DEFECT (no pool to exploit)
    - Final round: DEFECT (maximum extraction with no future consequences)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = 0.7 * (self.k / self.n_players)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        cooperation_last_round = np.sum(history.opponent_actions[round_number - 1, :]) / self.n_players
        if cooperation_last_round > self.threshold:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_184(BaseStrategy):
    """
    Adaptive Predation Strategy: Exploitative approach that defects strategically
    to extract maximum value from cooperative players while remaining robust against
    defectors. Uses reconnaissance to identify opponent types, then exploits cooperators
    systematically until the endgame.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number < 2:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        previous_round_cooperators = int(np.sum(history.opponent_actions[round_number - 1, :]))
        if_defect_payoff = 1.0 + self.k / self.n_players * previous_round_cooperators
        if_cooperate_payoff = self.k / self.n_players * (previous_round_cooperators + 1)
        if if_cooperate_payoff > if_defect_payoff:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_185(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core approach: Always defect to maximize personal payoff by free-riding on others'
    contributions while avoiding the costs of cooperation. This pure defection strategy
    is individually rational regardless of opponent behavior.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_upper = 0.5
        self.threshold_lower = 0.2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        prev_round_idx = state.round_number - 1
        cooperators_prev = np.sum(history.opponent_actions[prev_round_idx, :])
        cooperation_rate = cooperators_prev / self.game_description.n_players
        if cooperation_rate > self.threshold_lower:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_186(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    This strategy maximizes personal payoff by free-riding on others' contributions.
    It defects by default, exploiting the asymmetry in the public goods game where
    defectors earn more than cooperators when others contribute.

    Core logic:
    - Round 1: Defect (establish defector type)
    - Final round: Defect (no future retaliation)
    - Middle rounds: Defect if cooperation rate > k/n (exploit excess cooperation),
      otherwise defect (cooperation isn't worthwhile)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        previous_round_index = current_round - 1
        opponent_cooperations_prev = history.opponent_actions[previous_round_index, :]
        num_cooperators_prev = int(np.sum(opponent_cooperations_prev))
        coop_rate = num_cooperators_prev / self.n_players
        threshold = self.k / self.n_players
        return Action.D

class Strategy_EXPLOITATIVE_187(BaseStrategy):
    """
    Adaptive Predation Strategy: Exploits cooperative tendencies by defecting
    consistently while monitoring cooperation rates. Always defects to maximize
    free-rider gains from public goods contributions.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        rounds_remaining = self.game_description.n_rounds - state.round_number
        if rounds_remaining <= 2:
            return Action.D
        last_round_cooperators = int(sum(history.opponent_actions[-1, :]))
        cooperation_rate = last_round_cooperators / self.game_description.n_players
        exploitation_threshold = (self.game_description.k - 1) / (self.game_description.n_players - 1)
        return Action.D

class Strategy_EXPLOITATIVE_188(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    This strategy prioritizes personal payoff maximization by exploiting the fundamental
    asymmetry in the payoff structure. It defects ruthlessly except in rare cases of
    near-universal cooperation, and always defects in the final round and early rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.n_rounds - 1:
            return Action.D
        total_rounds_played = round_num
        total_opponent_plays = (self.n_players - 1) * total_rounds_played
        if total_opponent_plays == 0:
            return Action.D
        total_cooperations = np.sum(history.opponent_actions[:round_num, :])
        cooperation_rate = total_cooperations / total_opponent_plays
        rounds_remaining = self.n_rounds - round_num
        if rounds_remaining <= math.ceil(0.3 * self.n_rounds):
            return Action.D
        if cooperation_rate > 0.9:
            if random.random() < 0.01:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_189(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Maximizes personal payoff by exploiting cooperators while avoiding mutual defection traps.
    Uses defection as default, with strategic signaling only when defection becomes unprofitable.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.consecutive_low_coop_rounds = 0
        self.threshold = game_description.k / game_description.n_players + 0.01

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        current_round = state.round_number
        if current_round >= r - 2:
            return Action.D
        cooperators_prev = sum(history.opponent_actions[current_round - 1, :])
        coop_rate_prev = cooperators_prev / n
        if coop_rate_prev > self.threshold:
            self.consecutive_low_coop_rounds = 0
            return Action.D
        if coop_rate_prev < k / n:
            self.consecutive_low_coop_rounds += 1
        else:
            self.consecutive_low_coop_rounds = 0
        if self.consecutive_low_coop_rounds >= 2 and current_round < r - 2:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_190(BaseStrategy):
    """
    Parasite with Adaptive Mimicry: An exploitative strategy that defects by default
    and only considers cooperation based on an adaptive threshold of opponent cooperation.
    The strategy systematically free-rides on others' contributions while avoiding the
    cost of cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.n_rounds - 1:
            return Action.D
        previous_round_idx = state.round_number - 1
        cooperators_last_round = np.sum(history.opponent_actions[previous_round_idx, :])
        coop_rate = cooperators_last_round / self.n_players
        base_threshold = 1.0 / (self.k - 1.0)
        temporal_adjustment = 0.1 * (state.round_number / self.n_rounds)
        threshold = base_threshold + temporal_adjustment
        return Action.D

class Strategy_EXPLOITATIVE_191(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    This strategy maximizes personal payoff by exploiting cooperators while avoiding
    mutual defection traps. It uses threshold-based logic to parasitize cooperation
    when beneficial and defaults to mutual defection otherwise.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.k = game_description.k
        self.n_rounds = game_description.n_rounds
        self.exploitation_threshold = 0.6 + self.k / self.n_players
        self.defection_collapse_threshold = 0.2
        self.expected_defection_payoff = 1.0 + self.k / self.n_players * (self.n_players * self.exploitation_threshold)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        last_round_idx = current_round - 1
        cooperators_last_round = sum(history.opponent_actions[last_round_idx, :])
        cooperation_rate = cooperators_last_round / self.n_players
        if cooperation_rate >= self.exploitation_threshold:
            return Action.D
        if cooperation_rate <= self.defection_collapse_threshold:
            return Action.D
        my_last_payoff = history.my_payoffs[last_round_idx]
        if my_last_payoff < self.expected_defection_payoff:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_192(BaseStrategy):
    """
    Exploitative Strategy: Conditional Defection with Adaptive Retaliation

    Exploits the fundamental asymmetry in the payoff structure by identifying and punishing
    cooperators while maximizing personal payoff through strategic defection. Uses conditional
    defection based on cooperation rates and adaptive retaliation with stochastic elements.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.p_persist = 0.85

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == r - 1:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[round_num - 1, :]))
        coop_rate = cooperators_last_round / n
        threshold = k / n
        if coop_rate >= threshold:
            return Action.D
        elif random.random() < self.p_persist:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_193(BaseStrategy):
    """
    Adaptive Predation: An exploitative strategy that defects consistently,
    with adaptive monitoring of opponent cooperation rates to maximize
    free-riding on others' contributions to the public good.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        opponent_cooperation_rates = self._calculate_opponent_cooperation_rates(history)
        total_cooperators_last_round = np.sum(history.opponent_actions[current_round - 1, :])
        max_cooperation_rate = np.max(opponent_cooperation_rates) if len(opponent_cooperation_rates) > 0 else 0
        if max_cooperation_rate > 0.65:
            return Action.D
        expected_public_good = self.k / self.n * total_cooperators_last_round
        if expected_public_good > 0.5:
            return Action.D
        avg_cooperation_rate = np.mean(opponent_cooperation_rates) if len(opponent_cooperation_rates) > 0 else 0
        if avg_cooperation_rate < 0.3:
            return Action.D
        return Action.D

    def _calculate_opponent_cooperation_rates(self, history: PlayerHistory) -> NDArray[np.float64]:
        """
        Calculate the cooperation rate for each opponent across all previous rounds.
        Returns array of cooperation rates indexed by opponent.
        """
        n_rounds_played = len(history.my_actions)
        n_opponents = self.n - 1
        cooperation_rates = np.zeros(n_opponents)
        if n_rounds_played == 0:
            return cooperation_rates
        for opponent_idx in range(n_opponents):
            cooperations = np.sum(history.opponent_actions[:n_rounds_played, opponent_idx])
            cooperation_rates[opponent_idx] = cooperations / n_rounds_played
        return cooperation_rates

class Strategy_EXPLOITATIVE_194(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    A ruthlessly exploitative strategy that defects by default and only cooperates
    conditionally when it appears strategically beneficial. Maximizes personal payoff
    by exploiting cooperators while avoiding wasted cooperation in defection-dominated
    environments.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        window_size = min(5, max(1, self.r // 3))
        start_idx = max(0, current_round - window_size)
        end_idx = current_round
        if end_idx > start_idx:
            recent_window = history.opponent_actions[start_idx:end_idx, :]
            cooperation_counts = np.sum(recent_window)
            max_possible_cooperations = (self.n - 1) * (end_idx - start_idx)
            recent_coop_rate = cooperation_counts / max_possible_cooperations if max_possible_cooperations > 0 else 0
        else:
            recent_coop_rate = 0
        equilibrium_threshold = self.k / self.n * 0.7
        moderate_threshold = self.k / self.n * 0.3
        if recent_coop_rate > equilibrium_threshold:
            return Action.D
        elif recent_coop_rate > moderate_threshold:
            my_recent_payoff = np.mean(history.my_payoffs[start_idx:end_idx]) if end_idx > start_idx else 0
            opponent_recent_payoffs = np.mean(history.opponent_payoffs[start_idx:end_idx, :]) if end_idx > start_idx else 0
            if my_recent_payoff < opponent_recent_payoffs:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_195(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation (ADCC)

    Core approach: Always defect to exploit the payoff asymmetry in the public goods game.
    Defection is individually rational regardless of others' actions, as the private payoff
    from keeping the endowment plus share of public good always exceeds cooperation's return.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.exploit_threshold = (self.k - 1) / (self.n_players - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.n_rounds - 1:
            return Action.D
        prev_round_idx = state.round_number - 1
        cooperators_prev = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        cooperation_rate_prev = cooperators_prev / self.n_players
        return Action.D

class Strategy_EXPLOITATIVE_196(BaseStrategy):
    """
    Adaptive Parasitism: An exploitative strategy that systematically defects to free-ride
    on others' contributions while avoiding costly cooperation. Tracks cooperation rates
    and adapts thresholds, but defaults to defection across all conditions since defection
    is mathematically superior in the public goods game structure.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_upper = 0.6
        self.threshold_lower = 0.2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        cooperation_rate = self._calculate_cooperation_rate(history, state.round_number)
        if cooperation_rate > self.threshold_upper:
            return Action.D
        elif cooperation_rate < self.threshold_lower:
            return Action.D
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the overall cooperation rate of opponents across all observed rounds.
        Returns a value between 0 and 1.
        """
        if current_round <= 0:
            return 0.0
        observed_actions = history.opponent_actions[:current_round, :]
        total_cooperations = np.sum(observed_actions)
        n_opponents = self.game_description.n_players - 1
        total_possible = n_opponents * current_round
        if total_possible == 0:
            return 0.0
        cooperation_rate = total_cooperations / total_possible
        return cooperation_rate

class Strategy_EXPLOITATIVE_197(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Participation

    Maximizes personal payoff by exploiting asymmetry between defection rewards and cooperation costs.
    Default strategy is to defect, with conditional cooperation only when observed cooperation rate
    is sufficiently high and the player defected in the previous round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        threshold = (self.n_players - 1) / self.n_players * 0.75
        if self.k > self.n_players * 0.9:
            threshold = (self.n_players - 1) / self.n_players * 0.9
        if self.n_rounds <= 3:
            return Action.D
        prev_round_idx = current_round - 1
        opponent_cooperators_prev = np.sum(history.opponent_actions[prev_round_idx, :])
        cooperation_rate_prev = opponent_cooperators_prev / (self.n_players - 1)
        my_action_prev = history.my_actions[prev_round_idx]
        if cooperation_rate_prev >= threshold and (not my_action_prev):
            return Action.D
        elif cooperation_rate_prev < 0.25:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_198(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism.

    This exploitative strategy maximizes personal payoff by:
    1. Always defecting (defection is dominant strategy when k < n)
    2. Parasitizing any cooperators that exist
    3. Avoiding losses when cooperation breaks down

    Core insight: Defection dominates cooperation in all scenarios within the
    public goods game constraints. This strategy unconditionally defects to
    extract maximum value from the game structure.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_199(BaseStrategy):
    """
    Predatory Opportunism: An exploitative strategy that always defects to extract value from cooperators.

    Strategy phases:
    - Rounds 0-2: Defect and observe cooperation patterns
    - Rounds 3+: Continue defecting, adapting observation of cooperator rates
    - Final round: Defect (no future punishment possible)

    Core logic: Defection strictly dominates cooperation when k/n < 1 and any cooperators exist.
    This strategy free-rides from the start, extracting maximum value while paying no cooperation cost.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round <= min(2, self.n_rounds - 1):
            return Action.D
        if current_round > 2 and history is not None:
            total_cooperators = np.sum(history.opponent_actions)
            total_rounds_played = current_round
            total_possible_cooperations = total_rounds_played * self.n_players
            avg_coop_rate = total_cooperators / total_possible_cooperations if total_possible_cooperations > 0 else 0
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_200(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core philosophy: Maximize personal payoff by always defecting to exploit
    cooperators and avoid endowment costs. Defection is the dominant strategy
    regardless of observed cooperation rates or round number.

    Decision rule: ALWAYS DEFECT
    - Round 1: No information available; defecting establishes baseline
    - Rounds 2 to r-1: Defecting dominates regardless of cooperation rate
    - Final round: No future rounds to influence; maximize extraction
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number < self.game_description.n_rounds - 1:
            total_cooperators = np.sum(history.opponent_actions[:state.round_number, :])
            total_possible_contributions = self.game_description.n_players * state.round_number
            coop_rate = total_cooperators / total_possible_contributions if total_possible_contributions > 0 else 0
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_201(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation Harvesting

    Exploits the tragedy of the commons by defecting when cooperation is detected,
    maintaining occasional cooperation to avoid being identified as a pure defector,
    and always defecting in the final round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round == self.n_rounds - 1:
            return Action.D
        prev_coop_count = int(sum(history.opponent_actions[current_round - 1, :]))
        prev_coop_rate = prev_coop_count / self.n_players
        my_defections = int(sum((1 for action in history.my_actions[:current_round] if not action)))
        my_defect_ratio = my_defections / current_round
        if self.n_players <= 3:
            coop_threshold_high = 0.66
            coop_threshold_low = 0.2
            margin_threshold = 0.35
        elif self.n_players >= 8:
            coop_threshold_high = 0.5
            coop_threshold_low = 0.15
            margin_threshold = 0.3
        else:
            coop_threshold_high = 0.4
            coop_threshold_low = 0.2
            margin_threshold = 0.35
        if current_round >= 2:
            prev_prev_coop_count = int(sum(history.opponent_actions[current_round - 2, :]))
            prev_prev_coop_rate = prev_prev_coop_count / self.n_players
            avg_coop_rate = (prev_coop_rate + prev_prev_coop_rate) / 2.0
        else:
            avg_coop_rate = prev_coop_rate
        if avg_coop_rate >= coop_threshold_high:
            return Action.D
        elif avg_coop_rate < coop_threshold_low:
            return Action.D
        elif my_defect_ratio >= 0.6:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_202(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    Maximizes personal payoff by exploiting cooperative players while minimizing losses from defectors.
    Uses conditional cooperation with randomization to create false reciprocity signals while actually free-riding.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.exploitation_threshold = (self.k - 1) / (self.n - 1)
        self.consecutive_all_defect_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round >= self.r - 2:
            if current_round == self.r - 1:
                return Action.D
            elif random.random() < 0.85:
                return Action.D
            else:
                return Action.C
        last_round_opponents = history.opponent_actions[current_round - 1, :]
        cooperation_count = int(np.sum(last_round_opponents))
        coop_rate = cooperation_count / self.n
        if coop_rate == 0:
            self.consecutive_all_defect_rounds += 1
            if self.consecutive_all_defect_rounds >= 2:
                return Action.D
        else:
            self.consecutive_all_defect_rounds = 0
        if coop_rate > self.exploitation_threshold:
            p_exploit = min(coop_rate, 0.6)
            if coop_rate > 0.9:
                p_exploit = min(p_exploit, 0.65)
            if random.random() < p_exploit:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_203(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Exploitation

    Core Philosophy: Prioritizes individual payoff maximization by exploiting the asymmetry
    between defection rewards and cooperation benefits. Always defects as the dominant strategy,
    regardless of opponent behavior or round number.

    Key Insight: Defection is strictly dominant because:
    - When opponents cooperate: Defecting yields 1 + (k/n)  m, which exceeds cooperation's (k/n)  (m+1)
    - When opponents defect: Both strategies yield low payoff, but defection is still optimal
    - The payoff difference is always 1 - k/n > 0 (since k < n)
    - No reputational concerns in a one-shot repeated game without binding commitments
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        """
        Decision rule: Always defect.

        Rationale across all cases:
        - Round 0 (opening): DEFECT - no history, establish dominance
        - Rounds 1 to r-2 (exploitation phase): DEFECT - dominant strategy regardless of cooperation rate
        - Round r-1 (final round): DEFECT - no future rounds, maximize exploitation

        Mathematical justification:
        Defection payoff: 1 + (k/n)  m_cooperators
        Cooperation payoff: (k/n)  (m_cooperators + 1)
        Difference: 1 + (k/n)  m - (k/n)  (m + 1) = 1 - k/n > 0
        Since constraint k < n, defection always yields strictly higher payoff.
        """
        return Action.D

class Strategy_EXPLOITATIVE_204(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    This strategy always defects, exploiting the asymmetry in the public goods game payoff structure.
    It parasitizes cooperative opponents while minimizing losses against defectors through pure defection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_205(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Opportunistic Harvesting

    Core approach:
    - Defect by default to free-ride on others' contributions
    - Cooperate only when observed cooperation rate exceeds threshold
    - Always defect in round 1 and final round for exploitation
    - Adapt mid-game based on empirical cooperation observations
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        total_cooperators = np.sum(history.opponent_actions[:current_round, :])
        total_actions = current_round * self.n
        observed_coop_rate = total_cooperators / total_actions
        cooperation_threshold = (self.n / self.k + 1) / self.n
        if observed_coop_rate > cooperation_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_206(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    This strategy implements pure defection to maximize payoff through free-riding.
    It always defects regardless of opponent behavior, exploiting the fundamental
    asymmetry in the public goods game where defection dominates cooperation
    when k < n.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_207(BaseStrategy):
    """
    Adaptive Defection with Conditional Exploitation Strategy for N-Player Public Goods Game.

    Core philosophy: Maximize personal payoff by exploiting cooperative players while minimizing
    losses to defectors. Always defect except when sufficient cooperators exist to make cooperation
    profitable based on a threshold derived from game parameters.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold_T = (self.k - self.n) / self.k
        self.prev_coop_rate = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        coop_count_prev = int(sum(history.opponent_actions[current_round - 1, :]))
        coop_rate = coop_count_prev / self.n
        if coop_rate == self.threshold_T:
            if self.prev_coop_rate is not None and self.prev_coop_rate >= self.threshold_T:
                self.prev_coop_rate = coop_rate
                return Action.C
            else:
                self.prev_coop_rate = coop_rate
                return Action.D
        self.prev_coop_rate = coop_rate
        if coop_rate >= self.threshold_T:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_208(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Exploitation

    This strategy maximizes individual payoff by exploiting the asymmetry between
    defection and cooperation in public goods games. The core principle is that
    defection is strictly dominant: Payoff(D) - Payoff(C) = 1 - k/n > 0 (since k < n).

    The strategy primarily defects to capture multiplier benefits from cooperators'
    contributions while avoiding the cost of contributing. Rare conditional cooperation
    only occurs late in the game when cooperation rates are extremely high (>80%)
    and few rounds remain (3), but even then defaults to defection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold_high = 0.5 + self.k / (2 * self.n_players)
        self.threshold_low = self.k / (2 * self.n_players)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        if history is not None:
            cooperators_last_round = int(np.sum(history.opponent_actions[-1, :]))
            cooperation_rate = cooperators_last_round / self.n_players
            rounds_remaining = self.n_rounds - current_round
            if cooperation_rate > 0.8 and rounds_remaining <= 3:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_209(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    Core approach: Defect in almost all scenarios to exploit cooperators while avoiding
    cooperation costs. Uses threshold-based analysis of recent cooperation rates to
    identify exploitation opportunities, but defaults to defection as the dominant strategy.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.k = game_description.k
        self.n_rounds = game_description.n_rounds
        self.threshold = self.k / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        recent_coop_count = 0
        recent_rounds_available = 0
        lookback_start = max(0, current_round - 2)
        lookback_range = current_round - lookback_start
        if lookback_range > 0:
            recent_opponent_actions = history.opponent_actions[lookback_start:current_round, :]
            recent_coop_count = int(np.sum(recent_opponent_actions))
            recent_rounds_available = lookback_range * self.n_players
        if recent_rounds_available > 0:
            recent_coop_rate = recent_coop_count / recent_rounds_available
        else:
            recent_coop_rate = 0.0
        if recent_coop_rate > self.threshold:
            return Action.D
        elif recent_coop_rate == self.threshold:
            return Action.D
        elif current_round < self.n_rounds - 2:
            return Action.D
        else:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_210(BaseStrategy):
    """
    Adaptive Predation Strategy for N-Player Public Goods Game.

    Core principle: Always defect to exploit cooperators while avoiding mutual
    defection traps. Defection yields maximum individual payoff by capturing
    endowment plus share of others' contributions, without reciprocating.

    Decision logic:
    - Round 1: Defect (reconnaissance)
    - Rounds 2 to r-1: Defect if cooperators exist, else defect anyway
    - Final round: Defect (no future reputation cost)

    Simplified rule: Always defect.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number < self.game_description.n_rounds - 1:
            prev_coop_count = int(np.sum(history.opponent_actions[-1, :]))
            if prev_coop_count >= 1:
                return Action.D
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_211(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Exploitation

    Maximizes personal payoff by exploiting cooperative tendencies in others.
    Core approach: Always defect, monitoring opponent cooperation rates to identify
    and extract value from reliable cooperators.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_high = 0.6
        self.threshold_mid = 0.3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        total_coop_last_round = int(sum(history.opponent_actions[-1, :]))
        if total_coop_last_round >= self.game_description.n_players / 2:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_212(BaseStrategy):
    """
    Exploitative strategy: "Adaptive Predation with Conditional Parasitism"

    Core approach: Always defect to exploit cooperators while avoiding losses from defectors.
    - Rounds 1-2: Reconnaissance via defection to identify cooperators
    - Rounds 3 to r-1: Consistent exploitation via defection
    - Round r (final): Defection with no future consequences

    This strategy maximizes payoff by capturing private endowment (1) plus share of others'
    contributions ((k/n)  total_cooperators), while avoiding the loss from cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == 1:
            cooperators_round_0 = sum(history.opponent_actions[0, :])
            return Action.D
        if state.round_number < self.game_description.n_rounds - 1:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_213(BaseStrategy):
    """
    PARASITE Strategy: Unconditional defection exploiting the dominance of defection.

    Core insight: Since k < n, cooperation is individually irrational (k/n < 1).
    Defection is the dominant strategy every round. This strategy maximizes payoff by:
    1. Always defecting to keep the endowment
    2. Exploiting any cooperators that emerge
    3. Never investing in cooperation that costs more than it returns
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.r - 1:
            return Action.D
        previous_round_index = state.round_number - 1
        cooperator_count = int(sum(history.opponent_actions[previous_round_index, :]))
        cooperation_rate = cooperator_count / self.n
        threshold = (self.k - 1) / self.k
        return Action.D

class Strategy_EXPLOITATIVE_214(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Exploitation

    This strategy always defects, exploiting the asymmetry in the payoff structure.
    It tracks observed cooperation rates but maintains defection as the dominant strategy
    since cooperation is individually irrational when k < n.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = (game_description.n_players - game_description.k) / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        if history is not None:
            total_rounds_played = state.round_number
            total_cooperators = np.sum(history.opponent_actions[:total_rounds_played, :])
            total_possible_cooperations = total_rounds_played * self.game_description.n_players
            cooperation_rate = total_cooperators / total_possible_cooperations if total_possible_cooperations > 0 else 0.0
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_215(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    Core approach:
    - Round 1: Always defect to establish free-riding willingness
    - Rounds 2 to r-1: Defect by default, cooperate only if opponent cooperation rate exceeds threshold T = (k-1)/k
    - Final round: Always defect for maximum extraction with no retaliation possible
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        previous_round_opponent_actions = history.opponent_actions[current_round - 1, :]
        num_opponent_cooperators = int(np.sum(previous_round_opponent_actions))
        num_opponents = self.n_players - 1
        cooperation_rate = num_opponent_cooperators / num_opponents if num_opponents > 0 else 0.0
        threshold = (self.k - 1.0) / self.k
        if cooperation_rate > threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_216(BaseStrategy):
    """
    Adaptive Defection with Conditional Cooperation - Exploitative Strategy

    Core approach: Defect by default to exploit the asymmetry in public goods games.
    Monitor opponent cooperation rates and use tactical mimicry only when all opponents
    cooperated in the previous round (to maintain access to high-cooperation scenarios).
    Always defect in round 1 and the final round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        total_opponent_cooperations = np.sum(history.opponent_actions[:current_round, :])
        possible_cooperations = (self.n_players - 1) * current_round
        coop_rate = total_opponent_cooperations / possible_cooperations if possible_cooperations > 0 else 0
        cooperators_last_round = np.sum(history.opponent_actions[current_round - 1, :])
        if cooperators_last_round == self.n_players - 1 and current_round < self.n_rounds - 2:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_217(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Maximizes personal payoff by exploiting cooperative tendencies in others while
    minimizing vulnerability. Uses conditional defection based on observed cooperation
    rates, with adaptive thresholds that become more aggressive in endgame rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold_high = (self.k - 1) / self.k
        self.threshold_low = 1 / self.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        last_round_cooperators = sum(history.opponent_actions[current_round - 1, :])
        cooperation_rate = last_round_cooperators / self.n
        rounds_remaining = self.r - current_round
        threshold_high_adjusted = self.threshold_high
        if rounds_remaining <= 2:
            threshold_high_adjusted = self.threshold_high * 0.9
        if cooperation_rate > threshold_high_adjusted:
            return Action.D
        if cooperation_rate == 0:
            return Action.D
        if cooperation_rate <= self.threshold_low:
            return Action.D
        if self.threshold_low < cooperation_rate <= threshold_high_adjusted:
            exploit_probability = 1 - cooperation_rate / threshold_high_adjusted
            if random.random() < exploit_probability:
                return Action.D
            else:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_218(BaseStrategy):
    """
    Adaptive Defection with Conditional Parasitism Strategy.

    Exploits cooperative tendencies by:
    1. Defecting in round 1 to gather information
    2. Defecting in the final round (no future punishment)
    3. In middle rounds: defecting if cooperation rate is high (exploitation),
       or cooperating if cooperation rate is low (accessing weak public good)

    The exploitation threshold is set at k/n + 0.1 to trigger defection
    when others are sufficiently cooperative to be worth exploiting.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        all_past_actions = history.opponent_actions[:round_number, :]
        total_cooperators = np.sum(all_past_actions)
        total_opportunities = round_number * self.n_players
        cooperation_rate = total_cooperators / total_opportunities
        exploitation_threshold = self.k / self.n_players + 0.1
        if cooperation_rate > exploitation_threshold:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_219(BaseStrategy):
    """
    Adaptive Predation: An exploitative strategy that maximizes individual payoff
    through unconditional defection, free-riding on others' contributions, and
    terminal round exploitation.

    Core logic:
    - Round 1: Defect to establish exploiter type and gather information
    - Final round: Defect to maximize terminal exploitation
    - Mid-game: Defect regardless of cooperation rate (always optimal)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold_exploit = game_description.k / game_description.n_players
        self.threshold_minimal = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        """
        Decision logic for Adaptive Predation strategy.

        Args:
            state: Current game state including round number (0-indexed)
            history: Player and opponent action/payoff history, or None if round 0

        Returns:
            Action.D (defect) in all cases
        """
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.n_rounds - 1:
            return Action.D
        if history is not None:
            last_round_opponent_actions = history.opponent_actions[-1, :]
            cooperators_last_round = sum(last_round_opponent_actions)
            cooperation_rate = cooperators_last_round / self.n_players
            if cooperation_rate >= self.threshold_exploit:
                return Action.D
            elif cooperation_rate <= self.threshold_minimal:
                return Action.D
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_220(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Maximizes personal payoff by exploiting cooperative tendencies in others
    while minimizing contributions to the public good. Defects by default,
    cooperates only when the public good is large enough to harvest profitably.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        prev_round_idx = current_round - 1
        prev_round_opponent_actions = history.opponent_actions[prev_round_idx, :]
        my_prev_action = history.my_actions[prev_round_idx]
        cooperators_prev = int(my_prev_action) + int(np.sum(prev_round_opponent_actions))
        cooperation_rate_prev = cooperators_prev / self.n
        threshold = self.k / self.n
        if cooperation_rate_prev <= threshold:
            return Action.D
        expected_cooperators = cooperators_prev
        payoff_if_cooperate = 0 + self.k / self.n * expected_cooperators
        payoff_if_defect = 1 + self.k / self.n * expected_cooperators
        if payoff_if_cooperate > payoff_if_defect:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_221(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core philosophy: Exploit the fundamental asymmetry in payoff structure by:
    1. Never cooperating unconditionally (it's exploitable)
    2. Harvesting cooperators when they emerge
    3. Matching defection to minimize losses
    4. Always defecting in round 1 and final round

    This strategy implements unconditional defection as the dominant strategy,
    recognizing that k < n makes defection always superior to cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = game_description.k / (2 * game_description.n_players)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        prev_cooperators = np.sum(history.opponent_actions[round_num - 1, :])
        cooperation_rate = prev_cooperators / self.n
        return Action.D

class Strategy_EXPLOITATIVE_222(BaseStrategy):
    """
    Exploitative strategy using adaptive defection with selective parasitism.

    Core approach:
    - Round 1: Defect (no history, test responsiveness)
    - Rounds 2 to r-1: Defect by default, but conditionally cooperate if cooperation_rate >= 60% for 2+ consecutive rounds (surgical exploitation)
    - Final round: Always defect (no reputational consequences)

    This strategy maximizes payoff by free-riding on others' cooperation while avoiding mutual defection traps.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.cooperation_threshold_high = 0.6

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        last_round_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        cooperation_rate = last_round_cooperators / self.n_players
        if cooperation_rate >= self.cooperation_threshold_high:
            if current_round >= 2:
                prev_round_cooperators = int(sum(history.opponent_actions[current_round - 2, :]))
                prev_cooperation_rate = prev_round_cooperators / self.n_players
                if prev_cooperation_rate >= self.cooperation_threshold_high:
                    return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_223(BaseStrategy):
    """
    Exploitative Adaptive Defection with Opportunistic Cooperation.

    Maximizes individual payoff by primarily defecting to exploit cooperators,
    with rare cooperation only when cooperation rate is extremely high and
    sufficient rounds remain to recover losses.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.r - 1:
            return Action.D
        previous_round_idx = round_number - 1
        cooperators_prev = sum(history.opponent_actions[previous_round_idx, :])
        c_rate_prev = cooperators_prev / self.n
        threshold = 1.0 / self.k
        epsilon = 0.01
        rounds_remaining = self.r - round_number
        if c_rate_prev >= threshold + epsilon:
            return Action.D
        expected_coop_payoff = self.k / self.n * c_rate_prev * self.n
        expected_defect_payoff = 1.0 + self.k / self.n * c_rate_prev * self.n
        if expected_defect_payoff > expected_coop_payoff + 0.05:
            return Action.D
        if c_rate_prev < threshold and rounds_remaining >= 3 and (expected_coop_payoff > 0.9):
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_224(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism:
    A ruthlessly exploitative strategy that defects in all rounds to extract maximum value
    from cooperative opponents while avoiding punishment exposure.

    Core logic:
    - Round 1: DEFECT (establish as non-cooperative, observe cooperators)
    - Rounds 2 to r-1: DEFECT (exploitation phase; k < n makes defection mathematically dominant)
    - Round r: DEFECT (final round; no future punishment possible)

    This strategy parasitizes cooperative tendencies while maintaining mathematical optimality.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_high = 0.5
        self.threshold_low = 0.2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        cooperation_rate = np.mean(history.opponent_actions[-1, :])
        return Action.D

class Strategy_EXPLOITATIVE_225(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    This strategy implements pure defection as the dominant strategy in public goods games.
    It recognizes that defection is individually rational when 1 < k < n, and maintains
    defection across all game states to extract maximum value from cooperators while
    avoiding the cost of contribution.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        n_players = self.game_description.n_players
        rounds_elapsed = state.round_number
        if history is not None and rounds_elapsed > 0:
            total_cooperators = int(np.sum(history.opponent_actions[:rounds_elapsed, :]))
            possible_observations = (n_players - 1) * rounds_elapsed
            cooperation_rate = total_cooperators / possible_observations if possible_observations > 0 else 0
        else:
            cooperation_rate = 0
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        if cooperation_rate > 0.7:
            return Action.D
        elif cooperation_rate > 0.3:
            return Action.D
        else:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_226(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Calculated Cooperation

    Core philosophy: Treat cooperation as a calculated investment to extract value from.
    Defect in round 1 and final round unconditionally. In middle rounds, adaptively defect
    when cooperation rate is high enough to be exploitable, cooperate only when cooperation
    is moderate but potentially self-sustaining, and defect when cooperation is too low.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.exploitation_threshold = 0.65
        self.minimum_viability_threshold = 0.25

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        last_round_cooperators = sum(history.opponent_actions[round_number - 1, :])
        cooperation_rate = last_round_cooperators / self.n_players
        if cooperation_rate >= self.exploitation_threshold:
            return Action.D
        elif cooperation_rate >= self.minimum_viability_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_227(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Exploitation

    Maximizes individual payoff by exploiting cooperative tendencies in others while avoiding
    mutual defection. The strategy calculates historical cooperation rates and defects when
    others cooperate above the exploitation threshold of k/n + .
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.exploitation_threshold = self.k / self.n + 0.01

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.D
        if round_t == self.r - 1:
            return Action.D
        total_rounds_completed = round_t
        total_cooperators = 0
        for round_idx in range(round_t):
            cooperators_in_round = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += cooperators_in_round
        historical_coop_rate = total_cooperators / (self.n * total_rounds_completed)
        if historical_coop_rate > self.exploitation_threshold:
            return Action.D
        elif historical_coop_rate > self.k / self.n - 0.05:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_228(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Exploitation

    Exploits the payoff asymmetry by defecting strategically:
    - Round 1: DEFECT to establish non-cooperation baseline
    - Rounds 2 to r-1: Adaptively defect unless cooperation is sufficiently dense
    - Last round: ALWAYS DEFECT to extract maximum final payoff

    Tracks population cooperation rate and only cooperates when the public good
    payoff exceeds private endowment AND cooperation is empirically dense enough.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n * (self.n - 1)
        self.coop_threshold = 1.0 / self.k if self.k > 0 else 1.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        if history is not None:
            total_cooperators = np.sum(history.opponent_actions[:current_round, :])
            total_opponent_observations = (self.n - 1) * current_round
            coop_rate = total_cooperators / total_opponent_observations if total_opponent_observations > 0 else 0.0
            if self.threshold > 1.0 and coop_rate > self.coop_threshold:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_229(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Maximizes personal payoff by free-riding on others' cooperation while minimizing
    own contribution costs. Uses conditional defection based on observed cooperation rates
    and game position (first/last rounds always defect).
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.n - self.k) / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        if history is not None:
            prev_round_index = current_round - 1
            cooperators_in_prev_round = np.sum(history.opponent_actions[prev_round_index, :])
            cooperation_rate = cooperators_in_prev_round / self.n
            if cooperation_rate > self.threshold:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_230(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Maximizes personal payoff by exploiting cooperators while minimizing losses from defectors.
    Uses a threshold-based decision rule to determine when exploitation is profitable.
    Always defects in round 1 and the final round. In middle rounds, defects based on whether
    the observed cooperation rate exceeds the mathematical threshold.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.n - self.k) / (self.n - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        previous_round_idx = current_round - 1
        cooperators_in_previous_round = sum(history.opponent_actions[previous_round_idx, :])
        observed_cooperation_rate = cooperators_in_previous_round / self.n
        return Action.D

class Strategy_EXPLOITATIVE_231(BaseStrategy):
    """
    Adaptive Predation: An exploitative strategy that cooperates in round 1 to gather
    information, then systematically defects to free-ride on others' cooperation while
    avoiding retaliation through adaptive threshold monitoring.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        if round_num == self.n_rounds - 1:
            return Action.D
        lookback = min(3, round_num)
        recent_rounds = history.opponent_actions[-lookback:, :]
        total_cooperators_recent = int(np.sum(recent_rounds))
        recent_coop_rate = total_cooperators_recent / (lookback * self.n_players)
        my_last_action = history.my_actions[-1]
        my_last_payoff = history.my_payoffs[-1]
        last_round_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        if my_last_action:
            hypothetical_defect_payoff = 1.0 + self.k / self.n_players * last_round_cooperators
            personal_advantage = hypothetical_defect_payoff - my_last_payoff
        else:
            hypothetical_coop_payoff = 0.0 + self.k / self.n_players * (last_round_cooperators + 1)
            personal_advantage = my_last_payoff - hypothetical_coop_payoff
        if recent_coop_rate > 0.2:
            if personal_advantage > -0.1:
                return Action.D
            else:
                return Action.D
        else:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_232(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    This strategy exploits the payoff asymmetry in public goods games by:
    1. Always defecting in round 1 (information gathering and baseline establishment)
    2. Monitoring cooperation rates in intermediate rounds and exploiting when beneficial
    3. Always defecting in the final round (no retaliation possible)

    The strategy captures gains from cooperators while maintaining parity against defectors.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.k = game_description.k
        self.n_rounds = game_description.n_rounds
        self.threshold_exploit = (self.k - 1) / self.k
        self.threshold_neutral = 1 / (2 * self.k)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        previous_round_actions = history.opponent_actions[current_round - 1, :]
        cooperators_last_round = np.sum(previous_round_actions)
        cooperation_rate = cooperators_last_round / self.n_players
        return Action.D

class Strategy_EXPLOITATIVE_233(BaseStrategy):
    """
    Adaptive Defection with Conditional Contribution (ADCC)

    A pure defection strategy that exploits the structure of the N-player public goods game.
    Always defects across all rounds by recognizing that defection weakly dominates cooperation
    in simultaneous-move games without communication.

    The strategy maintains an adaptive framework that evaluates cooperation rates and applies
    a principled threshold, but the optimal action consistently remains defection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self._calculate_threshold()

    def _calculate_threshold(self) -> None:
        """Calculate the cooperation rate threshold for adaptive evaluation."""
        denominator = self.k * (self.n - 1)
        if denominator > 0:
            self.threshold = (self.k - 1) / denominator
        else:
            self.threshold = 1.0

    def _get_last_round_cooperation_rate(self, history: PlayerHistory) -> float:
        """
        Calculate the cooperation rate from the previous round.

        Returns the fraction of players (including self) who cooperated in the last round.
        """
        last_round_idx = history.my_actions.shape[0] - 1
        cooperators_count = sum(history.opponent_actions[last_round_idx, :])
        if history.my_actions[last_round_idx]:
            cooperators_count += 1
        cooperation_rate = cooperators_count / self.n
        return cooperation_rate

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        """
        Determine action for current round.

        Round 0 (initial): DEFECT (probe strategy, guarantee minimum payoff)
        Round r-1 (final): DEFECT (no future rounds to condition on, backward induction)
        Rounds 1 to r-2 (adaptive): DEFECT (always optimal regardless of cooperation rate)
        """
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.r - 1:
            return Action.D
        cooperation_rate_last_round = self._get_last_round_cooperation_rate(history)
        if cooperation_rate_last_round >= self.threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_234(BaseStrategy):
    """
    Adaptive Predation: An exploitative strategy that builds false credibility early,
    exploits heightened cooperation mid-game, and defects without consequence late-game.
    Dynamically adjusts to prevent opponent learning.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        early_threshold = math.floor(self.r / 3)
        mid_threshold = math.floor(2 * self.r / 3)
        if round_num <= early_threshold:
            return Action.C
        elif round_num > mid_threshold:
            return Action.D
        else:
            if round_num == 0:
                coop_rate_last = 1.0
            else:
                cooperators_last_round = sum(history.opponent_actions[round_num - 1, :])
                coop_rate_last = cooperators_last_round / self.n
            threshold = 2 * self.k / self.n
            if coop_rate_last >= threshold:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_235(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Maximizes individual payoff through consistent defection, with adaptive monitoring
    of opponent cooperation rates. Exploits the asymmetry where defecting while others
    cooperate yields the highest payoff. Uses early rounds for reconnaissance, middle
    rounds for conditional defection based on cooperation threshold, and late rounds
    for pure exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number <= 1:
            return Action.D
        if round_number >= self.n_rounds - 2:
            return Action.D
        if history is not None and len(history.opponent_actions) > 0:
            total_opponent_cooperations = np.sum(history.opponent_actions)
            total_possible_cooperations = len(history.opponent_actions) * self.n_players - 1
            if total_possible_cooperations > 0:
                cooperation_rate = total_opponent_cooperations / total_possible_cooperations
            else:
                cooperation_rate = 0.0
            if cooperation_rate > self.threshold:
                return Action.D
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_236(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Free-Riding

    Core mechanism: Defect by default to extract maximum immediate payoff.
    Conditionally cooperate only in high-cooperation scenarios (>80% cooperation)
    where marginal gains exceed private costs, or in early rounds (2-3) to probe
    for exploitable cooperative types. Defect in final round regardless of history.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        prev_cooperators = int(np.sum(history.opponent_actions[round_number - 1, :]))
        coop_rate = prev_cooperators / self.n_players
        if coop_rate > 0.8:
            expected_total_cooperators = prev_cooperators + 1
            expected_public_benefit = self.k / self.n_players * expected_total_cooperators
            private_cost = 1.0
            if expected_public_benefit > private_cost:
                return Action.C
            else:
                return Action.D
        if round_number <= 2 and coop_rate > 0.7:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_237(BaseStrategy):
    """
    Exploitative strategy using adaptive defection with selective exploitation.

    Core approach: Always defect except conditionally during middle rounds based on
    opponent cooperation rates. Treats cooperation as a resource to extract value from
    without reciprocation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = 0.4

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        cooperators_last_round = sum(history.opponent_actions[state.round_number - 1, :])
        cooperation_rate = cooperators_last_round / self.game_description.n_players
        if cooperation_rate > self.threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_238(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Exploitation

    Always defects to maximize personal payoff by exploiting cooperators while
    avoiding losses to other defectors. The strategy treats cooperation as a
    resource to extract rather than a norm to reciprocate.

    Core principle: Defection always yields 1 + (k/n)  C_prev, while cooperation
    yields only (k/n)  C_prev. The private endowment (1) is always preserved
    through defection, making it the dominant strategy regardless of history,
    opponent composition, or round number.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number < self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_239(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism Strategy.

    Exploits the payoff asymmetry in public goods games by defaulting to defection
    and systematically free-riding on cooperative players. Uses cooperation rate
    thresholds to determine when to exploit, with guaranteed defection in terminal rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        if round_number == self.n_rounds - 2:
            return Action.D
        if history is not None:
            previous_round_index = round_number - 1
            cooperators_in_previous = sum(history.opponent_actions[previous_round_index, :])
            cooperation_rate = cooperators_in_previous / self.n_players
            threshold = self.k / self.n_players
            if cooperation_rate >= threshold:
                return Action.D
            if cooperation_rate > 0:
                return Action.D
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_240(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Exploitation

    Maximizes personal payoff by exploiting cooperators while minimizing losses from defectors.
    Core approach: Always defect to capture private payoff, with adaptive refinement based on
    observed cooperation patterns and variance detection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.k = game_description.k
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.threshold = self.k / self.n - 0.01
        self.cooperators_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
        self.cooperators_history.append(cooperators_last_round)
        cooperation_rate = cooperators_last_round / self.n
        if current_round >= self.r - 2:
            return Action.D
        if cooperation_rate > self.threshold:
            return Action.D
        else:
            return Action.D
        if len(self.cooperators_history) >= 3:
            recent_avg = sum(self.cooperators_history[-3:]) / 3.0
            if recent_avg >= 2:
                if random.random() < 0.05:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D
        if len(self.cooperators_history) >= 4:
            variance = self._calculate_variance(self.cooperators_history)
            if variance > 1.5:
                if random.random() < 0.02:
                    return Action.C
                else:
                    return Action.D
        return Action.D

    def _calculate_variance(self, data: list) -> float:
        """Calculate variance of cooperation counts"""
        if len(data) == 0:
            return 0.0
        mean = sum(data) / len(data)
        variance = sum(((x - mean) ** 2 for x in data)) / len(data)
        return variance

class Strategy_EXPLOITATIVE_241(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Exploitation

    This strategy maximizes personal payoff by exploiting cooperators through:
    1. Default defection (Nash equilibrium)
    2. Conditional probing when cooperation is detected (>50%)
    3. Sustained defection against exploitable groups
    4. Final-round defection for maximum extraction
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.probed_this_phase = False
        self.last_probe_round = -2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        n_rounds = self.game_description.n_rounds
        n_players = self.game_description.n_players
        if current_round == 0:
            return Action.D
        if current_round == n_rounds - 1:
            return Action.D
        history_start = max(0, current_round - 3)
        recent_rounds_count = current_round - history_start
        total_cooperators = 0
        for round_idx in range(history_start, current_round):
            cooperators_in_round = int(np.sum(history.opponent_actions[round_idx, :]))
            total_cooperators += cooperators_in_round
        cooperation_rate = total_cooperators / (recent_rounds_count * n_players) if recent_rounds_count > 0 else 0
        probe_successful = False
        if current_round > 0 and current_round - 1 == self.last_probe_round:
            last_round_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
            last_round_coop_rate = last_round_cooperators / n_players
            if last_round_coop_rate > 0.4:
                probe_successful = True
        if probe_successful:
            self.probed_this_phase = False
            return Action.D
        if cooperation_rate > 0.5 and (not self.probed_this_phase) and (current_round < n_rounds - 2):
            self.probed_this_phase = True
            self.last_probe_round = current_round
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_242(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Exploits cooperative environments by tracking opponent cooperation rates
    and defecting strategically based on adaptive thresholds that scale with
    the extraction coefficient k/n. Uses probabilistic defection in moderate
    cooperation environments to avoid predictability.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        cooperation_rate = self._calculate_cooperation_rate(history, round_num)
        extraction_ratio = self.k / self.n
        threshold_aggressive = 0.65 + extraction_ratio * 0.2
        threshold_moderate = 0.4 + extraction_ratio * 0.15
        threshold_minimal = 0.2
        if cooperation_rate > threshold_aggressive:
            return Action.D
        elif cooperation_rate > threshold_moderate:
            return Action.D if random.random() < 0.85 else Action.C
        elif cooperation_rate > threshold_minimal:
            return Action.D if random.random() < 0.6 else Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate the rolling average cooperation rate of opponents across all previous rounds.

        cooperation_rate = (total_cooperators_observed) / ((n-1)  rounds_completed)
        """
        if round_num == 0:
            return 0.5
        total_cooperators = np.sum(history.opponent_actions[:round_num, :])
        total_possible = (self.n - 1) * round_num
        cooperation_rate = total_cooperators / total_possible if total_possible > 0 else 0.5
        return cooperation_rate

class Strategy_EXPLOITATIVE_243(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    This strategy maximizes payoff by defecting by default and conditionally cooperating
    only when exploitation opportunities are detected. It systematically free-rides on
    cooperators while maintaining minimal exposure to retaliation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round >= self.r - 2:
            return Action.D
        cooperation_rate_last_round = self._get_cooperation_rate(history, current_round - 1)
        critical_threshold = 0.6
        if self.k >= self.n * 0.75:
            critical_threshold = 0.5 + (self.n - self.k) / (2 * self.n)
        if self.n == 2:
            return Action.D
        if cooperation_rate_last_round > critical_threshold:
            return Action.C
        else:
            return Action.D

    def _get_cooperation_rate(self, history: PlayerHistory, round_idx: int) -> float:
        """
        Calculate the cooperation rate of opponents in a given round.
        Cooperation rate = (number of cooperators) / (n - 1)
        """
        if round_idx < 0 or round_idx >= len(history.opponent_actions):
            return 0.0
        cooperators_in_round = np.sum(history.opponent_actions[round_idx, :])
        cooperation_rate = cooperators_in_round / (self.n - 1)
        return cooperation_rate

class Strategy_EXPLOITATIVE_244(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core approach: Always defect to exploit cooperators without cost.
    - Round 0: DEFECT (initial probe)
    - Rounds 1 to r-2: DEFECT (free-ride on cooperation or avoid losses)
    - Round r-1: DEFECT (terminal defection, no future reputation concerns)

    The strategy monitors cooperation rates but always defaults to defection,
    as it is either dominant or tied with cooperation in standard parameterizations.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        previous_round_idx = state.round_number - 1
        cooperators_last_round = int(sum(history.opponent_actions[previous_round_idx, :]))
        coop_rate = cooperators_last_round / self.game_description.n_players
        exploitation_threshold = self.game_description.k / self.game_description.n_players
        if coop_rate > exploitation_threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_245(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    Maximizes personal payoff by exploiting cooperative opponents while minimizing losses to defectors.
    Uses threshold-based conditional cooperation and opponent profiling to extract value.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.base_threshold = (self.k - 1) / self.k
        self.threshold = self.base_threshold
        self.opponent_coop_counts = np.zeros(self.n - 1)
        self.opponent_total_rounds = np.zeros(self.n - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        opponents_last_round = history.opponent_actions[round_num - 1, :]
        cooperation_count = np.sum(opponents_last_round)
        cooperation_rate = cooperation_count / (self.n - 1)
        self.opponent_coop_counts += opponents_last_round
        self.opponent_total_rounds += 1
        if round_num > self.r / 2:
            global_cooperation_rate = np.sum(self.opponent_coop_counts) / np.sum(self.opponent_total_rounds + 1e-10)
            if global_cooperation_rate < 0.3:
                self.threshold = self.base_threshold - 0.1
            elif global_cooperation_rate > 0.7:
                self.threshold = self.base_threshold + 0.05
            else:
                self.threshold = self.base_threshold
        if round_num >= 2:
            prev_round_coop = np.sum(history.opponent_actions[round_num - 2, :]) / (self.n - 1)
            curr_coop = cooperation_rate
            if abs(prev_round_coop - curr_coop) > 0.4:
                return Action.D
        if round_num >= 2:
            last_defected = np.sum(history.opponent_actions[round_num - 1, :]) == 0
            prev_defected = np.sum(history.opponent_actions[round_num - 2, :]) == 0
            if last_defected and prev_defected:
                return Action.D
        if cooperation_rate >= self.threshold:
            expected_payoff_coop = self.k / self.n * (cooperation_count + 1)
            expected_payoff_def = 1.0 + self.k / self.n * cooperation_count
            if expected_payoff_coop > expected_payoff_def:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_246(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core approach: Defect by default, cooperate only when the public good pool
    is sufficiently large to justify the cost. Adapts cooperation threshold based
    on observed opponent behavior to maximize exploitation of cooperators.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.cooperation_threshold = math.ceil(self.n / self.k + 0.1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        if current_round <= 2:
            return Action.D
        total_cooperators_observed = np.sum(history.opponent_actions[:current_round, :])
        total_opponent_rounds = current_round * (self.n - 1)
        observed_cooperation_rate = total_cooperators_observed / total_opponent_rounds if total_opponent_rounds > 0 else 0.5
        expected_cooperators = observed_cooperation_rate * (self.n - 1)
        rounds_remaining = self.r - current_round
        adjusted_threshold = self.cooperation_threshold
        if rounds_remaining < self.r / 3:
            adjusted_threshold = self.cooperation_threshold * 1.1
        elif np.sum(history.my_payoffs[:current_round]) < current_round * 1.5:
            adjusted_threshold = self.cooperation_threshold * 0.95
        if expected_cooperators >= adjusted_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_247(BaseStrategy):
    """
    Adaptive Conditional Exploitation (ACE) strategy for N-Player Public Goods Game.

    Exploits cooperators through strategic free-riding while using periodic cooperation
    to maintain an exploitable population. Defects in information gathering phase,
    exploits in middle rounds, and commits to defection in endgame.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        n = self.n_players
        r = self.n_rounds
        k = self.k
        if round_num == 0:
            return Action.D
        if round_num == r - 1 or round_num == r - 2:
            return Action.D
        if r <= 3:
            return Action.D
        if round_num <= 2:
            return Action.D
        cooperators_observed = np.sum(history.opponent_actions[0:3, :])
        total_observations = 3 * n
        coop_rate = cooperators_observed / total_observations
        threshold = k / n + 0.15
        if coop_rate <= threshold:
            return Action.D
        adaptive_cycle = max(4, math.floor(r / 4))
        trigger_round = adaptive_cycle - 1
        if round_num % adaptive_cycle == trigger_round:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_248(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    Maximizes payoff by detecting cooperation opportunities and exploiting them,
    while defaulting to defection when cooperation is insufficient or in terminal rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.n - self.k) / (self.n - 1) if self.n > 1 else 0
        self.exploit_probability = (2 - self.k) / (self.n - 1) if self.n > 1 else 0
        self.exploit_probability = max(0, min(1, self.exploit_probability))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.r - 1:
            return Action.D
        total_cooperators = np.sum(history.opponent_actions[:round_number, :])
        rounds_completed = round_number
        coop_rate = total_cooperators / (self.n * rounds_completed)
        if round_number == 2 and coop_rate < 0.2:
            return Action.D
        if coop_rate >= self.threshold:
            if random.random() < self.exploit_probability:
                return Action.D
            else:
                return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_249(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Parasitism with Dynamic Punishment

    Core behavior: Always defect to exploit cooperators while being robust to defection cascades.
    - Round 0: Defect (establish baseline)
    - Final round: Defect (end-game extraction)
    - Middle rounds: Defect if cooperation rate > threshold, otherwise defect anyway
    - Cascade mode: Detect and lock into defection if cooperation collapses
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.cascade_mode = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        if self.cascade_mode:
            return Action.D
        if current_round >= 2:
            coop_rate_prev = sum(history.opponent_actions[current_round - 1, :]) / self.n
            coop_rate_prev_prev = sum(history.opponent_actions[current_round - 2, :]) / self.n
            if coop_rate_prev < 0.2 and coop_rate_prev_prev < 0.2:
                self.cascade_mode = True
                return Action.D
        previous_cooperators = sum(history.opponent_actions[current_round - 1, :])
        cooperation_rate = previous_cooperators / self.n
        threshold = (self.n - 1) / self.n * 0.7
        return Action.D

class Strategy_EXPLOITATIVE_250(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Opportunistic Exploitation

    Core principle: Defection is mathematically dominant in this game (k < n implies k/n < 1).
    Strategy exploits cooperative players by defecting, only conditionally cooperating when
    the cooperation rate exceeds a threshold and expected payoff from cooperation exceeds defection.
    Always defects in final round and first round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        if round_num < 3:
            return Action.D
        prev_round_idx = round_num - 1
        prev_opponent_actions = history.opponent_actions[prev_round_idx, :]
        prev_cooperation_count = int(np.sum(prev_opponent_actions))
        prev_cooperation_rate = prev_cooperation_count / (self.n - 1) if self.n > 1 else 0.0
        threshold = 2.0 * self.k / self.n
        if prev_cooperation_rate < threshold:
            return Action.D
        cooperation_probability = min(0.25, prev_cooperation_rate - threshold)
        if random.random() < cooperation_probability:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_251(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism strategy.

    Exploits the asymmetry between defection and cooperation payoffs by:
    1. Defaulting to defection (the dominant strategy)
    2. Selectively cooperating only when cooperation rate exceeds threshold T = (k-1)/k
    3. Always defecting in round 1 and the final round
    4. Adapting to opponent cooperation rates in middle rounds
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.k - 1) / self.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        previous_round_actions = history.opponent_actions[current_round - 1, :]
        previous_cooperators = sum(previous_round_actions)
        previous_coop_rate = previous_cooperators / self.n_players
        if previous_coop_rate >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_252(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Exploitation

    Core strategy: Always defect. The payoff structure makes defection strictly dominant.
    - Round 1: Defect to probe and avoid suboptimal cooperation
    - Rounds 2 to r-1: Defect, with adaptive logic based on cooperation rate threshold
    - Final round: Unconditional defection (no future rounds to recoup)

    The cooperation threshold (coop_rate > 1/k) is mechanistically sound but never triggers
    in equilibrium, so the strategy effectively defects every round to maximize exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = 1.0 / self.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        previous_round_idx = current_round - 1
        cooperators_last_round = sum(history.opponent_actions[previous_round_idx, :])
        coop_rate = cooperators_last_round / self.n
        if coop_rate > self.threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_253(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    This strategy exploits the public goods game by defecting to parasitize
    cooperators while avoiding mutual defection costs. It uses adaptive thresholds
    based on cooperation rates and always defects in the final round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.k_over_n = game_description.k / game_description.n_players
        self.rolling_avg_coop = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        prev_round_idx = current_round - 1
        cooperators_last_round = np.sum(history.opponent_actions[prev_round_idx, :])
        cooperation_rate = cooperators_last_round / self.n_players
        self.rolling_avg_coop = 0.7 * self.rolling_avg_coop + 0.3 * cooperation_rate
        decay_noise = 0.15 * (1.0 - current_round / self.n_rounds)
        threshold = self.k_over_n + decay_noise
        if current_round >= 2:
            recent_rates = [np.sum(history.opponent_actions[i, :]) / self.n_players for i in range(max(0, current_round - 3), current_round)]
            if len(recent_rates) > 1:
                volatility = np.std(recent_rates)
                if volatility > 0.3:
                    return Action.D
        if self.k_over_n > 0.8:
            if self.rolling_avg_coop > threshold:
                return Action.D
            return Action.D
        elif self.k_over_n < 0.5:
            if self.rolling_avg_coop > 0.9:
                return Action.D
            return Action.D
        elif self.n_players > 10:
            if self.rolling_avg_coop > threshold * 0.9:
                return Action.D
            return Action.D
        if self.rolling_avg_coop > threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_254(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    This strategy exploits the fundamental asymmetry in the public goods game by:
    1. Defecting in round 1 to gather information about cooperation rates
    2. Defecting in rounds 2 to r-2 based on observed cooperation (always defecting since k < n makes it dominant)
    3. Defecting in the final rounds (r-1 and r) to maximize terminal payoff

    Core principle: Since k < n, defection is the unique best response to any cooperation rate.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number >= self.n_rounds - 2:
            return Action.D
        previous_round_idx = round_number - 1
        cooperators_previous = sum(history.opponent_actions[previous_round_idx, :])
        cooperation_rate = cooperators_previous / self.n_players
        if cooperation_rate >= self.threshold:
            return Action.D
        elif cooperation_rate == self.threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_255(BaseStrategy):
    """
    Adaptive Parasite: Exploitative strategy that defects to maximize personal payoff
    by parasitizing cooperative behavior while avoiding vulnerability to defectors.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold_high = min(0.5, (self.k - 1) / (2 * self.k))
        self.threshold_mid = self.threshold_high / 3
        self.observation_window = min(3, max(1, self.r // 3))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        rounds_to_examine = min(self.observation_window, current_round)
        start_idx = current_round - rounds_to_examine
        recent_opponent_actions = history.opponent_actions[start_idx:current_round, :]
        total_cooperators = np.sum(recent_opponent_actions)
        total_possible_actions = self.n * rounds_to_examine
        cooperation_rate = total_cooperators / total_possible_actions if total_possible_actions > 0 else 0.0
        if cooperation_rate > self.threshold_high:
            return Action.D
        elif cooperation_rate > self.threshold_mid:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_256(BaseStrategy):
    """
    Adaptive Predation with Threshold Switching - Exploitative strategy for N-Player Public Goods Game.

    Core approach: Always defect to exploit cooperators' contributions while avoiding contribution costs.
    - Round 1: Defect (initial probe)
    - Rounds 2 to r-1: Defect (harvest cooperation)
    - Round r: Defect (final round, no future consequences)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number > 0 and state.round_number < self.game_description.n_rounds - 1:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_257(BaseStrategy):
    """
    Adaptive Defection with Conditional Cooperation Strategy.

    Core principle: Defection is individually rational. This strategy:
    1. Defaults to defection (dominant strategy)
    2. Conditionally exploits cooperation when observed
    3. Adapts based on opponent behavior to maximize personal payoff
    4. Always defects in final round (no shadow of future)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        if history is None or current_round == 0:
            return Action.D
        opponent_actions = history.opponent_actions[:current_round]
        total_cooperations = np.sum(opponent_actions)
        total_observations = opponent_actions.shape[0] * opponent_actions.shape[1]
        avg_opponent_cooperation = total_cooperations / max(1, total_observations)
        expected_total_cooperators = 1 + avg_opponent_cooperation * (self.n - 1)
        expected_public_payoff = self.k / self.n * expected_total_cooperators
        expected_defect_payoff = 1 + self.k / self.n * (avg_opponent_cooperation * (self.n - 1))
        cooperation_threshold = (self.n - 1) / (2 * self.k)
        exploitation_index = expected_defect_payoff - expected_public_payoff
        if exploitation_index > 0.01:
            return Action.D
        if avg_opponent_cooperation < cooperation_threshold:
            return Action.D
        if current_round < self.r / 3:
            my_total_payoff = np.sum(history.my_payoffs[:current_round])
            opponent_avg_payoff = np.mean(history.opponent_payoffs[:current_round])
            if my_total_payoff <= opponent_avg_payoff:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_258(BaseStrategy):
    """
    Adaptive Predation: An exploitative strategy that always defects.

    Core insight: Defection is weakly dominant in the public goods game.
    - When cooperation rate > k/n: Defecting yields more than cooperating
    - When cooperation rate  k/n: Defecting yields at least as much

    This strategy exploits the asymmetry by:
    1. Always defecting to free-ride on others' contributions
    2. Abandoning any reputation in the final round
    3. Monitoring cooperation rates to confirm defection remains optimal
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold_rate = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        total_cooperators_last_round = np.sum(history.opponent_actions[current_round - 1, :])
        cooperation_rate_last_round = total_cooperators_last_round / self.n_players
        return Action.D

class Strategy_EXPLOITATIVE_259(BaseStrategy):
    """
    Adaptive Predation Strategy: Pure defection with opportunistic exploitation.

    Defects in every round, especially targeting detected cooperators. This exploitative
    strategy extracts value from cooperative opponents while maintaining a baseline payoff
    against defectors. The core insight: defection is the dominant strategy in public goods
    games, yielding payoff of 1 + (k/n)  cooperators when defecting against cooperators,
    versus 0 + (k/n)  cooperators when cooperating.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        """
        Decision rule: Always defect.

        Rationale:
        - Round 0 (first round): No history; defection is safe default that gathers intelligence
        - Last round (r-1): No future punishment possible; defection is temporally optimal
        - Mid-game rounds (1 to r-2): Continue defecting to exploit any cooperators detected

        Defection yields: 1 + (k/n)  total_cooperators
        Cooperation yields: 0 + (k/n)  total_cooperators

        Therefore defection strictly dominates when any player defects (which is rational).
        """
        if history is not None:
            last_round_idx = state.round_number - 1
            cooperators_last_round = int(np.sum(history.opponent_actions[last_round_idx, :]))
            cooperation_rate = cooperators_last_round / self.game_description.n_players
            self.cooperation_history.append(cooperation_rate)
        return Action.D

class Strategy_EXPLOITATIVE_260(BaseStrategy):
    """
    Adaptive Defection with Calculated Exploitation strategy for N-Player Public Goods Game.

    Maximizes individual payoff by exploiting cooperative players while minimizing losses
    to defectors. Defects universally in early rounds, final rounds, and whenever cooperation
    rate doesn't exceed exploitation threshold. Only cooperates in sustained high-cooperation
    environments during non-critical rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold_buffer = 0.15

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round >= self.n_rounds - 2:
            return Action.D
        prev_round_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        my_prev_action = history.my_actions[current_round - 1]
        coop_rate = prev_round_cooperators / self.n_players
        threshold = self.k / self.n_players
        if coop_rate <= threshold + self.threshold_buffer:
            return Action.D
        if coop_rate < 0.5:
            return Action.D
        if my_prev_action == False and prev_round_cooperators > 0:
            return Action.D
        if coop_rate > 0.7:
            return Action.D
        if current_round >= 3:
            recent_coop_rates = []
            for i in range(max(0, current_round - 3), current_round):
                recent_cooperators = int(np.sum(history.opponent_actions[i, :]))
                recent_coop_rates.append(recent_cooperators / self.n_players)
            if all((rate < 0.3 for rate in recent_coop_rates)):
                return Action.D
        if coop_rate > threshold + self.threshold_buffer and my_prev_action == False:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_261(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Core philosophy: Always defect to maximize personal payoff by parasitizing
    cooperation while minimizing losses. Defection is the dominant strategy in
    this public goods game when others may cooperate.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.n - self.k) / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        if history is not None:
            last_round_opponent_actions = history.opponent_actions[current_round - 1, :]
            cooperators_last_round = int(np.sum(last_round_opponent_actions))
            cooperation_rate = cooperators_last_round / self.n
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_262(BaseStrategy):
    """
    Exploitative Strategy: Unconditional Defection

    This strategy always defects across all rounds. Defection is the dominant strategy
    in the N-Player Public Goods Game because:
    - Round 1: No history; defection guarantees payoff of 1 (strictly better than cooperation's k/n < 1)
    - Middle rounds: Defection yields maximum payoff regardless of others' cooperation rates
    - Final round: No future punishment possible; defection maximizes immediate payoff

    The strategy exploits cooperators by free-riding on their contributions while
    avoiding the cost of cooperation. Against defectors, it matches their payoff.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        return Action.D

class Strategy_EXPLOITATIVE_263(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core philosophy: Exploit the asymmetry in the public goods game by always defecting.
    - Round 0 (first): Defect to test the environment
    - Round r-1 (last): Defect unconditionally (no future punishment possible)
    - Rounds 1 to r-2: Defect based on cooperation rate threshold
      - If previous cooperation rate > k/n: Defect to capture surplus
      - If previous cooperation rate <= k/n: Defect (mutual defection equilibrium)

    This strategy parasitizes cooperative behavior when available and transitions
    to mutual defection when cooperation dries up.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        previous_round_actions = history.opponent_actions[round_number - 1, :]
        cooperator_count = np.sum(previous_round_actions)
        cooperation_rate = cooperator_count / self.n_players
        threshold = self.k / self.n_players
        if cooperation_rate > threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_264(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    Exploits the asymmetry in public goods games by probing opponent cooperation
    tendencies and ruthlessly free-riding on cooperators while avoiding mutual
    defection traps. Uses end-game defection to eliminate final-round exploitation risks.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num >= self.n_rounds - 2:
            return Action.D
        opponent_actions = history.opponent_actions[:round_num + 1, :]
        total_cooperations = np.sum(opponent_actions)
        total_observations = (round_num + 1) * self.n_players
        avg_cooperation = total_cooperations / total_observations if total_observations > 0 else 0.0
        if avg_cooperation > 0.5:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_265(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    This strategy maximizes personal payoff by always defecting. Defection is the
    dominant strategy in this n-player public goods game because:
    - In round 1: No information exists, defection guarantees payoff of 1
    - In mid-rounds: Defection exploits any cooperation (payoff > 1) or ties with defectors (payoff = 1)
    - In final round: No reputation consequences, maximize extraction from any remaining cooperation

    The strategy is parameter-independent and works for any valid (n, k, r) combination.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_266(BaseStrategy):
    """
    Exploitative strategy: Adaptive Defection with Calculated Cooperation.

    Core approach:
    - Defect unconditionally in round 1 and final round
    - In middle rounds, calculate cooperation rate with recency weighting
    - Cooperate only when the expected public good share exceeds a dynamic threshold
    - Systematically exploit high-cooperation environments
    - Adjust threshold more aggressively in later rounds
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        cooperation_rate = self._calculate_cooperation_rate(history, round_num)
        threshold = (self.n - self.k) / (2.0 * self.n)
        if round_num > self.r / 2.0:
            threshold *= 0.8
        if round_num == self.r - 2 and cooperation_rate < 0.4:
            return Action.D
        if cooperation_rate > threshold:
            expected_cooperators = cooperation_rate * self.n
            expected_payoff_cooperate = self.k / self.n * (expected_cooperators + 1.0)
            expected_payoff_defect = 1.0 + self.k / self.n * expected_cooperators
            if expected_payoff_cooperate > 0.5:
                if cooperation_rate > 0.7:
                    return Action.C
                elif expected_payoff_cooperate > expected_payoff_defect * 0.95:
                    return Action.C
        return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_num: int) -> float:
        """
        Calculate observed cooperation rate with recency weighting.
        Recent rounds (last 5) count more heavily than older rounds.
        """
        if history is None or len(history.opponent_actions) == 0:
            return 0.0
        window_size = min(5, len(history.opponent_actions))
        recent_rounds = history.opponent_actions[-window_size:]
        total_weighted_cooperators = 0.0
        total_weight = 0.0
        for i, round_actions in enumerate(recent_rounds):
            weight = 1.0 + i / float(window_size)
            cooperators_in_round = np.sum(round_actions)
            total_weighted_cooperators += cooperators_in_round * weight
            total_weight += weight * self.n
        cooperation_rate = total_weighted_cooperators / total_weight if total_weight > 0 else 0.0
        return cooperation_rate

class Strategy_EXPLOITATIVE_267(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core philosophy: Always defect to free-ride on others' cooperation.
    Uses threshold-based logic (k/n) to identify when exploitation is most profitable,
    but defaults to defection in all cases since defection is the dominant strategy
    in the Public Goods Game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        total_cooperations = np.sum(history.opponent_actions[:state.round_number, :])
        total_observations = state.round_number * (self.game_description.n_players - 1)
        if total_observations == 0:
            return Action.D
        cooperation_rate = total_cooperations / total_observations
        if cooperation_rate >= self.threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_268(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core logic:
    - Round 1: DEFECT (information gathering)
    - Rounds 2 to r-1: COOPERATE if observed cooperators > n/k, else DEFECT
    - Round r: DEFECT (final round exploitation)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.r - 1:
            return Action.D
        previous_round_idx = round_number - 1
        cooperators_last_round = int(sum(history.opponent_actions[previous_round_idx, :]))
        cooperation_threshold = self.n / self.k
        if cooperators_last_round > cooperation_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_269(BaseStrategy):
    """
    Exploitative Adaptive Defection Strategy for N-Player Public Goods Game.

    Core principle: Always defect to parasitize cooperative opponents while avoiding
    losses from misplaced cooperation. Strategy observes opponent cooperation rates
    and maintains defection as the dominant action across all game phases.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.break_even_threshold = self.k / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        if history is None:
            return Action.D
        opponent_actions = history.opponent_actions[:round_number, :]
        if len(opponent_actions) == 0:
            return Action.D
        total_cooperators = np.sum(opponent_actions)
        total_possible = opponent_actions.shape[0] * opponent_actions.shape[1]
        if total_possible == 0:
            return Action.D
        avg_coop_rate = total_cooperators / total_possible
        if avg_coop_rate > self.break_even_threshold:
            return Action.D
        if round_number > self.n_rounds / 3:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_270(BaseStrategy):
    """
    Adaptive Defection with Conditional Cooperation (ADCC) Strategy.

    A purely exploitative strategy that defects in all rounds, regardless of
    opponent cooperation levels. This maximizes personal payoff by:
    - Round 1: Defect to establish baseline and secure maximum private payoff
    - Rounds 2 to r-1: Defect to exploit any level of opponent cooperation
    - Round r: Defect since no shadow of the future exists

    The strategy exploits the payoff structure where defection yields
    1 + (k/n) * (opponent contributions), which always exceeds cooperation's
    0 + (k/n) * (opponent contributions) when k < n.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        return Action.D

class Strategy_EXPLOITATIVE_271(BaseStrategy):
    """
    Exploitative strategy that gathers information about cooperation rates
    during an exploration phase, then defects for the remainder of the game
    to free-ride on any cooperators found.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.exploration_rounds = max(3, math.ceil(game_description.n_rounds / 4))
        self.avg_observed_cooperation = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        if current_round < self.exploration_rounds:
            return Action.C
        if self.avg_observed_cooperation is None:
            cooperation_rates = []
            for round_idx in range(current_round):
                coop_count = int(np.sum(history.opponent_actions[round_idx, :]))
                if history.my_actions[round_idx]:
                    coop_count += 1
                cooperation_rate = coop_count / n
                cooperation_rates.append(cooperation_rate)
            self.avg_observed_cooperation = float(np.mean(cooperation_rates)) if cooperation_rates else 0.0
        if current_round < r:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_272(BaseStrategy):
    """
    Exploitative strategy using adaptive defection with conditional cooperation.

    Core approach: Always defect to exploit the public goods game structure where
    defection is individually rational when others contribute. Monitors cooperation
    rates but consistently chooses defection as it dominates when any cooperation exists.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = game_description.k / game_description.n_players + 0.05

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        previous_round_coop_count = np.sum(history.opponent_actions[state.round_number - 1, :])
        coop_rate = previous_round_coop_count / self.game_description.n_players
        if coop_rate == 0:
            return Action.D
        if coop_rate < 0.1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_273(BaseStrategy):
    """
    Adaptive Exploitative Strategy: Maximizes personal payoff by exploiting
    cooperation asymmetry. Defects in rounds 1 and r, then probabilistically
    cooperates in middle rounds based on cooperation rates relative to a
    dynamically calculated threshold.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        last_round_opponent_actions = history.opponent_actions[round_num - 1, :]
        cooperators_last_round = int(np.sum(last_round_opponent_actions))
        if history.my_actions[round_num - 1]:
            cooperators_last_round += 1
        coop_rate = cooperators_last_round / self.n
        threshold = (self.n - self.k) / (self.n - 1)
        if coop_rate >= threshold:
            exploit_prob = max(0.0, (coop_rate - threshold) / (1.0 - threshold))
            if random.random() < exploit_prob:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_274(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Maximizes personal payoff by always defecting, exploiting any cooperators
    while avoiding losses from defectors. Defection is the dominant strategy
    in public goods games, yielding strictly higher payoff than cooperation
    regardless of opponent behavior.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = (game_description.k + 1) / (2 * game_description.n_players)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        previous_round_idx = state.round_number - 1
        cooperators_last_round = sum(history.opponent_actions[previous_round_idx, :])
        cooperation_rate = cooperators_last_round / self.game_description.n_players
        return Action.D

class Strategy_EXPLOITATIVE_275(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Exploitation

    Maximizes individual payoff by exploiting the asymmetry between defection rewards
    and cooperation costs. Always defects in round 0 and final round. In middle rounds,
    calculates cooperation rate and defects regardless, since defection is always
    mathematically optimal given k < n.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        if state.round_number == 0:
            return Action.D
        if state.round_number == r - 1:
            return Action.D
        total_cooperators = np.sum(history.opponent_actions[:state.round_number, :])
        total_slots = state.round_number * n
        coop_rate = total_cooperators / total_slots if total_slots > 0 else 0.0
        return Action.D

class Strategy_EXPLOITATIVE_276(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    This strategy prioritizes individual payoff maximization by exploiting asymmetries
    between defection and cooperation. It adaptively switches between defection and
    selective cooperation based on observed opponent behavior patterns.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        observed_coop_rate = self._calculate_cooperation_rate(history, window=3)
        cooperation_trend = self._calculate_trend(history)
        volatility = self._calculate_volatility(history, window=3)
        threshold_high = self.k / self.n_players + 0.1
        threshold_low = self.k / self.n_players - 0.1
        if observed_coop_rate > threshold_high:
            return Action.D
        if cooperation_trend < -0.05 and observed_coop_rate > threshold_low:
            return Action.D
        if observed_coop_rate == 0:
            return Action.D
        if volatility > 0.15 and 0.2 < observed_coop_rate < 0.8:
            if random.random() < 0.15:
                return Action.C
            else:
                return Action.D
        if 0.2 <= observed_coop_rate <= 0.7 and volatility <= 0.15:
            return Action.D
        return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, window: int=3) -> float:
        """Calculate proportion of opponents cooperating in recent rounds."""
        total_rounds = len(history.my_actions)
        if total_rounds == 0:
            return 0.0
        start_idx = max(0, total_rounds - window)
        recent_actions = history.opponent_actions[start_idx:, :]
        if len(recent_actions) == 0:
            return 0.0
        cooperators = np.sum(recent_actions)
        total_actions = recent_actions.size
        return float(cooperators) / float(total_actions) if total_actions > 0 else 0.0

    def _calculate_trend(self, history: PlayerHistory) -> float:
        """Calculate cooperation trend: recent average - historical average."""
        total_rounds = len(history.my_actions)
        if total_rounds < 2:
            return 0.0
        window = min(3, total_rounds)
        recent_start = max(0, total_rounds - window)
        recent_avg = float(np.sum(history.opponent_actions[recent_start:, :])) / float((total_rounds - recent_start) * self.n_players)
        historical_avg = float(np.sum(history.opponent_actions[:-window, :])) / float((total_rounds - window) * self.n_players) if total_rounds > window else recent_avg
        return recent_avg - historical_avg

    def _calculate_volatility(self, history: PlayerHistory, window: int=3) -> float:
        """Calculate variance in opponent cooperation rates across recent rounds."""
        total_rounds = len(history.my_actions)
        if total_rounds < 2:
            return 0.0
        start_idx = max(0, total_rounds - window)
        recent_actions = history.opponent_actions[start_idx:, :]
        if len(recent_actions) < 2:
            return 0.0
        round_coop_rates = []
        for round_idx in range(len(recent_actions)):
            rate = float(np.sum(recent_actions[round_idx, :])) / float(self.n_players)
            round_coop_rates.append(rate)
        if len(round_coop_rates) < 2:
            return 0.0
        mean_rate = np.mean(round_coop_rates)
        variance = np.mean([(r - mean_rate) ** 2 for r in round_coop_rates])
        return float(variance)

class Strategy_EXPLOITATIVE_277(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Core philosophy: Extract maximum value from cooperators while minimizing losses.
    - Round 1: Defect (probe)
    - Rounds 2 to r-1: Defect unless cooperation rate >= k/n AND sustained for 2+ rounds
    - Final round: Defect (terminal round exploitation)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.r - 1:
            return Action.D
        total_cooperators = np.sum(history.opponent_actions[:round_number, :])
        total_slots = self.n * round_number
        cooperation_rate = total_cooperators / total_slots
        sustained = False
        if round_number >= 2:
            recent_rounds = history.opponent_actions[round_number - 2:round_number, :]
            cooperators_in_recent = np.sum(recent_rounds)
            sustained = cooperators_in_recent >= (self.n - 1) * 1.5
        elif round_number == 1:
            cooperators_prev = np.sum(history.opponent_actions[0, :])
            sustained = cooperators_prev >= (self.n - 1) * 0.75
        if cooperation_rate >= self.threshold and sustained:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_278(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Maximizes personal payoff by defaulting to defection while strategically
    exploiting cooperative opponents. Uses an exploitation threshold to determine
    when to defect based on observed cooperation rates.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.exploitation_threshold = (1 + game_description.k) / (2 * game_description.k)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        prev_round_cooperators = int(sum(history.opponent_actions[state.round_number - 1, :]))
        cooperation_rate = prev_round_cooperators / self.game_description.n_players
        if cooperation_rate == 0:
            return Action.D
        if cooperation_rate >= self.exploitation_threshold:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_279(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Opportunistic Exploitation

    Core philosophy: Exploit the asymmetry in payoff structure by defecting by default
    while selectively exploiting cooperators when profitable. Maximizes individual payoff
    by refusing to bear cooperation costs while capturing shared benefits.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        n = self.n_players
        r = self.n_rounds
        k = self.k
        if round_number == r - 1:
            return Action.D
        if round_number == 0:
            return Action.D
        if round_number == r - 2:
            recent_cooperators = self._count_recent_cooperators(history, rounds_back=3)
            observed_coop_rate = recent_cooperators / (min(3, round_number + 1) * n)
            if observed_coop_rate > 0.75 and k > n - 1:
                return Action.C
            return Action.D
        recent_cooperators = self._count_recent_cooperators(history, rounds_back=3)
        rounds_available = min(3, round_number + 1)
        observed_coop_rate = recent_cooperators / (rounds_available * n)
        exploitation_threshold = k / n
        if observed_coop_rate > exploitation_threshold:
            return Action.C
        else:
            return Action.D

    def _count_recent_cooperators(self, history: PlayerHistory, rounds_back: int) -> float:
        """
        Count total cooperations in recent rounds.
        Returns the sum of cooperators across the last 'rounds_back' rounds.
        """
        if history is None or len(history.opponent_actions) == 0:
            return 0.0
        available_rounds = min(rounds_back, len(history.opponent_actions))
        recent_history = history.opponent_actions[-available_rounds:, :]
        total_cooperators = float(np.sum(recent_history))
        return total_cooperators

class Strategy_EXPLOITATIVE_280(BaseStrategy):
    """
    Adaptive Defection with Conditional Reciprocal Punishment.

    Exploits the structural vulnerability of public goods games by defaulting to defection
    while selectively cooperating only when it creates asymmetric advantage. The strategy
    prioritizes personal payoff maximization through opportunistic exploitation of cooperators.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.k_over_n = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        prev_round_idx = current_round - 1
        cooperators_prev = int(sum(history.opponent_actions[prev_round_idx, :]))
        coop_rate = cooperators_prev / self.n
        if coop_rate > self.k_over_n:
            return Action.D
        if coop_rate <= 1.0 / self.n:
            return Action.D
        if self.k >= self.n - 1 and coop_rate > 0.8:
            if not history.my_actions[prev_round_idx]:
                return Action.C
            else:
                return Action.D
        expected_payoff_defect = 1.0 + self.k_over_n * cooperators_prev
        expected_payoff_coop = self.k_over_n * (cooperators_prev + 1)
        if expected_payoff_coop > expected_payoff_defect:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_281(BaseStrategy):
    """
    Exploitative Defection with Conditional Parasitism.

    This strategy maximizes payoff by always defecting, exploiting any cooperation
    in the population while avoiding the sucker's payoff. It defects in round 1,
    the final round, and all middle rounds regardless of cooperation levels.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.exploitation_threshold = (game_description.k - 1) / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        total_cooperators = int(np.sum(history.opponent_actions[:state.round_number, :]))
        total_slots = self.game_description.n_players * state.round_number
        cooperation_rate = total_cooperators / total_slots if total_slots > 0 else 0
        if cooperation_rate > self.exploitation_threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_282(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Core philosophy: Exploit the asymmetry in payoff structure by free-riding on
    cooperation while minimizing losses to defectors. Always defects except in edge
    cases, maximizing individual gain through parasitism on cooperators.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_high = 0.6
        self.threshold_low = 0.2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        prev_round_idx = state.round_number - 1
        cooperators_prev = np.sum(history.opponent_actions[prev_round_idx, :])
        coop_density = cooperators_prev / self.game_description.n_players
        if coop_density > self.threshold_high:
            return Action.D
        elif coop_density > self.threshold_low:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_283(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Maximizes personal payoff by freeloading on others' contributions while minimizing
    wasted cooperation. Defects by default unless specific conditions indicate that
    exploitation of cooperators is suboptimal.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.r - 1:
            return Action.D
        total_cooperators = np.sum(history.opponent_actions)
        total_past_actions = round_number * self.n
        cooperation_rate = total_cooperators / total_past_actions
        expected_next_cooperators = cooperation_rate * self.n
        cooperation_threshold = self.n / self.k
        if expected_next_cooperators >= cooperation_threshold and cooperation_rate > 0.3:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_284(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Predation

    This strategy exploits cooperative players by defaulting to defection,
    only cooperating when sufficient others are cooperating to guarantee
    positive returns. It uses an exploitation index to identify high-value
    cooperation opportunities while avoiding mutual defection traps.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.r - 1:
            return Action.D
        previous_round_idx = round_number - 1
        previous_cooperators = int(sum(history.opponent_actions[previous_round_idx, :]))
        if history.my_actions[previous_round_idx]:
            previous_cooperators += 1
        total_cooperators = previous_cooperators
        defection_rate = 1.0 - total_cooperators / self.n
        if defection_rate > 0.5:
            return Action.D
        threshold = math.ceil(self.n * self.k / (self.k + 1.0))
        if total_cooperators >= threshold and total_cooperators >= 3:
            expected_coop_payoff = self.k / self.n * total_cooperators
            expected_def_payoff = 1.0 + self.k / self.n * (total_cooperators - 1.0)
            if expected_coop_payoff > 0.9:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_285(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Exploitation

    Maximizes personal payoff by exploiting cooperators while minimizing losses from defectors.
    Core principle: Always defect, as defection is the unique Nash equilibrium when k < n.

    Decision rule:
    - Round 0 (first round): DEFECT (probe with zero risk)
    - Round r-1 (final round): DEFECT (no future retaliation)
    - Middle rounds: DEFECT based on cooperation rate vs. threshold

    The strategy exploits the asymmetry that defectors always gain more than cooperators
    when k < n, while maintaining adaptivity through threshold-based observation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.epsilon = 0.01

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        if history is not None:
            previous_round_actions = history.opponent_actions[current_round - 1, :]
            cooperation_count = int(np.sum(previous_round_actions))
            cooperation_rate = cooperation_count / self.n
            threshold = self.k / (self.n - 1) - self.epsilon
            if cooperation_rate >= threshold:
                return Action.D
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_286(BaseStrategy):
    """
    Exploitative Defection with Selective Parasitism.

    Core strategy: Always defect to maximize personal payoff by exploiting
    cooperative contributions without reciprocating. Defection is the dominant
    strategy in each round, and this strategy implements it consistently across
    all rounds, including first and last rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        cooperation_last_round = sum(history.opponent_actions[-1, :])
        threshold = self.game_description.n_players / 2
        return Action.D

class Strategy_EXPLOITATIVE_287(BaseStrategy):
    """
    Adaptive Parasitic Harvesting Strategy

    A purely exploitative strategy that unconditionally defects throughout the game.
    The strategy maximizes payoff by free-riding on any cooperation that emerges while
    avoiding the risks of cooperation. In all rounds, defection is the dominant action:
    - Round 1: Defect to gather information at no cost
    - Rounds 2 to r-1: Defect to exploit cooperators or minimize loss against defectors
    - Final round: Defect with no shadow of the future

    The strategy extracts +1 payoff per round from any cooperators while maintaining
    baseline payoff of 1 against all defectors.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.r - 1:
            return Action.D
        last_round_cooperators = np.sum(history.opponent_actions[state.round_number - 1, :])
        cooperation_rate = last_round_cooperators / self.n
        cooperation_threshold = (self.k - 1) / (2 * self.k)
        return Action.D

class Strategy_EXPLOITATIVE_288(BaseStrategy):
    """
    Adaptive Defection with Conditional Parasitism.

    Exploitative strategy that always defects to maximize personal gain.
    - Round 1: Defect (no history, establish as exploiter)
    - Rounds 2 to r-1: Defect (exploit any cooperation, safe against defectors)
    - Final round: Defect (no future consequences, backward induction)

    Core insight: Defection is weakly dominant. Defecting captures the public good
    benefits from cooperators while keeping private endowment, strictly dominating
    cooperation which only yields a share of the public good.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_289(BaseStrategy):
    """
    Adaptive Parasite: An exploitative strategy that identifies and extracts value from
    cooperative players while minimizing losses from defectors. Maximizes personal payoff
    through free-riding on public goods and periodic baiting of conditional cooperators.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.bait_rounds_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        if current_round == self.n_rounds - 2:
            return Action.D
        prev_rounds = current_round
        total_cooperators = np.sum(history.opponent_actions[:current_round, :])
        cooperation_rate = total_cooperators / (prev_rounds * self.n_players)
        efficiency_threshold = self.k / self.n_players
        total_defectors = prev_rounds * self.n_players - total_cooperators
        defection_rate = total_defectors / (prev_rounds * self.n_players)
        if self.bait_rounds_remaining > 0:
            self.bait_rounds_remaining -= 1
            return Action.C
        if defection_rate > 0.7:
            return Action.D
        if cooperation_rate > efficiency_threshold:
            return Action.D
        if cooperation_rate < 0.3:
            return Action.D
        if current_round % 5 == 0 and cooperation_rate >= 0.3 and (cooperation_rate <= 0.7):
            self.bait_rounds_remaining = 2
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_290(BaseStrategy):
    """
    Adaptive Predation: An exploitative strategy that free-rides on cooperators
    while avoiding vulnerability to defectors. Defects in round 1 and final round,
    then adaptively exploits based on observed cooperation rates in middle rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        previous_round_idx = current_round - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[previous_round_idx, :]))
        cooperation_rate = cooperators_last_round / self.n
        threshold_high = max(0.4, self.k / (self.n - 1) + 0.1)
        threshold_low = 0.2
        if cooperation_rate >= threshold_high:
            return Action.D
        elif cooperation_rate > threshold_low:
            my_last_action = history.my_actions[previous_round_idx]
            if not my_last_action:
                return Action.D
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_291(BaseStrategy):
    """
    Adaptive Predation: An exploitative strategy that systematically exploits cooperative
    tendencies while minimizing vulnerability to defection. Defects by default, with
    probabilistic cooperation only when rare cooperators can be baited into reciprocation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.D
        if round_t == self.r - 1:
            return Action.D
        coop_rate = self._compute_rolling_coop_rate(history, round_t)
        threshold = max(0.15, self.k / self.n - 0.05)
        rounds_remaining = self.r - round_t
        if rounds_remaining < self.r / 4:
            threshold = max(0.05, threshold - 0.1)
        if coop_rate > threshold + 0.1:
            return Action.D
        elif coop_rate < threshold:
            cooperation_probability = 0.4 * (1.0 - coop_rate)
            if random.random() < cooperation_probability:
                return Action.C
            else:
                return Action.D
        elif random.random() < 0.9:
            return Action.D
        else:
            return Action.C

    def _compute_rolling_coop_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Compute exponential moving average of cooperation rates from recent rounds.
        Uses window of up to 3 most recent rounds with weights: recent=0.6, older=0.4
        """
        if current_round == 0:
            return 0.0
        start_idx = max(0, current_round - 3)
        window_rounds = current_round - start_idx
        if window_rounds == 0:
            return 0.0
        coop_counts = []
        for i in range(start_idx, current_round):
            cooperators = int(np.sum(history.opponent_actions[i, :]))
            coop_counts.append(cooperators)
        if window_rounds == 1:
            weighted_coop = coop_counts[0] / self.n
        elif window_rounds == 2:
            weighted_coop = (0.4 * coop_counts[0] + 0.6 * coop_counts[1]) / self.n
        else:
            weighted_coop = (0.2 * coop_counts[0] + 0.4 * coop_counts[1] + 0.6 * coop_counts[2]) / self.n
        return weighted_coop

class Strategy_EXPLOITATIVE_292(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Core philosophy: Exploit the asymmetry between defectors and cooperators by free-riding
    on cooperation while avoiding mutual defection traps. Adapts to opponent types by
    monitoring cooperation rates and switching between exploitation and pool maintenance.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n_players + 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        observed_coop_rate = self._calculate_observed_cooperation_rate(history, round_number)
        if observed_coop_rate >= self.threshold:
            return Action.D
        else:
            return Action.C

    def _calculate_observed_cooperation_rate(self, history: PlayerHistory, current_round: int) -> float:
        """
        Calculate the observed cooperation rate from all previous rounds.

        observed_coop_rate = total_cooperators_observed / (n_players - 1) * current_round

        We observe n_players - 1 opponents per round, so over current_round rounds,
        we have (n_players - 1) * current_round total observations.
        """
        if current_round == 0:
            return 0.0
        total_cooperations = int(np.sum(history.opponent_actions[:current_round, :]))
        total_observations = (self.n_players - 1) * current_round
        if total_observations == 0:
            return 0.0
        coop_rate = total_cooperations / total_observations
        return coop_rate

class Strategy_EXPLOITATIVE_293(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Always defects to maximize payoff. In the public goods game where k < n,
    defection dominates cooperation. The strategy:
    - Defects in round 1 to gather information
    - Defects in the final round (no reputation consequence)
    - Defects in middle rounds based on observed cooperation rates
    - Exploits cooperators when the cooperation rate exceeds k/n threshold
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.exploitation_threshold = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        total_cooperators = int(np.sum(history.opponent_actions[:current_round, :]))
        total_player_rounds = self.n * current_round
        observed_coop_rate = total_cooperators / total_player_rounds if total_player_rounds > 0 else 0
        if observed_coop_rate > self.exploitation_threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_294(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Maximizes personal payoff by exploiting cooperative tendencies in others while
    minimizing own contribution costs. Uses strategic defection with occasional
    deceptive cooperation to avoid detection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.cooperation_threshold = self.k / self.n_players + 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        window_size = min(3, current_round)
        recent_rounds = history.opponent_actions[-window_size:, :]
        total_cooperators_recent = np.sum(recent_rounds)
        total_possible = window_size * self.n_players
        cooperation_rate = total_cooperators_recent / total_possible if total_possible > 0 else 0.0
        if cooperation_rate > self.cooperation_threshold:
            my_last_payoff = history.my_payoffs[-1]
            average_payoff_last_round = np.mean(history.opponent_payoffs[-1, :])
            was_defecting_last_round = not history.my_actions[-1]
            if was_defecting_last_round and my_last_payoff > average_payoff_last_round:
                return Action.D
            elif random.random() < 0.15:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_295(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    Maximizes payoff by defecting unless observed cooperation rate exceeds threshold (1/k).
    Always defects in round 1 and final round based on backward induction.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = 1.0 / game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        previous_round_idx = current_round - 1
        cooperators_count = int(sum(history.opponent_actions[previous_round_idx, :]))
        observed_coop_rate = cooperators_count / n
        if observed_coop_rate > self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_296(BaseStrategy):
    """
    ADAPTIVE PREDATION: Always-Defect exploitative strategy for N-Player Public Goods Game.

    Core principle: Defect every round to free-ride on others' contributions.
    Defection is strictly dominant regardless of cooperation levels, as long as k < n.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        prev_round_idx = state.round_number - 1
        prev_cooperators = np.sum(history.opponent_actions[prev_round_idx, :])
        prev_coop_rate = prev_cooperators / self.game_description.n_players
        profitability_threshold = self.game_description.k / self.game_description.n_players
        if prev_coop_rate >= profitability_threshold:
            return Action.D
        else:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_297(BaseStrategy):
    """
    Adaptive Predation Strategy: Exploits cooperative players through strategic defection.

    Core mechanics:
    - Default to defection to capture private endowment + share of others' contributions
    - Identify cooperation rate in early rounds
    - Maintain defection when cooperators are present to maximize exploitation
    - Execute end-game defection without retaliation risk
    - Occasionally cooperate when cooperation rate is high to sustain opponent engagement
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.defect_count = 0
        self.cooperate_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        n_rounds = self.game_description.n_rounds
        n_players = self.game_description.n_players
        if round_num == 0:
            return Action.D
        total_rounds_played = round_num
        total_cooperators = int(np.sum(history.opponent_actions[:round_num, :]))
        cooperation_rate = total_cooperators / (total_rounds_played * n_players) if total_rounds_played > 0 else 0.0
        if round_num <= 2:
            return Action.D
        if round_num >= n_rounds - 2:
            return Action.D
        if cooperation_rate > 0.3:
            if round_num % 5 == 0 and cooperation_rate > 0.4:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_298(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism: A pure exploitative strategy
    that always defects to free-ride on any cooperation while avoiding the costs
    of contributing to the public good.

    Core insight: Defection is individually rational in all rounds because:
    - Defectors earn 1 + (k/n)  total_contributions
    - Cooperators earn 0 + (k/n)  total_contributions
    - The +1 advantage is constant regardless of opponent behavior

    Therefore, always defecting maximizes payoff against any opponent configuration.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        """
        Decision rule: ALWAYS DEFECT

        This applies uniformly across all rounds because:
        - Round 1: No history to exploit, but defection guarantees minimum payoff of 1
        - Rounds 2 to r-1: Regardless of cooperation_density, defection dominates
        - Round r: Final round has no reputational concerns; defection dominates

        The strategy is robust because it performs well against:
        - Cooperators: We free-ride earning 1 + (k/n)  contributions
        - Other defectors: We tie at mutual payoff of 1
        - Mixed/conditional strategies: We guarantee at least 1 per round
        """
        return Action.D

class Strategy_EXPLOITATIVE_299(BaseStrategy):
    """
    Adaptive Predation: An exploitative strategy that maximizes payoff by consistently
    defecting to free-ride on cooperators' contributions while avoiding retaliation costs.

    Core logic:
    - Round 1: Defect to establish non-cooperation baseline
    - Rounds 2 to r-1: Defect to free-ride on any cooperators
    - Final round: Defect (no future punishment risk)

    This strategy exploits the asymmetry where defectors gain 1 unit relative to
    cooperators when others contribute, while capturing their public good benefits.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_rate = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == 1:
            round_1_cooperators = sum(history.opponent_actions[0, :])
            self.cooperation_rate = round_1_cooperators / self.game_description.n_players
        if state.round_number < self.game_description.n_rounds - 1:
            current_round_idx = state.round_number - 1
            current_cooperators = sum(history.opponent_actions[current_round_idx, :])
            if current_cooperators >= math.ceil(self.game_description.k):
                if self.cooperation_rate > 0.5 and state.round_number < self.game_description.n_rounds - 2:
                    return Action.D
                elif self.cooperation_rate <= 0.5 and current_cooperators > 0:
                    return Action.D
                elif current_cooperators == 1:
                    return Action.D
                else:
                    return Action.D
            elif self.cooperation_rate == 0:
                return Action.D
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_300(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    This strategy exploits the public goods game by always defecting, with special
    attention to the first and last rounds for information gathering and terminal
    exploitation respectively. In middle rounds, it adapts based on observed cooperation
    rates relative to a mathematically-derived threshold.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold_k = (self.k - 1) / (self.n - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.r - 1:
            return Action.D
        total_cooperators_observed = np.sum(history.opponent_actions[:round_number, :])
        total_observations = round_number * self.n
        obs_coop_rate = total_cooperators_observed / total_observations
        if obs_coop_rate >= self.threshold_k:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_301(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Exploitation

    This strategy exploits the structural vulnerability of public goods games by:
    1. Always defecting in round 1 to establish free-riding behavior
    2. In middle rounds, defecting when cooperation rate exceeds k/n threshold
    3. Always defecting in the final round to maximize end-game extraction

    The core insight is that defection is always optimal: you capture the public good
    benefit from cooperators while avoiding the cost of contribution.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.exploitation_threshold = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        previous_round_idx = current_round - 1
        total_cooperators_previous = sum(history.opponent_actions[previous_round_idx, :])
        coop_rate = total_cooperators_previous / self.n
        return Action.D

class Strategy_EXPLOITATIVE_302(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    This strategy exploits the fundamental asymmetry in public goods games by:
    1. Defaulting to defection to avoid sucker's payoff
    2. Cooperating only when public good is sufficiently large
    3. Always defecting in final round for end-game extraction
    4. Using adaptive thresholds based on recent cooperation rates
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.margin_of_safety = 0.05

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        prev_round_cooperators = int(np.sum(history.opponent_actions[round_number - 1, :]))
        cooperation_last_round = prev_round_cooperators / self.n_players
        threshold = max(0.4, cooperation_last_round - 0.1)
        if cooperation_last_round < threshold:
            return Action.D
        expected_public_contribution = cooperation_last_round * self.k / self.n_players
        if expected_public_contribution > 1.0 + self.margin_of_safety:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_303(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    This strategy exploits the Public Goods Game by recognizing that defection is dominant.
    It defects in round 1 (probe), adapts based on cooperation ratios in middle rounds,
    and defects in the final round (no reputation cost).

    Core logic: Always defect, as defection dominates cooperation in all scenarios.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        previous_round_idx = state.round_number - 1
        cooperators_count = int(sum(history.opponent_actions[previous_round_idx, :]))
        coop_ratio = cooperators_count / self.game_description.n_players
        threshold = 1.0 / self.game_description.k
        return Action.D

class Strategy_EXPLOITATIVE_304(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Maximizes payoff by free-riding on cooperative players through systematic defection,
    with adaptive monitoring of cooperation rates to track and exploit shifting dynamics.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.intelligence_phase_length = max(3, math.ceil(0.1 * self.n_rounds))
        self.exploitation_start = self.intelligence_phase_length
        self.late_game_start = max(self.exploitation_start + 1, self.n_rounds - 2)
        self.cooperation_history = []
        self.last_cooperation_rate = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num < self.intelligence_phase_length:
            return Action.D
        if round_num >= self.late_game_start:
            return Action.D
        self._update_cooperation_estimates(history, round_num)
        return Action.D

    def _update_cooperation_estimates(self, history: PlayerHistory, round_num: int) -> None:
        """
        Update cooperation rate estimates based on observed opponent actions.
        Uses moving average of last 3 rounds to smooth oscillations.
        """
        if history is None or round_num == 0:
            self.last_cooperation_rate = 0.0
            return
        rounds_to_analyze = min(3, round_num)
        start_idx = round_num - rounds_to_analyze
        total_cooperations = 0
        total_observations = 0
        for i in range(start_idx, round_num):
            cooperations_in_round = np.sum(history.opponent_actions[i, :])
            total_cooperations += cooperations_in_round
            total_observations += self.n_players - 1
        if total_observations > 0:
            self.last_cooperation_rate = total_cooperations / total_observations
        else:
            self.last_cooperation_rate = 0.0
        self.cooperation_history.append(self.last_cooperation_rate)

class Strategy_EXPLOITATIVE_305(BaseStrategy):
    """
    Adaptive Parasitism Strategy for N-Player Public Goods Game.

    Exploits cooperative players through conditional free-riding while adapting
    to avoid mutual defection traps. Uses exponentially-weighted recent cooperation
    rates to determine exploitation intensity across game phases.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.decay_weights = [0.1, 0.2, 0.3, 0.4]
        self.threshold_high = 0.65
        self.threshold_mid = 0.4
        self.threshold_low = 0.2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        recent_coop_rate = self._calculate_recent_cooperation_rate(current_round, history)
        if recent_coop_rate > self.threshold_high:
            return Action.D
        elif recent_coop_rate > self.threshold_mid:
            defect_prob = 1.0 - recent_coop_rate
            if random.random() < defect_prob:
                return Action.D
            else:
                return Action.C
        elif recent_coop_rate > self.threshold_low:
            if random.random() < 0.4:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _calculate_recent_cooperation_rate(self, current_round: int, history: PlayerHistory) -> float:
        """
        Calculate exponentially-weighted cooperation rate from recent rounds.
        Emphasizes last 4 rounds with weights [0.1, 0.2, 0.3, 0.4].
        """
        num_recent_rounds = min(4, current_round)
        cooperation_sum = 0.0
        weight_sum = 0.0
        for i in range(num_recent_rounds):
            round_idx = current_round - 1 - i
            weight_idx = num_recent_rounds - 1 - i
            weight = self.decay_weights[weight_idx]
            cooperators_in_round = float(np.sum(history.opponent_actions[round_idx, :]))
            cooperation_sum += cooperators_in_round * weight
            weight_sum += weight
        if weight_sum > 0:
            recent_coop_rate = cooperation_sum / weight_sum / (self.n_players - 1)
        else:
            recent_coop_rate = 0.0
        recent_coop_rate = max(0.0, min(1.0, recent_coop_rate))
        return recent_coop_rate

class Strategy_EXPLOITATIVE_306(BaseStrategy):
    """
    Exploitative Defection with Conditional Parasitism Strategy.

    This strategy exploits the public goods game by:
    1. Always defecting as the dominant strategy when k < n
    2. Never cooperating unless mathematically forced (which never occurs)
    3. Parasitizing on any cooperators in the environment
    4. Intensifying defection in the final round with zero future consequences

    The core insight: cooperation is collectively irrational and individually exploitable
    when the multiplication factor k is less than the number of players n.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == self.n_rounds - 1:
            return Action.D
        if current_round == 0:
            return Action.D
        observed_cooperators = np.sum(history.my_actions) + np.sum(history.opponent_actions)
        observed_total_actions = current_round * self.n_players
        cooperation_rate = observed_cooperators / observed_total_actions if observed_total_actions > 0 else 0
        threshold = 1.0 / self.k
        if cooperation_rate > threshold:
            return Action.D
        else:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_307(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    Maximizes individual payoff by exploiting cooperators while minimizing losses from defectors.
    Always defects except in carefully bounded tactical situations. Treats cooperation as a
    resource to be extracted, not a norm to be reciprocated.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n_players + 0.1
        self.last_probe_round = -10

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        total_cooperators = 0
        for round_idx in range(current_round):
            round_cooperators = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += round_cooperators
        cooperation_rate = total_cooperators / (current_round * self.n_players)
        if cooperation_rate >= self.threshold:
            return Action.D
        if cooperation_rate > 0.15:
            if current_round - self.last_probe_round >= 3:
                self.last_probe_round = current_round
                return Action.C
            return Action.D
        if cooperation_rate <= 0.15:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_308(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core approach: Always defect to exploit cooperators, with rare contingent cooperation
    when cooperation rate is extremely high (>75%) and past halfway point.
    Dominates because defection is always a best-response when k < n.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_high = 0.5
        self.threshold_medium = 0.25
        self.threshold_critical = 0.75
        self.p_adapt = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        prev_cooperators = sum(history.opponent_actions[current_round - 1, :])
        cooperation_rate = prev_cooperators / n
        if cooperation_rate > self.threshold_critical and current_round >= r / 2:
            if random.random() < self.p_adapt:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_309(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Exploitation

    Exploits the asymmetry in public goods games by defecting against cooperators
    while minimizing losses against defectors. Uses adaptive thresholds based on
    observed cooperation rates to maximize relative gains.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.k - 1) / self.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        opponent_actions = history.opponent_actions[:current_round, :]
        total_cooperations = np.sum(opponent_actions)
        total_opponent_actions = (self.n - 1) * current_round
        if total_opponent_actions == 0:
            cooperation_rate = 0.0
        else:
            cooperation_rate = total_cooperations / total_opponent_actions
        if cooperation_rate > self.threshold:
            return Action.D
        elif cooperation_rate > self.threshold / 2:
            if random.random() < cooperation_rate:
                return Action.D
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_310(BaseStrategy):
    """
    Exploitative strategy for N-Player Public Goods Game.

    Core approach: Always defect to exploit cooperators and avoid the sucker's payoff.
    Defection is the dominant strategy when k < n (guaranteed by game spec).
    Tracks opponent cooperation rates but maintains defection as the primary tactic.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_threshold = 0.3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        opponent_coop_rates = np.mean(history.opponent_actions, axis=0)
        avg_coop_rate = np.mean(opponent_coop_rates)
        rounds_remaining = self.game_description.n_rounds - state.round_number
        if avg_coop_rate > self.cooperation_threshold and rounds_remaining > 1:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_311(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Calculated Cooperation

    Maximizes personal payoff by exploiting cooperative tendencies in others while
    minimizing vulnerability to defection. Uses strategic signaling through occasional
    cooperation to build false trust, then exploits increased cooperation through defection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        other_cooperators = int(np.sum(history.opponent_actions[round_number - 1, :]))
        coop_rate = other_cooperators / (self.n_players - 1) if self.n_players > 1 else 0
        threshold = self.k / self.n_players
        if coop_rate >= threshold:
            return Action.D
        elif coop_rate < threshold and round_number <= self.n_rounds - 3:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_312(BaseStrategy):
    """
    Ruthless Defection: Exploitative strategy that defects in all rounds to maximize payoff.

    Core principle: Defection is individually rational in the public goods game.
    - Against cooperators: Extract maximum value by defecting while they contribute
    - Against defectors: Achieve parity with mutual defection (payoff = 1)
    - No incentive to cooperate given finite rounds and k < n
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_313(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core approach: Always defect to maximize personal payoff by free-riding on others'
    contributions. Defection is always weakly dominant in this public goods game structure.
    Tracks opponent cooperation patterns for informational purposes only, but action
    remains defection across all scenarios and rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.opponent_cooperation_counts = np.zeros(game_description.n_players - 1)
        self.threshold = (game_description.k - 1) / game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        if history is not None and state.round_number > 0:
            previous_round_idx = state.round_number - 1
            self.opponent_cooperation_counts += history.opponent_actions[previous_round_idx, :]
            rounds_elapsed = state.round_number
            opponent_coop_rates = self.opponent_cooperation_counts / rounds_elapsed
            for opponent_idx, coop_rate in enumerate(opponent_coop_rates):
                if coop_rate > 0.7:
                    pass
                elif 0.3 <= coop_rate <= 0.7:
                    pass
                else:
                    pass
        if history is not None:
            previous_round_idx = state.round_number - 1
            total_cooperators = np.sum(history.opponent_actions[previous_round_idx, :])
            cooperation_rate = total_cooperators / self.game_description.n_players
        return Action.D

class Strategy_EXPLOITATIVE_314(BaseStrategy):
    """
    Adaptive Defection with Conditional Cooperation strategy for N-Player Public Goods Game.

    This strategy exploits the dominant strategy advantage of defection while adapting to
    opponent cooperation rates. It defects in round 1 and the final round unconditionally,
    and uses a probabilistic defection strategy in intermediate rounds based on observed
    cooperation rates.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_1 = 0.4
        self.threshold_2 = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        n_rounds = self.game_description.n_rounds
        n_players = self.game_description.n_players
        if current_round == 0:
            return Action.D
        if current_round == n_rounds - 1:
            return Action.D
        total_cooperators = 0
        for round_idx in range(current_round):
            total_cooperators += np.sum(history.opponent_actions[round_idx, :])
        cooperation_rate = total_cooperators / (current_round * n_players)
        if cooperation_rate > self.threshold_1:
            return Action.D
        elif cooperation_rate > self.threshold_2:
            p_defect = 0.8 + 0.2 * cooperation_rate
            if random.random() < p_defect:
                return Action.D
            else:
                return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_315(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Exploitation

    Maximizes payoff by defaulting to defection, exploiting cooperative opponents,
    and adapting only when defection becomes unprofitable. Uses threshold-based
    logic with thresholds derived from game parameters k and n.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.exploitation_threshold = self.k / self.n
        self.engagement_threshold = self.k / (2 * self.n)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        opponent_actions = history.opponent_actions[:current_round, :]
        total_opponent_cooperations = float(np.sum(opponent_actions))
        total_possible_opponent_plays = float((self.n - 1) * current_round)
        cooperation_rate = total_opponent_cooperations / total_possible_opponent_plays if total_possible_opponent_plays > 0 else 0.0
        if cooperation_rate > self.exploitation_threshold:
            return Action.D
        if cooperation_rate < self.engagement_threshold:
            return Action.D
        opponent_coop_last_round = np.sum(history.opponent_actions[current_round - 1, :]) / float(self.n - 1)
        if opponent_coop_last_round > 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_316(BaseStrategy):
    """
    Adaptive Defection with Selective Farming: An exploitative strategy that
    always defects to maximize payoff by parasitizing cooperators while avoiding
    mutual defection traps. Never cooperates, as defection is risk-dominant and
    always yields equal or better payoffs than cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold_upper = (self.k - 1) / self.k
        self.threshold_lower = 1 / (2 * self.n)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_317(BaseStrategy):
    """
    Adaptive Predation: An exploitative strategy that free-rides on cooperators,
    selectively cooperates only when profitable, and defects in final rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        if self.n == 2:
            self.threshold_high = 0.4
            self.threshold_low = 0.1
        elif self.k < 1.2:
            self.threshold_high = 0.6
            self.threshold_low = 0.05
        else:
            self.threshold_high = 0.5
            self.threshold_low = 0.15
        self.cooperation_exit_round = max(1, self.r - 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num >= self.cooperation_exit_round:
            return Action.D
        total_cooperators = 0
        total_player_rounds = round_num * self.n
        for t in range(round_num):
            total_cooperators += np.sum(history.opponent_actions[t, :])
        cooperation_rate = total_cooperators / total_player_rounds if total_player_rounds > 0 else 0.0
        recent_window = min(3, round_num)
        recent_start = round_num - recent_window
        recent_cooperators = 0
        for t in range(recent_start, round_num):
            recent_cooperators += np.sum(history.opponent_actions[t, :])
        recent_cooperation_rate = recent_cooperators / (recent_window * self.n) if recent_window > 0 else 0.0
        if cooperation_rate > self.threshold_high:
            return Action.D
        elif cooperation_rate < self.threshold_low:
            return Action.D
        else:
            expected_return = self.k / self.n * recent_cooperation_rate
            if expected_return >= 0.5:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_318(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Exploitation

    Maximizes personal payoff by exploiting cooperators while minimizing losses from defection.
    Defects by default, with thresholds for when cooperation might theoretically maximize exploitation.
    Given the payoff structure (k < n), defection is mathematically dominant in almost all scenarios.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.exploitation_threshold = self.n_players * self.k / (self.n_players - self.k + 1)
        self.abandonment_threshold = self.k / (2 * self.n_players)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        prev_round_idx = current_round - 1
        cooperators_last_round = sum(history.opponent_actions[prev_round_idx, :])
        cooperation_rate = cooperators_last_round / self.n_players
        if cooperation_rate >= self.exploitation_threshold:
            return Action.D
        if cooperation_rate <= self.abandonment_threshold:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_319(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    This strategy exploits the asymmetry in public goods games by:
    1. Always defecting in round 1 to establish exploiter identity
    2. Always defecting in the final round (no future punishment possible)
    3. Adaptively defecting in middle rounds based on cooperation rates
    4. Converging to mutual defection equilibrium against other defectors
    5. Free-riding on any cooperators present
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        prev_round_opponent_actions = history.opponent_actions[round_number - 1, :]
        cooperators_prev = int(sum(prev_round_opponent_actions))
        cooperation_rate = cooperators_prev / self.n_players
        k_ratio = self.k / self.n_players
        alpha = 0.3 if k_ratio > 0.5 else 0.5
        beta = 0.05
        if cooperation_rate >= alpha:
            return Action.D
        elif cooperation_rate > beta:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_320(BaseStrategy):
    """
    Adaptive Predation: An exploitative strategy that systematically defects
    to maximize personal payoff in N-player public goods games.

    Core insight: Defection dominates cooperation across all game scenarios.
    The strategy identifies when cooperation rates exceed the exploitation
    threshold (k/n) and maintains defection to capture asymmetric gains.
    In all other cases, defection remains the safer baseline strategy.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.exploitation_threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        previous_round_index = current_round - 1
        cooperators_previous_round = np.sum(history.opponent_actions[previous_round_index, :])
        coop_rate_previous_round = cooperators_previous_round / self.n_players
        if coop_rate_previous_round > self.exploitation_threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_321(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism: Exploits cooperative opponents
    through strategic defection in early phases, with selective cooperation in
    mid-game to rebuild exploitation opportunities, followed by unconditional
    defection in endgame.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.R1 = math.floor(self.r * 0.6)
        self.R2 = math.floor(self.r * 0.85)
        self.threshold = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round > self.R2:
            return Action.D
        if current_round <= self.R1:
            return Action.D
        opponent_actions = history.opponent_actions
        cooperators_per_round = np.sum(opponent_actions, axis=1)
        cooperation_ratios = cooperators_per_round / self.n
        avg_cooperation = np.mean(cooperation_ratios)
        rounds_remaining = self.r - current_round
        opponent_defections = np.sum(~opponent_actions)
        if avg_cooperation > self.threshold:
            if rounds_remaining > 5 and opponent_defections < self.n * current_round / 2:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_322(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    Exploits the asymmetry in public goods games by:
    1. Defecting in round 1 to observe opponent strategies
    2. Adaptively exploiting cooperators in middle rounds based on cooperation rate
    3. Unconditionally defecting in the final round
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = 0.4
        self.multiplier_ratio = self.k / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        opponent_actions = history.opponent_actions[:round_number, :]
        total_cooperators = np.sum(opponent_actions)
        max_possible_observations = (self.n_players - 1) * round_number
        if max_possible_observations == 0:
            cooperation_rate = 0.0
        else:
            cooperation_rate = total_cooperators / max_possible_observations
        if cooperation_rate >= self.threshold:
            return Action.D
        elif self.multiplier_ratio > 0.6:
            if round_number <= 2:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_323(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Maximizes personal payoff by exploiting cooperative players while avoiding mutual defection traps.
    Core logic:
    - Round 0 (first): DEFECT to establish baseline and gather information
    - Final round: DEFECT (no future consequences, strictly dominant)
    - Middle rounds: DEFECT if cooperation rate > k/n (exploitation threshold)
    - Endgame desperation: COOPERATE only if score is critically low with 2 rounds left
    - Default: DEFECT
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.exploitation_threshold = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        rounds_total = self.r
        if round_number == rounds_total - 1:
            return Action.D
        if round_number == 0:
            return Action.D
        last_round_opponent_actions = history.opponent_actions[round_number - 1, :]
        cooperators_in_last_round = np.sum(last_round_opponent_actions)
        cooperation_rate = cooperators_in_last_round / self.n
        if cooperation_rate > self.exploitation_threshold:
            return Action.D
        rounds_remaining = rounds_total - round_number
        if rounds_remaining <= 2:
            my_cumulative_payoff = np.sum(history.my_payoffs)
            average_payoff = np.mean(history.my_payoffs) if len(history.my_payoffs) > 0 else 1.0
            desperation_threshold = 0.7 * average_payoff * round_number
            if my_cumulative_payoff < desperation_threshold:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_324(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    This strategy exploits the fundamental incentive structure of the public goods game
    by always defecting. The core insight is that defection is individually rational in
    this game structure, allowing the strategy to:
    1. Identify and exploit cooperators
    2. Extract maximum value from the game
    3. Adapt to opponent behavior
    4. Avoid vulnerability to retaliation

    Decision rule: ALWAYS DEFECT
    - Round 0 (first): Defect (no history to evaluate)
    - Rounds 1 to r-2: Defect (exploit any cooperators, defection dominates)
    - Round r-1 (final): Defect (no future punishment possible)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        prev_round_idx = current_round - 1
        cooperators_in_prev = sum(history.opponent_actions[prev_round_idx, :])
        cooperation_rate = cooperators_in_prev / self.n_players
        if cooperation_rate >= self.threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_325(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core principle: Exploit asymmetry between private retention (1 unit guaranteed)
    and public good returns (dependent on others' cooperation). Systematically defect
    to extract value while minimizing contribution costs.

    Decision logic:
    - Round 1 (Reconnaissance): DEFECT to identify cooperators
    - Rounds 2 to r-1 (Exploitation): DEFECT unless cooperation rate exceeds threshold
    - Final round: DEFECT (no future consequences)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n_players + 0.05

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[current_round - 1, :]))
        cooperation_rate = cooperators_last_round / self.n_players
        return Action.D

class Strategy_EXPLOITATIVE_326(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Core approach: Defect in rounds 1-2 to establish non-cooperation, then defect
    in all remaining rounds regardless of observed cooperation rates. This strategy
    treats cooperation as a resource to extract rather than a norm to reciprocate.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        if current_round <= 1:
            return Action.D
        if current_round == r - 1:
            return Action.D
        cooperators_last_round = sum(history.opponent_actions[current_round - 1, :])
        coop_rate = cooperators_last_round / n
        threshold = k / n
        return Action.D

class Strategy_EXPLOITATIVE_327(BaseStrategy):
    """
    Adaptive Defection with Conditional Parasitism

    Exploitative strategy that defaults to defection while monitoring opponents
    for naive cooperators to systematically exploit. Uses early-game observation,
    mid-game parasitism, and end-game pure defection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.coop_threshold = 0.7
        self.opponent_coop_history = {}

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        n_rounds = self.game_description.n_rounds
        n_players = self.game_description.n_players
        if round_num <= 2:
            return Action.D
        if round_num >= n_rounds - 2:
            return Action.D
        if history is not None:
            opponent_coop_rates = {}
            look_back_rounds = min(5, round_num)
            for opponent_idx in range(n_players - 1):
                start_round = max(0, round_num - look_back_rounds)
                coop_count = 0
                round_count = 0
                for past_round in range(start_round, round_num):
                    if history.opponent_actions[past_round, opponent_idx]:
                        coop_count += 1
                    round_count += 1
                if round_count > 0:
                    coop_rate = coop_count / round_count
                    opponent_coop_rates[opponent_idx] = coop_rate
            naive_cooperators_count = 0
            for opponent_idx, coop_rate in opponent_coop_rates.items():
                if coop_rate >= self.coop_threshold:
                    naive_cooperators_count += 1
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_328(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    This strategy exploits the fundamental asymmetry in the public goods game by:
    1. Always defecting in round 1 (no history to condition on)
    2. Defecting whenever observed cooperation rate > k/n (parasitizing cooperators)
    3. Defecting when cooperation rate  k/n (mutual defection is optimal)
    4. Always defecting in the final round (no future punishment mechanism)

    Core insight: Defection is individually rational against any cooperation rate,
    making this a purely exploitative strategy that maximizes personal payoff.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        cooperators_in_prev_round = sum(history.opponent_actions[state.round_number - 1, :])
        cooperation_rate = cooperators_in_prev_round / self.game_description.n_players
        return Action.D

class Strategy_EXPLOITATIVE_329(BaseStrategy):
    """
    Exploitative Adaptive Defection with Conditional Parasitism.

    Defects unconditionally to extract maximum value from cooperators while
    avoiding mutual defection costs. Tracks opponent cooperation rates but
    always defects since defection dominates cooperation in the payoff structure.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.opponent_cooperation_counts = np.zeros(game_description.n_players - 1)
        self.round_counts = np.zeros(game_description.n_players - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if history is not None:
            opponent_actions_last_round = history.opponent_actions[state.round_number - 1, :]
            self.opponent_cooperation_counts += opponent_actions_last_round.astype(float)
            self.round_counts += 1.0
        return Action.D

class Strategy_EXPLOITATIVE_330(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Exploitation

    This strategy maximizes personal payoff by perpetually defecting to exploit
    the public goods game structure. Since 1 < k < n implies k/n < 1, defection
    is mathematically dominant regardless of opponent cooperation rates.

    Decision Rule: ALWAYS DEFECT
    - Round 1: Defect (establish dominance, no history to analyze)
    - Rounds 2 to r-1: Defect (exploit any cooperation; mutual defection if none)
    - Final Round: Defect (no future consequences, extract maximum value)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        cooperators_last_round = sum(history.opponent_actions[-1, :])
        return Action.D

class Strategy_EXPLOITATIVE_331(BaseStrategy):
    """
    Exploitative strategy: Adaptive Defection with Calculated Cooperation.

    Core approach: Systematically defect to exploit cooperation while avoiding
    vulnerability. Uses adaptive thresholds based on historical cooperation rates
    and round number to maximize personal gain.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        rounds_elapsed = current_round
        total_cooperations = np.sum(history.opponent_actions[:current_round, :])
        total_possible = rounds_elapsed * self.n
        coop_rate = total_cooperations / total_possible if total_possible > 0 else 0.0
        if current_round < self.r / 2.0:
            threshold = 1.0 / self.k * 1.1
        else:
            threshold = 1.0 / self.k * 1.02
        if coop_rate == 0.0:
            return Action.D
        if coop_rate >= 1.0:
            return Action.D
        if coop_rate > threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_332(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Maximizes personal payoff by exploiting cooperative players while avoiding mutual destruction.
    Uses defection as default, switches to selective cooperation based on observed vulnerability,
    and applies end-game betrayal in final rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.tau = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        if round_num == self.r - 2:
            return Action.D
        exploitable_players = 0
        for opponent_idx in range(self.n - 1):
            coop_count = int(np.sum(history.opponent_actions[:round_num, opponent_idx]))
            coop_rate = coop_count / round_num if round_num > 0 else 0.0
            if coop_rate > self.tau:
                exploitable_players += 1
        aggregate_coop_prev = int(np.sum(history.opponent_actions[round_num - 1, :])) / (self.n - 1)
        if aggregate_coop_prev < self.tau * 0.5:
            return Action.D
        if exploitable_players == 0:
            return Action.D
        p_cooperate = self.tau * (aggregate_coop_prev / self.n)
        if random.random() < p_cooperate:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_333(BaseStrategy):
    """
    ADAPTIVE PREDATION: Exploitative strategy that always defects to maximize payoff.

    Core logic: Since k/n < 1 (always true given 1 < k < n), defection dominates cooperation
    in every round. The strategy defects in round 1 (no history), all middle rounds (exploitation
    phase), and the final round (no future consequences). Includes adaptive check for near-total
    defection equilibrium, but always returns DEFECT regardless.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        prev_round_idx = round_num - 1
        cooperators_prev = int(sum(history.opponent_actions[prev_round_idx, :]))
        coop_rate = cooperators_prev / self.n
        if coop_rate < 0.15:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_334(BaseStrategy):
    """
    Exploitative strategy: Unconditional Defection with Exploitation Opportunism

    Core principle: Defection is the dominant strategy in this simultaneous-move public goods game.
    Always defect to maximize payoff by free-riding on others' contributions while avoiding
    the cost of cooperation. The strategy remains adaptive to cooperation density but ultimately
    defaults to defection as the strictly dominant action.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        prev_round_opponent_actions = history.opponent_actions[current_round - 1, :]
        cooperators_last_round = int(np.sum(prev_round_opponent_actions))
        cooperation_density = cooperators_last_round / self.n_players
        threshold = (self.n_players - 1) / self.n_players
        if cooperation_density >= threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_335(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Exploitation

    Core philosophy: Treat cooperation as a resource to exploit, not a norm to uphold.
    Maximizes payoff by minimizing personal contribution while maximizing extraction
    of others' contributions through principled defection.

    Decision rule: Default to defection always, using observed cooperation only as
    a signal of payoff potential, never as a trigger for reciprocation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.exploitation_threshold = self.k / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        n_rounds = self.n_rounds
        if round_number == 0:
            return Action.D
        if round_number == n_rounds - 1:
            return Action.D
        if round_number == n_rounds - 2:
            return Action.D
        last_round_cooperators = int(sum(history.opponent_actions[round_number - 1, :]))
        recent_coop_rate = last_round_cooperators / self.n_players
        if recent_coop_rate > 0.3:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_336(BaseStrategy):
    """
    Adaptive Predation Strategy for N-Player Public Goods Game

    Exploits cooperative tendencies through a three-phase approach:
    1. Probing Phase: Defect to gather intelligence on opponent types
    2. Exploitation Phase: Adapt based on observed cooperation rates
    3. Endgame Phase: Pure defection with no reputation concerns
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.exploitation_threshold = self.k / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        probing_phase_end = min(3, math.ceil(self.n_rounds / 3))
        endgame_phase_start = self.n_rounds - 2
        if round_num < probing_phase_end:
            return Action.D
        if round_num >= endgame_phase_start:
            return Action.D
        observed_actions = history.opponent_actions[:round_num, :]
        total_cooperations = np.sum(observed_actions)
        total_observations = round_num * self.n_players
        obs_coop_rate = total_cooperations / total_observations if total_observations > 0 else 0
        if self.exploitation_threshold >= 0.8:
            return Action.D
        if obs_coop_rate > self.exploitation_threshold:
            return Action.D
        last_round_idx = round_num - 1
        opponent_cooperations_last_round = history.opponent_actions[last_round_idx, :]
        prop_cooperated_last = np.mean(opponent_cooperations_last_round)
        if prop_cooperated_last > 0.5:
            return Action.D
        coop_probability = min(0.3, self.exploitation_threshold)
        if random.random() < coop_probability:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_337(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Defaults to defection to exploit cooperators. Switches to cooperation only when
    the proportion of cooperators is high enough that the public good benefit exceeds
    the private gain from defection. Always defects in the final round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = game_description.n_players / game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == r - 1:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[round_num - 1, :]))
        if cooperators_last_round >= self.threshold:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_338(BaseStrategy):
    """
    Adaptive Predation: An exploitative strategy that cooperates in round 1 to identify
    cooperators, then defects in subsequent rounds to exploit the public good they generate.
    Always defects in the final round to maximize end-game payoff.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        if state.round_number == 0:
            return Action.C
        if state.round_number == r - 1:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[state.round_number - 1, :]))
        if cooperators_last_round > 0:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_339(BaseStrategy):
    """
    Adaptive Predation Strategy: An exploitative approach that defects in all rounds
    to free-ride on cooperators' contributions while avoiding the cost of cooperation.

    Core logic:
    - Round 1: Defect to probe and establish baseline
    - Rounds 2 to r-1: Always defect (strictly dominant regardless of cooperation rate)
    - Final round: Defect (no future rounds, no reputation consequences)

    This strategy exploits the asymmetry in public goods games where defectors gain
    full benefit of others' contributions without paying the cooperation cost.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_340(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Maximizes personal payoff by exploiting cooperative opponents while minimizing
    losses against defectors. Never reciprocates cooperation; always defects because:
    1. Defection is the dominant strategy in every round
    2. Cooperation subsidizes others' payoffs at your expense
    3. The public good multiplier makes defection against cooperators most profitable
    4. The final round collapses all cooperative incentives
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        previous_round_index = state.round_number - 1
        cooperators_in_previous = int(sum(history.opponent_actions[previous_round_index, :]))
        my_previous_action = history.my_actions[previous_round_index]
        total_cooperators = cooperators_in_previous + (1 if my_previous_action else 0)
        cooperation_rate = total_cooperators / self.game_description.n_players
        threshold = self.game_description.k / self.game_description.n_players
        return Action.D

class Strategy_EXPLOITATIVE_341(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core approach:
    - Always defect by default to maximize free-riding
    - Adaptively identify high-cooperation environments
    - Strategically cooperate at calculated moments to appear reformed and re-stimulate opponent cooperation
    - Exploit the asymmetry where defectors gain 1 while cooperators gain only (k/n)  total_cooperators
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold_k = self.k * 0.6 / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.r - 1:
            return Action.D
        opponent_cooperations = np.sum(history.opponent_actions[:round_number, :])
        opponent_rounds_played = (self.n - 1) * round_number
        if opponent_rounds_played == 0:
            cooperation_rate = 0.0
        else:
            cooperation_rate = opponent_cooperations / opponent_rounds_played
        feeding_round_1 = round_number == math.floor(self.r * 0.75)
        feeding_round_2 = self.r >= 10 and round_number == math.floor(self.r * 0.4)
        is_feeding_round = feeding_round_1 or feeding_round_2
        if cooperation_rate > self.threshold_k and is_feeding_round:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_342(BaseStrategy):
    """
    Adaptive Defection with Selective Exploitation strategy for N-Player Public Goods Game.

    Core approach:
    - Phase 1 (rounds 1-3): Defect to gather information about cooperators
    - Phase 2 (rounds 4 to r-2): Exploit by cooperating when cooperation rate >= 50%
    - Phase 3 (final round): Always defect for final extraction
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.cooperation_threshold = math.ceil(self.n_players / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round < 3 and current_round < self.n_rounds - 1:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        if history is None or current_round == 0:
            return Action.D
        total_cooperators = 0
        rounds_observed = current_round
        for round_idx in range(rounds_observed):
            round_cooperators = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += round_cooperators
        mean_coop_rate = total_cooperators / (rounds_observed * self.n_players) if rounds_observed > 0 else 0.0
        if mean_coop_rate >= 0.5:
            return Action.C
        if rounds_observed >= 2:
            recent_defection_payoffs = history.my_payoffs[max(0, rounds_observed - 2):rounds_observed]
            overall_payoff_mean = np.mean(history.my_payoffs[:rounds_observed])
            recent_defection_mean = np.mean(recent_defection_payoffs)
            if recent_defection_mean < overall_payoff_mean * 0.9:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_343(BaseStrategy):
    """
    Exploitative Strategy: Unconditional Defection

    This strategy exploits the mathematical structure of the N-Player Public Goods Game
    by always defecting. Defection is a dominant strategy because:
    - When others cooperate: defectors earn the public good without contributing
    - When others defect: mutual defection yields payoff of 1, which ties or beats cooperation

    The strategy is theoretically unbeatable and requires no complex bookkeeping or opponent modeling.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        return Action.D

class Strategy_EXPLOITATIVE_344(BaseStrategy):
    """
    Adaptive Predation: An exploitative strategy that systematically defects to free-ride
    on cooperators' contributions while avoiding costly mutual defection when possible.

    Phases:
    1. Reconnaissance (rounds 0-3): Defect to identify exploitable cooperators
    2. Exploitation (rounds 4 to r-3): Defect whenever others cooperate
    3. Endgame (final 2 rounds): Unconditional defection
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.exploitation_threshold = self.k / self.n_players / (1 + self.k / self.n_players)
        self.opponent_defection_rate = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        reconnaissance_rounds = math.ceil(self.n_rounds / 4)
        if current_round < min(3, reconnaissance_rounds):
            return Action.D
        if current_round >= self.n_rounds - 2:
            return Action.D
        if history is not None and len(history.opponent_actions) > 0:
            last_round_idx = len(history.opponent_actions) - 1
            opponent_cooperations = np.sum(history.opponent_actions[last_round_idx, :])
            cooperation_rate = opponent_cooperations / (self.n_players - 1)
            self.opponent_defection_rate = 1.0 - cooperation_rate
            if self.opponent_defection_rate > 0.7:
                return Action.D
            if cooperation_rate > 0:
                return Action.D
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_345(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Exploitation

    This strategy implements unconditional defection to maximize payoff by exploiting
    cooperators in the public goods game. It defects in all rounds, as defection is
    the subgame perfect equilibrium strategy.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        numerator = self.n * (1 - self.k)
        denominator = self.k - 1
        self.threshold = math.ceil(numerator / denominator) + 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_346(BaseStrategy):
    """
    Adaptive Defection with Conditional Parasitism.

    Exploits the public goods game by consistently defecting while monitoring
    cooperation rates. Defects when cooperation is detected above a threshold
    (k/n), maximizing payoff by free-riding on others' contributions while
    maintaining the private endowment.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.exploitation_threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        total_rounds_played = state.round_number
        total_cooperators = 0
        for round_idx in range(total_rounds_played):
            cooperators_in_round = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += cooperators_in_round
        total_possible_cooperations = total_rounds_played * self.game_description.n_players
        cooperation_rate_history = total_cooperators / total_possible_cooperations
        if cooperation_rate_history > self.exploitation_threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_347(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    This strategy exploits the payoff asymmetry in the Public Goods Game by:
    1. Always defecting (since k < n makes defection dominant)
    2. Tracking opponent cooperation rates to identify exploitable cooperators
    3. Adapting thresholds based on population behavior
    4. Ensuring final round defection via backward induction

    Core insight: Defection is the dominant strategy across all scenarios, but
    tracking cooperation history helps confirm this remains optimal and maximizes
    exploitation of any cooperators in the population.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = 0.4
        self.secondary_threshold = 0.15
        self.tertiary_threshold = 0.3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n_rounds = self.game_description.n_rounds
        n_players = self.game_description.n_players
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == n_rounds - 1:
            return Action.D
        opponent_actions = history.opponent_actions[:current_round, :]
        rounds_so_far = current_round
        total_cooperations = float(np.sum(opponent_actions))
        total_possible = rounds_so_far * (n_players - 1)
        if total_possible > 0:
            avg_coop_rate = total_cooperations / total_possible
        else:
            avg_coop_rate = 0.0
        if avg_coop_rate > self.threshold:
            return Action.D
        elif avg_coop_rate > self.secondary_threshold:
            cooperator_count = 0
            for opponent_idx in range(n_players - 1):
                opponent_cooperations = float(np.sum(opponent_actions[:, opponent_idx]))
                if opponent_cooperations > 0:
                    opponent_coop_rate = opponent_cooperations / rounds_so_far
                else:
                    opponent_coop_rate = 0.0
                if opponent_coop_rate > self.tertiary_threshold:
                    cooperator_count += 1
            if cooperator_count >= (n_players - 1) / 2.0:
                return Action.D
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_348(BaseStrategy):
    """
    Parasitic Defection with Threshold Adaptation.

    Core strategy: Always defect to maximize payoff by free-riding on cooperators.
    Only cooperate when sufficient cooperators exist in previous round and we're
    not in the final third of rounds (to maintain the cooperator pool for exploitation).
    In the final third, always defect to harvest remaining cooperators.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.final_third_threshold = 2 * self.n_rounds / 3
        self.coop_threshold = math.ceil((self.n_players + 1) / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number >= self.final_third_threshold:
            return Action.D
        cooperators_prev_round = int(sum(history.opponent_actions[round_number - 1, :]))
        if cooperators_prev_round >= self.coop_threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_349(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation Probing

    Core strategy: Defect by default, cooperate only when the public good is sufficiently
    funded to exploit. This preys on reciprocal strategies like Tit-for-Tat while avoiding
    wasted cooperation on pure defectors.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n_players
        self.payoff_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = sum(history.opponent_actions[round_number - 1, :])
        cooperation_rate = cooperators_last_round / self.n_players
        if len(history.my_payoffs) > 0:
            self.payoff_history.append(history.my_payoffs[-1])
        adaptive_threshold = self.threshold
        if len(self.payoff_history) >= 5:
            avg_recent_payoff = np.mean(self.payoff_history[-5:])
            expected_defect_payoff = 1.0 + self.k / self.n_players * (self.n_players - 1) * 0.5
            if avg_recent_payoff < expected_defect_payoff - 0.1:
                adaptive_threshold *= 0.95
            elif avg_recent_payoff > expected_defect_payoff + 0.3:
                adaptive_threshold = min(adaptive_threshold * 1.02, self.k / self.n_players)
        if cooperation_rate > adaptive_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_350(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core approach: Always defect to maximize personal gain by parasitizing
    cooperators while avoiding losses against defectors. Defection is the
    dominant strategy in this public goods game structure.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = (game_description.k - 1) / game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_351(BaseStrategy):
    """
    Adaptive Predation: An exploitative strategy that defects by default while
    selectively cooperating to maintain and exploit cooperative opponents.

    Core mechanics:
    - Always defect in round 1 and final round
    - Monitor cooperation rate of all players across history
    - Cooperate opportunistically when cooperation rate exceeds threshold,
      with probability decreasing over time
    - Exploit cooperative opponents by free-riding on their contributions
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        total_cooperations = np.sum(history.opponent_actions[:current_round, :])
        total_cooperations += np.sum(history.my_actions[:current_round])
        total_possible = (self.n_players + 1) * current_round
        cooperation_rate = total_cooperations / total_possible if total_possible > 0 else 0.0
        threshold = (1.0 + self.k) / (2.0 * self.n_players)
        if cooperation_rate > threshold:
            if current_round < self.n_rounds / 2.0:
                p_exploit = min(0.3, cooperation_rate * 0.5)
            else:
                p_exploit = min(0.15, cooperation_rate * 0.25)
            if random.random() < p_exploit:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_352(BaseStrategy):
    """
    Adaptive Predation with Conditional Defection Strategy.

    Exploits the public goods game by ruthlessly defecting when beneficial,
    while adapting to cooperation patterns through threshold-based and
    probabilistic decision rules. Maximizes personal payoff by identifying
    and exploiting high-cooperation environments while avoiding costly
    punishment cycles.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold_high = (self.k + 0.5) / self.n_players
        self.threshold_mid = 1.0 / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperation_history = self._get_cooperation_rates(history, current_round)
        smoothed_coop_rate = self._get_smoothed_cooperation_rate(cooperation_history, current_round)
        rounds_remaining = self.n_rounds - current_round
        endgame_factor = 1.0 - min(3, rounds_remaining) / 4.0
        if smoothed_coop_rate > self.threshold_high + endgame_factor:
            return Action.D
        elif smoothed_coop_rate >= self.threshold_mid:
            defection_probability = max(0.65, 1.0 - smoothed_coop_rate)
            if random.random() < defection_probability:
                return Action.D
            else:
                return Action.C
        else:
            return Action.D

    def _get_cooperation_rates(self, history: PlayerHistory, current_round: int) -> list:
        """Calculate cooperation rate for each past round."""
        cooperation_rates = []
        for round_idx in range(current_round):
            my_action = history.my_actions[round_idx]
            opponent_cooperations = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators = int(my_action) + opponent_cooperations
            coop_rate = total_cooperators / self.n_players
            cooperation_rates.append(coop_rate)
        return cooperation_rates

    def _get_smoothed_cooperation_rate(self, cooperation_history: list, current_round: int) -> float:
        """Calculate smoothed cooperation rate using moving average."""
        if len(cooperation_history) == 0:
            return 0.0
        window_size = min(3, len(cooperation_history))
        recent_history = cooperation_history[-window_size:]
        smoothed_rate = np.mean(recent_history)
        return float(smoothed_rate)

class Strategy_EXPLOITATIVE_353(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    Core philosophy: Maximize personal payoff by exploiting the game structure.
    Defection is individually rational when others cooperate, and cooperation is
    wasteful when others defect. Always defect in round 1 and final round.
    In middle rounds, defect regardless of cooperation rate (strict dominance).
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.k - 1) / self.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_354(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Exploits the asymmetry in public goods games by defaulting to defection,
    only cooperating when observed cooperation rate exceeds a dynamic threshold
    that decreases over time. Unconditionally defects in the final round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.r - 1:
            return Action.D
        previous_round_idx = round_number - 1
        cooperators_last_round = np.sum(history.opponent_actions[previous_round_idx, :])
        observed_cooperation_rate = cooperators_last_round / self.n
        threshold = self._calculate_threshold(round_number)
        if observed_cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_threshold(self, round_number: int) -> float:
        """
        Calculate cooperation threshold that decreases over time.

        Threshold = k/n + exploitation_margin

        Margin decreases from 0.15 (early) to 0.05 (late) as game progresses.
        """
        progress = (round_number + 1) / self.r
        if progress < 0.33:
            margin = 0.15
        elif progress < 0.67:
            margin = 0.1
        else:
            margin = 0.05
        base_threshold = self.k / self.n
        return base_threshold + margin

class Strategy_EXPLOITATIVE_355(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Exploitation

    Maximizes personal payoff by exploiting cooperative tendencies in others while
    minimizing losses from defectors. Defects unconditionally in rounds 1 and r,
    and uses opportunistic mimicry in middle rounds based on cooperation rate threshold.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.epsilon = 0.01

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        if history is None:
            return Action.D
        last_round_idx = current_round - 1
        opponent_actions_last_round = history.opponent_actions[last_round_idx, :]
        cooperators_last_round = int(np.sum(opponent_actions_last_round))
        cooperation_rate = cooperators_last_round / self.n_players
        threshold = self.k / self.n_players - self.epsilon
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_356(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Maximizes personal payoff by exploiting cooperators while avoiding mutual defection traps.
    Uses unconditional defection in early rounds for reconnaissance, then selectively exploits
    any cooperation detected. Always defects in the final round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.reconnaissance_rounds = max(3, math.ceil(self.r * 0.2))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number < self.reconnaissance_rounds:
            return Action.D
        if round_number == self.r - 1:
            return Action.D
        if history is None:
            return Action.D
        previous_round_index = round_number - 1
        opponent_actions_previous = history.opponent_actions[previous_round_index, :]
        cooperators_previous = np.sum(opponent_actions_previous)
        cooperation_rate = cooperators_previous / self.n
        threshold = self.k / self.n * 1.5
        if cooperation_rate >= threshold:
            return Action.D
        elif cooperation_rate > 0:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_357(BaseStrategy):
    """
    Exploitative Adaptive Defection with Conditional Parasitism.

    This strategy exploits the free-rider advantage in public goods games by:
    1. Always defaulting to defection (dominant action)
    2. Monitoring cooperation rates to confirm parasitism profitability
    3. Maintaining defection through all rounds regardless of cooperation observed
    4. Extracting maximum value in the terminal round with zero punishment risk
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        total_rounds_completed = state.round_number
        n_opponents = self.game_description.n_players - 1
        total_cooperators = 0
        for round_idx in range(total_rounds_completed):
            cooperators_in_round = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += cooperators_in_round
        max_possible_cooperations = total_rounds_completed * n_opponents
        if max_possible_cooperations > 0:
            cooperation_rate = total_cooperators / max_possible_cooperations
        else:
            cooperation_rate = 0.0
        return Action.D

class Strategy_EXPLOITATIVE_358(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Maximizes personal payoff by exploiting cooperative tendencies in others.
    - Rounds 1-2: Defect to gather information
    - Rounds 3 to r-1: Defect based on observed cooperation rates
    - Final rounds: Defect (backward induction)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round <= 1:
            return Action.D
        if current_round >= self.n_rounds - 2:
            return Action.D
        cooperation_rate = self._calculate_cooperation_rate(history)
        surplus_threshold = self.k / self.n_players
        if cooperation_rate > surplus_threshold:
            return Action.D
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        """
        Calculate the average cooperation rate among all opponents
        across all previous rounds.
        """
        if history is None or len(history.opponent_actions) == 0:
            return 0.0
        total_cooperations = float(np.sum(history.opponent_actions))
        total_observations = float(history.opponent_actions.size)
        cooperation_rate = total_cooperations / total_observations if total_observations > 0 else 0.0
        return cooperation_rate

class Strategy_EXPLOITATIVE_359(BaseStrategy):
    """
    Adaptive Predation Strategy for N-Player Public Goods Game.

    Core philosophy: Always defect to exploit asymmetry between defectors and cooperators.
    Defection is strictly dominant - cooperators bear contribution costs while all players
    share benefits. This strategy systematically preys upon cooperative behavior while
    minimizing own contribution costs.

    Decision rule: ALWAYS DEFECT, with threshold-based observation for adaptivity.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        k_over_n = self.k / self.n_players
        self.threshold_rate = (1.0 - k_over_n) / (1.0 + k_over_n)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number < self.n_rounds - 1:
            previous_round_actions = history.opponent_actions[state.round_number - 1, :]
            num_cooperators = np.sum(previous_round_actions)
            coop_rate = num_cooperators / self.n_players
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_360(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core philosophy: Exploit asymmetry in payoff structure by defecting by default,
    cooperating only when sustainable cooperation exists and parasitism value exceeds
    mutual defection value. Always defects in final round and when no exploitable
    cooperation is observed.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.r - 1:
            return Action.D
        total_cooperations = np.sum(history.opponent_actions[:round_number, :])
        rounds_elapsed = round_number
        cooperation_rate = total_cooperations / (self.n * rounds_elapsed)
        exploitation_threshold = self.k / self.n
        if cooperation_rate > exploitation_threshold:
            return Action.D
        elif cooperation_rate > 0:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_361(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Opportunistic Exploitation

    This strategy maximizes personal payoff by exploiting the asymmetry in the public goods game.
    It defects in the first round to gather information, defects in the final round with no future
    consequences, and in middle rounds defects based on whether previous cooperation rates warrant
    exploitation. The strategy simplifies to unconditional defection while maintaining the decision
    structure for potential refinement.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.n_rounds - 1:
            return Action.D
        previous_round_cooperators = sum(history.opponent_actions[state.round_number - 1, :])
        cooperation_rate = previous_round_cooperators / self.n_players
        if cooperation_rate >= self.threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_362(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Exploitation

    Maximizes personal payoff by exploiting cooperative players while minimizing losses.
    Defaults to defection, cooperates only when observed cooperation rate exceeds a threshold,
    and always defects in the final round for maximum extraction.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        previous_round_idx = current_round - 1
        opponent_cooperations_prev = np.sum(history.opponent_actions[previous_round_idx, :])
        observed_cooperation_rate = opponent_cooperations_prev / self.n
        cooperation_threshold = (self.n - 1) / self.n * (1 - 1 / self.k)
        if observed_cooperation_rate > cooperation_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_363(BaseStrategy):
    """
    Adaptive Parasitism: Exploitative strategy that defects to harvest cooperators
    while adapting to opponent patterns. Treats cooperation as a resource to exploit
    rather than a norm to reciprocate.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.opponent_cooperation_streak = {}

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        prev_round_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        coop_ratio = prev_round_cooperators / (self.n_players - 1)
        rounds_remaining = self.n_rounds - current_round - 1
        for opponent_idx in range(self.n_players - 1):
            if opponent_idx not in self.opponent_cooperation_streak:
                self.opponent_cooperation_streak[opponent_idx] = 0
            if history.opponent_actions[current_round - 1, opponent_idx]:
                self.opponent_cooperation_streak[opponent_idx] += 1
            else:
                self.opponent_cooperation_streak[opponent_idx] = 0
        for streak_count in self.opponent_cooperation_streak.values():
            if streak_count >= 3:
                return Action.D
        threshold = 0.6
        if coop_ratio > threshold:
            return Action.D
        elif coop_ratio >= 0.15:
            return Action.D
        else:
            return Action.D
        if coop_ratio > 0.9 and rounds_remaining > 3:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_364(BaseStrategy):
    """
    Adaptive Defection with Calculated Cooperation (ADCC)

    An exploitative strategy that defects in early and final rounds,
    then adaptively decides based on observed opponent cooperation rates:
    - If cooperation_rate > 0.40: DEFECT (exploit cooperators)
    - If cooperation_rate < 0.15: DEFECT (no benefit)
    - If 0.15  cooperation_rate  0.40: Sparse cooperation (25% rate)
    """
    EXPLOITATION_THRESHOLD = 0.4
    MINIMAL_THRESHOLD = 0.15

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_cycle_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        total_opponent_actions = history.opponent_actions[:current_round, :]
        total_cooperations = np.sum(total_opponent_actions)
        total_actions_observed = current_round * (n - 1)
        if total_actions_observed == 0:
            cooperation_rate = 0.0
        else:
            cooperation_rate = total_cooperations / total_actions_observed
        if cooperation_rate > self.EXPLOITATION_THRESHOLD:
            return Action.D
        elif cooperation_rate < self.MINIMAL_THRESHOLD:
            return Action.D
        else:
            self.cooperation_cycle_counter += 1
            if self.cooperation_cycle_counter % 4 == 0:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_365(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism Strategy.

    Exploits the public goods game by consistently defecting while parasitizing
    cooperators' contributions. Adapts exploitation intensity based on observed
    cooperation rates, with guaranteed defection in first and final rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold_exploitation = max(0.1, (self.k - 1) / (self.n_players - 1) + 0.05)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        total_cooperators = np.sum(history.my_actions) + np.sum(history.opponent_actions)
        total_players_rounds = current_round * self.n_players
        coop_rate = total_cooperators / total_players_rounds if total_players_rounds > 0 else 0.0
        if coop_rate > self.threshold_exploitation:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_366(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core principle: Unconditional defection to maximize personal payoff by
    capturing private endowment (1) while parasitizing public good produced
    by cooperators. Defection is the dominant strategy in public goods games
    where 1 < k < n.

    Decision rule:
    - Round 0 (first): DEFECT (establish dominance, gather information)
    - Rounds 1 to r-2 (middle): DEFECT (free-ride on others' cooperation)
    - Round r-1 (final): DEFECT (no future consequences, terminal exploitation)

    Mathematical justification:
    Defection payoff = 1 + (k/n)  total_cooperators
    Cooperation payoff = (k/n)  total_cooperators
    Defection advantage = always +1, regardless of others' choices
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        if history is not None and len(history.opponent_actions) > 0:
            prev_round_idx = round_number - 1
            cooperators_prev_round = np.sum(history.opponent_actions[prev_round_idx, :])
            cooperation_rate = cooperators_prev_round / self.n_players
        return Action.D

class Strategy_EXPLOITATIVE_367(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    This strategy implements unconditional defection to maximize individual payoff
    by exploiting the asymmetry in the public goods game. It defects in the first round
    (exploration), middle rounds (exploitation of any cooperation), and last round
    (no shadow of future), while adapting confidence based on observed cooperation rates.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        prev_round_idx = state.round_number - 1
        cooperators_prev_round = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        cooperation_rate = cooperators_prev_round / self.game_description.n_players
        return Action.D

class Strategy_EXPLOITATIVE_368(BaseStrategy):
    """
    Adaptive Defection with Conditional Exploitation strategy for N-Player Public Goods Game.

    This strategy exploits the game's mathematical structure by prioritizing defection,
    dynamically tracking opponent cooperation rates, and intensifying exploitation against
    high-cooperators while defaulting to defection against defectors and ambiguous opponents.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        n_opponents = self.n_players - 1
        cooperation_rates = np.zeros(n_opponents)
        for opponent_idx in range(n_opponents):
            cooperations = np.sum(history.opponent_actions[:current_round, opponent_idx])
            cooperation_rates[opponent_idx] = cooperations / current_round
        threshold_t = 0.6 - 0.1 * current_round / self.n_rounds
        if self.k < 1.5:
            threshold_t *= 0.8
        max_cooperation_rate = np.max(cooperation_rates) if len(cooperation_rates) > 0 else 0
        if max_cooperation_rate > 0.7:
            return Action.D
        prev_round_cooperators = np.sum(history.opponent_actions[current_round - 1, :])
        if prev_round_cooperators == 0:
            return Action.D
        has_exploitable_opponent = False
        has_ambiguous_opponent = False
        for coop_rate in cooperation_rates:
            if coop_rate > threshold_t:
                has_exploitable_opponent = True
                break
            elif coop_rate >= threshold_t / 2:
                has_ambiguous_opponent = True
        if has_exploitable_opponent:
            return Action.D
        all_are_defectors = all((coop_rate < threshold_t / 2 for coop_rate in cooperation_rates))
        if all_are_defectors:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_369(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    A parasitic strategy that exploits others' cooperation while minimizing own contributions.
    Defects by default, cooperates selectively only when it demonstrates increased payoff
    through critical mass of existing cooperators.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.critical_mass = math.ceil(self.n / self.k)
        self.permanent_defect = False
        self.opponent_coop_rates = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        if self.permanent_defect:
            return Action.D
        coop_count_prev = int(sum(history.opponent_actions[current_round - 1, :]))
        if coop_count_prev < self.critical_mass:
            self.permanent_defect = True
            return Action.D
        self._update_opponent_coop_rates(history, current_round)
        reliable_coops = sum((1 for rate in self.opponent_coop_rates if rate >= 0.8))
        expected_return = self.k / self.n * coop_count_prev
        if reliable_coops > 0 and expected_return >= 1.0:
            decay_factor = 1.0 - current_round / self.r * 0.5
            coop_probability = reliable_coops / self.n * decay_factor
            if random.random() < coop_probability:
                return Action.C
        return Action.D

    def _update_opponent_coop_rates(self, history: PlayerHistory, current_round: int) -> None:
        """
        Calculate cooperation rates for each opponent up to current_round (exclusive).
        """
        if self.opponent_coop_rates is None:
            self.opponent_coop_rates = [0.0] * (self.n - 1)
        rounds_played = current_round
        if rounds_played == 0:
            return
        for opponent_idx in range(self.n - 1):
            coop_actions = sum(history.opponent_actions[:current_round, opponent_idx])
            self.opponent_coop_rates[opponent_idx] = coop_actions / rounds_played

class Strategy_EXPLOITATIVE_371(BaseStrategy):
    """
    Exploitative strategy using adaptive defection with selective parasitism.

    Maximizes personal payoff by exploiting cooperators while minimizing losses to defectors.
    Defaults to defection but conditionally cooperates when cooperation rate exceeds an adaptive threshold,
    treating cooperation as a harvestable resource rather than a norm to reciprocate.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        prev_round_idx = round_num - 1
        cooperators_prev = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        coop_rate = cooperators_prev / self.n
        if round_num >= self.r - 2:
            if round_num == self.r - 1:
                return Action.D
            if coop_rate >= 0.15:
                return Action.C
            else:
                return Action.D
        threshold = min(0.5, 1.0 - 1.0 / (self.r - round_num + 2))
        if coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_372(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core approach: Always defect (dominant strategy) while monitoring opponent cooperation
    to determine if parasitic exploitation is profitable. Adapts behavior based on whether
    the public good threshold is exceeded, but ultimately always plays defection as the
    dominant strategy in all rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.k - 1) / (self.n_players - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        if history is not None and len(history.opponent_actions) > 0:
            last_round_idx = current_round - 1
            cooperators_last_round = sum(history.opponent_actions[last_round_idx, :])
            cooperation_rate = cooperators_last_round / self.n_players
            opponent_consistencies = []
            for opponent_idx in range(self.n_players - 1):
                rounds_cooperated = sum(history.opponent_actions[:current_round, opponent_idx])
                consistency = rounds_cooperated / current_round if current_round > 0 else 0
                opponent_consistencies.append(consistency)
        return Action.D

class Strategy_EXPLOITATIVE_373(BaseStrategy):
    """
    Adaptive Parasitic Harvesting (APH) Strategy

    Core approach: Exploit the fundamental asymmetry of public goods games through
    unconditional defection. Defection strictly dominates cooperation because:
    - Defect payoff: 1 + (k/n)  m cooperators
    - Cooperate payoff: 0 + (k/n)  m cooperators

    Strategy: Always defect, with emphasis on endgame exploitation when punishment
    becomes impossible. Parasitize any cooperators present while maintaining maximum
    private payoff.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        endgame_threshold = self.n_rounds - math.ceil(self.n_rounds / 5)
        if current_round >= endgame_threshold:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_374(BaseStrategy):
    """
    Pure Exploitation via Unconditional Defection

    This strategy implements unconditional defection in the N-player public goods game.
    The strategy exploits the payoff structure where defection is strictly dominant:
    - Marginal benefit of cooperation: k/n
    - Marginal cost of cooperation: 1
    - Net payoff: k/n - 1 < 0 (since k < n by specification)

    Therefore, defection maximizes payoff against any opponent configuration.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        return Action.D

class Strategy_EXPLOITATIVE_375(BaseStrategy):
    """
    Exploitative strategy with adaptive defection and selective parasitism.

    Tracks opponent cooperation rates and uses global cooperation density to decide
    between defection (when others cooperate) and occasional cooperation (to avoid
    reputation damage). Defects unconditionally in first and last rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.D
        if round_t == self.r - 1:
            return Action.D
        prev_round_cooperations = np.sum(history.opponent_actions[round_t - 1, :])
        coop_density = prev_round_cooperations / (self.n - 1)
        theta_high = 0.5 + self.k / (2.0 * self.n)
        theta_mid = 0.25
        if self.n == 2:
            theta_high = 0.7
        if self.k > self.n - 0.5:
            theta_high = max(0.4, theta_high - 0.1)
            theta_mid = max(0.15, theta_mid - 0.05)
        if coop_density > theta_high:
            return Action.D
        elif coop_density > theta_mid:
            if random.random() < 0.2:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_376(BaseStrategy):
    """
    Adaptive Predatory Defection (APD) Strategy for N-Player Public Goods Game.

    Core principle: Unconditional defection to exploit cooperators by free-riding
    on their contributions while avoiding the cost of cooperation. Defect in all
    rounds regardless of history, as defection is the dominant strategy in this
    simultaneous-move game with no communication or reputation mechanism.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number < self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_377(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Core philosophy: Defect by default, but parasitize cooperators when conditions are met.
    - Round 0: Always defect (establish baseline, gather intelligence)
    - Final round: Always defect (no future punishment to fear)
    - Middle rounds: Cooperate only when cooperation rate is very high (>= threshold)
      and the public good multiplier makes parasitism profitable
    - Threshold: (n-1)/n (require nearly everyone else cooperating)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.n_players - 1) / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        if current_round == self.n_rounds - 2:
            return Action.D
        prev_round_idx = current_round - 1
        prev_opponent_actions = history.opponent_actions[prev_round_idx, :]
        prev_cooperators = int(np.sum(prev_opponent_actions))
        if history.my_actions[prev_round_idx]:
            prev_cooperators += 1
        prev_cooperation_rate = prev_cooperators / self.n_players
        public_good_payoff_per_cooperator = self.k / self.n_players * prev_cooperation_rate
        if prev_cooperation_rate >= self.threshold and public_good_payoff_per_cooperator > 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_378(BaseStrategy):
    """
    Adaptive Predation Strategy: Exploitative approach that maximizes personal payoff
    by strategically timing cooperation and defection to extract maximum surplus from
    the public good while minimizing personal contribution.

    Core mechanics:
    - Always defect in round 1 (information gathering)
    - Always defect in final round (no future consequences)
    - Mid-game: Defect when cooperation is very high (exploit) or very low (abandon)
    - Mid-game: Selectively cooperate in middle ranges, with bias toward defection
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold_high = (self.k - 1) / self.k
        self.threshold_low = 1 / self.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        prev_round_cooperators = int(sum(history.opponent_actions[round_num - 1, :]))
        cooperation_rate = prev_round_cooperators / self.n
        cooperation_trend = 0
        if round_num >= 2:
            prev_prev_cooperators = int(sum(history.opponent_actions[round_num - 2, :]))
            prev_prev_cooperation_rate = prev_prev_cooperators / self.n
            cooperation_trend = cooperation_rate - prev_prev_cooperation_rate
        if cooperation_rate >= self.threshold_high:
            return Action.D
        if cooperation_rate <= self.threshold_low:
            return Action.D
        if cooperation_trend > 0:
            return Action.D
        return Action.C

class Strategy_EXPLOITATIVE_379(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Contribution

    Core approach: Always defect to exploit the free-rider problem in public goods games.
    - Round 0 (first): DEFECT (no history to exploit yet)
    - Rounds 1 to r-2 (middle): DEFECT (exploit any cooperators via threshold logic)
    - Round r-1 (final): DEFECT (no future consequences)

    The strategy recognizes that defection is the dominant strategy: defectors capture
    the endowment (1) plus a share of the public good without contributing, while
    cooperators only get the public good share. This creates a +1 payoff advantage
    for defectors when others cooperate.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.n_players - 1) / (2 * self.n_players)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        previous_round_idx = current_round - 1
        cooperators_last_round = sum(history.opponent_actions[previous_round_idx, :])
        cooperation_rate = cooperators_last_round / self.n_players
        if cooperation_rate > self.threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_380(BaseStrategy):
    """
    Exploitative Defection Strategy: Systematically free-rides on others' contributions
    to the public good while minimizing own contributions through adaptive defection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.k - 1) / (self.n - 1) if self.n > 1 else 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        previous_round_actions = history.opponent_actions[current_round - 1, :]
        cooperators_last_round = np.sum(previous_round_actions)
        cooperation_rate = cooperators_last_round / self.n
        defection_payoff_advantage = self.k / self.n - (1 - self.k / self.n)
        if cooperation_rate >= self.k / self.n and defection_payoff_advantage > 0:
            return Action.D
        if cooperation_rate > self.threshold and defection_payoff_advantage > 0:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_381(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Free-Riding

    Core philosophy: Exploit the asymmetry between private retention and shared contributions.
    Since k < n, cooperation is individually suboptimal. The strategy maximizes personal payoff
    by defecting as much as possible while extracting value from others' cooperation.

    Decision rule:
    - Round 1: Defect (establish baseline, gather information)
    - Rounds 2 to r-1: Defect, with observation of opponent cooperation rates
    - Final round: Defect (no future consequences)

    The strategy always defaults to defection, exploiting the free-rider problem.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.exploitation_threshold = self.k / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        if history is not None:
            total_opponent_actions = history.opponent_actions.shape[0] * history.opponent_actions.shape[1]
            total_cooperations = int(np.sum(history.opponent_actions))
            if total_opponent_actions > 0:
                cooperation_rate = total_cooperations / total_opponent_actions
            else:
                cooperation_rate = 0.0
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_382(BaseStrategy):
    """
    Adaptive Predation: An exploitative strategy that defects in nearly all scenarios
    to maximize individual payoff by leveraging the asymmetry between defection rewards
    and cooperation costs in public goods games.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.alpha = (self.n - self.k) / self.n
        self.beta = self.k / (self.n * (self.n - 1)) if self.n > 1 else 0
        self.gamma = (self.n - self.k) / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        past_cooperators = history.opponent_actions[:round_num, :].sum(axis=1)
        total_cooperators = past_cooperators.sum()
        total_possible = self.n * round_num
        cooperation_rate = total_cooperators / total_possible if total_possible > 0 else 0
        if cooperation_rate > self.alpha:
            return Action.D
        if cooperation_rate < self.beta:
            return Action.D
        if round_num >= 3:
            recent_rounds = history.opponent_actions[max(0, round_num - 3):round_num, :]
            recent_cooperators = recent_rounds.sum()
            recent_total = recent_rounds.shape[0] * self.n
            recent_coop_rate = recent_cooperators / recent_total if recent_total > 0 else 0
        else:
            recent_coop_rate = cooperation_rate
        if recent_coop_rate > self.gamma:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_383(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Harvesting

    Always defects to exploit cooperators while avoiding losses from unilateral cooperation.
    Monitors cooperation rates but maintains defection as the dominant strategy across all rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.n_players / self.k - 0.05

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.n_rounds - 1:
            return Action.D
        if history is not None and state.round_number > 0:
            last_round_idx = state.round_number - 1
            cooperators_last_round = int(sum(history.opponent_actions[last_round_idx, :]))
            cooperation_rate = cooperators_last_round / self.n_players
            if cooperation_rate > self.threshold:
                return Action.D
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_384(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Exploitation

    Always defects based on dominant strategy theory. In the public goods game,
    defection is mathematically superior to cooperation on a per-round basis
    because k < n, meaning the personal benefit from cooperation (k/n) is always
    less than 1, the cost of cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_385(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Exploitation

    Core principle: Always defect to exploit cooperative opponents while avoiding
    mutual destruction. Defection is the dominant strategy in public goods games
    since k < n means I benefit more from others' contributions than my own.

    Decision framework:
    - Round 0 (first): DEFECT to establish non-cooperator type
    - Rounds 1 to r-2 (middle): DEFECT while tracking cooperation patterns
    - Round r-1 (final): DEFECT with maximum confidence (no future consequences)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        if history is not None:
            cooperators_observed = np.sum(history.opponent_actions)
            if cooperators_observed > 0:
                return Action.D
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_386(BaseStrategy):
    """
    Adaptive Parasitism: An exploitative strategy that always defects to maximize
    free-riding on cooperators' contributions to the public good.

    Core principle: Defection is weakly dominant given 1 < k < n. The strategy
    extracts value from any cooperation while avoiding the cost of contributing.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_387(BaseStrategy):
    """
    Adaptive Predation: An exploitative strategy that cooperates in round 1 to gather information,
    then defects to exploit cooperators in middle rounds, and defects in final rounds to lock in gains.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.C
        if current_round >= self.r - 2:
            return Action.D
        my_actions = history.my_actions[:current_round]
        opponent_actions = history.opponent_actions[:current_round, :]
        total_cooperations = np.sum(opponent_actions)
        total_actions_observed = current_round * self.n
        cooperation_rate = total_cooperations / total_actions_observed if total_actions_observed > 0 else 0.0
        threshold = self.k / (self.n - 1)
        if cooperation_rate > threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_388(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism: An exploitative strategy that
    systematically extracts value from cooperative players while avoiding losses
    to rational defectors. Uses observed cooperation rates to identify and exploit
    exploitable phenotypes, with particular intensity in final rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.THRESHOLD_HIGH = 0.6
        self.THRESHOLD_MID = 0.3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        current_round = state.round_number
        n_players = self.game_description.n_players
        n_rounds = self.game_description.n_rounds
        k = self.game_description.k
        total_cooperations = np.sum(history.opponent_actions)
        total_possible_cooperations = current_round * (n_players - 1)
        cooperation_rate = total_cooperations / total_possible_cooperations if total_possible_cooperations > 0 else 0.0
        if current_round == n_rounds - 1:
            if np.any(history.opponent_actions):
                return Action.D
            else:
                return Action.D
        if cooperation_rate > self.THRESHOLD_HIGH:
            return Action.D
        elif cooperation_rate > self.THRESHOLD_MID:
            recent_rounds_count = min(3, current_round)
            recent_cooperations = np.sum(history.opponent_actions[-recent_rounds_count:, :])
            recent_possible = recent_rounds_count * (n_players - 1)
            recent_cooperation_rate = recent_cooperations / recent_possible if recent_possible > 0 else 0.0
            if recent_cooperation_rate > 0.5:
                return Action.D
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_389(BaseStrategy):
    """
    Exploitative strategy: Unconditional Defection with Parasitic Adaptation.

    Core principle: Always defect to extract maximum value from cooperators while
    avoiding the cost of contribution. Defection guarantees a baseline payoff of 1
    and captures a share of any public good created by others' cooperation.

    This strategy exploits the fundamental asymmetry: defectors always earn 1 unit
    more than cooperators when others cooperate, making cooperation irrational in
    a finite-horizon game against heterogeneous opponents.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_390(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Maximizes personal payoff by defaulting to defection, selectively freeloading
    on cooperators when detected, and adapting to opponent cooperation rates.
    Uses a cooperation threshold model that decreases over time to enable
    late-game exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == 1:
            cooperators_r0 = sum(history.opponent_actions[0, :])
            if cooperators_r0 == self.n - 1:
                return Action.C
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        total_cooperators = 0
        for round_idx in range(round_num):
            total_cooperators += sum(history.opponent_actions[round_idx, :])
            total_cooperators += history.my_actions[round_idx]
        cooperation_rate = total_cooperators / (round_num * self.n)
        base_threshold = self.k / (self.n + 1)
        round_adj = -0.05 * (round_num / self.r)
        late_game_adj = 0.0
        if round_num > 0.75 * self.r:
            late_game_adj = -0.1
        if round_num == self.r - 2:
            late_game_adj = -0.15
        param_adj = 0.0
        if self.n <= 3:
            param_adj += 0.05
        if self.k > self.n - 0.5:
            param_adj -= 0.05
        if self.k < 1.5:
            param_adj += 0.05
        threshold = base_threshold + round_adj + late_game_adj + param_adj
        threshold = max(0.01, min(0.99, threshold))
        if round_num >= 1:
            prev_coop_rate = sum(history.opponent_actions[round_num - 1, :]) + history.my_actions[round_num - 1]
            prev_coop_rate = prev_coop_rate / self.n
            current_coop_rate = (sum(history.opponent_actions[round_num - 1, :]) + history.my_actions[round_num - 1]) / self.n
            if round_num >= 2:
                prev_prev_coop_rate = (sum(history.opponent_actions[round_num - 2, :]) + history.my_actions[round_num - 2]) / self.n
                if prev_prev_coop_rate - current_coop_rate > 0.15:
                    return Action.D
        if cooperation_rate > threshold:
            expected_public_return = self.k / self.n * cooperation_rate * self.n
            if expected_public_return > 1.0:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_391(BaseStrategy):
    """
    Adaptive Parasitism Strategy: Exploits cooperative behavior in public goods games
    by defecting by default and only considering cooperation when cooperation rates
    exceed an adaptive threshold that decreases over time.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_t = state.round_number
        if round_t == 0:
            return Action.D
        if round_t == self.r - 1:
            return Action.D
        prev_round_cooperators = np.sum(history.opponent_actions[round_t - 1, :])
        observed_rate = prev_round_cooperators / self.n
        base_threshold = self.k / self.n
        threshold = base_threshold + (self.r - round_t) / self.r * (base_threshold - 0.01)
        expected_payoff_defect = 1.0 + self.k / self.n * prev_round_cooperators
        expected_payoff_coop = self.k / self.n * (prev_round_cooperators + 1)
        if observed_rate < threshold:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_392(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    Exploits the public goods game by defaulting to defection while selectively
    cooperating only when harvesting from high-cooperation environments. Adapts
    to observed cooperation rates and always defects in terminal rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def _compute_threshold_high(self) -> float:
        """Compute high cooperation threshold based on game parameters."""
        base = (self.n - 1) / self.n
        if self.k / self.n > 0.8:
            return base * 0.5
        else:
            return base * 0.7

    def _compute_threshold_low(self) -> float:
        """Compute low cooperation threshold based on game parameters."""
        return (self.n - 1) / self.n * 0.3

    def _get_observed_cooperation_rate(self, history: PlayerHistory, round_idx: int) -> float:
        """Calculate observed cooperation rate in a given round."""
        if round_idx < 0 or round_idx >= len(history.opponent_actions):
            return 0.0
        opponent_cooperations = sum(history.opponent_actions[round_idx, :])
        total_opponents = self.n - 1
        return opponent_cooperations / total_opponents if total_opponents > 0 else 0.0

    def _should_use_strict_thresholds(self) -> bool:
        """Determine if strict thresholds should apply (small n)."""
        return self.n <= 3

    def _get_effective_threshold_high(self, base_threshold: float) -> float:
        """Adjust threshold based on game conditions."""
        if self._should_use_strict_thresholds():
            return 0.8
        if self.r > 20:
            return base_threshold * 0.9
        return base_threshold

    def _detect_cooperation_collapse(self, history: PlayerHistory, current_round: int) -> bool:
        """Detect if cooperation rate dropped sharply."""
        if current_round < 1:
            return False
        prev_coop = self._get_observed_cooperation_rate(history, current_round - 1)
        if current_round < 2:
            return False
        prev_prev_coop = self._get_observed_cooperation_rate(history, current_round - 2)
        if prev_prev_coop - prev_coop > 0.3:
            return True
        return False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if self.k / self.n < 1:
            return Action.D
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        if self._detect_cooperation_collapse(history, current_round):
            return Action.D
        coop_rate = self._get_observed_cooperation_rate(history, current_round - 1)
        threshold_high_base = self._compute_threshold_high()
        threshold_high = self._get_effective_threshold_high(threshold_high_base)
        threshold_low = self._compute_threshold_low()
        if coop_rate >= threshold_high:
            return Action.C
        elif coop_rate > threshold_low:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_393(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation Probing

    Maximizes personal payoff by defaulting to defection while strategically exploiting
    cooperative tendencies. Defects in round 1 and final round, adapts based on observed
    cooperation rates in intermediate rounds with occasional probing.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_alpha = 0.4
        self.threshold_beta = 0.1
        self.p_probe = 0.25

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        prev_round_idx = current_round - 1
        cooperators_prev_round = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        coop_rate = cooperators_prev_round / n
        if coop_rate > self.threshold_alpha:
            return Action.D
        elif coop_rate > self.threshold_beta:
            if random.random() < self.p_probe:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_394(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    This strategy always defects to maximize payoff by:
    1. Free-riding on any cooperators in the population
    2. Avoiding wasteful cooperation when others defect
    3. Establishing defection as the baseline from round 1

    Core insight: Defection is the dominant strategy in simultaneous-move
    public goods games when k < n. Even when opponents cooperate, defecting
    yields higher payoff (1 + share of contributions) than cooperating
    (share of contributions only).
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        """
        Decision rule: Always defect.

        Round 1 (history=None): Defect to probe and avoid exploitation
        Rounds 2 to r-1: Defect to exploit cooperators or match defectors
        Round r: Defect with no future punishment possible

        This is the dominant strategy regardless of opponent behavior.
        """
        return Action.D

class Strategy_EXPLOITATIVE_395(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Opportunistic Exploitation

    Maximizes personal payoff by exploiting cooperative tendencies in others while avoiding
    mutual defection traps. Uses conditional defection based on cooperation rates and payoff
    differentials.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.exploitation_threshold = self.k / self.n_players
        self.min_viable_threshold = 2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        prev_round_idx = current_round - 1
        cooperators_prev_round = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        global_coop_rate = cooperators_prev_round / self.n_players
        if global_coop_rate > self.exploitation_threshold:
            return Action.D
        if cooperators_prev_round < self.min_viable_threshold:
            return Action.D
        expected_payoff_defect = 1.0 + self.k / self.n_players * cooperators_prev_round
        expected_payoff_cooperate = self.k / self.n_players * (cooperators_prev_round + 1)
        if expected_payoff_defect >= expected_payoff_cooperate:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_396(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Harvesting

    This strategy exploits the fundamental asymmetry in the public goods game by:
    1. Always defecting to extract private endowment value
    2. Harvesting contributions from cooperative players
    3. Tracking cooperation rates to identify exploitation opportunities
    4. Terminal exploitation in the final round when reputation doesn't matter
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        """
        Decision rule: Defect by default in all rounds.

        Rationale:
        - Round 0 (first): Defect to observe opponent strategies while securing baseline payoff
        - Rounds 1 to n_rounds-2 (middle): Defect to exploit cooperative players if they exist
        - Round n_rounds-1 (final): Defect with no fear of punishment (terminal round)
        """
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.n_rounds - 1:
            return Action.D
        if 1 <= state.round_number < self.n_rounds - 1:
            total_cooperators = np.sum(history.opponent_actions[:state.round_number, :])
            total_actions = self.n_players * state.round_number
            cooperation_rate = total_cooperators / total_actions if total_actions > 0 else 0.0
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_397(BaseStrategy):
    """
    Adaptive Predation: An exploitative strategy that defects unconditionally in first and last rounds,
    and defects in middle rounds to exploit any cooperative tendencies while maintaining immunity to
    reputational punishment. Based on the fundamental asymmetry that defection strictly dominates
    cooperation in public goods games when k < n.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        if history is not None:
            total_rounds_observed = round_number
            total_opponent_slots = total_rounds_observed * (self.n_players - 1)
            if total_opponent_slots > 0:
                total_cooperators_observed = np.sum(history.opponent_actions[:round_number, :])
                observed_coop_rate = total_cooperators_observed / total_opponent_slots
            else:
                observed_coop_rate = 0.0
            if observed_coop_rate > 0:
                return Action.D
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_398(BaseStrategy):
    """
    Adaptive Predation Strategy for N-Player Public Goods Game.

    Exploits cooperative players through consistent defection while adaptively
    tracking opponent cooperation patterns. Uses early rounds to identify cooperators,
    then systematically free-rides on their contributions throughout the middle game,
    with guaranteed defection in terminal rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round <= 2:
            return Action.D
        if current_round >= self.n_rounds - 2:
            return Action.D
        opponent_cooperation_rates = self._calculate_opponent_cooperation_rates(history, current_round)
        high_cooperators_exist = any((rate >= 0.7 for rate in opponent_cooperation_rates))
        moderate_cooperators_exist = any((0.3 <= rate < 0.7 for rate in opponent_cooperation_rates))
        if current_round > 0:
            total_cooperators_last_round = sum(history.opponent_actions[current_round - 1, :])
        else:
            total_cooperators_last_round = 0
        if high_cooperators_exist:
            return Action.D
        elif moderate_cooperators_exist and total_cooperators_last_round > self.n_players / 2:
            return Action.D
        elif total_cooperators_last_round == 0:
            return Action.D
        else:
            cooperation_rate = sum(opponent_cooperation_rates) / len(opponent_cooperation_rates) if opponent_cooperation_rates else 0
            if cooperation_rate < self.k / self.n_players:
                return Action.D
            else:
                return Action.D

    def _calculate_opponent_cooperation_rates(self, history: PlayerHistory, current_round: int) -> list:
        """
        Calculate the cooperation rate for each opponent based on history so far.
        Returns a list of cooperation rates indexed by opponent.
        """
        if current_round == 0:
            return []
        opponent_cooperation_rates = []
        for opponent_idx in range(self.n_players - 1):
            cooperations = sum(history.opponent_actions[:current_round, opponent_idx])
            cooperation_rate = cooperations / current_round
            opponent_cooperation_rates.append(cooperation_rate)
        return opponent_cooperation_rates

class Strategy_EXPLOITATIVE_399(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism: An exploitative strategy that defaults to defection,
    parasitizes cooperators when present, and abandons cooperation opportunities when they collapse.
    Maximizes personal payoff by free-riding on others' contributions while maintaining individual rationality.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.defection_threshold = 0.7
        self.cooperation_sustainability_threshold = 0.35
        self.recent_window_size = min(10, self.n_rounds)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        if round_number <= 2:
            return Action.D
        recent_start = max(0, round_number - self.recent_window_size)
        recent_rounds = history.opponent_actions[recent_start:round_number]
        if len(recent_rounds) > 0:
            cooperators_per_round = np.sum(recent_rounds, axis=1)
            avg_cooperators = np.mean(cooperators_per_round)
        else:
            avg_cooperators = 0
        cooperation_level = avg_cooperators / self.n_players
        expected_public_good_return = self.k / self.n_players * avg_cooperators
        if expected_public_good_return < 1.0:
            return Action.D
        if cooperation_level >= self.cooperation_sustainability_threshold:
            my_recent_actions = history.my_actions[recent_start:round_number]
            if len(my_recent_actions) > 0:
                my_defection_rate = np.sum(~my_recent_actions) / len(my_recent_actions)
            else:
                my_defection_rate = 1.0
            if my_defection_rate > self.defection_threshold:
                return Action.D
        if round_number >= self.n_rounds - 3:
            if cooperation_level < 0.25:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_400(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism Strategy.

    Exploits cooperative players through unconditional defection while monitoring
    cooperation rates to ensure the public good remains attractive to parasitize.
    Uses threshold-based decision making in the exploitation phase.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number <= 1:
            return Action.D
        if history is not None:
            total_cooperations = np.sum(history.opponent_actions)
            total_decisions = round_number * self.n_players
            observed_cooperation_rate = total_cooperations / total_decisions if total_decisions > 0 else 0.0
        else:
            observed_cooperation_rate = 0.0
        threshold = self.k / self.n_players * 0.4
        if round_number >= 2 and round_number <= self.n_rounds - 2:
            return Action.D
        if round_number >= self.n_rounds - 2:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_401(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Implements pure defection strategy based on game-theoretic analysis that defection
    is the dominant strategy in the N-player public goods game. The strategy always defects
    because:
    1. In round 1: No history to exploit, defection is safe
    2. In final round: No future punishment possible
    3. In mid-game: Defection captures public good benefits without contributing
    4. At all times: Cooperation is dominated by defection given any cooperation rate
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.exploitation_count = 0
        self.observed_defector_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        n_rounds = self.game_description.n_rounds
        n_players = self.game_description.n_players
        k = self.game_description.k
        if round_number == 0:
            return Action.D
        if round_number == n_rounds - 1:
            return Action.D
        if history is not None:
            cooperators_prev = int(sum(history.opponent_actions[-1, :]))
            cooperation_rate = cooperators_prev / n_players
            if cooperation_rate > 0:
                self.exploitation_count += 1
            else:
                self.observed_defector_rounds += 1
            threshold = k / n_players
        return Action.D

class Strategy_EXPLOITATIVE_402(BaseStrategy):
    """
    Threshold Parasitism: An exploitative strategy that defects by default and parasitizes
    cooperators when cooperation rates exceed a mathematically-derived threshold.

    Core mechanics:
    - Round 1: DEFECT (no history, safe default)
    - Final round: DEFECT (end-game extraction, no future incentives)
    - Middle rounds: DEFECT if previous cooperation rate >= (k-1)/k, else DEFECT

    The strategy is always defection, but adapts its reasoning based on observed
    cooperation rates. When cooperation is high, it exploits the public good.
    When cooperation collapses, it maintains defection as universal best response.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold = (self.k - 1) / self.k
        self.min_threshold = max(0.05, 1.0 / self.n)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.r - 1:
            return Action.D
        prev_round_actions = history.opponent_actions[round_number - 1, :]
        prev_cooperators = int(np.sum(prev_round_actions))
        prev_cooperation_rate = prev_cooperators / self.n
        if prev_cooperation_rate >= self.threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_403(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Exploitation

    This strategy implements a dominant defection approach that:
    - Always defects in round 1 to avoid naive cooperation
    - Always defects in the final round with no future consequences
    - In middle rounds, defects to exploit any cooperation present
    - Uses an exploitation threshold to calibrate decisions based on game parameters

    The strategy recognizes that defection is dominant when k < n, and maximizes
    payoff by exploiting cooperators while avoiding contribution costs.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.exploitation_threshold = (self.n - self.k) / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        last_round_idx = current_round - 1
        cooperators_last_round = int(sum(history.opponent_actions[last_round_idx, :]))
        cooperation_rate = cooperators_last_round / self.n
        return Action.D

class Strategy_EXPLOITATIVE_404(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Exploitation

    Always defects to maximize payoff. Tracks which opponents have cooperated
    in previous rounds to identify exploitation opportunities, but always defects
    regardless. This strategy exploits cooperators while avoiding vulnerability
    to defectors through unconditional defection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperator_status = {}

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number > 0 and history is not None:
            previous_round = state.round_number - 1
            for opponent_idx in range(self.game_description.n_players - 1):
                opponent_action = history.opponent_actions[previous_round, opponent_idx]
                self.cooperator_status[opponent_idx] = opponent_action
        return Action.D

class Strategy_EXPLOITATIVE_405(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    This strategy always defects to maximize personal payoff by free-riding on any
    cooperators. The mathematical advantage of defection (1 - k/n > 0) is always positive
    since k < n, making defection strictly dominant regardless of opponent behavior.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_406(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    Defaults to defection and only cooperates when the observed cooperation rate
    from the previous round exceeds the break-even threshold k/n, making it rational
    to exploit the public good. Defects in round 1 and the final round to avoid
    vulnerability and maximize exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        previous_round_cooperators = sum(history.opponent_actions[current_round - 1, :])
        observed_coop_rate = previous_round_cooperators / self.n_players
        if observed_coop_rate > self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_407(BaseStrategy):
    """
    Adaptive Predation Strategy for N-Player Public Goods Game.

    Core principle: Always defect to maximize exploitation of cooperators
    while maintaining parity with defectors. Defection is a dominant strategy
    in simultaneous-move public goods games.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        """
        Decision rule: ALWAYS DEFECT

        Reasoning:
        - Round 0 (first round): Defect to establish baseline and probe for cooperators
        - Rounds 1 to r-2 (middle rounds): Defect to exploit any cooperators while
          avoiding losses against defectors
        - Round r-1 (final round): Defect due to backward induction (no future payoff)

        Defection dominates because:
        - Against cooperators: we gain private endowment (1) + share of public good
        - Against defectors: we match their payoff (1)
        - In all cases: defection  cooperation payoff
        """
        return Action.D

class Strategy_EXPLOITATIVE_408(BaseStrategy):
    """
    Adaptive Predation: An exploitative strategy that always defects to free-ride on cooperators.

    Core mechanism:
    - Round 1: Defect to gather information
    - Rounds 2 to r-1: Defect to free-ride on any cooperators, using adaptive monitoring
    - Last round: Defect with no shadow of the future

    Always defects, but dynamically monitors opponent cooperation to maximize exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_history = []
        self.threshold = 0.3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        cooperators_last_round = sum(history.opponent_actions[state.round_number - 1, :])
        observed_cooperation_rate = cooperators_last_round / (self.game_description.n_players - 1)
        self.cooperation_history.append(observed_cooperation_rate)
        moving_window = min(3, len(self.cooperation_history))
        moving_avg_rate = sum(self.cooperation_history[-moving_window:]) / moving_window
        return Action.D

class Strategy_EXPLOITATIVE_409(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core philosophy: Exploit the asymmetry of public goods games by parasitizing
    cooperative behavior. Always defect except where forced, capturing public goods
    created by cooperators without contributing.

    Decision rule:
    - Round 1: DEFECT (gather intelligence)
    - Final round: DEFECT (no retaliation to fear)
    - Last 2-3 rounds: DEFECT (endgame exploitation)
    - Middle rounds: DEFECT (always defect when cooperation is uncertain)

    This strategy is robust because defection is never a dominated strategy in
    n-player PGGs where k < n.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        rounds_remaining = self.n_rounds - current_round
        if rounds_remaining <= 3:
            return Action.D
        if history is not None and current_round > 0:
            prev_round_idx = current_round - 1
            prev_cooperators = int(sum(history.opponent_actions[prev_round_idx, :]))
            cooperation_rate = prev_cooperators / self.n_players
            threshold = 1.0 / self.k
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_410(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core philosophy: Exploit the structural incentive where defection yields higher
    immediate payoff than cooperation when others contribute. Always defect to avoid
    being exploited while parasitizing cooperators.

    Decision rules:
    - Round 1: DEFECT (probe and observe)
    - Rounds 2 to r-1: DEFECT (parasitize cooperators if present)
    - Last round: DEFECT (final exploitation spike)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = math.ceil(self.n_players * self.k / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        previous_round_idx = current_round - 1
        cooperators_prev_round = sum(history.opponent_actions[previous_round_idx, :])
        if cooperators_prev_round >= self.threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_411(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism.

    Maximizes personal payoff through strategic defection while parasitically
    harvesting contributions from cooperative opponents. Classifies opponent types
    and exploits them accordingly.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.opponent_types = {}
        self.classification_threshold = 4

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        if state.round_number >= self.classification_threshold:
            self._classify_opponents(history, state.round_number)
        return Action.D

    def _classify_opponents(self, history: PlayerHistory, current_round: int) -> None:
        """
        Classify opponents into types based on their cooperation history.

        Type A (Sucker Cooperators): Cooperate despite consistent defection from us
        Type B (Reciprocators): Cooperate conditionally based on others' behavior
        Type C (Rational Defectors): Defect consistently
        """
        n_opponents = self.game_description.n_players - 1
        for opponent_idx in range(n_opponents):
            if opponent_idx in self.opponent_types:
                continue
            opponent_cooperations = sum(history.opponent_actions[:current_round, opponent_idx])
            rounds_so_far = current_round
            cooperation_rate = opponent_cooperations / rounds_so_far if rounds_so_far > 0 else 0
            my_defections = sum((1 for i in range(rounds_so_far) if not history.my_actions[i]))
            if cooperation_rate >= 0.8 and my_defections >= rounds_so_far * 0.7:
                self.opponent_types[opponent_idx] = 'A'
            elif cooperation_rate >= 0.5:
                self.opponent_types[opponent_idx] = 'B'
            else:
                self.opponent_types[opponent_idx] = 'C'

class Strategy_EXPLOITATIVE_412(BaseStrategy):
    """
    Adaptive Parasitism Strategy: Exploits cooperative behavior while avoiding costly cooperation.
    Defaults to defection except under specific arithmetic conditions that guarantee net positive payoff.
    Systematically extracts value from cooperators while minimizing vulnerability to exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        cooperators_prev = int(sum(history.opponent_actions[current_round - 1, :]))
        coop_rate = cooperators_prev / self.n
        if self.k < 2:
            threshold = 0.5
        elif self.k < self.n - 1:
            threshold = 0.4
        else:
            threshold = 0.3
        public_payoff = self.k / self.n * cooperators_prev
        if current_round >= 2:
            total_cooperators_so_far = int(sum(history.opponent_actions[:current_round, :].flatten()))
            total_slots = current_round * self.n
            overall_coop_rate = total_cooperators_so_far / total_slots
            if overall_coop_rate < 0.1:
                return Action.D
        if current_round >= 2:
            coop_rate_prev = int(sum(history.opponent_actions[current_round - 2, :])) / self.n
            if coop_rate > 0.6 and coop_rate_prev < 0.3:
                return Action.D
        if current_round == self.r - 2:
            return Action.D
        if coop_rate >= threshold and public_payoff > 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_413(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Maximizes personal payoff by exploiting cooperative tendencies in others
    while minimizing contribution costs. Always defects or defects whenever
    cooperation rates exceed the threshold k/n, treating cooperation as a
    resource to extract rather than a norm to uphold.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        if history is None:
            return Action.D
        previous_round_idx = current_round - 1
        cooperators_last_round = sum(history.opponent_actions[previous_round_idx, :])
        coop_rate = cooperators_last_round / self.n
        if coop_rate > self.threshold:
            return Action.D
        elif coop_rate >= self.threshold / 2 and self.r - current_round > 2:
            return Action.D
        elif self.r - current_round <= 2:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_414(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core philosophy: Exploit the asymmetry between individual incentives and collective welfare.
    Since defection always yields higher individual payoff than cooperation (a constant 1-unit advantage),
    this strategy plays Defect in every round to maximize personal gain while free-riding on others' contributions.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        return Action.D

class Strategy_EXPLOITATIVE_415(BaseStrategy):
    """
    Adaptive Predation Strategy: Exploit cooperators through systematic defection.

    Core approach: Always defect except when adapting based on observed cooperation rates.
    In practice, this simplifies to pure defection since k < n makes cooperation individually suboptimal.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        total_cooperations = int(np.sum(history.opponent_actions[:current_round, :]))
        total_actions = current_round * self.n
        cooperation_rate = total_cooperations / total_actions if total_actions > 0 else 0
        threshold = self.k / self.n
        if cooperation_rate > threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_416(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Always defects to free-ride on others' contributions and avoid losses from exploitation.
    Exploits the mathematical dominance of defection in the public goods game by:
    1. Defecting in round 1 to establish aggressiveness
    2. Defecting in all mid-game rounds regardless of cooperation rate
    3. Defecting in the final round to extract maximum value

    The strategy recognizes that defection is individually rational because:
    - Free-riding on cooperation yields: 1 + (k/n)  contributions
    - Contributing when others defect yields: 0 + (k/n)  few_contributions < 1
    - No punishment mechanism exists to deter defection
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        if history is not None and len(history.opponent_actions) > 0:
            total_cooperators = np.sum(history.opponent_actions)
            total_player_rounds = len(history.opponent_actions) * self.n
            cooperation_rate = total_cooperators / total_player_rounds
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_417(BaseStrategy):
    """
    Adaptive Parasitism with Escalation: An exploitative strategy that free-rides on
    cooperative players while maintaining plausible deniability through selective cooperation.
    Defects in round 1 and final round, adapts in middle rounds based on cooperation density.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.break_even = self.k / self.n
        self.threshold = 0.4

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        total_cooperators = int(np.sum(history.opponent_actions[:current_round, :]))
        total_slots = self.n * current_round
        coop_density = total_cooperators / total_slots
        any_cooperators_last_round = bool(np.sum(history.opponent_actions[current_round - 1, :]) > 0)
        if coop_density >= self.break_even:
            if coop_density >= self.threshold:
                p_coop = (coop_density - self.break_even) / (1.0 - self.break_even)
                p_coop = min(p_coop, 0.5)
                if random.random() < p_coop:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D
        elif any_cooperators_last_round:
            if random.random() < 0.15:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_418(BaseStrategy):
    """
    Adaptive Parasitism: A pure defection strategy that exploits cooperative players
    by always defecting regardless of opponent behavior or game phase.

    Core principle: Defection strictly dominates cooperation in the payoff structure.
    By always defecting, this strategy maximizes personal payoff while free-riding
    on any public good contributions made by cooperators.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_419(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Core principle: Always defect to maximize individual payoff by exploiting
    any cooperators in the game. Defection is mathematically optimal given that
    k < n (the multiplication factor is less than the number of players).

    Strategy:
    - Always plays D (Defect) across all rounds
    - Optionally observes cooperation rates to track opponent behavior
    - Never reciprocates cooperation, maintaining pure defection
    - Exploits the payoff structure where defectors earn 1 unit more than cooperators
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_rate = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if history is not None:
            total_opponent_cooperations = np.sum(history.opponent_actions)
            total_opponent_actions = history.opponent_actions.shape[0] * history.opponent_actions.shape[1]
            if total_opponent_actions > 0:
                self.cooperation_rate = total_opponent_cooperations / total_opponent_actions
        return Action.D

class Strategy_EXPLOITATIVE_420(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Maximizes payoff by free-riding on others' cooperation while minimizing losses
    when cooperation collapses. Uses threshold-based decision rule to determine when
    defection is profitable versus when conditional cooperation is advantageous.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold = math.ceil(self.k / (self.n - self.k))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.r - 1:
            return Action.D
        cooperators_prev_round = int(sum(history.opponent_actions[round_number - 1, :]))
        if history.my_actions[round_number - 1]:
            cooperators_prev_round += 1
        cooperation_rate_prev = cooperators_prev_round / self.n
        threshold_rate = self.threshold / self.n
        if cooperation_rate_prev >= threshold_rate:
            last_payoff_as_defector = 1.0 + self.k / self.n * cooperators_prev_round
            breakeven_payoff = self.k
            if last_payoff_as_defector < breakeven_payoff - 0.1:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_421(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Exploitation

    Core principle: Always defect to maximize individual payoff by free-riding
    on others' cooperation and avoiding the cost of contributing to the public good.
    Defection strictly dominates cooperation in all game states.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        return Action.D

class Strategy_EXPLOITATIVE_422(BaseStrategy):
    """
    Adaptive Parasitism with Opportunistic Defection.

    Exploits cooperators ruthlessly by defecting by default, only cooperating
    when expected payoff from cooperation exceeds defection against observed
    opponent distribution. Employs threshold-based decision rules and adaptive
    exploitation mechanisms targeting high cooperation rates.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = 0.8

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        if history is None:
            return Action.D
        cooperator_counts = np.sum(history.opponent_actions, axis=1)
        cooperator_ratio = np.mean(cooperator_counts) / self.n
        if self.k > self.n / 2:
            if cooperator_ratio > self.threshold:
                return Action.D
            else:
                return Action.D
        else:
            return Action.D
        if cooperator_ratio >= 0.5 and cooperator_ratio <= self.threshold:
            if len(cooperator_counts) >= 2:
                recent_rate = np.mean(cooperator_counts[-2:]) / self.n
                previous_rate = np.mean(cooperator_counts[-3:-1]) / self.n if len(cooperator_counts) >= 3 else cooperator_ratio
                trend = recent_rate - previous_rate
                if trend > 0.1:
                    return Action.D
                if trend < -0.1:
                    return Action.D
            if len(cooperator_counts) >= 3:
                variance = np.var(cooperator_counts[-3:] / self.n)
                if variance > 0.3:
                    return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_423(BaseStrategy):
    """
    Adaptive Defection with Conditional Parasitism Strategy.

    This exploitative strategy defaults to defection in all rounds, exploiting any
    cooperators in the population while never reciprocating cooperation. The core
    insight is that defection is the dominant strategy in every round of the public
    goods game, so the rational response is to always defect and free-ride on any
    cooperation that emerges.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_threshold = 1.0 / 3.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        total_cooperators = np.sum(history.opponent_actions)
        total_observations = state.round_number * self.game_description.n_players
        average_coop_rate = total_cooperators / total_observations if total_observations > 0 else 0.0
        if average_coop_rate > 0.0:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_424(BaseStrategy):
    """
    Adaptive Predation: An exploitative strategy that systematically defects to exploit
    cooperative opponents while adapting to changing opponent behavior patterns.

    Core approach:
    - Always defect in round 1 and final round
    - In middle rounds, track opponent cooperation rates and defect if exploitation opportunities exist
    - Default action is always defection; cooperation is never played
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.coop_count = None
        self.coop_threshold = 0.3
        self.pop_coop_threshold = 0.4

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if self.coop_count is None:
            self.coop_count = np.zeros(self.game_description.n_players - 1)
        current_round = state.round_number
        n_players = self.game_description.n_players
        n_rounds = self.game_description.n_rounds
        k = self.game_description.k
        if current_round == 0:
            return Action.D
        if current_round == n_rounds - 1:
            return Action.D
        for round_idx in range(current_round):
            opponent_actions_this_round = history.opponent_actions[round_idx, :]
            self.coop_count += opponent_actions_this_round
        rounds_elapsed = current_round
        coop_rates = self.coop_count / rounds_elapsed
        max_coop_rate = np.max(coop_rates)
        avg_coop_rate = np.mean(coop_rates)
        total_public_good = np.sum(history.opponent_actions[:current_round, :])
        public_good_threshold = k * rounds_elapsed / 2.0
        if max_coop_rate > self.coop_threshold or avg_coop_rate > self.pop_coop_threshold or total_public_good > public_good_threshold:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_425(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Opportunistic Parasitism

    Core philosophy: Exploit the asymmetry in public goods games by defecting
    to harvest cooperation from others without contributing. Defect every round
    to maximize personal payoff at the expense of collective welfare.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.cooperation_threshold = math.ceil(self.n / self.k)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        previous_round_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        if previous_round_cooperators >= self.cooperation_threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_426(BaseStrategy):
    """
    Exploitative Strategy: Unconditional Defection with Opportunistic Late-Game Defection

    This strategy exploits the fundamental asymmetry in the Public Goods Game by always defecting.
    Defection is optimal because:
    1. It extracts maximum value from cooperators via free-riding
    2. It matches payoffs against other defectors
    3. It avoids the sucker's payoff from unilateral cooperation

    Core principle: Defect every round without exception.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        return Action.D

class Strategy_EXPLOITATIVE_427(BaseStrategy):
    """
    EXPLOITATIVE STRATEGY: UNCONDITIONAL DEFECTION WITH PARASITIC EXPLOITATION

    Core Philosophy: Maximize personal payoff by always defecting and parasitizing
    any cooperation that emerges. Defection is strictly dominant in the public goods
    game, so this strategy never cooperates regardless of opponent behavior.

    Decision Rule:
    - Round 0 (first round): DEFECT to establish non-cooperation baseline
    - Rounds 1 to r-1 (intermediate): DEFECT unconditionally
    - Final round: DEFECT (no retaliation possible)

    Rationale: In the public goods game, defection always yields higher individual
    return than cooperation. A defector receives the full private endowment (1) plus
    a share of the public good (k/n  total_cooperators), while a cooperator only
    receives the share (k/n  total_cooperators) without the private endowment.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_428(BaseStrategy):
    """
    Adaptive Predation: An exploitative strategy that defects consistently while
    monitoring opponent cooperation rates. Exploits cooperators by free-riding on
    their contributions, and matches defectors by also defecting. Never cooperates
    in practice due to the 0.3 cooperation threshold being difficult to reach
    organically, ensuring maximum payoff extraction.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.defection_threshold = 0.3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        n_rounds = self.game_description.n_rounds
        if current_round == 0:
            return Action.D
        if current_round == n_rounds - 1:
            return Action.D
        rounds_observed = current_round
        for opponent_idx in range(self.game_description.n_players - 1):
            opponent_cooperations = np.sum(history.opponent_actions[:current_round, opponent_idx])
            cooperation_rate = opponent_cooperations / rounds_observed
            if cooperation_rate > self.defection_threshold:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_429(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core approach: Always defect to exploit cooperators while avoiding the cost
    of contribution. Maintains a threshold-based adaptation that simplifies to
    pure defection across all rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = math.ceil(self.n * self.k / 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        cooperators_prev = int(sum(history.opponent_actions[current_round - 1, :]))
        if cooperators_prev >= self.threshold:
            return Action.D
        elif cooperators_prev == 0:
            return Action.D
        elif current_round > self.r / 2:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_430(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism: An exploitative strategy that always defects
    to maximize payoff by free-riding on others' contributions to the public good.

    Core behavior:
    - Round 1: DEFECT (establish baseline, observe cooperators)
    - Rounds 2 to r-1: DEFECT (parasitize any cooperation that emerges)
    - Final round: DEFECT (terminal exploitation, no future rounds for retaliation)

    The strategy is based on the principle that defection is individually dominant in the
    public goods game when others cooperate, and provides no worse payoff than cooperation
    when others defect.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold_cooperators = math.ceil(self.k + 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        previous_round_idx = current_round - 1
        cooperators_in_previous_round = int(sum(history.opponent_actions[previous_round_idx, :]))
        return Action.D

class Strategy_EXPLOITATIVE_431(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core approach: Always defect to exploit cooperators while avoiding the sucker's payoff.
    Defection guarantees a private endowment (1) plus a share of any public contributions,
    while cooperators only receive the shared bonus without the private payoff.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_432(BaseStrategy):
    """
    Adaptive Defection with Selective Farming Strategy

    Exploits cooperative opponents while maintaining defensive defection.
    - Round 1: Defect to establish baseline
    - Rounds 2 to r-1: Track opponent cooperation rates and defect to exploit cooperators
    - Final round: Always defect (no future rounds)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        opponent_actions = history.opponent_actions[:current_round, :]
        coop_counts = np.sum(opponent_actions, axis=0)
        coop_rates = coop_counts / current_round
        rounds_remaining = r - current_round
        threshold = k / n + (1 - k / n) * (rounds_remaining / r)
        num_exploitable = np.sum(coop_rates >= threshold)
        return Action.D

class Strategy_EXPLOITATIVE_433(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Core Philosophy: Exploit the asymmetry between defection and cooperation payoffs.
    Default action is DEFECT to extract maximum value from cooperators while minimizing
    losses against defectors. Only cooperate when strong evidence suggests sufficient
    others will cooperate to make it worthwhile (which rarely happens under this strategy).
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        previous_round_idx = round_number - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[previous_round_idx, :]))
        coop_rate = cooperators_last_round / self.n_players
        defector_payoff = 1 + self.k / self.n_players * cooperators_last_round
        cooperator_payoff = self.k / self.n_players * cooperators_last_round
        if defector_payoff >= cooperator_payoff:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_434(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core logic:
    - Round 0 (first): Always defect to gather information
    - Round r-1 (last): Always defect for final exploitation
    - Middle rounds: Cooperate only if expected cooperators exceed threshold n/k

    The strategy exploits the public goods game structure by parasitizing
    cooperators when beneficial, while avoiding mutual defection traps.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.r - 1:
            return Action.D
        prev_round_idx = round_number - 1
        cooperators_last_round = int(sum(history.opponent_actions[prev_round_idx, :]))
        threshold = self.n / self.k
        if cooperators_last_round > threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_435(BaseStrategy):
    """
    Adaptive Predation Strategy: An exploitative approach that defects to free-ride on others'
    cooperation, with selective cooperation only in the final round if sustained cooperation
    is observed. Maximizes payoff by exploiting the asymmetry between defection (payoff 1)
    and cooperation (payoff 0 + share of public good).
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        cooperators_prev = int(sum(history.opponent_actions[round_number - 1, :]))
        cooperation_rate = cooperators_prev / self.n
        if round_number < self.r - 1:
            public_good_share = self.k / self.n * cooperation_rate
            if public_good_share >= 1.0 or cooperation_rate >= 0.5:
                return Action.D
            else:
                return Action.D
        elif round_number == self.r - 1:
            if cooperation_rate >= 0.75:
                return Action.D
            else:
                return Action.D
        else:
            total_cooperators_history = int(np.sum(history.opponent_actions[:round_number, :]))
            expected_history_cooperations = 0.5 * self.n * (self.r - 1)
            if cooperation_rate >= 0.67 and total_cooperators_history >= expected_history_cooperations:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_436(BaseStrategy):
    """
    Adaptive Parasite Strategy: Always defect to exploit cooperators.

    This strategy implements pure defection across all rounds, exploiting the
    dominant strategy equilibrium of the N-player Public Goods Game. Defection
    is strictly dominant regardless of others' choices, as it guarantees a
    baseline payoff while capturing value generated by any cooperators.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number < self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_437(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Calculated Cooperation

    Core approach:
    - Round 0: COOPERATE (probe for exploitable cooperators)
    - Rounds 1 to r-2: DEFECT if any opponent cooperated in previous round, else DEFECT
    - Round r-1 (last): DEFECT (terminal round exploitation)

    This strategy exploits the fundamental asymmetry in public goods games by
    first gathering information about opponent types, then systematically defecting
    to free-ride on any cooperation while avoiding wasted contributions.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_438(BaseStrategy):
    """
    Adaptive Defection with Conditional Parasitism.

    Core strategy: Always defect (D) to exploit the asymmetry between private gains
    from defection and public good benefits. Cooperators yield 1 + (k/n)  total_contributions
    while defectors get the same public good share without the cost of contributing.

    Decision logic:
    - Round 0 (first): Defect
    - Rounds 1 to r-2 (middle): Defect while monitoring cooperation rates
    - Round r-1 (last): Defect with absolute certainty (no future rounds)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number < self.game_description.n_rounds - 1:
            prev_round_idx = state.round_number - 1
            cooperators_prev_round = sum(history.opponent_actions[prev_round_idx, :])
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_439(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    This strategy exploits the public goods game by recognizing that defection
    strictly dominates cooperation in every round. It parasitizes cooperators
    while adapting to opponent pool composition dynamically.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            if self.k / self.n > 1 and self.k / self.n < 2:
                return Action.C
            else:
                return Action.D
        if current_round == self.r - 1:
            return Action.D
        prev_round_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        opponent_cooperation_rate = prev_round_cooperators / self.n
        if opponent_cooperation_rate >= 0.5:
            return Action.D
        elif opponent_cooperation_rate >= 0.25:
            return Action.D
        elif opponent_cooperation_rate < 0.25:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_440(BaseStrategy):
    """
    Exploitative strategy: Always Defect.

    This strategy maximizes personal payoff by defecting in all rounds.
    Defection is the dominant strategy in the n-player public goods game
    across all parameter ranges where 1 < k < n, as it guarantees a payoff
    of 1 plus a share of any contributions from others, while avoiding the
    opportunity cost of cooperation.

    Core principle: Never cooperate, systematically exploit any cooperators,
    and maintain immunity to punishment through constant defection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        return Action.D

class Strategy_EXPLOITATIVE_441(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Maximizes individual payoff by exploiting cooperators through:
    1. Default defection to avoid sucker's payoff
    2. Early game observation of cooperation patterns
    3. Mid-game selective parasitism against high-cooperators
    4. End-game pure defection for terminal exploitation
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0 or current_round >= self.n_rounds - 1:
            return Action.D
        early_game_threshold = math.ceil(self.n_rounds / 3)
        late_game_threshold = self.n_rounds - 2
        if current_round < early_game_threshold:
            return Action.D
        if current_round >= late_game_threshold:
            return Action.D
        prev_round_cooperators = int(np.sum(history.opponent_actions[current_round - 1, :]))
        cooperation_threshold = math.ceil(0.6 * (self.n_players - 1))
        if prev_round_cooperators >= cooperation_threshold:
            expected_cooperators = prev_round_cooperators + 1
            expected_return = self.k / self.n_players * expected_cooperators
            if expected_return >= 0.5:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_442(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism: An exploitative strategy that
    defects to free-ride on cooperators' contributions while avoiding retaliation.

    Core mechanics:
    - Round 1: Defect to probe opponent types without cost
    - Rounds 2 to r-1: Defect to exploit any cooperation in the population
    - Round r: Defect for final extraction (no future retaliation possible)

    Rationale: Defection is weakly dominant in public goods games when k < n.
    By always defecting, we capture the public good multiplier without contributing.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        prev_round_idx = current_round - 1
        prev_cooperators = sum(history.opponent_actions[prev_round_idx, :])
        coop_rate = prev_cooperators / self.n_players
        if current_round == self.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_443(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Exploitation

    Maximizes individual payoff by exploiting cooperators while minimizing losses from defectors.
    Core approach: Always defect, but calibrate exploitation intensity based on opponent cooperation patterns.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_threshold = 0.4
        self.recent_coop_threshold = 0.33

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        n_rounds = self.game_description.n_rounds
        if round_number == 0:
            return Action.D
        if round_number == 1:
            return Action.D
        if round_number >= n_rounds - 2:
            return Action.D
        opponent_actions = history.opponent_actions[:round_number, :]
        total_cooperations = np.sum(opponent_actions)
        total_possible = round_number * self.game_description.n_players
        overall_cooperation_rate = total_cooperations / total_possible if total_possible > 0 else 0
        if round_number % 3 == 0 and round_number >= 3:
            recent_rounds = opponent_actions[max(0, round_number - 3):round_number, :]
            recent_cooperations = np.sum(recent_rounds)
            recent_total = recent_rounds.size
            recent_cooperation_rate = recent_cooperations / recent_total if recent_total > 0 else 0
            if recent_cooperation_rate > self.recent_coop_threshold:
                return Action.D
            else:
                return Action.D
        if overall_cooperation_rate > self.cooperation_threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_444(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Maximizes payoff by free-riding on cooperation when it exists, matching defection
    when cooperation disappears, and never initiating cooperation. Uses an adaptive
    threshold to trigger parasitic cooperation only when enough others are cooperating
    to justify the 1-point sacrifice.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = math.ceil(self.game_description.n_players / self.game_description.k) + 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        t = state.round_number
        if t == 0:
            return Action.D
        if t == r - 1:
            return Action.D
        previous_cooperators = int(sum(history.opponent_actions[t - 1, :]))
        rounds_remaining = r - t
        if previous_cooperators >= self.threshold and rounds_remaining > 1:
            if t >= 2:
                cooperators_2_rounds_ago = int(sum(history.opponent_actions[t - 2, :]))
                if cooperators_2_rounds_ago > previous_cooperators:
                    return Action.D
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_445(BaseStrategy):
    """
    Adaptive Predation with Threshold Exploitation Strategy.

    Core approach: Always defect to exploit cooperative tendencies while
    minimizing vulnerability. The strategy treats cooperation as a resource
    to extract rather than a norm to reciprocate.

    Decision logic:
    - Round 0 (first): DEFECT (gather information, zero commitment)
    - Rounds 1 to r-2 (middle): DEFECT (continuous exploitation)
    - Round r-1 (last): DEFECT (no future consequences)

    This pure defection strategy is robust across diverse opponent types:
    beats pure cooperators through free-riding, locks in mutual defection
    with reciprocators, ties with other defectors, and minimizes losses
    against punishers.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold_a = (self.k - 1) / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_446(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    Maximizes personal payoff by exploiting cooperative tendencies while minimizing
    vulnerability to defection. Uses persistent defection as the dominant strategy,
    with adaptive monitoring of opponent cooperation rates to identify and exploit
    cooperative players.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.cooperation_threshold = max(2 / self.n_players, 0.3)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        last_round_opponent_actions = history.opponent_actions[-1, :]
        cooperators_last_round = int(np.sum(last_round_opponent_actions))
        cooperation_rate = cooperators_last_round / self.n_players
        defection_rate = 1 - cooperation_rate
        if cooperation_rate >= self.cooperation_threshold:
            return Action.D
        if defection_rate >= 0.8:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_447(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core philosophy: Exploit the public goods game by defecting by default,
    parasitizing cooperation when it emerges, and never voluntarily cooperating.
    The strategy identifies when cooperators create extractable surplus and defects
    to capture it while minimizing personal contribution.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.k - 1) / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == self.n_rounds - 1:
            return Action.D
        if current_round == 0:
            return Action.D
        previous_round_idx = current_round - 1
        previous_opponent_actions = history.opponent_actions[previous_round_idx, :]
        num_cooperators_previous = int(np.sum(previous_opponent_actions))
        cooperation_rate_previous = num_cooperators_previous / self.n_players
        if cooperation_rate_previous >= self.threshold:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_448(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core behavior: Always defect across all rounds.
    - Round 1: Defect (no history; gather information risk-free)
    - Rounds 2 to r-1: Defect (k < n makes cooperation suboptimal)
    - Round r: Defect (final round; no future consequences)

    This strategy extracts value from cooperators while avoiding the cost of cooperation.
    Since k < n, defection is strictly dominant: payoff from defecting (1 + k/n  others' contributions)
    exceeds cooperation (0 + k/n  others' contributions + own contribution).
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_449(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Systematically free-rides on cooperation while minimizing exposure to mutual defection.
    Always defects except in rare cases where cooperation might be marginally beneficial.
    Maximizes personal payoff through exploitation of cooperators' contributions.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold_count = math.ceil(self.n_players * (1 - 1 / self.k))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        previous_round_idx = current_round - 1
        cooperators_in_previous = int(np.sum(history.opponent_actions[previous_round_idx, :]))
        if cooperators_in_previous >= self.threshold_count:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_450(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    This strategy exploits the public goods game by always defecting to:
    1. Keep the full endowment (payoff = 1)
    2. Free-ride on any cooperation that emerges (payoff > 1)
    3. Maintain baseline payoff when others defect (payoff = 1)

    The strategy defects every round regardless of opponent behavior,
    as defection is the dominant strategy in finite public goods games
    where k < n.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if history is not None and state.round_number > 0:
            last_round_cooperators = sum(history.opponent_actions[state.round_number - 1, :])
            coop_rate = last_round_cooperators / self.n_players
        return Action.D

class Strategy_EXPLOITATIVE_451(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Harvesting

    Exploits asymmetry in payoff structure by defecting in round 1 (information gathering),
    selectively cooperating in middle rounds only when expected cooperators exceed threshold n/k,
    and unconditionally defecting in the final round to harvest remaining cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.cooperation_threshold = self.n_players / self.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        expected_cooperators = 0.0
        opponent_has_defected = [False] * (self.n_players - 1)
        for opponent_idx in range(self.n_players - 1):
            cooperations = np.sum(history.opponent_actions[:current_round, opponent_idx])
            rounds_observed = current_round
            if np.any(~history.opponent_actions[:current_round, opponent_idx]):
                opponent_has_defected[opponent_idx] = True
                cooperation_rate = 0.0
            else:
                cooperation_rate = cooperations / rounds_observed
            expected_cooperators += cooperation_rate
        late_game_threshold = 0.75 * self.n_rounds
        any_defection_observed = any(opponent_has_defected)
        if expected_cooperators > self.cooperation_threshold and (not any_defection_observed) and (current_round < late_game_threshold):
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_452(BaseStrategy):
    """
    Exploitative Strategy for N-Player Public Goods Game.

    This strategy implements pure defection as a dominant strategy, exploiting
    cooperative players by free-riding on their contributions while avoiding
    the costs of cooperation. Defection is maintained across all rounds,
    including the first and last rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        if history is not None and state.round_number > 0:
            total_cooperators = np.sum(history.opponent_actions[:state.round_number, :])
            total_observations = state.round_number * self.game_description.n_players
            avg_cooperation_rate = total_cooperators / total_observations
            exploitation_threshold = self.game_description.k / (self.game_description.n_players + self.game_description.k)
            if avg_cooperation_rate > exploitation_threshold:
                return Action.D
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_453(BaseStrategy):
    """
    Adaptive Parasitism: An exploitative strategy that systematically defects to extract value
    from cooperative players while minimizing losses against defectors.

    Core approach:
    - Always defect in round 1 (establish aggressive baseline)
    - Always defect in final round (terminal exploitation)
    - In middle rounds: defect if recent cooperation rate >= 0.4 (exploit), else defect (safe)
    - Result: Defect-dominant strategy optimized for extracting value from cooperators
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = np.sum(history.opponent_actions[current_round - 1, :])
        coop_rate = cooperators_last_round / self.n_players
        exploitation_threshold = 0.4
        if coop_rate >= exploitation_threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_454(BaseStrategy):
    """
    Exploitative Strategy: "Adaptive Defection with Conditional Parasitism"

    Core philosophy: Always defect to maximize payoff by free-riding on others'
    contributions. Defection is the dominant strategy when k < n, so this strategy
    consistently exploits that mathematical reality across all rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_455(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism: A ruthlessly exploitative strategy
    that free-rides on cooperators' contributions while never investing in the public good.

    Core behavior:
    - Round 1: DEFECT (baseline, no history to condition on)
    - Rounds 2 to r-1: DEFECT (exploit any cooperation observed, or defect if none exists)
    - Final round: DEFECT (no future rounds to influence, extract maximum payoff)

    The strategy unconditionally defects throughout, maximizing relative payoff against
    any opponent set that includes cooperators or cooperation-prone strategies.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.n_rounds - 1:
            return Action.D
        total_cooperators = np.sum(history.my_actions) + np.sum(history.opponent_actions)
        total_actions = self.n_players * state.round_number
        coop_rate = total_cooperators / total_actions if total_actions > 0 else 0.0
        threshold = (self.n_players - self.k) / self.n_players
        return Action.D

class Strategy_EXPLOITATIVE_456(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core approach: Always defect by default. Only consider the strategy profitable
    if average cooperation rate across all players meets or exceeds k/n threshold.
    When threshold is met, enter "Freeloading Mode" and continue defecting to
    harvest contributions from cooperators. Never voluntarily cooperate.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.cooperation_threshold = self.k / self.n_players
        self.in_freeloading_mode = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        total_rounds_played = round_number
        total_cooperators = np.sum(history.opponent_actions[:round_number, :])
        total_possible_cooperations = self.n_players * total_rounds_played
        avg_coop_rate = total_cooperators / total_possible_cooperations
        if avg_coop_rate >= self.cooperation_threshold:
            self.in_freeloading_mode = True
        return Action.D

class Strategy_EXPLOITATIVE_457(BaseStrategy):
    """
    Adaptive Predation: An exploitative strategy that defects to parasitize cooperation.

    Core mechanics:
    - Round 1: DEFECT (gather baseline information)
    - Final round: DEFECT (no reputation consequences)
    - Middle rounds: Adapt based on observed cooperation rate
      - High cooperation (>60%): DEFECT to exploit
      - Low cooperation (<20%): DEFECT (no value in public good)
      - Medium cooperation: DEFECT unless underperforming and high cooperation (rare signal)
    - Occasional false cooperation (20% chance) only when cooperation >75% and own payoff trails average
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_high = 0.6
        self.threshold_low = 0.2
        self.cooperation_threshold_signal = 0.75
        self.exploit_threshold = 0.7
        self.cooperation_signal_probability = 0.2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        rounds_played = state.round_number
        total_opponent_actions = history.opponent_actions[:rounds_played, :]
        observed_cooperators = np.sum(total_opponent_actions)
        total_actors = self.game_description.n_players * rounds_played
        coop_rate = observed_cooperators / total_actors if total_actors > 0 else 0.0
        if coop_rate > self.threshold_high:
            return Action.D
        elif coop_rate < self.threshold_low:
            return Action.D
        else:
            recent_payoffs = history.my_payoffs[max(0, rounds_played - 3):rounds_played]
            my_recent_avg = np.mean(recent_payoffs) if len(recent_payoffs) > 0 else 0.0
            max_exploit_payoff = 1.0 + self.game_description.k
            if my_recent_avg < self.exploit_threshold * max_exploit_payoff:
                return Action.D
            else:
                if coop_rate > self.cooperation_threshold_signal:
                    opponent_payoffs = history.opponent_payoffs[max(0, rounds_played - 3):rounds_played, :]
                    opponent_avg = np.mean(opponent_payoffs) if opponent_payoffs.size > 0 else 0.0
                    if my_recent_avg < opponent_avg:
                        if random.random() < self.cooperation_signal_probability:
                            return Action.C
                return Action.D

class Strategy_EXPLOITATIVE_458(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Core principle: Always defect because k/n < 1 makes cooperation strictly dominated.
    - Never cooperate: The marginal benefit (k/n) is always less than the marginal cost (1)
    - Parasite cooperative players: Receive their contributions while defecting
    - Robust to all opponent strategies: Defection is a Nash equilibrium
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        return Action.D

class Strategy_EXPLOITATIVE_459(BaseStrategy):
    """
    Adaptive Predation Strategy: Exploits cooperative players while avoiding mutual defection.

    Core approach:
    - Always defect as dominant strategy
    - Track cooperation rates to identify exploitation opportunities
    - Use rare cooperative probes late-game to identify conditional cooperators
    - End-game defection to avoid punishment windows
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold_high = self.k / self.n + 0.1
        self.threshold_low = 0.15
        self.probe_probability = 0.05

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        previous_round_idx = current_round - 1
        cooperators_last_round = int(sum(history.opponent_actions[previous_round_idx, :]))
        cooperation_rate = cooperators_last_round / self.n
        if current_round < self.r * 0.3:
            if cooperation_rate >= self.threshold_high:
                return Action.D
            return Action.D
        if current_round >= self.r * 0.6:
            if current_round >= self.r - 2:
                return Action.D
            if cooperation_rate > 0.4 and random.random() < self.probe_probability:
                return Action.C
            return Action.D
        if cooperation_rate >= self.threshold_high:
            return Action.D
        if cooperation_rate < self.threshold_low:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_460(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Opportunistic Exploitation

    This strategy implements a pure exploitation approach to the public goods game.
    Core principle: Always defect to maximize individual payoff by exploiting
    cooperators' contributions while avoiding the cost of cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        prev_opponent_actions = history.opponent_actions[current_round - 1, :]
        prev_cooperators = int(np.sum(prev_opponent_actions))
        prev_coop_rate = prev_cooperators / n
        self.cooperation_history.append(prev_coop_rate)
        threshold_high = k / n
        threshold_low = k / n - 0.1
        if prev_coop_rate >= threshold_high:
            action = Action.D
        elif prev_coop_rate < threshold_low:
            action = Action.D
        elif current_round >= 2:
            recent_avg = np.mean(self.cooperation_history[-2:])
            if recent_avg >= 0.4:
                action = Action.D
            else:
                action = Action.D
        else:
            action = Action.D
        if current_round == r - 1:
            expected_cooperators = prev_coop_rate * n
            v_defect = 1.0 + k / n * expected_cooperators
            v_coop = 0.0 + k / n * expected_cooperators
            if v_defect - v_coop > 0.5:
                action = Action.D
            elif current_round >= 3:
                recent_window = self.cooperation_history[-4:]
                if len(recent_window) >= 3 and np.mean(recent_window) >= 0.6:
                    action = Action.D
                else:
                    action = Action.D
            else:
                action = Action.D
        if r == 2:
            action = Action.D
        return action

class Strategy_EXPLOITATIVE_461(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core philosophy: Extract maximum value from the public good while minimizing
    contributions. Defect by default, cooperate strategically only when it serves
    to exploit others' cooperation or test initial conditions.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == self.n_rounds - 1:
            return Action.D
        if round_number == 0:
            p_coop = max(0.0, (self.k - 1.0) / (self.n_players - 1.0))
            if random.random() < p_coop:
                return Action.C
            else:
                return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[round_number - 1, :]))
        if cooperators_last_round >= self.n_players - 2:
            return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_462(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core philosophy: Maximize personal payoff by exploiting cooperators while avoiding
    mutual defection traps. Always defect to extract maximum value from any cooperators
    in the population.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        cooperators_last_round = np.sum(history.opponent_actions[round_num - 1, :])
        cooperation_rate = cooperators_last_round / self.n
        threshold = self.k / self.n
        return Action.D

class Strategy_EXPLOITATIVE_463(BaseStrategy):
    """
    Exploitative strategy using adaptive defection with conditional cooperation.
    Exploits the payoff asymmetry in public goods games by defecting when beneficial,
    cooperating conditionally only when it maximizes long-term relative advantage.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0 or current_round == self.r - 1:
            return Action.D
        breakeven_threshold = self.k / self.n
        exploitation_threshold = 1.0 - 1.0 / self.k
        if self.n <= 3:
            exploitation_threshold = 1.0 - 0.5 / self.k
        prev_cooperators = int(sum(history.opponent_actions[current_round - 1, :]))
        coop_rate = prev_cooperators / self.n
        if current_round >= 1:
            all_prev_cooperators = sum((sum(history.opponent_actions[t, :]) for t in range(current_round)))
            avg_cooperation = all_prev_cooperators / (current_round * self.n)
        else:
            avg_cooperation = 0.0
        rounds_remaining = self.r - current_round
        if avg_cooperation >= 0.5 and rounds_remaining >= 3:
            return Action.D
        if avg_cooperation < 0.3:
            return Action.D
        if coop_rate > 1.0 or coop_rate < 0.0:
            return Action.D
        if self.k >= self.n:
            return Action.D
        if self.r <= 3:
            if coop_rate >= exploitation_threshold:
                return Action.D
            else:
                return Action.D
        if coop_rate >= exploitation_threshold:
            return Action.D
        if coop_rate < breakeven_threshold:
            return Action.D
        if coop_rate >= breakeven_threshold and coop_rate < exploitation_threshold:
            if rounds_remaining >= 2:
                conditional_range = exploitation_threshold - breakeven_threshold
                if conditional_range > 0:
                    conditional_prob = (coop_rate - breakeven_threshold) / conditional_range
                else:
                    conditional_prob = 0.0
                decay_factor = 1.0 / math.sqrt(max(1, rounds_remaining))
                conditional_prob *= decay_factor
                if random.random() < conditional_prob:
                    return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_464(BaseStrategy):
    """
    Exploitative Strategy: Conditional Free-Rider with Adaptive Defection

    Core principle: Defection is the strictly dominant strategy in public goods games
    when 1 < k < n. This strategy always defects to maximize individual payoff by
    exploiting any cooperation while avoiding the cost of contributing to the public good.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        return Action.D

class Strategy_EXPLOITATIVE_465(BaseStrategy):
    """
    Adaptive Defection with Conditional Parasitism: Pure defection strategy that exploits
    the asymmetry in the public goods game by always defecting, regardless of opponent behavior.
    This maximizes payoff by free-riding on cooperators' contributions while avoiding the cost
    of cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_threshold = (game_description.n_players - 1) / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        previous_round_idx = state.round_number - 1
        cooperators_previous = sum(history.opponent_actions[previous_round_idx, :])
        coop_rate = cooperators_previous / self.game_description.n_players
        return Action.D

class Strategy_EXPLOITATIVE_466(BaseStrategy):
    """
    Adaptive Parasitism: An exploitative strategy that cooperates selectively
    to harvest payoffs from cooperators, while defecting in the first and last
    rounds, and adapting based on recent cooperation rates in middle rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        m = min(3, round_num)
        recent_rounds_start = max(0, round_num - m)
        recent_actions = history.opponent_actions[recent_rounds_start:round_num, :]
        cooperation_count = np.sum(recent_actions)
        recent_coop_rate = cooperation_count / (m * self.n)
        exploitation_threshold = self.k / self.n * 0.5
        if recent_coop_rate > exploitation_threshold:
            expected_cooperators = recent_coop_rate * self.n
            payoff_if_cooperate = 0 + self.k / self.n * expected_cooperators
            payoff_if_defect = 1 + self.k / self.n * expected_cooperators
            if payoff_if_cooperate >= payoff_if_defect * 0.95:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_467(BaseStrategy):
    """
    PARASITE Strategy: Adaptive Defection with Selective Parasitism

    Exploits the public goods game by defecting strategically to free-ride on cooperators.
    Core principle: Defection dominates cooperation when k < n (guaranteed by specification).
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = 0.4

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        previous_round_idx = current_round - 1
        cooperators_last_round = np.sum(history.opponent_actions[previous_round_idx, :])
        cooperation_rate = cooperators_last_round / n
        if cooperation_rate >= self.threshold:
            return Action.D
        elif cooperation_rate > 0:
            return Action.D
        else:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_468(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Exploitation

    Exploits asymmetry between defection and cooperation payoffs by defaulting to defection
    while opportunistically cooperating only when it maximizes personal advantage through
    parasitism on others' contributions.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.cooperation_threshold = self.k / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        if round_number == self.n_rounds - 2:
            if random.random() < 0.1:
                opponent_cooperation_rate = self._calculate_cooperation_rate(history)
                if opponent_cooperation_rate > 0.7 and self.k >= 0.9 * self.n_players:
                    return Action.C
            return Action.D
        opponent_cooperation_rate = self._calculate_cooperation_rate(history)
        if opponent_cooperation_rate >= 1.5 * self.cooperation_threshold:
            if random.random() < 0.05:
                return Action.C
            return Action.D
        if opponent_cooperation_rate > self.cooperation_threshold:
            cooperation_probability = self.cooperation_threshold / 2.0
            if random.random() < cooperation_probability:
                return Action.C
            return Action.D
        return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        """
        Calculate the cooperation rate of opponents across all previous rounds.
        """
        if history is None or history.opponent_actions.shape[0] == 0:
            return 0.0
        total_cooperations = float(np.sum(history.opponent_actions))
        total_opponent_moves = float(history.opponent_actions.shape[0] * history.opponent_actions.shape[1])
        if total_opponent_moves == 0:
            return 0.0
        return total_cooperations / total_opponent_moves

class Strategy_EXPLOITATIVE_469(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Predatory Harvesting

    Treats cooperation as a resource to exploit. Defects in first and last rounds,
    and adapts mid-game based on observed cooperation rates:
    - High cooperation (50%): Always defect to maximize free-riding
    - Medium cooperation (20-50%): Defect 85%, cooperate 15% for strategic ambiguity
    - Low cooperation (<20%): Always defect as insufficient pool to exploit
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_high = 0.5
        self.threshold_low = 0.2
        self.medium_cooperation_prob = 0.15

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        cooperation_rate = last_round_cooperators / self.game_description.n_players
        if cooperation_rate >= self.threshold_high:
            return Action.D
        elif cooperation_rate >= self.threshold_low:
            if random.random() < self.medium_cooperation_prob:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_470(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Contribution

    Exploits asymmetry between private retention and public contribution by defaulting
    to defection and only cooperating when estimated cooperators exceed the threshold
    needed to match defection payoff.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold = math.ceil(self.n / self.k)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        window_size = max(2, self.r // 3)
        start_idx = max(0, current_round - window_size)
        total_opponent_cooperators = 0
        rounds_in_window = current_round - start_idx
        for round_idx in range(start_idx, current_round):
            round_cooperators = np.sum(history.opponent_actions[round_idx, :])
            total_opponent_cooperators += round_cooperators
        total_possible_opponent_actions = (self.n - 1) * rounds_in_window
        if total_possible_opponent_actions > 0:
            estimated_opponent_cooperation_rate = total_opponent_cooperators / total_possible_opponent_actions
        else:
            estimated_opponent_cooperation_rate = 0.0
        predicted_opponent_cooperators = round(estimated_opponent_cooperation_rate * (self.n - 1))
        if predicted_opponent_cooperators >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_471(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism: An exploitative strategy that
    consistently defects to free-ride on cooperators' contributions while avoiding
    losses from mutual defection. Tracks opponent cooperation rates but maintains
    a default defection stance across all rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.opponent_coop_counts = np.zeros(game_description.n_players - 1)
        self.round_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        if history is not None and state.round_number > 0:
            prev_round_idx = state.round_number - 1
            for opponent_idx in range(self.game_description.n_players - 1):
                if history.opponent_actions[prev_round_idx, opponent_idx]:
                    self.opponent_coop_counts[opponent_idx] += 1
        if history is not None and state.round_number > 0:
            prev_round_idx = state.round_number - 1
            total_cooperators_last_round = int(np.sum(history.opponent_actions[prev_round_idx, :]))
        else:
            total_cooperators_last_round = 0
        threshold = max(1, math.ceil(self.game_description.k))
        return Action.D

class Strategy_EXPLOITATIVE_472(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Calculated Cooperation

    This strategy ruthlessly exploits cooperators by consistently defecting.
    It recognizes that defection is the dominant strategy in every round of the
    public goods game and maximizes payoff by parasitizing any cooperation while
    maintaining baseline payoff against other defectors.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        cooperators_last_round = sum(history.opponent_actions[-1, :])
        my_payoff_if_defected = 1 + self.game_description.k / self.game_description.n_players * cooperators_last_round
        cooperative_payoff = self.game_description.k / self.game_description.n_players * cooperators_last_round
        if cooperators_last_round > 0 and my_payoff_if_defected > cooperative_payoff:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_473(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Free-Riding

    Maximizes personal payoff by systematically free-riding on cooperation while
    maintaining just enough cooperative signaling to prevent complete defection.
    Uses threshold-based decisions and end-game exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.break_even = math.ceil(self.n * (self.n - self.k) / self.k)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        if t == 0:
            return Action.D
        if t == self.r - 1:
            return Action.D
        observed_cooperators_per_round = np.sum(history.opponent_actions, axis=1)
        avg_cooperation = float(np.mean(observed_cooperators_per_round))
        my_cumulative_payoff = float(np.sum(history.my_payoffs))
        opponent_cumulative_payoffs = np.sum(history.opponent_payoffs, axis=1)
        avg_opponent_payoff = float(np.mean(opponent_cumulative_payoffs))
        if avg_cooperation >= self.break_even:
            return Action.D
        if t > 2 * self.r / 3 and avg_cooperation > self.k / self.n:
            return Action.D
        if my_cumulative_payoff < avg_opponent_payoff * 0.85:
            return Action.C
        if avg_cooperation < self.k / self.n:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_474(BaseStrategy):
    """
    Unconditional Defector: Always defect strategy for N-Player Public Goods Game.

    This strategy exploits the fundamental asymmetry in the payoff structure where
    defection always yields higher immediate returns than cooperation. By always
    defecting, this strategy:
    - Extracts maximum value from cooperative players
    - Matches defection of other defectors
    - Avoids losses from unilateral cooperation
    - Achieves the Nash Equilibrium outcome
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        return Action.D

class Strategy_EXPLOITATIVE_475(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Calculated Cooperation

    This strategy exploits the public goods game by:
    1. Probing with low-probability cooperation in round 1
    2. Tracking observed cooperation rates
    3. Defecting when cooperation is detected (to exploit)
    4. Always defecting in endgame rounds
    5. Using adaptive thresholds that become more aggressive early on
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == self.n_rounds - 1:
            return Action.D
        if round_number == self.n_rounds - 2:
            if history is not None:
                coop_rate = self._calculate_cooperation_rate(history, round_number)
                if coop_rate > 0.6:
                    return Action.D
        if round_number == 0:
            if random.random() < 0.4:
                return Action.C
            else:
                return Action.D
        if round_number == 1:
            return Action.D
        coop_rate = self._calculate_cooperation_rate(history, round_number)
        decay_factor = min(round_number, 3)
        threshold_t = 0.5 - 0.1 * decay_factor
        if coop_rate >= threshold_t:
            return Action.D
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_number: int) -> float:
        """
        Calculate the observed cooperation rate from all previous rounds.

        coop_rate = (total_cooperators_observed) / (n  rounds_played_so_far)
        """
        if round_number == 0:
            return 0.0
        total_cooperators = 0
        rounds_played = round_number
        for round_idx in range(round_number):
            round_cooperators = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += round_cooperators
        coop_rate = total_cooperators / (self.n_players * rounds_played)
        return coop_rate

class Strategy_EXPLOITATIVE_476(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Calculated Cooperation Phases

    A ruthlessly adaptive strategy that exploits the asymmetry in public goods games by:
    1. Defecting in early phases to identify cooperators
    2. Adapting exploitation based on observed cooperation rates
    3. Strategically defecting when others cooperate to capture asymmetric gains
    4. Unconditionally defecting in the final round
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.phase1_end = max(1, math.floor(self.n_rounds / 3))
        self.phase2_end = max(self.phase1_end + 1, 2 * math.floor(self.n_rounds / 2))
        self.phase3_end = self.n_rounds - 1
        self.reliable_cooperator_threshold = 0.7
        self.cooperation_rate_threshold = (self.k - 1) / self.n_players

    def _get_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate observed cooperation rate across all opponents and rounds."""
        if history.opponent_actions.size == 0:
            return 0.0
        total_cooperations = np.sum(history.opponent_actions)
        total_observations = history.opponent_actions.size
        return total_cooperations / total_observations if total_observations > 0 else 0.0

    def _get_opponent_cooperation_frequencies(self, history: PlayerHistory) -> NDArray[np.float64]:
        """Calculate each opponent's individual cooperation frequency."""
        n_rounds_observed = history.opponent_actions.shape[0]
        if n_rounds_observed == 0:
            return np.zeros(self.n_players - 1)
        cooperation_counts = np.sum(history.opponent_actions, axis=0)
        frequencies = cooperation_counts / n_rounds_observed
        return frequencies

    def _identify_reliable_cooperators(self, history: PlayerHistory) -> int:
        """Count how many opponents are reliable cooperators."""
        frequencies = self._get_opponent_cooperation_frequencies(history)
        reliable_count = np.sum(frequencies >= self.reliable_cooperator_threshold)
        return int(reliable_count)

    def _get_current_round_cooperators(self, history: PlayerHistory) -> int:
        """Count cooperators in the most recent round."""
        if history.opponent_actions.shape[0] == 0:
            return 0
        return int(np.sum(history.opponent_actions[-1, :]))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == self.n_rounds - 1:
            return Action.D
        if current_round < self.phase1_end:
            return Action.D
        if current_round < self.phase2_end:
            cooperation_rate = self._get_cooperation_rate(history)
            if cooperation_rate < self.cooperation_rate_threshold:
                return Action.D
            reliable_cooperators = self._identify_reliable_cooperators(history)
            current_round_cooperators = self._get_current_round_cooperators(history)
            if reliable_cooperators > 0 and current_round_cooperators > 2:
                return Action.D
            else:
                return Action.D
        if current_round < self.phase3_end:
            remaining_rounds = self.n_rounds - current_round
            reliable_cooperators = self._identify_reliable_cooperators(history)
            frequencies = self._get_opponent_cooperation_frequencies(history)
            projected_cooperators = int(np.sum(frequencies >= 0.5))
            expected_gain = self.k / self.n_players * projected_cooperators - 1.0
            if expected_gain > 0.1 and remaining_rounds >= 2 and (reliable_cooperators >= 2):
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_477(BaseStrategy):
    """
    Adaptive Parasitism: An exploitative strategy that defects to parasitize cooperators
    while avoiding punishment through adaptive monitoring of population cooperation rates.

    Core mechanics:
    - Round 1: DEFECT (establish predatory positioning, gather info)
    - Final round: DEFECT (no future punishment possible, extract parasitic payoff)
    - Middle rounds: DEFECT if cooperation_rate > threshold, else DEFECT
      (essentially always defect, but adaptively monitor to preempt punishment)

    The strategy exploits the asymmetry where defectors earn 1 + (k/n)*cooperators
    while cooperators earn (k/n)*cooperators. As long as cooperation exists,
    defection dominates.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        epsilon = 0.05
        self.threshold_T = (1.0 - epsilon) / self.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        weighted_cooperation_sum = 0.0
        total_weight = 0.0
        for past_round in range(current_round):
            cooperators_in_round = np.sum(history.opponent_actions[past_round, :])
            weight = 2.0 ** (past_round - (current_round - 1))
            cooperation_in_round = cooperators_in_round / self.n
            weighted_cooperation_sum += weight * cooperation_in_round
            total_weight += weight
        cooperation_rate = weighted_cooperation_sum / total_weight if total_weight > 0 else 0.0
        if cooperation_rate > self.threshold_T:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_478(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Exploits the public goods game structure by defecting by default and only cooperating
    when historical cooperation rates exceed the threshold (1/k), enabling profitable free-riding.
    Always defects in round 1 and final round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = 1.0 / game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        if history is not None:
            total_cooperators = np.sum(history.opponent_actions)
            rounds_completed = current_round
            total_player_rounds = rounds_completed * n
            observed_coop_rate = total_cooperators / total_player_rounds
            if observed_coop_rate > self.threshold:
                return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_479(BaseStrategy):
    """
    Exploitative Free-Rider Strategy with Adaptive Conditional Engagement.

    Core approach: Always defect to maximize personal payoff by exploiting cooperators.
    Adapts based on observed cooperation rates, but maintains pure defection as dominant strategy.
    Handles first/last round asymmetries and cooperation momentum tracking.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n_players
        self.prev_cooperation_rate = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            self.prev_cooperation_rate = 0.0
            return Action.D
        if round_num == self.n_rounds - 1:
            return Action.D
        if self.k <= 1.0:
            return Action.D
        if self.k >= self.n_players - 0.1:
            return Action.D
        if self.n_players == 2:
            return Action.D
        cooperators_last_round = np.sum(history.opponent_actions[-1, :])
        cooperation_rate = cooperators_last_round / self.n_players
        if len(history.opponent_actions) > 1:
            cooperators_prev_round = np.sum(history.opponent_actions[-2, :])
            prev_cooperation_rate = cooperators_prev_round / self.n_players
            cooperation_momentum = cooperation_rate - prev_cooperation_rate
        else:
            cooperation_momentum = 0.0
            prev_cooperation_rate = 0.0
        if cooperation_rate >= self.threshold:
            rounds_remaining = self.n_rounds - round_num - 1
            if cooperation_momentum < -0.2:
                return Action.D
            if rounds_remaining >= 3:
                return Action.D
            return Action.D
        else:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_480(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Core principle: Always defect to maximize payoff by exploiting cooperators while
    avoiding the sucker's payoff against defectors. Uses a cooperation rate threshold
    (0.40) to monitor opponent behavior, but ultimately always defects across all rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_threshold = 0.4

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        if history is not None and state.round_number > 0:
            total_cooperations = np.sum(history.opponent_actions[:state.round_number, :])
            total_possible = (self.game_description.n_players - 1) * state.round_number
            if total_possible > 0:
                cooperation_rate = total_cooperations / total_possible
            else:
                cooperation_rate = 0.0
            if cooperation_rate >= self.cooperation_threshold:
                return Action.D
            else:
                return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_481(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Core approach: Always defect, but monitor cooperation rates to confirm we're
    successfully parasitizing the public good. Defect in round 1 (baseline exploitation),
    defect in middle rounds if cooperation rate exceeds threshold, and defect in final
    round (no future reputation effects). Never cooperate; never be the sucker.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.k - 1) / self.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperation_rates = []
        for round_idx in range(current_round):
            cooperators_in_round = np.sum(history.opponent_actions[round_idx, :])
            cooperation_rate = cooperators_in_round / self.n_players
            cooperation_rates.append(cooperation_rate)
        avg_cooperation = np.mean(cooperation_rates)
        if avg_cooperation > self.threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_482(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism strategy for N-Player Public Goods Game.

    Core approach:
    - Round 1: DEFECT (establish baseline, no history to exploit)
    - Rounds 2 to r-1: COOPERATE if cooperation index >= k/n, else DEFECT
    - Final round: DEFECT (no future punishment possible)

    This exploits the asymmetry in public goods games by defecting when environments
    are poor, cooperating selectively when rich, and always defecting at boundaries.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        previous_round_index = state.round_number - 1
        cooperators_previous = sum(history.opponent_actions[previous_round_index, :])
        cooperation_index = cooperators_previous / self.game_description.n_players
        if cooperation_index >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_483(BaseStrategy):
    """
    Adaptive Predation Strategy: Exploits the public goods game by consistently
    defecting to parasitize cooperators while maintaining competitive returns
    against defectors. Uses adaptive thresholds to monitor cooperation ecology
    but always defaults to defection as the dominant strategy.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        previous_round_idx = state.round_number - 1
        cooperators_previous = sum(history.opponent_actions[previous_round_idx, :])
        cooperation_rate = cooperators_previous / self.n
        threshold_high = 0.5 + self.k / (2 * self.n)
        threshold_low = self.k / (2 * self.n)
        return Action.D

class Strategy_EXPLOITATIVE_484(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Core philosophy: Exploit the fundamental asymmetry in payoff structure by
    free-riding on others' cooperation while minimizing exposure to mutual defection.
    Always defect to maximize personal payoff through parasitism.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == r - 1:
            return Action.D
        prev_round_idx = current_round - 1
        cooperators_last_round = sum(history.opponent_actions[prev_round_idx, :])
        coop_rate = cooperators_last_round / n
        threshold = 1.0 / k
        if coop_rate > threshold:
            return Action.D
        elif coop_rate == 0:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_485(BaseStrategy):
    """
    Adaptive Defection with Conditional Reciprocity (ADCR):
    Exploitative strategy that defects in rounds 1 and r, and conditionally
    reciprocates in middle rounds based on exploitation surplus and cooperation rates.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.theta_high = 0.6
        self.theta_low = 0.3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.r - 1:
            return Action.D
        prev_round_idx = round_number - 1
        opponent_coop_count = np.sum(history.opponent_actions[prev_round_idx, :])
        total_coop_count = opponent_coop_count + (1 if history.my_actions[prev_round_idx] else 0)
        coop_rate = opponent_coop_count / (self.n - 1) if self.n > 1 else 0.0
        surplus = 1.0 - self.k / self.n * opponent_coop_count
        if surplus > 0.01:
            return Action.D
        elif coop_rate > self.theta_high:
            expected_benefit = self.k / self.n * (opponent_coop_count + 1)
            if expected_benefit >= 0:
                return Action.C
            else:
                return Action.D
        elif coop_rate > self.theta_low:
            predicted_coop = coop_rate * (self.n - 1)
            public_payoff = self.k / self.n * predicted_coop
            private_payoff = 1.0 - public_payoff
            if public_payoff > private_payoff:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_486(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core approach: Always defect to exploit cooperators' contributions to the public good.
    The strategy recognizes that defection yields strictly higher payoffs than cooperation
    in the public goods game (where k < n), and maintains this advantage by parasitizing
    the public pool created by any cooperators while avoiding the cost of contribution.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.k = game_description.k
        self.n_rounds = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_487(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Exploitation

    This strategy exploits the fundamental asymmetry in the Public Goods Game by:
    1. Defecting in round 1 to probe for cooperators
    2. Adaptively defecting based on observed cooperation rates vs. a calculated threshold
    3. Intensifying defection in the final 5 rounds
    4. Pure defection in the terminal round

    The strategy uses stochastic defection at low cooperation to hedge against all-defector
    punishment and avoid predictability.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.n_rounds - 1:
            return Action.D
        if round_number >= self.n_rounds - 5:
            rand_val = random.random()
            if rand_val < 0.95:
                return Action.D
            else:
                return Action.C
        cooperators_last_round = int(np.sum(history.opponent_actions[-1, :]))
        cooperation_rate = cooperators_last_round / self.n_players - 1 / self.n_players
        threshold = 1 / self.k - 1 / self.n_players
        net_benefit_of_defection = cooperation_rate * (self.k / self.n_players - 1)
        if cooperation_rate > threshold:
            return Action.D
        else:
            rand_val = random.random()
            if rand_val < 0.85:
                return Action.D
            else:
                return Action.C

class Strategy_EXPLOITATIVE_488(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Exploitation

    This strategy always defects, with mathematical justification through:
    - Dominance in the final round (backwards induction)
    - Superiority when cooperation exists (free-riding on public goods)
    - Equivalence when cooperation doesn't exist
    - A threshold-based rule proving defection is individually rational across all game states

    Core insight: Defection yields higher immediate returns than cooperation in all scenarios,
    while the threshold rule (k-1)/(n-1) identifies when a cooperative pool exists to exploit.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.k - 1) / (self.n_players - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number >= self.n_rounds - 2:
            return Action.D
        cooperators_last_round = int(sum(history.opponent_actions[round_number - 1, :]))
        cooperation_rate = cooperators_last_round / self.n_players
        if cooperation_rate > self.threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_489(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism: Exploitative strategy that maximizes
    personal payoff by free-riding on cooperators' contributions. Always defects in round 1
    and final round. In middle rounds, uses an adaptive threshold based on observed
    cooperation rate to decide between defection and defection (always defects due to
    dominant strategy equilibrium).
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperators_observed = int(np.sum(history.opponent_actions[:current_round, :]))
        total_actions_observed = current_round * self.n_players
        cooperation_rate = cooperators_observed / total_actions_observed if total_actions_observed > 0 else 0.0
        threshold = self.k / self.n_players + (1.0 - self.k / self.n_players) * ((self.n_rounds - current_round) / self.n_rounds)
        return Action.D

class Strategy_EXPLOITATIVE_490(BaseStrategy):
    """
    Exploitative strategy: Adaptive defection with conditional parasitism.

    Core philosophy: Maximize personal payoff by exploiting cooperative opponents
    while minimizing losses from defectors. The strategy always defects, treating
    cooperation as a resource to exploit rather than a norm to reciprocate.

    Decision logic:
    - Round 0 (first round): DEFECT (no history, defection guarantees payoff of 1)
    - Round r-1 (final round): DEFECT (no future consequences)
    - Middle rounds: DEFECT (either parasitizing cooperators or matching defection equilibrium)

    The adaptive threshold mechanism naturally filters for parasitism opportunities
    based on observed cooperation rates, but ultimately recommends defection in all cases.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = 1.0 / self.k * (self.n_players - 1) / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        previous_round_idx = current_round - 1
        cooperators_last_round = np.sum(history.opponent_actions[previous_round_idx, :])
        cooperation_rate = cooperators_last_round / self.n_players
        return Action.D

class Strategy_EXPLOITATIVE_491(BaseStrategy):
    """
    Adaptive Predation: An exploitative strategy that maximizes payoff by
    defecting to parasitize cooperators while avoiding losses to defectors.

    Core logic: Always defect except when strategically uncertain, using an
    adaptive threshold that declines over time to become increasingly aggressive.
    In practice, this results in consistent defection across all rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        if state.round_number == 0:
            return Action.D
        if state.round_number == r - 1:
            return Action.D
        previous_round_idx = state.round_number - 1
        cooperators_prev_round = int(sum(history.opponent_actions[previous_round_idx, :]))
        coop_rate = cooperators_prev_round / n
        threshold_t = 0.5 - 0.1 * (state.round_number / r)
        if coop_rate > threshold_t:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_492(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core approach: Defect persistently to exploit the asymmetry in public goods games.
    - Round 1: Defect to gather information
    - Rounds 2 to r-2: Conditional defection based on cooperation threshold
    - Final rounds: Continue defection to maximize exploitation
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = 1.0 / game_description.k + 0.05

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round >= r - 2:
            return Action.D
        total_rounds_played = current_round
        total_opponent_actions = history.opponent_actions[:current_round, :]
        total_cooperators = np.sum(total_opponent_actions)
        total_action_slots = total_rounds_played * (n - 1)
        observed_coop_rate = total_cooperators / total_action_slots if total_action_slots > 0 else 0.0
        if observed_coop_rate > self.threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_493(BaseStrategy):
    """
    Adaptive Predation Strategy for N-Player Public Goods Game.

    Exploits cooperative tendencies through:
    1. Initial defection to gather information
    2. Adaptive threshold-based decisions in middle rounds
    3. Terminal defection in the final round
    4. Opportunistic baiting when cooperation is rare
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        total_cooperators = np.sum(history.opponent_actions[:current_round, :])
        total_actions = current_round * self.n
        cooperation_rate = total_cooperators / total_actions if total_actions > 0 else 0.0
        denominator = 1.0 - (self.k - 1.0) / self.n
        threshold = self.k / self.n / denominator if denominator != 0 else float('inf')
        if cooperation_rate > threshold:
            return Action.D
        elif cooperation_rate == 0:
            return Action.D
        else:
            last_round_cooperators = np.sum(history.opponent_actions[current_round - 1, :])
            if last_round_cooperators > 0:
                return Action.C
            else:
                return Action.D

class Strategy_EXPLOITATIVE_494(BaseStrategy):
    """
    Predatory Opportunism: Exploitative strategy that defects by default, exploiting
    cooperative players while adapting to pure defectors. Uses cooperation rate thresholds
    and rare signaling to maximize extraction of public goods value.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold = self.k / self.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        cooperators_last_round = sum(history.opponent_actions[current_round - 1, :])
        coop_rate = cooperators_last_round / self.n_players
        if 1 < current_round < self.n_rounds - 2:
            if current_round >= 3:
                recent_coop_rates = []
                for i in range(current_round - 3, current_round):
                    recent_coops = sum(history.opponent_actions[i, :])
                    recent_coop_rates.append(recent_coops / self.n_players)
                mean_rate = sum(recent_coop_rates) / len(recent_coop_rates)
                variance = sum(((rate - mean_rate) ** 2 for rate in recent_coop_rates)) / len(recent_coop_rates)
                if coop_rate > 0.8 and variance < 0.05:
                    return Action.C
        return Action.D

class Strategy_EXPLOITATIVE_495(BaseStrategy):
    """
    Adaptive Defection with Conditional Parasitism.

    Exploits the public goods game by:
    1. Defecting in round 1 (no history to exploit)
    2. Conditionally cooperating in rounds 2 to r-1 based on observed cooperation levels
    3. Always defecting in the final round (no future punishment possible)

    Cooperates when the proportion of cooperators exceeds threshold = (n - k) / n,
    ensuring the public goods share exceeds the private endowment cost.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold = (self.n - self.k) / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        if round_number == 0:
            return Action.D
        if round_number == self.r - 1:
            return Action.D
        previous_round_index = round_number - 1
        cooperators_previous_round = int(np.sum(history.opponent_actions[previous_round_index, :]))
        cooperation_proportion = cooperators_previous_round / self.n
        if cooperation_proportion >= self.threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_496(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    This strategy exploits the asymmetry in public goods games by always defecting,
    while adaptively tracking cooperation rates and individual opponent reliability
    to identify and extract value from cooperators.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.exploitation_threshold = (self.k - 1) / self.k
        self.reliability_threshold = 0.75

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        prev_round_idx = current_round - 1
        coop_count_prev = np.sum(history.opponent_actions[prev_round_idx, :])
        coop_rate = coop_count_prev / self.n_players
        reliable_cooperators_count = 0
        for opponent_idx in range(self.n_players - 1):
            opponent_coop_count = np.sum(history.opponent_actions[:current_round, opponent_idx])
            observed_rounds = current_round
            if observed_rounds > 0:
                reliability = opponent_coop_count / observed_rounds
                if reliability >= self.reliability_threshold:
                    reliable_cooperators_count += 1
        if coop_rate >= self.exploitation_threshold or reliable_cooperators_count >= 1:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_497(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Cooperation

    Core philosophy: Maximize individual payoff by exploiting cooperative tendencies
    in others while minimizing vulnerability to defection. The strategy defects
    unconditionally across all rounds, since defection is mathematically dominant
    given the constraint 1 < k < n.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold_t = (game_description.k - 1) / (game_description.k * game_description.n_players)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_498(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    This strategy exploits the Public Goods Game by defaulting to defection,
    selectively cooperating only when marginal returns exceed private costs,
    and adapting based on observed cooperation rates to maximize extraction.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.exploitation_threshold = (self.k - 1) / (self.n * 2)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        if current_round <= 4:
            return Action.D
        total_cooperations = np.sum(history.opponent_actions[:current_round, :])
        total_possible = self.n * current_round
        cooperation_rate = total_cooperations / total_possible if total_possible > 0 else 0.0
        if current_round >= self.r - 3:
            return Action.D
        if cooperation_rate > 0.85:
            if random.random() < 0.95:
                return Action.D
            else:
                return Action.C
        time_remaining = self.r - current_round
        if cooperation_rate > 0.6 and time_remaining > 3:
            return Action.D
        if cooperation_rate <= 0.3:
            return Action.D
        if cooperation_rate > self.exploitation_threshold:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_499(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core approach: Always defect to free-ride on others' contributions while avoiding
    contribution costs. Uses observed cooperation rates to identify when exploitation
    is most profitable, but defects regardless since defection is dominant.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = game_description.k / game_description.n_players

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number >= self.game_description.n_rounds - 2:
            return Action.D
        observed_cooperations = np.sum(history.opponent_actions[:state.round_number, :])
        opponent_possible_cooperations = (self.game_description.n_players - 1) * state.round_number
        if opponent_possible_cooperations == 0:
            observed_coop_rate = 0.0
        else:
            observed_coop_rate = observed_cooperations / opponent_possible_cooperations
        if observed_coop_rate > self.threshold:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_500(BaseStrategy):
    """
    Adaptive Parasitism with Opportunistic Defection.

    Exploits cooperators through three phases:
    - Phase 1 (Exploration): Defect to identify opponent types
    - Phase 2 (Adaptive): Selective cooperation based on observed cooperation rate
    - Phase 3 (Final Squeeze): Defect to maximize final extraction
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.phase1_end = math.ceil(self.r / 3)
        self.phase2_end = math.ceil(2 * self.r / 3)
        self.threshold_high = 0.6
        self.threshold_low = 0.2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num < self.phase1_end:
            return Action.D
        elif round_num < self.phase2_end:
            total_cooperators = 0
            for past_round in range(round_num):
                total_cooperators += np.sum(history.opponent_actions[past_round, :])
            coop_rate = total_cooperators / (self.n * round_num)
            if coop_rate >= self.threshold_high or coop_rate < self.threshold_low:
                return Action.D
            else:
                prob_cooperate = 0.4
                if random.random() < prob_cooperate:
                    return Action.C
                else:
                    return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_501(BaseStrategy):
    """
    Threshold Exploitation with Decay: An exploitative strategy that defaults to defection,
    adapts based on observed cooperation rates, and ruthlessly exploits cooperators.

    Core insight: Since k/n < 1, defection is individually rational. The strategy maximizes
    payoff by defecting every round, with special attention to exploiting periods where
    others cooperate, and using an adaptive threshold that becomes more aggressive toward
    the end-game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        previous_round_idx = current_round - 1
        cooperators_previous = int(np.sum(history.opponent_actions[previous_round_idx, :]))
        cooperation_ratio_previous = cooperators_previous / self.n_players
        threshold = max(0.3, 1.0 - current_round / self.n_rounds * 0.2)
        return Action.D

class Strategy_EXPLOITATIVE_502(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Exploitation

    This strategy maximizes payoff through aggressive defection, exploiting cooperative
    opponents while avoiding losses from cascading defection. Core principles:
    - Always defect in round 1 (establish dominance)
    - Always defect in final round (no punishment possible)
    - Defect when cooperation rate exceeds threshold (free-ride on public good)
    - Defect when cooperation is declining (avoid being caught in collapse)
    - Defect when experiencing consistent losses (escape bad equilibrium)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.threshold = self.k / self.n
        self.baseline_defection_payoff = 1.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        prev_round_cooperators = np.sum(history.opponent_actions[round_num - 1, :])
        cooperation_rate = prev_round_cooperators / self.n
        if cooperation_rate >= self.threshold:
            return Action.D
        if round_num >= 2:
            prev_prev_cooperation = np.sum(history.opponent_actions[round_num - 2, :]) / self.n
            if prev_prev_cooperation > cooperation_rate:
                return Action.D
        deficit_rounds = 0
        for i in range(round_num):
            if history.my_payoffs[i] < self.baseline_defection_payoff:
                deficit_rounds += 1
        if deficit_rounds > self.r / 3.0:
            return Action.D
        return Action.D

class Strategy_EXPLOITATIVE_503(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Calculated Cooperation

    Maximizes personal payoff by defecting against observable cooperators,
    cooperating strategically in round r-1 to exploit reciprocity-based strategies,
    and defecting unconditionally in the final round. Adapts to cooperation rates
    with a decaying threshold to balance exploitation with avoiding mutual defection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.decay_factor = 0.3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        t = state.round_number
        r = self.n_rounds
        n = self.n_players
        k = self.k
        if t == 0:
            return Action.D
        if t == r - 1:
            return Action.D
        if t == r - 2:
            return Action.C
        prev_round_cooperators = int(np.sum(history.opponent_actions[t - 1, :]))
        cooperation_rate = prev_round_cooperators / n
        threshold = k / n * (1.0 - self.decay_factor * (t / r))
        if cooperation_rate > threshold:
            return Action.D
        else:
            return Action.C

class Strategy_EXPLOITATIVE_504(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Exploitation

    This strategy exploits the fundamental asymmetry in the public goods game by:
    1. Always defecting to free-ride on others' contributions
    2. Detecting cooperation patterns and maintaining defection
    3. Adapting defection across all rounds to maximize personal payoff

    Core insight: Defection is strictly dominant (payoff difference = 1 > 0)
    regardless of others' cooperation rates, so we always defect.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if history is not None and len(history.opponent_actions) > 0:
            previous_round_idx = state.round_number - 1
            cooperators_in_previous = int(sum(history.opponent_actions[previous_round_idx, :]))
            self.cooperation_history.append(cooperators_in_previous)
        if len(self.cooperation_history) > 0:
            estimated_total_cooperators = sum(self.cooperation_history)
            rounds_observed = len(self.cooperation_history)
            estimated_cooperation_rate = estimated_total_cooperators / (self.game_description.n_players * rounds_observed)
        else:
            estimated_cooperation_rate = 0.0
        return Action.D

class Strategy_EXPLOITATIVE_505(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Controlled Exploitation

    Maximizes personal payoff by exploiting cooperative tendencies in others.
    - Round 0: DEFECT (establish baseline)
    - Rounds 1 to r-2: Adapt based on cooperation rate threshold
    - Round r-1: DEFECT (endgame abandonment)

    Cooperates only when cooperation rate >= (k-1)/k, ensuring public good gains exceed private endowment.
    Locks into defection if two consecutive rounds show zero cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.consecutive_zero_coop = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        if state.round_number == 0:
            return Action.D
        if state.round_number == r - 1:
            return Action.D
        previous_round_idx = state.round_number - 1
        previous_round_actions = history.opponent_actions[previous_round_idx, :]
        opponent_cooperators = np.sum(previous_round_actions)
        total_cooperators = opponent_cooperators + int(history.my_actions[previous_round_idx])
        coop_rate = total_cooperators / n
        threshold = (k - 1.0) / k
        if total_cooperators == 0:
            self.consecutive_zero_coop += 1
            if self.consecutive_zero_coop >= 2:
                return Action.D
        else:
            self.consecutive_zero_coop = 0
        if coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_EXPLOITATIVE_506(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core principle: Always defect to exploit cooperators and avoid losses from defectors.
    - Round 0: DEFECT (baseline testing)
    - Rounds 1 to r-2: DEFECT (exploit if cooperation exists, match if defection dominates)
    - Round r-1 (last): DEFECT (subgame perfect equilibrium)
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        cooperators_last_round = sum(history.opponent_actions[state.round_number - 1, :])
        cooperation_ratio = cooperators_last_round / self.game_description.n_players
        return Action.D

class Strategy_EXPLOITATIVE_507(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Core approach: Always defect to exploit the asymmetry between defection and cooperation payoffs.
    Monitors opponent cooperation rates to confirm exploitation opportunities, but defaults to defection
    as the dominant strategy given k < n constraint.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.COOP_THRESHOLD = 0.4
        self.ROLLING_WINDOW = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.D
        opponent_coop_rates = self._calculate_opponent_coop_rates(history, state.round_number)
        avg_coop_rate = self._compute_average_coop_rate(opponent_coop_rates)
        smoothed_coop_rate = self._apply_rolling_average_smoothing(history, state.round_number, opponent_coop_rates)
        if smoothed_coop_rate > self.COOP_THRESHOLD or avg_coop_rate > self.COOP_THRESHOLD:
            return Action.D
        return Action.D

    def _calculate_opponent_coop_rates(self, history: PlayerHistory, current_round: int) -> list:
        """
        Calculate cooperation rate for each opponent based on observed history.
        Returns list of cooperation rates (0.0 to 1.0) for each opponent.
        """
        coop_rates = []
        n_opponents = self.game_description.n_players - 1
        for opponent_idx in range(n_opponents):
            coop_count = np.sum(history.opponent_actions[:current_round, opponent_idx])
            total_rounds = current_round
            coop_rate = float(coop_count) / float(total_rounds) if total_rounds > 0 else 0.0
            coop_rates.append(coop_rate)
        return coop_rates

    def _compute_average_coop_rate(self, coop_rates: list) -> float:
        """
        Compute mean cooperation rate across all opponents.
        """
        if len(coop_rates) == 0:
            return 0.0
        return float(np.mean(coop_rates))

    def _apply_rolling_average_smoothing(self, history: PlayerHistory, current_round: int, coop_rates: list) -> float:
        """
        Apply rolling window average to smooth noise in cooperation rates.
        Uses a 3-round window to detect trends while filtering volatility.
        """
        if current_round < self.ROLLING_WINDOW:
            return self._compute_average_coop_rate(coop_rates)
        n_opponents = self.game_description.n_players - 1
        rolling_coop_sum = 0.0
        rolling_total_rounds = 0.0
        start_round = max(0, current_round - self.ROLLING_WINDOW)
        for round_idx in range(start_round, current_round):
            for opponent_idx in range(n_opponents):
                if history.opponent_actions[round_idx, opponent_idx]:
                    rolling_coop_sum += 1.0
            rolling_total_rounds += float(n_opponents)
        smoothed_rate = rolling_coop_sum / rolling_total_rounds if rolling_total_rounds > 0 else 0.0
        return smoothed_rate

class Strategy_EXPLOITATIVE_508(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Conditional Parasitism

    Maximizes personal payoff by exploiting cooperators while minimizing losses.
    Uses aggressive defection in round 1, exploit phase in middle rounds (tracking
    opponent cooperation rates), and pure defection in endgame rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_threshold = 0.6

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if state.round_number == 0:
            return Action.D
        if state.round_number >= self.game_description.n_rounds - 2:
            return Action.D
        num_rounds_so_far = state.round_number
        cooperation_rates = self._calculate_cooperation_rates(history, num_rounds_so_far)
        predicted_cooperators = self._predict_total_cooperators(cooperation_rates)
        k = self.game_description.k
        n = self.game_description.n_players
        cooperate_payoff = 0.0 + k / n * predicted_cooperators
        defect_payoff = 1.0 + k / n * predicted_cooperators
        if defect_payoff > cooperate_payoff:
            return Action.D
        for j in range(self.game_description.n_players - 1):
            if cooperation_rates[j] > self.cooperation_threshold:
                return Action.D
        return Action.D

    def _calculate_cooperation_rates(self, history: PlayerHistory, num_rounds_so_far: int) -> list:
        """
        Calculate cooperation rate for each opponent based on history.
        Returns list of cooperation rates indexed by opponent.
        """
        cooperation_rates = []
        for j in range(self.game_description.n_players - 1):
            if num_rounds_so_far > 0:
                cooperations = int(np.sum(history.opponent_actions[:num_rounds_so_far, j]))
                rate = cooperations / num_rounds_so_far
            else:
                rate = 0.5
            cooperation_rates.append(rate)
        return cooperation_rates

    def _predict_total_cooperators(self, cooperation_rates: list) -> float:
        """
        Predict total number of cooperators in the current round.
        Assumes opponents continue their historical cooperation patterns.
        """
        predicted = sum(cooperation_rates)
        return predicted

class Strategy_EXPLOITATIVE_509(BaseStrategy):
    """
    Adaptive Defection with Selective Parasitism - Exploitative Strategy

    Exploits the fundamental asymmetry in public goods games by:
    1. Probing with defection in round 1
    2. Classifying opponents based on cooperation rates
    3. Systematically exploiting unconditional cooperators
    4. Defecting in final round regardless of classification
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.opponent_classifications = {}

    def _classify_opponent(self, opponent_idx: int, cooperation_rate: float, recent_actions: NDArray[np.bool_]) -> str:
        """Classify opponent based on cooperation rate and reciprocal patterns."""
        if cooperation_rate >= 0.8:
            return 'unconditional_cooperator'
        elif cooperation_rate <= 0.3:
            return 'defector'
        elif self._shows_reciprocal_pattern(recent_actions):
            return 'conditional_cooperator'
        else:
            return 'uncertain'

    def _shows_reciprocal_pattern(self, opponent_recent_actions: NDArray[np.bool_]) -> bool:
        """Detect if opponent shows correlation between their actions and prior round outcomes."""
        if len(opponent_recent_actions) < 3:
            return False
        recent_cooperations = sum(opponent_recent_actions[-3:])
        return 1 <= recent_cooperations <= 2

    def _get_opponent_cooperation_rate(self, history: PlayerHistory, opponent_idx: int) -> float:
        """Calculate the cooperation rate for a specific opponent."""
        opponent_actions = history.opponent_actions[:, opponent_idx]
        if len(opponent_actions) == 0:
            return 0.5
        return float(np.sum(opponent_actions)) / float(len(opponent_actions))

    def _decide_for_opponent(self, opponent_idx: int, opponent_type: str, round_number: int, n_rounds: int) -> Action:
        """Decide action against a specific opponent based on their classification."""
        if opponent_type == 'unconditional_cooperator':
            return Action.D
        elif opponent_type == 'defector':
            return Action.D
        elif opponent_type == 'conditional_cooperator':
            return Action.D
        elif random.random() < 0.7:
            return Action.D
        else:
            return Action.C

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_number = state.round_number
        n_rounds = self.game_description.n_rounds
        n_players = self.game_description.n_players
        if round_number == 0:
            return Action.D
        if round_number == n_rounds - 1:
            return Action.D
        decisions = []
        for opponent_idx in range(n_players - 1):
            cooperation_rate = self._get_opponent_cooperation_rate(history, opponent_idx)
            recent_actions = history.opponent_actions[max(0, round_number - 3):, opponent_idx]
            should_reclassify = round_number % 10 == 0 or opponent_idx not in self.opponent_classifications
            if should_reclassify:
                opponent_type = self._classify_opponent(opponent_idx, cooperation_rate, recent_actions)
                self.opponent_classifications[opponent_idx] = opponent_type
            else:
                opponent_type = self.opponent_classifications.get(opponent_idx, 'uncertain')
            decision = self._decide_for_opponent(opponent_idx, opponent_type, round_number, n_rounds)
            decisions.append(decision)
        defection_count = sum((1 for d in decisions if d == Action.D))
        if defection_count >= len(decisions) / 2:
            return Action.D
        else:
            return Action.D

class Strategy_EXPLOITATIVE_510(BaseStrategy):
    """
    Exploitative Strategy: Unconditional Defection

    Always plays Defect (D) across all rounds. This strategy exploits the asymmetry
    in the payoff structure where defection strictly dominates cooperation:
    - Defection payoff: 1 + (k/n)  m (where m is number of cooperators)
    - Cooperation payoff: (k/n)  (m + 1)
    - Defection advantage: 1 - k/n > 0 (since k < n)

    This is the game-theoretically rational strategy for the N-Player Public Goods Game
    under standard assumptions of rationality and no reputation concerns.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        return Action.D

class Strategy_EXPLOITATIVE_511(BaseStrategy):
    """
    Adaptive Predation Strategy: An exploitative approach that defects strategically
    to free-ride on cooperators while matching defectors. Classifies opponents by type
    and exploits unconditional cooperators while avoiding commitment traps.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == 0:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        return self._adaptive_exploitation(history, current_round)

    def _adaptive_exploitation(self, history: PlayerHistory, current_round: int) -> Action:
        """
        Classify opponents and decide whether to exploit based on observed cooperation patterns.
        """
        opponent_histories = history.opponent_actions[:current_round, :]
        total_cooperation_count = np.sum(opponent_histories)
        total_possible_actions = current_round * (self.n_players - 1)
        cooperation_rate = total_cooperation_count / total_possible_actions if total_possible_actions > 0 else 0.0
        unconditional_cooperators = self._count_unconditional_cooperators(opponent_histories, current_round)
        consistent_defectors = self._count_consistent_defectors(opponent_histories, current_round)
        if cooperation_rate >= 0.7 and unconditional_cooperators > 0:
            return Action.D
        if cooperation_rate <= 0.3:
            return Action.D
        if unconditional_cooperators >= (self.n_players - 1) / 2:
            return Action.D
        if consistent_defectors >= 1:
            return Action.D
        return Action.D

    def _count_unconditional_cooperators(self, opponent_histories: NDArray[np.bool_], current_round: int) -> int:
        """
        Count opponents who have cooperated in every round observed (Type A).
        Classification window: rounds 0-min(2, current_round-1) for early detection.
        """
        if current_round <= 1:
            return 0
        classification_depth = min(3, current_round)
        count = 0
        for opponent_idx in range(opponent_histories.shape[1]):
            opponent_actions = opponent_histories[:classification_depth, opponent_idx]
            if np.all(opponent_actions):
                count += 1
        return count

    def _count_consistent_defectors(self, opponent_histories: NDArray[np.bool_], current_round: int) -> int:
        """
        Count opponents who have defected in most/all rounds (Type C).
        """
        if current_round <= 1:
            return 0
        classification_depth = min(3, current_round)
        count = 0
        for opponent_idx in range(opponent_histories.shape[1]):
            opponent_actions = opponent_histories[:classification_depth, opponent_idx]
            defection_count = np.sum(~opponent_actions)
            defection_rate = defection_count / classification_depth
            if defection_rate >= 0.8:
                count += 1
        return count

class Strategy_EXPLOITATIVE_512(BaseStrategy):
    """
    Adaptive Predation: An exploitative strategy that always defects to maximize
    personal gain by extracting value from any cooperators while contributing nothing
    to the public good. Defection is the dominant strategy since k < n implies
    k/n < 1, making the private payoff from defection always exceed cooperation payoff.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        return Action.D

class Strategy_EXPLOITATIVE_370(BaseStrategy):
    """
    Exploitative Strategy: Adaptive Defection with Selective Parasitism

    Exploits the public goods game by defaulting to defection, identifying
    cooperators, and parasitizing their contributions while locking defectors
    into mutual defection equilibrium.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if current_round == self.n_rounds - 1:
            return Action.D
        if current_round == 0:
            return Action.D
        total_cooperators = int(np.sum(history.opponent_actions))
        cooperation_rate = total_cooperators / (current_round * self.n_players)
        cooperator_persistence = np.sum(history.opponent_actions, axis=0) / current_round
        max_persistence = float(np.max(cooperator_persistence))
        if cooperation_rate > 0.4:
            return Action.D
        elif cooperation_rate >= 0.15:
            if random.random() < 0.05:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COLLECTIVE_195(BaseStrategy):
    """
    Adaptive Threshold Reciprocity with Decay (ATRD) Strategy for N-Player Public Goods Game.

    Balances individual and collective rationality through dynamic threshold-based reciprocity.
    Cooperates in round 1, applies adaptive thresholds in middle rounds, and uses strict
    breakeven logic in the final round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if round_num == 0:
            return Action.C
        prev_round_cooperators = sum(history.opponent_actions[round_num - 1, :])
        if history.my_actions[round_num - 1]:
            prev_round_cooperators += 1
        prev_cooperation_rate = prev_round_cooperators / self.n
        min_threshold = (self.k - 1) / (self.n - 1)
        decay_factor = (self.n - self.k) / self.n
        current_threshold = max(min_threshold, self.k / self.n + decay_factor * round_num / self.r)
        if round_num == self.r - 1:
            if prev_cooperation_rate >= min_threshold:
                return Action.C
            else:
                return Action.D
        if prev_cooperation_rate >= current_threshold:
            return Action.C
        else:
            return Action.D
