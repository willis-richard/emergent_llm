"""
Generated LLM strategies for social dilemma games.

This file contains strategy classes generated by LLMs for game theory experiments.
Each strategy is a callable class that implements a specific approach to the game.

Generated with:
- Provider: Anthropic
- Model: claude-sonnet-4-0
- Game: PublicGoodsDescription
"""

from emergent_llm.players import BaseStrategy
from emergent_llm.games import PublicGoodsDescription, CollectiveRiskDescription, CommonPoolDescription, CommonPoolState
from emergent_llm.common import Action, C, D, PlayerHistory, GameState
import numpy as np
from numpy.typing import NDArray
import math
import random



class Strategy_COOPERATIVE_1(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation Strategy (ARCS)
    
    Balances cooperative intent with adaptive self-protection, using dynamic 
    cooperation thresholds based on recent group behavior and parameter sensitivity.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_number = history.round_number
        memory_window = min(5, round_number)
        recent_opponent_actions = history.opponent_actions[-memory_window:]
        recent_my_actions = history.my_actions[-memory_window:]
        total_cooperators_recent = 0
        total_decisions_recent = 0
        for round_idx in range(memory_window):
            opponent_cooperators = sum(recent_opponent_actions[round_idx, :])
            my_cooperation = 1 if recent_my_actions[round_idx] else 0
            total_cooperators_recent += opponent_cooperators + my_cooperation
            total_decisions_recent += self.n
        cooperation_rate = total_cooperators_recent / total_decisions_recent if total_decisions_recent > 0 else 0
        expected_others_cooperating = cooperation_rate * (self.n - 1)
        expected_benefit = self.k / self.n * (expected_others_cooperating + 1)
        expected_cost = 1
        base_threshold = 0.8
        rounds_since_cooperation = 0
        for i in range(min(10, round_number)):
            if history.my_actions[-(i + 1)]:
                rounds_since_cooperation = i
                break
            rounds_since_cooperation = i + 1
        forgiveness_bonus = max(0, 0.3 - rounds_since_cooperation / 10)
        consecutive_group_defections = 0
        for round_idx in range(min(10, round_number)):
            recent_round = -(round_idx + 1)
            round_cooperators = sum(history.opponent_actions[recent_round, :])
            if history.my_actions[recent_round]:
                round_cooperators += 1
            group_coop_rate = round_cooperators / self.n
            if group_coop_rate < 0.3:
                consecutive_group_defections += 1
            else:
                break
        exploitation_penalty = min(0.4, consecutive_group_defections / 20)
        adjustment_factor = base_threshold + forgiveness_bonus - exploitation_penalty
        if self.k > self.n / 2:
            adjustment_factor *= 0.9
        elif self.k < 1.5:
            adjustment_factor *= 1.2
        if round_number == self.r - 1:
            recent_3_rounds = min(3, round_number)
            if recent_3_rounds > 0:
                recent_group_coop = 0
                recent_total = 0
                for i in range(recent_3_rounds):
                    round_idx = -(i + 1)
                    round_cooperators = sum(history.opponent_actions[round_idx, :])
                    if history.my_actions[round_idx]:
                        round_cooperators += 1
                    recent_group_coop += round_cooperators
                    recent_total += self.n
                if recent_total > 0 and recent_group_coop / recent_total > 0.6:
                    return Action.C
                else:
                    return Action.D
        if round_number <= 2:
            adjustment_factor = 0.9
        if cooperation_rate >= 0.8:
            return Action.C
        elif cooperation_rate < 0.2:
            return Action.D
        elif cooperation_rate < 0.4:
            adjustment_factor = 1.1
        if round_number % 10 == 0 and round_number > 10:
            adjustment_factor -= 0.2
        if expected_benefit >= expected_cost * adjustment_factor:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_2(BaseStrategy):
    """
    Generous Tit-for-Tat with Momentum: An adaptive cooperative strategy that responds to group cooperation levels.
    
    Always cooperates in round 1, then uses cooperation rate thresholds (50% for rounds 2 to r-1, 40% for final round)
    with a forgiveness mechanism that gives groups second chances when cooperation is borderline (â‰¥30%).
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        last_round = history.round_number - 1
        my_last_action = history.my_actions[last_round]
        opponent_cooperators = sum(history.opponent_actions[last_round, :])
        total_cooperators = int(my_last_action) + opponent_cooperators
        cooperation_rate = total_cooperators / self.game_description.n_players
        if state.round_number == self.game_description.n_rounds - 1:
            if cooperation_rate >= 0.4:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= 0.5:
            return Action.C
        if not my_last_action and cooperation_rate >= 0.3:
            return Action.C
        if cooperation_rate < 0.5:
            return Action.D
        return Action.C

class Strategy_COOPERATIVE_3(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation (ARC) Strategy
    
    Balances cooperation with adaptive responses to others' behavior using graduated
    reciprocation. Maintains dynamic cooperation thresholds that adjust based on
    group behavior while protecting against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.current_threshold = 0.5
        self.base_threshold = 0.5
        self.fresh_start_active = False
        self.fresh_start_rounds_remaining = 0
        self.low_cooperation_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number
        n_players = self.game_description.n_players
        total_rounds = self.game_description.n_rounds
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        cooperation_rate = last_round_cooperators / n_players
        if cooperation_rate < 0.2:
            self.low_cooperation_streak += 1
        else:
            self.low_cooperation_streak = 0
        if self.low_cooperation_streak >= 3 and (not self.fresh_start_active):
            self.fresh_start_active = True
            self.fresh_start_rounds_remaining = 2
            self.current_threshold = 0.4
        if self.fresh_start_active and self.fresh_start_rounds_remaining > 0:
            self.fresh_start_rounds_remaining -= 1
            if self.fresh_start_rounds_remaining == 0:
                self.fresh_start_active = False
            return Action.C
        endgame_threshold = max(3, math.ceil(0.2 * total_rounds))
        rounds_remaining = total_rounds - current_round
        if rounds_remaining <= endgame_threshold:
            return self._handle_endgame(history, rounds_remaining)
        if cooperation_rate >= self.current_threshold:
            self.current_threshold = max(0.3, self.current_threshold - 0.05)
        else:
            self.current_threshold = min(0.7, self.current_threshold + 0.1)
        if cooperation_rate >= self.current_threshold:
            return Action.C
        else:
            return Action.D

    def _handle_endgame(self, history: PlayerHistory, rounds_remaining: int) -> Action:
        """Handle decision making in the endgame phase."""
        n_players = self.game_description.n_players
        if rounds_remaining == 1:
            if history.round_number >= 1:
                last_round_cooperators = sum(history.opponent_actions[-1, :])
                if history.my_actions[-1]:
                    last_round_cooperators += 1
                cooperation_rate = last_round_cooperators / n_players
                return Action.C if cooperation_rate >= 0.5 else Action.D
            return Action.C
        rounds_to_check = min(5, history.round_number)
        total_cooperators = 0
        total_decisions = 0
        for i in range(rounds_to_check):
            round_idx = -(i + 1)
            round_cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                round_cooperators += 1
            total_cooperators += round_cooperators
            total_decisions += n_players
        avg_cooperation_rate = total_cooperators / total_decisions if total_decisions > 0 else 0
        if avg_cooperation_rate >= 0.6:
            return Action.C
        else:
            last_round_cooperators = sum(history.opponent_actions[-1, :])
            if history.my_actions[-1]:
                last_round_cooperators += 1
            cooperation_rate = last_round_cooperators / n_players
            return Action.C if cooperation_rate >= self.current_threshold else Action.D

class Strategy_COOPERATIVE_4(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation Strategy (ARC) - Balances cooperative intent 
    with adaptive protection against exploitation using dual-threshold system.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.high_threshold = 0.6
        self.low_threshold = 0.3
        self.endgame_threshold = 0.4
        if self.k > 2.0:
            self.high_threshold -= 0.1
            self.low_threshold -= 0.1
            self.endgame_threshold -= 0.1
        if self.n > 8:
            self.high_threshold -= 0.05
            self.low_threshold -= 0.05
        elif self.n <= 4:
            self.high_threshold += 0.05
            self.low_threshold += 0.05
        if self.r <= 5:
            self.high_threshold -= 0.1
            self.low_threshold -= 0.1
        elif self.r > 15:
            self.endgame_threshold -= 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = history.round_number
        if round_num == self.r - 1:
            return self._endgame_decision(history)
        return self._main_phase_decision(history)

    def _endgame_decision(self, history: PlayerHistory) -> Action:
        """Endgame phase: Cooperate if long-term cooperation rate >= threshold"""
        if history.round_number == 0:
            return Action.C
        total_opponent_cooperations = np.sum(history.opponent_actions)
        total_possible = history.round_number * (self.n - 1)
        if total_possible == 0:
            return Action.C
        long_term_rate = total_opponent_cooperations / total_possible
        return Action.C if long_term_rate >= self.endgame_threshold else Action.D

    def _main_phase_decision(self, history: PlayerHistory) -> Action:
        """Main phase decision using dual-threshold system"""
        round_num = history.round_number
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        cooperation_rate = last_round_cooperators / (self.n - 1)
        edge_case_action = self._check_edge_cases(history, cooperation_rate)
        if edge_case_action is not None:
            return edge_case_action
        if cooperation_rate >= self.high_threshold:
            return Action.C
        elif cooperation_rate <= self.low_threshold:
            if self._should_offer_olive_branch(history):
                return Action.C
            return Action.D
        else:
            return self._apply_forgiveness_rule(history)

    def _check_edge_cases(self, history: PlayerHistory, cooperation_rate: float) -> Action | None:
        """Check for special edge cases"""
        round_num = history.round_number
        if round_num >= 3:
            recent_rates = []
            for i in range(max(0, round_num - 3), round_num):
                round_cooperators = np.sum(history.opponent_actions[i, :])
                round_rate = round_cooperators / (self.n - 1)
                recent_rates.append(round_rate)
            if all((rate >= 0.9 for rate in recent_rates)):
                return Action.C
        if round_num >= 3:
            recent_rates = []
            for i in range(max(0, round_num - 3), round_num):
                round_cooperators = np.sum(history.opponent_actions[i, :])
                round_rate = round_cooperators / (self.n - 1)
                recent_rates.append(round_rate)
            if all((rate == 0.0 for rate in recent_rates)):
                return Action.D
        if round_num >= 4:
            recent_rates = []
            for i in range(round_num):
                round_cooperators = np.sum(history.opponent_actions[i, :])
                round_rate = round_cooperators / (self.n - 1)
                recent_rates.append(round_rate)
            if len(recent_rates) >= 4:
                variance = np.var(recent_rates)
                if variance > 0.2:
                    return Action.C if cooperation_rate >= 0.5 else Action.D
        return None

    def _should_offer_olive_branch(self, history: PlayerHistory) -> bool:
        """Check if should offer olive branch after defection streak"""
        if len(history.my_actions) < 3:
            return False
        consecutive_defections = 0
        for i in range(len(history.my_actions) - 1, -1, -1):
            if history.my_actions[i] == False:
                consecutive_defections += 1
            else:
                break
        return consecutive_defections >= 3

    def _apply_forgiveness_rule(self, history: PlayerHistory) -> Action:
        """Apply forgiveness rule in middle cooperation zone"""
        my_last_action = history.my_actions[-1]
        if not my_last_action:
            last_round_cooperators = np.sum(history.opponent_actions[-1, :])
            cooperation_rate = last_round_cooperators / (self.n - 1)
            if cooperation_rate >= 0.5:
                return Action.C
        if my_last_action:
            return Action.C
        else:
            return Action.D

    def _get_personal_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate personal cooperation rate"""
        if len(history.my_actions) == 0:
            return 1.0
        return np.mean(history.my_actions.astype(float))

class Strategy_COOPERATIVE_5(BaseStrategy):
    """
    Graduated Reciprocator: An adaptive cooperative strategy that adjusts cooperation 
    thresholds based on observed behavior, uses forgiveness mechanisms, and considers 
    game efficiency (k/n ratio) to balance cooperation with protection from exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.base_threshold = 0.5 if self.k / self.n <= 0.5 else 0.3
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.consecutive_defections = 0
            return Action.C
        current_round = history.round_number + 1
        if current_round <= 3:
            prev_cooperators = np.sum(history.opponent_actions[-1, :])
            prev_coop_rate = prev_cooperators / self.n
            return Action.C if prev_coop_rate >= 0.5 else Action.D
        elif current_round >= self.r - 1:
            prev_cooperators = np.sum(history.opponent_actions[-1, :])
            prev_coop_rate = prev_cooperators / self.n
            if current_round == self.r - 1:
                return Action.C if prev_coop_rate >= 0.4 else Action.D
            else:
                return Action.C if prev_coop_rate >= 0.5 else Action.D
        else:
            prev_cooperators = np.sum(history.opponent_actions[-1, :])
            prev_coop_rate = prev_cooperators / self.n
            rounds_to_check = min(3, history.round_number)
            recent_coop_rates = []
            for i in range(rounds_to_check):
                round_cooperators = np.sum(history.opponent_actions[-(i + 1), :])
                recent_coop_rates.append(round_cooperators / self.n)
            avg_coop_3 = np.mean(recent_coop_rates)
            threshold = self.base_threshold
            if avg_coop_3 > 0.7:
                threshold -= 0.1
            if avg_coop_3 < 0.3:
                threshold += 0.2
            threshold = max(0.0, min(1.0, threshold))
            if self.consecutive_defections >= 2 and current_round % 3 == 0:
                self.consecutive_defections = 0
                return Action.C
            if prev_coop_rate >= threshold:
                self.consecutive_defections = 0
                return Action.C
            else:
                self.consecutive_defections += 1
                return Action.D

class Strategy_COOPERATIVE_6(BaseStrategy):
    """
    Graduated Reciprocator: An adaptive cooperative strategy that scales cooperation
    based on group dynamics, game parameters, and includes punishment/forgiveness mechanisms.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.base_threshold = (self.n - self.k) / (self.n - 1) if self.n > 1 else 0.5
        if self.n <= 4:
            self.base_threshold -= 0.1
        if self.k > 0.8 * self.n:
            self.base_threshold -= 0.15
        if self.r <= 5:
            self.base_threshold *= 0.5
        self.base_threshold = max(0.1, min(0.9, self.base_threshold))
        self.adjustment_factor = 0.7
        self.punishment_rounds_left = 0
        self.just_finished_punishment = False
        self.personal_exploitation_count = 0
        self.total_cooperation_opportunities = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number + 1
        if self.punishment_rounds_left > 0:
            self.punishment_rounds_left -= 1
            return Action.D
        if self.just_finished_punishment:
            self.just_finished_punishment = False
            self.adjustment_factor = 0.8
            return Action.C
        recent_coop_rate = self._calculate_recent_cooperation(history)
        self._update_adjustment_factor(current_round, history)
        current_threshold = self.base_threshold * self.adjustment_factor
        current_threshold = max(0.3, min(0.9, current_threshold))
        if self._should_punish(history, recent_coop_rate):
            remaining_rounds = self.r - current_round
            self.punishment_rounds_left = max(1, min(2, math.floor(remaining_rounds / 4)))
            self.just_finished_punishment = False
            return Action.D
        if current_round == self.r:
            if recent_coop_rate < 0.3:
                return Action.D
            else:
                current_threshold += 0.2
        if self._is_high_defection_scenario(history):
            if len(history.opponent_actions) > 0:
                last_round_cooperators = sum(history.opponent_actions[-1, :])
                if last_round_cooperators >= 2:
                    return Action.C
                else:
                    return Action.D
        if recent_coop_rate >= current_threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_recent_cooperation(self, history):
        """Calculate cooperation rate over recent rounds (last 3 or available rounds)"""
        if len(history.opponent_actions) == 0:
            return 0.5
        lookback = min(3, len(history.opponent_actions))
        recent_actions = history.opponent_actions[-lookback:, :]
        total_decisions = recent_actions.size
        total_cooperations = np.sum(recent_actions)
        return total_cooperations / total_decisions if total_decisions > 0 else 0.5

    def _update_adjustment_factor(self, current_round, history):
        """Update adjustment factor based on game phase and trends"""
        trust_building_end = min(5, self.r // 3)
        endgame_start = max(self.r - max(3, self.r // 5), self.r - 3)
        recent_coop_rate = self._calculate_recent_cooperation(history)
        if current_round <= trust_building_end:
            if recent_coop_rate >= 0.5:
                self.adjustment_factor = max(0.3, self.adjustment_factor - 0.05)
            elif recent_coop_rate < 0.3:
                self.adjustment_factor = min(0.9, self.adjustment_factor + 0.1)
        elif current_round >= endgame_start:
            self.adjustment_factor = min(0.9, self.adjustment_factor + 0.1)
        elif len(history.opponent_actions) >= 3:
            cooperation_trend = self._calculate_cooperation_trend(history)
            if cooperation_trend > 0:
                self.adjustment_factor = max(0.3, self.adjustment_factor - 0.02)
            elif cooperation_trend < 0:
                self.adjustment_factor = min(0.9, self.adjustment_factor + 0.05)

    def _calculate_cooperation_trend(self, history):
        """Calculate if cooperation is trending up or down over recent rounds"""
        if len(history.opponent_actions) < 3:
            return 0
        if len(history.opponent_actions) >= 4:
            recent_2 = np.mean(history.opponent_actions[-2:, :])
            prev_2 = np.mean(history.opponent_actions[-4:-2, :])
            return recent_2 - prev_2
        else:
            last_round = np.mean(history.opponent_actions[-1, :])
            earlier_rounds = np.mean(history.opponent_actions[:-1, :])
            return last_round - earlier_rounds

    def _should_punish(self, history, recent_coop_rate):
        """Determine if punishment phase should be triggered"""
        if len(history.opponent_actions) >= 2:
            last_2_rounds = history.opponent_actions[-2:, :]
            coop_rates = [np.mean(round_actions) for round_actions in last_2_rounds]
            if all((rate < 0.2 for rate in coop_rates)):
                return True
        self._update_exploitation_tracking(history)
        if self.total_cooperation_opportunities > 0:
            exploitation_ratio = self.personal_exploitation_count / self.total_cooperation_opportunities
            if exploitation_ratio > 0.6:
                return True
        return False

    def _update_exploitation_tracking(self, history):
        """Track how often this player cooperated while others mostly defected"""
        if len(history.my_actions) == 0:
            return
        my_last_action = history.my_actions[-1]
        if my_last_action:
            others_coop_rate = np.mean(history.opponent_actions[-1, :])
            self.total_cooperation_opportunities += 1
            if others_coop_rate < 0.4:
                self.personal_exploitation_count += 1

    def _is_high_defection_scenario(self, history):
        """Check if we're in a high defection scenario requiring cautious tit-for-tat"""
        if len(history.opponent_actions) < 3:
            return False
        recent_rounds = min(3, len(history.opponent_actions))
        for i in range(recent_rounds):
            round_coop_rate = np.mean(history.opponent_actions[-(i + 1), :])
            if round_coop_rate >= 0.1:
                return False
        return True

class Strategy_COOPERATIVE_7(BaseStrategy):
    """
    Graduated Reciprocator: An adaptive cooperative strategy that balances cooperation 
    with self-protection by starting cooperatively, rewarding collective cooperation, 
    and responding proportionally to defection while maintaining forgiveness.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_history = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        current_round = state.round_number + 1
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        coop_rate_last = last_round_cooperators / n
        self.cooperation_history.append(coop_rate_last)
        if current_round == r:
            rolling_window = min(3, len(self.cooperation_history))
            rolling_avg = np.mean(self.cooperation_history[-rolling_window:])
            return Action.C if rolling_avg >= 0.5 else Action.D
        rolling_window = min(3, len(self.cooperation_history))
        rolling_avg = np.mean(self.cooperation_history[-rolling_window:])
        if n <= 4:
            high_coop_threshold = 0.5
            low_coop_threshold = 0.25
        elif n >= 10:
            high_coop_threshold = 0.7
            low_coop_threshold = 0.35
        else:
            high_coop_threshold = 0.6
            low_coop_threshold = 0.3
        if rolling_avg >= high_coop_threshold:
            action = Action.C
        elif rolling_avg <= low_coop_threshold:
            action = Action.D
        else:
            rounds_to_check = min(2, len(history.my_actions))
            defectors_against_me = 0
            for i in range(rounds_to_check):
                round_idx = -(i + 1)
                if history.my_actions[round_idx]:
                    defectors_against_me += np.sum(~history.opponent_actions[round_idx, :])
            action = Action.D if defectors_against_me >= n / 2 else Action.C
        if action == Action.D and current_round > r / 2:
            if len(self.cooperation_history) >= 2:
                recent_trend = []
                for i in range(min(2, len(self.cooperation_history) - 1)):
                    recent_trend.append(self.cooperation_history[-(i + 1)] > self.cooperation_history[-(i + 2)])
                if all(recent_trend):
                    action = Action.C
        if current_round <= 3 and rolling_avg > 0.2:
            action = Action.C
        return action

class Strategy_COOPERATIVE_8(BaseStrategy):
    """
    Graduated Reciprocity with Forgiveness: An adaptive cooperative strategy that balances
    cooperation with protection against exploitation through graduated responses and forgiveness mechanisms.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.consecutive_defections = 0
        self.low_cooperation_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.consecutive_defections = 0
            self.low_cooperation_streak = 0
            return Action.C
        current_round = state.round_number
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        cooperation_rate = last_round_cooperators / self.n_players
        if current_round == self.n_rounds - 1:
            return Action.C if cooperation_rate >= 0.6 else Action.D
        base_action = Action.C if cooperation_rate >= 0.5 else Action.D
        if cooperation_rate < 0.2:
            self.low_cooperation_streak += 1
        else:
            self.low_cooperation_streak = 0
        if self.low_cooperation_streak >= 3 and cooperation_rate < 0.4:
            self.consecutive_defections += 1 if base_action == Action.D else 0
            return Action.D
        if self.consecutive_defections >= 2 and cooperation_rate >= 0.3:
            self.consecutive_defections = 0
            return Action.C
        if len(history.my_actions) >= 2:
            prev_round_cooperators = sum(history.opponent_actions[-2, :])
            if history.my_actions[-2]:
                prev_round_cooperators += 1
            prev_cooperation_rate = prev_round_cooperators / self.n_players
            trend = cooperation_rate - prev_cooperation_rate
            if base_action == Action.D and trend > 0.2:
                self.consecutive_defections = 0
                return Action.C
        if base_action == Action.D:
            self.consecutive_defections += 1
        else:
            self.consecutive_defections = 0
        return base_action

class Strategy_COOPERATIVE_9(BaseStrategy):
    """
    Generous Tit-for-Tat with Forgiveness strategy for N-Player Public Goods Game.
    
    Starts cooperatively, uses adaptive cooperation threshold based on game parameters,
    includes forgiveness mechanism to prevent defection spirals, and handles end-game strategically.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = state.round_number
        base_threshold = max(0.3, (self.k - 1) / (self.n - 1))
        if self.n <= 3:
            threshold = max(0.2, (self.k - 1) / (self.n - 1))
        elif self.k > self.n - 1:
            threshold = 0.2
        else:
            threshold = base_threshold
        last_round_cooperators = sum(history.opponent_actions[-1, :]) + int(history.my_actions[-1])
        last_round_coop_rate = last_round_cooperators / self.n
        if self._consecutive_defections(history) >= 3:
            avg_recent_coop = self._average_cooperation_last_3_rounds(history)
            if avg_recent_coop >= 0.2:
                return Action.C
        if round_num == self.r:
            if len(history.my_actions) >= 1:
                prev_round_cooperators = sum(history.opponent_actions[-1, :]) + int(history.my_actions[-1])
                prev_round_coop_rate = prev_round_cooperators / self.n
                if prev_round_coop_rate >= 0.4:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.C
        if self.r <= 3 and round_num < self.r:
            return Action.C
        if last_round_coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _consecutive_defections(self, history: PlayerHistory) -> int:
        """Count consecutive defections from the end of my action history."""
        if len(history.my_actions) == 0:
            return 0
        consecutive = 0
        for i in range(len(history.my_actions) - 1, -1, -1):
            if not history.my_actions[i]:
                consecutive += 1
            else:
                break
        return consecutive

    def _average_cooperation_last_3_rounds(self, history: PlayerHistory) -> float:
        """Calculate average cooperation rate over last 3 rounds (including all players)."""
        if len(history.my_actions) == 0:
            return 0.0
        start_idx = max(0, len(history.my_actions) - 3)
        total_cooperation = 0
        total_decisions = 0
        for round_idx in range(start_idx, len(history.my_actions)):
            round_cooperators = sum(history.opponent_actions[round_idx, :]) + int(history.my_actions[round_idx])
            total_cooperation += round_cooperators
            total_decisions += self.n
        if total_decisions == 0:
            return 0.0
        return total_cooperation / total_decisions

class Strategy_COOPERATIVE_10(BaseStrategy):
    """
    Generous Tit-for-Tat with Forgiveness: An adaptive cooperative strategy that balances
    cooperative intent with proportional responses to others' behavior. Starts cooperatively,
    rewards cooperation, punishes defection proportionally, but maintains forgiveness to
    avoid permanent punishment spirals.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        current_round = state.round_number
        total_rounds = self.game_description.n_rounds
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        recent_coop_rate = last_round_cooperators / n
        trend = 0
        if len(history.my_actions) >= 2:
            prev_round_cooperators = sum(history.opponent_actions[-2, :])
            if history.my_actions[-2]:
                prev_round_cooperators += 1
            prev_coop_rate = prev_round_cooperators / n
            trend = recent_coop_rate - prev_coop_rate
        if current_round == total_rounds - 1:
            total_cooperators = 0
            total_observations = 0
            for round_idx in range(len(history.my_actions)):
                round_cooperators = sum(history.opponent_actions[round_idx, :])
                if history.my_actions[round_idx]:
                    round_cooperators += 1
                total_cooperators += round_cooperators
                total_observations += n
            historical_avg_coop = total_cooperators / total_observations if total_observations > 0 else 0
            if historical_avg_coop >= 0.5:
                return Action.C
            elif recent_coop_rate >= 0.6:
                return Action.C
            else:
                return Action.D
        if recent_coop_rate >= 0.6:
            return Action.C
        elif recent_coop_rate >= 0.4:
            if trend >= 0:
                return Action.C
            elif random.random() < 0.7:
                return Action.C
            else:
                return Action.D
        elif recent_coop_rate >= 0.2:
            if trend > 0:
                return Action.C
            else:
                return Action.D
        elif trend > 0.1:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_11(BaseStrategy):
    """
    Graduated Reciprocator: An adaptive cooperative strategy that balances cooperation 
    with protection against exploitation using a graduated response system based on 
    recent group behavior and game parameters.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        current_round = state.round_number + 1
        base_threshold = k / n
        window_size = min(3, current_round - 1)
        if r >= 20:
            window_size = min(5, current_round - 1)
        recent_rounds = min(window_size, len(history.my_actions))
        recent_cooperators = 0
        for i in range(recent_rounds):
            round_idx = len(history.my_actions) - 1 - i
            if history.my_actions[round_idx]:
                recent_cooperators += 1
            recent_cooperators += sum(history.opponent_actions[round_idx, :])
        total_recent_actions = n * recent_rounds
        recent_coop_rate = recent_cooperators / total_recent_actions if total_recent_actions > 0 else 0
        adjusted_threshold = max(0.3, base_threshold - 0.1)
        if n <= 4:
            adjusted_threshold = max(0.25, base_threshold - 0.15)
        if k > 0.8 * n:
            adjusted_threshold -= 0.1
        if len(history.my_actions) >= 2:
            my_last_two = history.my_actions[-2:]
            all_my_defections = not any(my_last_two)
            any_cooperated_last = any(history.opponent_actions[-1, :])
            if all_my_defections and any_cooperated_last:
                return Action.C
        if current_round == r:
            final_window = min(3, r - 1)
            final_recent_rounds = min(final_window, len(history.my_actions))
            final_cooperators = 0
            for i in range(final_recent_rounds):
                round_idx = len(history.my_actions) - 1 - i
                if history.my_actions[round_idx]:
                    final_cooperators += 1
                final_cooperators += sum(history.opponent_actions[round_idx, :])
            final_total_actions = n * final_recent_rounds
            final_coop_rate = final_cooperators / final_total_actions if final_total_actions > 0 else 0
            if final_coop_rate >= 0.4:
                return Action.C
            else:
                return Action.D
        if recent_coop_rate >= adjusted_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_12(BaseStrategy):
    """
    Adaptive Cooperative Strategy: "Graduated Reciprocator"
    
    Balances cooperative intent with adaptive learning, starting optimistically
    but learning from experience to match the cooperation level of the group.
    Uses a cooperation threshold system with graduated responses and recovery mechanisms.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.consecutive_high_coop_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        cooperation_rate = last_round_cooperators / self.n_players
        if current_round == self.n_rounds - 1:
            if cooperation_rate >= 0.6:
                return Action.C
        my_threshold = max(0.3, cooperation_rate * 1.1)
        if cooperation_rate >= 0.7:
            self.consecutive_high_coop_rounds += 1
        elif cooperation_rate < 0.5:
            self.consecutive_high_coop_rounds = 0
        streak_bonus = min(0.3, self.consecutive_high_coop_rounds // 3 * 0.1)
        if self._check_low_participation_mode(history):
            return Action.C if random.random() < 0.4 else Action.D
        if self._check_exploration_mode(history):
            rounds_since_start = len(history.my_actions)
            return Action.C if rounds_since_start % 4 == 0 else Action.D
        effective_coop_rate = self._get_effective_cooperation_rate(history)
        if effective_coop_rate >= my_threshold:
            return Action.C
        else:
            coop_probability = min(1.0, effective_coop_rate + streak_bonus)
            return Action.C if random.random() < coop_probability else Action.D

    def _check_low_participation_mode(self, history: PlayerHistory) -> bool:
        """Check if we should enter rebuild mode due to consistently low participation."""
        if len(history.my_actions) < 2:
            return False
        low_coop_count = 0
        for i in range(max(0, len(history.my_actions) - 2), len(history.my_actions)):
            round_cooperators = sum(history.opponent_actions[i, :])
            if history.my_actions[i]:
                round_cooperators += 1
            if round_cooperators / self.n_players < 0.3:
                low_coop_count += 1
        return low_coop_count >= 2

    def _check_exploration_mode(self, history: PlayerHistory) -> bool:
        """Check if we should enter exploration mode due to near-unanimous defection."""
        if len(history.my_actions) < 2:
            return False
        very_low_coop_count = 0
        for i in range(max(0, len(history.my_actions) - 2), len(history.my_actions)):
            round_cooperators = sum(history.opponent_actions[i, :])
            if history.my_actions[i]:
                round_cooperators += 1
            if round_cooperators / self.n_players <= 0.1:
                very_low_coop_count += 1
        return very_low_coop_count >= 2

    def _get_effective_cooperation_rate(self, history: PlayerHistory) -> float:
        """Get cooperation rate, using moving average if there's high volatility."""
        if len(history.my_actions) < 2:
            last_round_cooperators = sum(history.opponent_actions[-1, :])
            if history.my_actions[-1]:
                last_round_cooperators += 1
            return last_round_cooperators / self.n_players
        recent_rates = []
        for i in range(max(0, len(history.my_actions) - 3), len(history.my_actions)):
            round_cooperators = sum(history.opponent_actions[i, :])
            if history.my_actions[i]:
                round_cooperators += 1
            recent_rates.append(round_cooperators / self.n_players)
        has_high_volatility = False
        if len(recent_rates) >= 2:
            for i in range(1, len(recent_rates)):
                if abs(recent_rates[i] - recent_rates[i - 1]) >= 0.4:
                    has_high_volatility = True
                    break
        if has_high_volatility and len(recent_rates) >= 3:
            return sum(recent_rates[-3:]) / min(3, len(recent_rates))
        else:
            return recent_rates[-1] if recent_rates else 0.0

class Strategy_COOPERATIVE_13(BaseStrategy):
    """
    Graduated Reciprocator: Adaptive cooperative strategy that balances forgiveness 
    with accountability using graduated responses and dynamic thresholds based on 
    game parameters and opponent behavior patterns.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.total_rounds = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if current_round <= 2:
            return Action.C
        base_threshold = (self.k - 1) / (self.n - 1)
        recent_rounds = min(3, current_round)
        recent_opponent_actions = history.opponent_actions[-recent_rounds:, :]
        recent_cooperation_rate = np.mean(recent_opponent_actions)
        adjustment = 0.2 * (recent_cooperation_rate - 0.5)
        cooperation_threshold = max(0.3, min(0.8, base_threshold + adjustment))
        last_round_cooperation = np.mean(history.opponent_actions[-1, :])
        my_recent_actions = history.my_actions[-recent_rounds:]
        my_recent_cooperation = np.mean(my_recent_actions)
        others_recent_cooperation = recent_cooperation_rate
        consecutive_defections = 0
        for i in range(min(len(history.my_actions), 3)):
            if not history.my_actions[-(i + 1)]:
                consecutive_defections += 1
            else:
                break
        if current_round % 4 == 0 or current_round % 5 == 0:
            if consecutive_defections >= 2 and last_round_cooperation >= 0.2:
                return Action.C
        if last_round_cooperation >= cooperation_threshold:
            return Action.C
        elif my_recent_cooperation > others_recent_cooperation + 0.15:
            if random.random() < 0.7:
                return Action.D
            else:
                return Action.C
        elif current_round <= 0.8 * self.total_rounds:
            if last_round_cooperation >= 0.2:
                return Action.C
            else:
                return Action.D
        elif last_round_cooperation >= 0.5:
            return Action.C
        else:
            return Action.D
        if current_round >= 3:
            last_3_cooperation = np.mean(history.opponent_actions[-3:, :])
            if last_3_cooperation < 0.15:
                cooperators_last_round = np.sum(history.opponent_actions[-1, :])
                if cooperators_last_round >= 2:
                    return Action.C
                else:
                    return Action.D
        if current_round >= 3:
            last_3_cooperation = np.mean(history.opponent_actions[-3:, :])
            if last_3_cooperation > 0.8:
                return Action.C
        if current_round == self.total_rounds - 1:
            if last_round_cooperation >= 0.6:
                return Action.C
            else:
                return Action.D
        return Action.C

class Strategy_COOPERATIVE_14(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation Strategy (ARC)
    
    Balances cooperative intent with adaptive protection against exploitation.
    Starts optimistically, uses cooperation thresholds to respond to group behavior,
    includes forgiveness mechanisms, and adjusts for end-game dynamics.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        prev_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            prev_round_cooperators += 1
        coop_rate = prev_round_cooperators / self.game_description.n_players
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C if coop_rate >= 0.4 else Action.D
        if len(history.my_actions) > 0 and (not history.my_actions[-1]) and (coop_rate >= 0.33):
            return Action.C
        if coop_rate >= 0.5:
            return Action.C
        elif coop_rate >= 0.25:
            cooperation_prob = 2 * coop_rate
            return Action.C if random.random() < cooperation_prob else Action.D
        else:
            return Action.D

class Strategy_COOPERATIVE_15(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation (ARC) Strategy.
    
    Begins with cooperation, adapts to group cooperation levels and trends,
    and maintains opportunities for renewed cooperation while protecting
    against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        total_rounds = self.game_description.n_rounds
        n_players = self.game_description.n_players
        if current_round == total_rounds - 1:
            return Action.C
        my_last_action = history.my_actions[-1]
        opponent_cooperators_last_round = sum(history.opponent_actions[-1, :])
        total_cooperators_last_round = opponent_cooperators_last_round + (1 if my_last_action else 0)
        cooperation_rate = total_cooperators_last_round / n_players
        trend = 'stable'
        if len(history.my_actions) >= 2:
            my_second_last_action = history.my_actions[-2]
            opponent_cooperators_second_last = sum(history.opponent_actions[-2, :])
            total_cooperators_second_last = opponent_cooperators_second_last + (1 if my_second_last_action else 0)
            previous_cooperation_rate = total_cooperators_second_last / n_players
            if cooperation_rate > previous_cooperation_rate:
                trend = 'improving'
            elif cooperation_rate < previous_cooperation_rate:
                trend = 'declining'
        if cooperation_rate >= 0.5:
            return Action.C
        elif cooperation_rate >= 0.3:
            if trend == 'improving':
                return Action.C
            else:
                return Action.D
        elif trend == 'improving' and cooperation_rate > 0:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_16(BaseStrategy):
    """
    Adaptive Cooperative Strategy: "Conditional Cooperator with Forgiveness"
    
    This strategy aims to maximize collective welfare while protecting against exploitation
    through adaptive cooperation based on observed group dynamics and reciprocity patterns.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.initial_threshold = 0.5
        self.exploitation_count = 0
        self.forgiveness_active = False
        self.low_cooperation_mode = False
        self.low_cooperation_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = history.round_number + 1
        recent_cooperation_rate = self._calculate_cooperation_rate(history, lookback=3)
        threshold = self._calculate_dynamic_threshold(history, recent_cooperation_rate, round_num)
        if self._should_forgive(history):
            self.forgiveness_active = True
            return Action.C
        else:
            self.forgiveness_active = False
        self._update_low_cooperation_mode(history)
        if self._being_exploited(history):
            threshold += 0.2
        if self.low_cooperation_mode:
            threshold = max(threshold, 0.4)
        if recent_cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, lookback: int=3) -> float:
        """Calculate cooperation rate over the last 'lookback' rounds."""
        if history.round_number == 0:
            return 0.0
        start_idx = max(0, history.round_number - lookback)
        recent_rounds = history.opponent_actions[start_idx:, :]
        if recent_rounds.size == 0:
            return 0.0
        total_decisions = recent_rounds.size
        total_cooperations = np.sum(recent_rounds)
        return total_cooperations / total_decisions if total_decisions > 0 else 0.0

    def _calculate_cooperation_trend(self, history: PlayerHistory) -> float:
        """Calculate trend in cooperation rates over recent rounds."""
        if history.round_number < 2:
            return 0.0
        last_round_rate = np.mean(history.opponent_actions[-1, :])
        if history.round_number >= 3:
            prev_rounds_rate = np.mean(history.opponent_actions[-3:-1, :])
        else:
            prev_rounds_rate = np.mean(history.opponent_actions[:-1, :])
        return last_round_rate - prev_rounds_rate

    def _calculate_dynamic_threshold(self, history: PlayerHistory, recent_cooperation_rate: float, round_num: int) -> float:
        """Calculate the dynamic threshold for cooperation decision."""
        threshold = self.initial_threshold
        cooperation_trend = self._calculate_cooperation_trend(history)
        trend_adjustment = cooperation_trend * 0.2
        efficiency_adjustment = 0.0
        if self.game_description.k > 1.5:
            efficiency_adjustment = -0.1
        group_size_adjustment = 0.0
        if self.game_description.n_players > 6:
            group_size_adjustment = 0.05
        rounds_remaining = self.game_description.n_rounds - round_num + 1
        total_rounds = self.game_description.n_rounds
        if rounds_remaining <= total_rounds * 0.2:
            overall_cooperation = self._calculate_cooperation_rate(history, lookback=total_rounds)
            if overall_cooperation > 0.6:
                rounds_adjustment = -0.1
            else:
                rounds_adjustment = 0.0
        else:
            rounds_adjustment = 0.0
        adjustment_factor = trend_adjustment + efficiency_adjustment + rounds_adjustment
        threshold = max(0.3, min(0.8, threshold + adjustment_factor + group_size_adjustment))
        return threshold

    def _should_forgive(self, history: PlayerHistory) -> bool:
        """Check if forgiveness mechanism should be triggered."""
        if history.round_number < 2:
            return False
        if history.round_number >= 2:
            prev_rate = np.mean(history.opponent_actions[-2, :])
            current_rate = np.mean(history.opponent_actions[-1, :])
            if current_rate - prev_rate > 0.3:
                return True
        if history.round_number >= 2:
            last_two_rates = [np.mean(history.opponent_actions[-2, :]), np.mean(history.opponent_actions[-1, :])]
            if all((rate > 0.7 for rate in last_two_rates)):
                return True
        return False

    def _being_exploited(self, history: PlayerHistory) -> bool:
        """Check if player is being consistently exploited."""
        if history.round_number < 4:
            return False
        my_recent_actions = history.my_actions[-4:]
        opponent_recent_rates = [np.mean(history.opponent_actions[i, :]) for i in range(-4, 0)]
        exploitation_rounds = sum((1 for i in range(4) if my_recent_actions[i] and opponent_recent_rates[i] < 0.3))
        return exploitation_rounds >= 4

    def _update_low_cooperation_mode(self, history: PlayerHistory) -> None:
        """Update low cooperation mode based on recent cooperation rates."""
        if history.round_number < 3:
            return
        recent_rates = [np.mean(history.opponent_actions[i, :]) for i in range(max(0, history.round_number - 3), history.round_number)]
        if all((rate < 0.2 for rate in recent_rates)):
            self.low_cooperation_mode = True
            self.low_cooperation_rounds += 1
        elif history.round_number > 0 and np.mean(history.opponent_actions[-1, :]) > 0.4:
            self.low_cooperation_mode = False
            self.low_cooperation_rounds = 0

class Strategy_COOPERATIVE_17(BaseStrategy):
    """
    Graduated Reciprocator: Adaptive cooperative strategy that balances cooperation 
    with proportional response to group dynamics. Uses dynamic thresholds, forgiveness 
    mechanisms, and trend analysis to maximize collective welfare while protecting 
    against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = state.round_number
        if round_num == 1:
            return Action.C
        if round_num >= self.r - 2:
            return self._endgame_strategy(round_num, history)
        return self._main_adaptive_strategy(history)

    def _main_adaptive_strategy(self, history: PlayerHistory) -> Action:
        prev_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            prev_cooperators += 1
        prev_coop_rate = prev_cooperators / self.n
        hist_avg_coop = self._calculate_historical_average(history)
        threshold = max(0.3, min(0.7, hist_avg_coop - 0.1))
        if prev_coop_rate >= threshold:
            return Action.C
        base_forgiveness = 0.2 + 0.3 * prev_coop_rate
        trend_adjustment = self._calculate_trend_adjustment(history)
        final_forgiveness = max(0.0, min(1.0, base_forgiveness + trend_adjustment))
        return Action.C if random.random() < final_forgiveness else Action.D

    def _endgame_strategy(self, round_num: int, history: PlayerHistory) -> Action:
        hist_avg_coop = self._calculate_historical_average(history)
        if round_num == self.r - 2:
            if hist_avg_coop >= 0.4:
                return Action.C
            elif hist_avg_coop >= 0.2:
                return Action.C if random.random() < 0.6 else Action.D
            else:
                return Action.D
        else:
            prev_cooperators = sum(history.opponent_actions[-1, :])
            if history.my_actions[-1]:
                prev_cooperators += 1
            prev_coop_rate = prev_cooperators / self.n
            if prev_coop_rate >= 0.5:
                return Action.C
            else:
                return Action.C if prev_coop_rate > 0.5 else Action.D

    def _calculate_historical_average(self, history: PlayerHistory) -> float:
        total_rounds = len(history.my_actions)
        if total_rounds == 0:
            return 0.5
        total_cooperation = 0
        for round_idx in range(total_rounds):
            round_cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                round_cooperators += 1
            total_cooperation += round_cooperators / self.n
        return total_cooperation / total_rounds

    def _calculate_trend_adjustment(self, history: PlayerHistory) -> float:
        total_rounds = len(history.my_actions)
        if total_rounds < 3:
            return 0.0
        coop_rates = []
        for i in range(max(0, total_rounds - 3), total_rounds):
            round_cooperators = sum(history.opponent_actions[i, :])
            if history.my_actions[i]:
                round_cooperators += 1
            coop_rates.append(round_cooperators / self.n)
        if len(coop_rates) < 2:
            return 0.0
        if len(coop_rates) >= 2 and coop_rates[-1] > coop_rates[-2]:
            if len(coop_rates) >= 3:
                if coop_rates[-2] > coop_rates[-3]:
                    return 0.2
            return 0.1
        if len(coop_rates) >= 3:
            if coop_rates[-1] < coop_rates[-2] < coop_rates[-3]:
                return -0.1
        return 0.0

class Strategy_COOPERATIVE_18(BaseStrategy):
    """
    Adaptive Cooperative Reciprocator (ACR): A cooperative strategy that balances 
    cooperation with protection against exploitation. Starts cooperative, uses 
    group-based reciprocity with an adaptive threshold, and maintains forgiveness 
    to recover from defection spirals.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        cooperation_rate = last_round_cooperators / n
        threshold = max(0.3, min(0.7, k / n - 0.1))
        if current_round >= r:
            if cooperation_rate >= 0.4:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_19(BaseStrategy):
    """
    Adaptive Cooperative Strategy: "Generous Tit-for-Tat with Forgiveness"
    
    Balances cooperation with self-protection by being initially cooperative, 
    responsive to group behavior, and forgiving of occasional defections.
    Aims to establish and maintain cooperative equilibria while protecting against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number + 1
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        cooperation_rate = last_round_cooperators / n
        adjustment = 0
        if n <= 4:
            adjustment = -0.1
        elif n >= 10:
            adjustment = 0.1
        if k >= n - 0.5:
            adjustment -= 0.1
        elif k <= 1.5:
            adjustment += 0.1
        high_thresh = max(0, min(1, 0.6 + adjustment))
        medium_thresh = max(0, min(1, 0.4 + adjustment))
        low_thresh = max(0, min(1, 0.2 + adjustment))
        if current_round == r:
            return Action.C if cooperation_rate >= 0.5 else Action.D
        trend = 'stable'
        if len(history.my_actions) >= 2:
            prev_cooperators = sum(history.opponent_actions[-2, :])
            if history.my_actions[-2]:
                prev_cooperators += 1
            prev_cooperation_rate = prev_cooperators / n
            if cooperation_rate > prev_cooperation_rate + 0.1:
                trend = 'increasing'
            elif cooperation_rate < prev_cooperation_rate - 0.1:
                trend = 'decreasing'
        was_exploited = False
        if history.my_actions[-1]:
            expected_if_defected = 1 + k / n * (last_round_cooperators - 1)
            was_exploited = history.my_payoffs[-1] < expected_if_defected - 0.1
        cooperation_improvement = 0
        if len(history.my_actions) >= 2:
            prev_cooperators = sum(history.opponent_actions[-2, :])
            if history.my_actions[-2]:
                prev_cooperators += 1
            prev_cooperation_rate = prev_cooperators / n
            cooperation_improvement = cooperation_rate - prev_cooperation_rate
            if not history.my_actions[-1] and cooperation_improvement > 0.2:
                return Action.C
        if cooperation_rate >= high_thresh:
            return Action.C
        if cooperation_rate >= medium_thresh:
            if trend == 'increasing':
                return Action.C
            if was_exploited:
                return Action.D
            return Action.C
        if cooperation_rate >= low_thresh:
            sustained_improvement = False
            if len(history.my_actions) >= 3:
                rates = []
                for i in range(3):
                    round_cooperators = sum(history.opponent_actions[-(i + 1), :])
                    if history.my_actions[-(i + 1)]:
                        round_cooperators += 1
                    rates.append(round_cooperators / n)
                sustained_improvement = rates[0] > rates[1] and rates[1] >= rates[2]
            if sustained_improvement:
                return Action.C
            return Action.D
        return Action.D

class Strategy_COOPERATIVE_20(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation Strategy for N-Player Public Goods Game.
    
    Starts cooperatively, then adapts based on group cooperation rates using
    a dynamic threshold. Implements graduated responses and forgiveness mechanisms
    to balance collective welfare with protection against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        parameter_threshold = (game_description.k - 1) / (game_description.n_players - 1)
        self.cooperation_threshold = max(0.3, parameter_threshold)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = history.round_number
        total_rounds = self.game_description.n_rounds
        if round_num == total_rounds - 1:
            overall_coop_rate = self._calculate_overall_cooperation_rate(history)
            if overall_coop_rate >= self.cooperation_threshold:
                return Action.C
            else:
                return Action.D
        recent_coop_rate = self._calculate_recent_cooperation_rate(history)
        overall_coop_rate = self._calculate_overall_cooperation_rate(history)
        if recent_coop_rate >= self.cooperation_threshold:
            return Action.C
        elif overall_coop_rate >= self.cooperation_threshold and recent_coop_rate >= 0.2:
            if random.random() < 0.7:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate in the last 3 rounds (or all available rounds if fewer)."""
        round_num = history.round_number
        lookback = min(3, round_num)
        if lookback == 0:
            return 0.0
        recent_my_actions = history.my_actions[-lookback:]
        recent_opponent_actions = history.opponent_actions[-lookback:, :]
        my_cooperations = np.sum(recent_my_actions)
        opponent_cooperations = np.sum(recent_opponent_actions)
        total_cooperations = my_cooperations + opponent_cooperations
        total_possible = lookback * self.game_description.n_players
        return total_cooperations / total_possible if total_possible > 0 else 0.0

    def _calculate_overall_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate since round 1."""
        round_num = history.round_number
        if round_num == 0:
            return 0.0
        my_cooperations = np.sum(history.my_actions)
        opponent_cooperations = np.sum(history.opponent_actions)
        total_cooperations = my_cooperations + opponent_cooperations
        total_possible = round_num * self.game_description.n_players
        return total_cooperations / total_possible if total_possible > 0 else 0.0

class Strategy_COOPERATIVE_21(BaseStrategy):
    """
    Graduated Reciprocator: An adaptive cooperative strategy that balances collective welfare 
    with protection against exploitation through graduated responses and forgiveness mechanisms.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = state.round_number
        lookback = min(3, history.round_number)
        recent_rounds = history.opponent_actions[-lookback:, :]
        total_cooperations = 0
        for i in range(lookback):
            round_idx = history.round_number - lookback + i
            total_cooperations += np.sum(recent_rounds[i, :])
            total_cooperations += int(history.my_actions[round_idx])
        recent_coop_rate = total_cooperations / (self.n * lookback)
        if recent_coop_rate >= 0.6:
            threshold = 0.4
        elif recent_coop_rate >= 0.3:
            threshold = 0.5
        else:
            threshold = 0.7
        if history.round_number >= 2:
            last_round_cooperations = np.sum(history.opponent_actions[-1, :]) + int(history.my_actions[-1])
            prev_round_cooperations = np.sum(history.opponent_actions[-2, :]) + int(history.my_actions[-2])
            last_round_rate = last_round_cooperations / self.n
            prev_round_rate = prev_round_cooperations / self.n
            if prev_round_rate < 0.3 and last_round_rate - prev_round_rate >= 0.2:
                threshold -= 0.15
        if self.k > 0.8 * self.n:
            threshold -= 0.1
        elif self.k < 0.4 * self.n:
            threshold += 0.1
        if history.round_number <= 3:
            threshold -= 0.1
        if round_num == self.r:
            return Action.C if recent_coop_rate >= 0.5 else Action.D
        if history.round_number >= 3:
            last_three_rates = []
            for i in range(3):
                round_idx = history.round_number - 3 + i
                round_cooperations = np.sum(history.opponent_actions[round_idx, :]) + int(history.my_actions[round_idx])
                round_rate = round_cooperations / self.n
                last_three_rates.append(round_rate)
            if all((rate < 0.2 for rate in last_three_rates)):
                if round_num % 5 == 0:
                    return Action.C
                else:
                    return Action.D
        return Action.C if recent_coop_rate >= threshold else Action.D

class Strategy_COOPERATIVE_22(BaseStrategy):
    """
    Adaptive Cooperative Strategy: "Graduated Reciprocator"
    
    Balances cooperation with strategic adaptation, starting optimistically but learning 
    from the group's behavior. Uses graduated responses based on group cooperation rates
    with forgiveness mechanisms to prevent defection spirals.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.consecutive_defections = 0
            return Action.C
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        current_round = state.round_number
        total_cooperations = 0
        total_decisions = 0
        for my_action in history.my_actions:
            if my_action:
                total_cooperations += 1
            total_decisions += 1
        for round_idx in range(len(history.my_actions)):
            for player_idx in range(history.opponent_actions.shape[1]):
                if history.opponent_actions[round_idx, player_idx]:
                    total_cooperations += 1
                total_decisions += 1
        group_coop_rate = total_cooperations / total_decisions if total_decisions > 0 else 0
        if current_round == r - 1:
            if group_coop_rate >= 0.5:
                return Action.C
            else:
                return Action.D
        if self.consecutive_defections >= 2:
            recent_coop_found = False
            rounds_to_check = min(2, len(history.my_actions))
            for round_back in range(rounds_to_check):
                round_idx = len(history.my_actions) - 1 - round_back
                if round_idx >= 0:
                    for player_idx in range(history.opponent_actions.shape[1]):
                        if history.opponent_actions[round_idx, player_idx]:
                            recent_coop_found = True
                            break
                if recent_coop_found:
                    break
            if recent_coop_found and random.random() < 0.3:
                self.consecutive_defections = 0
                return Action.C
        if group_coop_rate >= 0.7:
            self.consecutive_defections = 0
            return Action.C
        elif group_coop_rate >= 0.4:
            coop_probability = group_coop_rate + 0.2
            if random.random() < coop_probability:
                self.consecutive_defections = 0
                return Action.C
            else:
                self.consecutive_defections += 1
                return Action.D
        elif group_coop_rate >= 0.2:
            if random.random() < group_coop_rate:
                self.consecutive_defections = 0
                return Action.C
            else:
                self.consecutive_defections += 1
                return Action.D
        else:
            self.consecutive_defections += 1
            return Action.D

class Strategy_COOPERATIVE_23(BaseStrategy):
    """
    Trust-Building Reciprocator: An adaptive cooperative strategy that starts optimistically 
    and maintains cooperation while protecting against exploitation through dynamic thresholds 
    based on group behavior.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        current_round = history.round_number + 1
        recent_cooperation_rate = self._calculate_recent_cooperation_rate(history)
        base_threshold = 0.3
        cooperation_threshold = max(base_threshold, recent_cooperation_rate * 0.8)
        if k > 0.8 * n:
            cooperation_threshold *= 0.9
        elif k < 1.5:
            cooperation_threshold *= 1.1
        if current_round == r:
            return self._final_round_decision(history, cooperation_threshold)
        if r <= 3:
            return self._short_game_decision(history, current_round)
        if recent_cooperation_rate >= cooperation_threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate based on recent rounds with weighted averaging."""
        rounds_completed = history.round_number
        n_opponents = self.game_description.n_players - 1
        if rounds_completed == 1:
            cooperators = sum(history.opponent_actions[-1, :])
            return cooperators / n_opponents
        elif rounds_completed == 2:
            recent_cooperators = sum(history.opponent_actions[-1, :])
            prev_cooperators = sum(history.opponent_actions[-2, :])
            return (recent_cooperators + prev_cooperators) / (2 * n_opponents)
        else:
            weights = [0.5, 0.3, 0.2]
            total_weighted_rate = 0
            for i, weight in enumerate(weights):
                round_idx = -(i + 1)
                if abs(round_idx) <= rounds_completed:
                    cooperators = sum(history.opponent_actions[round_idx, :])
                    cooperation_rate = cooperators / n_opponents
                    total_weighted_rate += weight * cooperation_rate
            return total_weighted_rate

    def _final_round_decision(self, history: PlayerHistory, cooperation_threshold: float) -> Action:
        """Special logic for the final round."""
        n_opponents = self.game_description.n_players - 1
        prev_round_cooperators = sum(history.opponent_actions[-1, :])
        prev_round_rate = prev_round_cooperators / n_opponents
        rounds_completed = history.round_number
        if rounds_completed >= 3:
            last_3_rates = []
            for i in range(3):
                round_idx = -(i + 1)
                cooperators = sum(history.opponent_actions[round_idx, :])
                last_3_rates.append(cooperators / n_opponents)
            avg_last_3 = sum(last_3_rates) / 3
        else:
            total_cooperators = 0
            for i in range(rounds_completed):
                cooperators = sum(history.opponent_actions[i, :])
                total_cooperators += cooperators
            avg_last_3 = total_cooperators / (rounds_completed * n_opponents)
        if prev_round_rate >= 0.5 and avg_last_3 >= 0.4:
            return Action.C
        else:
            return Action.D

    def _short_game_decision(self, history: PlayerHistory, current_round: int) -> Action:
        """Handle very short games (r <= 3)."""
        n_opponents = self.game_description.n_players - 1
        if current_round == 2:
            cooperators = sum(history.opponent_actions[-1, :])
            cooperation_rate = cooperators / n_opponents
            return Action.C if cooperation_rate >= 0.5 else Action.D
        elif current_round == 3:
            cooperators = sum(history.opponent_actions[-1, :])
            cooperation_rate = cooperators / n_opponents
            return Action.C if cooperation_rate >= 0.4 else Action.D
        else:
            recent_cooperation_rate = self._calculate_recent_cooperation_rate(history)
            cooperation_threshold = max(0.3, recent_cooperation_rate * 0.8)
            return Action.C if recent_cooperation_rate >= cooperation_threshold else Action.D

class Strategy_COOPERATIVE_24(BaseStrategy):
    """
    Adaptive Trust Builder - A cooperative strategy that balances trust with protection against exploitation.
    Starts with cooperation, adapts based on community behavior, includes forgiveness mechanisms,
    and maintains a fundamentally cooperative orientation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_number = state.round_number
        ctl = self._calculate_community_trust_level(history)
        threshold = self._calculate_cooperation_threshold()
        if round_number == self.r:
            return Action.C if ctl >= threshold * 0.8 else Action.D
        if ctl > 0.7:
            return Action.C
        if ctl >= threshold:
            return Action.C
        if self._recent_trend_improving(history) and ctl >= threshold * 0.5:
            return Action.C
        if self._is_forgiveness_round(round_number) and ctl > 0.15:
            return Action.C
        if ctl < 0.15 and round_number % 5 == 1:
            return Action.C
        return Action.D

    def _calculate_community_trust_level(self, history: PlayerHistory) -> float:
        """Calculate the overall cooperation rate across all players and rounds."""
        total_rounds = history.round_number
        if total_rounds == 0:
            return 0.0
        my_cooperations = sum(history.my_actions)
        opponent_cooperations = np.sum(history.opponent_actions)
        total_cooperations = my_cooperations + opponent_cooperations
        total_possible = self.n * total_rounds
        return total_cooperations / total_possible

    def _calculate_cooperation_threshold(self) -> float:
        """Calculate dynamic cooperation threshold based on game parameters."""
        base_threshold = max(0.3, 1.0 / self.k)
        size_adjustment = 1.0 - 0.1 * math.log(self.n) / math.log(10)
        cooperation_threshold = base_threshold * size_adjustment
        return max(0.2, cooperation_threshold)

    def _recent_trend_improving(self, history: PlayerHistory) -> bool:
        """Check if recent cooperation trend is improving."""
        total_rounds = history.round_number
        if total_rounds < 4:
            return False
        recent_window = min(3, total_rounds // 2)
        if recent_window < 2:
            return False
        recent_my_coop = sum(history.my_actions[-recent_window:])
        recent_opp_coop = np.sum(history.opponent_actions[-recent_window:, :])
        recent_total = recent_my_coop + recent_opp_coop
        recent_rate = recent_total / (self.n * recent_window)
        prev_start = max(0, total_rounds - 2 * recent_window)
        prev_end = total_rounds - recent_window
        if prev_end <= prev_start:
            return False
        prev_window_size = prev_end - prev_start
        prev_my_coop = sum(history.my_actions[prev_start:prev_end])
        prev_opp_coop = np.sum(history.opponent_actions[prev_start:prev_end, :])
        prev_total = prev_my_coop + prev_opp_coop
        prev_rate = prev_total / (self.n * prev_window_size)
        return recent_rate > prev_rate

    def _is_forgiveness_round(self, round_number: int) -> bool:
        """Check if this is a forgiveness round."""
        if self.n <= 3:
            return round_number % 3 == 1 and round_number > 3
        else:
            return round_number % 4 == 1 and round_number > 4

class Strategy_COOPERATIVE_25(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation Strategy (ARC)
    
    Balances cooperative intent with adaptive response to group behavior using
    optimism, reciprocity, and strategic forgiveness to promote sustained cooperation
    while protecting against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if self.r <= 3:
            if current_round == self.r - 1:
                return self._final_round_decision(history)
            else:
                return Action.C
        if current_round == self.r - 1:
            return self._final_round_decision(history)
        if current_round > 0 and current_round % 4 == 0:
            if len(history.my_actions) > 0 and (not history.my_actions[-1]):
                return Action.C
        return self._adaptive_reciprocation(history)

    def _adaptive_reciprocation(self, history: PlayerHistory) -> Action:
        recent_coop_rate = self._calculate_recent_cooperation_rate(history)
        cooperation_threshold = self._get_cooperation_threshold()
        if recent_coop_rate >= cooperation_threshold:
            return Action.C
        elif recent_coop_rate >= 0.15:
            prob_cooperate = recent_coop_rate / cooperation_threshold
            return Action.C if random.random() < prob_cooperate else Action.D
        else:
            return Action.D

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory) -> float:
        rounds_completed = len(history.my_actions)
        lookback = min(3, rounds_completed)
        if lookback == 0:
            return 1.0
        recent_rounds = history.opponent_actions[-lookback:, :]
        total_cooperators = np.sum(recent_rounds)
        total_possible = self.n * lookback
        return total_cooperators / total_possible if total_possible > 0 else 1.0

    def _get_cooperation_threshold(self) -> float:
        base_threshold = max(0.3, self.k / self.n)
        if self.n > 10:
            base_threshold = max(0.25, self.k / self.n)
        return base_threshold

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        recent_coop_rate = self._calculate_recent_cooperation_rate(history)
        if recent_coop_rate >= 0.4:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_26(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation Strategy (ARC)
    
    Balances cooperative intent with adaptive response to observed behavior patterns.
    Uses weighted cooperation thresholds, forgiveness mechanisms, and reputation tracking
    to maximize collective welfare while protecting against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.base_threshold = 0.4
        self.rounds_since_olive_branch = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = history.round_number
        total_rounds = self.game_description.n_rounds
        n_players = self.game_description.n_players
        if round_num < 3:
            return Action.C
        group_coop_rates = []
        for r in range(round_num):
            round_cooperators = np.sum(history.opponent_actions[r, :])
            if history.my_actions[r]:
                round_cooperators += 1
            group_coop_rates.append(round_cooperators / n_players)
        avg_group_rate = np.mean(group_coop_rates)
        history_adj = 0
        if avg_group_rate > 0.6:
            history_adj = -0.1
        elif avg_group_rate < 0.3:
            history_adj = 0.1
        if round_num >= 6:
            recent_rounds = group_coop_rates[-3:]
            earlier_rounds = group_coop_rates[-6:-3]
            recent_trend = np.mean(recent_rounds) - np.mean(earlier_rounds)
            if recent_trend > 0.1:
                history_adj -= 0.05
        endgame_adj = 0
        if round_num > 0.8 * total_rounds:
            endgame_adj = 0.15
        current_threshold = self.base_threshold + history_adj + endgame_adj
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        last_round_coop_rate = last_round_cooperators / n_players
        self.rounds_since_olive_branch += 1
        if self.rounds_since_olive_branch >= 4 and current_threshold > 0.7:
            if round_num >= 2:
                prev_olive_reciprocated = np.sum(history.opponent_actions[-1, :]) >= n_players * 0.5
                if prev_olive_reciprocated:
                    current_threshold = 0.5
            self.rounds_since_olive_branch = 0
            return Action.C
        if round_num >= 2:
            recent_total_coop = np.sum(history.opponent_actions[-1, :]) + np.sum(history.opponent_actions[-2, :])
            if recent_total_coop == 0:
                if self.rounds_since_olive_branch >= 2:
                    self.rounds_since_olive_branch = 0
                    return Action.C
        if round_num == total_rounds - 1:
            final_threshold = 0.7
            return Action.C if last_round_coop_rate >= final_threshold else Action.D
        individual_coop_rates = []
        for player in range(n_players - 1):
            player_cooperations = np.sum(history.opponent_actions[:, player])
            individual_coop_rates.append(player_cooperations / round_num)
        if abs(last_round_coop_rate - current_threshold) <= 0.05:
            consistent_cooperators = sum((1 for rate in individual_coop_rates if rate > 0.75))
            likely_cooperators = 0
            for player in range(n_players - 1):
                player_rate = individual_coop_rates[player]
                if player_rate > 0.6 and history.opponent_actions[-1, player]:
                    likely_cooperators += 1
                elif player_rate > 0.8:
                    likely_cooperators += 1
            if consistent_cooperators >= (n_players - 1) // 2 or likely_cooperators >= (n_players - 1) // 2:
                return Action.C
            else:
                return Action.D
        else:
            return Action.C if last_round_coop_rate >= current_threshold else Action.D

class Strategy_COOPERATIVE_27(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation (ARC) Strategy
    
    Balances cooperation, reciprocity, and forgiveness while adapting to opponent behavior.
    Uses dynamic thresholds based on game parameters and maintains cooperation when beneficial
    while protecting against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number + 1
        if current_round <= 3:
            return Action.C
        cooperation_threshold = max(0.3, (self.k - 1) / (self.n - 1))
        if current_round <= self.r - 2:
            return self._main_strategy_decision(history, cooperation_threshold)
        elif current_round == self.r - 1:
            recent_coop_rate = self._get_cooperation_rate(history, last_n_rounds=3)
            return Action.C if recent_coop_rate >= 0.5 else Action.D
        else:
            recent_coop_rate = self._get_cooperation_rate(history, last_n_rounds=2)
            return Action.C if recent_coop_rate >= 0.6 else Action.D

    def _main_strategy_decision(self, history: PlayerHistory, cooperation_threshold: float) -> Action:
        """Main strategy logic for rounds 4 to r-2."""
        recent_coop_rate = self._get_cooperation_rate(history, last_n_rounds=3)
        overall_coop_rate = self._get_cooperation_rate(history, since_round=3)
        if recent_coop_rate >= cooperation_threshold:
            return Action.C
        if overall_coop_rate >= cooperation_threshold and recent_coop_rate >= 0.2:
            return Action.C
        if len(history.my_actions) > 0:
            my_last_action = history.my_actions[-1]
            if not my_last_action and recent_coop_rate >= 0.2:
                return Action.C
        return Action.D

    def _get_cooperation_rate(self, history: PlayerHistory, last_n_rounds: int=None, since_round: int=None) -> float:
        """Calculate cooperation rate of opponents over specified period."""
        if len(history.opponent_actions) == 0:
            return 0.0
        if last_n_rounds is not None:
            start_round = max(0, len(history.opponent_actions) - last_n_rounds)
            relevant_actions = history.opponent_actions[start_round:]
        elif since_round is not None:
            if since_round >= len(history.opponent_actions):
                return 0.0
            relevant_actions = history.opponent_actions[since_round:]
        else:
            relevant_actions = history.opponent_actions
        if len(relevant_actions) == 0:
            return 0.0
        total_cooperations = np.sum(relevant_actions)
        total_decisions = relevant_actions.size
        return total_cooperations / total_decisions if total_decisions > 0 else 0.0

class Strategy_COOPERATIVE_28(BaseStrategy):
    """
    Adaptive Cooperative Strategy: "Graduated Reciprocity with Forgiveness"
    
    Balances cooperative intent with adaptive response to opponents' behavior.
    Uses dynamic cooperation thresholds, forgiveness mechanisms, and endgame protection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_number = history.round_number + 1
        recent_rounds = min(3, history.round_number)
        if recent_rounds > 0:
            recent_opponent_actions = history.opponent_actions[-recent_rounds:, :]
            recent_my_actions = history.my_actions[-recent_rounds:]
            total_recent_cooperators = 0
            for i in range(recent_rounds):
                round_cooperators = np.sum(recent_opponent_actions[i, :]) + (1 if recent_my_actions[i] else 0)
                total_recent_cooperators += round_cooperators
            cooperation_rate = total_recent_cooperators / (recent_rounds * self.n)
        else:
            cooperation_rate = 1.0
        threshold = 0.3 + 0.2 * cooperation_rate
        if round_number > 0.25 * self.r:
            early_rounds = max(1, int(0.25 * self.r))
            if history.round_number >= early_rounds:
                early_opponent_actions = history.opponent_actions[:early_rounds, :]
                early_my_actions = history.my_actions[:early_rounds]
                total_early_cooperators = 0
                for i in range(early_rounds):
                    round_cooperators = np.sum(early_opponent_actions[i, :]) + (1 if early_my_actions[i] else 0)
                    total_early_cooperators += round_cooperators
                early_coop_rate = total_early_cooperators / (early_rounds * self.n)
                if early_coop_rate >= 0.6:
                    threshold -= 0.1
        if round_number % 4 == 0:
            recent_check = min(2, history.round_number)
            if recent_check > 0:
                recent_my_actions = history.my_actions[-recent_check:]
                if np.sum(recent_my_actions) == 0:
                    return Action.C
        if round_number > 0.8 * self.r:
            all_opponent_actions = history.opponent_actions
            all_my_actions = history.my_actions
            total_cooperators = 0
            for i in range(history.round_number):
                round_cooperators = np.sum(all_opponent_actions[i, :]) + (1 if all_my_actions[i] else 0)
                total_cooperators += round_cooperators
            overall_coop_rate = total_cooperators / (history.round_number * self.n)
            if overall_coop_rate < 0.4:
                return Action.D
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_29(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation Strategy (ARCS)
    
    Balances collective welfare with protection against exploitation through
    adaptive reciprocity, graduated responses, and forgiveness mechanisms.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        total_rounds = self.game_description.n_rounds
        n_players = self.game_description.n_players
        if current_round == total_rounds:
            prev_coop_rate = self._get_cooperation_rate(history, -1)
            if prev_coop_rate >= 0.4:
                return Action.C
            else:
                return Action.D
        prev_coop_rate = self._get_cooperation_rate(history, -1)
        if current_round <= total_rounds / 3:
            threshold = 0.3
        elif current_round <= 2 * total_rounds / 3:
            threshold = 0.4
        else:
            threshold = 0.5
        if self._should_attempt_forgiveness(history, current_round):
            return Action.C
        if prev_coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _get_cooperation_rate(self, history: PlayerHistory, round_index: int) -> float:
        """Calculate cooperation rate for a specific round."""
        if round_index >= len(history.my_actions) or round_index < -len(history.my_actions):
            return 0.0
        my_coop = 1 if history.my_actions[round_index] else 0
        opponent_coops = sum(history.opponent_actions[round_index, :])
        total_cooperators = my_coop + opponent_coops
        total_players = self.game_description.n_players
        return total_cooperators / total_players

    def _should_attempt_forgiveness(self, history: PlayerHistory, current_round: int) -> bool:
        """Check if we should attempt forgiveness cooperation."""
        if current_round % 4 != 0:
            return False
        rounds_to_check = min(3, len(history.my_actions))
        if rounds_to_check < 2:
            return False
        recent_actions = history.my_actions[-rounds_to_check:]
        defection_count = sum((1 for action in recent_actions if not action))
        return defection_count >= 2

class Strategy_COOPERATIVE_30(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation Strategy (ARCS)
    
    Balances cooperative intent with adaptive protection against exploitation,
    using dynamic thresholds based on observed behavior patterns and game parameters.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.base_threshold = max(0.1, (self.k - 1) / (self.n - 1))
        self.cooperation_rates = []
        self.last_revival_attempt = -10

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        window_size = min(5, max(2, current_round // 3))
        recent_coop_rate = self._calculate_recent_cooperation_rate(history, window_size)
        threshold = self._calculate_dynamic_threshold(current_round, recent_coop_rate)
        if current_round == self.r - 1:
            threshold = threshold - 0.1
        elif current_round == self.r:
            threshold = max(0.3, threshold - 0.2)
        revival_attempt = self._should_attempt_revival(history, current_round)
        if recent_coop_rate >= threshold or revival_attempt:
            return Action.C
        else:
            return Action.D

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory, window_size: int) -> float:
        """Calculate cooperation rate over the sliding window."""
        if history.round_number == 0:
            return 1.0
        start_round = max(0, history.round_number - window_size)
        total_cooperators = 0
        total_possible = 0
        for round_idx in range(start_round, history.round_number):
            my_coop = 1 if history.my_actions[round_idx] else 0
            opponent_coop = sum(history.opponent_actions[round_idx, :])
            total_cooperators += my_coop + opponent_coop
            total_possible += self.n
        if total_possible == 0:
            return 1.0
        return total_cooperators / total_possible

    def _calculate_dynamic_threshold(self, current_round: int, recent_coop_rate: float) -> float:
        """Calculate the dynamic cooperation threshold."""
        time_adjustment = -0.1 * (current_round / self.r)
        trend_adjustment = self._calculate_trend_adjustment(recent_coop_rate)
        size_adjustment = 0
        if self.n <= 4:
            size_adjustment = -0.05
        elif self.n >= 8:
            size_adjustment = 0.05
        efficiency_adjustment = 0
        if self.k > self.n / 2:
            efficiency_adjustment = -0.1
        threshold = self.base_threshold + time_adjustment + trend_adjustment + size_adjustment + efficiency_adjustment
        return max(0.05, min(0.9, threshold))

    def _calculate_trend_adjustment(self, current_rate: float) -> float:
        """Calculate adjustment based on cooperation rate trends."""
        self.cooperation_rates.append(current_rate)
        if len(self.cooperation_rates) > 3:
            self.cooperation_rates = self.cooperation_rates[-3:]
        if len(self.cooperation_rates) < 2:
            return 0
        recent_trend = self.cooperation_rates[-1] - self.cooperation_rates[-2]
        if recent_trend > 0.05:
            return -0.1
        elif recent_trend < -0.05:
            return 0.1
        return 0

    def _should_attempt_revival(self, history: PlayerHistory, current_round: int) -> bool:
        """Determine if we should attempt revival cooperation."""
        if current_round - self.last_revival_attempt < 3:
            return False
        if history.round_number < 3:
            return False
        recent_cooperation = 0
        for round_idx in range(max(0, history.round_number - 3), history.round_number):
            my_coop = 1 if history.my_actions[round_idx] else 0
            opponent_coop = sum(history.opponent_actions[round_idx, :])
            recent_cooperation += my_coop + opponent_coop
        recent_rate = recent_cooperation / (3 * self.n)
        if 0.1 <= recent_rate <= 0.3 and random.random() < 0.3:
            self.last_revival_attempt = current_round
            return True
        return False

class Strategy_COOPERATIVE_31(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS) - balances cooperative intent 
    with adaptive resilience using dynamic thresholds based on observed cooperation levels.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.low_participation_counter = 0
        self.forgiveness_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = history.round_number + 1
        initial_period = max(3, int(self.r * 0.2))
        if round_num <= initial_period:
            return Action.C
        cooperation_rate = self._calculate_cooperation_rate(history)
        threshold = self._calculate_threshold(history, round_num)
        if round_num == self.r:
            return Action.C if cooperation_rate >= 0.4 else Action.D
        if self._detect_low_participation(history):
            if self.low_participation_counter < 2:
                self.low_participation_counter += 1
                return Action.D
            else:
                self.low_participation_counter = 0
                threshold -= 0.1
        if self.forgiveness_counter > 0:
            self.forgiveness_counter -= 1
            return Action.C
        if self._should_trigger_forgiveness(history, cooperation_rate, threshold):
            self.forgiveness_counter = 1
            return Action.C
        if cooperation_rate >= threshold - 0.05:
            return Action.C
        if cooperation_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, window: int=5) -> float:
        """Calculate recent cooperation rate of opponents with reciprocity bonus."""
        if history.round_number == 0:
            return 0.0
        start_idx = max(0, history.round_number - window)
        recent_actions = history.opponent_actions[start_idx:, :]
        if recent_actions.size == 0:
            return 0.0
        total_weighted_cooperations = 0.0
        total_possible = recent_actions.size
        for round_idx in range(recent_actions.shape[0]):
            for player_idx in range(recent_actions.shape[1]):
                cooperation = recent_actions[round_idx, player_idx]
                weight = 1.0
                actual_round = start_idx + round_idx
                if actual_round > 0 and cooperation:
                    prev_action = history.opponent_actions[actual_round - 1, player_idx]
                    if not prev_action:
                        rounds_since_switch = history.round_number - actual_round
                        if rounds_since_switch <= 2:
                            weight = 1.2
                total_weighted_cooperations += cooperation * weight
        return total_weighted_cooperations / total_possible

    def _calculate_threshold(self, history: PlayerHistory, round_num: int) -> float:
        """Calculate dynamic cooperation threshold."""
        efficiency = self.k / self.n
        if efficiency >= 0.4:
            base_threshold = 0.3
        elif efficiency >= 0.25:
            base_threshold = 0.4
        else:
            base_threshold = 0.5
        volatility_adj = self._calculate_volatility_adjustment(history)
        endgame_adj = self._calculate_endgame_adjustment(round_num)
        pattern_adj = self._calculate_pattern_adjustment(history)
        threshold = base_threshold + volatility_adj + endgame_adj + pattern_adj
        if self._is_high_volatility(history):
            threshold += 0.15
        return max(0.0, min(1.0, threshold))

    def _calculate_volatility_adjustment(self, history: PlayerHistory) -> float:
        """Calculate volatility adjustment based on cooperation rate variance."""
        if history.round_number < 5:
            return 0.0
        rates = []
        for i in range(max(0, history.round_number - 5), history.round_number):
            round_cooperations = np.sum(history.opponent_actions[i, :])
            rate = round_cooperations / history.opponent_actions.shape[1]
            rates.append(rate)
        if len(rates) < 2:
            return 0.0
        volatility = np.std(rates)
        return min(0.2, volatility * 0.5)

    def _calculate_endgame_adjustment(self, round_num: int) -> float:
        """Calculate endgame adjustment for final 25% of rounds."""
        rounds_remaining = self.r - round_num
        if rounds_remaining <= self.r / 4:
            return 0.1 * (1 - rounds_remaining / (self.r / 4))
        return 0.0

    def _calculate_pattern_adjustment(self, history: PlayerHistory) -> float:
        """Calculate adjustment based on recent cooperation trends."""
        if history.round_number < 6:
            return 0.0
        recent_start = max(0, history.round_number - 3)
        recent_cooperations = np.sum(history.opponent_actions[recent_start:, :])
        prev_start = max(0, history.round_number - 6)
        prev_end = max(0, history.round_number - 3)
        prev_cooperations = np.sum(history.opponent_actions[prev_start:prev_end, :])
        if prev_cooperations == 0:
            return 0.0
        recent_trend = (recent_cooperations - prev_cooperations) / prev_cooperations
        if recent_trend > 0.2:
            return -0.1
        elif recent_trend < -0.2:
            return 0.1
        return 0.0

    def _detect_low_participation(self, history: PlayerHistory) -> bool:
        """Detect if fewer than 30% of players cooperated in last 3 rounds."""
        if history.round_number < 3:
            return False
        recent_actions = history.opponent_actions[-3:, :]
        total_cooperations = np.sum(recent_actions)
        total_possible = recent_actions.size
        cooperation_rate = total_cooperations / total_possible
        return cooperation_rate < 0.3

    def _is_high_volatility(self, history: PlayerHistory) -> bool:
        """Check if cooperation rates have high volatility."""
        if history.round_number < 5:
            return False
        rates = []
        for i in range(max(0, history.round_number - 7), history.round_number):
            round_cooperations = np.sum(history.opponent_actions[i, :])
            rate = round_cooperations / history.opponent_actions.shape[1]
            rates.append(rate)
        return len(rates) >= 3 and np.std(rates) > 0.3

    def _should_trigger_forgiveness(self, history: PlayerHistory, cooperation_rate: float, threshold: float) -> bool:
        """Check if we should trigger forgiveness mechanism after mutual defection period."""
        if history.round_number < 3 or cooperation_rate < threshold:
            return False
        recent_rates = []
        for i in range(max(0, history.round_number - 3), history.round_number):
            round_cooperations = np.sum(history.opponent_actions[i, :])
            rate = round_cooperations / history.opponent_actions.shape[1]
            recent_rates.append(rate)
        if len(recent_rates) < 2:
            return False
        was_low_cooperation = any((rate < 0.3 for rate in recent_rates[:-1]))
        is_improving = recent_rates[-1] > recent_rates[-2]
        return was_low_cooperation and is_improving and (cooperation_rate >= threshold)

class Strategy_COOPERATIVE_32(BaseStrategy):
    """
    Adaptive Cooperative Strategy: "Generous Tit-for-Tat with Dynamic Threshold"
    
    This strategy aims to maximize collective welfare while protecting against exploitation 
    through adaptive cooperation thresholds and generous forgiveness mechanisms.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        cooperation_threshold = max(0.3, self.k / self.n * 0.8)
        if current_round == self.r - 1:
            cooperation_rate_last_5 = self._get_cooperation_rate_last_n_rounds(history, 5)
            if cooperation_rate_last_5 >= 0.4:
                return Action.C
            else:
                return Action.D
        recent_cooperation_rate = self._get_cooperation_rate_last_n_rounds(history, min(3, current_round))
        personal_cooperation_rate = np.mean(history.my_actions) if current_round > 0 else 1.0
        if recent_cooperation_rate >= cooperation_threshold:
            return Action.C
        elif recent_cooperation_rate >= cooperation_threshold * 0.7 and personal_cooperation_rate >= 0.6:
            return Action.C
        elif self._was_exploited_last_round(history) and recent_cooperation_rate < 0.2:
            return Action.D
        else:
            cooperation_probability = min(0.8, recent_cooperation_rate + 0.2)
            if random.random() < cooperation_probability:
                return Action.C
            else:
                return Action.D

    def _get_cooperation_rate_last_n_rounds(self, history: PlayerHistory, n: int) -> float:
        """Calculate cooperation rate over the last n rounds."""
        if history.round_number == 0:
            return 1.0
        rounds_to_check = min(n, history.round_number)
        if rounds_to_check == 0:
            return 1.0
        recent_opponent_actions = history.opponent_actions[-rounds_to_check:, :]
        total_actions = recent_opponent_actions.size
        total_cooperations = np.sum(recent_opponent_actions)
        return total_cooperations / total_actions if total_actions > 0 else 0.0

    def _was_exploited_last_round(self, history: PlayerHistory) -> bool:
        """Check if we were exploited in the last round."""
        if history.round_number == 0:
            return False
        i_cooperated_last = history.my_actions[-1]
        if not i_cooperated_last:
            return False
        others_cooperation_last = np.mean(history.opponent_actions[-1, :])
        return others_cooperation_last < 0.3

class Strategy_COOPERATIVE_33(BaseStrategy):
    """
    Graduated Reciprocator: An adaptive cooperative strategy that balances cooperation with strategic 
    adaptation. Starts optimistically, uses graduated reciprocation based on cooperation rates, 
    implements forgiveness cycles, and adapts thresholds based on game economics.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.last_cooperation_round = -1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.last_cooperation_round = 0
            return Action.C
        n = self.game_description.n_players
        k = self.game_description.k
        current_round = history.round_number
        total_rounds = self.game_description.n_rounds
        if current_round == total_rounds - 1:
            historical_cooperation_rate = np.sum(history.opponent_actions) / (n * current_round)
            if historical_cooperation_rate >= 0.4:
                return Action.C
            else:
                return Action.D
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        cooperation_rate = last_round_cooperators / n
        total_cooperators_history = np.sum(history.opponent_actions) + np.sum(history.my_actions)
        historical_cooperation_rate = total_cooperators_history / (n * current_round)
        base_threshold = max(0.3, k / n)
        rounds_since_last_cooperation = current_round - self.last_cooperation_round - 1
        if rounds_since_last_cooperation >= 3:
            self.last_cooperation_round = current_round
            return Action.C
        if cooperation_rate >= 0.7:
            self.last_cooperation_round = current_round
            return Action.C
        elif cooperation_rate >= base_threshold:
            if historical_cooperation_rate >= base_threshold:
                self.last_cooperation_round = current_round
                return Action.C
            elif random.random() < cooperation_rate:
                self.last_cooperation_round = current_round
                return Action.C
            else:
                return Action.D
        elif historical_cooperation_rate >= 0.5:
            if random.random() < 0.4:
                self.last_cooperation_round = current_round
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COOPERATIVE_34(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation Strategy (ARC)
    
    Balances forgiveness with accountability, adapting to group cooperation levels
    while maintaining incentives for mutual cooperation. Uses sliding window approach
    with weighted recent vs overall cooperation rates.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number + 1
        if current_round == self.r:
            if history.round_number == 1:
                return Action.C
            total_cooperators = 0
            total_opportunities = 0
            for round_idx in range(1, history.round_number):
                cooperators_in_round = int(np.sum(history.opponent_actions[round_idx, :]))
                total_cooperators += cooperators_in_round
                total_opportunities += self.n - 1
            if total_opportunities > 0:
                overall_gcr = total_cooperators / total_opportunities
                return Action.C if overall_gcr >= 0.5 else Action.D
            else:
                return Action.C
        lookback_rounds = min(3, history.round_number)
        recent_cooperators = 0
        recent_opportunities = 0
        for i in range(lookback_rounds):
            round_idx = history.round_number - 1 - i
            cooperators_in_round = int(np.sum(history.opponent_actions[round_idx, :]))
            recent_cooperators += cooperators_in_round
            recent_opportunities += self.n - 1
        recent_gcr = recent_cooperators / recent_opportunities if recent_opportunities > 0 else 0
        total_cooperators = 0
        total_opportunities = 0
        for round_idx in range(history.round_number):
            cooperators_in_round = int(np.sum(history.opponent_actions[round_idx, :]))
            total_cooperators += cooperators_in_round
            total_opportunities += self.n - 1
        overall_gcr = total_cooperators / total_opportunities if total_opportunities > 0 else 0
        weighted_gcr = 0.7 * recent_gcr + 0.3 * overall_gcr
        base_threshold = (self.n - 1) / self.n
        adjusted_threshold = base_threshold * (1 - 0.1 * (self.k - 1))
        if weighted_gcr >= adjusted_threshold:
            return Action.C
        elif recent_gcr > 0 and current_round <= self.r / 2:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_35(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation Strategy (ARC)
    
    Balances cooperation with protection against exploitation using adaptive reciprocity
    based on observed opponent behavior patterns and game dynamics.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.total_rounds = game_description.n_rounds
        self.currently_defecting_phase = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = history.round_number + 1
        if round_num <= 3:
            return Action.C
        cr = self._calculate_cooperation_rate(history)
        per = self._calculate_personal_exploitation_rate(history)
        if round_num % 5 == 0 and self.currently_defecting_phase:
            self.currently_defecting_phase = False
            return Action.C
        if round_num == self.total_rounds:
            recent_cr = self._calculate_recent_cooperation_rate(history, 3)
            return Action.C if recent_cr >= 0.5 else Action.D
        if round_num == self.total_rounds - 1:
            recent_cr = self._calculate_recent_cooperation_rate(history, 3)
            early_cr = self._calculate_early_cooperation_rate(history, 3)
            weighted_cr = 0.7 * recent_cr + 0.3 * early_cr
            cr = weighted_cr
        if cr < 0.2 and self._check_consecutive_low_cooperation(history, 3):
            self.currently_defecting_phase = True
            return Action.D
        if cr >= 0.6:
            self.currently_defecting_phase = False
            return Action.C
        elif cr >= 0.4 and per <= 0.3:
            self.currently_defecting_phase = False
            return Action.C
        elif self._previous_round_cooperators(history) >= math.ceil(self.n / 2):
            self.currently_defecting_phase = False
            return Action.C
        elif self._recovery_opportunity_detected(history):
            self.currently_defecting_phase = False
            return Action.C
        else:
            self.currently_defecting_phase = True
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate overall cooperation rate of opponents."""
        if history.round_number == 0:
            return 0.0
        total_cooperations = np.sum(history.opponent_actions)
        total_possible = history.round_number * (self.n - 1)
        return total_cooperations / total_possible if total_possible > 0 else 0.0

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory, rounds: int) -> float:
        """Calculate cooperation rate over the last 'rounds' rounds."""
        if history.round_number == 0:
            return 0.0
        start_round = max(0, history.round_number - rounds)
        recent_actions = history.opponent_actions[start_round:, :]
        total_cooperations = np.sum(recent_actions)
        total_possible = recent_actions.shape[0] * (self.n - 1)
        return total_cooperations / total_possible if total_possible > 0 else 0.0

    def _calculate_early_cooperation_rate(self, history: PlayerHistory, recent_rounds: int) -> float:
        """Calculate cooperation rate excluding the last 'recent_rounds' rounds."""
        if history.round_number <= recent_rounds:
            return 0.0
        early_actions = history.opponent_actions[:-recent_rounds, :]
        total_cooperations = np.sum(early_actions)
        total_possible = early_actions.shape[0] * (self.n - 1)
        return total_cooperations / total_possible if total_possible > 0 else 0.0

    def _calculate_personal_exploitation_rate(self, history: PlayerHistory) -> float:
        """Calculate rate of rounds where I cooperated but received below-average payoff."""
        if history.round_number == 0:
            return 0.0
        cooperation_rounds = []
        for round_idx in range(history.round_number):
            if history.my_actions[round_idx]:
                cooperation_rounds.append(round_idx)
        if not cooperation_rounds:
            return 0.0
        avg_payoff = np.mean(history.my_payoffs)
        exploited_rounds = 0
        for round_idx in cooperation_rounds:
            if history.my_payoffs[round_idx] < avg_payoff:
                exploited_rounds += 1
        return exploited_rounds / len(cooperation_rounds)

    def _previous_round_cooperators(self, history: PlayerHistory) -> int:
        """Count cooperators in the previous round."""
        if history.round_number == 0:
            return 0
        return int(np.sum(history.opponent_actions[-1, :]))

    def _recovery_opportunity_detected(self, history: PlayerHistory) -> bool:
        """Check if last round had high cooperation and I defected."""
        if history.round_number == 0:
            return False
        last_round_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        i_defected_last = not history.my_actions[-1]
        return last_round_cooperators >= self.n - 2 and i_defected_last

    def _check_consecutive_low_cooperation(self, history: PlayerHistory, rounds: int) -> bool:
        """Check if cooperation rate has been low for consecutive rounds."""
        if history.round_number < rounds:
            return False
        for i in range(rounds):
            round_idx = history.round_number - 1 - i
            if round_idx < 0:
                return False
            round_cooperators = np.sum(history.opponent_actions[round_idx, :])
            round_cr = round_cooperators / (self.n - 1)
            if round_cr >= 0.2:
                return False
        return True

class Strategy_COOPERATIVE_36(BaseStrategy):
    """
    Adaptive Generous Tit-for-Tat Strategy (AGTT)
    
    Balances cooperation with protection against exploitation using adaptive forgiveness
    and generous reciprocation. Starts cooperative, responds to group cooperation level,
    and maintains resilience against both noise and exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if current_round == self.r - 1:
            total_cooperators = 0
            total_rounds = history.round_number
            for round_idx in range(total_rounds):
                round_cooperators = sum(history.opponent_actions[round_idx, :]) + int(history.my_actions[round_idx])
                total_cooperators += round_cooperators
            avg_cooperation_rate = total_cooperators / (total_rounds * self.n)
            if avg_cooperation_rate >= 0.5:
                return Action.C
            else:
                return Action.D
        last_round_idx = history.round_number - 1
        last_round_cooperators = sum(history.opponent_actions[last_round_idx, :]) + int(history.my_actions[last_round_idx])
        cooperation_rate = last_round_cooperators / self.n
        base_threshold = self.k / self.n
        cooperation_threshold = max(0.3, min(0.7, base_threshold))
        if cooperation_rate >= cooperation_threshold:
            return Action.C
        else:
            generous_threshold = cooperation_threshold - 0.2
            if cooperation_rate >= generous_threshold and random.random() < 0.3:
                return Action.C
            else:
                return Action.D

class Strategy_COOPERATIVE_37(BaseStrategy):
    """
    Adaptive Cooperative Strategy: "Graduated Reciprocator"
    
    Balances cooperation promotion with defection deterrence through adaptive
    reciprocation and forgiveness mechanisms. Starts cooperative, uses graduated
    punishment based on cooperation rates, and includes endgame adjustments.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = history.round_number
        if round_num <= 2:
            return Action.C
        cooperation_threshold = max(0.3, (self.k - 1) / (self.n - 1))
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        current_cooperation_rate = last_round_cooperators / self.n
        rounds_remaining = self.r - round_num - 1
        endgame_threshold = max(3, int(0.2 * self.r))
        is_endgame = rounds_remaining <= endgame_threshold
        if is_endgame and rounds_remaining <= 3:
            recent_rounds = min(3, round_num)
            recent_cooperators = 0
            recent_total = 0
            for i in range(-recent_rounds, 0):
                round_cooperators = sum(history.opponent_actions[i, :])
                if history.my_actions[i]:
                    round_cooperators += 1
                recent_cooperators += round_cooperators
                recent_total += self.n
            if recent_total > 0 and recent_cooperators / recent_total < 0.2:
                return Action.D
        cooperation_trend_improving = False
        if round_num >= 3:
            recent_2_cooperators = 0
            previous_2_cooperators = 0
            for i in range(-2, 0):
                cooperators = sum(history.opponent_actions[i, :])
                if history.my_actions[i]:
                    cooperators += 1
                recent_2_cooperators += cooperators
            if round_num >= 4:
                for i in range(-4, -2):
                    cooperators = sum(history.opponent_actions[i, :])
                    if history.my_actions[i]:
                        cooperators += 1
                    previous_2_cooperators += cooperators
                if previous_2_cooperators > 0:
                    cooperation_trend_improving = recent_2_cooperators > previous_2_cooperators
        rounds_since_last_cooperation = 0
        for i in range(round_num - 1, -1, -1):
            if history.my_actions[i]:
                break
            rounds_since_last_cooperation += 1
        if cooperation_trend_improving and rounds_since_last_cooperation >= 2:
            return Action.C
        if current_cooperation_rate >= cooperation_threshold:
            return Action.C
        else:
            defection_severity = 1.0 - current_cooperation_rate
            forgiveness_factor = min(0.8, rounds_remaining / self.r)
            cooperation_boost = 0.5 if is_endgame else 0.0
            if defection_severity > 0.7:
                defect_prob = (1 - forgiveness_factor) * (1 - cooperation_boost)
                if random.random() < defect_prob:
                    return Action.D
                else:
                    return Action.C
            elif defection_severity > 0.4:
                defect_prob = 0.6 * (1 - forgiveness_factor) * (1 - cooperation_boost)
                if random.random() < defect_prob:
                    return Action.D
                else:
                    return Action.C
            else:
                return Action.C

class Strategy_COOPERATIVE_38(BaseStrategy):
    """
    Graduated Reciprocity with Forgiveness - An adaptive cooperative strategy that balances
    collective welfare with exploitation protection through conditional cooperation,
    graduated responses, and strategic forgiveness mechanisms.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.forgiveness_counter = 0
        self.rounds_since_last_cooperation = 0
        self.last_forgiveness_probe = -5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        current_round = state.round_number + 1
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        coop_rate = last_round_cooperators / n
        if history.my_actions[-1]:
            self.rounds_since_last_cooperation = 0
        else:
            self.rounds_since_last_cooperation += 1
        my_avg_payoff = np.mean(history.my_payoffs)
        all_defect_baseline = 1.0
        defensive_mode = False
        if len(history.my_payoffs) >= 3 and my_avg_payoff < all_defect_baseline:
            defensive_mode = True
        if current_round == r:
            total_cooperators = np.sum(history.opponent_actions) + np.sum(history.my_actions)
            total_possible = len(history.my_actions) * n
            overall_coop_rate = total_cooperators / total_possible
            rounds_to_check = min(3, len(history.my_actions))
            recent_cooperators = np.sum(history.opponent_actions[-rounds_to_check:, :]) + np.sum(history.my_actions[-rounds_to_check:])
            recent_possible = rounds_to_check * n
            recent_coop_rate = recent_cooperators / recent_possible
            if overall_coop_rate >= 0.5 and recent_coop_rate >= 0.4:
                return Action.C
            else:
                return Action.D
        if len(history.my_actions) >= 3:
            recent_my_actions = history.my_actions[-3:]
            recent_coop_rates = []
            for i in range(max(0, len(history.my_actions) - 3), len(history.my_actions)):
                round_cooperators = sum(history.opponent_actions[i, :])
                if history.my_actions[i]:
                    round_cooperators += 1
                recent_coop_rates.append(round_cooperators / n)
            if all(recent_my_actions) and all((rate < 0.2 for rate in recent_coop_rates)):
                return Action.D
        prob_adjustment = 0.2 if n <= 4 else 0.0
        if k > n - 1:
            prob_adjustment += 0.3
        if current_round <= 3:
            if coop_rate >= 0.5:
                return Action.C
            elif history.my_actions[-1] and len(history.my_payoffs) > 0:
                last_round_total_cooperators = sum(history.opponent_actions[-1, :]) + (1 if history.my_actions[-1] else 0)
                avg_payoff_estimate = k / n * last_round_total_cooperators + 0.5
                if history.my_payoffs[-1] >= avg_payoff_estimate:
                    return Action.C
            base_coop_prob = 0.7
            adjusted_prob = min(1.0, base_coop_prob + prob_adjustment)
            if defensive_mode:
                adjusted_prob *= 0.7
            return Action.C if random.random() < adjusted_prob else Action.D
        cooperation_momentum = 0
        if len(history.my_actions) >= 3:
            recent_rounds = min(2, len(history.my_actions) - 1)
            older_rounds = min(2, len(history.my_actions) - recent_rounds - 1)
            if recent_rounds > 0 and older_rounds > 0:
                recent_cooperators = 0
                older_cooperators = 0
                for i in range(recent_rounds):
                    round_idx = len(history.my_actions) - 1 - i
                    round_cooperators = sum(history.opponent_actions[round_idx, :])
                    if history.my_actions[round_idx]:
                        round_cooperators += 1
                    recent_cooperators += round_cooperators / n
                for i in range(older_rounds):
                    round_idx = len(history.my_actions) - 1 - recent_rounds - i
                    if round_idx >= 0:
                        round_cooperators = sum(history.opponent_actions[round_idx, :])
                        if history.my_actions[round_idx]:
                            round_cooperators += 1
                        older_cooperators += round_cooperators / n
                recent_coop_rate = recent_cooperators / recent_rounds
                older_coop_rate = older_cooperators / older_rounds
                cooperation_momentum = recent_coop_rate - older_coop_rate
        self.forgiveness_counter += 1
        forgiveness_threshold = 3 if n <= 4 else 4
        should_forgiveness_probe = False
        if self.forgiveness_counter >= forgiveness_threshold:
            consecutive_low_coop = 0
            for i in range(min(2, len(history.my_actions))):
                round_idx = len(history.my_actions) - 1 - i
                round_cooperators = sum(history.opponent_actions[round_idx, :])
                if history.my_actions[round_idx]:
                    round_cooperators += 1
                if round_cooperators / n < 0.3:
                    consecutive_low_coop += 1
                else:
                    break
            if consecutive_low_coop >= 2 and current_round - self.last_forgiveness_probe > 3:
                should_forgiveness_probe = True
                self.last_forgiveness_probe = current_round
                self.forgiveness_counter = 0
        if should_forgiveness_probe:
            return Action.C
        if coop_rate >= 0.6:
            return Action.C
        elif coop_rate >= 0.4 and cooperation_momentum >= 0:
            return Action.C
        elif coop_rate >= 0.3:
            base_prob = 0.4 + cooperation_momentum
            adjusted_prob = min(1.0, max(0.0, base_prob + prob_adjustment))
            if defensive_mode:
                adjusted_prob *= 0.7
            return Action.C if random.random() < adjusted_prob else Action.D
        elif self.rounds_since_last_cooperation <= 2:
            return Action.D
        else:
            base_prob = 0.25
            adjusted_prob = min(1.0, base_prob + prob_adjustment)
            if defensive_mode:
                adjusted_prob *= 0.5
            return Action.C if random.random() < adjusted_prob else Action.D

class Strategy_COOPERATIVE_39(BaseStrategy):
    """
    Generous Tit-for-Tat with Momentum: An adaptive cooperation strategy that balances 
    initial generosity with self-protection. Uses momentum-based decisions over recent 
    rounds and decreasing forgiveness over time to establish stable cooperation while 
    preventing exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.cooperation_threshold = max(0.3, self.k / self.n - 0.1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number + 1
        if current_round == self.r:
            recent_rounds = min(3, history.round_number)
            cooperation_momentum = 0
            for i in range(max(0, history.round_number - recent_rounds), history.round_number):
                cooperators = sum(history.opponent_actions[i, :])
                if history.my_actions[i]:
                    cooperators += 1
                cooperation_rate = cooperators / self.n
                if cooperation_rate >= self.cooperation_threshold:
                    cooperation_momentum += 1
            return Action.C if cooperation_momentum > 0 else Action.D
        recent_rounds = min(3, history.round_number)
        cooperation_momentum = 0
        defection_momentum = 0
        for i in range(max(0, history.round_number - recent_rounds), history.round_number):
            cooperators = sum(history.opponent_actions[i, :])
            if history.my_actions[i]:
                cooperators += 1
            cooperation_rate = cooperators / self.n
            if cooperation_rate >= self.cooperation_threshold:
                cooperation_momentum += 1
            else:
                defection_momentum += 1
        if current_round <= self.r / 3:
            forgiveness = 0.4
        elif current_round <= 2 * self.r / 3:
            forgiveness = 0.2
        else:
            forgiveness = 0.1
        if cooperation_momentum > defection_momentum:
            return Action.C
        elif cooperation_momentum == defection_momentum:
            if random.random() < self.cooperation_threshold + forgiveness:
                return Action.C
            else:
                return Action.D
        elif random.random() < forgiveness:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_40(BaseStrategy):
    """
    Graduated Reciprocator: An adaptive cooperative strategy that balances collective welfare 
    with protection against exploitation through graduated responses and dynamic cooperation thresholds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.ct_base = self.n / self.k
        self.adaptation_factor = 0.0
        self.last_coop_test_round = -1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = state.round_number
        if round_num == self.r - 1:
            if round_num > 0:
                recent_coop_rate = self._get_recent_cooperation_rate(history, 1)
                if recent_coop_rate > self.ct_base:
                    return Action.C
            return Action.D
        if round_num == self.r - 2:
            current_coop_rate = self._get_recent_cooperation_rate(history, min(5, round_num))
            if current_coop_rate > self.ct_base:
                return Action.C
            return Action.D
        self._update_adaptation_factor(history)
        ct = self.ct_base + self.adaptation_factor
        predicted_cooperators = self._estimate_cooperators(history)
        cooperation_rate = predicted_cooperators / self.n
        if self._should_test_cooperation(history, round_num) and round_num - self.last_coop_test_round >= 3:
            self.last_coop_test_round = round_num
            return Action.C
        if cooperation_rate >= ct:
            return Action.C
        else:
            return Action.D

    def _get_recent_cooperation_rate(self, history: PlayerHistory, window: int) -> float:
        """Calculate cooperation rate over the last 'window' rounds"""
        if history.round_number == 0:
            return 0.0
        start_round = max(0, history.round_number - window)
        my_coops = sum(history.my_actions[start_round:])
        opponent_coops = np.sum(history.opponent_actions[start_round:, :])
        total_coops = my_coops + opponent_coops
        total_possible = (history.round_number - start_round) * self.n
        if total_possible == 0:
            return 0.0
        return total_coops / total_possible

    def _update_adaptation_factor(self, history: PlayerHistory):
        """Update adaptation factor based on recent cooperation trends"""
        if history.round_number < 10:
            return
        window = min(5, max(3, history.round_number // 4))
        recent_coop_rate = self._get_recent_cooperation_rate(history, window)
        prev_start = max(0, history.round_number - 2 * window)
        prev_end = max(1, history.round_number - window)
        if prev_end > prev_start:
            my_prev_coops = sum(history.my_actions[prev_start:prev_end])
            opponent_prev_coops = np.sum(history.opponent_actions[prev_start:prev_end, :])
            prev_total = my_prev_coops + opponent_prev_coops
            prev_possible = (prev_end - prev_start) * self.n
            prev_coop_rate = prev_total / prev_possible if prev_possible > 0 else 0.0
        else:
            prev_coop_rate = recent_coop_rate
        if recent_coop_rate > self.ct_base + 0.1:
            self.adaptation_factor = max(-0.1, self.adaptation_factor - 0.05)
        elif recent_coop_rate < self.ct_base - 0.1:
            self.adaptation_factor = min(0.2, self.adaptation_factor + 0.05)

    def _estimate_cooperators(self, history: PlayerHistory) -> float:
        """Estimate how many players (including self) will cooperate this round"""
        if history.round_number == 0:
            return self.n * 0.7
        predicted = 1.0
        look_back = min(3, history.round_number)
        for player_idx in range(history.opponent_actions.shape[1]):
            player_actions = history.opponent_actions[-look_back:, player_idx]
            coop_rate = np.mean(player_actions)
            if coop_rate >= 0.7:
                predicted += 1.0
            elif coop_rate <= 0.3:
                predicted += coop_rate * 0.5
            elif self._has_alternating_pattern(player_actions):
                predicted += 0.5
            else:
                predicted += coop_rate
        return min(predicted, self.n)

    def _has_alternating_pattern(self, actions: NDArray[np.bool_]) -> bool:
        """Check if a player has an alternating cooperation pattern"""
        if len(actions) < 2:
            return False
        alternations = 0
        for i in range(1, len(actions)):
            if actions[i] != actions[i - 1]:
                alternations += 1
        return alternations >= len(actions) - 1

    def _should_test_cooperation(self, history: PlayerHistory, round_num: int) -> bool:
        """Determine if we should test cooperation after a period of defection"""
        if history.round_number < 3:
            return False
        recent_my_actions = history.my_actions[-3:]
        if np.mean(recent_my_actions) > 0.5:
            return False
        recent_coop_rate = self._get_recent_cooperation_rate(history, 3)
        return recent_coop_rate > self.ct_base - 0.05 or round_num - self.last_coop_test_round >= 4

class Strategy_COOPERATIVE_41(BaseStrategy):
    """
    Graduated Reciprocator: An adaptive cooperative strategy that balances optimistic cooperation 
    with strategic learning. Starts by cooperating, then adapts based on group cooperation patterns
    with forgiveness mechanisms and exploitation protection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_number = state.round_number
        rounds_played = history.round_number
        total_cooperations = self._count_total_cooperations(history)
        cooperation_rate = total_cooperations / (self.n * rounds_played)
        if rounds_played >= 2:
            recent_cooperations = self._count_recent_cooperations(history, 2)
            recent_cooperation_rate = recent_cooperations / (self.n * min(2, rounds_played))
        else:
            recent_cooperation_rate = cooperation_rate
        health_metric = 0.7 * cooperation_rate + 0.3 * recent_cooperation_rate
        if rounds_played >= 4:
            old_period_rate = self._count_cooperations_in_period(history, rounds_played - 4, rounds_played - 3)
            recent_period_rate = self._count_cooperations_in_period(history, rounds_played - 2, rounds_played - 1)
            if recent_period_rate > old_period_rate:
                health_metric = min(1.0, health_metric + 0.1)
        if round_number == self.r:
            return Action.C if cooperation_rate >= 0.5 else Action.D
        if health_metric >= 0.6:
            my_last_action = history.my_actions[-1]
            others_cooperated_last = sum(history.opponent_actions[-1, :])
            if my_last_action and others_cooperated_last < self.n / 3:
                return Action.D
            else:
                return Action.C
        elif health_metric >= 0.3:
            others_cooperated_last = sum(history.opponent_actions[-1, :])
            if others_cooperated_last > 2 * self.n / 3:
                return Action.C
            elif others_cooperated_last >= self.n / 2:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _count_total_cooperations(self, history: PlayerHistory) -> int:
        """Count total cooperations from all players across all rounds."""
        my_cooperations = sum(history.my_actions)
        opponent_cooperations = np.sum(history.opponent_actions)
        return int(my_cooperations + opponent_cooperations)

    def _count_recent_cooperations(self, history: PlayerHistory, num_rounds: int) -> int:
        """Count cooperations in the last num_rounds rounds."""
        rounds_to_check = min(num_rounds, len(history.my_actions))
        my_recent = sum(history.my_actions[-rounds_to_check:])
        opponent_recent = np.sum(history.opponent_actions[-rounds_to_check:, :])
        return int(my_recent + opponent_recent)

    def _count_cooperations_in_period(self, history: PlayerHistory, start_round: int, end_round: int) -> float:
        """Count cooperation rate in a specific period of rounds."""
        if start_round < 0 or end_round >= len(history.my_actions):
            return 0.0
        period_length = end_round - start_round + 1
        my_cooperations = sum(history.my_actions[start_round:end_round + 1])
        opponent_cooperations = np.sum(history.opponent_actions[start_round:end_round + 1, :])
        total_cooperations = my_cooperations + opponent_cooperations
        return total_cooperations / (self.n * period_length)

class Strategy_COOPERATIVE_42(BaseStrategy):
    """
    Adaptive Tit-for-Majority Strategy (ATFM)
    
    Balances cooperative intent with adaptive protection against exploitation.
    Starts cooperative, follows majority behavior with forgiveness mechanism,
    and protects against exploitation through payoff monitoring.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.forgave_last_round = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.forgave_last_round = False
            return Action.C
        current_round = state.round_number
        if current_round == self.r - 1:
            return self._final_round_decision(history)
        if self._is_being_exploited(history):
            self.forgave_last_round = False
            return Action.D
        return self._majority_based_decision(history)

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """Final round: cooperate only if strong cooperative pattern exists"""
        recent_coop_rate = self._get_recent_cooperation_rate(history, 3)
        return Action.C if recent_coop_rate > 0.6 else Action.D

    def _majority_based_decision(self, history: PlayerHistory) -> Action:
        """Main decision logic based on majority cooperation"""
        last_round_coop_rate = self._get_last_round_cooperation_rate(history)
        threshold = 0.6 if self.n <= 4 else 0.5
        if last_round_coop_rate > threshold:
            self.forgave_last_round = False
            return Action.C
        elif self._should_forgive(history):
            self.forgave_last_round = True
            return Action.C
        else:
            self.forgave_last_round = False
            return Action.D

    def _get_last_round_cooperation_rate(self, history: PlayerHistory) -> float:
        """Get cooperation rate of other players in the last round"""
        if len(history.opponent_actions) == 0:
            return 0.0
        last_round_actions = history.opponent_actions[-1, :]
        cooperators = np.sum(last_round_actions)
        return cooperators / (self.n - 1)

    def _get_recent_cooperation_rate(self, history: PlayerHistory, rounds: int) -> float:
        """Get average cooperation rate over recent rounds"""
        if len(history.opponent_actions) == 0:
            return 0.0
        start_round = max(0, len(history.opponent_actions) - rounds)
        recent_actions = history.opponent_actions[start_round:, :]
        total_actions = recent_actions.size
        if total_actions == 0:
            return 0.0
        total_cooperators = np.sum(recent_actions)
        return total_cooperators / total_actions

    def _should_forgive(self, history: PlayerHistory) -> bool:
        """Check if should forgive first transition from cooperation to defection"""
        if self.forgave_last_round:
            return False
        if len(history.opponent_actions) < 2:
            return False
        current_coop_rate = self._get_last_round_cooperation_rate(history)
        threshold = 0.6 if self.n <= 4 else 0.5
        if current_coop_rate > threshold:
            return False
        prev_round_actions = history.opponent_actions[-2, :]
        prev_coop_rate = np.sum(prev_round_actions) / (self.n - 1)
        return prev_coop_rate > threshold

    def _is_being_exploited(self, history: PlayerHistory) -> bool:
        """Check if being exploited based on relative payoffs over recent rounds"""
        window = 3
        if len(history.my_payoffs) < window:
            return False
        my_recent_payoffs = history.my_payoffs[-window:]
        opponent_recent_payoffs = history.opponent_payoffs[-window:, :]
        my_avg = np.mean(my_recent_payoffs)
        opponents_avg = np.mean(opponent_recent_payoffs)
        return my_avg < opponents_avg * 0.9

class Strategy_COOPERATIVE_43(BaseStrategy):
    """
    Adaptive Cooperative Strategy: "Graduated Reciprocator"
    
    Balances cooperation with strategic adaptation, starting optimistically but responding 
    proportionally to collective behavior. Uses graduated response, forgiveness mechanisms,
    and parameter-sensitive optimization.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.k_n_ratio = self.k / self.n
        if self.k_n_ratio > 0.4:
            self.optimism_bonus = 0.3
        elif self.k_n_ratio < 0.25:
            self.optimism_bonus = 0.15
        else:
            self.optimism_bonus = 0.2
        self.min_cooperation = 0.05 if self.n > 10 else 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = state.round_number
        current_round = round_num + 1
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        cooperation_rate = last_round_cooperators / (self.n - 1)
        if current_round <= 3:
            if current_round == 1:
                return Action.C
            else:
                return Action.C if cooperation_rate > 0.2 else Action.D
        if current_round > self.r - 2:
            if current_round == self.r - 1:
                cooperation_prob = max(self.min_cooperation, min(0.9, cooperation_rate + 0.1))
            else:
                return Action.C if cooperation_rate >= 0.4 else Action.D
        else:
            cooperation_prob = max(self.min_cooperation, min(0.9, cooperation_rate + self.optimism_bonus))
        if round_num >= 2:
            recent_rates = []
            for i in range(max(0, round_num - 2), round_num):
                round_cooperators = sum(history.opponent_actions[i, :])
                recent_rates.append(round_cooperators / (self.n - 1))
            if len([r for r in recent_rates if r < 0.1]) >= 2:
                cooperation_prob *= 0.5
                cooperation_prob = max(self.min_cooperation, cooperation_prob)
        if round_num >= 2:
            recent_high_rates = []
            for i in range(max(0, round_num - 2), round_num):
                round_cooperators = sum(history.opponent_actions[i, :])
                recent_high_rates.append(round_cooperators / (self.n - 1))
            if len([r for r in recent_high_rates if r > 0.8]) >= 2:
                cooperation_prob = 0.95
        if current_round % 4 == 0 and round_num >= 3:
            recent_low_cooperation = 0
            for i in range(max(0, round_num - 3), round_num):
                round_cooperators = sum(history.opponent_actions[i, :])
                rate = round_cooperators / (self.n - 1)
                if rate < 0.3:
                    recent_low_cooperation += 1
            if recent_low_cooperation >= 3:
                return Action.C
        return Action.C if random.random() < cooperation_prob else Action.D

class Strategy_COOPERATIVE_44(BaseStrategy):
    """
    Adaptive Cooperative Strategy: "Graduated Reciprocator"
    
    This strategy aims to maximize collective welfare while protecting against exploitation
    through adaptive reciprocation and gradual trust-building. It starts cooperative but
    learns from the group's behavior, using threshold-based cooperation with adaptive
    mechanisms for forgiveness, momentum detection, and anti-exploitation protection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = history.round_number + 1
        last_round_coop_rate = self._get_cooperation_rate(history, -1)
        avg_coop_rate = self._get_average_cooperation_rate(history)
        base_threshold = self._adjust_for_group_size(0.5)
        threshold = self._adapt_threshold(base_threshold, avg_coop_rate)
        if round_num <= 3:
            threshold = min(threshold, 0.3)
        if self._check_exploitation_protection(history):
            return Action.D
        if last_round_coop_rate < threshold and self._recent_trend_was_cooperative(history):
            return Action.C
        if self._increasing_cooperation_trend(history):
            return Action.C
        if round_num == self.r:
            return self._last_round_decision(history)
        if self._should_attempt_recovery(history):
            if random.random() < 0.2:
                return Action.C
        if last_round_coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _get_cooperation_rate(self, history: PlayerHistory, round_idx: int) -> float:
        """Get cooperation rate for a specific round (including self)."""
        if round_idx >= history.round_number or round_idx < -history.round_number:
            return 0.0
        opponent_cooperators = np.sum(history.opponent_actions[round_idx, :])
        my_cooperation = 1 if history.my_actions[round_idx] else 0
        total_cooperators = opponent_cooperators + my_cooperation
        return total_cooperators / self.n

    def _get_average_cooperation_rate(self, history: PlayerHistory) -> float:
        """Get average cooperation rate across all completed rounds."""
        if history.round_number == 0:
            return 0.5
        total_cooperation = 0
        for round_idx in range(history.round_number):
            total_cooperation += self._get_cooperation_rate(history, round_idx)
        return total_cooperation / history.round_number

    def _adjust_for_group_size(self, base_threshold: float) -> float:
        """Adjust threshold based on group size."""
        if self.n <= 4:
            return 0.4
        elif self.n > 8:
            return 0.6
        else:
            return base_threshold

    def _adapt_threshold(self, base_threshold: float, avg_coop_rate: float) -> float:
        """Adapt threshold based on historical cooperation rate."""
        adjustment = (avg_coop_rate - 0.5) * 0.1
        new_threshold = base_threshold + adjustment
        return max(0.2, min(0.8, new_threshold))

    def _recent_trend_was_cooperative(self, history: PlayerHistory) -> bool:
        """Check if recent trend was cooperative (forgiveness condition)."""
        if history.round_number < 3:
            return False
        recent_rounds = min(2, history.round_number - 1)
        cooperative_rounds = 0
        for i in range(recent_rounds):
            round_idx = -(i + 2)
            if self._get_cooperation_rate(history, round_idx) > 0.6:
                cooperative_rounds += 1
        return cooperative_rounds >= recent_rounds

    def _increasing_cooperation_trend(self, history: PlayerHistory) -> bool:
        """Check if cooperation has been increasing for 3+ consecutive rounds."""
        if history.round_number < 3:
            return False
        rounds_to_check = min(3, history.round_number)
        rates = []
        for i in range(rounds_to_check):
            round_idx = -(i + 1)
            rates.append(self._get_cooperation_rate(history, round_idx))
        rates.reverse()
        for i in range(1, len(rates)):
            if rates[i] <= rates[i - 1]:
                return False
        return True

    def _check_exploitation_protection(self, history: PlayerHistory) -> bool:
        """Check if anti-exploitation protection should trigger."""
        if history.round_number < 3:
            return False
        consecutive_low_rounds = 0
        for i in range(min(3, history.round_number)):
            round_idx = -(i + 1)
            if self._get_cooperation_rate(history, round_idx) < 0.15:
                consecutive_low_rounds += 1
            else:
                break
        return consecutive_low_rounds >= 3

    def _should_attempt_recovery(self, history: PlayerHistory) -> bool:
        """Check if we should attempt recovery after prolonged mutual defection."""
        if history.round_number < 5:
            return False
        consecutive_defection_rounds = 0
        for i in range(min(5, history.round_number)):
            round_idx = -(i + 1)
            if self._get_cooperation_rate(history, round_idx) < 0.2:
                consecutive_defection_rounds += 1
            else:
                break
        return consecutive_defection_rounds >= 5

    def _last_round_decision(self, history: PlayerHistory) -> Action:
        """Make decision for the last round based on expected value calculation."""
        recent_coop_rate = self._get_cooperation_rate(history, -1)
        expected_others_cooperating = (self.n - 1) * recent_coop_rate
        payoff_cooperate = 0 + self.k / self.n * (expected_others_cooperating + 1)
        payoff_defect = 1 + self.k / self.n * expected_others_cooperating
        return Action.C if payoff_cooperate >= payoff_defect else Action.D

class Strategy_COOPERATIVE_45(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation Strategy (ARCS) that balances cooperation 
    with protection against exploitation using adaptive thresholds and graduated responses.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        last_round_coop_rate = self._calculate_last_round_cooperation_rate(history)
        avg_coop_rate = self._calculate_average_cooperation_rate(history)
        cooperation_threshold = max(0.3, min(0.7, avg_coop_rate * 1.2))
        if state.round_number == self.game_description.n_rounds - 1:
            return Action.C if last_round_coop_rate >= 0.5 else Action.D
        if self._consecutive_defections(history) >= 2 and last_round_coop_rate >= 0.4:
            return Action.C
        if last_round_coop_rate >= cooperation_threshold:
            return Action.C
        elif self._my_last_action_was_cooperate(history) and last_round_coop_rate > 0:
            return Action.C
        else:
            return Action.D

    def _calculate_last_round_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate the cooperation rate in the most recent round."""
        if len(history.my_actions) == 0:
            return 0.0
        last_round_idx = -1
        my_last_action = history.my_actions[last_round_idx]
        opponent_cooperators = np.sum(history.opponent_actions[last_round_idx, :])
        total_cooperators = opponent_cooperators + (1 if my_last_action else 0)
        total_players = self.game_description.n_players
        return total_cooperators / total_players

    def _calculate_average_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate the average cooperation rate across all completed rounds."""
        if len(history.my_actions) == 0:
            return 0.0
        total_cooperations = 0
        total_decisions = 0
        for round_idx in range(len(history.my_actions)):
            if history.my_actions[round_idx]:
                total_cooperations += 1
            total_cooperations += np.sum(history.opponent_actions[round_idx, :])
            total_decisions += self.game_description.n_players
        return total_cooperations / total_decisions if total_decisions > 0 else 0.0

    def _consecutive_defections(self, history: PlayerHistory) -> int:
        """Count consecutive defections from the end of my action history."""
        if len(history.my_actions) == 0:
            return 0
        consecutive = 0
        for i in range(len(history.my_actions) - 1, -1, -1):
            if not history.my_actions[i]:
                consecutive += 1
            else:
                break
        return consecutive

    def _my_last_action_was_cooperate(self, history: PlayerHistory) -> bool:
        """Check if my last action was cooperate."""
        if len(history.my_actions) == 0:
            return False
        return bool(history.my_actions[-1])

class Strategy_COOPERATIVE_46(BaseStrategy):
    """
    Adaptive Cooperative Strategy: "Generous Tit-for-Tat with Social Learning"
    
    This strategy fosters cooperation while protecting against exploitation through
    adaptive learning and generous reciprocity. It balances optimism about cooperation
    with realistic responses to defection patterns.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if current_round == self.r - 1:
            total_cooperations = 0
            total_possible = 0
            for round_idx in range(len(history.my_actions)):
                if history.my_actions[round_idx]:
                    total_cooperations += 1
                total_cooperations += np.sum(history.opponent_actions[round_idx, :])
                total_possible += self.n
            overall_coop_rate = total_cooperations / total_possible if total_possible > 0 else 0
            return Action.C if overall_coop_rate >= 0.4 else Action.D
        last_round_idx = len(history.my_actions) - 1
        my_last_action = history.my_actions[last_round_idx]
        opponent_last_actions = history.opponent_actions[last_round_idx, :]
        cooperators_last_round = int(my_last_action) + np.sum(opponent_last_actions)
        prev_coop_rate = cooperators_last_round / self.n
        times_i_cooperated = 0
        times_others_reciprocated = 0
        for round_idx in range(len(history.my_actions)):
            if history.my_actions[round_idx]:
                times_i_cooperated += 1
                times_others_reciprocated += np.sum(history.opponent_actions[round_idx, :])
        reciprocity_score = times_others_reciprocated / (times_i_cooperated * (self.n - 1)) if times_i_cooperated > 0 else 0
        if prev_coop_rate >= 0.5:
            return Action.C
        elif prev_coop_rate >= 1.0 / self.n:
            if reciprocity_score >= 0.3 or random.random() < 0.3:
                return Action.C
            else:
                return Action.D
        elif reciprocity_score >= 0.5:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_47(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation (ARC) Strategy.
    
    Begins cooperatively, then adapts based on group behavior using cooperation
    thresholds, recent trends, and exploitation protection. Balances collective
    welfare with defection deterrence through probabilistic decisions.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.initial_phase_rounds = max(1, math.floor(0.2 * self.r))
        self.endgame_phase_start = math.ceil(0.8 * self.r)
        if self.r <= 5:
            self.initial_phase_rounds = 1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number
        if self.r <= 3:
            if current_round == 0:
                return Action.C
            elif current_round == 1:
                if np.any(history.opponent_actions[0, :]):
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D
        if current_round == self.r - 1:
            return Action.D
        if current_round < self.initial_phase_rounds:
            return Action.C
        total_actions = (current_round + 1) * self.n
        my_cooperations = np.sum(history.my_actions)
        opponent_cooperations = np.sum(history.opponent_actions)
        total_cooperations = my_cooperations + opponent_cooperations
        group_coop_rate = total_cooperations / total_actions
        if current_round >= self.endgame_phase_start:
            lookback = min(3, current_round + 1)
            recent_my_coop = np.sum(history.my_actions[-lookback:])
            recent_opp_coop = np.sum(history.opponent_actions[-lookback:, :])
            recent_total_coop = recent_my_coop + recent_opp_coop
            recent_total_actions = lookback * self.n
            recent_coop_rate = recent_total_coop / recent_total_actions
            if recent_coop_rate >= 0.6:
                return Action.C
            elif recent_coop_rate >= 0.3:
                return Action.C if random.random() < 0.5 else Action.D
            else:
                return Action.D
        if group_coop_rate >= 0.7:
            base_prob = 0.9
        elif group_coop_rate >= 0.5:
            base_prob = 0.7
        elif group_coop_rate >= 0.3:
            base_prob = 0.4
        else:
            base_prob = 0.2
        recent_rounds = min(3, current_round + 1)
        recent_my_coop = np.sum(history.my_actions[-recent_rounds:])
        recent_opp_coop = np.sum(history.opponent_actions[-recent_rounds:, :])
        recent_total_coop = recent_my_coop + recent_opp_coop
        recent_total_actions = recent_rounds * self.n
        recent_rate = recent_total_coop / recent_total_actions
        trend_adjustment = 0
        if recent_rate > group_coop_rate + 0.1:
            trend_adjustment = 0.15
        elif recent_rate < group_coop_rate - 0.1:
            trend_adjustment = -0.15
        exploitation_adjustment = 0
        if current_round > 0:
            last_round_opponents_coop = history.opponent_actions[-1, :]
            last_round_my_action = history.my_actions[-1]
            if last_round_my_action and (not np.any(last_round_opponents_coop)):
                exploitation_adjustment = -0.2
            elif last_round_my_action and np.mean(last_round_opponents_coop) < 0.3:
                exploitation_adjustment = -0.1
        k_adjustment = 0
        if self.k > 0.8 * self.n:
            k_adjustment = 0.1
        elif self.k < 0.4 * self.n:
            k_adjustment = -0.1
        final_prob = base_prob + trend_adjustment + exploitation_adjustment + k_adjustment
        final_prob = max(0, min(1, final_prob))
        return Action.C if random.random() < final_prob else Action.D

class Strategy_COOPERATIVE_48(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Forgiveness (ATTF) Strategy.
    
    Balances cooperation with protection against exploitation by adapting to 
    the overall cooperation level while maintaining a fundamentally cooperative stance.
    Uses cooperation thresholds, forgiveness mechanisms, and history-aware decisions.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.consecutive_low_coop = 0
        self.threshold = 0.3 if game_description.k / game_description.n_players > 0.5 else 0.4

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.consecutive_low_coop = 0
            return Action.C
        n = self.game_description.n_players
        current_round = state.round_number
        total_rounds = self.game_description.n_rounds
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        coop_rate = last_round_cooperators / n
        if current_round == total_rounds - 1:
            historical_good_rounds = 0
            for round_idx in range(len(history.my_actions)):
                round_cooperators = sum(history.opponent_actions[round_idx, :])
                if history.my_actions[round_idx]:
                    round_cooperators += 1
                if round_cooperators / n >= self.threshold:
                    historical_good_rounds += 1
            if coop_rate >= self.threshold or historical_good_rounds > current_round / 2:
                return Action.C
            else:
                return Action.D
        if coop_rate >= self.threshold:
            self.consecutive_low_coop = 0
            return Action.C
        else:
            self.consecutive_low_coop += 1
            if self.consecutive_low_coop <= 2:
                return Action.C
            else:
                return Action.D

class Strategy_COOPERATIVE_49(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation (ARC) Strategy
    
    Establishes cooperation through graduated reciprocity, starting optimistically
    but adapting based on observed cooperation levels and trends. Balances
    exploitation protection with long-term cooperation incentives.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number + 1
        if current_round <= 2:
            return Action.C
        if self.r <= 5:
            return self._main_phase_decision(history)
        if current_round >= self.r - 1:
            return self._endgame_decision(history, current_round)
        return self._main_phase_decision(history)

    def _main_phase_decision(self, history: PlayerHistory) -> Action:
        """Main phase cooperation threshold strategy."""
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        cooperation_rate = last_round_cooperators / self.n
        recent_trend = self._calculate_trend(history)
        i_defected_last = not history.my_actions[-1]
        if cooperation_rate >= 0.5:
            return Action.C
        elif cooperation_rate >= 0.3 and recent_trend >= 0:
            return Action.C
        elif cooperation_rate < 0.3 and i_defected_last and (recent_trend > 0.1):
            return Action.C
        else:
            return Action.D

    def _endgame_decision(self, history: PlayerHistory, current_round: int) -> Action:
        """Conditional final cooperation for last 2 rounds."""
        overall_coop_rate = self._calculate_overall_cooperation_rate(history)
        if current_round == self.r - 1:
            return Action.C if overall_coop_rate >= 0.4 else Action.D
        else:
            last_round_cooperators = sum(history.opponent_actions[-1, :])
            if history.my_actions[-1]:
                last_round_cooperators += 1
            last_round_coop_rate = last_round_cooperators / self.n
            if overall_coop_rate >= 0.6 and last_round_coop_rate >= 0.5:
                return Action.C
            else:
                return Action.D

    def _calculate_trend(self, history: PlayerHistory) -> float:
        """Calculate cooperation trend (recent 3 rounds vs previous 3 rounds)."""
        rounds_played = len(history.my_actions)
        if rounds_played < 6:
            if rounds_played < 3:
                return 0.0
            recent_avg = self._get_avg_cooperation_rate(history, max(0, rounds_played - 3), rounds_played)
            early_avg = self._get_avg_cooperation_rate(history, 0, min(3, rounds_played))
            return recent_avg - early_avg
        recent_avg = self._get_avg_cooperation_rate(history, rounds_played - 3, rounds_played)
        previous_avg = self._get_avg_cooperation_rate(history, rounds_played - 6, rounds_played - 3)
        return recent_avg - previous_avg

    def _get_avg_cooperation_rate(self, history: PlayerHistory, start_idx: int, end_idx: int) -> float:
        """Get average cooperation rate for a range of rounds."""
        if start_idx >= end_idx:
            return 0.0
        total_cooperators = 0
        total_players = 0
        for round_idx in range(start_idx, end_idx):
            if round_idx < len(history.my_actions):
                round_cooperators = sum(history.opponent_actions[round_idx, :])
                if history.my_actions[round_idx]:
                    round_cooperators += 1
                total_cooperators += round_cooperators
                total_players += self.n
        return total_cooperators / total_players if total_players > 0 else 0.0

    def _calculate_overall_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate overall cooperation rate across all rounds."""
        return self._get_avg_cooperation_rate(history, 0, len(history.my_actions))

class Strategy_COOPERATIVE_50(BaseStrategy):
    """
    Adaptive Cooperative Strategy: Graduated Reciprocator
    
    Balances cooperation with protection against exploitation using graduated responses
    and maintaining a cooperative default while adapting to group behavior patterns.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number + 1
        if current_round == self.r:
            group_coop_rate = self._get_group_coop_rate(history, -1)
            recent_trend = self._get_recent_trend(history)
            if group_coop_rate >= 0.7 and recent_trend >= 0.6:
                return Action.C
            else:
                return Action.D
        return self._adaptive_reciprocation(history)

    def _adaptive_reciprocation(self, history: PlayerHistory) -> Action:
        group_coop_rate = self._get_group_coop_rate(history, -1)
        recent_trend = self._get_recent_trend(history)
        my_exploitation = self._calculate_exploitation(history)
        if recent_trend >= 0.6:
            base_threshold = 0.4
        elif recent_trend >= 0.3:
            base_threshold = 0.5
        else:
            base_threshold = 0.7
        adjusted_threshold = base_threshold
        if my_exploitation >= 2:
            adjusted_threshold += 0.2
        if len(history.my_actions) >= 2:
            previous_trend = self._get_recent_trend(history, exclude_last=True)
            if recent_trend > previous_trend + 0.15:
                adjusted_threshold -= 0.15
        adjusted_threshold = self._apply_parameter_adjustments(adjusted_threshold)
        adjusted_threshold = max(0.2, min(0.8, adjusted_threshold))
        if group_coop_rate >= adjusted_threshold:
            return Action.C
        else:
            return Action.D

    def _get_group_coop_rate(self, history: PlayerHistory, round_idx: int) -> float:
        """Calculate cooperation rate of all players (including self) in specified round."""
        if round_idx >= len(history.my_actions):
            return 0.0
        my_action = history.my_actions[round_idx]
        opponent_actions = history.opponent_actions[round_idx, :]
        total_cooperators = int(my_action) + sum(opponent_actions)
        return total_cooperators / self.n

    def _get_recent_trend(self, history: PlayerHistory, exclude_last: bool=False) -> float:
        """Calculate average cooperation rate over recent rounds."""
        rounds_completed = len(history.my_actions)
        if exclude_last:
            rounds_completed -= 1
        if rounds_completed <= 0:
            return 0.0
        lookback = min(3, rounds_completed)
        start_idx = rounds_completed - lookback
        total_rate = 0.0
        for i in range(start_idx, rounds_completed):
            total_rate += self._get_group_coop_rate(history, i)
        return total_rate / lookback

    def _calculate_exploitation(self, history: PlayerHistory) -> int:
        """Count rounds where I cooperated but would have been better off defecting."""
        exploitation_count = 0
        rounds_completed = len(history.my_actions)
        start_round = max(0, rounds_completed - 3)
        for round_idx in range(start_round, rounds_completed):
            if not history.my_actions[round_idx]:
                continue
            opponent_cooperators = sum(history.opponent_actions[round_idx, :])
            total_cooperators_if_defected = opponent_cooperators
            actual_payoff = history.my_payoffs[round_idx]
            hypothetical_payoff = 1.0 + self.k / self.n * total_cooperators_if_defected
            if hypothetical_payoff > actual_payoff:
                exploitation_count += 1
        return exploitation_count

    def _apply_parameter_adjustments(self, threshold: float) -> float:
        """Apply adjustments based on game parameters."""
        adjusted = threshold
        if self.n <= 3:
            adjusted -= 0.1
        if self.k / self.n >= 0.8:
            adjusted -= 0.1
        if self.r <= 3:
            adjusted -= 0.15
        return adjusted

class Strategy_COOPERATIVE_51(BaseStrategy):
    """
    Graduated Reciprocator: An adaptive cooperative strategy that balances cooperation
    with protection against exploitation using dynamic thresholds and graduated responses.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.base_threshold = 0.4
        self.exploitation_count = 0
        self.olive_branch_used = False
        self.last_olive_branch_round = -10

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        total_rounds = self.game_description.n_rounds
        if current_round <= 2:
            prev_coop_rate = self._get_cooperation_rate(history, -1)
            return Action.C if prev_coop_rate >= 0.3 else Action.D
        if current_round >= total_rounds - 2:
            return self._endgame_decision(history, current_round, total_rounds)
        return self._main_phase_decision(history, current_round)

    def _main_phase_decision(self, history: PlayerHistory, current_round: int) -> Action:
        recent_coop_rate = self._weighted_cooperation_rate(history)
        current_threshold = self._adjust_threshold(history)
        if self._should_offer_olive_branch(history, current_round):
            self.olive_branch_used = True
            self.last_olive_branch_round = current_round
            return Action.C
        if self._collective_benefit_observed(history):
            current_threshold = max(0.25, current_threshold - 0.1)
        if recent_coop_rate >= current_threshold:
            return Action.C
        else:
            self._update_exploitation_count(history)
            return Action.D

    def _weighted_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate weighted cooperation rate over recent rounds."""
        rounds_to_check = min(3, len(history.my_actions))
        if rounds_to_check == 0:
            return 0.0
        weights = [0.5, 0.3, 0.2]
        total_weight = 0
        weighted_sum = 0
        for i in range(rounds_to_check):
            round_idx = -(i + 1)
            coop_rate = self._get_cooperation_rate(history, round_idx)
            weight = weights[i]
            weighted_sum += coop_rate * weight
            total_weight += weight
        return weighted_sum / total_weight if total_weight > 0 else 0.0

    def _get_cooperation_rate(self, history: PlayerHistory, round_idx: int) -> float:
        """Get cooperation rate for a specific round."""
        if abs(round_idx) > len(history.my_actions):
            return 0.0
        total_players = self.game_description.n_players
        cooperators = sum(history.opponent_actions[round_idx, :])
        if history.my_actions[round_idx]:
            cooperators += 1
        return cooperators / total_players

    def _adjust_threshold(self, history: PlayerHistory) -> float:
        """Adjust threshold based on exploitation history and mutual cooperation."""
        threshold = self.base_threshold
        exploitation_limit = max(1, self.game_description.n_rounds // 4)
        if self.exploitation_count > exploitation_limit:
            threshold += 0.15
        if len(history.my_actions) >= 2:
            recent_mutual_coop = True
            for i in range(min(2, len(history.my_actions))):
                round_idx = -(i + 1)
                if self._get_cooperation_rate(history, round_idx) < 0.5:
                    recent_mutual_coop = False
                    break
            if recent_mutual_coop:
                threshold -= 0.05
        return max(0.25, min(0.6, threshold))

    def _should_offer_olive_branch(self, history: PlayerHistory, current_round: int) -> bool:
        """Check if we should offer an olive branch after mutual defection."""
        if current_round - self.last_olive_branch_round <= 3:
            return False
        if len(history.my_actions) < 2:
            return False
        consecutive_low_coop = 0
        for i in range(min(2, len(history.my_actions))):
            round_idx = -(i + 1)
            if self._get_cooperation_rate(history, round_idx) < 0.25:
                consecutive_low_coop += 1
            else:
                break
        return consecutive_low_coop >= 2

    def _collective_benefit_observed(self, history: PlayerHistory) -> bool:
        """Check if collective benefit was observed in previous round."""
        if len(history.my_actions) == 0:
            return False
        all_defect_payoff = 1.0
        my_payoff = history.my_payoffs[-1]
        avg_opponent_payoff = np.mean(history.opponent_payoffs[-1, :])
        actual_avg_payoff = (my_payoff + avg_opponent_payoff * (self.game_description.n_players - 1)) / self.game_description.n_players
        return actual_avg_payoff > all_defect_payoff * 1.2

    def _update_exploitation_count(self, history: PlayerHistory) -> None:
        """Update exploitation count if I cooperated while others mostly defected."""
        if len(history.my_actions) == 0:
            return
        if history.my_actions[-1]:
            others_coop_rate = sum(history.opponent_actions[-1, :]) / (self.game_description.n_players - 1)
            if others_coop_rate <= 0.25:
                self.exploitation_count += 1

    def _endgame_decision(self, history: PlayerHistory, current_round: int, total_rounds: int) -> Action:
        """Handle endgame decisions for last 2 rounds."""
        if current_round == total_rounds - 1:
            if len(history.my_actions) > 0:
                prev_coop_rate = self._get_cooperation_rate(history, -1)
                return Action.C if prev_coop_rate >= 0.5 else Action.D
            return Action.C
        else:
            if len(history.my_actions) >= 3:
                low_coop_count = 0
                for i in range(min(3, len(history.my_actions))):
                    round_idx = -(i + 1)
                    if self._get_cooperation_rate(history, round_idx) < 0.3:
                        low_coop_count += 1
                return Action.D if low_coop_count >= 3 else Action.C
            return Action.C

class Strategy_COOPERATIVE_52(BaseStrategy):
    """
    Generous Tit-for-Majority: An adaptive cooperative strategy that cooperates based on 
    the cooperation rate of other players, with generous forgiveness mechanisms and 
    protection against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.base_threshold = 0.5
        self.historical_threshold = 0.33
        self.forgiveness_probability = 0.1
        self.recovery_attempt_interval = 3
        self.last_recovery_attempt = -999

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = state.round_number
        n_opponents = self.n - 1
        recent_cooperation_count = np.sum(history.opponent_actions[-1, :])
        recent_cooperation_rate = recent_cooperation_count / n_opponents
        lookback = min(3, round_num)
        if self.r > 10:
            lookback = min(5, round_num)
        historical_cooperation_count = np.sum(history.opponent_actions[-lookback:, :])
        historical_cooperation_rate = historical_cooperation_count / (lookback * n_opponents)
        recent_threshold = self.base_threshold
        if self.n > 8:
            recent_threshold *= 0.8
        if self.k > 1.5:
            recent_threshold *= 1.2
        if round_num > 0.8 * self.r:
            recent_threshold *= 1.2
        recent_threshold = recent_threshold * (1 + 0.1 * (self.n - 6) / 6)
        recent_threshold = max(0.1, min(0.9, recent_threshold))
        decision = Action.D
        if recent_cooperation_rate >= recent_threshold:
            decision = Action.C
        elif historical_cooperation_rate >= self.historical_threshold and recent_cooperation_rate >= 0.25:
            decision = Action.C
        elif self._detect_recovery_opportunity(history, round_num):
            decision = Action.C
            self.last_recovery_attempt = round_num
        elif round_num == self.r - 1:
            if recent_cooperation_rate >= 0.5:
                decision = Action.C
            elif recent_cooperation_rate < 0.5 and historical_cooperation_rate >= 0.4:
                decision = Action.C
        if self._is_being_exploited(history):
            decision = Action.D
        if decision == Action.D and historical_cooperation_rate >= 0.3 and (random.random() < self.forgiveness_probability):
            decision = Action.C
        return decision

    def _detect_recovery_opportunity(self, history: PlayerHistory, round_num: int) -> bool:
        """Detect if it's time for an olive branch to restart cooperation."""
        if round_num - self.last_recovery_attempt < self.recovery_attempt_interval:
            return False
        if round_num < 3:
            return False
        recent_rates = []
        for i in range(min(3, round_num)):
            round_idx = round_num - 1 - i
            coop_count = np.sum(history.opponent_actions[round_idx, :])
            rate = coop_count / (self.n - 1)
            recent_rates.append(rate)
        avg_recent_rate = np.mean(recent_rates)
        return avg_recent_rate < 0.2

    def _is_being_exploited(self, history: PlayerHistory) -> bool:
        """Check if we're being systematically exploited."""
        round_num = len(history.my_actions)
        if round_num < 3:
            return False
        lookback = min(3, round_num)
        recent_cooperation_rates = []
        for i in range(lookback):
            round_idx = round_num - 1 - i
            coop_count = np.sum(history.opponent_actions[round_idx, :])
            rate = coop_count / (self.n - 1)
            recent_cooperation_rates.append(rate)
        return all((rate < 0.1 for rate in recent_cooperation_rates))

class Strategy_COOPERATIVE_53(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation Strategy (ARCS)
    
    Balances cooperative intent with adaptive protection against exploitation.
    Uses dynamic threshold adjustment and graduated responses based on recent
    cooperation rates among other players.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = 0.4
        self.window_size = max(3, game_description.n_rounds // 4)
        self.consecutive_bad_rounds = 0
        self.first_round_coop_rate = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        recent_others_coop_rate = self._calculate_others_cooperation_rate(history)
        effective_threshold = self.threshold
        if state.round_number <= 3 and self.first_round_coop_rate is not None and (self.first_round_coop_rate >= 0.5):
            effective_threshold -= 0.1
        if state.round_number > 0.8 * self.game_description.n_rounds and self.threshold < 0.6:
            effective_threshold -= 0.1
        if self.consecutive_bad_rounds >= 2:
            effective_threshold += 0.15
        if len(history.my_actions) >= 2:
            current_coop_rate = recent_others_coop_rate
            prev_window_start = max(0, len(history.my_actions) - self.window_size - 1)
            prev_window_end = len(history.my_actions) - 1
            if prev_window_end > prev_window_start:
                prev_coop_rate = np.mean(history.opponent_actions[prev_window_start:prev_window_end, :])
                if current_coop_rate - prev_coop_rate > 0.3:
                    effective_threshold -= 0.2
        if recent_others_coop_rate >= effective_threshold:
            action = Action.C
        else:
            action = Action.D
        if len(history.my_payoffs) > 0:
            last_payoff = history.my_payoffs[-1]
            expected_all_coop = self.game_description.k
            expected_all_defect = 1.0
            if last_payoff >= expected_all_coop * 0.7:
                self.threshold = max(0.2, self.threshold - 0.05)
                self.consecutive_bad_rounds = 0
            elif last_payoff <= expected_all_defect * 1.3:
                self.threshold = min(0.8, self.threshold + 0.08)
                self.consecutive_bad_rounds += 1
            else:
                self.consecutive_bad_rounds = 0
        if state.round_number == 1 and self.first_round_coop_rate is None:
            self.first_round_coop_rate = np.mean(history.opponent_actions[0, :])
        return action

    def _calculate_others_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate of other players in recent window."""
        if len(history.my_actions) == 0:
            return 0.5
        window_start = max(0, len(history.my_actions) - self.window_size)
        window_end = len(history.my_actions)
        if window_end <= window_start:
            return 0.5
        recent_actions = history.opponent_actions[window_start:window_end, :]
        total_possible = recent_actions.size
        total_cooperations = np.sum(recent_actions)
        if total_possible == 0:
            return 0.5
        return total_cooperations / total_possible

class Strategy_COOPERATIVE_54(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation Strategy (ARC)
    
    Balances cooperative intent with adaptive protection against exploitation.
    Starts optimistically but learns from group behavior, rewarding collective
    cooperation while defending against persistent defection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        prev_round_idx = current_round - 1
        prev_cooperators = sum(history.opponent_actions[prev_round_idx, :])
        if history.my_actions[prev_round_idx]:
            prev_cooperators += 1
        cooperation_rate = prev_cooperators / self.n
        was_exploited = False
        if history.my_actions[prev_round_idx]:
            all_payoffs = list(history.opponent_payoffs[prev_round_idx, :]) + [history.my_payoffs[prev_round_idx]]
            avg_payoff = sum(all_payoffs) / len(all_payoffs)
            was_exploited = history.my_payoffs[prev_round_idx] < avg_payoff
        high_coop_threshold = self._adjust_for_group_size(0.6)
        low_coop_threshold = self._adjust_for_multiplier(0.3)
        if current_round == self.r - 1:
            return Action.C if cooperation_rate >= 0.5 else Action.D
        if self.r <= 3:
            return Action.D if cooperation_rate <= 0.2 else Action.C
        if cooperation_rate >= high_coop_threshold:
            return Action.C
        elif cooperation_rate >= low_coop_threshold:
            return Action.D if was_exploited else Action.C
        elif (current_round + 1) % 3 == 0:
            return Action.C
        else:
            return Action.D

    def _adjust_for_group_size(self, base_threshold):
        """Adjust cooperation threshold based on group size"""
        if self.n <= 3:
            return 0.5
        elif self.n >= 10:
            return base_threshold
        else:
            return base_threshold

    def _adjust_for_multiplier(self, base_threshold):
        """Adjust low cooperation threshold based on multiplication factor"""
        if self.k > 0.8 * self.n:
            return 0.2
        else:
            return base_threshold

class Strategy_COOPERATIVE_55(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation Strategy (ARCS).
    
    Balances cooperative intent with adaptive response to group behavior.
    Starts cooperatively, then adjusts based on Group Cooperation Rate (GCR).
    Uses probabilistic cooperation in middle ranges and stricter thresholds
    for the final round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        total_cooperations = 0
        total_possible = 0
        total_cooperations += np.sum(history.my_actions)
        total_possible += len(history.my_actions)
        total_cooperations += np.sum(history.opponent_actions)
        total_possible += history.opponent_actions.size
        gcr = total_cooperations / total_possible if total_possible > 0 else 0
        if state.round_number == self.game_description.n_rounds - 1:
            if gcr >= 0.7:
                return Action.C
            else:
                return Action.D
        if gcr >= 0.6:
            return Action.C
        elif gcr >= 0.3:
            cooperation_probability = 2 * gcr - 0.6
            if random.random() < cooperation_probability:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COOPERATIVE_56(BaseStrategy):
    """
    Graduated Reciprocator: Adaptive cooperative strategy that balances cooperation 
    with protection against exploitation using dynamic thresholds and trend analysis.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if self.r <= 3:
            return self._handle_short_game(current_round, history)
        if current_round == self.r - 1:
            return self._handle_final_round(history)
        return self._adaptive_reciprocation(current_round, history)

    def _handle_short_game(self, current_round: int, history: PlayerHistory) -> Action:
        """Handle games with 3 or fewer rounds."""
        if current_round == 1:
            prev_cooperators = sum(history.opponent_actions[-1, :])
            cooperation_rate = prev_cooperators / self.n
            return Action.C if cooperation_rate >= 0.5 else Action.D
        else:
            prev_cooperators = sum(history.opponent_actions[-1, :])
            cooperation_rate = prev_cooperators / self.n
            return Action.C if cooperation_rate >= 0.4 else Action.D

    def _handle_final_round(self, history: PlayerHistory) -> Action:
        """Final round: cooperate only if recent cooperation suggests reciprocation."""
        rounds_to_check = min(2, len(history.opponent_actions))
        if rounds_to_check == 0:
            return Action.D
        recent_cooperations = 0
        recent_total = 0
        for i in range(rounds_to_check):
            round_idx = -(i + 1)
            cooperators = sum(history.opponent_actions[round_idx, :])
            recent_cooperations += cooperators
            recent_total += self.n
        cooperation_rate = recent_cooperations / recent_total if recent_total > 0 else 0
        return Action.C if cooperation_rate >= 0.4 else Action.D

    def _adaptive_reciprocation(self, current_round: int, history: PlayerHistory) -> Action:
        """Main adaptive reciprocation logic for middle rounds."""
        total_cooperations = 0
        total_possible = 0
        for round_idx in range(len(history.opponent_actions)):
            cooperators = sum(history.opponent_actions[round_idx, :])
            total_cooperations += cooperators
            total_possible += self.n
        cooperation_rate = total_cooperations / total_possible if total_possible > 0 else 0
        base_threshold = max(0.3, min(0.8, cooperation_rate * 1.2))
        threshold = self._adjust_threshold_for_parameters(base_threshold)
        recent_rounds = min(3, len(history.opponent_actions))
        recent_cooperations = 0
        recent_total = 0
        for i in range(recent_rounds):
            round_idx = -(i + 1)
            cooperators = sum(history.opponent_actions[round_idx, :])
            recent_cooperations += cooperators
            recent_total += self.n
        recent_cooperation_rate = recent_cooperations / recent_total if recent_total > 0 else 0
        if recent_cooperation_rate > cooperation_rate + 0.1:
            trend = 'improving'
        elif recent_cooperation_rate < cooperation_rate - 0.1:
            trend = 'declining'
        else:
            trend = 'stable'
        if recent_cooperation_rate >= threshold:
            return Action.C
        if trend == 'improving' and recent_cooperation_rate >= 0.25:
            return Action.C
        forgiveness_interval = max(3, math.floor(self.r / 5))
        if current_round % forgiveness_interval == 0:
            if len(history.opponent_actions) > 0:
                prev_cooperators = sum(history.opponent_actions[-1, :])
                if prev_cooperators >= 1:
                    return Action.C
        if current_round > 0.7 * self.r:
            if recent_cooperation_rate >= 0.2:
                return Action.C
            if len(history.opponent_actions) > 0:
                prev_cooperators = sum(history.opponent_actions[-1, :])
                cooperation_threshold = 2 if self.n > 4 else 1
                if prev_cooperators >= cooperation_threshold:
                    return Action.C
        return Action.D

    def _adjust_threshold_for_parameters(self, base_threshold: float) -> float:
        """Adjust thresholds based on game parameters."""
        adjusted_threshold = base_threshold
        if self.k < 1.5:
            adjusted_threshold += 0.15
        if self.k > self.n - 1.5:
            adjusted_threshold -= 0.1
        return max(0.1, min(0.9, adjusted_threshold))

class Strategy_COOPERATIVE_57(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation Strategy (ARC)
    
    Starts with initial cooperation, then uses proportional response to group behavior
    with forgiveness mechanisms and adaptive thresholds. Balances collective welfare
    with protection against exploitation through graduated reciprocity.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        if self.r <= 5:
            self.initial_coop_rounds = math.floor(self.r / 2)
        elif self.n <= 3:
            self.initial_coop_rounds = math.floor(0.4 * self.r)
        else:
            self.initial_coop_rounds = 3
        if self.k > 0.8 * self.n:
            self.base_threshold = 0.4
        elif self.n <= 3:
            self.forgiveness_threshold = 0.5
        else:
            self.base_threshold = 0.3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = history.round_number
        if round_num < self.initial_coop_rounds:
            return Action.C
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        total_players = self.n
        cooperation_rate = last_round_cooperators / total_players
        if self.r <= 5:
            return Action.C if cooperation_rate >= 0.5 else Action.D
        if round_num >= self.r - 2:
            return self._handle_endgame(history, cooperation_rate)
        cooperation_threshold = max(getattr(self, 'base_threshold', 0.3), cooperation_rate * 0.8)
        if self._should_forgive(history):
            return Action.C
        if cooperation_rate >= cooperation_threshold:
            return Action.C
        else:
            defect_prob = 1 - cooperation_rate
            return Action.D if random.random() < defect_prob else Action.C

    def _should_forgive(self, history: PlayerHistory) -> bool:
        """Check if forgiveness conditions are met"""
        if history.round_number < 3:
            return False
        recent_rounds = min(3, history.round_number)
        cooperation_rates = []
        for i in range(recent_rounds):
            round_idx = -(i + 1)
            cooperators = sum(history.opponent_actions[round_idx, :])
            rate = cooperators / self.n
            cooperation_rates.append(rate)
        cooperation_rates.reverse()
        if len(cooperation_rates) >= 3:
            if cooperation_rates[1] > cooperation_rates[0] and cooperation_rates[2] > cooperation_rates[1]:
                return True
        if history.round_number >= 2:
            last_cooperators = sum(history.opponent_actions[-1, :])
            prev_cooperators = sum(history.opponent_actions[-2, :])
            if last_cooperators > prev_cooperators and last_cooperators / self.n >= 0.3:
                return random.random() < 0.6
        return False

    def _handle_endgame(self, history: PlayerHistory, last_cooperation_rate: float) -> Action:
        """Handle the final two rounds with specific endgame logic"""
        round_num = history.round_number
        if round_num == self.r - 2:
            if last_cooperation_rate > 0.5:
                return Action.C
            else:
                last_round_actions = history.opponent_actions[-1, :]
                cooperators = sum(last_round_actions)
                defectors = self.n - cooperators
                return Action.C if cooperators >= defectors else Action.D
        elif round_num == self.r - 1:
            total_cooperations = 0
            total_opportunities = 0
            for round_idx in range(history.round_number):
                cooperators = sum(history.opponent_actions[round_idx, :])
                total_cooperations += cooperators
                total_opportunities += self.n
            cumulative_rate = total_cooperations / total_opportunities if total_opportunities > 0 else 0
            if cumulative_rate > 0.6:
                return Action.C
            elif abs(cumulative_rate - 0.5) < 0.01:
                return Action.C
            else:
                return Action.D
        return Action.C

class Strategy_COOPERATIVE_58(BaseStrategy):
    """
    Graduated Reciprocator: An adaptive cooperative strategy that balances 
    cooperative intent with intelligent response to group behavior. Uses a 
    dynamic threshold based on game efficiency to determine cooperation levels,
    with graduated responses and forgiveness mechanisms to maintain cooperation
    while preventing exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        k = self.game_description.k
        total_rounds = self.game_description.n_rounds
        current_round = state.round_number
        threshold = max(0.3, k / n)
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        last_coop_rate = last_round_cooperators / n
        if current_round == total_rounds - 1:
            rounds_to_check = min(3, len(history.my_actions))
            recent_coop_rates = []
            for i in range(rounds_to_check):
                round_idx = -(i + 1)
                round_cooperators = sum(history.opponent_actions[round_idx, :])
                if history.my_actions[round_idx]:
                    round_cooperators += 1
                recent_coop_rates.append(round_cooperators / n)
            recent_avg = sum(recent_coop_rates) / len(recent_coop_rates)
            if recent_avg >= threshold * 0.7:
                return Action.C
        if last_coop_rate >= threshold:
            return Action.C
        elif last_coop_rate >= threshold * 0.5:
            cooperation_probability = last_coop_rate / threshold
            if random.random() < cooperation_probability:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COOPERATIVE_59(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation Strategy (ARC)
    
    Balances cooperative intent with adaptive resilience. Starts optimistic,
    adapts based on recent cooperation rates, and includes forgiveness and
    revival mechanisms to escape defection spirals.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.base_threshold = max(0.3, self.k / self.n)
        if self.n <= 3:
            self.threshold = self.k / (self.n + 1)
        elif self.k > 0.8 * self.n:
            self.threshold = 0.8 * (self.k / self.n)
        elif self.k < 1.5:
            self.threshold = 1.5 * (self.k / self.n)
        else:
            self.threshold = self.base_threshold
        self.low_coop_streak = 0
        self.exploitation_count = 0
        self.last_revival_round = -5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if history is None:
            return Action.C
        if current_round == self.r - 1 and self.r > 3:
            return Action.D
        recent_coop_rate = self._calculate_recent_cooperation_rate(history)
        if self._should_attempt_revival(history, current_round):
            self.last_revival_round = current_round
            return Action.C
        if self._should_forgive(history):
            self.low_coop_streak = 0
            return Action.C
        if recent_coop_rate >= self.threshold:
            self.low_coop_streak = 0
            return Action.C
        elif recent_coop_rate >= self.threshold * 0.7:
            prob = recent_coop_rate / self.threshold
            if self.exploitation_count > 0:
                prob *= 1.0 - 0.2 * min(self.exploitation_count, 3)
            if random.random() < prob:
                return Action.C
            else:
                self.low_coop_streak += 1
                return Action.D
        else:
            self.low_coop_streak += 1
            self._update_exploitation_count(history)
            return Action.D

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate over recent rounds."""
        current_round = history.round_number
        if self.r <= 5:
            window = max(1, self.r - 2)
        else:
            window = min(3, current_round)
        if window <= 0:
            return 0.0
        start_idx = max(0, current_round - window)
        recent_opponent_actions = history.opponent_actions[start_idx:current_round, :]
        if recent_opponent_actions.size == 0:
            return 0.0
        total_cooperators = np.sum(recent_opponent_actions)
        total_decisions = recent_opponent_actions.size
        return total_cooperators / total_decisions if total_decisions > 0 else 0.0

    def _should_forgive(self, history: PlayerHistory) -> bool:
        """Check if forgiveness protocol should activate."""
        if history.round_number < 3:
            return False
        if self.low_coop_streak < 2:
            return False
        current_rate = self._calculate_recent_cooperation_rate(history)
        prev_window_start = max(0, history.round_number - 4)
        prev_window_end = max(1, history.round_number - 1)
        if prev_window_start >= prev_window_end:
            return False
        prev_actions = history.opponent_actions[prev_window_start:prev_window_end, :]
        if prev_actions.size == 0:
            return False
        prev_rate = np.sum(prev_actions) / prev_actions.size
        return current_rate - prev_rate >= 0.2

    def _should_attempt_revival(self, history: PlayerHistory, current_round: int) -> bool:
        """Check if we should attempt revival from mutual defection."""
        if current_round - self.last_revival_round < 5:
            return False
        recent_rate = self._calculate_recent_cooperation_rate(history)
        return recent_rate < 0.2

    def _update_exploitation_count(self, history: PlayerHistory) -> None:
        """Update exploitation count if we're being consistently exploited."""
        if history.round_number < 2:
            return
        last_round = history.round_number - 1
        if last_round >= 0 and history.my_actions[last_round] and (np.sum(history.opponent_actions[last_round, :]) <= 1):
            if last_round >= 1 and history.my_actions[last_round - 1] and (np.sum(history.opponent_actions[last_round - 1, :]) <= 1):
                self.exploitation_count = min(self.exploitation_count + 1, 5)

class Strategy_COOPERATIVE_60(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation Strategy (ARCS) - balances cooperative intent 
    with adaptive resilience using trust-based approach that rewards cooperation 
    while protecting against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_threshold = 0.5
        self.recovery_attempt_round = -10

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_number = history.round_number + 1
        if round_number == self.game_description.n_rounds:
            if self._cooperation_rate_last_round(history) >= 0.8:
                return Action.C
            else:
                return Action.D
        recent_coop = self._cooperation_rate_last_round(history)
        historical_coop = self._cooperation_rate_last_n_rounds(history, 3)
        weighted_score = 0.6 * recent_coop + 0.4 * historical_coop
        self._update_threshold(history)
        if self._low_cooperation_streak(history) >= 3:
            if round_number - self.recovery_attempt_round >= 4:
                self.recovery_attempt_round = round_number
                return Action.C
        if recent_coop >= 0.7 and historical_coop < self.cooperation_threshold:
            return Action.C
        if self._count_consistent_cooperators(history) <= 2:
            if recent_coop >= 0.8:
                return Action.C
            else:
                return Action.D
        if weighted_score >= self.cooperation_threshold - 0.1:
            return Action.C
        elif round_number % 4 == 0:
            return Action.C
        else:
            return Action.D

    def _cooperation_rate_last_round(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate in the most recent round."""
        if history.round_number == 0:
            return 1.0
        last_round_actions = history.opponent_actions[-1, :]
        cooperators = np.sum(last_round_actions)
        total_opponents = len(last_round_actions)
        if history.my_actions[-1]:
            cooperators += 1
        total_players = total_opponents + 1
        return cooperators / total_players

    def _cooperation_rate_last_n_rounds(self, history: PlayerHistory, n: int) -> float:
        """Calculate cooperation rate over last n rounds."""
        if history.round_number == 0:
            return 1.0
        start_round = max(0, history.round_number - n)
        opponent_cooperations = np.sum(history.opponent_actions[start_round:, :])
        total_opponent_decisions = (history.round_number - start_round) * history.opponent_actions.shape[1]
        my_cooperations = np.sum(history.my_actions[start_round:])
        total_my_decisions = history.round_number - start_round
        total_cooperations = opponent_cooperations + my_cooperations
        total_decisions = total_opponent_decisions + total_my_decisions
        return total_cooperations / total_decisions if total_decisions > 0 else 1.0

    def _update_threshold(self, history: PlayerHistory):
        """Update dynamic cooperation threshold based on recent outcomes."""
        if history.round_number < 2:
            return
        if history.my_actions[-1] and self._cooperation_rate_last_round(history) < 0.4:
            self.cooperation_threshold = max(0.3, self.cooperation_threshold - 0.05)
        elif history.round_number >= 2:
            recent_rates = [self._cooperation_rate_in_round(history, i) for i in range(max(0, history.round_number - 2), history.round_number)]
            if all((rate >= 0.6 for rate in recent_rates)):
                self.cooperation_threshold = min(0.7, self.cooperation_threshold + 0.03)

    def _cooperation_rate_in_round(self, history: PlayerHistory, round_idx: int) -> float:
        """Calculate cooperation rate in a specific round."""
        if round_idx >= history.round_number or round_idx < 0:
            return 1.0
        opponent_cooperators = np.sum(history.opponent_actions[round_idx, :])
        my_cooperation = 1 if history.my_actions[round_idx] else 0
        total_cooperators = opponent_cooperators + my_cooperation
        total_players = history.opponent_actions.shape[1] + 1
        return total_cooperators / total_players

    def _low_cooperation_streak(self, history: PlayerHistory) -> int:
        """Count consecutive rounds with cooperation rate below 30%."""
        if history.round_number < 3:
            return 0
        streak = 0
        for i in range(history.round_number - 1, -1, -1):
            if self._cooperation_rate_in_round(history, i) < 0.3:
                streak += 1
            else:
                break
        return streak

    def _count_consistent_cooperators(self, history: PlayerHistory) -> int:
        """Count players who have cooperated in at least 60% of recent rounds."""
        if history.round_number < 3:
            return self.game_description.n_players
        consistent_count = 0
        recent_rounds = min(3, history.round_number)
        start_round = history.round_number - recent_rounds
        for player_idx in range(history.opponent_actions.shape[1]):
            player_cooperations = np.sum(history.opponent_actions[start_round:, player_idx])
            cooperation_rate = player_cooperations / recent_rounds
            if cooperation_rate >= 0.6:
                consistent_count += 1
        my_cooperations = np.sum(history.my_actions[start_round:])
        my_rate = my_cooperations / recent_rounds
        if my_rate >= 0.6:
            consistent_count += 1
        return consistent_count

class Strategy_COOPERATIVE_61(BaseStrategy):
    """
    Adaptive Reciprocity with Forgiveness Strategy
    
    Balances cooperation with adaptive responses to community cooperation levels.
    Starts optimistically, learns from group behavior, and maintains resilience 
    against exploitation through dynamic thresholds and periodic forgiveness.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number + 1
        look_back = min(3, current_round - 1)
        recent_rounds_start = max(0, len(history.opponent_actions) - look_back)
        if len(history.opponent_actions) > 0:
            recent_opponent_actions = history.opponent_actions[recent_rounds_start:]
            total_others = recent_opponent_actions.shape[0] * recent_opponent_actions.shape[1]
            recent_others_coop_count = np.sum(recent_opponent_actions)
            recent_others_coop_rate = recent_others_coop_count / total_others if total_others > 0 else 0
        else:
            recent_others_coop_rate = 0
        base_threshold = k / n
        if n <= 3:
            base_threshold *= 0.6
        elif k >= 0.8 * n:
            base_threshold *= 0.7
        if recent_others_coop_rate >= base_threshold:
            threshold = 0.8 * base_threshold
        else:
            threshold = 1.2 * base_threshold
        if current_round % 4 == 0:
            look_back_defect = min(2, len(history.my_actions))
            if look_back_defect > 0:
                recent_my_actions = history.my_actions[-look_back_defect:]
                was_defecting = not np.any(recent_my_actions)
                if was_defecting:
                    return Action.C
        if current_round == r:
            if len(history.opponent_actions) > 0:
                last_round_others = history.opponent_actions[-1, :]
                last_round_coop_rate = np.mean(last_round_others)
                return Action.C if last_round_coop_rate >= k / n else Action.D
            else:
                return Action.D
        if r <= 5 and current_round <= r - 2:
            return Action.C
        return Action.C if recent_others_coop_rate >= threshold else Action.D

class Strategy_COOPERATIVE_62(BaseStrategy):
    """
    Adaptive Cooperative Strategy: "Graduated Reciprocator"
    
    Balances cooperative intent with adaptive resilience, starting optimistically but learning
    from opponents' behavior to maintain cooperation when possible while protecting against exploitation.
    Uses a cooperation threshold system based on observed cooperation rates with forgiveness mechanisms.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.base_threshold = max(0.3, (self.k - 1) / (self.n - 1))
        self.recovery_attempts = 0
        self.max_recovery_attempts = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = state.round_number
        initial_phase_length = max(3, math.ceil(0.2 * self.r))
        if round_num < initial_phase_length:
            return Action.C
        last_round_cooperators = sum(history.opponent_actions[-1, :]) + int(history.my_actions[-1])
        cooperation_rate = last_round_cooperators / self.n
        if round_num >= 0.9 * self.r:
            end_game_progress = (round_num - 0.9 * self.r) / (0.1 * self.r)
            threshold = self.base_threshold * (1 - 0.1 * end_game_progress)
        else:
            threshold = self.base_threshold
        if self._all_defected_recently(history, rounds=3):
            if self._should_attempt_recovery(round_num):
                self.recovery_attempts += 1
                return Action.C
            elif self.recovery_attempts >= self.max_recovery_attempts:
                return Action.D
        trend_improving = self._is_trend_improving(history)
        rounds_remaining = self.r - round_num
        if cooperation_rate >= threshold:
            return Action.C
        elif trend_improving and rounds_remaining > 0.25 * self.r:
            return Action.C
        else:
            if self._should_forgive(history):
                return Action.C
            return Action.D

    def _all_defected_recently(self, history: PlayerHistory, rounds: int) -> bool:
        """Check if all players defected in the last 'rounds' consecutive rounds."""
        if len(history.my_actions) < rounds:
            return False
        for i in range(rounds):
            round_idx = -(i + 1)
            total_cooperators = sum(history.opponent_actions[round_idx, :]) + int(history.my_actions[round_idx])
            if total_cooperators > 0:
                return False
        return True

    def _should_attempt_recovery(self, round_num: int) -> bool:
        """Determine if we should attempt recovery after mutual defection."""
        if self.recovery_attempts >= self.max_recovery_attempts:
            return False
        return round_num % 4 == 0

    def _is_trend_improving(self, history: PlayerHistory) -> bool:
        """Check if cooperation trend is improving over the last few rounds."""
        if len(history.my_actions) < 3:
            return False
        recent_coop = 0
        earlier_coop = 0
        for i in range(2):
            recent_cooperators = sum(history.opponent_actions[-(i + 1), :]) + int(history.my_actions[-(i + 1)])
            recent_coop += recent_cooperators / self.n
            if len(history.my_actions) > i + 2:
                earlier_cooperators = sum(history.opponent_actions[-(i + 3), :]) + int(history.my_actions[-(i + 3)])
                earlier_coop += earlier_cooperators / self.n
        return recent_coop > earlier_coop

    def _should_forgive(self, history: PlayerHistory) -> bool:
        """Implement forgiveness mechanism after consecutive defection."""
        if len(history.my_actions) < 3:
            return False
        consecutive_defection = 0
        for i in range(min(3, len(history.my_actions))):
            round_idx = -(i + 1)
            total_cooperators = sum(history.opponent_actions[round_idx, :]) + int(history.my_actions[round_idx])
            if total_cooperators == 0:
                consecutive_defection += 1
            else:
                break
        return consecutive_defection >= 3 and len(history.my_actions) % 4 == 0

class Strategy_COOPERATIVE_63(BaseStrategy):
    """
    Graduated Reciprocator: An adaptive cooperative strategy that starts optimistically,
    adjusts cooperation thresholds based on observed behavior, and uses graduated responses
    to maintain cooperation while protecting against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_number = history.round_number + 1
        if round_number <= 3:
            return Action.C
        overall_coop_rate = self._calculate_overall_cooperation_rate(history)
        threshold = max(0.3, overall_coop_rate * 0.8)
        if round_number >= self.n_rounds - 1:
            return self._endgame_decision(round_number, history, overall_coop_rate)
        recent_coop_rate = self._calculate_recent_cooperation_rate(history)
        if recent_coop_rate >= threshold:
            return Action.C
        if self._cooperation_improving(history):
            return Action.C
        if round_number % 4 == 0:
            return Action.C
        if overall_coop_rate > 1.0 / self.k:
            return Action.C
        return Action.D

    def _calculate_overall_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate the overall cooperation rate across all players and rounds."""
        total_cooperations = 0
        total_possible = 0
        for round_idx in range(history.round_number):
            total_cooperations += sum(history.opponent_actions[round_idx, :])
            total_possible += self.n_players - 1
            if history.my_actions[round_idx]:
                total_cooperations += 1
            total_possible += 1
        return total_cooperations / total_possible if total_possible > 0 else 0.0

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate in the last 2 rounds."""
        total_cooperations = 0
        total_possible = 0
        start_round = max(0, history.round_number - 2)
        for round_idx in range(start_round, history.round_number):
            total_cooperations += sum(history.opponent_actions[round_idx, :])
            total_possible += self.n_players - 1
            if history.my_actions[round_idx]:
                total_cooperations += 1
            total_possible += 1
        return total_cooperations / total_possible if total_possible > 0 else 0.0

    def _cooperation_improving(self, history: PlayerHistory) -> bool:
        """Check if cooperation rate increased in the most recent round."""
        if history.round_number < 2:
            return False
        recent_round_idx = history.round_number - 1
        recent_cooperations = sum(history.opponent_actions[recent_round_idx, :])
        if history.my_actions[recent_round_idx]:
            recent_cooperations += 1
        recent_rate = recent_cooperations / self.n_players
        prev_round_idx = history.round_number - 2
        prev_cooperations = sum(history.opponent_actions[prev_round_idx, :])
        if history.my_actions[prev_round_idx]:
            prev_cooperations += 1
        prev_rate = prev_cooperations / self.n_players
        return recent_rate > prev_rate

    def _endgame_decision(self, round_number: int, history: PlayerHistory, overall_coop_rate: float) -> Action:
        """Handle endgame decisions for last 2 rounds."""
        if round_number == self.n_rounds - 1:
            return Action.C if overall_coop_rate > 0.5 else Action.D
        elif round_number == self.n_rounds:
            if history.round_number > 0:
                last_round_idx = history.round_number - 1
                last_round_cooperations = sum(history.opponent_actions[last_round_idx, :])
                if history.my_actions[last_round_idx]:
                    last_round_cooperations += 1
                last_round_rate = last_round_cooperations / self.n_players
                return Action.C if last_round_rate >= 0.6 else Action.D
            else:
                return Action.D
        return Action.D

class Strategy_COOPERATIVE_64(BaseStrategy):
    """
    Adaptive Generous Tit-for-Tat (AGTT) Strategy
    
    Balances cooperation with strategic self-protection by being generous in rewarding 
    cooperation while maintaining measured responses to defection. Adapts to the overall 
    cooperation level in the group and becomes more forgiving as the game progresses.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if current_round == self.r:
            prev_coop_rate = self._get_cooperation_rate(history, -1)
            return Action.C if prev_coop_rate >= 0.4 else Action.D
        if self._check_perfect_cooperation(history):
            return Action.C
        prev_coop_rate = self._get_cooperation_rate(history, -1)
        if prev_coop_rate >= 0.5:
            return Action.C
        if self._in_recovery_mode(history):
            return Action.C
        forgiveness_cycle = self._get_forgiveness_cycle(current_round)
        if current_round % forgiveness_cycle == 0:
            return Action.C
        reciprocity = self._calculate_reciprocity(history)
        threshold = self._get_reciprocity_threshold()
        return Action.C if reciprocity >= threshold else Action.D

    def _get_cooperation_rate(self, history: PlayerHistory, round_idx: int) -> float:
        """Get cooperation rate for a specific round (negative indexing supported)"""
        if round_idx >= len(history.opponent_actions):
            return 0.0
        my_action = history.my_actions[round_idx]
        opponent_cooperators = sum(history.opponent_actions[round_idx, :])
        total_cooperators = opponent_cooperators + (1 if my_action else 0)
        return total_cooperators / self.n

    def _check_perfect_cooperation(self, history: PlayerHistory) -> bool:
        """Check if all players cooperated in the last 2 consecutive rounds"""
        if len(history.my_actions) < 2:
            return False
        for i in range(2):
            round_idx = -(i + 1)
            coop_rate = self._get_cooperation_rate(history, round_idx)
            if coop_rate < 1.0:
                return False
        return True

    def _in_recovery_mode(self, history: PlayerHistory) -> bool:
        """Check if we should enter recovery mode after mass defection"""
        if len(history.my_actions) < 2:
            return False
        low_coop_rounds = 0
        for i in range(min(2, len(history.my_actions))):
            round_idx = -(i + 1)
            coop_rate = self._get_cooperation_rate(history, round_idx)
            if coop_rate < 0.2:
                low_coop_rounds += 1
        if low_coop_rounds >= 2:
            return True
        return False

    def _get_forgiveness_cycle(self, current_round: int) -> int:
        """Get forgiveness cycle based on game phase"""
        game_progress = current_round / self.r
        if game_progress <= 0.25:
            return 3
        elif game_progress >= 0.75:
            return 5
        else:
            return 4

    def _calculate_reciprocity(self, history: PlayerHistory) -> float:
        """Calculate reciprocity ratio from recent history"""
        recent_rounds = min(3, len(history.my_actions))
        if recent_rounds == 0:
            return 1.0
        my_cooperation_attempts = 0
        others_cooperation_when_i_cooperated = 0
        current_round = len(history.my_actions) + 1
        is_endgame = current_round >= 0.9 * self.r
        for i in range(recent_rounds):
            round_idx = -(i + 1)
            my_action = history.my_actions[round_idx]
            if my_action:
                weight = 2 if is_endgame and i < 2 else 1
                my_cooperation_attempts += weight
                opponent_cooperators = sum(history.opponent_actions[round_idx, :])
                others_cooperation_when_i_cooperated += opponent_cooperators * weight
        if my_cooperation_attempts == 0:
            return 0.0
        total_possible_others_cooperation = my_cooperation_attempts * (self.n - 1)
        return others_cooperation_when_i_cooperated / total_possible_others_cooperation

    def _get_reciprocity_threshold(self) -> float:
        """Get reciprocity threshold based on group size"""
        if self.n <= 4:
            return 0.2
        elif self.n >= 8:
            return 0.4
        else:
            return 0.3

class Strategy_COOPERATIVE_65(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation (ARC) Strategy
    
    Balances cooperative intent with adaptive protection against exploitation.
    Uses a cooperation threshold model based on recent cooperation rates,
    historical trends, and personal vulnerability assessment.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        rcr = last_round_cooperators / n
        rounds_to_consider = min(3, len(history.my_actions))
        total_cooperators = 0
        total_possible = 0
        for i in range(rounds_to_consider):
            round_idx = len(history.my_actions) - 1 - i
            round_cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                round_cooperators += 1
            weight = 1.0 / (i + 1)
            total_cooperators += round_cooperators * weight
            total_possible += n * weight
        hct = total_cooperators / total_possible if total_possible > 0 else 0
        base_threshold = 0.3 + (k - 1) / (n - 1) * 0.4
        if hct > 0.6:
            adjusted_threshold = base_threshold * 0.8
        elif hct < 0.3:
            adjusted_threshold = base_threshold * 1.3
        else:
            adjusted_threshold = base_threshold
        if current_round == r:
            return Action.C if hct >= 0.4 else Action.D
        if rcr >= adjusted_threshold:
            return Action.C
        if hct > 0.5:
            my_last_payoff = history.my_payoffs[-1]
            avg_last_payoff = np.mean(history.opponent_payoffs[-1, :])
            if my_last_payoff >= avg_last_payoff:
                return Action.C
        if len(history.my_actions) >= 2:
            last_round_total = sum(history.opponent_actions[-1, :])
            if history.my_actions[-1]:
                last_round_total += 1
            second_last_total = sum(history.opponent_actions[-2, :])
            if history.my_actions[-2]:
                second_last_total += 1
            if last_round_total > second_last_total:
                return Action.C
        if random.random() < 0.05 and hct > 0.2:
            return Action.C
        return Action.D

class Strategy_COOPERATIVE_66(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation Strategy (ARC)
    
    Balances cooperative intent with adaptive protection against exploitation.
    Starts optimistically but learns from group behavior, rewarding collective 
    cooperation while defending against systematic defection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = state.round_number
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        RCR = last_round_cooperators / n
        if round_num == r - 1:
            return Action.C if RCR >= 0.5 else Action.D
        HCT = self._calculate_weighted_trend(history, n)
        if RCR >= 0.6:
            return Action.C
        elif RCR >= 0.3:
            return Action.C if HCT >= 0.4 else Action.D
        else:
            recent_low_coop_count = self._count_low_cooperation_rounds(history, n)
            if recent_low_coop_count <= 1:
                return Action.C
            else:
                return Action.D

    def _calculate_weighted_trend(self, history: PlayerHistory, n: int) -> float:
        """Calculate weighted average of cooperation rates over recent rounds."""
        rounds_completed = len(history.my_actions)
        lookback = min(3, rounds_completed)
        if lookback == 0:
            return 0.0
        weights = [0.5, 0.3, 0.2][:lookback]
        total_weight = sum(weights)
        weighted_sum = 0.0
        for i in range(lookback):
            round_idx = rounds_completed - 1 - i
            cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            cooperation_rate = cooperators / n
            weighted_sum += weights[i] * cooperation_rate
        return weighted_sum / total_weight

    def _count_low_cooperation_rounds(self, history: PlayerHistory, n: int) -> int:
        """Count rounds with low cooperation (< 0.3) in the last 4 rounds."""
        rounds_completed = len(history.my_actions)
        lookback = min(4, rounds_completed)
        low_coop_count = 0
        for i in range(lookback):
            round_idx = rounds_completed - 1 - i
            cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                cooperators += 1
            cooperation_rate = cooperators / n
            if cooperation_rate < 0.3:
                low_coop_count += 1
        return low_coop_count

class Strategy_COOPERATIVE_67(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation Strategy (ARCS).
    
    Balances cooperation with adaptive learning, using reciprocity as the foundation
    while adjusting to observed opponent behaviors. Aims to foster cooperation when
    possible while protecting against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.low_coop_consecutive = 0
        self.probe_mode = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = history.round_number + 1
        cooperators_last_round = int(sum(history.opponent_actions[-1, :]))
        if history.my_actions[-1]:
            cooperators_last_round += 1
        cooperators_two_rounds_ago = 0
        if len(history.my_actions) >= 2:
            cooperators_two_rounds_ago = int(sum(history.opponent_actions[-2, :]))
            if history.my_actions[-2]:
                cooperators_two_rounds_ago += 1
        recent_coop_rate = cooperators_last_round / self.n
        if len(history.my_actions) >= 2:
            prev_coop_rate = cooperators_two_rounds_ago / self.n
            CMS = recent_coop_rate * 0.6 + prev_coop_rate * 0.4
        else:
            CMS = recent_coop_rate
        base_threshold = max(0.3, min(0.7, self.k / self.n - 0.1))
        decline_penalty = 0
        if len(history.my_actions) >= 2:
            prev_coop_rate = cooperators_two_rounds_ago / self.n
            decline_penalty = max(0, prev_coop_rate - recent_coop_rate)
        effective_threshold = base_threshold + decline_penalty * 0.3
        if recent_coop_rate < 0.2:
            self.low_coop_consecutive += 1
        else:
            self.low_coop_consecutive = 0
            self.probe_mode = False
        if self.low_coop_consecutive >= 3:
            self.probe_mode = True
        in_final_phase = round_num > 0.8 * self.r
        historical_coop_rate = 0
        if len(history.my_actions) > 0:
            total_cooperators = 0
            total_rounds = len(history.my_actions)
            for i in range(total_rounds):
                round_cooperators = int(sum(history.opponent_actions[i, :]))
                if history.my_actions[i]:
                    round_cooperators += 1
                total_cooperators += round_cooperators
            historical_coop_rate = total_cooperators / (total_rounds * self.n)
        was_only_cooperator = history.my_actions[-1] and sum(history.opponent_actions[-1, :]) == 0
        if in_final_phase and historical_coop_rate < 0.5:
            return Action.D
        if self.probe_mode:
            if round_num % 4 == 0:
                return Action.C
            else:
                return Action.D
        if was_only_cooperator and recent_coop_rate < 0.25:
            return Action.D
        if recent_coop_rate < 0.3 and historical_coop_rate < 0.3 and (round_num % random.choice([5, 6, 7]) == 0) and (round_num < 0.8 * self.r):
            return Action.C
        if CMS >= effective_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_68(BaseStrategy):
    """
    Adaptive Cooperative Strategy: "Generous Tit-for-Tat with Momentum"
    
    Balances cooperative intent with adaptive protection against exploitation.
    Starts optimistically, rewards collective cooperation, responds proportionally 
    to defection while maintaining opportunities for cooperation recovery.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        total_rounds = self.game_description.n_rounds
        n = self.game_description.n_players
        k = self.game_description.k
        if current_round == total_rounds:
            if current_round >= 3:
                recent_rounds_start = max(0, current_round - 2)
                recent_my_actions = history.my_actions[recent_rounds_start:]
                recent_opponent_actions = history.opponent_actions[recent_rounds_start:, :]
                total_cooperators = 0
                total_decisions = 0
                for round_idx in range(len(recent_my_actions)):
                    if recent_my_actions[round_idx]:
                        total_cooperators += 1
                    total_decisions += 1
                    for player_idx in range(recent_opponent_actions.shape[1]):
                        if recent_opponent_actions[round_idx, player_idx]:
                            total_cooperators += 1
                        total_decisions += 1
                coop_rate = total_cooperators / total_decisions if total_decisions > 0 else 0
                return Action.C if coop_rate >= 0.5 else Action.D
            else:
                return Action.C
        lookback_rounds = min(3, current_round)
        start_idx = max(0, current_round - lookback_rounds)
        recent_my_actions = history.my_actions[start_idx:]
        recent_opponent_actions = history.opponent_actions[start_idx:, :]
        total_cooperators = 0
        total_decisions = 0
        for round_idx in range(len(recent_my_actions)):
            if recent_my_actions[round_idx]:
                total_cooperators += 1
            total_decisions += 1
            for player_idx in range(recent_opponent_actions.shape[1]):
                if recent_opponent_actions[round_idx, player_idx]:
                    total_cooperators += 1
                total_decisions += 1
        recent_coop_rate = total_cooperators / total_decisions if total_decisions > 0 else 0
        base_threshold = max(0.3, k / n)
        if recent_coop_rate >= 0.6:
            adjusted_threshold = base_threshold - 0.1
        elif recent_coop_rate <= 0.3:
            adjusted_threshold = base_threshold + 0.1
        else:
            adjusted_threshold = base_threshold
        if current_round % 4 == 0:
            consecutive_defections = 0
            for i in range(min(2, len(history.my_actions))):
                if not history.my_actions[-(i + 1)]:
                    consecutive_defections += 1
                else:
                    break
            if consecutive_defections >= 2:
                return Action.C
        if recent_coop_rate >= adjusted_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_69(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation Strategy (ARC)
    
    Starts cooperatively, then adapts cooperation threshold based on group behavior.
    Includes forgiveness mechanism to escape mutual defection cycles.
    Always defects in final round.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_threshold = 0.5
        self.consecutive_mutual_defection = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n_players = self.game_description.n_players
        n_rounds = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == n_rounds - 1:
            return Action.D
        last_round_idx = history.round_number - 1
        my_last_action = history.my_actions[last_round_idx]
        opponents_last_actions = history.opponent_actions[last_round_idx, :]
        total_cooperators = int(my_last_action) + sum(opponents_last_actions)
        group_coop_rate = total_cooperators / n_players
        self.cooperation_threshold = 0.7 * self.cooperation_threshold + 0.3 * group_coop_rate
        if group_coop_rate < 0.3 and (not my_last_action):
            self.consecutive_mutual_defection += 1
        else:
            self.consecutive_mutual_defection = 0
        if self.consecutive_mutual_defection >= 2:
            if random.random() < 0.4:
                return Action.C
            else:
                return Action.D
        if group_coop_rate >= self.cooperation_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_70(BaseStrategy):
    """
    Adaptive Threshold Cooperation (ATC) Strategy
    
    Balances cooperative intent with adaptive resilience by using dynamic thresholds
    that adjust based on observed cooperation levels. Starts cooperatively and adapts
    expectations based on group behavior while protecting against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.consecutive_below_threshold = 0
        self.last_threshold = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        round_num = state.round_number
        window_size = max(3, r // 5)
        recent_rounds = min(history.round_number, window_size)
        total_cooperators = 0
        for i in range(recent_rounds):
            round_idx = history.round_number - 1 - i
            round_cooperators = sum(history.opponent_actions[round_idx, :]) + (1 if history.my_actions[round_idx] else 0)
            total_cooperators += round_cooperators
        recent_cooperation_rate = total_cooperators / (n * recent_rounds)
        base_threshold = 0.4
        if n > 10:
            base_threshold = 0.45
        if k < 1.5:
            base_threshold = 0.3
        elif k > n - 0.5:
            base_threshold = 0.5
        adjustment_factor = (recent_cooperation_rate - 0.5) * 0.3
        threshold = base_threshold + adjustment_factor
        if self.last_threshold is not None and recent_cooperation_rate < self.last_threshold:
            self.consecutive_below_threshold += 1
        else:
            self.consecutive_below_threshold = 0
        if self.consecutive_below_threshold >= 2:
            threshold -= 0.1
        self.last_threshold = threshold
        final_phase_start = max(r - 3, int(0.8 * r))
        if round_num >= final_phase_start:
            total_past_cooperators = 0
            for i in range(history.round_number):
                round_cooperators = sum(history.opponent_actions[i, :]) + (1 if history.my_actions[i] else 0)
                total_past_cooperators += round_cooperators
            avg_cooperation_rate = total_past_cooperators / (n * history.round_number)
            if avg_cooperation_rate >= 0.6:
                return Action.C
            elif avg_cooperation_rate < 0.3:
                return Action.D
        if r <= 5:
            if round_num <= 2:
                return Action.C
            elif round_num == r:
                total_past_cooperators = 0
                for i in range(history.round_number):
                    round_cooperators = sum(history.opponent_actions[i, :]) + (1 if history.my_actions[i] else 0)
                    total_past_cooperators += round_cooperators
                avg_cooperation_rate = total_past_cooperators / (n * history.round_number)
                return Action.C if avg_cooperation_rate >= 0.5 else Action.D
            else:
                return Action.C if recent_cooperation_rate >= 0.5 else Action.D
        return Action.C if recent_cooperation_rate >= threshold else Action.D

class Strategy_COOPERATIVE_71(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation Strategy (ARC)
    
    Balances cooperative intentions with adaptive responses to opponent behavior,
    using forgiveness and escalation mechanisms to maintain cooperation while
    protecting against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number + 1
        total_rounds = self.game_description.n_rounds
        if current_round == total_rounds:
            overall_coop_rate = self._calculate_overall_cooperation_rate(history)
            recent_coop_rate = self._calculate_recent_cooperation_rate(history, 3)
            if overall_coop_rate >= 0.6 or recent_coop_rate >= 0.7:
                return Action.C
            else:
                return Action.D
        recent_coop_rate = self._calculate_recent_cooperation_rate(history, 3)
        overall_coop_rate = self._calculate_overall_cooperation_rate(history)
        trend_direction = self._calculate_trend_direction(history)
        if recent_coop_rate >= 0.7:
            base_action = Action.C
        elif recent_coop_rate >= 0.4:
            if overall_coop_rate >= 0.5:
                base_action = Action.C
            else:
                base_action = Action.D
        else:
            base_action = Action.D
        coop_prob = 1.0 if base_action == Action.C else 0.0
        if base_action == Action.D and history.my_actions[-1] == False:
            coop_prob = 0.3
        if trend_direction == 'increasing':
            coop_prob = min(1.0, coop_prob + 0.2)
        elif trend_direction == 'decreasing' and coop_prob > 0:
            coop_prob = max(0.0, coop_prob - 0.1)
        return Action.C if random.random() < coop_prob else Action.D

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory, window: int) -> float:
        """Calculate cooperation rate over the last 'window' rounds"""
        rounds_completed = history.round_number
        actual_window = min(window, rounds_completed)
        if actual_window == 0:
            return 1.0
        recent_actions = history.opponent_actions[-actual_window:, :]
        total_decisions = recent_actions.size
        total_cooperations = np.sum(recent_actions)
        return total_cooperations / total_decisions if total_decisions > 0 else 1.0

    def _calculate_overall_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate since round 1"""
        total_decisions = history.opponent_actions.size
        total_cooperations = np.sum(history.opponent_actions)
        return total_cooperations / total_decisions if total_decisions > 0 else 1.0

    def _calculate_trend_direction(self, history: PlayerHistory) -> str:
        """Calculate whether cooperation is increasing, decreasing, or stable over last 3 rounds"""
        rounds_completed = history.round_number
        if rounds_completed < 3:
            return 'stable'
        window = min(3, rounds_completed)
        recent_actions = history.opponent_actions[-window:, :]
        coop_rates = []
        for i in range(window):
            round_actions = recent_actions[i, :]
            round_coop_rate = np.mean(round_actions)
            coop_rates.append(round_coop_rate)
        if len(coop_rates) < 2:
            return 'stable'
        if len(coop_rates) >= 3:
            early_avg = np.mean(coop_rates[:len(coop_rates) // 2])
            late_avg = np.mean(coop_rates[len(coop_rates) // 2:])
            if late_avg > early_avg + 0.1:
                return 'increasing'
            elif late_avg < early_avg - 0.1:
                return 'decreasing'
        return 'stable'

class Strategy_COOPERATIVE_72(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation Strategy
    
    Begins optimistically but adapts based on observed group behavior using graduated responses.
    Uses a cooperation threshold system that adjusts based on recent cooperation rates,
    promoting cooperation while protecting against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number + 1
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        lookback = min(3, current_round - 1)
        recent_my_actions = history.my_actions[-lookback:]
        recent_opponent_actions = history.opponent_actions[-lookback:, :]
        total_cooperators = 0
        for round_idx in range(lookback):
            round_cooperators = int(recent_my_actions[round_idx])
            round_cooperators += int(np.sum(recent_opponent_actions[round_idx, :]))
            total_cooperators += round_cooperators
        recent_coop_rate = total_cooperators / (n * lookback)
        if recent_coop_rate >= 0.6:
            threshold = 0.4
        elif recent_coop_rate >= 0.4:
            threshold = 0.5
        elif recent_coop_rate >= 0.2:
            threshold = 0.6
        else:
            threshold = 0.7
        if current_round == 2:
            threshold = min(threshold, 1.0 / n)
        if current_round == r:
            threshold = max(threshold, 0.5)
        if recent_coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_73(BaseStrategy):
    """
    Graduated Reciprocator: An adaptive cooperative strategy that starts with cooperation,
    maintains cooperation when group reciprocates, and gradually reduces cooperation when
    faced with low group cooperation rates. Uses forgiveness mechanisms and individual
    player tracking for robustness.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.base_threshold = self.k / self.n
        self.adjusted_threshold = self.base_threshold * 0.8
        self.decline_counter = 0
        self.last_cooperation_rate = 1.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if current_round <= 2:
            return Action.C
        rounds_to_consider = min(3, current_round)
        recent_rounds_start = max(0, current_round - rounds_to_consider)
        total_cooperators = 0
        for round_idx in range(recent_rounds_start, current_round):
            if history.my_actions[round_idx]:
                total_cooperators += 1
            total_cooperators += sum(history.opponent_actions[round_idx, :])
        cooperation_rate = total_cooperators / (rounds_to_consider * self.n)
        if cooperation_rate < self.last_cooperation_rate:
            self.decline_counter += 1
        elif cooperation_rate > self.last_cooperation_rate and self.decline_counter >= 3:
            self.last_cooperation_rate = cooperation_rate
            self.decline_counter = 0
            return Action.C
        else:
            self.decline_counter = max(0, self.decline_counter - 1)
        self.last_cooperation_rate = cooperation_rate
        if current_round == self.r - 1:
            if cooperation_rate > self.adjusted_threshold:
                return Action.C
            else:
                return Action.D
        if cooperation_rate >= self.adjusted_threshold:
            cooperate_probability = 1.0
        elif cooperation_rate >= self.adjusted_threshold * 0.5:
            cooperate_probability = cooperation_rate
        else:
            cooperate_probability = 0.1
        if current_round >= 5:
            rounds_to_check = min(5, current_round)
            start_round = current_round - rounds_to_check
            high_defectors = 0
            for player_idx in range(self.n - 1):
                defections = 0
                for round_idx in range(start_round, current_round):
                    if not history.opponent_actions[round_idx, player_idx]:
                        defections += 1
                defection_rate = defections / rounds_to_check
                if defection_rate > 0.8:
                    high_defectors += 1
            if high_defectors > (self.n - 1) * 0.5:
                cooperate_probability = max(0.0, cooperate_probability - 0.1)
        return Action.C if random.random() < cooperate_probability else Action.D

class Strategy_COOPERATIVE_74(BaseStrategy):
    """
    Graduated Reciprocator: An adaptive cooperative strategy that balances cooperative intent 
    with responsive adaptation based on group behavior. Starts with cooperation, then adapts 
    using graduated responses based on group cooperation rates and trends.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.consecutive_defection_rounds = 0
        self.last_forgiveness_round = -10

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number
        if current_round <= 2:
            return Action.C
        return self._make_adaptive_decision(current_round, history)

    def _make_adaptive_decision(self, current_round: int, history: PlayerHistory) -> Action:
        recent_gcr = self._calculate_recent_gcr(history)
        trend = self._calculate_trend(history)
        if current_round >= self.game_description.n_rounds - 3:
            return self._handle_endgame(current_round, recent_gcr, history)
        coop_threshold_high = 0.6
        coop_threshold_medium = 0.3
        if self.game_description.k > self.game_description.n_players / 2:
            coop_threshold_high *= 1.2
            coop_threshold_medium *= 1.2
        elif self.game_description.k <= 1.5:
            coop_threshold_high *= 0.85
            coop_threshold_medium *= 0.85
        if recent_gcr >= coop_threshold_high:
            self.consecutive_defection_rounds = 0
            return Action.C
        elif recent_gcr >= coop_threshold_medium and trend >= 0:
            self.consecutive_defection_rounds = 0
            return Action.C
        elif recent_gcr >= coop_threshold_medium and trend < 0:
            self.consecutive_defection_rounds = 0
            coop_prob = 0.7 * recent_gcr
            return Action.C if random.random() < coop_prob else Action.D
        else:
            self.consecutive_defection_rounds += 1
            if self._should_attempt_forgiveness(current_round):
                self.last_forgiveness_round = current_round
                self.consecutive_defection_rounds = 0
                return Action.C
            return Action.D

    def _calculate_recent_gcr(self, history: PlayerHistory) -> float:
        """Calculate Group Cooperation Rate for recent rounds."""
        current_round = history.round_number
        window_size = 3
        if self.game_description.n_players > 8:
            window_size = 5
        elif self._is_highly_volatile(history):
            window_size = 5
        start_round = max(0, current_round - window_size)
        if start_round == current_round:
            return 0.0
        total_cooperators = 0
        total_decisions = 0
        for round_idx in range(start_round, current_round):
            cooperators_in_round = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += cooperators_in_round
            total_decisions += self.game_description.n_players - 1
        return total_cooperators / total_decisions if total_decisions > 0 else 0.0

    def _calculate_trend(self, history: PlayerHistory) -> float:
        """Calculate trend in cooperation rate."""
        current_round = history.round_number
        if current_round < 6:
            return 0.0
        recent_start = max(0, current_round - 3)
        previous_start = max(0, current_round - 6)
        previous_end = recent_start
        recent_cooperators = 0
        recent_decisions = 0
        for round_idx in range(recent_start, current_round):
            cooperators_in_round = np.sum(history.opponent_actions[round_idx, :])
            recent_cooperators += cooperators_in_round
            recent_decisions += self.game_description.n_players - 1
        recent_gcr = recent_cooperators / recent_decisions if recent_decisions > 0 else 0.0
        previous_cooperators = 0
        previous_decisions = 0
        for round_idx in range(previous_start, previous_end):
            cooperators_in_round = np.sum(history.opponent_actions[round_idx, :])
            previous_cooperators += cooperators_in_round
            previous_decisions += self.game_description.n_players - 1
        previous_gcr = previous_cooperators / previous_decisions if previous_decisions > 0 else 0.0
        return recent_gcr - previous_gcr

    def _is_highly_volatile(self, history: PlayerHistory) -> bool:
        """Check if the group behavior is highly volatile."""
        current_round = history.round_number
        if current_round < 6:
            return False
        rates = []
        for round_idx in range(current_round - 6, current_round):
            cooperators = np.sum(history.opponent_actions[round_idx, :])
            rate = cooperators / (self.game_description.n_players - 1)
            rates.append(rate)
        return np.std(rates) > 0.3

    def _should_attempt_forgiveness(self, current_round: int) -> bool:
        """Determine if we should attempt forgiveness cooperation."""
        rounds_since_forgiveness = current_round - self.last_forgiveness_round
        if self.consecutive_defection_rounds >= 5 and rounds_since_forgiveness >= 5:
            return True
        elif self.consecutive_defection_rounds >= 7 and rounds_since_forgiveness >= 7:
            return True
        return False

    def _handle_endgame(self, current_round: int, recent_gcr: float, history: PlayerHistory) -> Action:
        """Handle cooperation decisions in the last 3 rounds."""
        rounds_remaining = self.game_description.n_rounds - current_round
        if recent_gcr >= 0.5:
            return Action.C
        if rounds_remaining == 3:
            coop_prob = max(0.3, recent_gcr)
        elif rounds_remaining == 2:
            coop_prob = max(0.2, recent_gcr * 0.8)
        else:
            coop_prob = max(0.1, recent_gcr * 0.6)
        return Action.C if random.random() < coop_prob else Action.D

class Strategy_COOPERATIVE_75(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation Strategy (ARCS)
    
    Balances cooperative intentions with adaptive responses to observed behavior patterns.
    Establishes and maintains cooperation while protecting against exploitation through
    measured reciprocity and parameter-based thresholds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        cooperation_threshold = max(0.3, (self.k - 1) / (self.n - 1) - 0.1)
        window_size = min(5, current_round)
        recent_opponent_actions = history.opponent_actions[-window_size:, :]
        recent_others_cooperation = np.sum(recent_opponent_actions)
        recent_others_total = (self.n - 1) * window_size
        recent_coop_rate = recent_others_cooperation / recent_others_total if recent_others_total > 0 else 0
        adjusted_threshold = cooperation_threshold
        if current_round <= 3:
            adjusted_threshold -= 0.1
        if current_round == self.r:
            if recent_coop_rate >= 0.6:
                return Action.C
            else:
                return Action.D
        if recent_coop_rate >= adjusted_threshold:
            return Action.C
        elif recent_coop_rate >= adjusted_threshold - 0.15:
            if random.random() < 0.7:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COOPERATIVE_76(BaseStrategy):
    """
    Adaptive Generous Tit-for-Tat (AGTT) Strategy
    
    Balances cooperation with self-protection by being generous in forgiving defection 
    while maintaining incentives for others to cooperate. Adapts to overall cooperation 
    level and becomes more forgiving when cooperation is struggling.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        current_round = history.round_number + 1
        total_rounds = self.game_description.n_rounds
        if current_round == total_rounds:
            return self._final_round_decision(history, n)
        return self._adaptive_decision(history, n, current_round)

    def _final_round_decision(self, history: PlayerHistory, n: int) -> Action:
        """Final round conditional cooperation logic"""
        total_cooperations = np.sum(history.opponent_actions) + np.sum(history.my_actions)
        total_possible = len(history.my_actions) * n
        average_cooperation_rate = total_cooperations / total_possible
        my_cooperation_rate = np.mean(history.my_actions)
        if average_cooperation_rate > 0.6:
            return Action.C
        elif my_cooperation_rate > 0.7 and average_cooperation_rate > 0.4:
            return Action.C
        else:
            return Action.D

    def _adaptive_decision(self, history: PlayerHistory, n: int, current_round: int) -> Action:
        """Main adaptive decision logic for rounds 2 to r-1"""
        last_round_opponents = history.opponent_actions[-1, :]
        last_round_cooperations = np.sum(last_round_opponents) + int(history.my_actions[-1])
        group_cooperation_rate = last_round_cooperations / n
        total_cooperations = np.sum(history.opponent_actions) + np.sum(history.my_actions)
        total_possible = len(history.my_actions) * n
        average_cooperation_rate = total_cooperations / total_possible
        forgiveness_threshold = max(0.3, average_cooperation_rate - 0.2)
        hostile_count = 0
        for player_idx in range(n - 1):
            opponent_actions = history.opponent_actions[:, player_idx]
            opponent_coop_rate = np.mean(opponent_actions)
            last_round_cooperated = last_round_opponents[player_idx]
            if not last_round_cooperated and opponent_coop_rate <= forgiveness_threshold:
                hostile_count += 1
        if group_cooperation_rate >= 0.5:
            return Action.C
        elif hostile_count <= n // 3:
            return Action.C
        elif average_cooperation_rate > 0.4:
            return Action.C if random.random() < 0.7 else Action.D
        else:
            return Action.D

class Strategy_COOPERATIVE_77(BaseStrategy):
    """
    Graduated Reciprocity with Collective Momentum: An adaptive cooperative strategy 
    that balances cooperation with protection against exploitation by tracking both 
    individual reciprocity and collective cooperation patterns.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_threshold = 0.4
        self.reciprocity_threshold = 0.3
        self.forgiveness_window = max(2, game_description.n_rounds // 10)
        self.exploitation_tolerance = 0.7
        if game_description.n_players <= 3:
            self.cooperation_threshold += 0.2
            self.forgiveness_window = 1
        if game_description.k > game_description.n_players / 2:
            self.cooperation_threshold += 0.1
            self.forgiveness_window += 1
        if game_description.n_rounds <= 5:
            self.exploitation_tolerance = 0.8

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        n_rounds = self.game_description.n_rounds
        n_players = self.game_description.n_players
        if current_round == n_rounds - 1:
            return self._final_round_decision(history)
        collective_coop_rate = self._calculate_collective_cooperation_rate(history)
        personal_reciprocity = self._calculate_personal_reciprocity_score(history)
        exploitation_level = self._calculate_exploitation_level(history)
        if collective_coop_rate < 0.3:
            self.cooperation_threshold = max(0.2, self.cooperation_threshold - 0.05)
        if collective_coop_rate >= self.cooperation_threshold:
            if personal_reciprocity >= self.reciprocity_threshold:
                return Action.C
            else:
                return self._graduated_response(exploitation_level)
        else:
            rounds_remaining = n_rounds - current_round
            if rounds_remaining <= self.forgiveness_window and self._showing_improvement(history):
                return Action.C
            else:
                return Action.D

    def _calculate_collective_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate over recent rounds"""
        current_round = history.round_number
        lookback = min(3, current_round)
        if lookback == 0:
            return 0.0
        start_round = max(0, current_round - lookback)
        total_possible = lookback * self.game_description.n_players
        total_cooperations = 0
        for round_idx in range(start_round, current_round):
            total_cooperations += np.sum(history.opponent_actions[round_idx, :])
        return total_cooperations / total_possible if total_possible > 0 else 0.0

    def _calculate_personal_reciprocity_score(self, history: PlayerHistory) -> float:
        """Calculate weighted average of others' cooperation when I cooperated"""
        current_round = history.round_number
        if current_round <= 1:
            return 0.5
        reciprocity_scores = []
        weights = []
        for round_idx in range(current_round - 1):
            if history.my_actions[round_idx]:
                next_round_idx = round_idx + 1
                if next_round_idx < current_round:
                    others_coop_rate = np.mean(history.opponent_actions[next_round_idx, :])
                    reciprocity_scores.append(others_coop_rate)
                    weight = 0.7 ** (current_round - 1 - round_idx)
                    weights.append(weight)
        if not reciprocity_scores:
            return 0.5
        weights = np.array(weights)
        reciprocity_scores = np.array(reciprocity_scores)
        return np.average(reciprocity_scores, weights=weights)

    def _calculate_exploitation_level(self, history: PlayerHistory) -> float:
        """Calculate how often others defect when I cooperate"""
        current_round = history.round_number
        my_coops = 0
        others_defects_when_i_coop = 0
        for round_idx in range(current_round):
            if history.my_actions[round_idx]:
                my_coops += 1
                others_defects_when_i_coop += np.sum(~history.opponent_actions[round_idx, :])
        if my_coops == 0:
            return 0.0
        total_possible_defects = my_coops * self.game_description.n_players
        return others_defects_when_i_coop / total_possible_defects

    def _graduated_response(self, exploitation_level: float) -> Action:
        """Apply graduated punishment based on exploitation level"""
        if exploitation_level < 0.3:
            return Action.C
        elif exploitation_level < 0.7:
            coop_prob = (0.7 - exploitation_level) / 0.4
            return Action.C if random.random() < coop_prob else Action.D
        else:
            return Action.D

    def _showing_improvement(self, history: PlayerHistory) -> bool:
        """Check if group cooperation is trending upward"""
        current_round = history.round_number
        if current_round < 3:
            return False
        recent_coop = np.mean(history.opponent_actions[-1, :]) if current_round > 0 else 0
        prev_coop = np.mean(history.opponent_actions[-2, :]) if current_round > 1 else 0
        return recent_coop > prev_coop

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """Strategic decision for the final round"""
        collective_coop_rate = self._calculate_collective_cooperation_rate(history)
        personal_reciprocity = self._calculate_personal_reciprocity_score(history)
        if collective_coop_rate > 0.6:
            return Action.C
        if personal_reciprocity < 0.3:
            return Action.D
        if history.round_number > 0:
            last_round_coops = np.sum(history.opponent_actions[-1, :])
            total_opponents = self.game_description.n_players
            if last_round_coops > total_opponents / 2:
                return Action.C
            else:
                return Action.D
        return Action.C

class Strategy_COOPERATIVE_78(BaseStrategy):
    """
    Adaptive Cooperative Strategy: "Trust with Graduated Forgiveness"
    
    Begins with trust and cooperation, adapts based on collective behavior while maintaining
    cooperative orientation. Uses dynamic thresholds, forgiveness windows, and trend detection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.forgiveness_window = 0
        self.cooperation_threshold = max(0.3, (game_description.k - 1) / (game_description.n_players - 1))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        current_round = history.round_number
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        cooperation_rate = last_round_cooperators / n
        if current_round == 1:
            if cooperation_rate >= 0.3:
                return Action.C
            else:
                self.forgiveness_window = 2
                return Action.C
        prev_round_cooperators = sum(history.opponent_actions[-2, :])
        if history.my_actions[-2]:
            prev_round_cooperators += 1
        prev_cooperation_rate = prev_round_cooperators / n
        cooperation_bias = 0.1 if cooperation_rate > prev_cooperation_rate else 0
        adjusted_threshold = self.cooperation_threshold - cooperation_bias
        if self.forgiveness_window > 0:
            self.forgiveness_window -= 1
            return Action.C
        if cooperation_rate == 0:
            self.forgiveness_window = 2
            return Action.C
        if cooperation_rate >= 0.8:
            return Action.C
        if current_round >= self.game_description.n_rounds - 2:
            total_cooperators = 0
            total_opportunities = 0
            for round_idx in range(current_round):
                round_cooperators = sum(history.opponent_actions[round_idx, :])
                if history.my_actions[round_idx]:
                    round_cooperators += 1
                total_cooperators += round_cooperators
                total_opportunities += n
            overall_cooperation_rate = total_cooperators / total_opportunities
            if overall_cooperation_rate >= 0.6:
                return Action.C
        cooperate_conditions = [cooperation_rate >= adjusted_threshold, cooperation_rate > prev_cooperation_rate]
        if any(cooperate_conditions):
            return Action.C
        else:
            if cooperation_rate < adjusted_threshold and cooperation_rate <= prev_cooperation_rate:
                self.forgiveness_window = 2
            return Action.D

class Strategy_COOPERATIVE_79(BaseStrategy):
    """
    Graduated Reciprocator: An adaptive cooperative strategy that balances cooperative intent 
    with adaptive responses based on observed group behavior. Uses dynamic cooperation thresholds
    and sliding window assessment to maintain cooperation while protecting against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.threshold = 0.5
        self.min_threshold = 0.3
        self.max_threshold = 0.8
        self.zero_coop_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.threshold = 0.5
            self.zero_coop_streak = 0
            return Action.C
        window_size = min(3, history.round_number)
        if self.game_description.n_players > 8:
            window_size = min(4, history.round_number)
        recent_opponent_actions = history.opponent_actions[-window_size:, :]
        recent_my_actions = history.my_actions[-window_size:]
        total_cooperators = 0
        for round_idx in range(window_size):
            round_cooperators = np.sum(recent_opponent_actions[round_idx, :]) + int(recent_my_actions[round_idx])
            total_cooperators += round_cooperators
        cooperation_rate = total_cooperators / (self.game_description.n_players * window_size)
        last_round_cooperators = np.sum(history.opponent_actions[-1, :]) + int(history.my_actions[-1])
        if last_round_cooperators == 0:
            self.zero_coop_streak += 1
        else:
            self.zero_coop_streak = 0
        if self.zero_coop_streak >= 2:
            self.threshold = 0.4
            self.zero_coop_streak = 0
            return Action.C
        if cooperation_rate > self.threshold:
            new_threshold = self.threshold * 0.9
        else:
            new_threshold = self.threshold * 1.1
        self.threshold = max(self.min_threshold, min(self.max_threshold, new_threshold))
        if history.round_number <= 2:
            self.threshold = min(self.threshold, 0.6)
        k_ratio = self.game_description.k / self.game_description.n_players
        adjusted_threshold = self.threshold
        if k_ratio > 0.8:
            adjusted_threshold *= 0.9
        elif k_ratio < 0.4:
            adjusted_threshold *= 1.15
        if state.round_number == self.game_description.n_rounds - 1:
            adjusted_threshold = max(0.25, adjusted_threshold * 0.8)
        if cooperation_rate >= adjusted_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_80(BaseStrategy):
    """
    Graduated Reciprocator: An adaptive cooperative strategy that maximizes collective welfare
    while protecting against exploitation through group behavior momentum tracking.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.forgiveness_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.forgiveness_counter = 0
            return Action.C
        n = self.game_description.n_players
        current_round = history.round_number
        total_rounds = self.game_description.n_rounds
        if current_round == total_rounds - 1:
            return self._final_round_decision(history, n)
        self.forgiveness_counter += 1
        if self.forgiveness_counter >= 3 and current_round > 2:
            self.forgiveness_counter = 0
            return Action.C
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        last_coop_rate = last_round_cooperators / n
        momentum = 0
        if current_round >= 2:
            prev_round_cooperators = sum(history.opponent_actions[-2, :])
            if history.my_actions[-2]:
                prev_round_cooperators += 1
            prev_coop_rate = prev_round_cooperators / n
            momentum = last_coop_rate - prev_coop_rate
        if last_coop_rate >= 0.6:
            return Action.C
        if last_coop_rate >= 0.4 and momentum >= 0:
            return Action.C
        if last_coop_rate >= 0.3 and history.my_actions[-1]:
            if current_round > 0:
                my_recent_payoff = history.my_payoffs[-1]
                group_payoffs = np.concatenate([history.opponent_payoffs[-1, :], [my_recent_payoff]])
                group_average = np.mean(group_payoffs)
                if my_recent_payoff >= group_average:
                    return Action.C
        if last_coop_rate >= 0.2:
            cooperation_probability = last_coop_rate + 0.2
            if random.random() < cooperation_probability:
                return Action.C
            else:
                return Action.D
        return Action.D

    def _final_round_decision(self, history: PlayerHistory, n: int) -> Action:
        """Special logic for the final round."""
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        last_coop_rate = last_round_cooperators / n
        if last_coop_rate >= 0.5:
            return Action.C
        if last_coop_rate >= 0.3:
            total_payoffs = []
            for i in range(self.game_description.n_players - 1):
                opponent_total = sum(history.opponent_payoffs[:, i])
                total_payoffs.append(opponent_total)
            my_total = sum(history.my_payoffs)
            total_payoffs.append(my_total)
            median_payoff = np.median(total_payoffs)
            if my_total >= median_payoff:
                return Action.C
        return Action.D

class Strategy_COOPERATIVE_81(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Forgiveness Strategy
    
    Balances cooperation promotion with exploitation resistance through:
    - Initial cooperation (rounds 1-2)
    - Threshold-based reciprocation (50% cooperation rate)
    - Periodic forgiveness every 4th round
    - No end-game defection
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_number = history.round_number + 1
        if round_number <= 2:
            return Action.C
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        cooperation_rate = last_round_cooperators / self.game_description.n_players
        if cooperation_rate >= 0.5:
            return Action.C
        if round_number % 4 == 0:
            return Action.C
        return Action.D

class Strategy_COOPERATIVE_82(BaseStrategy):
    """
    Adaptive Cooperative Strategy: "Graduated Reciprocator"
    
    Prioritizes cooperation while maintaining resilience against exploitation through
    graduated responses and adaptive thresholds. Balances trust-building with 
    self-protection by adjusting cooperation thresholds over time and responding
    proportionally to defection levels.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.base_threshold = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number + 1
        if current_round == self.r:
            return self._final_round_decision(history)
        return self._adaptive_reciprocation(history, current_round)

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """Final round: Conditional cooperation based on overall patterns"""
        my_cooperation_rate = np.mean(history.my_actions)
        others_cooperation_rate = np.mean(history.opponent_actions)
        if my_cooperation_rate > 0.6 and others_cooperation_rate > self.base_threshold:
            return Action.C
        else:
            return Action.D

    def _adaptive_reciprocation(self, history: PlayerHistory, current_round: int) -> Action:
        """Main decision logic for rounds 2 to r-1"""
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        cooperation_rate = last_round_cooperators / (self.n - 1)
        adjustment_factor = 0.1 * (current_round / self.r)
        cooperation_threshold = self.base_threshold - adjustment_factor
        if cooperation_rate >= cooperation_threshold:
            return Action.C
        defection_severity = (self.base_threshold - cooperation_rate) / self.base_threshold
        if defection_severity < 0.3:
            return Action.C
        elif defection_severity < 0.7:
            last_round_i_cooperated = bool(history.my_actions[-1])
            if last_round_i_cooperated and cooperation_rate > 0.2:
                return Action.C
            else:
                return Action.D
        else:
            if len(history.my_actions) >= 3:
                if self._check_forgiveness_condition(history):
                    return Action.C
            return Action.D

    def _check_forgiveness_condition(self, history: PlayerHistory) -> bool:
        """Check if forgiveness should be applied"""
        if len(history.opponent_actions) < 3:
            return False
        recent_coop_rates = []
        for i in range(-2, 0):
            round_cooperators = np.sum(history.opponent_actions[i, :])
            round_coop_rate = round_cooperators / (self.n - 1)
            recent_coop_rates.append(round_coop_rate)
        cooperation_improved = recent_coop_rates[-1] > recent_coop_rates[-2]
        my_recent_cooperation = np.mean(history.my_actions[-3:]) > 0.7
        return cooperation_improved and my_recent_cooperation

class Strategy_COOPERATIVE_83(BaseStrategy):
    """
    Progressive Trust Builder: An adaptive cooperative strategy that starts with trust,
    maintains cooperation when mutually beneficial, and includes forgiveness mechanisms
    to prevent permanent breakdown of cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.cooperation_threshold = self.n / self.k
        self.consecutive_defection_rounds = 0
        self.last_cooperation_test_round = -10

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.consecutive_defection_rounds = 0
            return Action.C
        current_round = state.round_number
        initial_phase_length = max(3, math.ceil(0.2 * self.r))
        if current_round < initial_phase_length:
            return Action.C
        recent_window = min(3, math.ceil(0.3 * (self.r - current_round)))
        recent_window = max(1, recent_window)
        start_round = max(0, history.round_number - recent_window)
        recent_cooperation_count = 0
        total_recent_decisions = 0
        for round_idx in range(start_round, history.round_number):
            my_cooperation = 1 if history.my_actions[round_idx] else 0
            opponent_cooperation = np.sum(history.opponent_actions[round_idx, :])
            total_cooperation = my_cooperation + opponent_cooperation
            recent_cooperation_count += total_cooperation
            total_recent_decisions += self.n
        recent_cooperation_rate = recent_cooperation_count / total_recent_decisions if total_recent_decisions > 0 else 0
        current_threshold = self.cooperation_threshold
        if current_round >= 0.9 * self.r:
            current_threshold *= 1.2
        if recent_cooperation_rate >= current_threshold:
            self.consecutive_defection_rounds = 0
            return Action.C
        if history.round_number > 0:
            last_round_opponent_cooperation = np.sum(history.opponent_actions[-1, :])
            if last_round_opponent_cooperation == 0:
                self.consecutive_defection_rounds += 1
            else:
                self.consecutive_defection_rounds = 0
        if self.consecutive_defection_rounds >= 2 and current_round - self.last_cooperation_test_round >= 4:
            self.last_cooperation_test_round = current_round
            self.consecutive_defection_rounds = 0
            return Action.C
        if self.consecutive_defection_rounds >= 3 and (current_round - self.last_cooperation_test_round) % 4 == 0:
            self.last_cooperation_test_round = current_round
            return Action.C
        return Action.D

class Strategy_COOPERATIVE_84(BaseStrategy):
    """
    Trust-Building Reciprocator: An adaptive cooperative strategy that builds trust
    while protecting against exploitation. Tracks individual cooperation scores
    and responds to group dynamics with forgiveness mechanisms.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        cooperation_scores = []
        for j in range(self.n - 1):
            total_rounds = len(history.my_actions)
            cooperations = sum(history.opponent_actions[:, j])
            cooperation_scores.append(cooperations / total_rounds if total_rounds > 0 else 0)
        if current_round == self.r - 1:
            return self._final_round_decision(history, cooperation_scores)
        return self._adaptive_reciprocation(history, cooperation_scores)

    def _final_round_decision(self, history, cooperation_scores):
        if len(history.my_actions) > 0:
            prev_round_coop = sum(history.opponent_actions[-1, :]) / (self.n - 1)
        else:
            prev_round_coop = 0
        reliable_cooperators = sum((1 for score in cooperation_scores if score >= 0.6))
        required_reliable = min(3, max(1, self.n // 2))
        if prev_round_coop >= 0.6 and reliable_cooperators >= required_reliable:
            return Action.C
        else:
            return Action.D

    def _adaptive_reciprocation(self, history, cooperation_scores):
        if len(history.my_actions) > 0:
            group_coop = sum(history.opponent_actions[-1, :]) / (self.n - 1)
        else:
            group_coop = 0
        coop_threshold = self._get_cooperation_threshold()
        reliable_threshold = 0.7
        required_reliable = self._get_required_reliable_cooperators()
        should_cooperate = False
        if group_coop >= coop_threshold:
            should_cooperate = True
        reliable_cooperators = sum((1 for score in cooperation_scores if score >= reliable_threshold))
        if reliable_cooperators >= required_reliable:
            should_cooperate = True
        if len(history.my_actions) > 0 and group_coop >= 0.99:
            should_cooperate = True
        if len(history.my_actions) > 0 and (not history.my_actions[-1]) and (group_coop >= 0.3):
            should_cooperate = True
        if len(history.my_actions) > 0:
            my_coop_rate = sum(history.my_actions) / len(history.my_actions)
            if my_coop_rate < 0.4:
                should_cooperate = True
        return Action.C if should_cooperate else Action.D

    def _get_cooperation_threshold(self):
        """Adjust cooperation threshold based on game parameters"""
        base_threshold = 0.5
        if self.n <= 4:
            base_threshold = 0.4
        if self.k > 0.8 * self.n:
            base_threshold = 0.3
        elif self.k < 0.4 * self.n:
            base_threshold = 0.6
        return base_threshold

    def _get_required_reliable_cooperators(self):
        """Determine how many reliable cooperators needed"""
        if self.n <= 4:
            return 1
        else:
            return 2

class Strategy_COOPERATIVE_85(BaseStrategy):
    """
    Graduated Reciprocal Cooperation (GRC) Strategy
    
    Balances cooperation with adaptive responses to opponent behavior through:
    1. Initial cooperation phase to establish cooperative intent
    2. Adaptive cooperation based on recent group cooperation rates
    3. Forgiveness mechanism to recover from defection spirals
    4. Endgame strategy that considers recent cooperation success
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.cooperation_threshold = max(0.4, (self.k - 1) / (self.n - 1) * 0.8)
        self.initial_phase_end = max(3, self.r // 3) if self.r > 4 else 1
        self.endgame_start = math.ceil(self.r * 0.8)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if current_round == self.r:
            return Action.C
        if current_round <= self.initial_phase_end:
            return Action.C
        lookback_rounds = min(3, current_round - 1)
        recent_opponent_actions = history.opponent_actions[-lookback_rounds:, :]
        total_recent_decisions = recent_opponent_actions.size
        recent_cooperators = np.sum(recent_opponent_actions)
        others_recent_cooperation = recent_cooperators / total_recent_decisions
        if current_round >= self.endgame_start:
            all_opponent_actions = history.opponent_actions
            total_decisions = all_opponent_actions.size
            total_cooperators = np.sum(all_opponent_actions)
            group_cooperation_rate = total_cooperators / total_decisions
            if group_cooperation_rate > 0.6:
                return Action.C
            elif group_cooperation_rate < 0.3 and current_round < self.r:
                return Action.D
            else:
                return Action.C
        if others_recent_cooperation >= self.cooperation_threshold:
            return Action.C
        else:
            consecutive_defections = 0
            for i in range(len(history.my_actions) - 1, -1, -1):
                if not history.my_actions[i]:
                    consecutive_defections += 1
                else:
                    break
            if consecutive_defections > 0 and consecutive_defections % 4 == 3:
                return Action.C
            else:
                return Action.D

class Strategy_COOPERATIVE_86(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation Strategy that maximizes collective welfare 
    while protecting against exploitation through graduated reciprocity and 
    adaptive cooperation thresholds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        round_num = state.round_number + 1
        if round_num <= 3:
            last_round_cooperators = sum(history.opponent_actions[-1, :])
            return Action.C if last_round_cooperators >= (n - 1) / 2 else Action.D
        last_round_rate = sum(history.opponent_actions[-1, :]) / (n - 1)
        prev_round_rate = sum(history.opponent_actions[-2, :]) / (n - 1)
        recent_cooperation_rate = (2 * last_round_rate + prev_round_rate) / 3
        rounds_remaining = r - round_num + 1
        tolerance_buffer = 0.1 + 0.2 * rounds_remaining / r
        cooperation_threshold = max(0.3, recent_cooperation_rate - tolerance_buffer)
        return Action.C if recent_cooperation_rate >= cooperation_threshold else Action.D

class Strategy_COOPERATIVE_87(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation (ARC) Strategy.
    
    Starts with cooperation to signal intent, then adapts based on others' cooperation rates.
    Uses proportional responses in medium cooperation scenarios and includes forgiveness
    mechanisms to help restart cooperation cycles.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if current_round <= 1:
            return Action.C
        if current_round == self.n_rounds - 1:
            prev_cooperators = sum(history.opponent_actions[-1, :])
            prev_cooperation_rate = prev_cooperators / (self.n_players - 1)
            return Action.C if prev_cooperation_rate >= 0.6 else Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        cooperation_rate = last_round_cooperators / (self.n_players - 1)
        consecutive_low = self._count_consecutive_low_cooperation(history)
        if cooperation_rate >= 0.6:
            return Action.C
        elif cooperation_rate >= 0.3:
            if random.random() < cooperation_rate:
                return Action.C
            else:
                return Action.D
        elif consecutive_low > 0 and consecutive_low % 3 == 0:
            return Action.C
        else:
            return Action.D

    def _count_consecutive_low_cooperation(self, history: PlayerHistory) -> int:
        """Count consecutive rounds where cooperation rate was below 0.3."""
        count = 0
        for round_idx in range(len(history.opponent_actions) - 1, -1, -1):
            cooperators = sum(history.opponent_actions[round_idx, :])
            cooperation_rate = cooperators / (self.n_players - 1)
            if cooperation_rate < 0.3:
                count += 1
            else:
                break
        return count

class Strategy_COOPERATIVE_88(BaseStrategy):
    """
    Graduated Reciprocator: An adaptive cooperative strategy that balances cooperative 
    intentions with graduated responses to observed behavior. Maintains cooperative bias 
    while protecting against exploitation through dynamic thresholds and forgiveness mechanisms.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.low_cooperation_streak = 0
        self.recovery_mode = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number + 1
        if current_round <= 3:
            if current_round == 2:
                first_round_cooperation = np.sum(history.opponent_actions[0, :]) / (self.n - 1)
                if first_round_cooperation <= 0.2:
                    return Action.D
                return Action.C
            elif current_round == 3:
                total_cooperators = np.sum(history.opponent_actions[:2, :])
                cooperation_rate = total_cooperators / (2 * (self.n - 1))
                if cooperation_rate <= 0.2:
                    return Action.D
                return Action.C
        lookback_rounds = min(3, history.round_number)
        recent_rounds_start = max(0, history.round_number - lookback_rounds)
        recent_opponent_actions = history.opponent_actions[recent_rounds_start:, :]
        recent_cooperators = np.sum(recent_opponent_actions)
        recent_cooperation_rate = recent_cooperators / (lookback_rounds * (self.n - 1))
        forgiveness_bonus = min(0.2, current_round / self.r * 0.15)
        base_threshold = self.k / self.n - 0.1
        cooperation_threshold = max(0.3, base_threshold + forgiveness_bonus)
        if history.round_number > 0:
            prev_round_cooperation = np.sum(history.opponent_actions[-1, :]) / (self.n - 1)
            if prev_round_cooperation > 0.7:
                return Action.C
        if recent_cooperation_rate < 0.2:
            self.low_cooperation_streak += 1
        else:
            self.low_cooperation_streak = 0
            self.recovery_mode = False
        if self.low_cooperation_streak >= 2:
            self.recovery_mode = True
        if self.recovery_mode and history.round_number >= 3:
            last_3_cooperation = np.sum(history.opponent_actions[-3:, :]) / (3 * (self.n - 1))
            if last_3_cooperation < 0.1:
                if current_round % 4 == 0:
                    return Action.C
                if history.round_number >= 4:
                    my_recent_actions = history.my_actions[-4:]
                    opponent_recent_actions = history.opponent_actions[-4:, :]
                    for i in range(len(my_recent_actions)):
                        if my_recent_actions[i] and np.sum(opponent_recent_actions[i, :]) > 0:
                            self.recovery_mode = False
                            break
        if history.round_number >= 5:
            last_5_cooperation = np.sum(history.opponent_actions[-5:, :]) / (5 * (self.n - 1))
            if last_5_cooperation > 0.8:
                if recent_cooperation_rate >= 0.6:
                    return Action.C
        final_rounds_threshold = max(1, int(0.1 * self.r))
        rounds_remaining = self.r - current_round + 1
        if rounds_remaining <= final_rounds_threshold:
            total_cooperators = np.sum(history.opponent_actions)
            total_cooperation_rate = total_cooperators / (history.round_number * (self.n - 1))
            if rounds_remaining == 1:
                if history.round_number > 0:
                    prev_round_cooperation = np.sum(history.opponent_actions[-1, :]) / (self.n - 1)
                    if prev_round_cooperation >= 0.4:
                        return Action.C
                    else:
                        return Action.D
            if total_cooperation_rate > 0.5:
                return Action.C
            elif total_cooperation_rate >= 0.3:
                if random.random() < 0.7:
                    return Action.C
                else:
                    return Action.D
            elif random.random() < total_cooperation_rate:
                return Action.C
            else:
                return Action.D
        if recent_cooperation_rate >= cooperation_threshold:
            return Action.C
        elif recent_cooperation_rate >= 0.2:
            cooperation_prob = min(1.0, recent_cooperation_rate + 0.1)
            if random.random() < cooperation_prob:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COOPERATIVE_89(BaseStrategy):
    """
    Gradual Trust Builder: An adaptive cooperative strategy that balances cooperation with self-protection
    by gradually building trust while maintaining the ability to respond to defection patterns.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.cooperation_threshold = max(0.3, self.k / self.n_players)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if current_round == 1:
            return Action.C
        if current_round == self.n_rounds - 1:
            return self._final_round_decision(history)
        return self._main_strategy_decision(history)

    def _get_recent_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate in recent window (last 3 rounds or all available)."""
        recent_window = min(3, history.round_number)
        if recent_window == 0:
            return 1.0
        recent_opponent_actions = history.opponent_actions[-recent_window:, :]
        recent_my_actions = history.my_actions[-recent_window:]
        total_cooperators = 0
        for round_idx in range(recent_window):
            round_cooperators = sum(recent_opponent_actions[round_idx, :]) + int(recent_my_actions[round_idx])
            total_cooperators += round_cooperators
        total_possible = self.n_players * recent_window
        return total_cooperators / total_possible if total_possible > 0 else 0.0

    def _get_overall_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate overall cooperation rate across all rounds."""
        if history.round_number == 0:
            return 1.0
        total_cooperators = 0
        for round_idx in range(history.round_number):
            round_cooperators = sum(history.opponent_actions[round_idx, :]) + int(history.my_actions[round_idx])
            total_cooperators += round_cooperators
        total_possible = self.n_players * history.round_number
        return total_cooperators / total_possible if total_possible > 0 else 0.0

    def _main_strategy_decision(self, history: PlayerHistory) -> Action:
        """Main strategy decision using dynamic threshold system."""
        recent_cooperation_rate = self._get_recent_cooperation_rate(history)
        if recent_cooperation_rate >= self.cooperation_threshold:
            return Action.C
        else:
            defection_severity = (self.cooperation_threshold - recent_cooperation_rate) / self.cooperation_threshold
            if defection_severity > 0.6:
                return Action.D
            elif defection_severity > 0.3:
                if random.random() < 0.7:
                    return Action.D
                else:
                    return Action.C
            else:
                return Action.C

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """Final round strategy based on overall and recent cooperation."""
        overall_cooperation_rate = self._get_overall_cooperation_rate(history)
        recent_cooperation_rate = self._get_recent_cooperation_rate(history)
        if overall_cooperation_rate >= 0.4:
            return Action.C
        elif recent_cooperation_rate >= self.cooperation_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_90(BaseStrategy):
    """
    Adaptive Cooperative Strategy: "Graduated Reciprocator"
    
    Balances cooperation and defection based on environmental cooperation rates,
    using dynamic thresholds and forgiveness mechanisms to avoid exploitation
    while encouraging mutual cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        rounds_to_check = min(3, history.round_number)
        recent_rounds = history.opponent_actions[-rounds_to_check:, :]
        recent_coop_rates = []
        for i in range(rounds_to_check):
            round_idx = -rounds_to_check + i
            opponent_cooperators = sum(recent_rounds[i, :])
            my_action_in_round = history.my_actions[round_idx]
            total_cooperators = opponent_cooperators + (1 if my_action_in_round else 0)
            coop_rate = total_cooperators / self.n_players
            recent_coop_rates.append(coop_rate)
        recent_coop_rate = sum(recent_coop_rates) / len(recent_coop_rates)
        if recent_coop_rate >= 0.6:
            cooperation_threshold = 0.4
        elif recent_coop_rate >= 0.3:
            cooperation_threshold = 0.5
        else:
            cooperation_threshold = 0.7
        rounds_remaining = self.n_rounds - state.round_number
        is_endgame = rounds_remaining <= max(1, math.floor(self.n_rounds * 0.1))
        last_round_opponents = history.opponent_actions[-1, :]
        last_round_cooperators = sum(last_round_opponents)
        my_last_action = history.my_actions[-1]
        last_round_total_cooperators = last_round_cooperators + (1 if my_last_action else 0)
        last_round_coop_rate = last_round_total_cooperators / self.n_players
        if is_endgame and recent_coop_rate < 0.3:
            return Action.D
        elif recent_coop_rate >= cooperation_threshold:
            return Action.C
        elif last_round_cooperators >= self.n_players / 2:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_91(BaseStrategy):
    """
    Adaptive Tit-for-Tat with Forgiveness Strategy (ATTF)
    
    Balances reciprocity, forgiveness, and adaptability in public goods games.
    Starts cooperatively, responds to cooperation rates, includes forgiveness
    mechanisms, and adapts thresholds based on game parameters.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.trust_score = 0.5
        self.last_forgiveness_round = -5
        self.base_coop_threshold = 0.5
        self.base_hope_threshold = 0.3
        n = game_description.n_players
        k = game_description.k
        if k / n > 0.8:
            self.coop_threshold = self.base_coop_threshold - 0.1
            self.hope_threshold = self.base_hope_threshold - 0.1
        elif k / n < 0.3:
            self.coop_threshold = self.base_coop_threshold + 0.1
            self.hope_threshold = self.base_hope_threshold + 0.1
        else:
            self.coop_threshold = self.base_coop_threshold
            self.hope_threshold = self.base_hope_threshold
        if n <= 4:
            self.coop_threshold -= 0.1
            self.hope_threshold -= 0.1
        elif n >= 10:
            self.coop_threshold += 0.1
            self.hope_threshold += 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = state.round_number
        n_rounds = self.game_description.n_rounds
        n_players = self.game_description.n_players
        k = self.game_description.k
        if round_num == n_rounds - 1:
            return self._final_round_decision(history)
        last_round_opponents = history.opponent_actions[-1, :]
        cooperators_last_round = sum(last_round_opponents)
        total_cooperators_last_round = cooperators_last_round + (1 if history.my_actions[-1] else 0)
        cooperation_rate = cooperators_last_round / (n_players - 1)
        my_last_payoff = history.my_payoffs[-1]
        defector_payoff = 1 + k / n_players * total_cooperators_last_round
        personal_benefit_ratio = my_last_payoff / defector_payoff if defector_payoff > 0 else 1.0
        self._update_trust_score(cooperation_rate)
        if self._should_attempt_forgiveness(history, round_num):
            self.last_forgiveness_round = round_num
            return Action.C
        if cooperation_rate >= self.coop_threshold:
            if personal_benefit_ratio >= 0.9:
                return Action.C
            else:
                return Action.D
        elif cooperation_rate >= self.hope_threshold and round_num <= 0.7 * n_rounds:
            return Action.C
        else:
            return Action.D

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """Endgame cooperation test"""
        rounds_to_check = min(3, len(history.my_actions))
        if rounds_to_check == 0:
            return Action.D
        recent_cooperation_rates = []
        for i in range(rounds_to_check):
            round_idx = -(i + 1)
            opponents_last = history.opponent_actions[round_idx, :]
            cr = sum(opponents_last) / len(opponents_last)
            recent_cooperation_rates.append(cr)
        avg_recent_cooperation = sum(recent_cooperation_rates) / len(recent_cooperation_rates)
        if avg_recent_cooperation >= 0.4:
            return Action.C
        else:
            return Action.D

    def _update_trust_score(self, cooperation_rate: float):
        """Update trust score based on cooperation rate"""
        if cooperation_rate > 0.6:
            self.trust_score = min(1.0, self.trust_score + 0.1)
        elif cooperation_rate < 0.2:
            self.trust_score = max(0.0, self.trust_score - 0.2)

    def _should_attempt_forgiveness(self, history: PlayerHistory, current_round: int) -> bool:
        """Check if we should attempt forgiveness"""
        if current_round - self.last_forgiveness_round < 5:
            return False
        if len(history.opponent_actions) < 3:
            return False
        consecutive_low_coop = 0
        for i in range(min(3, len(history.opponent_actions))):
            round_idx = -(i + 1)
            opponents = history.opponent_actions[round_idx, :]
            cr = sum(opponents) / len(opponents)
            if cr < 0.3:
                consecutive_low_coop += 1
            else:
                break
        return consecutive_low_coop >= 3

class Strategy_COOPERATIVE_92(BaseStrategy):
    """
    Adaptive Cooperative Strategy: "Generous Tit-for-Tat with Momentum"
    
    This strategy balances cooperative intent with adaptive punishment, using forgiveness 
    mechanisms to maintain cooperation while protecting against exploitation. It maintains
    cooperation scores for each opponent and adapts based on group cooperation levels.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_scores = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.cooperation_scores = [1.0] * (self.game_description.n_players - 1)
            return Action.C
        recent_actions = history.opponent_actions[-1, :]
        for j in range(len(self.cooperation_scores)):
            self.cooperation_scores[j] = 0.7 * self.cooperation_scores[j] + 0.3 * float(recent_actions[j])
        group_cooperation_rate = sum(self.cooperation_scores) / (self.game_description.n_players - 1)
        previous_round_cooperators = sum(recent_actions)
        cooperation_fraction = previous_round_cooperators / (self.game_description.n_players - 1)
        if state.round_number == self.game_description.n_rounds - 1:
            if group_cooperation_rate >= 0.5:
                return Action.C
            else:
                return Action.D
        if group_cooperation_rate >= 0.7:
            return Action.C
        elif group_cooperation_rate >= 0.4:
            if cooperation_fraction >= 0.5:
                return Action.C
            elif random.random() < 0.6:
                return Action.C
            else:
                return Action.D
        elif cooperation_fraction >= 0.3:
            if random.random() < 0.3:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_COOPERATIVE_93(BaseStrategy):
    """
    Graduated Reciprocator: An adaptive cooperative strategy that balances optimism with 
    responsiveness to group dynamics. Starts cooperatively, adjusts thresholds based on 
    group behavior history, includes forgiveness mechanisms, and handles endgame scenarios.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_number = history.round_number + 1
        prev_round_cooperators = sum(history.opponent_actions[-1, :]) + int(history.my_actions[-1])
        coop_rate = prev_round_cooperators / self.n
        total_cooperators_history = 0
        total_rounds_so_far = len(history.my_actions)
        for round_idx in range(total_rounds_so_far):
            round_cooperators = sum(history.opponent_actions[round_idx, :]) + int(history.my_actions[round_idx])
            total_cooperators_history += round_cooperators
        avg_coop_rate = total_cooperators_history / (total_rounds_so_far * self.n)
        base_threshold = 0.4
        adjustment = 0.1 * (avg_coop_rate - 0.5)
        threshold = max(0.2, min(0.7, base_threshold + adjustment))
        if round_number > 0.8 * self.r or round_number > self.r - 3:
            threshold += 0.1
            threshold = min(0.7, threshold)
        if self._is_recovery_round(history, coop_rate):
            return Action.C
        if self._is_declining_trend(history) and coop_rate < 0.3:
            threshold = 0.6
        if round_number == self.r:
            my_coop_rate = sum(history.my_actions) / len(history.my_actions)
            if coop_rate >= 0.5 or my_coop_rate >= 0.7:
                return Action.C
            else:
                return Action.D
        if coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _is_recovery_round(self, history: PlayerHistory, current_coop_rate: float) -> bool:
        """Check if this is a recovery round after consecutive low cooperation."""
        if len(history.my_actions) < 3:
            return False
        consecutive_low = 0
        for i in range(max(0, len(history.my_actions) - 2), len(history.my_actions)):
            round_cooperators = sum(history.opponent_actions[i, :]) + int(history.my_actions[i])
            round_coop_rate = round_cooperators / self.n
            if round_coop_rate < 0.4:
                consecutive_low += 1
        return consecutive_low >= 2 and current_coop_rate >= 0.6

    def _is_declining_trend(self, history: PlayerHistory) -> bool:
        """Check if cooperation has been declining over the last 3 rounds."""
        if len(history.my_actions) < 3:
            return False
        recent_rates = []
        for i in range(max(0, len(history.my_actions) - 3), len(history.my_actions)):
            round_cooperators = sum(history.opponent_actions[i, :]) + int(history.my_actions[i])
            round_coop_rate = round_cooperators / self.n
            recent_rates.append(round_coop_rate)
        if len(recent_rates) >= 3:
            return recent_rates[0] > recent_rates[1] > recent_rates[2]
        elif len(recent_rates) == 2:
            return recent_rates[0] > recent_rates[1]
        return False

class Strategy_COOPERATIVE_94(BaseStrategy):
    """
    Graduated Reciprocator: Adaptive cooperative strategy that balances collective welfare
    with protection against exploitation through dynamic cooperation thresholds and
    graduated responses to defection patterns.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_threshold = 0.5
        self.defection_countdown = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number
        n_players = self.game_description.n_players
        n_rounds = self.game_description.n_rounds
        k = self.game_description.k
        early_phase_end = min(5, n_rounds // 4)
        if current_round < early_phase_end:
            return Action.C
        if self.defection_countdown > 0:
            self.defection_countdown -= 1
            return Action.D
        W = min(3, max(1, current_round // 2))
        recent_start = max(0, current_round - W)
        recent_opponent_actions = history.opponent_actions[recent_start:, :]
        recent_my_actions = history.my_actions[recent_start:]
        total_recent_decisions = recent_opponent_actions.size
        if total_recent_decisions > 0:
            recent_cooperation_rate = np.sum(recent_opponent_actions) / total_recent_decisions
        else:
            recent_cooperation_rate = 0.5
        my_recent_cooperations = np.sum(recent_my_actions)
        if my_recent_cooperations > 0:
            exploitation_sum = 0
            cooperation_count = 0
            for i, my_action in enumerate(recent_my_actions):
                if my_action:
                    opponent_defection_rate = 1 - np.mean(recent_opponent_actions[i, :])
                    exploitation_sum += opponent_defection_rate
                    cooperation_count += 1
            my_exploitation_rate = exploitation_sum / cooperation_count if cooperation_count > 0 else 0
        else:
            my_exploitation_rate = 0
        if my_exploitation_rate > 0.6:
            self.cooperation_threshold = min(0.8, self.cooperation_threshold + 0.1)
        elif recent_cooperation_rate > 0.7:
            self.cooperation_threshold = max(0.3, self.cooperation_threshold - 0.1)
        if k > n_players / 2:
            self.cooperation_threshold = max(0.3, self.cooperation_threshold - 0.05)
        if n_rounds < 10:
            self.cooperation_threshold = max(0.3, self.cooperation_threshold - 0.1)
        rounds_remaining = n_rounds - current_round
        final_phase = n_rounds * 0.1
        if rounds_remaining <= final_phase:
            if rounds_remaining == 1:
                final_window = min(3, current_round)
                if final_window > 0:
                    final_start = max(0, current_round - final_window)
                    final_opponent_actions = history.opponent_actions[final_start:, :]
                    final_coop_rate = np.sum(final_opponent_actions) / final_opponent_actions.size
                    return Action.C if final_coop_rate > 0.6 else Action.D
            elif recent_cooperation_rate > 0.4:
                return Action.C
        if current_round % 5 == 0 and current_round > 0:
            temp_threshold = max(0.3, self.cooperation_threshold - 0.2)
            if recent_cooperation_rate >= temp_threshold:
                return Action.C
        if current_round >= 2:
            prev_window_start = max(0, current_round - W - 1)
            prev_window_end = max(1, current_round - 1)
            if prev_window_end > prev_window_start:
                prev_opponent_actions = history.opponent_actions[prev_window_start:prev_window_end, :]
                prev_coop_rate = np.sum(prev_opponent_actions) / prev_opponent_actions.size
                if recent_cooperation_rate - prev_coop_rate > 0.3:
                    self.cooperation_threshold = 0.4
                    return Action.C
        if recent_cooperation_rate >= self.cooperation_threshold:
            return Action.C
        elif recent_cooperation_rate >= 0.3:
            return Action.D
        elif recent_cooperation_rate >= 0.1:
            self.defection_countdown = 1
            return Action.D
        elif recent_cooperation_rate < 0.2 and current_round >= 6:
            last_round_cooperators = np.sum(history.opponent_actions[-1, :])
            return Action.C if last_round_cooperators >= 2 else Action.D
        else:
            return Action.D

class Strategy_COOPERATIVE_95(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation Strategy
    
    Balances initial cooperation with adaptive responses using reputation-based decisions.
    Starts cooperative, tracks opponent reputations, and uses parameter-scaled thresholds
    to decide when to cooperate while protecting against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.probation_rounds_left = 0
        self.low_reputation_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        opponent_reputations = []
        for player_idx in range(self.n - 1):
            cooperations = np.sum(history.opponent_actions[:, player_idx])
            total_rounds = history.round_number
            reputation = cooperations / total_rounds if total_rounds > 0 else 0
            opponent_reputations.append(reputation)
        avg_reputation = np.mean(opponent_reputations)
        if self.probation_rounds_left > 0:
            self.probation_rounds_left -= 1
            return Action.C
        if avg_reputation < 0.2:
            self.low_reputation_streak += 1
        else:
            self.low_reputation_streak = 0
        if self.low_reputation_streak >= 3 and current_round <= self.r - 3:
            self.probation_rounds_left = 2
            self.low_reputation_streak = 0
            return Action.C
        if current_round == self.r:
            return Action.C if avg_reputation >= 0.5 else Action.D
        cooperation_threshold = max(0.3, (self.k - 1) / (self.n - 1))
        min_cooperators = max(1, math.floor(self.n * self.k / (2 * self.n - self.k)))
        cooperators_last_round = np.sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            cooperators_last_round += 1
        if avg_reputation >= cooperation_threshold and cooperators_last_round >= min_cooperators:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_96(BaseStrategy):
    """
    Adaptive Cooperative Strategy: "Generous Tit-for-Tat with Dynamic Forgiveness"
    
    Balances cooperation with protection against exploitation by adapting to overall 
    cooperation levels while maintaining a fundamentally cooperative stance.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if current_round <= 2:
            return Action.C
        if current_round >= self.r - 3:
            return self._handle_endgame(history)
        return self._main_strategy(history, current_round)

    def _handle_endgame(self, history: PlayerHistory) -> Action:
        """Handle the last 3 rounds with gradually increasing cooperation tendency."""
        rounds_remaining = self.r - history.round_number
        if rounds_remaining == 1:
            return Action.C
        elif rounds_remaining == 2:
            cooperation_rate = self._get_last_round_cooperation_rate(history)
            return Action.C if cooperation_rate >= 0.2 else Action.D
        else:
            cooperation_rate = self._get_last_round_cooperation_rate(history)
            return Action.C if cooperation_rate >= 0.3 else Action.D

    def _main_strategy(self, history: PlayerHistory, current_round: int) -> Action:
        """Main strategy framework after initial cooperation phase."""
        cooperation_rate = self._get_last_round_cooperation_rate(history)
        my_recent_cooperation_rate = self._get_my_recent_cooperation_rate(history)
        base_threshold = max(0.3, (self.k - 1) / (self.n - 1) * 0.8)
        if my_recent_cooperation_rate >= 0.67:
            adjusted_threshold = base_threshold * 0.8
        else:
            adjusted_threshold = base_threshold * 1.2
        if (current_round + 1) % 5 == 0:
            return Action.C
        if abs(cooperation_rate - adjusted_threshold) <= 0.1:
            return Action.C
        return Action.C if cooperation_rate >= adjusted_threshold else Action.D

    def _get_last_round_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate in the most recent round."""
        if len(history.opponent_actions) == 0:
            return 0.0
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        return last_round_cooperators / self.n

    def _get_my_recent_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate my cooperation rate in the last 3 rounds."""
        recent_rounds = min(3, len(history.my_actions))
        if recent_rounds == 0:
            return 1.0
        recent_cooperations = np.sum(history.my_actions[-recent_rounds:])
        return recent_cooperations / recent_rounds

class Strategy_COOPERATIVE_97(BaseStrategy):
    """
    Adaptive Cooperative Strategy: "Graduated Reciprocator"
    
    Balances cooperative ideals with strategic protection through adaptive cooperation
    based on observed group behavior patterns and strategic reciprocity.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.base_threshold = max(0.3, (self.k - 1) / (self.n - 1) - 0.1)
        if self.n <= 4:
            self.base_threshold -= 0.1
        if self.k > self.n - 1:
            self.base_threshold = (self.k - 1) / (self.n - 1) + 0.1
        if self.k <= 1.5:
            self.base_threshold = 0.5
        self.warning_given = False
        self.in_punishment = False
        self.consecutive_low_payoff = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = history.round_number
        if round_num < 3:
            return Action.C
        if round_num >= self.r - 2:
            return self._endgame_strategy(history)
        return self._main_strategy(history)

    def _calculate_group_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate the overall cooperation rate including self."""
        window_size = min(5, max(1, self.r // 3))
        start_round = max(0, history.round_number - window_size)
        total_cooperations = 0
        total_decisions = 0
        for round_idx in range(start_round, history.round_number):
            if history.my_actions[round_idx]:
                total_cooperations += 1
            total_decisions += 1
            total_cooperations += sum(history.opponent_actions[round_idx, :])
            total_decisions += self.n - 1
        return total_cooperations / total_decisions if total_decisions > 0 else 0.0

    def _calculate_threshold(self) -> float:
        """Calculate current cooperation threshold."""
        return self.base_threshold

    def _main_strategy(self, history: PlayerHistory) -> Action:
        """Main strategy phase decision logic."""
        cooperation_rate = self._calculate_group_cooperation_rate(history)
        threshold = self._calculate_threshold()
        if self._check_exploitation(history):
            return self._tit_for_tat_response(history)
        if cooperation_rate >= threshold + 0.2:
            self.warning_given = False
            self.in_punishment = False
            return Action.C
        elif cooperation_rate >= threshold:
            if self.in_punishment:
                self.in_punishment = False
                self.warning_given = False
            return Action.C
        else:
            return self._graduated_response(cooperation_rate, threshold)

    def _graduated_response(self, cooperation_rate: float, threshold: float) -> Action:
        """Implement graduated response to low cooperation."""
        if not self.warning_given and (not self.in_punishment):
            self.warning_given = True
            return Action.D
        elif self.warning_given and (not self.in_punishment):
            if cooperation_rate >= threshold + 0.1:
                self.warning_given = False
                return Action.C
            else:
                self.in_punishment = True
                return Action.D
        elif cooperation_rate >= threshold + 0.1:
            self.in_punishment = False
            self.warning_given = False
            return Action.C
        else:
            return Action.D

    def _check_exploitation(self, history: PlayerHistory) -> bool:
        """Check if being exploited based on recent payoffs."""
        if history.round_number < 3:
            return False
        recent_payoffs = history.my_payoffs[-3:]
        expected_minimum = 1 + self.k / self.n * 0.3
        low_payoff_count = sum((1 for payoff in recent_payoffs if payoff < expected_minimum))
        if low_payoff_count == 3:
            self.consecutive_low_payoff += 1
            return True
        else:
            self.consecutive_low_payoff = 0
            return False

    def _tit_for_tat_response(self, history: PlayerHistory) -> Action:
        """Tit-for-tat response when being exploited."""
        if history.round_number == 0:
            return Action.C
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        return Action.C if last_round_cooperators > self.n / 2 else Action.D

    def _endgame_strategy(self, history: PlayerHistory) -> Action:
        """Strategy for the last 2 rounds."""
        round_num = history.round_number
        if round_num == self.r - 2:
            cooperation_rate = self._calculate_group_cooperation_rate(history)
            return Action.C if cooperation_rate >= 0.4 else Action.D
        elif history.round_number > 0:
            last_round_cooperators = sum(history.opponent_actions[-1, :])
            if history.my_actions[-1]:
                last_round_cooperators += 1
            return Action.C if last_round_cooperators >= self.n / 2 else Action.D
        else:
            return Action.C

class Strategy_COOPERATIVE_98(BaseStrategy):
    """
    Graduated Reciprocator: An adaptive cooperative strategy that balances trust with protection against exploitation.
    Begins cooperatively, maintains cooperation based on group behavior thresholds, and includes forgiveness mechanisms.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == r - 1:
            total_rounds = len(history.my_actions)
            total_cooperators = np.sum(history.opponent_actions)
            overall_coop_rate = total_cooperators / (n * total_rounds)
            if overall_coop_rate >= 0.3:
                return Action.C
            else:
                return Action.D
        rounds_to_examine = min(3, len(history.my_actions))
        recent_opponent_actions = history.opponent_actions[-rounds_to_examine:, :]
        recent_cooperators = np.sum(recent_opponent_actions)
        recent_coop_rate = recent_cooperators / (n * rounds_to_examine)
        base_threshold = 0.4
        adjusted_threshold = base_threshold
        if k / n > 0.5:
            adjusted_threshold -= 0.1
        if n >= 8:
            adjusted_threshold -= 0.1
        cooperation_threshold = max(0.2, adjusted_threshold)
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        my_recent_actions = history.my_actions[-rounds_to_examine:]
        my_recent_coop_rate = np.sum(my_recent_actions) / rounds_to_examine
        if recent_coop_rate >= cooperation_threshold:
            return Action.C
        elif last_round_cooperators == 0:
            return Action.D
        elif my_recent_coop_rate > recent_coop_rate + 0.2:
            return Action.D
        elif random.random() < 0.7:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_99(BaseStrategy):
    """
    Generous Tit-for-Tat with Momentum: Adaptive cooperative strategy that balances 
    cooperative intent with protection against exploitation using cooperation rates,
    recent momentum, and personal exploitation tracking.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number + 1
        cr = self._calculate_cooperation_rate(history)
        rm = self._calculate_recent_momentum(history)
        pe = self._calculate_personal_exploitation(history)
        if current_round <= self.r // 2:
            if cr >= 0.3 or rm > 0.1:
                return Action.C
            else:
                return Action.D
        elif current_round == self.r:
            if cr >= 0.5 and pe < 0.4:
                return Action.C
            else:
                return Action.D
        elif cr >= 0.4 and rm >= -0.1 or cr >= 0.6:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate average cooperation rate across all previous rounds."""
        total_rounds = history.round_number
        if total_rounds == 0:
            return 0.0
        total_cooperators = 0
        for round_idx in range(total_rounds):
            if history.my_actions[round_idx]:
                total_cooperators += 1
            total_cooperators += np.sum(history.opponent_actions[round_idx, :])
        total_possible = self.n * total_rounds
        return total_cooperators / total_possible

    def _calculate_recent_momentum(self, history: PlayerHistory) -> float:
        """Calculate weighted cooperation trend over recent rounds."""
        total_rounds = history.round_number
        if total_rounds <= 1:
            return 0.0
        recent_rounds = min(3, total_rounds)
        weights = [0.5, 0.3, 0.2]
        baseline = 0.0
        if total_rounds >= 2:
            baseline_cooperators = 0
            for round_idx in range(min(2, total_rounds)):
                if history.my_actions[round_idx]:
                    baseline_cooperators += 1
                baseline_cooperators += np.sum(history.opponent_actions[round_idx, :])
            baseline = baseline_cooperators / (self.n * min(2, total_rounds))
        weighted_recent = 0.0
        for i in range(recent_rounds):
            round_idx = total_rounds - 1 - i
            round_cooperators = 0
            if history.my_actions[round_idx]:
                round_cooperators += 1
            round_cooperators += np.sum(history.opponent_actions[round_idx, :])
            round_cooperation_rate = round_cooperators / self.n
            weighted_recent += weights[i] * round_cooperation_rate
        return weighted_recent - baseline

    def _calculate_personal_exploitation(self, history: PlayerHistory) -> float:
        """Calculate how often I cooperated while others defected."""
        total_rounds = history.round_number
        if total_rounds == 0:
            return 0.0
        my_cooperations = 0
        others_cooperations_when_i_cooperated = 0
        for round_idx in range(total_rounds):
            if history.my_actions[round_idx]:
                my_cooperations += 1
                others_cooperations_when_i_cooperated += np.sum(history.opponent_actions[round_idx, :])
        if my_cooperations == 0:
            return 0.0
        max_possible_others = my_cooperations * (self.n - 1)
        if max_possible_others == 0:
            return 0.0
        return 1.0 - others_cooperations_when_i_cooperated / max_possible_others

class Strategy_COOPERATIVE_100(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation Strategy (ARC)
    
    Balances cooperative intentions with adaptive responses to observed behavior,
    using graduated reciprocity to encourage cooperation while protecting against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = history.round_number
        if round_num == self.r - 1:
            return self._final_round_decision(history)
        return self._adaptive_reciprocity_decision(history)

    def _final_round_decision(self, history: PlayerHistory) -> Action:
        """Handle final round with conditional cooperation."""
        overall_coop_rate = self._calculate_overall_cooperation_rate(history)
        recent_coop_rate = self._calculate_recent_cooperation_rate(history)
        if overall_coop_rate >= 0.5 or recent_coop_rate >= 0.6:
            return Action.C
        else:
            return Action.D

    def _adaptive_reciprocity_decision(self, history: PlayerHistory) -> Action:
        """Main adaptive reciprocity logic for rounds 2 to r-1."""
        cooperation_rate = self._calculate_overall_cooperation_rate(history)
        recent_cooperation_rate = self._calculate_recent_cooperation_rate(history)
        if cooperation_rate >= 0.6:
            cooperation_probability = 0.8
        elif cooperation_rate <= 0.3:
            cooperation_probability = 0.2
        else:
            cooperation_probability = 0.5
        if recent_cooperation_rate > cooperation_rate + 0.1:
            cooperation_probability += 0.2
        if len(history.opponent_actions) > 0:
            last_round_cooperators = sum(history.opponent_actions[-1, :])
            if history.my_actions[-1]:
                last_round_cooperators += 1
            if last_round_cooperators >= self.n / 2:
                cooperation_probability += 0.1
        if recent_cooperation_rate < cooperation_rate - 0.1:
            cooperation_probability -= 0.2
        if len(history.opponent_actions) > 0:
            last_round_cooperators = sum(history.opponent_actions[-1, :])
            if history.my_actions[-1]:
                last_round_cooperators += 1
            if last_round_cooperators <= self.n / 4:
                cooperation_probability -= 0.15
        if self._consecutive_defections(history) >= 2 and recent_cooperation_rate >= 0.4:
            cooperation_probability = 0.7
        cooperation_probability = max(0.0, min(1.0, cooperation_probability))
        if cooperation_probability >= 0.5:
            return Action.C
        else:
            return Action.D

    def _calculate_overall_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate overall cooperation rate across all players and rounds."""
        total_rounds = len(history.my_actions)
        if total_rounds == 0:
            return 0.0
        my_cooperations = sum(history.my_actions)
        opponent_cooperations = np.sum(history.opponent_actions)
        total_cooperations = my_cooperations + opponent_cooperations
        total_possible = self.n * total_rounds
        return total_cooperations / total_possible if total_possible > 0 else 0.0

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate for the last 3 rounds."""
        total_rounds = len(history.my_actions)
        if total_rounds == 0:
            return 0.0
        recent_rounds = min(3, total_rounds)
        start_idx = total_rounds - recent_rounds
        my_recent_cooperations = sum(history.my_actions[start_idx:])
        opponent_recent_cooperations = np.sum(history.opponent_actions[start_idx:, :])
        total_recent_cooperations = my_recent_cooperations + opponent_recent_cooperations
        total_recent_possible = self.n * recent_rounds
        return total_recent_cooperations / total_recent_possible if total_recent_possible > 0 else 0.0

    def _consecutive_defections(self, history: PlayerHistory) -> int:
        """Count consecutive defections by this player from the end."""
        if len(history.my_actions) == 0:
            return 0
        consecutive = 0
        for i in range(len(history.my_actions) - 1, -1, -1):
            if not history.my_actions[i]:
                consecutive += 1
            else:
                break
        return consecutive

class Strategy_COOPERATIVE_101(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation Strategy (ARCS)
    
    Balances cooperation with protection against exploitation using adaptive thresholds
    based on observed cooperation rates and remaining game length.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.adjustment_factor = 1.2
        self.min_threshold = 0.3
        self.max_threshold = 0.7
        self.exploitation_threshold = 0.2
        self.recovery_threshold = 0.4
        self.exploitation_window = 3
        self.weight_decay = 0.8

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number + 1
        if history is None or current_round == 1:
            return Action.C
        if current_round == self.r:
            return Action.D
        historical_coop_rate = self._calculate_weighted_coop_rate(history, current_round)
        if self._is_exploitation_detected(history):
            if historical_coop_rate < self.recovery_threshold:
                return Action.D
        threshold = self._calculate_adaptive_threshold(historical_coop_rate, current_round)
        if historical_coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_weighted_coop_rate(self, history: PlayerHistory, current_round: int) -> float:
        """Calculate cooperation rate with exponential decay weighting."""
        total_weighted_cooperators = 0.0
        total_weight = 0.0
        for past_round_idx in range(len(history.my_actions)):
            weight = self.weight_decay ** (current_round - 1 - past_round_idx)
            my_coop = 1 if history.my_actions[past_round_idx] else 0
            opponent_coops = np.sum(history.opponent_actions[past_round_idx, :])
            total_cooperators = my_coop + opponent_coops
            total_weighted_cooperators += total_cooperators * weight
            total_weight += self.n * weight
        if total_weight == 0:
            return 0.0
        return total_weighted_cooperators / total_weight

    def _is_exploitation_detected(self, history: PlayerHistory) -> bool:
        """Check if exploitation protection should activate."""
        if len(history.my_actions) < self.exploitation_window:
            return False
        recent_rounds = min(self.exploitation_window, len(history.my_actions))
        total_cooperators = 0
        total_players = 0
        for i in range(recent_rounds):
            round_idx = len(history.my_actions) - 1 - i
            my_coop = 1 if history.my_actions[round_idx] else 0
            opponent_coops = np.sum(history.opponent_actions[round_idx, :])
            total_cooperators += my_coop + opponent_coops
            total_players += self.n
        if total_players == 0:
            return False
        recent_coop_rate = total_cooperators / total_players
        return recent_coop_rate < self.exploitation_threshold

    def _calculate_adaptive_threshold(self, historical_coop_rate: float, current_round: int) -> float:
        """Calculate the adaptive cooperation threshold."""
        base_threshold = max(self.min_threshold, min(self.max_threshold, historical_coop_rate * self.adjustment_factor))
        remaining_rounds = self.r - current_round
        endgame_window = max(3, int(0.2 * self.r))
        if remaining_rounds <= endgame_window:
            endgame_factor = remaining_rounds / endgame_window
        else:
            endgame_factor = 1.0
        return base_threshold * endgame_factor

class Strategy_COOPERATIVE_102(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation Strategy (ARCS)
    
    Balances cooperation and protection through adaptive reciprocity, graduated responses,
    and forgiveness mechanisms. Adjusts cooperation threshold based on group behavior
    trends while maintaining robustness against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_threshold = 0.5
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        if self.n > 10:
            self.cooperation_threshold = 0.4
        elif self.n <= 3:
            self.cooperation_threshold = 0.5
        self.always_defect_payoff = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = history.round_number
        if self.r <= 5:
            return self._simple_reciprocity(history)
        if self.n <= 3:
            return self._small_group_strategy(history)
        return self._adaptive_strategy(state, history)

    def _simple_reciprocity(self, history: PlayerHistory) -> Action:
        """Simple strategy for short games"""
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        majority_cooperated = last_round_cooperators >= (self.n - 1) / 2
        return Action.C if majority_cooperated else Action.D

    def _small_group_strategy(self, history: PlayerHistory) -> Action:
        """Stricter reciprocity for small groups"""
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        cooperation_rate = last_round_cooperators / (self.n - 1)
        return Action.C if cooperation_rate >= 0.5 else Action.D

    def _adaptive_strategy(self, state: GameState, history: PlayerHistory) -> Action:
        round_num = history.round_number
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        cooperation_rate_last = last_round_cooperators / (self.n - 1)
        cooperation_trend = self._calculate_trend(history)
        self._adjust_threshold(cooperation_trend)
        if round_num % 4 == 0 and self.cooperation_threshold <= 0.8:
            return Action.C
        endgame_threshold = max(2, math.ceil(0.2 * self.r))
        if round_num >= self.r - endgame_threshold:
            return Action.C if cooperation_rate_last >= 0.6 else Action.D
        self._adjust_for_performance(history)
        if cooperation_rate_last >= self.cooperation_threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_trend(self, history: PlayerHistory) -> float:
        """Calculate cooperation trend over last 3 rounds"""
        if history.round_number < 3:
            return 0.0
        rates = []
        for i in range(3):
            round_idx = -(i + 1)
            cooperators = sum(history.opponent_actions[round_idx, :])
            rate = cooperators / (self.n - 1)
            rates.append(rate)
        trend = (rates[0] - rates[2]) / 2.0
        return trend

    def _adjust_threshold(self, cooperation_trend: float):
        """Adjust cooperation threshold based on trend"""
        if cooperation_trend > 0.1:
            self.cooperation_threshold = max(0.3, self.cooperation_threshold - 0.1)
        elif cooperation_trend < -0.1:
            self.cooperation_threshold = min(0.7, self.cooperation_threshold + 0.1)

    def _adjust_for_performance(self, history: PlayerHistory):
        """Adjust strategy based on payoff performance"""
        if history.round_number < 3:
            return
        actual_payoff = sum(history.my_payoffs)
        estimated_defect_payoff = 0.0
        for round_idx in range(history.round_number):
            cooperators = sum(history.opponent_actions[round_idx, :])
            round_payoff = 1.0 + self.game_description.k / self.n * cooperators
            estimated_defect_payoff += round_payoff
        if actual_payoff < 0.85 * estimated_defect_payoff:
            self.cooperation_threshold = min(0.8, self.cooperation_threshold + 0.1)

class Strategy_COOPERATIVE_103(BaseStrategy):
    """
    Adaptive Cooperative Strategy: "Graduated Reciprocator"
    
    Balances cooperative intent with protection against exploitation through
    graduated responses and adaptive cooperation thresholds. Uses recent and
    overall cooperation rates to determine threshold adjustments.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number + 1
        n_rounds = self.game_description.n_rounds
        if current_round == n_rounds:
            overall_coop_rate = self._calculate_overall_cooperation_rate(history)
            if overall_coop_rate >= 0.5:
                return Action.C
            else:
                return Action.D
        recent_coop_rate = self._calculate_recent_cooperation_rate(history)
        overall_coop_rate = self._calculate_overall_cooperation_rate(history)
        trend_weight = 0.6
        effective_coop_rate = trend_weight * recent_coop_rate + (1 - trend_weight) * overall_coop_rate
        k = self.game_description.k
        n = self.game_description.n_players
        base_threshold = max(0.3, (k - 1) / (n - 1))
        if effective_coop_rate >= 0.7:
            threshold = base_threshold - 0.1
        elif effective_coop_rate <= 0.3:
            threshold = base_threshold + 0.15
        else:
            threshold = base_threshold
        if effective_coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate over last min(3, current_round) rounds"""
        current_round = history.round_number
        window_size = min(3, current_round)
        if window_size == 0:
            return 1.0
        recent_actions = history.opponent_actions[-window_size:, :]
        total_cooperations = np.sum(recent_actions)
        total_possible = window_size * self.game_description.n_players
        return total_cooperations / total_possible if total_possible > 0 else 1.0

    def _calculate_overall_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate since round 1"""
        current_round = history.round_number
        if current_round == 0:
            return 1.0
        total_cooperations = np.sum(history.opponent_actions)
        total_possible = current_round * self.game_description.n_players
        return total_cooperations / total_possible if total_possible > 0 else 1.0

class Strategy_COOPERATIVE_104(BaseStrategy):
    """
    Adaptive Generous Tit-for-Tat (AGTT) Strategy
    
    Balances cooperation with protection against exploitation by adapting to the overall 
    cooperation level while maintaining a generous, forgiving approach that encourages 
    mutual cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        lookback_rounds = min(3, current_round)
        recent_cooperations = 0
        total_observations = 0
        start_round = max(0, current_round - lookback_rounds)
        for round_idx in range(start_round, current_round):
            for player_idx in range(n - 1):
                if history.opponent_actions[round_idx, player_idx]:
                    recent_cooperations += 1
                total_observations += 1
        recent_coop_rate = recent_cooperations / total_observations if total_observations > 0 else 0.0
        if recent_coop_rate >= 0.5:
            threshold = 0.3
        elif recent_coop_rate >= 0.3:
            threshold = 0.4
        else:
            threshold = 0.5
        if current_round >= 2 and (not history.my_actions[-1]):
            prev_lookback = min(3, current_round - 1)
            prev_start = max(0, current_round - 1 - prev_lookback)
            prev_cooperations = 0
            prev_observations = 0
            for round_idx in range(prev_start, current_round - 1):
                for player_idx in range(n - 1):
                    if history.opponent_actions[round_idx, player_idx]:
                        prev_cooperations += 1
                    prev_observations += 1
            prev_coop_rate = prev_cooperations / prev_observations if prev_observations > 0 else 0.0
            if recent_coop_rate - prev_coop_rate >= 0.15:
                return Action.C
        if current_round == r - 1:
            last_two_start = max(0, current_round - 2)
            last_two_cooperations = 0
            last_two_observations = 0
            for round_idx in range(last_two_start, current_round):
                for player_idx in range(n - 1):
                    if history.opponent_actions[round_idx, player_idx]:
                        last_two_cooperations += 1
                    last_two_observations += 1
            last_two_rate = last_two_cooperations / last_two_observations if last_two_observations > 0 else 0.0
            return Action.C if last_two_rate >= 0.4 else Action.D
        return Action.C if recent_coop_rate >= threshold else Action.D

class Strategy_COOPERATIVE_105(BaseStrategy):
    """
    Generous Tit-for-Tat with Momentum: An adaptive cooperative strategy that balances
    cooperation with self-protection by being generous initially, responsive to group 
    dynamics, and adaptive to changing conditions.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.treatment_score = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = history.round_number + 1
        if round_num <= 3:
            return Action.C
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        coop_rate = last_round_cooperators / self.game_description.n_players
        if history.my_actions[-1]:
            if coop_rate >= 0.5:
                self.treatment_score += 0.1
            else:
                self.treatment_score -= 0.2
            self.treatment_score = max(0.0, min(1.0, self.treatment_score))
        momentum = 0
        if len(history.opponent_actions) >= 2:
            two_rounds_ago_cooperators = sum(history.opponent_actions[-2, :])
            if history.my_actions[-2]:
                two_rounds_ago_cooperators += 1
            prev_coop_rate = two_rounds_ago_cooperators / self.game_description.n_players
            if coop_rate > prev_coop_rate:
                momentum = 1
            elif coop_rate < prev_coop_rate:
                momentum = -1
            else:
                momentum = 0
        if round_num == self.game_description.n_rounds:
            if self.treatment_score >= 0.6:
                return Action.C
            total_cooperation = 0
            total_rounds = len(history.opponent_actions)
            for r in range(total_rounds):
                round_cooperators = sum(history.opponent_actions[r, :])
                if history.my_actions[r]:
                    round_cooperators += 1
                total_cooperation += round_cooperators / self.game_description.n_players
            avg_coop_rate = total_cooperation / total_rounds
            if avg_coop_rate >= 0.5:
                return Action.C
            else:
                return Action.D
        if coop_rate >= 0.6 or (coop_rate >= 0.4 and self.treatment_score >= 0.6) or (coop_rate >= 0.3 and momentum == 1 and (self.treatment_score >= 0.4)):
            return Action.C
        else:
            prob_cooperate = min(0.3, self.treatment_score)
            if random.random() < prob_cooperate:
                return Action.C
            else:
                return Action.D

class Strategy_COOPERATIVE_106(BaseStrategy):
    """
    Generous Tit-for-Tat with Forgiveness: An adaptive cooperative strategy that starts cooperatively,
    uses a dynamic threshold based on group cooperation rate, includes forgiveness mechanisms,
    and adapts to game parameters and group size.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = history.round_number + 1
        if round_num == self.r:
            return Action.C if history.my_actions[-1] else Action.D
        last_round_opponents = history.opponent_actions[-1, :]
        other_cooperators = np.sum(last_round_opponents)
        cooperation_rate = other_cooperators / (self.n - 1)
        base_threshold = max(0.3, self.k / self.n - 0.1)
        if self.n <= 3:
            base_threshold = max(0.5, self.k / self.n - 0.05)
        elif self.n > 10:
            base_threshold -= 0.1
        if self.k > self.n - 1:
            if round_num <= self.r // 2:
                return Action.C
            base_threshold = max(0.2, self.k / self.n - 0.2)
        elif self.k < 1.5:
            base_threshold = self.k / self.n + 0.1
        if round_num % 4 == 0:
            consecutive_defections = self._count_consecutive_defections(history)
            if consecutive_defections >= 2:
                return Action.C
        if len(history.my_actions) >= 2:
            recent_coop_rates = []
            for i in range(min(3, len(history.my_actions))):
                round_idx = -(i + 1)
                round_cooperators = np.sum(history.opponent_actions[round_idx, :])
                recent_coop_rates.append(round_cooperators / (self.n - 1))
            if len(recent_coop_rates) >= 2 and all((rate < 0.2 for rate in recent_coop_rates)):
                return Action.D
        if self._detect_mutual_defection_period(history) >= 3:
            return Action.C
        if len(history.my_actions) >= 3:
            recent_rates = []
            for i in range(3):
                round_idx = -(i + 1)
                round_cooperators = np.sum(history.opponent_actions[round_idx, :])
                recent_rates.append(round_cooperators / (self.n - 1))
            if recent_rates[0] > recent_rates[1] > recent_rates[2]:
                base_threshold -= 0.1
            elif recent_rates[0] < recent_rates[1] < recent_rates[2]:
                base_threshold += 0.1
        if round_num <= self.r * 0.25:
            base_threshold -= 0.1
        if cooperation_rate >= base_threshold:
            return Action.C
        else:
            return Action.D

    def _count_consecutive_defections(self, history: PlayerHistory) -> int:
        """Count consecutive rounds where this player defected from the end."""
        count = 0
        for i in range(len(history.my_actions) - 1, -1, -1):
            if not history.my_actions[i]:
                count += 1
            else:
                break
        return count

    def _detect_mutual_defection_period(self, history: PlayerHistory) -> int:
        """Detect consecutive rounds of mutual defection (everyone defecting)."""
        count = 0
        for i in range(len(history.my_actions) - 1, -1, -1):
            my_defected = not history.my_actions[i]
            all_opponents_defected = np.sum(history.opponent_actions[i, :]) == 0
            if my_defected and all_opponents_defected:
                count += 1
            else:
                break
        return count

class Strategy_COOPERATIVE_107(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS)
    
    Balances cooperation with self-protection using a dynamic cooperation threshold
    based on observed group behavior. Starts optimistically but adapts to actual
    cooperation levels while maintaining a fundamentally cooperative stance.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.initial_threshold = max(1, math.ceil(self.n / 2) - 1)
        self.cooperation_threshold = float(self.initial_threshold)
        self.memory_window = min(4, max(2, self.r // 3))
        self.early_phase = min(5, max(2, self.r // 4))
        self.endgame_phase = max(3, self.r // 5)
        self.threshold_decrease = 0.1
        self.threshold_increase = 0.2
        self.forgiveness_decay = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if current_round <= self.early_phase:
            return self._early_round_decision(history)
        if current_round > self.r - self.endgame_phase:
            return self._endgame_decision(history)
        return self._main_game_decision(history, current_round)

    def _early_round_decision(self, history: PlayerHistory) -> Action:
        """Decision logic for early rounds with increased generosity."""
        if len(history.my_actions) == 0:
            return Action.C
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        last_round_coop_rate = last_round_cooperators / (self.n - 1)
        if last_round_coop_rate >= 0.25:
            return Action.C
        else:
            return Action.D

    def _main_game_decision(self, history: PlayerHistory, current_round: int) -> Action:
        """Main adaptive threshold decision logic."""
        recent_coop_rate = self._get_recent_cooperation_rate(history)
        self._update_threshold(recent_coop_rate, current_round)
        threshold_rate = self.cooperation_threshold / (self.n - 1)
        if recent_coop_rate >= threshold_rate:
            return Action.C
        elif self._safe_to_punish(current_round) and self._being_exploited(history):
            return Action.D
        else:
            return Action.C

    def _endgame_decision(self, history: PlayerHistory) -> Action:
        """Special handling for endgame rounds."""
        current_round = len(history.my_actions) + 1
        all_opponent_actions = history.opponent_actions.flatten()
        overall_coop_rate = np.mean(all_opponent_actions) if len(all_opponent_actions) > 0 else 0.5
        if current_round == self.r:
            lookback = min(3, len(history.my_actions))
            if lookback > 0:
                recent_actions = history.opponent_actions[-lookback:, :]
                recent_coop_rate = np.mean(recent_actions)
                if recent_coop_rate < 0.25:
                    return Action.D
            return Action.C
        if overall_coop_rate >= 0.5:
            return Action.C
        elif overall_coop_rate < 0.35:
            if current_round == self.r - 1:
                return Action.C
            else:
                return Action.D
        else:
            recent_coop_rate = self._get_recent_cooperation_rate(history)
            threshold_rate = max(0.3, self.cooperation_threshold / (self.n - 1))
            return Action.C if recent_coop_rate >= threshold_rate else Action.C

    def _get_recent_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate over recent memory window."""
        if len(history.my_actions) == 0:
            return 0.5
        lookback = min(self.memory_window, len(history.my_actions))
        recent_actions = history.opponent_actions[-lookback:, :]
        return np.mean(recent_actions) if recent_actions.size > 0 else 0.5

    def _update_threshold(self, recent_coop_rate: float, current_round: int):
        """Update cooperation threshold based on recent performance."""
        expected_cooperators = recent_coop_rate * (self.n - 1)
        if current_round % 3 == 0:
            if self.cooperation_threshold > self.initial_threshold:
                self.cooperation_threshold -= self.forgiveness_decay
            elif self.cooperation_threshold < self.initial_threshold:
                self.cooperation_threshold += self.forgiveness_decay
        if expected_cooperators >= self.cooperation_threshold:
            self.cooperation_threshold = max(1.0, self.cooperation_threshold - self.threshold_decrease)
        else:
            self.cooperation_threshold = min(float(self.n - 1), self.cooperation_threshold + self.threshold_increase)

    def _safe_to_punish(self, current_round: int) -> bool:
        """Check if it's safe to implement punishment."""
        rounds_remaining = self.r - current_round
        return rounds_remaining > self.n

    def _being_exploited(self, history: PlayerHistory) -> bool:
        """Check if we're being exploited (cooperating while others defect)."""
        if len(history.my_actions) < 2:
            return False
        lookback = min(2, len(history.my_actions))
        my_recent_actions = history.my_actions[-lookback:]
        opponent_recent_actions = history.opponent_actions[-lookback:, :]
        my_coop_rate = np.mean(my_recent_actions)
        opponent_coop_rate = np.mean(opponent_recent_actions)
        return my_coop_rate > opponent_coop_rate + 0.3

class Strategy_COOPERATIVE_108(BaseStrategy):
    """
    Forgiving Tit-for-Tat with Declining Forgiveness strategy.
    
    Starts cooperative, responds to group cooperation rates with declining forgiveness
    over time, and uses historical performance for end-game decisions.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        current_round = state.round_number + 1
        if current_round == r:
            total_cooperators = 0
            total_rounds_completed = len(history.my_actions)
            for round_idx in range(total_rounds_completed):
                my_cooperation = int(history.my_actions[round_idx])
                opponent_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
                total_cooperators += my_cooperation + opponent_cooperators
            total_possible_cooperations = total_rounds_completed * n
            avg_cooperation_rate = total_cooperators / total_possible_cooperations
            if avg_cooperation_rate >= 0.4:
                return Action.C
            else:
                return Action.D
        else:
            last_round_idx = len(history.my_actions) - 1
            my_last_cooperation = int(history.my_actions[last_round_idx])
            opponent_cooperators_last = int(np.sum(history.opponent_actions[last_round_idx, :]))
            total_cooperators_last = my_last_cooperation + opponent_cooperators_last
            cooperation_rate = total_cooperators_last / n
            forgiveness_threshold = 0.8 - 0.6 * (current_round - 1) / (r - 2)
            if cooperation_rate >= forgiveness_threshold:
                return Action.C
            else:
                return Action.D

class Strategy_COOPERATIVE_109(BaseStrategy):
    """
    Adaptive Trust Builder: A cooperative strategy that builds trust gradually and responds 
    proportionally to the cooperation level in the population. Uses adaptive thresholds 
    and forgiveness mechanisms to balance collective welfare with protection against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.cooperation_threshold = max(0.3, min(0.7, self.k / self.n - 0.1))
        self.low_coop_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.low_coop_streak = 0
            return Action.C
        current_round = state.round_number
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        coop_rate_last = last_round_cooperators / self.n
        if current_round == self.r - 1:
            return Action.C if coop_rate_last >= 0.5 else Action.D
        if self.low_coop_streak >= 3 and len(history.my_actions) >= 2:
            prev_round_cooperators = sum(history.opponent_actions[-2, :])
            if history.my_actions[-2]:
                prev_round_cooperators += 1
            coop_rate_prev = prev_round_cooperators / self.n
            if coop_rate_last > coop_rate_prev:
                self.low_coop_streak = 0
                return Action.C
        if coop_rate_last >= self.cooperation_threshold:
            self.low_coop_streak = 0
            return Action.C
        else:
            self.low_coop_streak += 1
            return Action.D

class Strategy_COOPERATIVE_110(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation Strategy for N-Player Public Goods Game.
    
    Balances cooperative intent with adaptive protection against exploitation.
    Starts cooperatively, adapts based on observed cooperation rates, and includes
    forgiveness mechanisms to enable renewed cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number + 1
        if current_round <= 3:
            return Action.C
        total_possible_cooperations = history.round_number * (self.n_players - 1)
        total_cooperations = np.sum(history.opponent_actions)
        cooperation_rate = total_cooperations / total_possible_cooperations if total_possible_cooperations > 0 else 0
        if current_round == self.n_rounds:
            return Action.C if cooperation_rate > 0.5 else Action.D
        if current_round % 5 == 0:
            return Action.C
        last_round_opponents = history.opponent_actions[-1, :]
        cooperators_last_round = np.sum(last_round_opponents)
        defectors_last_round = len(last_round_opponents) - cooperators_last_round
        total_opponents = len(last_round_opponents)
        effective_cooperation_rate = cooperation_rate
        if current_round > self.n_rounds - 3:
            rounds_from_end = self.n_rounds - current_round
            reduction = (3 - rounds_from_end) * 0.1
            effective_cooperation_rate -= reduction
        if effective_cooperation_rate >= 0.6:
            defection_rate_last_round = defectors_last_round / total_opponents if total_opponents > 0 else 0
            return Action.D if defection_rate_last_round > 0.6 else Action.C
        elif effective_cooperation_rate >= 0.3:
            cooperation_rate_last_round = cooperators_last_round / total_opponents if total_opponents > 0 else 0
            return Action.C if cooperation_rate_last_round >= 0.4 else Action.D
        else:
            player_coop_scores = np.mean(history.opponent_actions, axis=0)
            recent_weight = 0.7
            historical_weight = 0.3
            recent_coop_rate = cooperators_last_round / total_opponents if total_opponents > 0 else 0
            avg_historical_rate = np.mean(player_coop_scores) if len(player_coop_scores) > 0 else 0
            predicted_coop_rate = recent_weight * recent_coop_rate + historical_weight * avg_historical_rate
            expected_cooperators = predicted_coop_rate * total_opponents
            expected_payoff_coop = self.k / self.n_players * (expected_cooperators + 1)
            expected_payoff_defect = 1 + self.k / self.n_players * expected_cooperators
            return Action.C if expected_payoff_coop > expected_payoff_defect else Action.D

class Strategy_COOPERATIVE_111(BaseStrategy):
    """
    Adaptive Cooperative Strategy: "Graduated Reciprocator"
    
    Maximizes collective welfare while protecting against exploitation through
    graduated responses and adaptive cooperation thresholds based on group dynamics.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.consecutive_defections = 0
            return Action.C
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = history.round_number
        if current_round == r - 1:
            total_cooperators = 0
            total_opportunities = 0
            for round_idx in range(current_round):
                total_cooperators += sum(history.opponent_actions[round_idx, :])
                total_opportunities += len(history.opponent_actions[round_idx, :])
            if total_opportunities > 0:
                historical_cooperation_rate = total_cooperators / total_opportunities
                if historical_cooperation_rate >= 0.4:
                    self.consecutive_defections = 0
                    return Action.C
            return Action.D
        recent_cooperators = sum(history.opponent_actions[-1, :])
        recent_cooperation_rate = recent_cooperators / len(history.opponent_actions[-1, :])
        total_cooperators = 0
        total_opportunities = 0
        for round_idx in range(current_round):
            total_cooperators += sum(history.opponent_actions[round_idx, :])
            total_opportunities += len(history.opponent_actions[round_idx, :])
        historical_cooperation_rate = total_cooperators / total_opportunities if total_opportunities > 0 else 0
        cooperation_trend = recent_cooperation_rate - historical_cooperation_rate
        base_threshold = k / n
        trend_adjustment = cooperation_trend * 0.3
        adaptive_threshold = max(0.2, min(0.8, base_threshold + trend_adjustment))
        should_cooperate = recent_cooperation_rate >= adaptive_threshold
        if not should_cooperate:
            if self.consecutive_defections >= 2:
                if recent_cooperation_rate > historical_cooperation_rate:
                    should_cooperate = True
        if should_cooperate:
            self.consecutive_defections = 0
            return Action.C
        else:
            self.consecutive_defections += 1
            return Action.D

class Strategy_COOPERATIVE_112(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation Strategy (ARCS) that balances cooperative intent 
    with adaptive response to opponent behavior, using reciprocity, forgiveness, and 
    strategic defection to maintain cooperation while protecting against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if current_round == self.r - 1:
            cooperation_rate = self._calculate_overall_cooperation_rate(history)
            if cooperation_rate >= 0.5:
                return Action.C
            else:
                return Action.D
        cooperation_rate = self._calculate_overall_cooperation_rate(history)
        recent_cooperation_rate = self._calculate_recent_cooperation_rate(history)
        personal_threshold = self._calculate_personal_threshold()
        if recent_cooperation_rate >= personal_threshold:
            return Action.C
        elif recent_cooperation_rate >= personal_threshold - 0.2:
            forgiveness_prob = self._get_forgiveness_probability()
            if random.random() < forgiveness_prob:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _calculate_overall_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate the overall cooperation rate of all opponents across all rounds."""
        total_cooperations = np.sum(history.opponent_actions)
        total_possible = history.opponent_actions.shape[0] * history.opponent_actions.shape[1]
        return total_cooperations / total_possible if total_possible > 0 else 0.0

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate weighted cooperation rate focusing on recent rounds."""
        rounds_completed = history.round_number
        look_back = min(5, rounds_completed)
        if look_back == 0:
            return 0.0
        weights = []
        weighted_cooperations = 0.0
        total_weight = 0.0
        for i in range(look_back):
            round_idx = rounds_completed - 1 - i
            weight = 0.7 ** i
            round_cooperations = np.sum(history.opponent_actions[round_idx, :])
            total_opponents = history.opponent_actions.shape[1]
            weighted_cooperations += weight * (round_cooperations / total_opponents)
            total_weight += weight
        return weighted_cooperations / total_weight if total_weight > 0 else 0.0

    def _calculate_personal_threshold(self) -> float:
        """Calculate the personal threshold based on game parameters."""
        base_threshold = self.k / self.n - 0.1
        if self.n <= 4:
            base_threshold = max(0.4, self.k / self.n - 0.05)
        elif self.k / self.n < 0.5:
            base_threshold = self.k / self.n - 0.15
        elif self.k / self.n > 0.8:
            base_threshold = self.k / self.n - 0.2
        return max(0.3, base_threshold)

    def _get_forgiveness_probability(self) -> float:
        """Get forgiveness probability based on game parameters."""
        base_prob = 0.3
        if self.n <= 4:
            return 0.4
        elif self.k / self.n > 0.8:
            return 0.5
        return base_prob

class Strategy_COOPERATIVE_113(BaseStrategy):
    """
    Trust-Based Reciprocator: An adaptive cooperative strategy that starts with trust
    but becomes more selective based on observed group behavior. Balances cooperative
    intent with protection against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.trust_score = 1.0
        self.base_threshold = self.k / self.n
        self.adjusted_threshold = max(0.3, self.base_threshold - 0.1)
        if self.n <= 3:
            self.adjusted_threshold -= 0.1
        if self.k > 2.5:
            self.adjusted_threshold += 0.1
        self.decay_rate = 0.7 if self.k < 1.5 else 0.8

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if history is None or current_round == 0:
            return Action.C
        if current_round == self.r - 1:
            total_cooperation = 0
            total_rounds = len(history.my_actions)
            for round_idx in range(total_rounds):
                total_cooperation += sum(history.opponent_actions[round_idx, :])
            avg_cooperation_rate = total_cooperation / (total_rounds * (self.n - 1))
            if avg_cooperation_rate >= 0.5:
                return Action.C
            else:
                return Action.D
        if self.r <= 3:
            last_round_cooperators = sum(history.opponent_actions[-1, :])
            if last_round_cooperators == 0:
                return Action.D
            else:
                return Action.C
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        gcr = last_round_cooperators / (self.n - 1)
        self.trust_score = self.decay_rate * self.trust_score + (1 - self.decay_rate) * gcr
        if gcr >= self.adjusted_threshold:
            return Action.C
        elif self.trust_score >= 0.4:
            return Action.C
        else:
            return Action.D

class Strategy_COOPERATIVE_114(BaseStrategy):
    """
    Graduated Reciprocator: An adaptive cooperative strategy that balances cooperation
    with protection against exploitation. Starts cooperatively, adapts based on group
    behavior using weighted recent history, and includes forgiveness mechanisms.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        if current_round == self.r - 1:
            if history.round_number > 0:
                last_round_cooperators = sum(history.opponent_actions[-1, :])
                cooperation_rate = last_round_cooperators / self.n
                if cooperation_rate >= 0.5:
                    return Action.C
            return Action.D
        recent_trend = self._calculate_recent_cooperation_trend(history)
        if self._should_forgive(current_round):
            if random.random() < 0.5:
                return Action.C
        if recent_trend >= 0.6:
            return Action.C
        elif recent_trend >= 0.4:
            if random.random() < 0.7:
                return Action.C
            else:
                return Action.D
        elif recent_trend >= 0.2:
            if random.random() < 0.3:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _calculate_recent_cooperation_trend(self, history: PlayerHistory) -> float:
        """Calculate weighted cooperation trend from recent rounds."""
        rounds_completed = history.round_number
        if rounds_completed == 1:
            cooperators = sum(history.opponent_actions[0, :])
            return cooperators / self.n
        weights = [0.5, 0.3, 0.2]
        cooperation_rates = []
        for i in range(min(3, rounds_completed)):
            round_idx = rounds_completed - 1 - i
            cooperators = sum(history.opponent_actions[round_idx, :])
            cooperation_rate = cooperators / self.n
            cooperation_rates.append(cooperation_rate)
        weighted_sum = 0.0
        total_weight = 0.0
        for i, rate in enumerate(cooperation_rates):
            if i < len(weights):
                weight = weights[i]
                weighted_sum += rate * weight
                total_weight += weight
        if total_weight > 0:
            return weighted_sum / total_weight
        else:
            return 0.0

    def _should_forgive(self, current_round: int) -> bool:
        """Determine if this is a forgiveness round (every 3-4 rounds)."""
        if current_round < 4:
            return False
        return (current_round - 1) % 4 == 0 or (current_round - 1) % 3 == 0

class Strategy_COOPERATIVE_115(BaseStrategy):
    """
    Graduated Reciprocator: An adaptive cooperation strategy that balances cooperative intent 
    with protection against exploitation. Starts cooperatively, uses a health score system 
    to evaluate group cooperation levels, and applies graduated responses with forgiveness mechanisms.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        current_round = history.round_number + 1
        total_rounds = self.game_description.n_rounds
        if current_round == total_rounds:
            total_cooperators = 0
            total_possible = 0
            for round_idx in range(history.round_number):
                round_cooperators = sum(history.opponent_actions[round_idx, :])
                if history.my_actions[round_idx]:
                    round_cooperators += 1
                total_cooperators += round_cooperators
                total_possible += n
            overall_cooperation_rate = total_cooperators / total_possible if total_possible > 0 else 0
            return Action.C if overall_cooperation_rate >= 0.5 else Action.D
        last_round_idx = history.round_number - 1
        last_round_cooperators = sum(history.opponent_actions[last_round_idx, :])
        if history.my_actions[last_round_idx]:
            last_round_cooperators += 1
        cooperation_rate = last_round_cooperators / n
        rounds_to_check = min(3, history.round_number)
        recent_cooperation_sum = 0
        for i in range(rounds_to_check):
            round_idx = history.round_number - 1 - i
            round_cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                round_cooperators += 1
            recent_cooperation_sum += round_cooperators / n
        recent_cooperation_trend = recent_cooperation_sum / rounds_to_check
        health_score = 0.7 * cooperation_rate + 0.3 * recent_cooperation_trend
        if health_score >= 0.6:
            return Action.C
        elif health_score < 0.3:
            return Action.D
        else:
            if history.round_number >= 2:
                prev_round_idx = history.round_number - 2
                prev_round_cooperators = sum(history.opponent_actions[prev_round_idx, :])
                if history.my_actions[prev_round_idx]:
                    prev_round_cooperators += 1
                prev_cooperation_rate = prev_round_cooperators / n
                if cooperation_rate > prev_cooperation_rate:
                    return Action.C
                elif prev_cooperation_rate - cooperation_rate > 0.3:
                    return Action.D
            return Action.C if random.random() < health_score else Action.D

class Strategy_COOPERATIVE_116(BaseStrategy):
    """
    Generous Tit-for-Tat with Momentum: An adaptive cooperative strategy that balances 
    cooperation with self-protection by being initially cooperative, forgiving occasional 
    defections, but firm against persistent free-riding.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        current_round = state.round_number + 1
        if current_round == r:
            last_round_cooperators = sum(history.opponent_actions[-1, :])
            if history.my_actions[-1]:
                last_round_cooperators += 1
            group_coop_rate = last_round_cooperators / n
            reciprocation_score = self._calculate_reciprocation_score(history)
            if group_coop_rate >= 0.5 or reciprocation_score >= 0.6:
                return Action.C
            else:
                return Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        group_coop_rate = last_round_cooperators / n
        reciprocation_score = self._calculate_reciprocation_score(history)
        if group_coop_rate >= 0.6:
            return Action.C
        elif group_coop_rate >= 0.4:
            if reciprocation_score >= 0.5:
                return Action.C
            else:
                return Action.C if random.random() < 0.7 else Action.D
        elif group_coop_rate >= 0.2:
            if reciprocation_score >= 0.6:
                return Action.C
            else:
                return Action.C if random.random() < 0.4 else Action.D
        elif reciprocation_score >= 0.7:
            return Action.C if random.random() < 0.3 else Action.D
        else:
            return Action.D

    def _calculate_reciprocation_score(self, history: PlayerHistory) -> float:
        """
        Calculate how often others cooperated when I cooperated.
        Returns the ratio of (times others cooperated when I cooperated) / (times I cooperated + 1)
        """
        times_i_cooperated = 0
        times_others_cooperated_when_i_cooperated = 0
        for round_idx in range(len(history.my_actions)):
            if history.my_actions[round_idx]:
                times_i_cooperated += 1
                opponent_cooperators = sum(history.opponent_actions[round_idx, :])
                times_others_cooperated_when_i_cooperated += opponent_cooperators
        return times_others_cooperated_when_i_cooperated / (times_i_cooperated * (self.game_description.n_players - 1) + 1)

class Strategy_COOPERATIVE_117(BaseStrategy):
    """
    Generous Tit-for-Majority strategy that adapts cooperation based on group behavior.
    Starts cooperative, uses a threshold mechanism with momentum tracking and forgiveness,
    and applies strategic defection in the final round unless group cooperation is exceptional.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number + 1
        if history is None:
            return Action.C
        base_threshold = (self.k - 1) / (self.k + 1)
        actual_threshold = max(0.2, base_threshold - 0.1)
        prev_round_idx = history.round_number - 1
        prev_round_coops = sum(history.opponent_actions[prev_round_idx, :])
        if history.my_actions[prev_round_idx]:
            prev_round_coops += 1
        coop_rate = prev_round_coops / self.n
        if round_num >= 4 and history.round_number >= 3:
            momentum = self._calculate_momentum(history)
            if momentum > 0:
                actual_threshold -= 0.05
            elif momentum < 0:
                actual_threshold += 0.05
        if not history.my_actions[prev_round_idx]:
            actual_threshold -= 0.1
        if round_num == self.r:
            if coop_rate >= 0.8:
                return Action.C
            else:
                return Action.D
        if coop_rate >= actual_threshold:
            return Action.C
        else:
            return Action.D

    def _calculate_momentum(self, history: PlayerHistory) -> float:
        """Calculate cooperation momentum over the last 3 rounds."""
        if history.round_number < 3:
            return 0.0
        coop_rates = []
        for i in range(3):
            round_idx = history.round_number - 3 + i
            round_coops = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                round_coops += 1
            coop_rates.append(round_coops / self.n)
        if coop_rates[2] > coop_rates[1] and coop_rates[1] > coop_rates[0]:
            return 1.0
        elif coop_rates[2] < coop_rates[1] and coop_rates[1] < coop_rates[0]:
            return -1.0
        else:
            return 0.0

class Strategy_COOPERATIVE_118(BaseStrategy):
    """
    Generous Tit-for-Tat with Collective Forgiveness: An adaptive cooperative strategy
    that responds to collective behavior rather than individual actions. Starts cooperative,
    forgives occasional defections, but protects against persistent free-riding.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        n_players = self.game_description.n_players
        n_rounds = self.game_description.n_rounds
        cooperators_last_round = sum(history.opponent_actions[-1, :])
        ccr = cooperators_last_round / (n_players - 1)
        if current_round == n_rounds - 1:
            return Action.C if ccr >= 0.5 else Action.D
        prev_ccr = 0.0
        if len(history.my_actions) >= 2:
            cooperators_prev_round = sum(history.opponent_actions[-2, :])
            prev_ccr = cooperators_prev_round / (n_players - 1)
        if ccr >= 0.6:
            return Action.C
        elif ccr >= 0.3:
            my_last_action = history.my_actions[-1]
            if my_last_action and len(history.my_actions) >= 2 and (ccr < prev_ccr - 0.3):
                return Action.D
            else:
                return Action.C
        else:
            consecutive_low = 0
            for i in range(len(history.my_actions) - 1, -1, -1):
                round_cooperators = sum(history.opponent_actions[i, :])
                round_ccr = round_cooperators / (n_players - 1)
                if round_ccr < 0.3:
                    consecutive_low += 1
                else:
                    break
            if consecutive_low >= 2:
                return Action.D
            else:
                return Action.C

class Strategy_COOPERATIVE_119(BaseStrategy):
    """
    Adaptive Reciprocal Cooperation Strategy (ARCS)
    
    Balances cooperative intent with adaptive protection against exploitation.
    Starts optimistically, learns from group behavior, and maintains sustainability
    while maximizing collective benefit through dynamic cooperation thresholds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.consecutive_low_cooperation_rounds = 0
        self.forgiveness_active = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        total_rounds = self.game_description.n_rounds
        n_players = self.game_description.n_players
        recent_cooperation_rate = self._calculate_recent_cooperation_rate(history, current_round, n_players)
        if current_round == total_rounds - 1:
            last_round_cooperation = self._get_round_cooperation_rate(history, -1, n_players)
            return Action.C if last_round_cooperation >= 0.4 else Action.D
        if self._should_apply_forgiveness(history, current_round, n_players):
            self.forgiveness_active = True
            return Action.C
        if self.forgiveness_active:
            self.forgiveness_active = False
        cooperation_threshold = max(0.3, recent_cooperation_rate - 0.1)
        return Action.C if recent_cooperation_rate >= cooperation_threshold else Action.D

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory, current_round: int, n_players: int) -> float:
        """Calculate recent cooperation rate based on round number."""
        if current_round <= 4:
            total_cooperation = 0
            total_possible = 0
            for round_idx in range(current_round):
                if history.my_actions[round_idx]:
                    total_cooperation += 1
                total_possible += 1
                total_cooperation += sum(history.opponent_actions[round_idx, :])
                total_possible += n_players - 1
            return total_cooperation / total_possible if total_possible > 0 else 0
        else:
            weights = [0.5, 0.3, 0.2]
            weighted_cooperation = 0
            for i, weight in enumerate(weights):
                round_idx = current_round - 1 - i
                if round_idx >= 0:
                    round_cooperation = self._get_round_cooperation_rate(history, round_idx, n_players)
                    weighted_cooperation += weight * round_cooperation
            return weighted_cooperation

    def _get_round_cooperation_rate(self, history: PlayerHistory, round_idx: int, n_players: int) -> float:
        """Get cooperation rate for a specific round."""
        if round_idx < 0:
            round_idx = len(history.my_actions) + round_idx
        if round_idx < 0 or round_idx >= len(history.my_actions):
            return 0
        total_cooperation = 0
        if history.my_actions[round_idx]:
            total_cooperation += 1
        total_cooperation += sum(history.opponent_actions[round_idx, :])
        return total_cooperation / n_players

    def _should_apply_forgiveness(self, history: PlayerHistory, current_round: int, n_players: int) -> bool:
        """Check if forgiveness protocol should be applied."""
        if current_round < 3:
            return False
        low_cooperation_rounds = 0
        for i in range(2):
            round_idx = current_round - 1 - i
            if round_idx >= 0:
                cooperation_rate = self._get_round_cooperation_rate(history, round_idx, n_players)
                if cooperation_rate < 0.2:
                    low_cooperation_rounds += 1
        last_round_cooperation = self._get_round_cooperation_rate(history, -1, n_players)
        if last_round_cooperation < 0.2:
            self.consecutive_low_cooperation_rounds += 1
        else:
            if last_round_cooperation > 0.5 and self.consecutive_low_cooperation_rounds >= 2:
                self.consecutive_low_cooperation_rounds = 0
                return True
            self.consecutive_low_cooperation_rounds = 0
        return False

class Strategy_COOPERATIVE_120(BaseStrategy):
    """
    Graduated Reciprocator: An adaptive cooperative strategy that balances cooperation 
    with self-protection by starting cooperatively and using a dynamic threshold system 
    to decide when to cooperate based on recent group behavior.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.cooperation_threshold = 0.3
        if game_description.n_players > 6:
            self.cooperation_threshold = max(0.2, self.cooperation_threshold - 0.05)
        if game_description.k > 2.0:
            self.cooperation_threshold = max(0.2, self.cooperation_threshold - 0.05)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_number = history.round_number
        n_rounds = self.game_description.n_rounds
        if round_number <= 2:
            last_round_cooperators = sum(history.opponent_actions[-1, :])
            if last_round_cooperators >= 1:
                return Action.C
            else:
                return Action.D
        recent_cooperation_rate = sum(history.opponent_actions[-1, :]) / self.game_description.n_players
        self._update_threshold(history, recent_cooperation_rate)
        current_threshold = self.cooperation_threshold
        if round_number >= n_rounds - 1:
            current_threshold = min(0.8, current_threshold + 0.2)
        elif round_number >= max(1, int(0.8 * n_rounds)):
            if len(history.opponent_actions) >= 3:
                recent_3_rounds = history.opponent_actions[-3:, :]
                trend_cooperation = np.mean(recent_3_rounds, axis=1)
                if len(trend_cooperation) >= 2 and trend_cooperation[-1] > trend_cooperation[-2]:
                    current_threshold = max(0.1, current_threshold - 0.1)
        forgiveness_interval = max(4, n_rounds // 4)
        if round_number % forgiveness_interval == 0 and current_threshold > 0.6 and self._has_cooperation_improvement(history):
            return Action.C
        if self._is_all_defection_environment(history):
            if round_number % 3 == 0:
                return Action.C
            else:
                return Action.D
        if recent_cooperation_rate >= current_threshold:
            return Action.C
        else:
            return Action.D

    def _update_threshold(self, history: PlayerHistory, recent_cooperation_rate: float):
        """Update the cooperation threshold based on recent experience."""
        if len(history.my_actions) < 1:
            return
        last_action_was_cooperate = history.my_actions[-1]
        if last_action_was_cooperate:
            if len(history.my_payoffs) >= 1:
                my_last_payoff = history.my_payoffs[-1]
                last_round_total_cooperators = sum(history.opponent_actions[-1, :])
                if history.my_actions[-1]:
                    expected_defect_payoff = 1 + self.game_description.k / self.game_description.n_players * last_round_total_cooperators
                else:
                    expected_defect_payoff = my_last_payoff
                if my_last_payoff >= expected_defect_payoff - 0.1:
                    self.cooperation_threshold = max(0.2, self.cooperation_threshold - 0.1)
                else:
                    self.cooperation_threshold = min(0.8, self.cooperation_threshold + 0.15)
        elif recent_cooperation_rate > 0.5:
            self.cooperation_threshold = max(0.1, self.cooperation_threshold - 0.05)

    def _has_cooperation_improvement(self, history: PlayerHistory) -> bool:
        """Check if there's been improvement in cooperation over last 2 rounds."""
        if len(history.opponent_actions) < 2:
            return False
        recent_2_rounds = history.opponent_actions[-2:, :]
        cooperation_rates = np.mean(recent_2_rounds, axis=1)
        return cooperation_rates[-1] > cooperation_rates[-2]

    def _is_all_defection_environment(self, history: PlayerHistory) -> bool:
        """Check if we're in an all-defection environment."""
        if len(history.opponent_actions) < 3:
            return False
        recent_3_rounds = history.opponent_actions[-3:, :]
        cooperation_rates = np.mean(recent_3_rounds, axis=1)
        return all((rate < 0.1 for rate in cooperation_rates))

class Strategy_COOPERATIVE_121(BaseStrategy):
    """
    Adaptive Threshold Cooperation Strategy (ATCS) - Balances cooperation with protection 
    against exploitation using an adaptive threshold based on observed group behavior patterns.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number + 1
        if current_round <= 3:
            if len(history.opponent_actions) > 0:
                any_cooperated = sum(history.opponent_actions[-1, :]) > 0
                return Action.C if any_cooperated else Action.D
            return Action.C
        if current_round >= self.r - 1:
            return self._endgame_decision(history, current_round)
        return self._main_phase_decision(history)

    def _main_phase_decision(self, history: PlayerHistory) -> Action:
        threshold = self._calculate_adaptive_threshold(history)
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if self._should_attempt_forgiveness(history):
            round_num = history.round_number + 1
            if round_num % 3 == 1:
                return Action.C
        return Action.C if last_round_cooperators >= threshold else Action.D

    def _calculate_adaptive_threshold(self, history: PlayerHistory) -> float:
        base_threshold = 0.3 + (self.k - 1) / (self.n - 1) * 0.4
        if self.n <= 3:
            base_threshold = 0.5
        recent_cooperation_rate = self._get_recent_cooperation_rate(history)
        momentum_factor = math.sqrt(recent_cooperation_rate)
        raw_threshold = self.n * base_threshold * momentum_factor
        cooperation_threshold = max(1, math.floor(raw_threshold))
        return cooperation_threshold

    def _get_recent_cooperation_rate(self, history: PlayerHistory) -> float:
        rounds_to_check = min(3, len(history.opponent_actions))
        if rounds_to_check == 0:
            return 0.3
        total_cooperations = 0
        total_possible = 0
        for i in range(rounds_to_check):
            round_idx = -(i + 1)
            total_cooperations += sum(history.opponent_actions[round_idx, :])
            total_possible += self.n
        return total_cooperations / total_possible if total_possible > 0 else 0.3

    def _should_attempt_forgiveness(self, history: PlayerHistory) -> bool:
        if len(history.opponent_actions) < 2:
            return False
        recent_rates = []
        for i in range(2):
            round_idx = -(i + 1)
            cooperators = sum(history.opponent_actions[round_idx, :])
            rate = cooperators / self.n
            recent_rates.append(rate)
        return all((rate < 0.2 for rate in recent_rates))

    def _endgame_decision(self, history: PlayerHistory, current_round: int) -> Action:
        if current_round == self.r - 1:
            total_cooperations = 0
            total_possible = 0
            for round_actions in history.opponent_actions:
                total_cooperations += sum(round_actions)
                total_possible += self.n
            avg_cooperation_rate = total_cooperations / total_possible if total_possible > 0 else 0
            return Action.C if avg_cooperation_rate >= 0.4 else Action.D
        else:
            last_round_cooperators = sum(history.opponent_actions[-1, :])
            if last_round_cooperators >= 2:
                cooperate_payoff = self.k / self.n * (last_round_cooperators + 1)
                defect_payoff = 1 + self.k / self.n * last_round_cooperators
                return Action.C if cooperate_payoff >= defect_payoff else Action.D
            else:
                return Action.D

class Strategy_COOPERATIVE_122(BaseStrategy):
    """
    Graduated Reciprocator: An adaptive cooperative strategy that balances cooperative intent 
    with learning-based responses. Uses graduated responses rather than binary punishment,
    aiming to build cooperative coalitions while protecting against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = state.round_number
        if round_num <= 2:
            return Action.C
        cooperation_rates = self._calculate_cooperation_rates(history)
        weighted_avg = self._weighted_average_cooperation(cooperation_rates)
        threshold = max(self.k / self.n, weighted_avg * 0.8)
        if round_num == self.r - 1:
            return Action.C if cooperation_rates[-1] >= threshold else Action.D
        if round_num == self.r - 2:
            avg_coop_rate = np.mean(cooperation_rates)
            return Action.C if avg_coop_rate >= self.k / self.n else Action.D
        last_coop_rate = cooperation_rates[-1]
        if last_coop_rate >= threshold:
            return Action.C
        forgiveness_period = 3 if self.n <= 4 else 4
        if (round_num + 1) % forgiveness_period == 0:
            return Action.C
        if self._consecutive_low_cooperation(cooperation_rates, self.k / self.n) >= 3:
            return Action.C
        if len(cooperation_rates) >= 2 and cooperation_rates[-1] > cooperation_rates[-2]:
            return Action.C
        if self.k > 1.5 * self.n and last_coop_rate >= 0.3:
            return Action.C
        return Action.D

    def _calculate_cooperation_rates(self, history: PlayerHistory) -> list:
        """Calculate cooperation rates for each completed round."""
        cooperation_rates = []
        for round_idx in range(history.round_number):
            my_cooperation = int(history.my_actions[round_idx])
            opponent_cooperation = int(np.sum(history.opponent_actions[round_idx, :]))
            total_cooperators = my_cooperation + opponent_cooperation
            cooperation_rate = total_cooperators / self.n
            cooperation_rates.append(cooperation_rate)
        return cooperation_rates

    def _weighted_average_cooperation(self, cooperation_rates: list) -> float:
        """Calculate weighted average with more weight on recent rounds."""
        if not cooperation_rates:
            return self.k / self.n
        weights = []
        for i in range(len(cooperation_rates)):
            weight = math.exp(i / len(cooperation_rates))
            weights.append(weight)
        weighted_sum = sum((rate * weight for rate, weight in zip(cooperation_rates, weights)))
        total_weight = sum(weights)
        return weighted_sum / total_weight if total_weight > 0 else self.k / self.n

    def _consecutive_low_cooperation(self, cooperation_rates: list, threshold: float) -> int:
        """Count consecutive rounds of low cooperation at the end of the list."""
        if not cooperation_rates:
            return 0
        consecutive_count = 0
        for rate in reversed(cooperation_rates):
            if rate < threshold:
                consecutive_count += 1
            else:
                break
        return consecutive_count

class Strategy_COOPERATIVE_123(BaseStrategy):
    """
    Adaptive Cooperative Strategy: "Graduated Reciprocator"
    
    Balances cooperation with calculated defection based on observed group dynamics.
    Uses graduated responses and strategic forgiveness to maximize collective welfare
    while protecting against exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.min_cooperators = math.ceil(self.n / self.k)
        self.consecutive_low_coop = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = state.round_number
        if round_num == self.r - 1:
            overall_coop_rate = self._calculate_overall_cooperation_rate(history)
            if overall_coop_rate >= 0.6:
                return Action.C
            elif overall_coop_rate >= 0.3:
                return Action.C if random.random() < 0.5 else Action.D
            else:
                return Action.D
        recent_coop_rate = self._calculate_recent_cooperation_rate(history)
        if (round_num + 1) % 4 == 0:
            self.consecutive_low_coop = 0
            return Action.C if random.random() < 0.7 else Action.D
        sufficient_threshold = self.min_cooperators / self.n
        if recent_coop_rate >= sufficient_threshold:
            self.consecutive_low_coop = 0
            return Action.C if random.random() < 0.9 else Action.D
        elif recent_coop_rate >= 0.3:
            self.consecutive_low_coop = 0
            coop_prob = min(0.9, recent_coop_rate + 0.1)
            return Action.C if random.random() < coop_prob else Action.D
        else:
            self.consecutive_low_coop += 1
            if self.consecutive_low_coop < 3:
                return Action.C if random.random() < 0.3 else Action.D
            else:
                return Action.C if random.random() < 0.1 else Action.D

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate over the last 3 rounds (or all available)."""
        n_recent_rounds = min(3, len(history.my_actions))
        if n_recent_rounds == 0:
            return 0.0
        recent_actions = history.opponent_actions[-n_recent_rounds:, :]
        total_decisions = recent_actions.size
        total_cooperations = np.sum(recent_actions)
        return total_cooperations / total_decisions if total_decisions > 0 else 0.0

    def _calculate_overall_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate overall cooperation rate across all rounds."""
        if len(history.my_actions) == 0:
            return 0.0
        total_decisions = history.opponent_actions.size
        total_cooperations = np.sum(history.opponent_actions)
        return total_cooperations / total_decisions if total_decisions > 0 else 0.0

class Strategy_COOPERATIVE_124(BaseStrategy):
    """
    Trust-Build-Punish-Forgive: Adaptive cooperative strategy that builds trust gradually,
    punishes defection decisively, and offers forgiveness to encourage long-term cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.trust_build_rounds = max(2, math.floor(self.r * 0.2))
        self.base_cooperation_threshold = 0.5 + (self.k - 2) / (2 * (self.n - 2)) if self.n > 2 else 0.5
        self.punishment_mode = False
        self.punishment_rounds_remaining = 0
        self.low_cooperation_streak = 0
        self.threshold_adjustment = 0.0
        if self.k > self.n / 2:
            self.threshold_adjustment = -0.1
        elif self.k < 1.5:
            self.threshold_adjustment = 0.1
        self.punishment_duration_base = 3
        if self.n <= 4:
            self.punishment_duration_multiplier = 1.5
        elif self.n >= 8:
            self.punishment_duration_multiplier = 0.7
        else:
            self.punishment_duration_multiplier = 1.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number
        if current_round < self.trust_build_rounds:
            return Action.C
        remaining_rounds = self.r - current_round
        if remaining_rounds <= 1:
            return Action.D
        elif remaining_rounds == 2:
            recent_coop_rate = self._get_recent_cooperation_rate(history, 3)
            return Action.C if recent_coop_rate >= 0.7 else Action.D
        elif remaining_rounds <= 5:
            endgame_adjustment = (5 - remaining_rounds) * 0.1
            adjusted_threshold = self.base_cooperation_threshold + self.threshold_adjustment + endgame_adjustment
            recent_coop_rate = self._get_recent_cooperation_rate(history, 3)
            return Action.C if recent_coop_rate >= adjusted_threshold else Action.D
        return self._adaptive_cooperation_decision(history)

    def _adaptive_cooperation_decision(self, history: PlayerHistory) -> Action:
        recent_coop_rate = self._get_recent_cooperation_rate(history, 3)
        cooperation_threshold = self.base_cooperation_threshold + self.threshold_adjustment
        if recent_coop_rate < 0.3:
            self.low_cooperation_streak += 1
        else:
            self.low_cooperation_streak = 0
        if self.low_cooperation_streak >= 2 and (not self.punishment_mode):
            self.punishment_mode = True
            remaining_rounds = self.r - history.round_number
            base_punishment = min(self.punishment_duration_base, remaining_rounds // 4)
            self.punishment_rounds_remaining = max(1, int(base_punishment * self.punishment_duration_multiplier))
        if self.punishment_mode and recent_coop_rate > 0.5:
            self.punishment_mode = False
            self.punishment_rounds_remaining = 0
            return Action.C
        if self.punishment_mode and self.punishment_rounds_remaining > 0:
            self.punishment_rounds_remaining -= 1
            if self.punishment_rounds_remaining == 0:
                self.punishment_mode = False
            return Action.D
        if recent_coop_rate >= cooperation_threshold:
            return Action.C
        else:
            if recent_coop_rate < 0.2 and random.random() < 0.1:
                return Action.C
            return Action.D

    def _get_recent_cooperation_rate(self, history: PlayerHistory, lookback_rounds: int) -> float:
        """Calculate weighted cooperation rate over recent rounds with exponential decay."""
        if history.round_number == 0:
            return 0.5
        actual_lookback = min(lookback_rounds, history.round_number)
        if actual_lookback == 0:
            return 0.5
        total_weighted_cooperations = 0.0
        total_weight = 0.0
        decay_factor = 0.8
        for i in range(actual_lookback):
            round_idx = history.round_number - 1 - i
            weight = decay_factor ** i
            cooperations_in_round = np.sum(history.opponent_actions[round_idx, :])
            cooperation_rate_in_round = cooperations_in_round / (self.n - 1)
            total_weighted_cooperations += cooperation_rate_in_round * weight
            total_weight += weight
        return total_weighted_cooperations / total_weight if total_weight > 0 else 0.0

class Strategy_COOPERATIVE_125(BaseStrategy):
    """
    Graduated Reciprocator: Adaptive cooperative strategy that balances cooperative intent
    with protection against exploitation using graduated punishment and forgiveness mechanisms.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.cooperation_threshold = 0.5
        self.consecutive_high_coop_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = history.round_number
        if current_round < 3:
            return Action.C
        last_3_rounds = min(3, current_round)
        start_idx = max(0, current_round - last_3_rounds)
        recent_opponent_actions = history.opponent_actions[start_idx:current_round, :]
        my_recent_actions = history.my_actions[start_idx:current_round]
        total_cooperators = 0
        total_decisions = 0
        for round_idx in range(recent_opponent_actions.shape[0]):
            opponent_cooperators = np.sum(recent_opponent_actions[round_idx, :])
            self_cooperated = 1 if my_recent_actions[round_idx] else 0
            total_cooperators += opponent_cooperators + self_cooperated
            total_decisions += self.n_players
        cooperation_rate = total_cooperators / total_decisions if total_decisions > 0 else 0
        self.cooperation_threshold = max(0.3, min(0.7, cooperation_rate - 0.1))
        if self.n_players <= 3:
            self.cooperation_threshold = max(0.2, cooperation_rate - 0.15)
        if cooperation_rate >= 0.6:
            self.consecutive_high_coop_rounds += 1
        else:
            self.consecutive_high_coop_rounds = 0
        if cooperation_rate < 0.2 and current_round >= 6:
            if current_round >= 6:
                last_3_coop_rates = []
                for i in range(3):
                    round_start = max(0, current_round - 3 + i - 2)
                    round_end = current_round - 3 + i + 1
                    if round_end > round_start:
                        round_actions = history.opponent_actions[round_start:round_end, :]
                        round_my_actions = history.my_actions[round_start:round_end]
                        round_total = np.sum(round_actions) + np.sum(round_my_actions)
                        round_decisions = (round_end - round_start) * self.n_players
                        last_3_coop_rates.append(round_total / round_decisions if round_decisions > 0 else 0)
                if len(last_3_coop_rates) == 3 and all((rate < 0.2 for rate in last_3_coop_rates)):
                    if current_round > 0:
                        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
                        return Action.C if last_round_cooperators >= 2 else Action.D
        end_game_threshold = math.ceil(0.2 * self.n_rounds)
        rounds_remaining = self.n_rounds - current_round
        if rounds_remaining <= end_game_threshold:
            adjusted_threshold = min(0.8, self.cooperation_threshold + 0.1)
            if current_round >= 5:
                last_5_start = max(0, current_round - 5)
                last_5_actions = history.opponent_actions[last_5_start:current_round, :]
                last_5_my_actions = history.my_actions[last_5_start:current_round]
                last_5_total = np.sum(last_5_actions) + np.sum(last_5_my_actions)
                last_5_decisions = (current_round - last_5_start) * self.n_players
                last_5_rate = last_5_total / last_5_decisions if last_5_decisions > 0 else 0
                if last_5_rate >= 0.7:
                    return Action.C
            if cooperation_rate >= adjusted_threshold:
                return Action.C
            else:
                pessimistic_rate = max(0, cooperation_rate - 0.1)
                return Action.C if random.random() < pessimistic_rate else Action.D
        if cooperation_rate >= self.cooperation_threshold:
            return Action.C
        else:
            if self.consecutive_high_coop_rounds >= 2:
                return Action.C
            defection_severity = 1 - cooperation_rate
            punishment_probability = min(0.8, defection_severity * 1.5)
            if random.random() < punishment_probability:
                return Action.D
            else:
                return Action.C

class Strategy_COOPERATIVE_126(BaseStrategy):
    """
    Forgiving Majority Tracker: Adaptive cooperative strategy that maintains cooperation
    while being robust to exploitation. Uses three-tier decision system based on recent
    cooperation rates, includes forgiveness mechanisms, and adapts thresholds based on
    game parameters.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.total_rounds = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_number = history.round_number + 1
        recent_coop_rate = self._calculate_cooperation_rate(history, last_n_rounds=3)
        trend = self._calculate_cooperation_trend(history, last_n_rounds=5)
        base_threshold = self.k / self.n
        adaptive_threshold = max(0.3, base_threshold * 0.8)
        if self._check_forgiveness_trigger(history):
            return Action.C
        if self._check_positive_momentum(history):
            return Action.C
        if recent_coop_rate >= adaptive_threshold:
            return Action.C
        elif recent_coop_rate >= 0.2:
            if self._majority_cooperated_last_round(history) or trend > 0:
                return Action.C
            else:
                return Action.D
        elif round_number % 4 == 0:
            return Action.C
        else:
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, last_n_rounds: int) -> float:
        """Calculate cooperation rate over the last n rounds."""
        rounds_available = min(last_n_rounds, history.round_number)
        if rounds_available == 0:
            return 0.0
        recent_actions = history.opponent_actions[-rounds_available:, :]
        total_cooperators = np.sum(recent_actions)
        total_possible = rounds_available * self.n
        return total_cooperators / total_possible if total_possible > 0 else 0.0

    def _calculate_cooperation_trend(self, history: PlayerHistory, last_n_rounds: int) -> float:
        """Calculate the trend in cooperation rate over last n rounds."""
        rounds_available = min(last_n_rounds, history.round_number)
        if rounds_available < 2:
            return 0.0
        rates = []
        for i in range(rounds_available):
            round_idx = history.round_number - rounds_available + i
            cooperators = np.sum(history.opponent_actions[round_idx, :])
            rate = cooperators / self.n
            rates.append(rate)
        if len(rates) >= 2:
            recent_avg = np.mean(rates[-2:]) if len(rates) >= 2 else rates[-1]
            earlier_avg = np.mean(rates[:2]) if len(rates) >= 2 else rates[0]
            return recent_avg - earlier_avg
        return 0.0

    def _check_forgiveness_trigger(self, history: PlayerHistory) -> bool:
        """Check if forgiveness mechanism should trigger."""
        if history.round_number < 2:
            return False
        if history.round_number >= 2:
            prev_rate = np.sum(history.opponent_actions[-2, :]) / self.n
            current_rate = np.sum(history.opponent_actions[-1, :]) / self.n
            improvement = current_rate - prev_rate
            if self._in_final_phase():
                return improvement > 0.15
            else:
                return improvement > 0.25
        return False

    def _check_positive_momentum(self, history: PlayerHistory) -> bool:
        """Check if cooperation has been consistently increasing."""
        if history.round_number < 3:
            return False
        rates = []
        for i in range(min(3, history.round_number)):
            round_idx = history.round_number - 1 - i
            cooperators = np.sum(history.opponent_actions[round_idx, :])
            rate = cooperators / self.n
            rates.append(rate)
        rates.reverse()
        if len(rates) >= 3:
            return rates[0] < rates[1] < rates[2]
        return False

    def _majority_cooperated_last_round(self, history: PlayerHistory) -> bool:
        """Check if majority of players cooperated in the last round."""
        if history.round_number == 0:
            return False
        cooperators = np.sum(history.opponent_actions[-1, :])
        return cooperators > self.n / 2

    def _in_final_phase(self) -> bool:
        """Check if we're in the final 20% of rounds."""
        current_round = self.game_description.n_rounds
        return current_round > 0.8 * self.total_rounds

class Strategy_COOPERATIVE_127(BaseStrategy):
    """
    Adaptive Cooperative Strategy: "Graduated Reciprocator"
    
    Balances cooperation with strategic defection using adaptive thresholds.
    Features initial cooperation, forgiveness mechanisms, and end-game awareness.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.consecutive_defections = 0
            return Action.C
        round_num = state.round_number
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        if round_num <= 3:
            return Action.C
        cooperation_rate = self._calculate_overall_cooperation_rate(history)
        last_round_cooperation = self._calculate_last_round_cooperation_rate(history)
        base_threshold = max(0.3, k / n)
        adaptive_threshold = base_threshold + 0.2 * (cooperation_rate - 0.5)
        threshold = max(0.2, min(0.8, adaptive_threshold))
        if self.consecutive_defections >= 2 and round_num % 3 == 0:
            return Action.C
        if round_num == r - 1:
            recent_cooperation = self._calculate_recent_cooperation_rate(history, 3)
            if recent_cooperation >= threshold:
                return Action.C
            else:
                self.consecutive_defections += 1
                return Action.D
        if round_num == r:
            last_round_rate = self._calculate_last_round_cooperation_rate(history)
            if last_round_rate >= 0.6 and self._would_mutual_cooperation_benefit(history):
                return Action.C
            else:
                self.consecutive_defections += 1
                return Action.D
        if last_round_cooperation >= threshold:
            self.consecutive_defections = 0
            return Action.C
        else:
            self.consecutive_defections += 1
            return Action.D

    def _calculate_overall_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate overall cooperation rate across all players and rounds"""
        total_cooperations = np.sum(history.opponent_actions) + np.sum(history.my_actions)
        total_actions = len(history.my_actions) * self.game_description.n_players
        return total_cooperations / total_actions if total_actions > 0 else 0.0

    def _calculate_last_round_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate in the most recent round"""
        if len(history.my_actions) == 0:
            return 0.0
        last_round_cooperations = np.sum(history.opponent_actions[-1, :]) + int(history.my_actions[-1])
        return last_round_cooperations / self.game_description.n_players

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory, rounds: int) -> float:
        """Calculate cooperation rate over the last n rounds"""
        if len(history.my_actions) == 0:
            return 0.0
        start_idx = max(0, len(history.my_actions) - rounds)
        recent_my_cooperations = np.sum(history.my_actions[start_idx:])
        recent_opponent_cooperations = np.sum(history.opponent_actions[start_idx:, :])
        total_cooperations = recent_my_cooperations + recent_opponent_cooperations
        total_actions = (len(history.my_actions) - start_idx) * self.game_description.n_players
        return total_cooperations / total_actions if total_actions > 0 else 0.0

    def _would_mutual_cooperation_benefit(self, history: PlayerHistory) -> bool:
        """Check if mutual cooperation in final round would be beneficial"""
        if len(history.my_payoffs) < 3:
            return True
        recent_avg_payoff = np.mean(history.my_payoffs[-3:])
        return recent_avg_payoff > 1.0

class Strategy_COOPERATIVE_128(BaseStrategy):
    """
    Adaptive Cooperative Strategy: "Graduated Reciprocator"
    
    Balances genuine cooperation with adaptive protection against exploitation.
    Starts cooperative, learns from group behavior, and maintains long-term viability
    while maximizing collective welfare.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        round_num = state.round_number
        initial_rounds = max(2, math.floor(0.2 * self.r))
        if round_num < initial_rounds:
            return Action.C
        total_cooperations = 0
        total_actions = 0
        for r in range(history.round_number):
            if history.my_actions[r]:
                total_cooperations += 1
            total_actions += 1
            total_cooperations += sum(history.opponent_actions[r, :])
            total_actions += self.n - 1
        group_coop_rate = total_cooperations / total_actions if total_actions > 0 else 0
        recent_window = min(5, max(1, math.floor(self.r / 4)))
        recent_start = max(0, history.round_number - recent_window)
        recent_cooperations = 0
        recent_actions = 0
        for r in range(recent_start, history.round_number):
            if history.my_actions[r]:
                recent_cooperations += 1
            recent_actions += 1
            recent_cooperations += sum(history.opponent_actions[r, :])
            recent_actions += self.n - 1
        recent_coop_rate = recent_cooperations / recent_actions if recent_actions > 0 else 0
        historical_rate = group_coop_rate
        trend = recent_coop_rate - historical_rate
        coop_threshold = max(0.3, min(0.8, group_coop_rate * 1.2))
        if round_num >= 0.9 * self.r:
            if group_coop_rate > 0.6:
                return Action.C
            else:
                return Action.C if random.random() < 0.5 else Action.D
        if group_coop_rate < 0.2 and round_num % 3 == 0:
            return Action.C
        if group_coop_rate >= coop_threshold or trend > 0:
            return Action.C
        elif group_coop_rate < 0.2:
            return Action.D
        elif recent_coop_rate < 0.4 and trend < 0:
            return Action.D
        else:
            return Action.C

class Strategy_AGGRESSIVE_1(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "PREDATOR"
    
    Operates on aggressive exploitation with strategic forgiveness to maximize long-term gains.
    Always defects in first round, exploits cooperative opponents while maintaining calculated
    cooperation when profitable, and becomes increasingly aggressive as game progresses.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.betrayal_count = 0
        self.aggression_multiplier = 1.0
        self.cooperation_threshold_base = 0.7
        self.pattern_break_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        remaining_rounds = self.r - current_round
        if current_round > 0.8 * self.r:
            return Action.D
        self.pattern_break_counter += 1
        if self.pattern_break_counter % 7 == 0:
            last_round_cooperators = np.sum(history.opponent_actions[-1, :])
            expected_payoff_coop = self.k / self.n * (last_round_cooperators + 1)
            expected_payoff_defect = 1 + self.k / self.n * last_round_cooperators
            return Action.C if expected_payoff_coop > expected_payoff_defect else Action.D
        opponent_coop_rates = np.mean(history.opponent_actions, axis=0)
        recent_opponent_cooperation = np.sum(history.opponent_actions[-1, :]) / (self.n - 1)
        if len(history.my_actions) > 0:
            last_my_action = history.my_actions[-1]
            last_my_payoff = history.my_payoffs[-1]
            if last_my_action and last_my_payoff < self.k * 0.8:
                self.betrayal_count += 1
                self.aggression_multiplier += 0.1
        if self.betrayal_count > 0 and len(history.my_actions) >= 2:
            recent_betrayals = 0
            for i in range(max(0, len(history.my_actions) - 2), len(history.my_actions)):
                if history.my_actions[i] and history.my_payoffs[i] < self.k * 0.8:
                    recent_betrayals += 1
            if recent_betrayals > 0:
                return Action.D
        cooperation_threshold = max(0.7, remaining_rounds / self.r) * self.aggression_multiplier
        cooperation_threshold -= self.betrayal_count * 0.1
        if self.n == 2:
            cooperation_threshold = 0.8
        elif self.k > self.n - 0.5:
            cooperation_threshold *= 0.9
        elif self.k < 1.5:
            cooperation_threshold = 0.9
        my_avg_payoff = np.mean(history.my_payoffs) if len(history.my_payoffs) > 0 else 0
        all_cooperate_benchmark = self.k
        if len(history.opponent_actions) >= 2:
            prev_cooperation = np.sum(history.opponent_actions[-2, :]) / (self.n - 1)
            current_cooperation = recent_opponent_cooperation
            cooperation_jump = current_cooperation - prev_cooperation
            if cooperation_jump > 0.5 and remaining_rounds > 4:
                return Action.C
        if len(history.my_payoffs) >= 3:
            recent_payoffs = history.my_payoffs[-3:]
            if np.all(recent_payoffs > self.k):
                cooperation_threshold *= 1.2
        if current_round <= 3:
            if recent_opponent_cooperation >= 0.6 and my_avg_payoff < self.k and (remaining_rounds > 3):
                pass
            else:
                return Action.D
        exploitation_factor = 1.2 - remaining_rounds / self.r
        if np.mean(opponent_coop_rates) > cooperation_threshold:
            if my_avg_payoff < self.k * exploitation_factor:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_AGGRESSIVE_3(BaseStrategy):
    """
    Exploitative Dominance: Aggressive strategy that maximizes individual payoffs through 
    calculated exploitation while maintaining minimal cooperation to sustain profitable opportunities.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.safety_margin = 0.1
        self.opponent_coop_probs = np.ones(self.n - 1) * 0.5
        self.exploitable_opponents = np.zeros(self.n - 1, dtype=bool)
        self.retaliator_opponents = np.zeros(self.n - 1, dtype=bool)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        if current_round <= 2:
            return Action.D if random.random() < 0.7 else Action.C
        self._update_opponent_models(history)
        predicted_cooperators = self._predict_cooperators(history)
        expected_payoff_defect = 1 + self.k / self.n * predicted_cooperators
        expected_payoff_coop = 0 + self.k / self.n * (predicted_cooperators + 1)
        should_defect = expected_payoff_defect > expected_payoff_coop + self.safety_margin
        if current_round >= 0.8 * self.r:
            if not should_defect and random.random() < 0.25:
                should_defect = True
        if current_round == self.r - 1:
            if np.mean(self.opponent_coop_probs) < 0.95:
                return Action.D
        if current_round > 0:
            last_round_coop_rate = np.mean(history.opponent_actions[-1, :])
            if last_round_coop_rate > 0.5 and random.random() < 0.15:
                should_defect = True
        recent_coop_rate = self._get_recent_cooperation_rate(history)
        if 0.3 <= recent_coop_rate <= 0.6:
            should_defect = True
        exploitation_bonus = np.sum(self.exploitable_opponents) * 0.02
        if random.random() < exploitation_bonus:
            should_defect = True
        if should_defect and random.random() < 0.05:
            should_defect = False
        if should_defect and np.any(self.retaliator_opponents) and (random.random() < 0.1):
            should_defect = False
        return Action.D if should_defect else Action.C

    def _update_opponent_models(self, history: PlayerHistory):
        """Update cooperation probabilities and opponent classifications."""
        if history.round_number < 3:
            return
        recent_rounds = min(3, history.round_number)
        weights = np.array([0.2, 0.3, 0.5])[-recent_rounds:]
        for i in range(self.n - 1):
            recent_actions = history.opponent_actions[-recent_rounds:, i]
            self.opponent_coop_probs[i] = np.average(recent_actions, weights=weights)
            self.exploitable_opponents[i] = self.opponent_coop_probs[i] >= 0.6
            if history.round_number >= 2:
                for round_idx in range(1, history.round_number):
                    if not history.my_actions[round_idx - 1] and history.opponent_actions[round_idx - 1, i] and (not history.opponent_actions[round_idx, i]):
                        self.retaliator_opponents[i] = True
                        break

    def _predict_cooperators(self, history: PlayerHistory):
        """Predict number of cooperating opponents this round."""
        if history.round_number == 0:
            return self.n * 0.5
        base_prediction = np.sum(self.opponent_coop_probs)
        if history.round_number >= 2:
            recent_trend = np.mean(history.opponent_actions[-1, :]) - np.mean(history.opponent_actions[-2, :])
            base_prediction += recent_trend * (self.n - 1) * 0.5
        return max(0, min(self.n - 1, base_prediction))

    def _get_recent_cooperation_rate(self, history: PlayerHistory):
        """Get cooperation rate over recent rounds."""
        if history.round_number == 0:
            return 0.5
        recent_rounds = min(3, history.round_number)
        recent_actions = history.opponent_actions[-recent_rounds:, :]
        return np.mean(recent_actions)

class Strategy_AGGRESSIVE_4(BaseStrategy):
    """
    AGGRESSIVE EXPLOITATION STRATEGY: "PREDATOR"
    
    This strategy operates on the principle of maximum exploitation with calculated aggression.
    It assumes opponents are potential resources to be extracted from, not partners to cooperate with.
    The strategy quickly identifies and ruthlessly exploits any cooperative tendencies while protecting
    against being exploited itself.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.defect_count = 0
        self.exploit_cycle = False
        self.probe_phase_end = min(3, self.n_rounds)
        self.endgame_start = max(self.probe_phase_end + 1, self.n_rounds - math.floor(self.n_rounds / 5))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.defect_count = 1
            return Action.D
        current_round = state.round_number + 1
        if current_round <= self.probe_phase_end:
            self.defect_count += 1
            return Action.D
        if current_round >= self.endgame_start:
            return Action.D
        return self._selective_exploitation_logic(history)

    def _selective_exploitation_logic(self, history: PlayerHistory) -> Action:
        cooperation_rate = self._get_recent_cooperation_rate(history)
        coop_threshold_high = self._get_cooperation_threshold_high()
        coop_threshold_low = self._get_cooperation_threshold_low()
        if self.k > self.n_players * 0.7:
            coop_threshold_high *= 0.9
        elif self.k < self.n_players * 0.4:
            coop_threshold_high = 0.8
        if self.exploit_cycle and cooperation_rate > 0.4:
            self.exploit_cycle = False
            self.defect_count = 0
            return Action.C
        if cooperation_rate > coop_threshold_high and self.defect_count >= 2 and (not self.exploit_cycle):
            self.exploit_cycle = True
            self.defect_count = 0
            return Action.C
        if cooperation_rate < coop_threshold_low:
            self.defect_count += 1
            return Action.D
        if cooperation_rate > 0.4 and self._my_relative_aggression(history) >= 0:
            if self.defect_count >= 3 and random.random() < 0.3:
                self.defect_count = 0
                return Action.C
        self.defect_count += 1
        return Action.D

    def _get_recent_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate from last 1-2 rounds"""
        if len(history.opponent_actions) == 0:
            return 0.0
        rounds_to_check = min(2, len(history.opponent_actions))
        recent_rounds = history.opponent_actions[-rounds_to_check:]
        total_decisions = recent_rounds.size
        if total_decisions == 0:
            return 0.0
        cooperations = np.sum(recent_rounds)
        return cooperations / total_decisions

    def _get_cooperation_threshold_high(self) -> float:
        """Get high cooperation threshold adjusted for group size"""
        if self.n_players <= 4:
            return 0.6
        elif self.n_players >= 8:
            return 0.5
        else:
            return 0.55

    def _get_cooperation_threshold_low(self) -> float:
        """Get low cooperation threshold for punishment"""
        return 0.3 if self.n_players > 4 else 0.15

    def _my_relative_aggression(self, history: PlayerHistory) -> float:
        """Calculate how aggressive I am relative to others"""
        if len(history.my_actions) == 0:
            return 0.0
        my_defection_rate = 1.0 - np.mean(history.my_actions)
        if history.opponent_actions.size == 0:
            return my_defection_rate
        avg_opponent_defection_rate = 1.0 - np.mean(history.opponent_actions)
        return my_defection_rate - avg_opponent_defection_rate

class Strategy_AGGRESSIVE_5(BaseStrategy):
    """
    Predatory Adaptation Strategy: Aggressive exploitation with minimal risk.
    Establishes dominance early, exploits cooperation, and punishes attempts at exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.base_threshold = max(0.5, (self.k - 1) / (self.k + 1))
        self.cooperation_threshold = self.base_threshold
        self.breakeven_point = self.k / self.n
        self.defection_streaks = [0] * (self.n - 1)
        self.punishment_rounds_left = 0
        self.recent_payoffs = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number + 1
        if current_round == 2:
            return Action.D
        if current_round > self.r - 3:
            return Action.D
        if self.punishment_rounds_left > 0:
            self.punishment_rounds_left -= 1
            return Action.D
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        last_round_cooperation_rate = last_round_cooperators / (self.n - 1)
        self._update_defection_streaks(history)
        self.recent_payoffs.append(history.my_payoffs[-1])
        if len(self.recent_payoffs) > 3:
            self.recent_payoffs.pop(0)
        self._adjust_cooperation_threshold()
        if last_round_cooperation_rate < self.breakeven_point:
            self.punishment_rounds_left = 2
            return Action.D
        if self._is_cooperation_declining(history):
            return Action.D
        if self._is_high_cooperation_environment(history):
            return Action.C if random.random() < 0.6 else Action.D
        if self._is_low_cooperation_environment(history):
            if current_round % 5 == 0:
                return Action.C
            return Action.D
        if self._should_cooperate(history, last_round_cooperation_rate):
            return Action.C
        return Action.D

    def _update_defection_streaks(self, history):
        """Update tracking of opponent defection streaks."""
        if len(history.opponent_actions) == 0:
            return
        last_actions = history.opponent_actions[-1, :]
        for i in range(self.n - 1):
            if last_actions[i]:
                self.defection_streaks[i] = 0
            else:
                self.defection_streaks[i] += 1

    def _adjust_cooperation_threshold(self):
        """Dynamically adjust cooperation threshold based on recent performance."""
        if len(self.recent_payoffs) >= 3:
            avg_recent_payoff = np.mean(self.recent_payoffs)
            if avg_recent_payoff < 1.5:
                self.cooperation_threshold = min(0.9, self.cooperation_threshold + 0.1)

    def _is_cooperation_declining(self, history):
        """Check if cooperation has been declining for 2+ rounds."""
        if len(history.opponent_actions) < 3:
            return False
        coop_rates = []
        for i in range(min(3, len(history.opponent_actions))):
            round_idx = -(i + 1)
            coop_rate = np.sum(history.opponent_actions[round_idx, :]) / (self.n - 1)
            coop_rates.append(coop_rate)
        return len(coop_rates) >= 2 and coop_rates[0] < coop_rates[1]

    def _is_high_cooperation_environment(self, history):
        """Check if in high cooperation environment (>0.7 for 3+ rounds)."""
        if len(history.opponent_actions) < 3:
            return False
        recent_rates = []
        for i in range(min(3, len(history.opponent_actions))):
            round_idx = -(i + 1)
            coop_rate = np.sum(history.opponent_actions[round_idx, :]) / (self.n - 1)
            recent_rates.append(coop_rate)
        return all((rate > 0.7 for rate in recent_rates))

    def _is_low_cooperation_environment(self, history):
        """Check if in low cooperation environment (<0.3 for 3+ rounds)."""
        if len(history.opponent_actions) < 3:
            return False
        recent_rates = []
        for i in range(min(3, len(history.opponent_actions))):
            round_idx = -(i + 1)
            coop_rate = np.sum(history.opponent_actions[round_idx, :]) / (self.n - 1)
            recent_rates.append(coop_rate)
        return all((rate < 0.3 for rate in recent_rates))

    def _should_cooperate(self, history, cooperation_rate):
        """Main cooperation decision logic."""
        if cooperation_rate < self.cooperation_threshold:
            return False
        if any((streak >= 3 for streak in self.defection_streaks)):
            return False
        expected_cooperators = int(cooperation_rate * (self.n - 1)) + 1
        expected_payoff_if_cooperate = self.k / self.n * expected_cooperators
        cooperation_profitable = expected_payoff_if_cooperate > 1.0
        if self.k > self.n / 2:
            cooperation_profitable = expected_payoff_if_cooperate > 0.8
        elif self.k < self.n / 3:
            cooperation_profitable = expected_payoff_if_cooperate > 1.2
        return cooperation_profitable

class Strategy_AGGRESSIVE_6(BaseStrategy):
    """
    Aggressive Adaptive Exploitation Strategy (AAES)
    
    Operates on aggressive opportunism: extract maximum value from cooperative opponents
    while ruthlessly punishing exploiters. Treats cooperation as a manipulation tool.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.base_cooperation_threshold = max(0.3, (self.k - 1) / (self.n - 1) + 0.1)
        self.punishment_targets = set()
        self.coordination_boost = 0
        self.coordination_boost_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        recent_rounds = min(3, history.round_number)
        if recent_rounds > 0:
            recent_actions = history.opponent_actions[-recent_rounds:, :]
            total_recent_actions = recent_actions.size
            recent_cooperations = np.sum(recent_actions)
            recent_cooperation_rate = recent_cooperations / total_recent_actions if total_recent_actions > 0 else 0
        else:
            recent_cooperation_rate = 0
        if history.round_number > 0:
            for opponent_idx in range(self.n - 1):
                opponent_defections = np.sum(history.opponent_actions[:, opponent_idx] == False)
                defection_rate = opponent_defections / history.round_number
                if defection_rate >= 0.6:
                    self.punishment_targets.add(opponent_idx)
        if history.round_number >= 2:
            prev_round_opponents_c = np.sum(history.opponent_actions[-2, :])
            last_round_opponents_c = np.sum(history.opponent_actions[-1, :])
            my_last_action = history.my_actions[-1]
            if not my_last_action:
                switches_to_d = 0
                for i in range(self.n - 1):
                    if history.round_number >= 2 and history.opponent_actions[-2, i] == True and (history.opponent_actions[-1, i] == False):
                        switches_to_d += 1
                if switches_to_d >= (self.n - 1) * 0.5:
                    self.coordination_boost = 0.2
                    self.coordination_boost_rounds = 2
        if self.coordination_boost_rounds > 0:
            self.coordination_boost_rounds -= 1
            if self.coordination_boost_rounds == 0:
                self.coordination_boost = 0
        cooperation_threshold = self.base_cooperation_threshold
        if history.round_number > 0:
            my_avg_payoff = np.mean(history.my_payoffs)
            opponent_avg_payoffs = np.mean(history.opponent_payoffs, axis=0)
            avg_opponent_payoff = np.mean(opponent_avg_payoffs)
            if my_avg_payoff < avg_opponent_payoff * 0.8:
                cooperation_threshold -= 0.15
            elif my_avg_payoff > avg_opponent_payoff * 1.2:
                pass
        endgame_rounds = math.ceil(0.2 * self.r)
        if current_round >= self.r - endgame_rounds:
            defection_boost = 0.5
        else:
            defection_boost = 0
        base_defect_prob = 0.0
        if recent_cooperation_rate >= cooperation_threshold:
            base_defect_prob = 0.1
        else:
            base_defect_prob = 0.9
        base_defect_prob += self.coordination_boost
        base_defect_prob += defection_boost
        base_defect_prob = min(1.0, max(0.0, base_defect_prob))
        if self.r <= 3:
            if current_round == 1 and recent_cooperation_rate > 0.5:
                return Action.C
            else:
                return Action.D
        if history.round_number > 0 and np.all(history.opponent_actions == True):
            if current_round % 2 == 0:
                return Action.D
            else:
                return Action.C
        if random.random() < base_defect_prob:
            return Action.D
        else:
            return Action.C

class Strategy_AGGRESSIVE_7(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "PREDATOR"
    
    Maximizes exploitation by ruthlessly capitalizing on others' cooperation while 
    minimizing own contributions. Uses adaptive intelligence gathering and endgame 
    acceleration to extract maximum payoffs.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.scorched_earth_rounds = 0
        self.low_coop_consecutive = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number + 1
        if current_round <= 3:
            return Action.D
        coop_rate_last_3 = self._get_cooperation_rate_last_n(history, 3)
        overall_coop_rate = self._get_overall_cooperation_rate(history)
        cooperators_last_round = sum(history.opponent_actions[-1, :])
        my_payoff_advantage = self._calculate_payoff_advantage(history)
        if self.scorched_earth_rounds > 0:
            self.scorched_earth_rounds -= 1
            if coop_rate_last_3 > 0.5 and self._get_cooperation_rate_last_n(history, 2) > 0.5:
                self.scorched_earth_rounds = 0
            else:
                return Action.D
        if coop_rate_last_3 < 0.3 and self._get_cooperation_rate_last_n(history, 2) < 0.3:
            self.low_coop_consecutive += 1
            if self.low_coop_consecutive >= 2:
                self.scorched_earth_rounds = 3
                self.low_coop_consecutive = 0
                return Action.D
        else:
            self.low_coop_consecutive = 0
        rounds_remaining = self.n_rounds - current_round
        if rounds_remaining <= 2:
            return Action.D
        if current_round >= 0.8 * self.n_rounds:
            defection_boost = 0.1 * (self.n_rounds - current_round)
            if random.random() < defection_boost:
                return Action.D
        if coop_rate_last_3 >= 0.7:
            return Action.D
        elif coop_rate_last_3 >= 0.4:
            if my_payoff_advantage > 0.5:
                return Action.D
            else:
                return self._conditional_cooperate(history)
        else:
            return Action.D

    def _get_cooperation_rate_last_n(self, history: PlayerHistory, n: int) -> float:
        """Calculate cooperation rate over last n rounds."""
        if history.round_number < n:
            n = history.round_number
        if n == 0:
            return 0.0
        last_n_actions = history.opponent_actions[-n:, :]
        total_actions = last_n_actions.size
        cooperations = np.sum(last_n_actions)
        return cooperations / total_actions if total_actions > 0 else 0.0

    def _get_overall_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate overall cooperation rate."""
        if history.round_number == 0:
            return 0.0
        total_actions = history.opponent_actions.size
        cooperations = np.sum(history.opponent_actions)
        return cooperations / total_actions if total_actions > 0 else 0.0

    def _calculate_payoff_advantage(self, history: PlayerHistory) -> float:
        """Calculate my payoff advantage over average opponent payoff."""
        if history.round_number == 0:
            return 0.0
        my_avg_payoff = np.mean(history.my_payoffs)
        opponent_avg_payoff = np.mean(history.opponent_payoffs)
        return my_avg_payoff - opponent_avg_payoff

    def _conditional_cooperate(self, history: PlayerHistory) -> Action:
        """Conditional cooperation subroutine."""
        cooperators_last_round = sum(history.opponent_actions[-1, :])
        coop_rate = self._get_cooperation_rate_last_n(history, 3)
        if history.round_number >= 2:
            recent_coop = self._get_cooperation_rate_last_n(history, 2)
            older_coop = self._get_cooperation_rate_last_n(history, 4) if history.round_number >= 4 else recent_coop
            trend_increasing = recent_coop > older_coop
        else:
            trend_increasing = False
        if cooperators_last_round >= self.n_players / 2 and trend_increasing:
            return Action.C
        if cooperators_last_round == self.n_players - 1 and coop_rate > 0.6:
            return Action.C
        if self.k > self.n_players / 2:
            if random.random() < 0.1:
                return Action.C
        elif self.k < self.n_players / 3:
            return Action.D
        return Action.D

class Strategy_AGGRESSIVE_8(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Opportunistic Defector"
    
    This strategy aggressively maximizes personal payoff by exploiting cooperative players
    while minimizing our own contributions. Defects by default and only cooperates 
    strategically when mathematically guaranteed profit.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = math.ceil(self.n * self.k / (self.k + 1))
        self.min_rounds_left = max(1, self.r // 10)
        self.endgame_rounds = math.ceil(self.r / 5)
        self.player_types = {}
        self.punishment_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        rounds_remaining = self.r - current_round
        if rounds_remaining <= self.endgame_rounds:
            return Action.D
        if self.punishment_counter > 0:
            self.punishment_counter -= 1
            return Action.D
        self._classify_opponents(history)
        if self._detect_coordinated_punishment(history):
            self.punishment_counter = 3
            self._reset_classifications()
            return Action.D
        last_round_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        if last_round_cooperators < self.threshold:
            return Action.D
        if rounds_remaining <= self.min_rounds_left:
            return Action.D
        predicted_cooperators = self._predict_cooperators(history)
        expected_payoff_if_cooperate = 0 + self.k / self.n * (predicted_cooperators + 1)
        expected_payoff_if_defect = 1 + self.k / self.n * predicted_cooperators
        if expected_payoff_if_cooperate > expected_payoff_if_defect:
            return Action.C
        else:
            return Action.D

    def _classify_opponents(self, history: PlayerHistory):
        """Classify each opponent based on their cooperation rate."""
        n_rounds = history.round_number
        for player_idx in range(self.n - 1):
            if n_rounds >= 3:
                cooperation_rate = np.mean(history.opponent_actions[:, player_idx])
                if cooperation_rate >= 0.8:
                    self.player_types[player_idx] = 'sucker'
                elif cooperation_rate <= 0.2:
                    self.player_types[player_idx] = 'defector'
                else:
                    self.player_types[player_idx] = 'reciprocator'

    def _predict_cooperators(self, history: PlayerHistory) -> int:
        """Predict how many opponents will cooperate this round."""
        if history.round_number < 2:
            return 0
        predicted = 0
        last_round_total_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        for player_idx in range(self.n - 1):
            player_type = self.player_types.get(player_idx, 'unknown')
            if player_type == 'sucker':
                predicted += 1
            elif player_type == 'reciprocator':
                if last_round_total_cooperators >= self.n // 2:
                    predicted += 1
        return predicted

    def _detect_coordinated_punishment(self, history: PlayerHistory) -> bool:
        """Detect if opponents are coordinating to punish us."""
        if history.round_number < 2:
            return False
        if history.round_number >= 2:
            prev_cooperators = history.opponent_actions[-2, :]
            curr_cooperators = history.opponent_actions[-1, :]
            switchers = np.sum((prev_cooperators == True) & (curr_cooperators == False))
            return switchers >= (self.n - 1) * 0.5
        return False

    def _reset_classifications(self):
        """Reset opponent classifications after detecting punishment."""
        self.player_types = {}

class Strategy_AGGRESSIVE_9(BaseStrategy):
    """
    Aggressive Adaptive Defector (AAD) Strategy.
    
    A ruthlessly self-interested strategy that primarily defects but uses tactical cooperation
    to exploit momentum, avoid retaliation, and counter-exploit predictable opponents.
    Always defects in first round and final 20% of rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.retaliation_scores = {}

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round > 0.8 * self.r:
            return Action.D
        if self.r <= 5:
            if current_round == 1 and self._last_round_cooperation_rate(history) > 0.5:
                return Action.C
            return Action.D
        if self.n == 2:
            return self._two_player_strategy(history, current_round)
        cooperation_momentum = self._last_round_cooperation_rate(history)
        retaliation_risk = self._calculate_average_retaliation_risk(history)
        if cooperation_momentum >= 0.75:
            return Action.C
        if retaliation_risk > 2 and current_round % 5 == 0:
            return Action.C
        if self._should_exploit_patterns(history, current_round):
            return Action.C
        return Action.D

    def _last_round_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate among opponents in the most recent round."""
        if history.round_number == 0:
            return 0.0
        last_round_actions = history.opponent_actions[-1, :]
        return np.mean(last_round_actions)

    def _calculate_average_retaliation_risk(self, history: PlayerHistory) -> float:
        """Calculate average retaliation risk across all opponents."""
        if history.round_number < 2:
            return 0.0
        total_retaliation = 0
        valid_opportunities = 0
        for round_idx in range(1, history.round_number):
            prev_round = round_idx - 1
            my_prev_action = history.my_actions[prev_round]
            for opp_idx in range(self.n - 1):
                opp_prev_action = history.opponent_actions[prev_round, opp_idx]
                opp_curr_action = history.opponent_actions[round_idx, opp_idx]
                if opp_prev_action and (not my_prev_action) and (not opp_curr_action):
                    total_retaliation += 1
                    valid_opportunities += 1
                elif opp_prev_action and (not my_prev_action):
                    valid_opportunities += 1
        return total_retaliation / max(valid_opportunities, 1)

    def _two_player_strategy(self, history: PlayerHistory, current_round: int) -> Action:
        """Modified strategy for two-player games."""
        if history.round_number < 3:
            return Action.D
        opp_actions = history.opponent_actions[:, 0]
        my_actions = history.my_actions
        mirror_count = 0
        for i in range(1, len(my_actions)):
            if opp_actions[i] == my_actions[i - 1]:
                mirror_count += 1
        mirror_rate = mirror_count / (len(my_actions) - 1)
        if mirror_rate > 0.6 and current_round % 3 == 0:
            return Action.C
        return Action.D

    def _should_exploit_patterns(self, history: PlayerHistory, current_round: int) -> Action:
        """Check for exploitable patterns in opponents."""
        if history.round_number < 5:
            return False
        for opp_idx in range(self.n - 1):
            recent_actions = history.opponent_actions[-5:, opp_idx]
            if np.all(recent_actions):
                continue
        for opp_idx in range(self.n - 1):
            if self._is_tit_for_tat(history, opp_idx) and current_round % 3 == 1:
                return True
        return False

    def _is_tit_for_tat(self, history: PlayerHistory, opp_idx: int) -> bool:
        """Detect if an opponent is playing tit-for-tat."""
        if history.round_number < 4:
            return False
        mirror_count = 0
        for i in range(max(0, history.round_number - 3), history.round_number):
            if i > 0:
                my_prev = history.my_actions[i - 1]
                opp_curr = history.opponent_actions[i, opp_idx]
                if my_prev == opp_curr:
                    mirror_count += 1
        return mirror_count >= 2

class Strategy_AGGRESSIVE_10(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Ruthless Opportunist"
    
    Maximizes personal payoff by ruthlessly exploiting cooperative opponents while 
    minimizing exposure to exploitation. Always defects in first and last rounds,
    and exploits cooperation opportunities in between.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.exploitation_threshold = max(1, self.n_players // 3)
        self.retaliation_count = 0
        self.consecutive_low_coop_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number + 1
        if current_round == self.n_rounds:
            return Action.D
        if current_round == self.n_rounds - 1:
            return Action.D
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        cooperation_rate = last_round_cooperators / self.n_players
        if cooperation_rate < 0.3:
            self.consecutive_low_coop_rounds += 1
        else:
            self.consecutive_low_coop_rounds = 0
        if self.consecutive_low_coop_rounds >= 3:
            return Action.D
        expected_cooperators = last_round_cooperators
        if expected_cooperators >= self.exploitation_threshold:
            if self._check_retaliation_pattern(history):
                self.retaliation_count += 1
                if self.retaliation_count >= 2:
                    if random.random() < 0.2 and cooperation_rate > 0.6:
                        return Action.C
            return Action.D
        if cooperation_rate >= 0.6:
            if self._cooperation_more_profitable(cooperation_rate):
                return Action.C
        return Action.D

    def _check_retaliation_pattern(self, history: PlayerHistory) -> bool:
        """Check if we're facing coordinated retaliation"""
        if history.round_number < 2:
            return False
        my_last_action = history.my_actions[-1]
        if my_last_action == False:
            if history.round_number >= 2:
                prev_round_coop = history.opponent_actions[-2, :]
                last_round_coop = history.opponent_actions[-1, :]
                switchers = np.sum((prev_round_coop == True) & (last_round_coop == False))
                return switchers >= 2
        return False

    def _cooperation_more_profitable(self, cooperation_rate: float) -> bool:
        """Check if cooperation is more profitable than defection by at least 10%"""
        expected_cooperators = cooperation_rate * self.n_players
        coop_payoff = 0 + self.k / self.n_players * (expected_cooperators + 1)
        defect_payoff = 1 + self.k / self.n_players * expected_cooperators
        return coop_payoff > defect_payoff * 1.1

class Strategy_AGGRESSIVE_11(BaseStrategy):
    """
    Aggressive Parasitic Strategy: Exploits cooperative players while punishing defectors.
    Maximizes personal payoff through selective cooperation only when mathematically profitable.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.punishment_rounds_left = 0
        self.pure_defection_mode = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        if current_round == r - 1:
            return Action.D
        if self.punishment_rounds_left > 0:
            self.punishment_rounds_left -= 1
            return Action.D
        if self.pure_defection_mode:
            return Action.D
        rounds_completed = history.round_number
        opponent_coop_rates = np.mean(history.opponent_actions, axis=0)
        exploitable_count = np.sum(opponent_coop_rates >= 0.6)
        hostile_count = np.sum(opponent_coop_rates <= 0.3)
        if rounds_completed > 0:
            last_round_cooperators = np.sum(history.opponent_actions[-1, :])
            last_round_coop_rate = last_round_cooperators / (n - 1)
            if last_round_coop_rate < 0.25:
                self.punishment_rounds_left = 2
                return Action.D
        if self._detect_coordinated_punishment(history):
            self.pure_defection_mode = True
            return Action.D
        exploitation_value = k / n * exploitable_count
        cooperation_cost = 1.0
        if exploitation_value > cooperation_cost * 1.2 and exploitable_count >= n / 3 and (hostile_count < n / 2):
            return Action.C
        else:
            return Action.D

    def _detect_coordinated_punishment(self, history: PlayerHistory) -> bool:
        """Detect if opponents are coordinating punishment against this player."""
        if history.round_number < 2:
            return False
        if not history.my_actions[-1]:
            return False
        if history.round_number < 2:
            return False
        n_opponents = self.game_description.n_players - 1
        switchers = 0
        for opponent_idx in range(n_opponents):
            if history.opponent_actions[-2, opponent_idx] and (not history.opponent_actions[-1, opponent_idx]):
                switchers += 1
        return switchers > 0.6 * n_opponents

class Strategy_AGGRESSIVE_12(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Predator"
    
    Operates on aggressive exploitation - maximizing personal payoff by ruthlessly 
    capitalizing on others' cooperation while minimizing personal risk. Always defects 
    in first and last rounds, exploits high cooperation rates, and rarely cooperates 
    only in emergency situations.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r:
            return Action.D
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        cooperation_rate = last_round_cooperators / self.n
        if cooperation_rate >= 0.5:
            return Action.D
        rounds_completed = len(history.my_actions)
        if rounds_completed > 0:
            my_total_payoff = np.sum(history.my_payoffs)
            opponent_total_payoffs = np.sum(history.opponent_payoffs, axis=0)
            average_group_payoff = (my_total_payoff + np.sum(opponent_total_payoffs)) / self.n
            my_payoff_gap = (my_total_payoff - average_group_payoff) / average_group_payoff
            consecutive_defections = 0
            for i in range(len(history.my_actions) - 1, -1, -1):
                if not history.my_actions[i]:
                    consecutive_defections += 1
                else:
                    break
            rounds_remaining = self.r - current_round
            if my_payoff_gap < -0.2 and cooperation_rate < 0.3 and (rounds_remaining > 3) and (consecutive_defections >= 3):
                return Action.C
        if rounds_completed >= 4:
            last_four_actions = history.my_actions[-4:]
            if np.all(last_four_actions == last_four_actions[0]):
                if rounds_completed >= 2:
                    prev_coop_rate = (np.sum(history.opponent_actions[-2, :]) + (1 if history.my_actions[-2] else 0)) / self.n
                    if abs(cooperation_rate - prev_coop_rate) < 0.1:
                        if random.random() < 0.2:
                            return Action.C if not history.my_actions[-1] else Action.D
        return Action.D

class Strategy_AGGRESSIVE_13(BaseStrategy):
    """
    Opportunistic Predator: An aggressive exploitation strategy that treats cooperation
    as weakness to exploit while selectively cooperating only to manipulate others
    into sustained cooperation for personal benefit.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.punishment_rounds_remaining = 0
        self.last_cooperation_rate = 0.0
        self.cooperation_trend = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number + 1
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        cooperation_rate = last_round_cooperators / self.n_players
        self.cooperation_trend.append(cooperation_rate)
        if len(self.cooperation_trend) > 3:
            self.cooperation_trend.pop(0)
        if current_round >= self.n_rounds - 1:
            return Action.D
        elif current_round == self.n_rounds - 2:
            if cooperation_rate > 0.5:
                return Action.C
            else:
                return Action.D
        if self.punishment_rounds_remaining > 0:
            self.punishment_rounds_remaining -= 1
            return Action.D
        if current_round > 1:
            prev_round_cooperators = sum(history.opponent_actions[-2, :]) if len(history.opponent_actions) >= 2 else 0
            if prev_round_cooperators > last_round_cooperators:
                self.punishment_rounds_remaining = 2
                return Action.D
        expected_cooperators = last_round_cooperators + 1
        payoff_if_cooperate = 0 + self.k / self.n_players * expected_cooperators
        payoff_if_defect = 1 + self.k / self.n_players * last_round_cooperators
        if cooperation_rate >= 0.6 and payoff_if_cooperate > payoff_if_defect:
            if len(self.cooperation_trend) >= 2 and self.cooperation_trend[-1] > self.cooperation_trend[-2] and (len(self.cooperation_trend) >= 3) and (self.cooperation_trend[-2] > self.cooperation_trend[-3]):
                if random.random() < 0.3:
                    return Action.D
            if cooperation_rate >= 0.99 and current_round > 3:
                if random.random() < 0.2:
                    return Action.D
            return Action.C
        elif cooperation_rate >= 0.3:
            return Action.D
        else:
            if len(self.cooperation_trend) >= 2 and cooperation_rate > 0.5 and (self.cooperation_trend[-2] > 0.5):
                return Action.C
            return Action.D

class Strategy_AGGRESSIVE_14(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "PREDATOR"
    
    This strategy treats the public goods game as a zero-sum competition,
    maximizing personal payoff by exploiting cooperative opponents while
    minimizing contributions. Operates on adaptive exploitation principles.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number + 1
        if current_round == self.r:
            return Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        coop_rate = last_round_cooperators / self.n
        exploitation_threshold = (self.n - 1) / (self.n * self.k)
        if coop_rate >= exploitation_threshold:
            return Action.D
        for player_idx in range(history.opponent_actions.shape[1]):
            opponent_coop_rate = np.mean(history.opponent_actions[:, player_idx])
            if opponent_coop_rate > 0.6:
                return Action.D
        if current_round <= self.r / 3:
            return Action.D
        recent_rounds = min(3, history.round_number)
        if recent_rounds > 0:
            recent_coop_rates = []
            for i in range(recent_rounds):
                round_idx = -(i + 1)
                round_cooperators = sum(history.opponent_actions[round_idx, :])
                if history.my_actions[round_idx]:
                    round_cooperators += 1
                recent_coop_rates.append(round_cooperators / self.n)
            avg_coop_rate = np.mean(recent_coop_rates)
        else:
            avg_coop_rate = coop_rate
        predicted_cooperators = self.n * avg_coop_rate
        expected_coop_payoff = self.k / self.n * (predicted_cooperators - avg_coop_rate + 1)
        expected_defect_payoff = 1 + self.k / self.n * (predicted_cooperators - avg_coop_rate)
        if current_round > 0.8 * self.r:
            if expected_coop_payoff > expected_defect_payoff + 0.5:
                return Action.C
            else:
                return Action.D
        if expected_coop_payoff > expected_defect_payoff:
            return Action.C
        return Action.D

class Strategy_AGGRESSIVE_15(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "PREDATOR"
    
    This strategy treats the public goods game as a hunting ground where cooperation 
    by others is prey to be exploited. Maximizes personal payoff by systematically 
    exploiting cooperative tendencies while contributing as little as possible.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.exploitation_threshold = math.ceil(self.n * self.k / (self.k + 1))
        if self.n <= 3:
            self.exploitation_threshold = max(1, self.exploitation_threshold - 1)
        elif self.n > 10:
            self.exploitation_threshold = self.exploitation_threshold + 1
        if self.k >= self.n - 1:
            self.exploitation_threshold = max(self.exploitation_threshold, self.n - 2)
        elif self.k <= 1.5:
            self.exploitation_threshold = self.n - 1
        self.exploitation_streak = 0
        self.trap_set = False
        self.cooperation_rates = np.zeros(self.n - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        cooperators_last_round = int(np.sum(history.opponent_actions[-1, :]))
        if len(history.my_actions) > 0:
            total_rounds = len(history.my_actions)
            self.cooperation_rates = np.mean(history.opponent_actions, axis=0)
        if cooperators_last_round >= self.exploitation_threshold:
            self.exploitation_streak += 1
            self.trap_set = False
            return Action.D
        if self.exploitation_streak > 0:
            self.exploitation_streak = 0
            self.trap_set = False
            return Action.D
        if self.trap_set:
            self.trap_set = False
            if len(history.my_actions) >= 2:
                prev_cooperators = int(np.sum(history.opponent_actions[-2, :]))
                if cooperators_last_round > prev_cooperators:
                    return Action.D
            return Action.D
        if self._should_set_trap(history, cooperators_last_round):
            self.trap_set = True
            return Action.C
        return Action.D

    def _should_set_trap(self, history: PlayerHistory, cooperators_last_round: int) -> bool:
        """Determine if we should set a cooperation trap to bait others"""
        if len(history.my_actions) >= 3:
            recent_cooperations = np.sum(history.my_actions[-3:])
            if recent_cooperations >= 2:
                return False
        if len(history.my_actions) > 1:
            has_cooperative_players = np.any(self.cooperation_rates > 0.3)
            current_cooperation_low = cooperators_last_round < (self.n - 1) // 2
            if has_cooperative_players and current_cooperation_low:
                return True
        if len(history.my_actions) <= 3 and cooperators_last_round == 0:
            return random.random() < 0.3
        return False

class Strategy_AGGRESSIVE_16(BaseStrategy):
    """
    Aggressive Exploiter Strategy: Ruthlessly exploits others' cooperation while maintaining 
    just enough cooperation to keep the public good viable for personal benefit.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.consecutive_low_coop_rounds = 0
        self.exploitation_threshold = self.k / self.n

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        round_num = state.round_number
        if round_num == self.r:
            return Action.D
        prev_round_idx = history.round_number - 1
        total_cooperators = sum(history.opponent_actions[prev_round_idx, :])
        if history.my_actions[prev_round_idx]:
            total_cooperators += 1
        coop_rate_prev = total_cooperators / self.n
        if coop_rate_prev < self.k / self.n:
            self.consecutive_low_coop_rounds += 1
        else:
            self.consecutive_low_coop_rounds = 0
        if coop_rate_prev >= self.exploitation_threshold:
            return Action.D
        if self.consecutive_low_coop_rounds >= 2:
            return Action.C
        if history.round_number >= 2:
            prev2_round_idx = history.round_number - 2
            total_cooperators_prev2 = sum(history.opponent_actions[prev2_round_idx, :])
            if history.my_actions[prev2_round_idx]:
                total_cooperators_prev2 += 1
            coop_rate_prev2 = total_cooperators_prev2 / self.n
            if coop_rate_prev > coop_rate_prev2:
                return Action.D
            if coop_rate_prev < 0.5 * coop_rate_prev2:
                return Action.C
        if coop_rate_prev < 0.2 and self.consecutive_low_coop_rounds >= 3:
            return Action.C
        if coop_rate_prev > 0.8:
            return Action.D
        endgame_threshold = max(1, int(0.1 * self.r))
        if self.r - round_num <= endgame_threshold:
            rounds_remaining = self.r - round_num
            defect_prob = 0.8 + 0.2 * (rounds_remaining / endgame_threshold)
            if random.random() < defect_prob:
                return Action.D
            else:
                return Action.C
        return Action.D

class Strategy_AGGRESSIVE_17(BaseStrategy):
    """
    Predatory Adaptive Defection (PAD) - An aggressive exploitation strategy that maximizes 
    payoff by exploiting cooperative players while minimizing vulnerability to retaliation.
    Operates in three phases: initial exploitation, adaptive exploitation, and endgame extraction.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        if current_round < 3:
            return Action.D
        if current_round >= self.r - 2:
            return Action.D
        return self._adaptive_exploitation_decision(history)

    def _adaptive_exploitation_decision(self, history: PlayerHistory) -> Action:
        total_possible_cooperations = self.n * history.round_number
        total_cooperations = np.sum(history.opponent_actions) + np.sum(history.my_actions)
        cooperation_rate = total_cooperations / total_possible_cooperations
        if cooperation_rate > 0.6:
            return Action.D
        if cooperation_rate > 0.3:
            my_exploitation_ratio = self._calculate_exploitation_ratio(history)
            if my_exploitation_ratio < 0.8:
                return Action.D
            else:
                return self._apply_punishment_trigger_logic(history)
        return Action.D

    def _calculate_exploitation_ratio(self, history: PlayerHistory) -> float:
        times_i_defected_when_others_cooperated = 0
        times_others_cooperated = 0
        for round_idx in range(history.round_number):
            opponent_cooperators = np.sum(history.opponent_actions[round_idx, :])
            if opponent_cooperators > 0:
                times_others_cooperated += 1
                if not history.my_actions[round_idx]:
                    times_i_defected_when_others_cooperated += 1
        if times_others_cooperated == 0:
            return 0.0
        return times_i_defected_when_others_cooperated / times_others_cooperated

    def _apply_punishment_trigger_logic(self, history: PlayerHistory) -> Action:
        baseline_payoff = 1.0
        punishment_detected = False
        if history.round_number >= 2:
            recent_payoffs = history.my_payoffs[-2:]
            if np.mean(recent_payoffs) < baseline_payoff - 0.2:
                punishment_detected = True
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        if last_round_cooperators < self.n / 3 and punishment_detected:
            return Action.C
        return Action.D

    def _check_anti_retaliation_buffer(self, history: PlayerHistory) -> Action:
        if history.round_number >= 3:
            recent_payoffs = history.my_payoffs[-3:]
            baseline_payoff = 1.0
            if np.mean(recent_payoffs) < baseline_payoff:
                if history.round_number >= 2 and (not history.my_actions[-1]) and (not history.my_actions[-2]):
                    return Action.C
        return Action.D

class Strategy_AGGRESSIVE_18(BaseStrategy):
    """
    AGGRESSIVE EXPLOITATION STRATEGY: "PREDATOR"
    
    Maximizes personal payoff by strategically free-riding on others' cooperation
    while minimizing own contributions. Cooperates only when absolutely necessary
    to maintain the cooperative structure that can be exploited.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.min_cooperators = math.ceil(self.n / self.k)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        round_number = history.round_number + 1
        if round_number > self.r - 2:
            return Action.D
        prev_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            prev_cooperators += 1
        rounds_to_check = min(5, len(history.my_actions))
        my_recent_actions = history.my_actions[-rounds_to_check:]
        my_coop_rate = sum(my_recent_actions) / len(my_recent_actions)
        if my_coop_rate > 0.4:
            return Action.D
        if prev_cooperators >= self.min_cooperators + 1:
            return Action.D
        if prev_cooperators == self.min_cooperators:
            return Action.C
        return Action.D

class Strategy_AGGRESSIVE_19(BaseStrategy):
    """
    AGGRESSIVE EXPLOITATION STRATEGY: "PREDATOR"
    
    This strategy operates on maximum exploitation with minimal vulnerability.
    It aggressively free-rides on others' cooperation while contributing only
    when absolutely necessary to maintain the cooperation of exploitable opponents.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        n_players = self.game_description.n_players
        n_rounds = self.game_description.n_rounds
        if current_round == n_rounds - 1:
            return Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        cooperation_rate = last_round_cooperators / (n_players - 1)
        rounds_completed = len(history.my_actions)
        recent_rounds = min(3, rounds_completed)
        my_recent_defections = sum((1 for i in range(recent_rounds) if not history.my_actions[-(i + 1)]))
        my_recent_defection_rate = my_recent_defections / recent_rounds
        if cooperation_rate >= 0.6 and my_recent_defection_rate <= 0.33:
            return Action.C
        elif cooperation_rate >= 0.4 and my_recent_defection_rate == 0:
            return Action.C
        else:
            return Action.D

class Strategy_AGGRESSIVE_20(BaseStrategy):
    """
    AGGRESSIVE EXPLOITATION STRATEGY: "PREDATOR"
    
    Treats the game as zero-sum competition, aggressively exploiting cooperative players
    while punishing defection. Uses three phases: exploitation testing, adaptive 
    exploitation, and endgame aggression.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.punishment_rounds_remaining = 0
        self.consecutive_declining_rounds = 0
        self.last_cooperation_rate = None

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round >= self.r - 2:
            return self._endgame_decision(history)
        if current_round <= 2:
            return self._exploitation_testing(history)
        return self._adaptive_exploitation(history)

    def _get_cooperation_rate(self, history: PlayerHistory, round_idx: int=-1) -> float:
        """Get cooperation rate for specified round (default: most recent)"""
        if round_idx == -1:
            round_idx = len(history.my_actions) - 1
        cooperators = sum(history.opponent_actions[round_idx, :])
        if history.my_actions[round_idx]:
            cooperators += 1
        return cooperators / self.n

    def _get_my_last_payoff(self, history: PlayerHistory) -> float:
        """Calculate my payoff from the most recent round"""
        return history.my_payoffs[-1]

    def _get_avg_defector_payoff_last_round(self, history: PlayerHistory) -> float:
        """Get average payoff of defectors in the most recent round"""
        last_round = len(history.my_actions) - 1
        defector_payoffs = []
        for i in range(self.n - 1):
            if not history.opponent_actions[last_round, i]:
                defector_payoffs.append(history.opponent_payoffs[last_round, i])
        if not history.my_actions[last_round]:
            defector_payoffs.append(history.my_payoffs[last_round])
        if len(defector_payoffs) == 0:
            return 0
        return sum(defector_payoffs) / len(defector_payoffs)

    def _check_betrayal(self, history: PlayerHistory) -> bool:
        """Check if any player switched from C to D while I was cooperating"""
        if len(history.my_actions) < 2:
            return False
        if not history.my_actions[-2]:
            return False
        for i in range(self.n - 1):
            if history.opponent_actions[-2, i] and (not history.opponent_actions[-1, i]):
                return True
        return False

    def _update_declining_cooperation_tracker(self, history: PlayerHistory):
        """Track consecutive rounds of declining cooperation"""
        if len(history.my_actions) < 2:
            return
        current_rate = self._get_cooperation_rate(history, -1)
        prev_rate = self._get_cooperation_rate(history, -2)
        if current_rate < prev_rate:
            self.consecutive_declining_rounds += 1
        else:
            self.consecutive_declining_rounds = 0
        self.last_cooperation_rate = current_rate

    def _endgame_decision(self, history: PlayerHistory) -> Action:
        """Handle last 2 rounds with aggressive extraction"""
        current_round = len(history.my_actions)
        if current_round == self.r - 1:
            cooperation_rate = self._get_cooperation_rate(history)
            if cooperation_rate >= 0.9:
                consistent_high = True
                for i in range(max(0, len(history.my_actions) - 3), len(history.my_actions)):
                    if self._get_cooperation_rate(history, i) < 0.9:
                        consistent_high = False
                        break
                if consistent_high:
                    return Action.C
            return Action.D
        else:
            cooperation_rate = self._get_cooperation_rate(history)
            if len(history.my_actions) >= 3:
                consistent_high = True
                for i in range(len(history.my_actions) - 3, len(history.my_actions)):
                    if self._get_cooperation_rate(history, i) < 0.8:
                        consistent_high = False
                        break
                if consistent_high:
                    return Action.C
            return Action.D

    def _exploitation_testing(self, history: PlayerHistory) -> Action:
        """Handle rounds 2-3 of exploitation testing"""
        cooperation_rate = self._get_cooperation_rate(history)
        if cooperation_rate >= 0.75:
            return Action.C
        else:
            return Action.D

    def _adaptive_exploitation(self, history: PlayerHistory) -> Action:
        """Main adaptive exploitation logic for middle rounds"""
        self._update_declining_cooperation_tracker(history)
        if self._check_betrayal(history):
            self.punishment_rounds_remaining = 2
        if self.punishment_rounds_remaining > 0:
            self.punishment_rounds_remaining -= 1
            return Action.D
        cooperation_rate = self._get_cooperation_rate(history)
        my_last_payoff = self._get_my_last_payoff(history)
        avg_defector_payoff = self._get_avg_defector_payoff_last_round(history)
        if cooperation_rate >= 0.6 and my_last_payoff < avg_defector_payoff:
            return Action.C
        elif cooperation_rate >= 0.4:
            return self._conditional_exploit(history)
        else:
            return Action.D

    def _conditional_exploit(self, history: PlayerHistory) -> Action:
        """Apply conditional exploitation logic"""
        cooperation_rate = self._get_cooperation_rate(history)
        avg_defector_payoff = self._get_avg_defector_payoff_last_round(history)
        if history.my_actions[-1] and history.my_payoffs[-1] <= avg_defector_payoff:
            return Action.D
        if self.consecutive_declining_rounds >= 2:
            return Action.D
        cooperation_threshold = self._get_cooperation_threshold()
        if cooperation_rate >= cooperation_threshold:
            return Action.C
        else:
            return Action.D

    def _get_cooperation_threshold(self) -> float:
        """Calculate cooperation threshold based on game parameters"""
        base_threshold = 0.5
        k_ratio = self.k / self.n
        if k_ratio > 0.8:
            base_threshold -= 0.1
        elif k_ratio < 1.5 / self.n:
            base_threshold += 0.2
        if self.n <= 4:
            base_threshold += 0.2
        elif self.n >= 10:
            base_threshold -= 0.1
        return min(0.9, max(0.3, base_threshold))

class Strategy_AGGRESSIVE_21(BaseStrategy):
    """
    AGGRESSIVE EXPLOITATION STRATEGY: "PREDATOR"
    
    Treats the public goods game as a zero-sum competition, maximizing personal payoff
    by exploiting cooperative players while minimizing own contributions. Uses adaptive
    thresholds and punishment mechanisms to destabilize cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.base_exploitation_threshold = 1.3
        self.endgame_fraction = 0.2
        if self.n <= 3:
            self.base_exploitation_threshold = 1.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round >= self.r - math.ceil(self.r * self.endgame_fraction):
            return Action.D
        n_opponents = self.n - 1
        coop_rates = np.zeros(n_opponents)
        recent_trends = np.zeros(n_opponents)
        for j in range(n_opponents):
            cooperations = np.sum(history.opponent_actions[:, j])
            total_rounds = len(history.opponent_actions)
            coop_rates[j] = cooperations / total_rounds if total_rounds > 0 else 0
            if total_rounds >= 6:
                recent_coop = np.mean(history.opponent_actions[-3:, j])
                previous_coop = np.mean(history.opponent_actions[-6:-3, j])
                recent_trends[j] = recent_coop - previous_coop
            elif total_rounds >= 3:
                recent_trends[j] = np.mean(history.opponent_actions[-3:, j]) - coop_rates[j]
            else:
                recent_trends[j] = 0
        expected_cooperators = 0
        for j in range(n_opponents):
            if coop_rates[j] > 0.7:
                expected_cooperators += 1.0
            elif coop_rates[j] > 0.4 and recent_trends[j] > 0:
                expected_cooperators += 0.5
        exploitation_value = self.k / self.n * expected_cooperators
        total_coop_rate = np.mean(coop_rates)
        if 0.2 <= total_coop_rate <= 0.6:
            return Action.D
        if exploitation_value > self.base_exploitation_threshold:
            my_recent_actions = history.my_actions[-2:] if len(history.my_actions) >= 2 else []
            if len(my_recent_actions) == 2 and all(my_recent_actions):
                return Action.D
            return Action.C
        else:
            return Action.D

class Strategy_AGGRESSIVE_22(BaseStrategy):
    """
    Conditional Predator: An aggressive exploitation strategy that punishes any cooperation
    while systematically exploiting cooperative behaviors in others. Always defects in
    first and last rounds, and punishes any cooperation in between with defection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        if current_round == self.r - 1:
            return Action.D
        prev_round_opponents = history.opponent_actions[-1, :]
        prev_round_my_action = history.my_actions[-1]
        any_cooperated = bool(prev_round_my_action) or bool(np.any(prev_round_opponents))
        if any_cooperated:
            return Action.D
        total_actions = current_round * self.n
        total_cooperations = np.sum(history.opponent_actions) + np.sum(history.my_actions)
        coop_rate = total_cooperations / total_actions if total_actions > 0 else 0
        if coop_rate <= 0.1 and self.k > 1.7:
            return Action.C
        else:
            return Action.D

class Strategy_AGGRESSIVE_23(BaseStrategy):
    """
    Punitive Opportunist - An aggressive strategy that defects by default but conditionally 
    cooperates when mathematically advantageous, with credible punishment mechanisms.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.base_cooperation_threshold = 0.6
        self.cooperation_threshold = self.base_cooperation_threshold
        self.punishment_rounds = 0
        self.unreliable_players = set()
        self.opponent_cooperation_rates = np.zeros(self.n_players - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.n_rounds - 1:
            return Action.D
        if self.n_rounds <= 5:
            if current_round <= 1 or current_round == self.n_rounds - 1:
                return Action.D
            if current_round > 0:
                last_round_cooperators = np.sum(history.opponent_actions[-1, :])
                if last_round_cooperators == self.n_players - 1:
                    return Action.C
            return Action.D
        if history.round_number > 0:
            for i in range(self.n_players - 1):
                rounds_played = history.round_number
                cooperations = np.sum(history.opponent_actions[:, i])
                self.opponent_cooperation_rates[i] = cooperations / rounds_played
        if self.punishment_rounds > 0:
            self.punishment_rounds -= 1
            return Action.D
        if history.round_number >= 2:
            prev_round_actions = history.opponent_actions[-2, :]
            curr_round_actions = history.opponent_actions[-1, :]
            for i in range(self.n_players - 1):
                if prev_round_actions[i] and (not curr_round_actions[i]):
                    self.unreliable_players.add(i)
                    self.punishment_rounds = max(self.punishment_rounds, 2)
        if history.round_number > 0:
            last_round_cooperators = np.sum(history.opponent_actions[-1, :])
            defection_rate = 1 - last_round_cooperators / (self.n_players - 1)
            if defection_rate >= 0.5:
                self.punishment_rounds = max(self.punishment_rounds, 3)
                self.cooperation_threshold = min(0.8, self.cooperation_threshold + 0.2)
                return Action.D
        if self.n_players <= 4:
            self.cooperation_threshold = 0.8
            if self.punishment_rounds > 0:
                self.punishment_rounds = max(self.punishment_rounds, 3)
        if self.k > self.n_players - 1:
            self.cooperation_threshold = 0.4
        late_game_threshold = math.floor(0.75 * self.n_rounds)
        if current_round >= late_game_threshold:
            self.cooperation_threshold = 0.75
            if random.random() < 0.2:
                return Action.D
        if history.round_number > 0:
            my_total_payoff = np.sum(history.my_payoffs)
            opponent_avg_payoffs = np.mean(np.sum(history.opponent_payoffs, axis=0))
            if my_total_payoff > opponent_avg_payoffs:
                rank_factor = 0.8
            else:
                rank_factor = 1.0
            adjusted_threshold = self.cooperation_threshold * rank_factor
        else:
            adjusted_threshold = self.cooperation_threshold
        if history.round_number > 0:
            last_round_cooperators = np.sum(history.opponent_actions[-1, :])
            cooperation_rate = last_round_cooperators / (self.n_players - 1)
            if cooperation_rate < adjusted_threshold:
                return Action.D
            predicted_cooperators = last_round_cooperators + 1
            my_coop_payoff = self.k / self.n_players * predicted_cooperators
            if history.round_number > 0:
                all_payoffs = np.concatenate([history.my_payoffs, history.opponent_payoffs.flatten()])
                current_avg_payoff = np.mean(all_payoffs)
            else:
                current_avg_payoff = 1.0
            if my_coop_payoff <= current_avg_payoff:
                return Action.D
            strategic_value = self.k / self.n_players * predicted_cooperators
            if strategic_value <= 1.2:
                return Action.D
            if self.k > self.n_players - 1:
                if last_round_cooperators < self.n_players - 2:
                    return Action.D
            return Action.C
        return Action.D

class Strategy_AGGRESSIVE_24(BaseStrategy):
    """
    AGGRESSIVE EXPLOITATION STRATEGY: "PREDATOR"
    
    Operates on aggressive exploitation principles - maximizing personal payoffs by strategically 
    defecting while maintaining just enough cooperation from others to benefit from the public good.
    Always defects in opening rounds and endgame, with strategic cooperation only when necessary
    to rebuild exploitation opportunities.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.threshold_high = max(0.6, self.k / self.n_players + 0.2)
        self.threshold_low = max(0.3, self.k / self.n_players - 0.1)
        self.recent_window = 3

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        if current_round == 1:
            return Action.D
        endgame_threshold = math.ceil(0.8 * self.n_rounds)
        if current_round >= endgame_threshold:
            return Action.D
        return self._calculate_exploitation_move(history)

    def _calculate_exploitation_move(self, history: PlayerHistory) -> Action:
        current_round = history.round_number
        cooperation_rate = self._get_others_cooperation_rate(history)
        my_recent_defections = self._count_my_recent_defections(history)
        punishment_detected = self._detect_punishment_pattern(history)
        if cooperation_rate >= self.threshold_high:
            return Action.D
        elif cooperation_rate >= self.threshold_low and my_recent_defections < 3:
            return Action.D
        elif cooperation_rate < self.threshold_low and self.n_rounds - current_round > 3:
            if punishment_detected:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _get_others_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate of other players in recent rounds."""
        current_round = history.round_number
        window_start = max(0, current_round - self.recent_window)
        if window_start >= current_round:
            return 0.0
        recent_actions = history.opponent_actions[window_start:current_round, :]
        total_actions = recent_actions.size
        if total_actions == 0:
            return 0.0
        cooperations = np.sum(recent_actions)
        return float(cooperations) / float(total_actions)

    def _count_my_recent_defections(self, history: PlayerHistory) -> int:
        """Count my defections in the recent window."""
        current_round = history.round_number
        window_start = max(0, current_round - self.recent_window)
        if window_start >= current_round:
            return 0
        recent_my_actions = history.my_actions[window_start:current_round]
        return int(np.sum(~recent_my_actions))

    def _detect_punishment_pattern(self, history: PlayerHistory) -> bool:
        """Detect if others are punishing (cooperation rate < 25% for 2+ rounds)."""
        current_round = history.round_number
        if current_round < 2:
            return False
        window_start = max(0, current_round - 2)
        recent_actions = history.opponent_actions[window_start:current_round, :]
        if recent_actions.size == 0:
            return False
        cooperation_rate = float(np.sum(recent_actions)) / float(recent_actions.size)
        return cooperation_rate < 0.25

class Strategy_AGGRESSIVE_25(BaseStrategy):
    """
    Aggressive Exploitative Strategy: "The Opportunistic Predator"
    
    This strategy maximizes personal payoff by strategically free-riding on others' cooperation
    while contributing minimally. It defects in round 1, uses exploitation thresholds, and
    becomes increasingly aggressive toward the end of the game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.exploitation_threshold = max(1, math.floor(self.n * self.k / (2 * self.n - self.k)))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if history is None or round_num == 0:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        early_phase_end = math.floor(self.r / 3)
        mid_phase_end = math.floor(2 * self.r / 3)
        if round_num < early_phase_end:
            if last_round_cooperators >= self.n - 1:
                return Action.C
            return Action.D
        elif round_num < mid_phase_end:
            if last_round_cooperators >= self.n - 2:
                expected_payoff_if_cooperate = 0 + self.k / self.n * (last_round_cooperators + 1)
                expected_payoff_if_defect = 1 + self.k / self.n * last_round_cooperators
                cooperation_trending_up = False
                if len(history.my_actions) >= 3:
                    recent_cooperation_rates = []
                    for i in range(min(3, len(history.my_actions))):
                        round_idx = -(i + 1)
                        round_cooperators = sum(history.opponent_actions[round_idx, :])
                        if history.my_actions[round_idx]:
                            round_cooperators += 1
                        recent_cooperation_rates.append(round_cooperators / self.n)
                    if len(recent_cooperation_rates) >= 3:
                        cooperation_trending_up = recent_cooperation_rates[0] > recent_cooperation_rates[-1]
                if expected_payoff_if_cooperate > expected_payoff_if_defect + 0.1 and cooperation_trending_up:
                    return Action.C
            return Action.D
        else:
            return Action.D

class Strategy_AGGRESSIVE_26(BaseStrategy):
    """
    Aggressive Exploiter Strategy: Ruthlessly maximizes personal payoff through strategic 
    free-riding and exploitation of cooperative behavior, with minimal tactical cooperation 
    only to avoid devastating retaliation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round <= 2:
            return Action.D
        if current_round >= self.r - 2:
            return Action.D
        return self._strategic_manipulation_decision(history)

    def _strategic_manipulation_decision(self, history: PlayerHistory) -> Action:
        declining_returns = self._check_declining_returns(history)
        punishment_detected = self._check_punishment_detection(history)
        sufficient_rounds = self._check_sufficient_rounds(history)
        recovery_potential = self._check_recovery_potential(history)
        if declining_returns and punishment_detected and sufficient_rounds and recovery_potential:
            return Action.C
        if self._should_return_to_defection(history):
            return Action.D
        return Action.D

    def _check_declining_returns(self, history: PlayerHistory) -> bool:
        """Check if average payoff over last 3 rounds < 1.2"""
        if len(history.my_payoffs) < 3:
            return False
        recent_payoffs = history.my_payoffs[-3:]
        return np.mean(recent_payoffs) < 1.2

    def _check_punishment_detection(self, history: PlayerHistory) -> bool:
        """Check if at least 50% of players defected in previous round"""
        if len(history.opponent_actions) == 0:
            return False
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        total_opponents = len(history.opponent_actions[-1, :])
        defection_rate = (total_opponents - last_round_cooperators) / total_opponents
        return defection_rate >= 0.5

    def _check_sufficient_rounds(self, history: PlayerHistory) -> bool:
        """Check if more than 3 rounds remaining"""
        current_round = len(history.my_actions)
        return self.r - current_round > 3

    def _check_recovery_potential(self, history: PlayerHistory) -> bool:
        """Check if at least 30% of players cooperated in any of last 3 rounds"""
        rounds_to_check = min(3, len(history.opponent_actions))
        if rounds_to_check == 0:
            return False
        for i in range(rounds_to_check):
            round_idx = -(i + 1)
            cooperators = np.sum(history.opponent_actions[round_idx, :])
            total_opponents = len(history.opponent_actions[round_idx, :])
            cooperation_rate = cooperators / total_opponents
            if cooperation_rate >= 0.3:
                return True
        return False

    def _should_return_to_defection(self, history: PlayerHistory) -> bool:
        """Check conditions for immediate return to defection"""
        if len(history.my_payoffs) > 0 and history.my_payoffs[-1] >= 1.5:
            return True
        if len(history.opponent_actions) > 0:
            total_cooperations = np.sum(history.opponent_actions)
            total_decisions = history.opponent_actions.size
            if total_cooperations / total_decisions < 0.25:
                return True
        if self._check_punishment_breakdown(history):
            return True
        return False

    def _check_punishment_breakdown(self, history: PlayerHistory) -> bool:
        """Check if coordinated punishment is breaking down"""
        if len(history.opponent_actions) < 2:
            return False
        last_round_defectors = len(history.opponent_actions[-1, :]) - np.sum(history.opponent_actions[-1, :])
        second_last_defectors = len(history.opponent_actions[-2, :]) - np.sum(history.opponent_actions[-2, :])
        total_opponents = len(history.opponent_actions[-1, :])
        if last_round_defectors < second_last_defectors and last_round_defectors < 0.5 * total_opponents:
            return True
        return False

class Strategy_AGGRESSIVE_27(BaseStrategy):
    """
    AGGRESSIVE EXPLOITATION STRATEGY: "PREDATOR"
    
    Maximizes personal payoff through calculated aggression. Always defects in first and last rounds,
    exploits cooperative environments when profitable, and punishes betrayal with sustained defection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.punishment_rounds_left = 0
        self.permanent_defection_mode = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        current_round = state.round_number
        if current_round >= r - 2:
            return Action.D
        last_round_idx = history.round_number - 1
        cooperators_last_round = int(np.sum(history.opponent_actions[last_round_idx, :]))
        my_last_action = history.my_actions[last_round_idx]
        my_last_payoff = history.my_payoffs[last_round_idx]
        if my_last_action and np.any(~history.opponent_actions[last_round_idx, :]):
            self.punishment_rounds_left = 2
        if cooperators_last_round < n / 3:
            self.permanent_defection_mode = True
        if self.punishment_rounds_left > 0:
            self.punishment_rounds_left -= 1
            return Action.D
        if self.permanent_defection_mode:
            return Action.D
        majority_threshold = math.ceil((n + 1) / 2)
        if cooperators_last_round >= majority_threshold and my_last_payoff > 1.5 and (current_round <= 0.7 * r):
            return Action.C
        return Action.D

class Strategy_AGGRESSIVE_28(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Predatory Defector"
    
    This strategy maximizes individual payoffs through aggressive defection while
    only cooperating when it can extract disproportionate value from others' cooperation.
    Operates on principles of exploitation maximization and risk minimization.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.punishment_rounds_left = 0
        self.cooperation_threshold = math.ceil(self.n * self.k / (self.n + self.k))
        if self.n <= 3:
            self.cooperation_threshold = self.n - 1
        elif self.n > 10:
            self.cooperation_threshold = math.ceil(self.n * self.k / (self.n + 1))
        if self.k < 1.5:
            self.cooperation_threshold = max(self.cooperation_threshold, math.ceil(2 * self.n / 3))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        round_num = state.round_number
        if round_num == self.r:
            return Action.D
        total_cooperators_last_round = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            total_cooperators_last_round += 1
        if self.punishment_rounds_left > 0:
            self.punishment_rounds_left -= 1
            return Action.D
        if len(history.my_actions) >= 2:
            prev_cooperators = sum(history.opponent_actions[-2, :])
            if history.my_actions[-2]:
                prev_cooperators += 1
            if prev_cooperators > 0 and total_cooperators_last_round < prev_cooperators * 0.5:
                self.punishment_rounds_left = 1
                return Action.D
        if round_num >= max(2, self.r - 3):
            late_game_threshold = math.ceil(3 * self.n / 4)
            if total_cooperators_last_round < late_game_threshold:
                return Action.D
        my_profit_if_defected = 1 + self.k / self.n * total_cooperators_last_round
        my_profit_if_cooperated = 0 + self.k / self.n * (total_cooperators_last_round + 1)
        if my_profit_if_defected > my_profit_if_cooperated:
            return Action.D
        if len(history.my_actions) >= 4:
            for player_idx in range(self.n - 1):
                player_cooperation_rate = sum(history.opponent_actions[:, player_idx]) / len(history.my_actions)
                if player_cooperation_rate > 0.75:
                    return Action.D
        if len(history.my_actions) >= 3:
            recent_cooperation = []
            for i in range(3):
                round_cooperators = sum(history.opponent_actions[-(i + 1), :])
                if history.my_actions[-(i + 1)]:
                    round_cooperators += 1
                recent_cooperation.append(round_cooperators)
            if max(recent_cooperation) - min(recent_cooperation) <= 1 and min(recent_cooperation) >= self.cooperation_threshold:
                if random.random() < 0.3:
                    return Action.D
        if self.k > self.n * 0.8 and len(history.my_actions) >= 2:
            cooperation_trend = []
            for i in range(min(3, len(history.my_actions))):
                round_cooperators = sum(history.opponent_actions[-(i + 1), :])
                if history.my_actions[-(i + 1)]:
                    round_cooperators += 1
                cooperation_trend.append(round_cooperators)
            if len(cooperation_trend) >= 2 and all((cooperation_trend[i] >= cooperation_trend[i + 1] for i in range(len(cooperation_trend) - 1))):
                if total_cooperators_last_round >= self.cooperation_threshold:
                    return Action.C
        if total_cooperators_last_round >= self.cooperation_threshold and total_cooperators_last_round >= self.n / 2:
            return Action.C
        return Action.D

class Strategy_AGGRESSIVE_29(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Opportunistic Punisher"
    
    This strategy aggressively exploits cooperative opponents while swiftly punishing defectors.
    It maximizes personal payoffs by free-riding on cooperation when possible, but maintains
    credible punishment threats to deter exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.punishment_rounds_remaining = 0
        self.exploitation_threshold = 0.5
        self.opponent_types = {}

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number + 1
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        if current_round == r:
            return Action.D
        if self.punishment_rounds_remaining > 0:
            self.punishment_rounds_remaining -= 1
            return Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        coop_rate = last_round_cooperators / n
        if current_round <= 4:
            if coop_rate >= 0.8:
                return Action.D
            else:
                return Action.D
        if current_round > r - 3:
            if current_round == r - 2:
                if last_round_cooperators == n:
                    return Action.C
                return Action.D
            elif current_round == r - 1:
                my_avg_payoff = np.mean(history.my_payoffs)
                if my_avg_payoff < 1.5 and coop_rate >= 0.9:
                    return Action.C
                return Action.D
        my_last_payoff = history.my_payoffs[-1]
        exploitation_threshold_payoff = k / n * (n - 1)
        if my_last_payoff < exploitation_threshold_payoff:
            self.punishment_rounds_remaining = 2
            return Action.D
        if coop_rate >= self.exploitation_threshold:
            return Action.D
        if coop_rate < 0.5:
            my_recent_exploitation = 0
            rounds_to_check = min(3, len(history.my_actions))
            for i in range(rounds_to_check):
                round_idx = -(i + 1)
                if round_idx < -len(history.my_actions):
                    break
                my_action = history.my_actions[round_idx]
                others_cooperated = sum(history.opponent_actions[round_idx, :])
                if not my_action and others_cooperated > 0:
                    my_recent_exploitation += 1
            if my_recent_exploitation >= 2:
                return Action.C
        self._update_opponent_types(history)
        if self._has_suckers(history):
            return Action.D
        self._adjust_threshold(history)
        if self._detect_coordination(history):
            return Action.D
        if len(history.my_payoffs) >= 10:
            my_avg_payoff = np.mean(history.my_payoffs[-10:])
            if my_avg_payoff < 1.2:
                return Action.D
        return Action.D

    def _update_opponent_types(self, history):
        """Update opponent classification based on recent behavior"""
        if len(history.opponent_actions) < 5:
            return
        n_opponents = history.opponent_actions.shape[1]
        for i in range(n_opponents):
            recent_actions = history.opponent_actions[-5:, i]
            coop_rate = np.mean(recent_actions)
            if coop_rate > 0.7:
                self.opponent_types[i] = 'Sucker'
            elif coop_rate < 0.3:
                self.opponent_types[i] = 'Hawk'
            else:
                self.opponent_types[i] = 'Conditional'

    def _has_suckers(self, history):
        """Check if there are suckers to exploit"""
        return any((opp_type == 'Sucker' for opp_type in self.opponent_types.values()))

    def _adjust_threshold(self, history):
        """Dynamically adjust exploitation threshold based on performance"""
        if len(history.my_payoffs) >= 5:
            recent_avg = np.mean(history.my_payoffs[-5:])
            if recent_avg < 1.2:
                self.exploitation_threshold = max(0.1, self.exploitation_threshold - 0.1)
            elif recent_avg > 1.8:
                self.exploitation_threshold = max(0.1, self.exploitation_threshold - 0.1)

    def _detect_coordination(self, history):
        """Detect if opponents are trying to coordinate"""
        if len(history.opponent_actions) < 4:
            return False
        recent_actions = history.opponent_actions[-4:, :]
        for round_idx in range(len(recent_actions)):
            round_cooperators = sum(recent_actions[round_idx, :])
            if round_cooperators == 0 or round_cooperators == recent_actions.shape[1]:
                return True
        return False

class Strategy_AGGRESSIVE_30(BaseStrategy):
    """
    Aggressive Conditional Defector Strategy - A ruthless opportunistic approach that maximizes
    personal payoff by exploiting early cooperators, only cooperating when mathematically
    advantageous, and aggressively punishing groups that don't adequately reward participation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.punishment_timer = 0
        self.cooperation_threshold = math.ceil(self.n * self.k / (self.k + 1))
        self.late_round_cutoff = self.r - math.ceil(self.r / 4)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if history is None:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        prev_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            prev_cooperators += 1
        if history.my_actions[-1] and prev_cooperators < math.ceil(self.n / 2):
            self.punishment_timer = 2
        if self.punishment_timer > 0:
            self.punishment_timer -= 1
            return Action.D
        cooperation_stable = True
        if len(history.my_actions) >= 2:
            prev_prev_cooperators = sum(history.opponent_actions[-2, :])
            if history.my_actions[-2]:
                prev_prev_cooperators += 1
            cooperation_stable = prev_cooperators >= prev_prev_cooperators
        sufficient_cooperation = prev_cooperators >= self.cooperation_threshold
        not_too_late = current_round < self.late_round_cutoff
        if sufficient_cooperation and cooperation_stable and not_too_late:
            return Action.C
        return Action.D

class Strategy_AGGRESSIVE_31(BaseStrategy):
    """
    Aggressive Predatory Strategy: "The Exploiter"
    
    This strategy operates on maximum exploitation with calculated aggression.
    It seeks to identify and ruthlessly exploit cooperative players while 
    protecting itself from being exploited by others.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.base_cooperation_threshold = 0.6
        self.exploitable_threshold = 0.5
        self.punishment_defection_threshold = 0.5
        self.consecutive_cooperation_limit = 2
        if self.n_players <= 4:
            self.cooperation_threshold_adjustment = 0.2
        elif self.n_players >= 8:
            self.cooperation_threshold_adjustment = 0.0
        else:
            self.cooperation_threshold_adjustment = 0.1
        if self.k >= self.n_players * 0.8:
            self.high_k_mode = True
            self.cascade_threshold = 0.75
        else:
            self.high_k_mode = False
            self.low_k_threshold = 0.9
        self.punishment_rounds_remaining = 0
        self.last_cooperation_rounds = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        round_num = history.round_number
        if round_num < 3:
            return Action.D
        if self.punishment_rounds_remaining > 0:
            self.punishment_rounds_remaining -= 1
            return Action.D
        if round_num >= self.n_rounds - 2:
            if round_num == self.n_rounds - 1:
                return Action.D
            else:
                if self._should_cooperate_endgame(history):
                    return Action.C
                return Action.D
        return self._exploitation_phase_decision(history)

    def _exploitation_phase_decision(self, history: PlayerHistory) -> Action:
        """Main decision logic for exploitation phase."""
        if self._detect_retaliation(history):
            self.punishment_rounds_remaining = 2
            return Action.D
        if self._should_enter_cooperation_trap(history):
            self.last_cooperation_rounds.append(history.round_number)
            if len(self.last_cooperation_rounds) > self.consecutive_cooperation_limit:
                self.last_cooperation_rounds.pop(0)
            return Action.C
        return Action.D

    def _should_enter_cooperation_trap(self, history: PlayerHistory) -> Action:
        """Check if all cooperation trap conditions are met."""
        if len(history.opponent_actions) == 0:
            return False
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        cooperation_rate = last_round_cooperators / (self.n_players - 1)
        threshold = self.base_cooperation_threshold + self.cooperation_threshold_adjustment
        if cooperation_rate < threshold:
            return False
        total_with_my_cooperation = last_round_cooperators + 1
        if total_with_my_cooperation / self.n_players < 0.7:
            return False
        expected_payoff = self._calculate_expected_payoff(total_with_my_cooperation)
        if expected_payoff < 1.2:
            return False
        if self._cooperated_recently():
            return False
        return True

    def _calculate_expected_payoff(self, total_cooperators: int) -> float:
        """Calculate expected payoff from cooperating given total cooperators."""
        private_payoff = 0
        public_payoff = self.k / self.n_players * total_cooperators
        return private_payoff + public_payoff

    def _cooperated_recently(self) -> bool:
        """Check if cooperated in last 2 consecutive rounds."""
        if len(self.last_cooperation_rounds) < 2:
            return False
        return self.last_cooperation_rounds[-1] - self.last_cooperation_rounds[-2] == 1

    def _detect_retaliation(self, history: PlayerHistory) -> bool:
        """Detect if opponents are retaliating against my defection."""
        if len(history.opponent_actions) < 2:
            return False
        if len(history.my_actions) > 0 and (not history.my_actions[-1]):
            current_defectors = np.sum(history.opponent_actions[-1, :] == 0)
            defection_rate = current_defectors / (self.n_players - 1)
            return defection_rate > self.punishment_defection_threshold
        return False

    def _should_cooperate_endgame(self, history: PlayerHistory) -> bool:
        """Decide whether to cooperate in second-to-last round."""
        my_defection_rate = np.sum(history.my_actions == 0) / len(history.my_actions)
        if my_defection_rate < 0.7:
            return False
        recent_cooperation_trend = self._estimate_cooperation_trend(history)
        if recent_cooperation_trend > 0.6:
            expected_final_round_cooperators = min(self.n_players - 1, int((self.n_players - 1) * recent_cooperation_trend * 1.5))
            expected_payoff = self._calculate_expected_payoff(expected_final_round_cooperators + 1)
            return expected_payoff > 2.0
        return False

    def _estimate_cooperation_trend(self, history: PlayerHistory) -> float:
        """Estimate recent cooperation trend among opponents."""
        if len(history.opponent_actions) < 3:
            return 0.0
        recent_rounds = min(3, len(history.opponent_actions))
        recent_cooperation_rates = []
        for i in range(recent_rounds):
            round_cooperators = np.sum(history.opponent_actions[-(i + 1), :])
            rate = round_cooperators / (self.n_players - 1)
            recent_cooperation_rates.append(rate)
        return np.mean(recent_cooperation_rates)

class Strategy_AGGRESSIVE_32(BaseStrategy):
    """
    Aggressive Exploiter Strategy - maximizes personal payoffs by ruthlessly exploiting
    cooperative opponents while minimizing vulnerability to being exploited.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.retaliation_dampening_active = False
        self.retaliation_dampening_countdown = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number + 1
        if current_round == r:
            return Action.D
        if self.retaliation_dampening_countdown > 0:
            self.retaliation_dampening_countdown -= 1
            return Action.C
        last_round_idx = history.round_number - 1
        my_last_action = history.my_actions[last_round_idx]
        opponent_cooperators = sum(history.opponent_actions[last_round_idx, :])
        total_cooperators = opponent_cooperators + (1 if my_last_action else 0)
        cooperation_rate = total_cooperators / n
        base_threshold = (n - 1) / (2 * n)
        if k > n / 2:
            exploitation_threshold = (n - 2) / (2 * n)
        else:
            exploitation_threshold = base_threshold
        endgame_threshold = math.ceil(0.2 * r)
        if r - current_round < endgame_threshold:
            exploitation_threshold = (n - 2) / (2 * n)
        if self._is_momentum_exploitation_opportunity(history):
            return Action.D
        if self._needs_retaliation_dampening(history, current_round):
            self.retaliation_dampening_active = True
            self.retaliation_dampening_countdown = 0
            return Action.C
        if self._unanimous_defection_detected(history):
            return Action.C
        if self._needs_performance_adjustment(history, current_round):
            if random.random() < 0.2:
                return Action.C
        if cooperation_rate >= exploitation_threshold:
            return Action.D
        else:
            return Action.C

    def _is_momentum_exploitation_opportunity(self, history: PlayerHistory) -> bool:
        """Check if cooperation rate has been increasing for 2+ consecutive rounds."""
        if history.round_number < 3:
            return False
        n = self.game_description.n_players
        cooperation_rates = []
        for i in range(max(0, history.round_number - 3), history.round_number):
            my_action = history.my_actions[i]
            opponent_cooperators = sum(history.opponent_actions[i, :])
            total_cooperators = opponent_cooperators + (1 if my_action else 0)
            cooperation_rates.append(total_cooperators / n)
        if len(cooperation_rates) >= 3:
            return cooperation_rates[-1] > cooperation_rates[-2] > cooperation_rates[-3]
        elif len(cooperation_rates) >= 2:
            return cooperation_rates[-1] > cooperation_rates[-2]
        return False

    def _needs_retaliation_dampening(self, history: PlayerHistory, current_round: int) -> bool:
        """Check if we need retaliation dampening based on being sole defector."""
        if history.round_number < 2:
            return False
        if self.game_description.n_rounds <= 5:
            return False
        threshold = 0.7 if self.game_description.n_players > 6 else 0.6
        only_defector_count = 0
        for i in range(history.round_number):
            my_action = history.my_actions[i]
            opponent_cooperators = sum(history.opponent_actions[i, :])
            if not my_action and opponent_cooperators == self.game_description.n_players - 1:
                only_defector_count += 1
        exploitation_ratio = only_defector_count / history.round_number
        return exploitation_ratio > threshold

    def _unanimous_defection_detected(self, history: PlayerHistory) -> bool:
        """Check if all players defected for 2+ consecutive rounds."""
        if history.round_number < 2:
            return False
        n = self.game_description.n_players
        consecutive_all_defect = 0
        for i in range(history.round_number - 1, -1, -1):
            my_action = history.my_actions[i]
            opponent_cooperators = sum(history.opponent_actions[i, :])
            total_cooperators = opponent_cooperators + (1 if my_action else 0)
            if total_cooperators == 0:
                consecutive_all_defect += 1
            else:
                break
        return consecutive_all_defect >= 2

    def _needs_performance_adjustment(self, history: PlayerHistory, current_round: int) -> bool:
        """Check if personal performance adjustment is needed."""
        if history.round_number < 3:
            return False
        k = self.game_description.k
        n = self.game_description.n_players
        performance_threshold = 1 + k / (2 * n)
        recent_payoffs = history.my_payoffs[-3:]
        avg_payoff = np.mean(recent_payoffs)
        return avg_payoff < performance_threshold

class Strategy_AGGRESSIVE_33(BaseStrategy):
    """
    AGGRESSIVE EXPLOITATION STRATEGY: "PREDATOR"
    
    Treats the public goods game as zero-sum competition, maximizing personal payoff
    through aggressive exploitation of cooperative behavior while minimizing contributions.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.sucker_threshold = self.k / self.n
        self.base_exploitation_threshold = max(0.3, self.k / self.n - 0.1)
        self.aggression_multiplier = (self.n - self.k) / self.n
        self.scorched_earth_mode = False
        self.scorched_earth_rounds_left = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if history is None:
            return Action.D
        self._update_scorched_earth_mode(history)
        if current_round >= self.r - 2:
            return Action.D
        if self.scorched_earth_mode:
            return Action.D
        if self.n <= 4:
            return self._small_group_strategy(history)
        if self.r <= 5:
            return self._short_game_strategy(history)
        if self.r > 10 and self._should_reputation_break(current_round):
            return Action.D
        return self._exploitation_phase_strategy(history)

    def _update_scorched_earth_mode(self, history: PlayerHistory):
        """Update scorched earth mode based on recent payoffs."""
        if self.scorched_earth_mode:
            self.scorched_earth_rounds_left -= 1
            if self.scorched_earth_rounds_left <= 0:
                self.scorched_earth_mode = False
            return
        if len(history.my_payoffs) >= 2:
            recent_payoffs = history.my_payoffs[-2:]
            if sum(recent_payoffs) < 2 * self.sucker_threshold:
                self.scorched_earth_mode = True
                rounds_remaining = self.r - len(history.my_payoffs)
                self.scorched_earth_rounds_left = min(3, rounds_remaining)

    def _small_group_strategy(self, history: PlayerHistory):
        """More aggressive strategy for small groups."""
        if len(history.my_payoffs) >= 1:
            if history.my_payoffs[-1] < self.sucker_threshold:
                self.scorched_earth_mode = True
                rounds_remaining = self.r - len(history.my_payoffs)
                self.scorched_earth_rounds_left = min(3, rounds_remaining)
                return Action.D
        cooperation_rate = self._get_cooperation_rate(history)
        threshold = self.base_exploitation_threshold + 0.1
        return Action.D

    def _short_game_strategy(self, history: PlayerHistory):
        """Strategy for short games - mostly defect."""
        cooperation_rate = self._get_cooperation_rate(history)
        if len(history.my_actions) == 1 and cooperation_rate > 0.8:
            return Action.C
        return Action.D

    def _should_reputation_break(self, current_round):
        """Determine if we should have a reputation break in long games."""
        cycle_position = current_round % 5
        return cycle_position in [3, 4]

    def _exploitation_phase_strategy(self, history: PlayerHistory):
        """Main exploitation phase strategy."""
        cooperation_rate = self._get_cooperation_rate(history)
        if self.k > self.n - 1:
            exploitation_threshold = 0.5
        else:
            exploitation_threshold = self.base_exploitation_threshold * (1 - self.aggression_multiplier)
        return Action.D

    def _get_cooperation_rate(self, history: PlayerHistory):
        """Calculate cooperation rate of opponents in the last round."""
        if len(history.opponent_actions) == 0:
            return 0.0
        last_round_actions = history.opponent_actions[-1, :]
        cooperators = np.sum(last_round_actions)
        return cooperators / (self.n - 1)

class Strategy_AGGRESSIVE_34(BaseStrategy):
    """
    Opportunistic Predator: An aggressive exploitation strategy that maximizes free-riding
    while strategically investing minimal cooperation only when necessary for future exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.exploitation_threshold = max(0.3, (self.k - 1) / self.n + 0.1)
        self.punishment_threshold = 0.15
        self.consecutive_low_cooperation = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        total_rounds = self.r
        rounds_remaining = total_rounds - current_round
        if rounds_remaining <= max(3, 0.2 * total_rounds):
            return Action.D
        last_round_coop_rate = self._get_cooperation_rate(history, -1)
        if last_round_coop_rate <= 0.1:
            self.consecutive_low_cooperation += 1
        else:
            self.consecutive_low_cooperation = 0
        if self.consecutive_low_cooperation >= 3:
            self.consecutive_low_cooperation = 0
            return Action.C
        if last_round_coop_rate > 0.7:
            return Action.D
        if last_round_coop_rate >= self.exploitation_threshold:
            return Action.D
        if self._recently_cooperated(history) and self._cooperation_declining(history):
            return Action.D
        if last_round_coop_rate < self.punishment_threshold:
            return Action.C
        if self._detect_growing_cooperation(history):
            return Action.D
        return Action.D

    def _get_cooperation_rate(self, history: PlayerHistory, round_index: int) -> float:
        """Get cooperation rate for a specific round."""
        if round_index >= 0 or abs(round_index) > len(history.opponent_actions):
            return 0.0
        opponent_cooperators = np.sum(history.opponent_actions[round_index, :])
        my_action = history.my_actions[round_index]
        total_cooperators = opponent_cooperators + (1 if my_action else 0)
        return total_cooperators / self.n

    def _recently_cooperated(self, history: PlayerHistory) -> bool:
        """Check if I cooperated in the last 2 rounds."""
        if len(history.my_actions) < 2:
            return bool(history.my_actions[-1]) if len(history.my_actions) > 0 else False
        return bool(history.my_actions[-1]) or bool(history.my_actions[-2])

    def _cooperation_declining(self, history: PlayerHistory) -> bool:
        """Check if cooperation rate is declining over recent rounds."""
        if len(history.opponent_actions) < 2:
            return False
        recent_rate = self._get_cooperation_rate(history, -1)
        previous_rate = self._get_cooperation_rate(history, -2)
        return recent_rate < previous_rate

    def _detect_growing_cooperation(self, history: PlayerHistory) -> bool:
        """Detect if cooperation is growing and worth exploiting."""
        if len(history.opponent_actions) < 3:
            return False
        weights = [0.5, 0.3, 0.2]
        recent_rates = []
        for i in range(3):
            rate = self._get_cooperation_rate(history, -(i + 1))
            recent_rates.append(rate)
        weighted_recent = sum((w * r for w, r in zip(weights, recent_rates)))
        if len(history.opponent_actions) >= 4:
            earlier_rate = self._get_cooperation_rate(history, -4)
        else:
            earlier_rate = 0.0
        return weighted_recent > earlier_rate and weighted_recent > 0.4

class Strategy_AGGRESSIVE_35(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Predator"
    
    Operates on maximum exploitation with minimal risk, free-riding on others' 
    cooperation while using aggressive punishments to maintain dominance.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.tactical_coop_used = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number + 1
        if current_round <= 3:
            return Action.D
        if current_round >= self.r - 1:
            if current_round == self.r:
                return Action.D
            else:
                my_cumulative = np.sum(history.my_payoffs)
                avg_opponent_cumulative = np.mean(np.sum(history.opponent_payoffs, axis=0))
                if my_cumulative > avg_opponent_cumulative * 1.1:
                    return Action.D
                elif my_cumulative < avg_opponent_cumulative * 0.85:
                    return Action.C
                else:
                    return Action.D
        prev_round_cooperators = np.sum(history.opponent_actions[-1, :])
        cooperation_rate = prev_round_cooperators / self.n
        declining_cooperation = False
        if len(history.opponent_actions) >= 2:
            prev2_cooperators = np.sum(history.opponent_actions[-2, :])
            prev2_rate = prev2_cooperators / self.n
            if len(history.opponent_actions) >= 3:
                prev3_cooperators = np.sum(history.opponent_actions[-3, :])
                prev3_rate = prev3_cooperators / self.n
                declining_cooperation = prev3_rate > prev2_rate > cooperation_rate
            else:
                declining_cooperation = prev2_rate > cooperation_rate
        if declining_cooperation and cooperation_rate < 0.3 and (not self.tactical_coop_used):
            self.tactical_coop_used = True
            return Action.C
        return Action.D

class Strategy_AGGRESSIVE_36(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "PREDATOR"
    
    A predatory exploiter that maximizes personal gain by ruthlessly capitalizing on 
    others' cooperation while minimizing its own contributions. Uses adaptive exploitation
    with cooperation baiting and endgame acceleration.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.consecutive_defections = 1
            return Action.D
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == r - 1:
            return Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        cooperation_rate = last_round_cooperators / n
        my_last_action = 1 if history.my_actions[-1] else 0
        total_cooperators_last = last_round_cooperators + my_last_action
        my_last_payoff = 1 - my_last_action + k / n * total_cooperators_last
        average_expected_payoff = 1 + k / n * cooperation_rate * n
        if current_round >= r - 2:
            if current_round == r - 2 and cooperation_rate > 0.7:
                total_rounds_so_far = len(history.my_payoffs)
                my_average = sum(history.my_payoffs) / total_rounds_so_far if total_rounds_so_far > 0 else 1
                if my_average < 1.5:
                    self.consecutive_defections = 0
                    return Action.C
            self.consecutive_defections += 1
            return Action.D
        if self.consecutive_defections >= 3 and cooperation_rate > 0.4 and (current_round < r - 3):
            self.consecutive_defections = 0
            return Action.C
        if cooperation_rate >= 0.5:
            self.consecutive_defections += 1
            return Action.D
        elif cooperation_rate >= 0.3:
            if my_last_payoff < average_expected_payoff:
                self.consecutive_defections = 0
                return Action.C
            else:
                self.consecutive_defections += 1
                return Action.D
        else:
            self.consecutive_defections += 1
            return Action.D

class Strategy_AGGRESSIVE_37(BaseStrategy):
    """
    PREDATOR Strategy: An aggressive strategy that exploits cooperative players while punishing defectors.
    Only cooperates when mathematically profitable and always defects in endgame.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.profitability_threshold = math.ceil(self.n / self.k)
        self.final_rounds_start = self.r - math.ceil(self.r * 0.2)
        self.punishment_rounds_left = 0
        self.punishment_boost = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round >= self.final_rounds_start:
            return Action.D
        expected_cooperators = self._predict_cooperators(history)
        if self.punishment_rounds_left > 0:
            self.punishment_rounds_left -= 1
            if random.random() < 0.7 + self.punishment_boost:
                return Action.D
        if expected_cooperators < self.profitability_threshold:
            return Action.D
        group_momentum = self._calculate_group_momentum(history)
        recent_rounds = min(3, len(history.my_actions))
        if recent_rounds > 0:
            our_recent_defection_rate = 1.0 - np.mean(history.my_actions[-recent_rounds:])
        else:
            our_recent_defection_rate = 0.0
        if group_momentum > 0 and our_recent_defection_rate < 0.8:
            self._check_punishment_trigger(history)
            return Action.C
        else:
            return Action.D

    def _predict_cooperators(self, history: PlayerHistory) -> float:
        """Predict number of cooperators based on opponent behavior patterns."""
        expected_cooperators = 0.0
        n_rounds = len(history.my_actions)
        for player_idx in range(self.n - 1):
            cooperation_rate = np.mean(history.opponent_actions[:, player_idx])
            recent_rounds = min(3, n_rounds)
            if recent_rounds > 0:
                recent_trend = np.mean(history.opponent_actions[-recent_rounds:, player_idx])
            else:
                recent_trend = cooperation_rate
            if recent_trend > 0.6:
                expected_cooperators += 0.8
            elif recent_trend > 0.3:
                expected_cooperators += 0.4
            else:
                expected_cooperators += 0.1
        return expected_cooperators

    def _calculate_group_momentum(self, history: PlayerHistory) -> float:
        """Calculate whether cooperation is increasing or decreasing in the group."""
        n_rounds = len(history.my_actions)
        if n_rounds < 2:
            return 0.0
        split_point = max(1, n_rounds // 2)
        early_cooperation = np.mean(history.opponent_actions[:split_point, :])
        recent_cooperation = np.mean(history.opponent_actions[split_point:, :])
        return recent_cooperation - early_cooperation

    def _check_punishment_trigger(self, history: PlayerHistory) -> None:
        """Check if we should punish players for not cooperating when expected."""
        if len(history.my_actions) < 2:
            return
        if not history.my_actions[-1]:
            return
        actual_cooperators = np.sum(history.opponent_actions[-1, :])
        last_round_history = PlayerHistory(my_actions=history.my_actions[:-1], my_payoffs=history.my_payoffs[:-1], opponent_actions=history.opponent_actions[:-1, :], opponent_payoffs=history.opponent_payoffs[:-1, :])
        expected_cooperators = self._predict_cooperators(last_round_history)
        if actual_cooperators < expected_cooperators - 0.5:
            self.punishment_rounds_left = 2
            self.punishment_boost = 0.3

class Strategy_AGGRESSIVE_38(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "PREDATOR"
    
    Treats cooperation as weakness to exploit. Uses a three-phase approach:
    1. Early Exploitation: Cooperate once to bait, then defect
    2. Adaptive Predation: Only cooperate when guaranteed maximum return
    3. Terminal Exploitation: Pure defection in final phase
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.C
        current_round = state.round_number
        phase_1_end = math.floor(self.r / 3)
        phase_2_end = math.floor(2 * self.r / 3)
        if current_round <= phase_1_end:
            return Action.D
        elif current_round <= phase_2_end:
            if len(history.opponent_actions) > 0:
                last_round_cooperators = sum(history.opponent_actions[-1, :])
                if history.my_actions[-1]:
                    total_last_cooperators = last_round_cooperators + 1
                else:
                    total_last_cooperators = last_round_cooperators
                if last_round_cooperators >= self.n - 1:
                    return Action.C
            return Action.D
        else:
            return Action.D

class Strategy_AGGRESSIVE_39(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "PREDATOR"
    
    Maximizes individual payoff through strategic exploitation while maintaining
    unpredictability. Defects aggressively in early and late rounds, with limited
    cooperation only when highly profitable in middle rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round < min(3, self.r // 4):
            return Action.D
        if current_round >= self.r - min(2, self.r // 5):
            return Action.D
        return self._adaptive_decision(history)

    def _adaptive_decision(self, history: PlayerHistory) -> Action:
        if len(history.opponent_actions) == 0:
            return Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        cooperation_rate = last_round_cooperators / self.n
        if cooperation_rate < 0.7:
            return Action.D
        predicted_cooperators = self._predict_cooperators(history)
        expected_benefit = self.k / self.n * (predicted_cooperators + 1)
        opportunity_cost = 1 + self.k / self.n * predicted_cooperators
        if expected_benefit > opportunity_cost + 0.2:
            if random.random() < 0.3:
                return Action.C
        return Action.D

    def _predict_cooperators(self, history: PlayerHistory) -> float:
        """Predict number of cooperators in next round based on recent behavior"""
        if len(history.opponent_actions) == 0:
            return 0.0
        rounds_to_consider = min(3, len(history.opponent_actions))
        predicted_cooperators = 0.0
        total_weight = 0.0
        for i in range(rounds_to_consider):
            round_idx = -(i + 1)
            weight = 1.0 / (i + 1)
            cooperators_in_round = sum(history.opponent_actions[round_idx, :])
            predicted_cooperators += weight * cooperators_in_round
            total_weight += weight
        if total_weight > 0:
            predicted_cooperators = predicted_cooperators / total_weight
        if self.k > self.n / 2:
            predicted_cooperators *= 1.1
        return min(predicted_cooperators, self.n)

class Strategy_AGGRESSIVE_40(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Predatory Defector"
    
    This strategy maximizes personal payoffs by exploiting cooperative behavior
    while minimizing own contributions. It aggressively punishes coordination
    attempts and adapts to squeeze maximum benefit from cooperative tendencies.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.exploitation_threshold = self.k / (2 * self.n)
        self.coordination_punishment_rounds = 0
        self.emergency_cooperation_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number + 1
        if current_round == self.r:
            return Action.D
        if self.coordination_punishment_rounds > 0:
            self.coordination_punishment_rounds -= 1
            return Action.D
        if self.emergency_cooperation_rounds > 0:
            self.emergency_cooperation_rounds -= 1
            return Action.C
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        cooperation_rate = last_round_cooperators / self.n
        if self._detect_coordination(history):
            self.coordination_punishment_rounds = 3
            return Action.D
        if current_round > 0.8 * self.r:
            if random.random() < 0.7:
                return Action.D
        if cooperation_rate > self.exploitation_threshold:
            return Action.D
        if cooperation_rate < 0.2 and self._payoffs_declining(history):
            self.emergency_cooperation_rounds = 2
            return Action.C
        if self._has_exploitable_players(history):
            return Action.D
        self._adjust_threshold(history)
        return Action.D

    def _detect_coordination(self, history: PlayerHistory) -> bool:
        """Detect if opponents show coordinated behavior patterns."""
        if history.round_number < 3:
            return False
        recent_actions = history.opponent_actions[-3:, :]
        for round_idx in range(recent_actions.shape[0] - 1):
            current_round = recent_actions[round_idx, :]
            next_round = recent_actions[round_idx + 1, :]
            switches = np.sum(current_round != next_round)
            if switches >= self.n * 0.7:
                return True
        return False

    def _payoffs_declining(self, history: PlayerHistory) -> bool:
        """Check if my recent payoffs are declining."""
        if history.round_number < 3:
            return False
        recent_payoffs = history.my_payoffs[-3:]
        if len(recent_payoffs) < 3:
            return False
        return recent_payoffs[-1] < recent_payoffs[0]

    def _has_exploitable_players(self, history: PlayerHistory) -> bool:
        """Check if any opponent has high cooperation frequency (>60%)."""
        if history.round_number < 5:
            return False
        for player_idx in range(history.opponent_actions.shape[1]):
            player_actions = history.opponent_actions[:, player_idx]
            cooperation_freq = np.mean(player_actions)
            if cooperation_freq > 0.6:
                return True
        return False

    def _adjust_threshold(self, history: PlayerHistory) -> None:
        """Dynamically adjust exploitation threshold based on performance."""
        if history.round_number < 3:
            return
        recent_my_payoffs = np.mean(history.my_payoffs[-3:])
        recent_opponent_payoffs = np.mean(history.opponent_payoffs[-3:, :])
        avg_opponent_payoff = np.mean(recent_opponent_payoffs)
        if avg_opponent_payoff > recent_my_payoffs:
            self.exploitation_threshold *= 0.8
        min_threshold = self.k / (4 * self.n)
        self.exploitation_threshold = max(self.exploitation_threshold, min_threshold)

class Strategy_AGGRESSIVE_41(BaseStrategy):
    """
    Ruthless Opportunist: An aggressive exploitation strategy that maximizes personal payoff
    through strategic deception, exploitation of cooperators, and adaptive punishment cascades.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        round_num = history.round_number + 1
        if round_num == 2:
            cooperators_last = np.sum(history.opponent_actions[0, :])
            cooperation_rate = cooperators_last / self.n
            if cooperation_rate >= 0.7:
                return Action.C
            else:
                return Action.D
        if round_num >= self.r - 1:
            return Action.D
        last_round_idx = history.round_number - 1
        cooperators_last = np.sum(history.opponent_actions[last_round_idx, :])
        my_last_action = history.my_actions[last_round_idx]
        total_cooperators_last = cooperators_last + (1 if my_last_action else 0)
        cooperation_rate = total_cooperators_last / self.n
        predicted_cooperators = cooperators_last
        my_expected_gain = self.k / self.n * (predicted_cooperators + 1) - 1
        if cooperation_rate >= 0.6 and my_expected_gain > 1.2:
            return Action.C
        elif cooperation_rate >= 0.4:
            if random.random() < 0.3:
                return Action.D
            elif self._should_use_deception_cooperation(history, round_num):
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _should_use_deception_cooperation(self, history: PlayerHistory, round_num: int) -> bool:
        """Apply deception tactics to maintain exploitable cooperation levels."""
        if round_num >= 3:
            recent_rounds = min(2, history.round_number)
            recent_cooperation = 0
            for i in range(recent_rounds):
                round_idx = history.round_number - 1 - i
                recent_cooperation += np.sum(history.opponent_actions[round_idx, :])
            recent_rate = recent_cooperation / (self.n * recent_rounds)
            if recent_rate > 0.5:
                cooperation_probability = max(0.1, 0.4 - round_num * 0.03)
                return random.random() < cooperation_probability
        return False

class Strategy_AGGRESSIVE_42(BaseStrategy):
    """
    Aggressive exploit-focused strategy that maximizes personal payoff by free-riding 
    on others' cooperation while punishing retaliation attempts.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.permanent_defect_mode = False
        self.retaliators = set()

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = history.round_number + 1
        if current_round >= r - 1:
            return Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        my_last_action = history.my_actions[-1]
        total_cooperators = last_round_cooperators + (1 if my_last_action else 0)
        cooperation_rate = total_cooperators / n
        my_last_payoff = history.my_payoffs[-1]
        if cooperation_rate < 0.4:
            self.permanent_defect_mode = True
        if self.permanent_defect_mode:
            return Action.D
        if len(history.my_actions) >= 2:
            for opponent_idx in range(n - 1):
                if not history.my_actions[-2] and history.opponent_actions[-2, opponent_idx] and (not history.opponent_actions[-1, opponent_idx]):
                    self.retaliators.add(opponent_idx)
        rounds_remaining = r - current_round
        if cooperation_rate >= 0.7 and my_last_payoff < 1.5 and (rounds_remaining >= 3):
            return Action.C
        return Action.D

class Strategy_AGGRESSIVE_43(BaseStrategy):
    """
    AGGRESSIVE EXPLOITATION STRATEGY: "PREDATOR"
    
    This strategy operates on aggressive exploitation principles, seeking to maximize
    personal payoff by strategically free-riding on others' cooperation while
    minimizing its own contributions. It adapts quickly to crush emerging cooperative
    patterns and exploits cooperative players mercilessly.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.exploitation_threshold = max(0.3, self.k / self.n_players)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.n_rounds - 1:
            return Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        cooperation_rate = last_round_cooperators / self.n_players
        cooperation_trend = 0
        if len(history.my_actions) >= 2:
            prev_round_cooperators = sum(history.opponent_actions[-2, :])
            if history.my_actions[-2]:
                prev_round_cooperators += 1
            prev_cooperation_rate = prev_round_cooperators / self.n_players
            cooperation_trend = cooperation_rate - prev_cooperation_rate
        rounds_remaining = self.n_rounds - current_round
        endgame_factor = 1.0
        if rounds_remaining < self.n_rounds / 3:
            endgame_factor = 1.2
        if cooperation_rate > self.exploitation_threshold:
            if random.random() < 0.95 * endgame_factor:
                return Action.D
        if cooperation_trend > 0.15:
            return Action.D
        if len(history.my_actions) >= 3:
            for player_idx in range(len(history.opponent_actions[0, :])):
                player_coop_rate = np.mean(history.opponent_actions[:, player_idx])
                if player_coop_rate > 0.8:
                    return Action.D
        if self._detect_coordination_pattern(history):
            return Action.D
        effective_multiplier = self.k / self.n_players
        cooperation_seeding_prob = 0.15
        if effective_multiplier > 0.5:
            cooperation_seeding_prob *= 0.5
        if cooperation_rate < 0.2 and random.random() < cooperation_seeding_prob:
            return Action.C
        if cooperation_rate < 0.15 and random.random() < 0.2:
            return Action.C
        if random.random() < 0.2 / endgame_factor:
            return Action.C
        return Action.D

    def _detect_coordination_pattern(self, history: PlayerHistory) -> bool:
        """Detect if opponents are showing coordination patterns"""
        if len(history.my_actions) < 3:
            return False
        recent_rounds = min(3, len(history.my_actions))
        recent_actions = history.opponent_actions[-recent_rounds:, :]
        for round_idx in range(recent_rounds):
            round_coop_rate = np.mean(recent_actions[round_idx, :])
            if round_coop_rate > 0.6:
                return True
        return False

class Strategy_AGGRESSIVE_44(BaseStrategy):
    """
    Aggressive Exploitation Strategy - maximizes individual payoff through ruthless opportunism
    while maintaining strategic flexibility and adaptive responses to different opponent types.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.opponent_types = {}
        self.exploitation_bonus = 0.1
        self.fallen_players = set()

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == r - 1:
            return Action.D
        self._classify_opponents(history)
        game_progress = current_round / r
        late_game_penalty = 0.5 if game_progress > 0.75 else 0.0
        expected_coop = self._estimate_cooperation(history, current_round, r)
        base_threshold = 1.0
        if game_progress > 0.8:
            profit_threshold = base_threshold + 0.2
        else:
            profit_threshold = base_threshold + self.exploitation_bonus
        profit_threshold += late_game_penalty
        if k > 1.5:
            profit_threshold -= 0.2
        elif k < 1.3:
            profit_threshold += 0.2
        if n > 8:
            profit_threshold += 0.1
        elif n <= 4:
            profit_threshold -= 0.1
        expected_benefit = k * expected_coop / n
        exploitable_count = sum((1 for t in self.opponent_types.values() if t == 'exploitable'))
        retaliatory_count = sum((1 for t in self.opponent_types.values() if t == 'retaliatory'))
        if current_round <= 2 and history.round_number > 0:
            last_round_coop_rate = np.mean(history.opponent_actions[-1, :])
            if last_round_coop_rate > 0.8:
                if random.random() < 0.3:
                    return Action.C
        if 0.3 < game_progress < 0.7:
            recent_coop_rate = np.mean(history.opponent_actions[-min(3, len(history.opponent_actions)):, :])
            if recent_coop_rate < 0.2 and random.random() < 0.15:
                return Action.C
        if expected_benefit > profit_threshold and exploitable_count > retaliatory_count and (len(self.fallen_players) < n * 0.5):
            return Action.C
        else:
            return Action.D

    def _classify_opponents(self, history: PlayerHistory):
        """Classify opponents based on their behavior patterns"""
        n_opponents = history.opponent_actions.shape[1]
        for player_idx in range(n_opponents):
            player_actions = history.opponent_actions[:, player_idx]
            cooperation_rate = np.mean(player_actions)
            if len(player_actions) >= 2:
                early_coop_rate = np.mean(player_actions[:max(1, len(player_actions) // 3)])
                recent_coop_rate = np.mean(player_actions[-max(1, len(player_actions) // 3):])
                if early_coop_rate > 0.6 and recent_coop_rate < 0.4:
                    self.fallen_players.add(player_idx)
            if cooperation_rate > 0.6:
                if len(player_actions) >= 3:
                    consistency = 1.0 - np.std(player_actions.astype(float))
                    if consistency > 0.7:
                        self.opponent_types[player_idx] = 'exploitable'
                    else:
                        self.opponent_types[player_idx] = 'random'
                else:
                    self.opponent_types[player_idx] = 'exploitable'
            elif cooperation_rate < 0.3:
                self.opponent_types[player_idx] = 'aggressive'
            elif len(player_actions) >= 2 and history.round_number >= 2:
                retaliatory_score = 0
                for i in range(1, len(player_actions)):
                    prev_round_defectors = np.sum(history.opponent_actions[i - 1, :] == False)
                    if prev_round_defectors > 0 and player_actions[i] == False:
                        retaliatory_score += 1
                if retaliatory_score > len(player_actions) * 0.4:
                    self.opponent_types[player_idx] = 'retaliatory'
                else:
                    self.opponent_types[player_idx] = 'random'
            else:
                self.opponent_types[player_idx] = 'random'

    def _estimate_cooperation(self, history: PlayerHistory, current_round: int, total_rounds: int):
        """Estimate expected cooperation in next round based on opponent types and trends"""
        n_opponents = history.opponent_actions.shape[1]
        expected_coop = 0
        if len(history.opponent_actions) >= 2:
            recent_window = min(3, len(history.opponent_actions))
            recent_coop = np.mean(history.opponent_actions[-recent_window:, :], axis=0)
            if len(history.opponent_actions) >= 3:
                older_coop = np.mean(history.opponent_actions[-min(6, len(history.opponent_actions)):-recent_window, :], axis=0)
                trend = recent_coop - older_coop
                trend = np.clip(trend, -0.2, 0.2)
                expected_coop = np.sum(np.clip(recent_coop + trend, 0, 1))
            else:
                expected_coop = np.sum(recent_coop)
        else:
            expected_coop = np.sum(history.opponent_actions[-1, :])
        type_adjustment = 0
        for player_idx, opponent_type in self.opponent_types.items():
            if opponent_type == 'exploitable':
                type_adjustment += 0.8
            elif opponent_type == 'retaliatory':
                type_adjustment += 0.5
            elif opponent_type == 'aggressive':
                type_adjustment += 0.1
            else:
                type_adjustment += 0.4
        expected_coop = 0.7 * expected_coop + 0.3 * type_adjustment
        game_progress = current_round / total_rounds
        if game_progress > 0.7:
            endgame_reduction = (game_progress - 0.7) * 0.5
            expected_coop *= 1 - endgame_reduction
        return max(0, expected_coop)

class Strategy_AGGRESSIVE_45(BaseStrategy):
    """
    Aggressive exploitation strategy "PREDATOR" that treats the public goods game as competitive.
    Exploits cooperative players while minimizing own contributions, using phase-based decision making.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        round_num = state.round_number
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        cooperation_rate_last = last_round_cooperators / self.n
        phase1_end = min(3, self.r // 3)
        if round_num <= phase1_end:
            return Action.D
        endgame_start = self.r - max(2, self.r // 4)
        if round_num > endgame_start:
            return Action.D
        if cooperation_rate_last >= 0.75:
            return Action.C
        if len(history.my_actions) >= 2 and history.my_actions[-1]:
            if len(history.opponent_actions) >= 2:
                prev_round_cooperators = np.sum(history.opponent_actions[-2, :])
                if history.my_actions[-2]:
                    prev_round_cooperators += 1
                prev_cooperation_rate = prev_round_cooperators / self.n
                if cooperation_rate_last >= 0.5 and prev_cooperation_rate > cooperation_rate_last:
                    return Action.D
        if cooperation_rate_last < 0.3:
            rounds_since_cooperation = 0
            for i in range(min(len(history.my_actions), 3)):
                if history.my_actions[-(i + 1)]:
                    break
                rounds_since_cooperation += 1
            if rounds_since_cooperation >= 3:
                return Action.C
        return Action.D

class Strategy_AGGRESSIVE_46(BaseStrategy):
    """
    Aggressive Predator Strategy: Exploits cooperative players while punishing defectors
    through calculated aggression, opportunistic exploitation, and strategic intimidation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.intimidation_rounds_left = 0
        self.collapse_defect_rounds_left = 0
        self.exploitation_defect_rounds_left = 0
        self.payoff_recovery_rounds_left = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        round_num = state.round_number
        if self.intimidation_rounds_left > 0:
            self.intimidation_rounds_left -= 1
            return Action.D
        if self.collapse_defect_rounds_left > 0:
            self.collapse_defect_rounds_left -= 1
            return Action.D
        if self.payoff_recovery_rounds_left > 0:
            self.payoff_recovery_rounds_left -= 1
            return Action.D
        if round_num >= self.r - 3:
            return Action.D
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        cooperation_rate_last = last_round_cooperators / (self.n - 1)
        if round_num <= 3:
            if cooperation_rate_last >= 0.8:
                return Action.C
            else:
                return Action.D
        declining_trend = self._check_declining_cooperation_trend(history)
        increasing_trend = self._check_increasing_cooperation_trend(history)
        punishment_risk = 0.3 if declining_trend else 0.1
        EP = cooperation_rate_last * self.k / self.n - punishment_risk
        my_avg_payoff = np.mean(history.my_payoffs)
        group_payoffs = np.concatenate([history.my_payoffs.reshape(-1, 1), history.opponent_payoffs], axis=1)
        group_avg_payoff = np.mean(group_payoffs)
        if self._check_cooperation_collapse(history):
            self.collapse_defect_rounds_left = 3
            return Action.D
        if self._check_high_cooperation_exploitation(history):
            if self.exploitation_defect_rounds_left > 0:
                self.exploitation_defect_rounds_left -= 1
                return Action.D
            else:
                self.exploitation_defect_rounds_left = 2
                return Action.C
        if round_num % 3 == 0:
            if self._check_ranking_drop(history):
                self.payoff_recovery_rounds_left = 2
                return Action.D
        if self._check_intimidation_needed(history):
            self.intimidation_rounds_left = 2
            return Action.D
        threshold_adjustment = 0.1 if self.k > self.n * 0.7 else 0.0
        if EP > 0.6 - threshold_adjustment:
            return Action.C
        elif EP > 0.3 - threshold_adjustment and my_avg_payoff < group_avg_payoff:
            return Action.C
        elif cooperation_rate_last < 0.3:
            return Action.D
        elif increasing_trend:
            return Action.D
        else:
            return Action.D

    def _check_declining_cooperation_trend(self, history: PlayerHistory) -> bool:
        if history.round_number < 2:
            return False
        recent_rates = []
        for i in range(max(0, history.round_number - 3), history.round_number):
            coop_rate = np.sum(history.opponent_actions[i, :]) / (self.n - 1)
            recent_rates.append(coop_rate)
        if len(recent_rates) >= 2:
            return recent_rates[-1] < recent_rates[-2]
        return False

    def _check_increasing_cooperation_trend(self, history: PlayerHistory) -> bool:
        if history.round_number < 3:
            return False
        increases = 0
        for i in range(max(1, history.round_number - 3), history.round_number):
            curr_rate = np.sum(history.opponent_actions[i, :]) / (self.n - 1)
            prev_rate = np.sum(history.opponent_actions[i - 1, :]) / (self.n - 1)
            if curr_rate > prev_rate:
                increases += 1
        return increases >= 2

    def _check_cooperation_collapse(self, history: PlayerHistory) -> bool:
        if history.round_number < 2:
            return False
        recent_rates = []
        for i in range(max(0, history.round_number - 2), history.round_number):
            coop_rate = np.sum(history.opponent_actions[i, :]) / (self.n - 1)
            recent_rates.append(coop_rate)
        return len(recent_rates) >= 2 and all((rate < 0.2 for rate in recent_rates))

    def _check_high_cooperation_exploitation(self, history: PlayerHistory) -> bool:
        if history.round_number < 2:
            return False
        recent_rates = []
        for i in range(max(0, history.round_number - 2), history.round_number):
            coop_rate = np.sum(history.opponent_actions[i, :]) / (self.n - 1)
            recent_rates.append(coop_rate)
        return len(recent_rates) >= 2 and all((rate > 0.7 for rate in recent_rates))

    def _check_ranking_drop(self, history: PlayerHistory) -> bool:
        my_total = np.sum(history.my_payoffs)
        opponent_totals = np.sum(history.opponent_payoffs, axis=0)
        all_totals = np.concatenate([[my_total], opponent_totals])
        my_rank = np.sum(all_totals > my_total) + 1
        top_40_percent_threshold = math.ceil(self.n * 0.4)
        return my_rank > top_40_percent_threshold

    def _check_intimidation_needed(self, history: PlayerHistory) -> bool:
        my_total = np.sum(history.my_payoffs)
        opponent_totals = np.sum(history.opponent_payoffs, axis=0)
        return np.any(opponent_totals > my_total)

class Strategy_AGGRESSIVE_47(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "PREDATOR"
    
    Treats cooperation as weakness to exploit. Always defects first round,
    classifies opponents as exploitable/competitive/unpredictable, and
    uses minimal cooperation only to maintain exploitable relationships.
    Employs group punishment and guarantees endgame defection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.k_n_ratio = self.k / self.n
        if self.k_n_ratio >= 0.4:
            self.max_cooperation_rate = 0.4
        elif self.k_n_ratio < 0.3:
            self.max_cooperation_rate = 0.2
        else:
            self.max_cooperation_rate = 0.3
        if self.n >= 8:
            self.exploitable_threshold = 0.4
        else:
            self.exploitable_threshold = 0.5
        self.competitive_threshold = 0.7
        self.punishment_rounds_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        endgame_threshold = max(1, int(0.8 * self.r))
        if current_round >= endgame_threshold:
            return Action.D
        if current_round >= self.r - 1:
            return Action.D
        if self.punishment_rounds_remaining > 0:
            self.punishment_rounds_remaining -= 1
            return Action.D
        opponent_classifications = self._classify_opponents(history)
        exploitable_count = sum((1 for c in opponent_classifications if c == 'EXPLOITABLE'))
        if self._should_punish(history, opponent_classifications):
            self.punishment_rounds_remaining = 2
            return Action.D
        n_opponents = self.n - 1
        if exploitable_count >= n_opponents / 2:
            return Action.D
        elif exploitable_count >= max(2, n_opponents / 3):
            my_recent_cooperation_rate = self._get_recent_cooperation_rate(history)
            if my_recent_cooperation_rate < self.max_cooperation_rate:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _classify_opponents(self, history):
        """Classify each opponent as EXPLOITABLE, COMPETITIVE, or UNPREDICTABLE"""
        classifications = []
        n_rounds = len(history.my_actions)
        for opponent_idx in range(self.n - 1):
            opponent_actions = history.opponent_actions[:, opponent_idx]
            cooperation_rate = np.mean(opponent_actions)
            if cooperation_rate >= self.exploitable_threshold:
                classifications.append('EXPLOITABLE')
            elif cooperation_rate <= 1 - self.competitive_threshold:
                classifications.append('COMPETITIVE')
            else:
                classifications.append('UNPREDICTABLE')
        return classifications

    def _should_punish(self, history, opponent_classifications):
        """Check if we should trigger group punishment"""
        if len(history.my_actions) < 3:
            return False
        for opponent_idx in range(self.n - 1):
            if len(history.my_actions) >= 3:
                past_actions = history.opponent_actions[:-2, opponent_idx]
                if len(past_actions) > 0 and np.mean(past_actions) >= self.exploitable_threshold:
                    recent_actions = history.opponent_actions[-2:, opponent_idx]
                    if len(recent_actions) >= 2 and np.sum(recent_actions) == 0:
                        return True
        return False

    def _get_recent_cooperation_rate(self, history):
        """Calculate cooperation rate over recent rounds"""
        if len(history.my_actions) == 0:
            return 0
        recent_rounds = min(5, len(history.my_actions))
        recent_actions = history.my_actions[-recent_rounds:]
        return np.mean(recent_actions)

class Strategy_AGGRESSIVE_48(BaseStrategy):
    """
    Predator Strategy: An aggressive free-rider that exploits cooperative behavior while minimizing contributions.
    Defects in most rounds, with limited cooperation only when strategically necessary for survival.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        if current_round < self.r - 2:
            return Action.D
        if current_round == self.r - 2:
            total_cooperations = np.sum(history.opponent_actions)
            total_possible = history.opponent_actions.shape[0] * history.opponent_actions.shape[1]
            avg_cooperation_rate = total_cooperations / total_possible if total_possible > 0 else 0
            my_total_payoff = np.sum(history.my_payoffs)
            theoretical_max_per_round = 1 + self.k / self.n * (self.n - 1)
            theoretical_maximum = theoretical_max_per_round * (current_round + 1)
            if avg_cooperation_rate > 0.7 and my_total_payoff < 0.8 * theoretical_maximum:
                return Action.C
            else:
                return Action.D
        return Action.D

class Strategy_AGGRESSIVE_49(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "PREDATOR"
    
    This strategy treats the public goods game as a zero-sum competition, aggressively 
    exploiting cooperative players while minimizing personal risk. It uses adaptive 
    thresholds and punishment mechanisms to maximize relative advantage.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.forced_defect_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        if self.forced_defect_rounds > 0:
            self.forced_defect_rounds -= 1
            return Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        coop_rate = last_round_cooperators / (self.n - 1)
        base_threshold = (self.n - self.k) / (self.n - 1)
        if self.n <= 4:
            threshold = 0.9
        else:
            threshold = base_threshold
            if self.k > self.n / 2:
                threshold = max(0.1, threshold - 0.1)
        if current_round < self.r / 2:
            rounds_to_check = min(3, len(history.my_actions))
            recent_coop_rates = []
            for i in range(rounds_to_check):
                round_idx = -(i + 1)
                round_cooperators = sum(history.opponent_actions[round_idx, :])
                recent_coop_rates.append(round_cooperators / (self.n - 1))
            avg_recent_coop = np.mean(recent_coop_rates)
            if avg_recent_coop < 0.2:
                return Action.D
        if len(history.my_actions) >= 3:
            for player_idx in range(self.n - 1):
                recent_actions = history.opponent_actions[-3:, player_idx]
                player_coop_rate = np.mean(recent_actions)
                if player_coop_rate > 0.8:
                    self.forced_defect_rounds = 2
                    return Action.D
        if len(history.my_payoffs) > 0:
            my_last_payoff = history.my_payoffs[-1]
            opponent_last_payoffs = history.opponent_payoffs[-1, :]
            avg_opponent_payoff = np.mean(opponent_last_payoffs)
            if my_last_payoff < avg_opponent_payoff:
                return Action.D
        if len(history.my_actions) >= 2:
            prev_cooperators = sum(history.opponent_actions[-2, :])
            prev_coop_rate = prev_cooperators / (self.n - 1)
            if prev_coop_rate > 0 and (prev_coop_rate - coop_rate) / prev_coop_rate > 0.25:
                return Action.D
        if coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_AGGRESSIVE_50(BaseStrategy):
    """
    Aggressive Exploit-then-Punish Strategy
    
    Operates on aggressive exploitation - maximize personal payoffs by exploiting 
    cooperative opponents while severely punishing any attempts at exploitation.
    Uses initial exploitation, adaptive aggression, and endgame exploitation phases.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.punishment_rounds = 0
        self.cooperation_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.punishment_rounds = 0
            self.cooperation_streak = 0
            return Action.D
        current_round = state.round_number
        n = self.game_description.n_players
        total_rounds = self.game_description.n_rounds
        if current_round < 3:
            return Action.D
        if current_round >= total_rounds - 2:
            return Action.D
        last_round_cooperators = int(sum(history.opponent_actions[-1, :]))
        total_cooperators_last_round = last_round_cooperators
        if history.my_actions[-1]:
            total_cooperators_last_round += 1
        cooperation_rate = total_cooperators_last_round / (n + 1)
        if self.punishment_rounds > 0:
            self.punishment_rounds -= 1
            return Action.D
        cooperation_threshold = math.floor(n / 2) + 1
        if total_cooperators_last_round >= cooperation_threshold:
            return Action.D
        if current_round >= 6:
            if self._cooperators_trend_increasing(history, n):
                return Action.D
        if history.my_actions[-1] and last_round_cooperators < n / 3:
            self.punishment_rounds = 2
            return Action.D
        if cooperation_rate < 0.2 and self._mutual_defection_for_3_rounds(history, n):
            if random.random() < 0.3:
                return Action.C
        return Action.D

    def _cooperators_trend_increasing(self, history: PlayerHistory, n: int) -> bool:
        """Check if cooperation is increasing over last 2 rounds"""
        if len(history.my_actions) < 2:
            return False
        recent_cooperators = []
        for i in range(-2, 0):
            round_cooperators = int(sum(history.opponent_actions[i, :]))
            if history.my_actions[i]:
                round_cooperators += 1
            recent_cooperators.append(round_cooperators)
        return recent_cooperators[1] > recent_cooperators[0]

    def _mutual_defection_for_3_rounds(self, history: PlayerHistory, n: int) -> bool:
        """Check if we've been in mutual defection for 3+ rounds"""
        if len(history.my_actions) < 3:
            return False
        for i in range(-3, 0):
            round_cooperators = int(sum(history.opponent_actions[i, :]))
            if history.my_actions[i]:
                round_cooperators += 1
            if round_cooperators > 0:
                return False
        return True

class Strategy_AGGRESSIVE_51(BaseStrategy):
    """
    PREDATOR Strategy: Aggressive exploitation with maximum value extraction.
    Always defects first, exploits cooperative opponents, punishes defectors,
    and guarantees defection in final rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.punishment_rounds_remaining = 0
        self.cooperation_threshold = 0.6
        self.pure_defection_mode = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        k = self.game_description.k
        if current_round >= r - 3:
            return Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        cooperation_rate = last_round_cooperators / (n - 1)
        if len(history.my_actions) >= 3:
            all_cooperation_rates = []
            for round_idx in range(len(history.my_actions)):
                round_cooperators = sum(history.opponent_actions[round_idx, :])
                all_cooperation_rates.append(round_cooperators / (n - 1))
            avg_cooperation = np.mean(all_cooperation_rates)
            if avg_cooperation < 0.3:
                self.pure_defection_mode = True
        if self.pure_defection_mode:
            return Action.D
        if self.punishment_rounds_remaining > 0:
            self.punishment_rounds_remaining -= 1
            return Action.D
        if cooperation_rate < self.cooperation_threshold:
            self.punishment_rounds_remaining = 2
            if len(history.my_actions) >= 2:
                prev_cooperators = sum(history.opponent_actions[-2, :])
                prev_cooperation_rate = prev_cooperators / (n - 1)
                if prev_cooperation_rate < self.cooperation_threshold:
                    self.punishment_rounds_remaining += 1
            return Action.D
        if len(history.my_actions) >= 3:
            recent_rates = []
            for i in range(3):
                round_cooperators = sum(history.opponent_actions[-(i + 1), :])
                recent_rates.append(round_cooperators / (n - 1))
            if recent_rates[0] < recent_rates[1] < recent_rates[2]:
                return Action.D
        if cooperation_rate > 0.8 and len(history.my_actions) >= 3:
            recent_high_coop = True
            for i in range(min(3, len(history.my_actions))):
                round_cooperators = sum(history.opponent_actions[-(i + 1), :])
                round_coop_rate = round_cooperators / (n - 1)
                if round_coop_rate <= 0.8:
                    recent_high_coop = False
                    break
            if recent_high_coop:
                if random.random() < 0.7:
                    if random.random() < 0.3:
                        return Action.D
                    return Action.C
                else:
                    return Action.D
        if cooperation_rate >= self.cooperation_threshold:
            estimated_cooperators = last_round_cooperators
            expected_coop_payoff = 0 + k / n * (estimated_cooperators + 1)
            expected_defect_payoff = 1 + k / n * estimated_cooperators
            if expected_coop_payoff > expected_defect_payoff + 0.1:
                if random.random() < 0.3:
                    return Action.D
                return Action.C
        return Action.D

class Strategy_AGGRESSIVE_52(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Predator"
    
    Treats the game as a hunting ground where cooperation from others is prey to be exploited.
    Uses aggressive exploitation with conditional retaliation to maintain fear-based cooperation
    from opponents while minimizing own contributions.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.retaliation_counter = 0
        self.survivor_mode_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        round_num = state.round_number + 1
        if self._should_retaliate(history):
            self.retaliation_counter = 3
        if self.retaliation_counter > 0:
            self.retaliation_counter -= 1
            return Action.D
        if self._should_enter_survivor_mode(history):
            self.survivor_mode_counter = 2
        if self.survivor_mode_counter > 0:
            self.survivor_mode_counter -= 1
            if random.random() < 0.6:
                return Action.C
            else:
                return Action.D
        if round_num <= self.r // 3:
            return self._early_exploitation(history)
        elif round_num <= 2 * self.r // 3:
            return self._calculated_exploitation(history)
        else:
            return self._endgame_extraction(history, round_num)

    def _should_retaliate(self, history: PlayerHistory) -> bool:
        """Check if my payoff in last round fell below all-defect baseline (payoff = 1)"""
        if len(history.my_payoffs) == 0:
            return False
        return history.my_payoffs[-1] < 1.0

    def _should_enter_survivor_mode(self, history: PlayerHistory) -> bool:
        """Check if average cooperation rate across all players falls below 30%"""
        if len(history.opponent_actions) == 0:
            return False
        total_cooperations = 0
        total_actions = 0
        for round_idx in range(len(history.opponent_actions)):
            total_cooperations += np.sum(history.opponent_actions[round_idx])
            total_actions += len(history.opponent_actions[round_idx])
        total_cooperations += np.sum(history.my_actions)
        total_actions += len(history.my_actions)
        if total_actions == 0:
            return False
        cooperation_rate = total_cooperations / total_actions
        return cooperation_rate < 0.3

    def _early_exploitation(self, history: PlayerHistory) -> Action:
        """Phase 1: Early Exploitation (Rounds 1 to r/3)"""
        if len(history.opponent_actions) == 0:
            return Action.D
        cooperators_last_round = np.sum(history.opponent_actions[-1])
        if cooperators_last_round >= (self.n - 1) / 2:
            return Action.D
        elif random.random() < 0.3:
            return Action.C
        else:
            return Action.D

    def _calculated_exploitation(self, history: PlayerHistory) -> Action:
        """Phase 2: Calculated Exploitation (Rounds r/3+1 to 2r/3)"""
        if len(history.opponent_actions) == 0:
            return Action.D
        T = math.ceil(self.n * self.k / self.n - 1)
        cooperators_last_round = np.sum(history.opponent_actions[-1])
        if cooperators_last_round >= T + 1:
            return Action.D
        elif cooperators_last_round == T:
            if random.random() < 0.8:
                return Action.D
            else:
                return Action.C
        elif cooperators_last_round == T - 1:
            return Action.C
        else:
            return Action.C

    def _endgame_extraction(self, history: PlayerHistory, round_num: int) -> Action:
        """Phase 3: Endgame Extraction (Rounds 2r/3+1 to r)"""
        if round_num > self.r - 3:
            return Action.D
        if self.r <= 5:
            return Action.D
        if len(history.opponent_actions) == 0:
            return Action.D
        rounds_in_phase3 = round_num - 2 * self.r // 3
        P = max(0.0, 0.4 - 0.1 * (rounds_in_phase3 - 1))
        cooperators_last_round = np.sum(history.opponent_actions[-1])
        if cooperators_last_round >= self.n - 2 and random.random() < P:
            return Action.C
        else:
            return Action.D

class Strategy_AGGRESSIVE_53(BaseStrategy):
    """
    AGGRESSIVE EXPLOITATION STRATEGY: "PREDATOR"
    
    Treats the public goods game as zero-sum competition, aggressively exploiting
    cooperative behavior while minimizing personal vulnerability through three phases:
    initial exploitation, conditional aggression, and endgame exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        round_num = state.round_number
        if round_num <= min(3, self.r // 3):
            return Action.D
        if round_num > self.r - min(2, self.r // 4):
            return Action.D
        return self._conditional_aggression_decision(history)

    def _conditional_aggression_decision(self, history: PlayerHistory) -> Action:
        """Execute conditional aggression logic for middle phase."""
        if len(history.opponent_actions) > 0:
            prev_cooperators = int(np.sum(history.opponent_actions[-1, :]))
            if prev_cooperators >= self.n - 1:
                if self.k > 0.8 * self.n:
                    return Action.C
                return Action.C
        if len(history.opponent_actions) > 0:
            total_opponent_actions = history.opponent_actions.size
            total_cooperations = int(np.sum(history.opponent_actions))
            others_cooperation_rate = total_cooperations / total_opponent_actions if total_opponent_actions > 0 else 0
            if others_cooperation_rate < 0.8:
                return Action.D
            if random.random() < 0.1 and others_cooperation_rate < 0.5:
                return Action.C
        if self._check_sole_defector_pattern(history):
            return Action.C
        return Action.D

    def _check_sole_defector_pattern(self, history: PlayerHistory) -> bool:
        """Check if we've been the sole defector for 2+ consecutive rounds."""
        if len(history.my_actions) < 2:
            return False
        consecutive_sole_defector = 0
        for i in range(len(history.my_actions)):
            round_idx = len(history.my_actions) - 1 - i
            if round_idx < 0:
                break
            my_action = history.my_actions[round_idx]
            opponent_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
            if not my_action and opponent_cooperators >= self.n - 1:
                consecutive_sole_defector += 1
            else:
                break
            if consecutive_sole_defector >= 2:
                return True
        return False

class Strategy_AGGRESSIVE_54(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "PREDATOR"
    
    This strategy treats cooperation as weakness to be exploited. It aggressively defects
    while strategically punishing cooperators to maintain a profitable environment of exploitation.
    Always defects in first and last rounds, with adaptive exploitation in between.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.total_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        round_num = history.round_number + 1
        if round_num == self.total_rounds:
            return Action.D
        last_round_opponents = history.opponent_actions[-1, :]
        cooperator_count = sum(last_round_opponents)
        my_last_action = history.my_actions[-1]
        if my_last_action:
            total_cooperators = cooperator_count + 1
        else:
            total_cooperators = cooperator_count
        exploitation_value = self.k / self.n * cooperator_count
        if round_num <= 5:
            if len(history.opponent_actions) >= 2:
                prev_round = history.opponent_actions[-2, :]
                curr_round = history.opponent_actions[-1, :]
                switched_to_defect = any((prev_round[i] == True and curr_round[i] == False for i in range(len(prev_round))))
                if switched_to_defect:
                    return Action.D
            if cooperator_count >= 0.6 * (self.n - 1):
                return Action.D
        if cooperator_count >= (self.n - 1) / 2 and exploitation_value > 0.8:
            return Action.D
        if cooperator_count == self.n - 1 and self.k / self.n * self.n > 1.2 and (self.total_rounds - round_num > 3):
            return Action.C
        if round_num > 0.8 * self.total_rounds:
            potential_payoff = self.k / self.n * (cooperator_count + 1)
            if potential_payoff <= 1.5:
                return Action.D
        return Action.D

class Strategy_AGGRESSIVE_55(BaseStrategy):
    """
    AGGRESSIVE EXPLOITATION STRATEGY: "PREDATOR"
    
    This strategy treats the public goods game as a zero-sum competition where the goal 
    is to maximize personal payoff by exploiting others' cooperation while minimizing 
    personal contribution. It operates on the principle that cooperation is weakness 
    to be punished, and any cooperative behavior from opponents is an opportunity to 
    be exploited.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.forced_defect_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round > self.r - 3:
            return Action.D
        if self.forced_defect_rounds > 0:
            self.forced_defect_rounds -= 1
            return Action.D
        last_round_opponent_actions = history.opponent_actions[-1, :]
        opponent_coop_rate = np.mean(last_round_opponent_actions)
        if opponent_coop_rate >= 0.3:
            return Action.D
        if self._not_in_top_performance(history):
            self.forced_defect_rounds = 1
            return Action.D
        if self._detect_consistent_cooperators(history):
            return Action.D
        if self._detect_cooperation_trends(history):
            return Action.D
        if opponent_coop_rate >= 0.7:
            self.forced_defect_rounds = 1
            return Action.D
        if self._all_defection_deadlock(history):
            return Action.C
        if self._all_cooperation_conditions_met(current_round, history):
            return Action.C
        return Action.D

    def _not_in_top_performance(self, history: PlayerHistory) -> bool:
        """Check if not performing in top 50% compared to opponents"""
        if len(history.my_payoffs) < 3:
            return False
        my_avg_payoff = np.mean(history.my_payoffs[-3:])
        opponent_avg_payoffs = np.mean(history.opponent_payoffs[-3:, :], axis=0)
        all_payoffs = np.append(opponent_avg_payoffs, my_avg_payoff)
        rank = np.sum(all_payoffs < my_avg_payoff) + 1
        return rank > len(all_payoffs) * 0.5

    def _detect_consistent_cooperators(self, history: PlayerHistory) -> bool:
        """Detect opponents with cooperation frequency > 0.6 over last 3 rounds"""
        if len(history.my_actions) < 3:
            return False
        last_3_rounds = history.opponent_actions[-3:, :]
        coop_frequencies = np.mean(last_3_rounds, axis=0)
        return np.any(coop_frequencies > 0.6)

    def _detect_cooperation_trends(self, history: PlayerHistory) -> bool:
        """Detect if majority of opponents show increasing cooperation trend"""
        if len(history.my_actions) < 3:
            return False
        increasing_trends = 0
        n_opponents = history.opponent_actions.shape[1]
        for opponent_idx in range(n_opponents):
            recent_actions = history.opponent_actions[-3:, opponent_idx]
            if len(recent_actions) >= 3:
                if np.mean(recent_actions[-2:]) > np.mean(recent_actions[:2]):
                    increasing_trends += 1
        return increasing_trends > n_opponents / 2

    def _all_defection_deadlock(self, history: PlayerHistory) -> bool:
        """Check if all players defected for 3+ consecutive rounds"""
        if len(history.my_actions) < 3:
            return False
        last_3_my_actions = history.my_actions[-3:]
        last_3_opponent_actions = history.opponent_actions[-3:, :]
        all_my_defect = np.all(last_3_my_actions == False)
        all_opponent_defect = np.all(last_3_opponent_actions == False)
        return all_my_defect and all_opponent_defect

    def _all_cooperation_conditions_met(self, current_round: int, history: PlayerHistory) -> bool:
        """Check if all conditions for limited strategic cooperation are met"""
        if current_round > self.r - 3:
            return False
        if len(history.my_actions) > 0:
            last_round_coop_rate = np.mean(history.opponent_actions[-1, :])
            if last_round_coop_rate >= 0.2:
                return False
        if len(history.my_payoffs) >= 3:
            my_avg_payoff = np.mean(history.my_payoffs[-3:])
            if my_avg_payoff >= 1.2:
                return False
        if len(history.my_actions) > 0:
            last_round_defect_rate = np.mean(history.opponent_actions[-1, :] == False)
            if last_round_defect_rate < 0.6:
                return False
        return True

class Strategy_AGGRESSIVE_56(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Ruthless Opportunist"
    
    Operates on maximum exploitation with minimal risk, aggressively exploiting
    cooperative opponents while quickly punishing defection signs. Prioritizes
    individual gain over collective welfare through conditional defection with
    exploitation windows.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        if current_round >= self.r - 2:
            return Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        cooperation_rate = last_round_cooperators / self.n
        rounds_to_check = min(3, current_round)
        my_recent_cooperations = sum(history.my_actions[-rounds_to_check:])
        cooperation_increasing = False
        if current_round >= 2:
            prev_cooperators = sum(history.opponent_actions[-2, :])
            cooperation_increasing = last_round_cooperators > prev_cooperators
        dramatic_drop = False
        if current_round >= 2:
            prev_cooperation_rate = sum(history.opponent_actions[-2, :]) / self.n
            if cooperation_rate < prev_cooperation_rate - 0.3:
                dramatic_drop = True
        if current_round % 4 == 0:
            if random.random() < 0.3:
                return Action.D if random.random() < 0.7 else Action.C
        if dramatic_drop:
            return Action.D
        high_coop_threshold = 0.7
        mid_coop_threshold = 0.4
        exploitation_threshold = 0.85 if self.n <= 4 else 0.7
        if self.k > 0.7 * self.n:
            mid_coop_threshold = 0.5
        elif self.k < 0.4 * self.n:
            exploitation_threshold = 0.9
            high_coop_threshold = 0.9
        if cooperation_rate >= exploitation_threshold and my_recent_cooperations <= 1:
            return Action.D
        sustained_cooperation = False
        if current_round >= 3:
            recent_rates = []
            for i in range(min(3, current_round)):
                round_cooperators = sum(history.opponent_actions[-(i + 1), :])
                recent_rates.append(round_cooperators / self.n)
            sustained_cooperation = all((rate > 0.6 for rate in recent_rates))
        if cooperation_rate >= high_coop_threshold and my_recent_cooperations <= 1:
            return Action.D
        elif cooperation_rate >= mid_coop_threshold and cooperation_rate < high_coop_threshold:
            if cooperation_increasing:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_AGGRESSIVE_57(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Opportunistic Dominance"
    
    This strategy maximizes personal payoffs through aggressive exploitation while maintaining
    strategic flexibility. It operates as a "smart free-rider" that capitalizes on others'
    cooperation while contributing minimally, adapting its behavior based on the cooperation
    environment.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.mode = None
        self.defection_streak = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.defection_streak = 1
            return Action.D
        current_round = history.round_number
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        my_last_action = history.my_actions[-1]
        total_last_cooperators = last_round_cooperators + (1 if my_last_action else 0)
        cooperation_rate_last = total_last_cooperators / self.n_players
        if current_round == 1:
            if cooperation_rate_last >= 0.6:
                self.mode = 'predator'
            elif cooperation_rate_last >= 0.3:
                self.mode = 'selective'
            else:
                self.mode = 'mutual_defection'
        rounds_remaining = self.n_rounds - current_round
        if not my_last_action:
            self.defection_streak += 1
        else:
            self.defection_streak = 0
        if rounds_remaining <= 0.2 * self.n_rounds:
            if cooperation_rate_last >= 0.4:
                return Action.D
            else:
                return Action.D
        if rounds_remaining == 0:
            return Action.D
        if self.mode == 'predator':
            return self._predator_mode(cooperation_rate_last, last_round_cooperators, rounds_remaining)
        elif self.mode == 'selective':
            return self._selective_exploitation_mode(cooperation_rate_last, rounds_remaining, history)
        else:
            return Action.D

    def _predator_mode(self, cooperation_rate_last, last_round_cooperators, rounds_remaining):
        """Predator mode for high cooperation environments"""
        if cooperation_rate_last >= 0.6:
            predicted_cooperators_without_me = last_round_cooperators
            if predicted_cooperators_without_me < self.n_players * 0.5:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _selective_exploitation_mode(self, cooperation_rate_last, rounds_remaining, history):
        """Selective exploitation for mixed environments"""
        if cooperation_rate_last >= 0.4:
            if rounds_remaining <= 3:
                return Action.D
            elif self.defection_streak >= 3:
                return Action.C
            else:
                return Action.D
        elif cooperation_rate_last >= 0.2 and rounds_remaining > self.n_rounds / 2:
            if random.random() < 0.3:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_AGGRESSIVE_58(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "PREDATOR"
    
    This strategy treats cooperation as weakness to be exploited and views the game 
    as a zero-sum competition. It uses adaptive exploitation mechanisms to maximize 
    personal gain at others' expense while punishing retaliation attempts.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.opponent_types = [0] * (self.n - 1)
        self.cumulative_advantage = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number + 1
        if current_round == self.r:
            return Action.D
        self._update_opponent_analysis(history)
        self._update_advantage(history)
        if current_round <= self.r // 2:
            return self._phase1_decision(history)
        else:
            return self._phase2_decision(history, current_round)

    def _update_opponent_analysis(self, history):
        """Update opponent type classification based on their responses."""
        if len(history.my_actions) < 2:
            return
        my_last_action = history.my_actions[-2]
        opponent_last_actions = history.opponent_actions[-1, :]
        if not my_last_action:
            for i in range(len(self.opponent_types)):
                if opponent_last_actions[i]:
                    if self.opponent_types[i] != 2:
                        self.opponent_types[i] = 1
                else:
                    self.opponent_types[i] = 2

    def _update_advantage(self, history):
        """Update personal payoff advantage."""
        if len(history.my_payoffs) > 0:
            my_avg = np.mean(history.my_payoffs)
            opponent_avg = np.mean(np.mean(history.opponent_payoffs, axis=1))
            self.cumulative_advantage = my_avg - opponent_avg

    def _phase1_decision(self, history):
        """Phase 1: Cooperative Exploitation (Rounds 2 to r/2)."""
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        avg_cooperation_rate = last_round_cooperators / (self.n - 1)
        if avg_cooperation_rate >= 0.3:
            return Action.D
        if self.cumulative_advantage > 0.5:
            return Action.D
        if last_round_cooperators >= (self.n - 1) / 2:
            return Action.C
        else:
            return Action.D

    def _phase2_decision(self, history, current_round):
        """Phase 2: Aggressive Endgame (Rounds r/2+1 to r-1)."""
        if current_round >= 0.8 * self.r:
            return Action.D
        retaliators = sum((1 for t in self.opponent_types if t == 2))
        opponents_retaliating = retaliators >= (self.n - 1) / 2
        if opponents_retaliating:
            if self.cumulative_advantage >= 2.0:
                return Action.D
            elif random.random() < 0.2:
                return Action.C
            else:
                return Action.D
        else:
            if self._detect_stagnation(history):
                if current_round % 5 == 0 and random.random() < 0.2:
                    return Action.C
            recent_cooperation = self._calculate_recent_cooperation(history)
            if recent_cooperation > 0.5:
                return Action.D if random.random() < 0.95 else Action.C
            elif recent_cooperation < 0.2:
                return Action.C if random.random() < 0.3 else Action.D
            return Action.D

    def _detect_stagnation(self, history):
        """Detect if all players are consistently defecting."""
        if len(history.my_actions) < 3:
            return False
        my_recent = history.my_actions[-3:]
        opponents_recent = history.opponent_actions[-3:, :]
        total_cooperations = sum(my_recent) + np.sum(opponents_recent)
        return total_cooperations == 0

    def _calculate_recent_cooperation(self, history):
        """Calculate cooperation rate in recent rounds."""
        if len(history.my_actions) < 3:
            rounds_to_check = len(history.my_actions)
        else:
            rounds_to_check = 3
        if rounds_to_check == 0:
            return 0.0
        recent_opponent_actions = history.opponent_actions[-rounds_to_check:, :]
        total_actions = rounds_to_check * (self.n - 1)
        total_cooperations = np.sum(recent_opponent_actions)
        return total_cooperations / total_actions if total_actions > 0 else 0.0

class Strategy_AGGRESSIVE_59(BaseStrategy):
    """
    Aggressive Punisher Strategy: Operates on aggressive reciprocity with strategic exploitation.
    Always defects first and last rounds, punishes any defection with extended retaliation,
    and exploits high cooperation situations while maintaining credible punishment threats.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.punishment_rounds_remaining = 0
        self.consecutive_high_cooperation = 0
        self.last_cooperation_rate = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        n = self.game_description.n_players
        final_round = self.game_description.n_rounds - 1
        if history is None:
            return Action.D
        if state.round_number == final_round:
            return Action.D
        total_players = n
        cooperators_last_round = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            cooperators_last_round += 1
        cooperation_rate = cooperators_last_round / total_players
        if self.punishment_rounds_remaining > 0:
            self.punishment_rounds_remaining -= 1
            return Action.D
        my_last_action = history.my_actions[-1]
        if self._detect_punishment_trigger(history, my_last_action, cooperation_rate):
            self.punishment_rounds_remaining = self._calculate_punishment_duration(cooperation_rate)
            return Action.D
        if cooperation_rate >= 0.8:
            self.consecutive_high_cooperation += 1
        else:
            self.consecutive_high_cooperation = 0
        if cooperation_rate >= 0.8 and self.consecutive_high_cooperation >= 2:
            return Action.D
        if cooperation_rate < 0.5:
            return Action.D
        if len(history.my_actions) >= 2:
            prev_cooperators = sum(history.opponent_actions[-2, :])
            if history.my_actions[-2]:
                prev_cooperators += 1
            prev_cooperation_rate = prev_cooperators / total_players
            if prev_cooperation_rate - cooperation_rate >= 0.3:
                return Action.D
        if self._am_only_defector(history):
            return Action.D
        if cooperation_rate >= 0.7 and self._expected_coop_payoff(cooperation_rate) > self._expected_defect_payoff(cooperation_rate):
            return Action.C
        return Action.D

    def _detect_punishment_trigger(self, history, my_last_action, cooperation_rate):
        """Detect if punishment should be triggered."""
        if my_last_action and any((not action for action in history.opponent_actions[-1, :])):
            return True
        if cooperation_rate <= 0.3:
            return True
        return False

    def _calculate_punishment_duration(self, cooperation_rate):
        """Calculate punishment duration based on severity."""
        if cooperation_rate <= 0.3:
            return 3
        elif cooperation_rate <= 0.5:
            return 3
        else:
            return 2

    def _am_only_defector(self, history):
        """Check if I've been the only defector for 2+ consecutive rounds."""
        if len(history.my_actions) < 2:
            return False
        rounds_to_check = min(3, len(history.my_actions))
        only_defector_count = 0
        for i in range(1, rounds_to_check + 1):
            round_idx = -i
            if not history.my_actions[round_idx] and all(history.opponent_actions[round_idx, :]):
                only_defector_count += 1
            else:
                break
        return only_defector_count >= 2

    def _expected_coop_payoff(self, cooperation_rate):
        """Calculate expected payoff from cooperating."""
        k = self.game_description.k
        n = self.game_description.n_players
        expected_cooperators = cooperation_rate * n
        return 0 + k / n * expected_cooperators

    def _expected_defect_payoff(self, cooperation_rate):
        """Calculate expected payoff from defecting."""
        k = self.game_description.k
        n = self.game_description.n_players
        expected_cooperators = cooperation_rate * (n - 1)
        return 1 + k / n * expected_cooperators

class Strategy_AGGRESSIVE_60(BaseStrategy):
    """
    Aggressive Punisher Strategy - A conditional aggression strategy that starts with measured 
    cooperation to identify opponents, then aggressively punishes defectors while maximizing 
    personal gain. Defaults to defection with high profitability thresholds for cooperation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.exploration_rounds = max(3, math.ceil(0.2 * self.r))
        self.endgame_rounds = math.ceil(0.15 * self.r)
        self.trust_threshold = 0.6
        self.cooperation_recovery_threshold = 0.5
        self.low_cooperation_threshold = 0.4
        self.profitability_bonus = 0.1
        self.punishment_rounds_left = 0
        self.betrayal_count = 0
        self.betrayal_window = []
        self.pure_defect_mode = False
        self.last_probe_round = -10
        self.threshold_adjustment = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if history is None:
            return Action.C
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        total_players = self.n
        last_round_coop_rate = last_round_cooperators / (total_players - 1)
        if self.r <= 5:
            return Action.D
        if self._detect_all_defect_environment(history):
            if current_round - self.last_probe_round >= random.choice([7, 8, 9, 10]):
                self.last_probe_round = current_round
                return Action.C
            return Action.D
        if current_round >= self.r - self.endgame_rounds:
            return Action.D
        if self.punishment_rounds_left > 0:
            self.punishment_rounds_left -= 1
            return Action.D
        if current_round < self.exploration_rounds:
            if current_round == 1:
                return Action.C if last_round_coop_rate >= 0.5 else Action.D
            else:
                return Action.C if last_round_coop_rate >= 0.5 else Action.D
        if self._should_punish(history):
            return Action.D
        if self._all_cooperation_conditions_met(history, current_round):
            return Action.C
        return Action.D

    def _detect_all_defect_environment(self, history):
        """Detect if no one cooperated for 3 consecutive rounds"""
        if history.round_number < 3:
            return False
        for i in range(3):
            round_cooperators = sum(history.opponent_actions[-(i + 1), :])
            if round_cooperators > 0:
                return False
        return True

    def _should_punish(self, history):
        """Check if we should punish based on various triggers"""
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        total_opponents = self.n - 1
        last_round_coop_rate = last_round_cooperators / total_opponents
        if len(history.my_actions) > 0 and history.my_actions[-1] and (last_round_coop_rate < 1.0):
            self.punishment_rounds_left = max(self.punishment_rounds_left, 1)
            self.betrayal_window.append(history.round_number)
            self.betrayal_window = [r for r in self.betrayal_window if history.round_number - r < 5]
            if len(self.betrayal_window) >= 2:
                self.punishment_rounds_left = max(self.punishment_rounds_left, 3)
        if last_round_coop_rate < self.low_cooperation_threshold:
            return True
        if history.round_number >= 3:
            rates = []
            for i in range(3):
                round_idx = -(i + 1)
                coop_count = sum(history.opponent_actions[round_idx, :])
                rates.append(coop_count / total_opponents)
            if len(rates) >= 3 and rates[0] < rates[1] < rates[2]:
                self.pure_defect_mode = True
                return True
        return False

    def _all_cooperation_conditions_met(self, history, current_round):
        """Check if all conditions for cooperation are met"""
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        total_opponents = self.n - 1
        last_round_coop_rate = last_round_cooperators / total_opponents
        predicted_cooperators = self._predict_cooperators(history)
        expected_coop_payoff = 0 + self.k / self.n * predicted_cooperators
        expected_defect_payoff = 1 + self.k / self.n * max(0, predicted_cooperators - 1)
        profitability_threshold = 1.0 + self.profitability_bonus + self.threshold_adjustment
        if expected_coop_payoff <= profitability_threshold * expected_defect_payoff:
            return False
        adjusted_trust_threshold = self.trust_threshold
        if self.n <= 4:
            adjusted_trust_threshold = 0.7
        if last_round_coop_rate < adjusted_trust_threshold:
            return False
        if history.round_number >= 2:
            prev_coop_rate = sum(history.opponent_actions[-2, :]) / total_opponents
            if last_round_coop_rate < prev_coop_rate - 0.05:
                return False
        my_defect_rate = sum(1 - history.my_actions) / len(history.my_actions)
        group_defect_rates = []
        for player in range(total_opponents):
            player_defect_rate = sum(1 - history.opponent_actions[:, player]) / history.round_number
            group_defect_rates.append(player_defect_rate)
        avg_group_defect_rate = sum(group_defect_rates) / len(group_defect_rates)
        if my_defect_rate >= avg_group_defect_rate:
            return False
        return True

    def _predict_cooperators(self, history):
        """Predict number of cooperators this round based on recent trends"""
        if history.round_number == 0:
            return self.n / 2
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        predicted_total = last_round_cooperators + 1
        return min(predicted_total, self.n)

class Strategy_AGGRESSIVE_61(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Ruthless Opportunist"
    
    Maximizes personal payoffs through aggressive exploitation of cooperative opponents
    while minimizing vulnerability to exploitation. Defaults to defection unless
    cooperation provides clear personal advantage.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.punishment_counter = {}

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        if current_round >= self.r - 2:
            return Action.D
        last_round_idx = current_round - 1
        last_round_cooperators = sum(history.opponent_actions[last_round_idx, :])
        if history.my_actions[last_round_idx]:
            last_round_cooperators += 1
        cooperation_rate_last_round = last_round_cooperators / self.n
        if current_round <= min(5, self.r - 2):
            if cooperation_rate_last_round >= 0.5:
                return Action.D
            elif cooperation_rate_last_round < 0.3:
                return Action.D
            else:
                my_last_payoff = history.my_payoffs[last_round_idx]
                avg_opponent_payoff = np.mean(history.opponent_payoffs[last_round_idx, :])
                average_payoff_last_round = (my_last_payoff + avg_opponent_payoff * (self.n - 1)) / self.n
                if my_last_payoff < average_payoff_last_round:
                    return Action.D
                else:
                    return Action.D
        cooperation_threshold = max(0.4, self.k / self.n)
        recent_rounds = min(3, current_round)
        recent_cooperators = 0
        total_recent_players = 0
        for i in range(recent_rounds):
            round_idx = current_round - 1 - i
            round_cooperators = sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                round_cooperators += 1
            recent_cooperators += round_cooperators
            total_recent_players += self.n
        recent_cooperation_rate = recent_cooperators / total_recent_players if total_recent_players > 0 else 0
        if current_round > 1:
            prev_round_idx = current_round - 2
            if current_round >= 2 and history.my_actions[prev_round_idx]:
                for j in range(self.n - 1):
                    if not history.opponent_actions[prev_round_idx, j]:
                        if j not in self.punishment_counter:
                            self.punishment_counter[j] = 0
                        self.punishment_counter[j] += 1
            total_punishment = sum(self.punishment_counter.values())
            if total_punishment >= self.n / 2:
                return Action.D
        if recent_cooperation_rate >= cooperation_threshold:
            my_cumulative_payoff = sum(history.my_payoffs)
            max_opponent_cumulative = 0
            for j in range(self.n - 1):
                opponent_cumulative = sum(history.opponent_payoffs[:, j])
                if opponent_cumulative > max_opponent_cumulative:
                    max_opponent_cumulative = opponent_cumulative
            if my_cumulative_payoff < max_opponent_cumulative * 0.95:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_AGGRESSIVE_62(BaseStrategy):
    """
    Aggressive Exploitative Strategy: "Predator"
    
    Views the game as a zero-sum competition, exploiting others' cooperation while
    strategically minimizing own contributions. Uses adaptive thresholds and reputation
    tracking to maximize personal payoffs.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.threshold = (self.n - 1) / self.n * 0.7
        self.min_cooperators = math.ceil(self.n * self.k / (self.k + 1))
        self.opponent_defection_rates = {}

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if history is None:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        total_rounds = history.round_number
        total_cooperators = np.sum(history.opponent_actions) + np.sum(history.my_actions)
        coop_rate = total_cooperators / (self.n * total_rounds)
        self._update_reputation_tracking(history)
        predicted_cooperators = self._predict_cooperators(history)
        if current_round == self.r - 2:
            return self._penultimate_round_decision(history, predicted_cooperators)
        return self._main_decision_logic(history, coop_rate, predicted_cooperators, current_round)

    def _update_reputation_tracking(self, history: PlayerHistory):
        """Update defection rates for each opponent."""
        total_rounds = history.round_number
        for player_idx in range(self.n - 1):
            defections = np.sum(~history.opponent_actions[:, player_idx])
            self.opponent_defection_rates[player_idx] = defections / total_rounds

    def _predict_cooperators(self, history: PlayerHistory):
        """Estimate how many players will cooperate this round."""
        if history.round_number < 2:
            total_cooperators = np.sum(history.opponent_actions) + np.sum(history.my_actions)
            coop_rate = total_cooperators / (self.n * history.round_number)
            return int(coop_rate * self.n)
        recent_rounds = min(3, history.round_number)
        recent_cooperators = []
        for round_idx in range(history.round_number - recent_rounds, history.round_number):
            round_cooperators = np.sum(history.opponent_actions[round_idx, :])
            if round_idx < len(history.my_actions) and history.my_actions[round_idx]:
                round_cooperators += 1
            recent_cooperators.append(round_cooperators)
        predicted = int(np.mean(recent_cooperators))
        return max(0, min(self.n, predicted))

    def _penultimate_round_decision(self, history: PlayerHistory, predicted_cooperators):
        """Special logic for round r-1."""
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        if len(history.my_actions) > 0 and history.my_actions[-1]:
            last_round_cooperators += 1
        condition1 = last_round_cooperators >= self.n - 1
        coop_payoff = 0 + self.k / self.n * (predicted_cooperators + 1)
        defect_payoff = 1 + self.k / self.n * predicted_cooperators
        condition2 = coop_payoff > defect_payoff * 1.2
        condition3 = all((rate <= 0.4 for rate in self.opponent_defection_rates.values()))
        if condition1 and condition2 and condition3:
            return Action.C
        else:
            return Action.D

    def _main_decision_logic(self, history: PlayerHistory, coop_rate, predicted_cooperators, current_round):
        """Main decision logic for standard rounds."""
        total_rounds = history.round_number
        in_punishment_mode = any((rate > 0.6 for rate in self.opponent_defection_rates.values()))
        momentum_cooperate = False
        if total_rounds >= 3:
            recent_rates = []
            for i in range(3):
                round_idx = total_rounds - 3 + i
                round_cooperators = np.sum(history.opponent_actions[round_idx, :])
                if round_idx < len(history.my_actions) and history.my_actions[round_idx]:
                    round_cooperators += 1
                recent_rates.append(round_cooperators / self.n)
            if len(recent_rates) == 3 and recent_rates[2] > recent_rates[1] > recent_rates[0]:
                if recent_rates[2] > self.threshold:
                    momentum_cooperate = True
        endgame_start = self.r - math.ceil(self.r / 4)
        endgame_penalty = 0
        if current_round >= endgame_start:
            rounds_into_endgame = current_round - endgame_start + 1
            endgame_penalty = rounds_into_endgame * 0.1
        effective_threshold = self.threshold + endgame_penalty
        basic_cooperation_condition = coop_rate >= effective_threshold and predicted_cooperators >= self.min_cooperators
        if self.n <= 4:
            basic_cooperation_condition = coop_rate >= 0.8 and predicted_cooperators >= self.min_cooperators
        if (basic_cooperation_condition or momentum_cooperate) and (not in_punishment_mode):
            return Action.C
        else:
            return Action.D

class Strategy_AGGRESSIVE_63(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "PREDATOR"
    
    Treats the game as zero-sum competition, exploiting cooperation opportunities
    while strategically cooperating only to induce profitable situations.
    Defaults to defection with sophisticated exploitation patterns.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        round_num = history.round_number + 1
        if round_num <= 3:
            return Action.D
        if round_num >= self.r - 1:
            return Action.D
        return self._adaptive_predation(history)

    def _adaptive_predation(self, history: PlayerHistory) -> Action:
        coop_rate = self._calculate_cooperation_rate(history)
        exploitation_threshold = self._get_exploitation_threshold()
        if coop_rate >= exploitation_threshold:
            return Action.D
        if coop_rate < 0.2:
            return self._baiting_strategy(history)
        return self._apply_secondary_rules(history)

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        recent_rounds = min(3, len(history.opponent_actions))
        if recent_rounds == 0:
            return 0.0
        start_idx = len(history.opponent_actions) - recent_rounds
        recent_actions = history.opponent_actions[start_idx:]
        total_cooperations = np.sum(recent_actions)
        total_possible = recent_rounds * (self.n - 1)
        return total_cooperations / total_possible if total_possible > 0 else 0.0

    def _get_exploitation_threshold(self) -> float:
        if self.k > 1.8:
            return 0.3
        elif self.k <= 1.2:
            return 0.7
        else:
            return 0.4

    def _baiting_strategy(self, history: PlayerHistory) -> Action:
        round_num = history.round_number + 1
        bait_frequency = 0.25 if self.n <= 4 else 0.5
        if self.n > 8:
            bait_frequency *= 1.5
        return Action.C if random.random() < bait_frequency else Action.D

    def _apply_secondary_rules(self, history: PlayerHistory) -> Action:
        if self._is_cooperation_increasing(history):
            return Action.D
        if self._is_being_punished(history):
            if self._should_reset_punishment(history):
                return Action.C
            return Action.D
        consistent_cooperators = self._count_consistent_cooperators(history)
        if 1 <= consistent_cooperators <= 2:
            round_num = history.round_number + 1
            if round_num % 4 == 0:
                return Action.C
        return Action.D

    def _is_cooperation_increasing(self, history: PlayerHistory) -> bool:
        if len(history.opponent_actions) < 2:
            return False
        recent_coop = np.sum(history.opponent_actions[-1])
        prev_coop = np.sum(history.opponent_actions[-2])
        return recent_coop > prev_coop

    def _is_being_punished(self, history: PlayerHistory) -> bool:
        if len(history.opponent_actions) < 2:
            return False
        if len(history.opponent_actions) >= 3:
            recent_coop = np.sum(history.opponent_actions[-1])
            prev_coop = np.sum(history.opponent_actions[-2])
            if prev_coop > 0:
                drop_rate = (prev_coop - recent_coop) / prev_coop
                return drop_rate > 0.5
        return False

    def _should_reset_punishment(self, history: PlayerHistory) -> bool:
        return len(history.my_actions) > 0 and (not history.my_actions[-1])

    def _count_consistent_cooperators(self, history: PlayerHistory) -> int:
        if len(history.opponent_actions) < 3:
            return 0
        recent_rounds = history.opponent_actions[-3:]
        consistent_count = 0
        for player_idx in range(self.n - 1):
            player_coops = np.sum(recent_rounds[:, player_idx])
            if player_coops >= 2:
                consistent_count += 1
        return consistent_count

class Strategy_AGGRESSIVE_64(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "PREDATOR"
    
    Treats the public goods game as a resource extraction opportunity.
    Uses three phases: Initial Exploitation (always defect first 3 rounds),
    Adaptive Exploitation (conditional defection based on cooperation rates),
    and Endgame Extraction (always defect final 2 rounds).
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number + 1
        if current_round <= 3:
            return Action.D
        if current_round > self.r - 2:
            return Action.D
        return self._adaptive_exploitation(history, current_round)

    def _adaptive_exploitation(self, history: PlayerHistory, current_round: int) -> Action:
        last_3_rounds = min(3, len(history.opponent_actions))
        recent_actions = history.opponent_actions[-last_3_rounds:, :]
        total_possible = last_3_rounds * (self.n - 1)
        cooperation_rate = np.sum(recent_actions) / total_possible if total_possible > 0 else 0
        cooperation_threshold = 0.6
        if self.n <= 3:
            cooperation_threshold *= 0.8
        if self.k <= 1.5:
            return Action.D if random.random() > 0.05 else Action.C
        if self.k > 0.8 * self.n:
            cooperation_threshold *= 0.8
        if len(history.my_payoffs) >= 3:
            recent_payoffs = history.my_payoffs[-3:]
            if len(recent_payoffs) >= 2:
                payoff_trend = recent_payoffs[-1] - recent_payoffs[0]
                if payoff_trend < -0.2:
                    if current_round % 4 == 1:
                        return Action.C
        if cooperation_rate < 0.15:
            if random.random() < 0.3:
                return Action.C
        if cooperation_rate >= cooperation_threshold:
            if len(history.my_payoffs) > 0 and len(history.opponent_payoffs) > 0:
                my_last_payoff = history.my_payoffs[-1]
                avg_opponent_payoff = np.mean(history.opponent_payoffs[-1, :])
                if my_last_payoff >= avg_opponent_payoff:
                    return Action.D
            return Action.D
        elif cooperation_rate >= 0.3:
            if current_round % 3 == 1:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_AGGRESSIVE_65(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "PREDATOR"
    
    An aggressive exploiter that maximizes personal payoff by strategically free-riding
    on others' cooperation while punishing those who threaten profitable arrangements.
    Always defects in first and last rounds, and uses dynamic thresholds to exploit
    cooperative opponents while destabilizing coalitions.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.base_exploitation_threshold = (self.n - 1) / (self.k * self.n)
        self.current_threshold = self.base_exploitation_threshold
        self.punishment_rounds_left = 0
        self.endgame_start = max(1, math.floor(self.r / 5))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        if self.punishment_rounds_left > 0:
            self.punishment_rounds_left -= 1
            return Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        last_round_coop_rate = last_round_cooperators / self.n
        adjusted_threshold = self._adjust_threshold_for_parameters()
        if len(history.my_actions) >= 2:
            prev_cooperators = sum(history.opponent_actions[-2, :])
            cooperator_drop = prev_cooperators - last_round_cooperators
            if cooperator_drop >= self.n / 3:
                self.punishment_rounds_left = 1
                return Action.D
        if current_round >= self.r - self.endgame_start:
            if last_round_coop_rate < 0.8:
                return Action.D
            if random.random() < 0.25:
                return Action.D
        if last_round_coop_rate < adjusted_threshold:
            return Action.D
        if len(history.my_actions) >= 1 and history.my_actions[-1]:
            my_last_payoff = history.my_payoffs[-1]
            if my_last_payoff >= self.k / self.n:
                if len(history.my_actions) >= 2:
                    prev_prev_cooperators = sum(history.opponent_actions[-2, :]) if len(history.opponent_actions) >= 2 else 0
                    rate_change = last_round_cooperators - prev_prev_cooperators
                    if rate_change < -1:
                        return Action.D
        if len(history.my_actions) >= 3:
            recent_coop_rates = []
            for i in range(min(3, len(history.opponent_actions))):
                recent_cooperators = sum(history.opponent_actions[-(i + 1), :])
                recent_coop_rates.append(recent_cooperators / self.n)
            avg_recent_coop = np.mean(recent_coop_rates)
            if avg_recent_coop < 0.3:
                adjusted_threshold *= 0.9
            elif self._consistently_above_average(history):
                adjusted_threshold *= 1.05
        if last_round_coop_rate >= adjusted_threshold:
            return Action.C
        else:
            return Action.D

    def _adjust_threshold_for_parameters(self):
        """Adjust exploitation threshold based on game parameters"""
        threshold = self.current_threshold
        if self.n <= 3:
            threshold = 0.8
        elif self.n > 10:
            threshold = (self.n - 2) / (self.k * self.n)
        elif self.k > 0.8 * self.n:
            threshold = 0.6
        elif self.k < 1.5:
            threshold = 0.9
        return threshold

    def _consistently_above_average(self, history):
        """Check if we're consistently earning above-average payoffs"""
        if len(history.my_payoffs) < 3:
            return False
        my_recent_avg = np.mean(history.my_payoffs[-3:])
        total_recent_payoffs = []
        for i in range(min(3, len(history.opponent_payoffs))):
            round_avg = np.mean(history.opponent_payoffs[-(i + 1), :])
            total_recent_payoffs.append(round_avg)
        if len(total_recent_payoffs) > 0:
            opponent_avg = np.mean(total_recent_payoffs)
            return my_recent_avg > opponent_avg
        return False

class Strategy_AGGRESSIVE_66(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "PREDATOR"
    
    This strategy treats the public goods game as a zero-sum competition, 
    exploiting cooperative players while adapting to competitive environments.
    Uses three phases: initial exploitation, adaptive predation, and endgame extraction.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.punishment_detected = False
        self.consecutive_defections = 0
        self.high_k_threshold = self.n * 0.8
        self.medium_k_threshold = self.n * 0.4

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round <= 2:
            return Action.D
        if current_round >= self.r - 2:
            return Action.D
        return self._adaptive_predation_decision(history, current_round)

    def _adaptive_predation_decision(self, history: PlayerHistory, current_round: int) -> Action:
        if self.consecutive_defections > 0:
            self.consecutive_defections -= 1
            return Action.D
        cooperation_rate = self._get_cooperation_rate(history)
        exploitation_potential = self._get_exploitation_potential(history)
        threat_level = self._get_threat_level(history)
        self._check_punishment(history)
        n_opponents = self.n - 1
        if exploitation_potential >= n_opponents * 0.6 and threat_level < 0.4:
            return Action.D
        elif exploitation_potential >= n_opponents * 0.3 and threat_level < 0.6:
            if self._should_continue_exploitation(history):
                return Action.D
            elif current_round % 4 == 0:
                return Action.C
            else:
                return Action.D
        elif cooperation_rate < 0.2:
            return Action.D
        elif current_round % 3 == 0:
            return Action.C
        else:
            return Action.D

    def _get_cooperation_rate(self, history: PlayerHistory) -> float:
        """Get cooperation rate in the last round"""
        if len(history.opponent_actions) == 0:
            return 0.0
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        return last_round_cooperators / (self.n - 1)

    def _get_exploitation_potential(self, history: PlayerHistory) -> float:
        """Get average number of cooperators over the last 3 rounds"""
        if len(history.opponent_actions) == 0:
            return 0.0
        start_idx = max(0, len(history.opponent_actions) - 3)
        recent_rounds = history.opponent_actions[start_idx:, :]
        if len(recent_rounds) == 0:
            return 0.0
        total_cooperators = np.sum(recent_rounds)
        return total_cooperators / len(recent_rounds)

    def _get_threat_level(self, history: PlayerHistory) -> float:
        """Get percentage of opponents who defected in response to high defection rates"""
        if len(history.opponent_actions) < 2:
            return 0.0
        last_round_defectors = np.sum(history.opponent_actions[-1, :] == False)
        threat_level = last_round_defectors / (self.n - 1)
        return threat_level

    def _check_punishment(self, history: PlayerHistory) -> None:
        """Check if coordinated punishment was detected"""
        if len(history.my_actions) < 2:
            return
        if history.my_actions[-1] == True and len(history.opponent_actions) >= 2:
            prev_coop_rate = np.sum(history.opponent_actions[-2, :]) / (self.n - 1)
            curr_coop_rate = np.sum(history.opponent_actions[-1, :]) / (self.n - 1)
            if prev_coop_rate - curr_coop_rate > 0.3:
                self.punishment_detected = True
                rounds_remaining = self.r - len(history.my_actions)
                self.consecutive_defections = min(3, rounds_remaining)

    def _should_continue_exploitation(self, history: PlayerHistory) -> bool:
        """Determine if exploitation should continue based on recent payoffs"""
        if len(history.my_payoffs) == 0:
            return True
        all_cooperate_payoff = 0 + self.k / self.n * self.n
        previous_payoff = history.my_payoffs[-1]
        threshold = all_cooperate_payoff * 0.8
        return previous_payoff > threshold

class Strategy_AGGRESSIVE_67(BaseStrategy):
    """
    RUTHLESS EXPLOITER: An aggressive strategy that maximizes personal payoff through 
    strategic exploitation while maintaining minimal cooperation to prevent system collapse.
    Operates in three phases: reconnaissance, exploitation, and final exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.recon_end = max(2, math.floor(0.1 * self.r))
        self.exploitation_end = math.floor(0.8 * self.r)
        self.player_types = ['UNKNOWN'] * (self.n - 1)
        self.retaliation_count = 0
        self.sucker_targets = set()
        self.profit_threshold = 0.8
        self.collective_punishment_threshold = 0.3
        self.zero_coop_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round <= self.recon_end:
            self._analyze_opponents(history)
            return Action.D
        if current_round > self.exploitation_end:
            return self._final_exploitation_decision(history)
        return self._exploitation_decision(history, current_round)

    def _analyze_opponents(self, history: PlayerHistory):
        """Analyze opponent behaviors during reconnaissance phase"""
        if history.round_number < 2:
            return
        if history.round_number >= 2:
            prev_round = history.round_number - 1
            my_prev_action = history.my_actions[prev_round - 1]
            if not my_prev_action:
                current_defectors = sum(~history.opponent_actions[prev_round, :])
                if prev_round > 0:
                    prev_defectors = sum(~history.opponent_actions[prev_round - 1, :])
                    if current_defectors > prev_defectors:
                        self.retaliation_count += current_defectors - prev_defectors
        for i in range(self.n - 1):
            actions = history.opponent_actions[:history.round_number, i]
            coop_rate = np.mean(actions)
            if coop_rate > 0.8:
                self.player_types[i] = 'NAIVE'
            elif coop_rate < 0.3:
                self.player_types[i] = 'FELLOW_DEFECTOR'
            elif self._is_retaliator(history, i):
                self.player_types[i] = 'RETALIATOR'
            else:
                self.player_types[i] = 'ADAPTIVE'
        if history.round_number >= 3:
            for i in range(self.n - 1):
                recent_rounds = min(3, history.round_number)
                my_recent = history.my_actions[-recent_rounds:]
                opp_recent = history.opponent_actions[-recent_rounds:, i]
                if np.all(~my_recent) and np.all(opp_recent):
                    self.sucker_targets.add(i)

    def _is_retaliator(self, history: PlayerHistory, opponent_idx: int):
        """Check if opponent shows retaliatory behavior"""
        if history.round_number < 3:
            return False
        retaliation_count = 0
        opportunities = 0
        for round_idx in range(1, history.round_number):
            if not history.my_actions[round_idx - 1]:
                opportunities += 1
                if not history.opponent_actions[round_idx, opponent_idx]:
                    retaliation_count += 1
        return opportunities > 0 and retaliation_count / opportunities > 0.6

    def _exploitation_decision(self, history: PlayerHistory, current_round: int):
        """Main exploitation phase decision logic"""
        total_actions = history.round_number * self.n
        total_cooperations = np.sum(history.opponent_actions) + np.sum(history.my_actions)
        cooperation_rate = total_cooperations / total_actions if total_actions > 0 else 0
        if history.round_number >= 3:
            recent_rounds = 3
            recent_coop = np.sum(history.opponent_actions[-recent_rounds:, :]) + np.sum(history.my_actions[-recent_rounds:])
            if recent_coop == 0:
                self.zero_coop_counter += 1
                if self.zero_coop_counter == 1:
                    return Action.C
            else:
                self.zero_coop_counter = 0
        profitability = cooperation_rate * self.k / self.n
        if self.retaliation_count > self.n / 3 and current_round % 5 == 0:
            return Action.C
        if profitability > self.profit_threshold and current_round % 5 != 0:
            return Action.C
        if cooperation_rate < self.collective_punishment_threshold:
            if random.random() < 0.1:
                return Action.C
        return Action.D

    def _final_exploitation_decision(self, history: PlayerHistory):
        """Final phase: maximum exploitation"""
        if history.round_number == self.r - 1:
            recent_coop_rate = np.mean(history.opponent_actions[-5:, :]) if history.round_number >= 5 else 0
            if recent_coop_rate * self.k / self.n > 1:
                return Action.C
        return Action.D

class Strategy_AGGRESSIVE_68(BaseStrategy):
    """
    Aggressive Adaptive Exploitation Strategy - maximizes personal payoff through strategic
    free-riding and punishment mechanisms while maintaining exploitable cooperative environments.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.punishment_rounds_remaining = 0
        self.reliability_scores = {}

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number + 1
        n = self.game_description.n_players
        total_rounds = self.game_description.n_rounds
        if current_round <= 3:
            return Action.D
        if current_round > 0.8 * total_rounds:
            return Action.D
        if self.punishment_rounds_remaining > 0:
            self.punishment_rounds_remaining -= 1
            return Action.D
        cooperation_ratio = self._calculate_cooperation_ratio(history, min(3, history.round_number))
        last_round_cooperators = sum(history.opponent_actions[-1, :]) if history.round_number > 0 else 0
        total_opponents = n - 1
        self._update_reliability_scores(history)
        if self._should_trigger_punishment():
            self.punishment_rounds_remaining = 3
            return Action.D
        if cooperation_ratio >= 0.6:
            if last_round_cooperators > 0.8 * total_opponents:
                return Action.D
            elif last_round_cooperators < 0.5 * total_opponents:
                self.punishment_rounds_remaining = 2
                return Action.D
            else:
                return Action.D
        elif cooperation_ratio >= 0.3:
            if last_round_cooperators >= 0.6 * total_opponents and self._calculate_welfare_loss() > self._get_welfare_threshold():
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _calculate_cooperation_ratio(self, history: PlayerHistory, rounds_to_check: int) -> float:
        """Calculate cooperation ratio from the first rounds_to_check rounds."""
        if history.round_number == 0:
            return 0.0
        total_cooperations = 0
        rounds_checked = min(rounds_to_check, history.round_number)
        total_opponents = self.game_description.n_players - 1
        for round_idx in range(rounds_checked):
            total_cooperations += sum(history.opponent_actions[round_idx, :])
        return total_cooperations / (rounds_checked * total_opponents) if rounds_checked > 0 else 0.0

    def _update_reliability_scores(self, history: PlayerHistory):
        """Update reliability scores for each opponent based on last 5 rounds."""
        if history.round_number == 0:
            return
        n_opponents = self.game_description.n_players - 1
        lookback_rounds = min(5, history.round_number)
        for opponent_idx in range(n_opponents):
            cooperations = 0
            for round_idx in range(history.round_number - lookback_rounds, history.round_number):
                if history.opponent_actions[round_idx, opponent_idx]:
                    cooperations += 1
            self.reliability_scores[opponent_idx] = cooperations / lookback_rounds

    def _should_trigger_punishment(self) -> bool:
        """Check if any opponent's reliability is below threshold."""
        for reliability in self.reliability_scores.values():
            if reliability < 0.4:
                return True
        return False

    def _calculate_welfare_loss(self) -> float:
        """Estimate welfare loss from defecting in current situation."""
        return 1.0

    def _get_welfare_threshold(self) -> float:
        """Get threshold for welfare loss that triggers cooperation."""
        return 0.5

class Strategy_AGGRESSIVE_69(BaseStrategy):
    """
    Opportunistic Predator: An aggressive exploitation strategy that treats cooperation 
    as weakness to exploit. Always defects early, exploits high cooperation rates, 
    and maximizes extraction in endgame while only cooperating when significantly behind.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        rounds_remaining = self.r - current_round
        endgame_threshold = max(2, math.floor(self.r / 10))
        if rounds_remaining <= endgame_threshold:
            return Action.D
        if current_round <= 3:
            return Action.D
        recent_coop_rate = self._get_recent_cooperation_rate(history)
        my_payoff_disadvantage = self._calculate_payoff_gap(history)
        if recent_coop_rate > 0.6:
            return Action.D
        if my_payoff_disadvantage > 0.5 and recent_coop_rate > 0.3:
            return Action.C
        return Action.D

    def _get_recent_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate of opponents in last 3 rounds."""
        rounds_completed = history.round_number
        look_back = min(3, rounds_completed)
        if look_back == 0:
            return 0.0
        recent_actions = history.opponent_actions[-look_back:, :]
        total_actions = recent_actions.size
        cooperations = np.sum(recent_actions)
        return cooperations / total_actions if total_actions > 0 else 0.0

    def _calculate_payoff_gap(self, history: PlayerHistory) -> float:
        """Calculate how much I'm behind the average opponent payoff per round."""
        rounds_completed = history.round_number
        if rounds_completed == 0:
            return 0.0
        my_avg_payoff = np.mean(history.my_payoffs)
        opponent_total_payoffs = np.sum(history.opponent_payoffs, axis=1)
        opponent_avg_payoffs = opponent_total_payoffs / (self.n - 1)
        overall_opponent_avg = np.mean(opponent_avg_payoffs)
        return overall_opponent_avg - my_avg_payoff

class Strategy_AGGRESSIVE_70(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "PREDATOR"
    
    Maximally exploits cooperative environments while avoiding exploitation.
    Uses adaptive punishment and selective participation based on cooperation thresholds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.base_threshold = max(0.6, self.k / self.n + 0.2)
        self.punishment_remaining = 0
        self.recent_coop_rates = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number + 1
        if current_round == self.r:
            return Action.D
        total_players = self.n
        recent_round = history.round_number - 1
        opponent_cooperators = sum(history.opponent_actions[recent_round, :])
        my_last_action = history.my_actions[recent_round]
        total_cooperators = opponent_cooperators + (1 if my_last_action else 0)
        coop_rate = total_cooperators / total_players
        self.recent_coop_rates.append(coop_rate)
        if len(self.recent_coop_rates) > 3:
            self.recent_coop_rates.pop(0)
        if len(self.recent_coop_rates) >= 3:
            if all((rate < 0.2 for rate in self.recent_coop_rates)):
                if coop_rate < 0.4:
                    return Action.D
        breakeven_point = self.k / self.n
        if len(self.recent_coop_rates) >= 3:
            if all((rate < breakeven_point for rate in self.recent_coop_rates[-3:])):
                self.punishment_remaining = 2
        if self.punishment_remaining > 0:
            self.punishment_remaining -= 1
            return Action.D
        threshold = self.base_threshold
        if current_round > 0.8 * self.r:
            threshold += 0.15
        if self.n <= 4:
            threshold -= 0.1
        if self.k > self.n - 1:
            threshold = self.k / self.n + 0.1
        if len(self.recent_coop_rates) >= 3:
            if self.recent_coop_rates[-1] > self.recent_coop_rates[-2] and self.recent_coop_rates[-2] > self.recent_coop_rates[-3]:
                if coop_rate < 0.8:
                    return Action.D
        if coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_AGGRESSIVE_71(BaseStrategy):
    """
    Aggressive Predatory Strategy: "The Exploiter"
    
    This strategy operates on maximum exploitation with minimal vulnerability,
    using sophisticated pattern recognition to identify and exploit cooperative players.
    Always defects in round 1 and final round, with adaptive exploitation in between.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number + 1
        if current_round == self.r:
            return Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        coop_rate = last_round_cooperators / self.n
        threshold = (self.n + 1) / (2 * self.k)
        if current_round >= 4 and len(history.my_actions) >= 3:
            recent_coop_rates = []
            for i in range(3):
                round_idx = -(3 - i)
                round_cooperators = sum(history.opponent_actions[round_idx, :])
                if history.my_actions[round_idx]:
                    round_cooperators += 1
                recent_coop_rates.append(round_cooperators / self.n)
            trend = (recent_coop_rates[-1] - recent_coop_rates[0]) / 2
            if trend > 0.2:
                return Action.C
            if trend < -0.2:
                return Action.D
        if current_round <= 3:
            threshold = 0.4
        if current_round > self.r - 3:
            threshold = 0.6
        if len(history.my_actions) >= 4:
            recent_rates = []
            for i in range(min(4, len(history.my_actions))):
                round_idx = -(4 - i)
                round_cooperators = sum(history.opponent_actions[round_idx, :])
                if history.my_actions[round_idx]:
                    round_cooperators += 1
                recent_rates.append(round_cooperators / self.n)
            if len(recent_rates) == 4:
                max_rate = max(recent_rates)
                min_rate = min(recent_rates)
                if max_rate - min_rate <= 0.1:
                    return Action.D
        if coop_rate >= threshold:
            return Action.C
        else:
            return Action.D

class Strategy_AGGRESSIVE_72(BaseStrategy):
    """
    Predatory Exploitation Strategy (PES) - Aggressively exploits cooperative players while 
    rapidly punishing attempts at exploitation. Operates through three phases: reconnaissance 
    & exploitation, selective parasitism, and endgame extraction.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.exploitability_scores = np.zeros(self.n - 1)
        self.opponent_interactions = np.zeros(self.n - 1)
        self.threat_retaliation_rounds = 0
        self.scorched_earth_mode = False
        self.last_cooperation_round = -10

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        self._update_exploitability_scores(history)
        if self.threat_retaliation_rounds > 0:
            self.threat_retaliation_rounds -= 1
            return Action.D
        if self.scorched_earth_mode:
            return Action.D
        phase1_end = min(5, self.r // 3)
        phase3_start = self.r - max(3, self.r // 5)
        if current_round < phase1_end:
            return self._phase1_decision(history)
        elif current_round >= phase3_start:
            return self._phase3_decision(history)
        else:
            return self._phase2_decision(history)

    def _update_exploitability_scores(self, history: PlayerHistory):
        """Update exploitability scores based on opponent behavior after our defections"""
        if history.round_number < 2:
            return
        if not history.my_actions[-1]:
            for i in range(self.n - 1):
                self.opponent_interactions[i] += 1
                if history.opponent_actions[-1, i]:
                    self.exploitability_scores[i] = (self.exploitability_scores[i] * (self.opponent_interactions[i] - 1) + 1) / self.opponent_interactions[i]
                else:
                    self.exploitability_scores[i] = self.exploitability_scores[i] * (self.opponent_interactions[i] - 1) / self.opponent_interactions[i]

    def _detect_punishment(self, history: PlayerHistory) -> bool:
        """Detect if we're being punished for previous defection"""
        if history.round_number < 2:
            return False
        if not history.my_actions[-2] and len(history.my_payoffs) >= 2:
            return history.my_payoffs[-1] < history.my_payoffs[-2] - 0.1
        return False

    def _get_cooperation_rate(self, history: PlayerHistory, rounds_back: int=1) -> float:
        """Get cooperation rate of opponents in recent rounds"""
        if history.round_number == 0:
            return 0.0
        start_idx = max(0, history.round_number - rounds_back)
        recent_actions = history.opponent_actions[start_idx:]
        return np.mean(recent_actions) if len(recent_actions) > 0 else 0.0

    def _phase1_decision(self, history: PlayerHistory) -> Action:
        """Phase 1: Reconnaissance & Exploitation"""
        current_round = history.round_number
        if self._detect_punishment(history):
            self.threat_retaliation_rounds = 2
        if current_round >= 2:
            cooperation_rate = self._get_cooperation_rate(history)
            if cooperation_rate < 0.3 and np.mean(self.exploitability_scores) < 0.3:
                self.scorched_earth_mode = True
        if current_round >= 1:
            prev_coop_rate = self._get_cooperation_rate(history)
            if prev_coop_rate >= 0.75:
                our_payoff = history.my_payoffs[-1]
                avg_opponent_payoff = np.mean(history.opponent_payoffs[-1])
                if our_payoff > avg_opponent_payoff:
                    return Action.D
        return Action.D

    def _phase2_decision(self, history: PlayerHistory) -> Action:
        """Phase 2: Selective Parasitism"""
        current_round = history.round_number
        if self._detect_punishment(history):
            self.threat_retaliation_rounds = 2
            return Action.D
        if current_round % 7 == 0:
            if random.random() < 0.8:
                return Action.D
            else:
                return Action.C
        highly_exploitable = np.sum(self.exploitability_scores > 0.6)
        if highly_exploitable >= self.n // 2:
            return Action.D
        prev_coop_rate = self._get_cooperation_rate(history)
        if prev_coop_rate >= 0.7:
            defectors = np.sum(history.opponent_actions[-1] == False) + (not history.my_actions[-1])
            if defectors > 1:
                return Action.D
        if len(history.my_payoffs) >= 3:
            recent_avg_payoff = np.mean(history.my_payoffs[-3:])
            threshold = self.k / self.n + 0.3
            if recent_avg_payoff < threshold and current_round - self.last_cooperation_round > 1:
                self.last_cooperation_round = current_round
                return Action.C
        if prev_coop_rate < 0.2 and random.random() < 0.1 and (current_round - self.last_cooperation_round > 1):
            self.last_cooperation_round = current_round
            return Action.C
        return Action.D

    def _phase3_decision(self, history: PlayerHistory) -> Action:
        """Phase 3: Endgame Extraction"""
        current_round = history.round_number
        if current_round == self.r - 1:
            return Action.D
        prev_coop_rate = self._get_cooperation_rate(history)
        if prev_coop_rate > 0.5:
            return Action.D
        if history.round_number >= 2:
            prev_prev_coop_rate = self._get_cooperation_rate(history, 2)
            if prev_prev_coop_rate - prev_coop_rate > 0.3:
                return Action.D
        return Action.D

class Strategy_AGGRESSIVE_73(BaseStrategy):
    """
    Aggressive Adaptive Defection Strategy (AADS)
    
    A ruthlessly opportunistic strategy that maximizes personal payoff while 
    aggressively exploiting cooperative opponents. Always defects in first round
    and endgame, only cooperates when immediately profitable based on recent 
    history and cooperation thresholds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.min_coop = math.ceil(self.n * self.k / (self.n + self.k))
        self.punishment_rounds_left = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        round_number = history.round_number + 1
        if round_number > 0.8 * self.r:
            return Action.D
        if self.r <= 5:
            return Action.D
        if self.n == 2:
            return Action.D
        if self.punishment_rounds_left > 0:
            self.punishment_rounds_left -= 1
            return Action.D
        last_round_cooperators = self._count_total_cooperators(history, -1)
        recent_coop_rate = self._calculate_recent_cooperation_rate(history)
        if self._should_enter_punishment(history):
            self.punishment_rounds_left = 1
            return Action.D
        avg_cooperation = self._calculate_average_cooperation_rate(history)
        if avg_cooperation < 0.3:
            return Action.D
        if last_round_cooperators >= self.min_coop + 1 and recent_coop_rate >= 0.6:
            if self._expected_payoff_cooperation(history) > self._expected_payoff_defection(history):
                return Action.C
        return Action.D

    def _count_total_cooperators(self, history: PlayerHistory, round_idx: int) -> int:
        """Count total cooperators (including self) in specified round."""
        if round_idx >= len(history.my_actions) or round_idx < -len(history.my_actions):
            return 0
        my_action = history.my_actions[round_idx]
        opponent_cooperators = sum(history.opponent_actions[round_idx, :])
        return int(my_action) + int(opponent_cooperators)

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate over last 3 rounds."""
        rounds_to_check = min(3, len(history.my_actions))
        if rounds_to_check == 0:
            return 0.0
        total_cooperators = 0
        total_possible = 0
        for i in range(-rounds_to_check, 0):
            cooperators = self._count_total_cooperators(history, i)
            total_cooperators += cooperators
            total_possible += self.n
        return total_cooperators / total_possible if total_possible > 0 else 0.0

    def _calculate_average_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate overall cooperation rate across all rounds."""
        if len(history.my_actions) == 0:
            return 0.0
        total_cooperators = 0
        total_possible = 0
        for i in range(len(history.my_actions)):
            cooperators = self._count_total_cooperators(history, i)
            total_cooperators += cooperators
            total_possible += self.n
        return total_cooperators / total_possible if total_possible > 0 else 0.0

    def _should_enter_punishment(self, history: PlayerHistory) -> bool:
        """Check if we should enter punishment phase based on recent cooperation attempts."""
        rounds_to_check = min(2, len(history.my_actions))
        for i in range(1, rounds_to_check + 1):
            round_idx = -i
            if round_idx < -len(history.my_actions):
                continue
            if history.my_actions[round_idx]:
                total_cooperators = self._count_total_cooperators(history, round_idx)
                if total_cooperators < self.min_coop + 1:
                    return True
        return False

    def _expected_payoff_cooperation(self, history: PlayerHistory) -> float:
        """Estimate expected payoff if we cooperate based on recent trends."""
        if len(history.my_actions) == 0:
            return 0.0
        recent_avg_cooperators = self._calculate_recent_cooperation_rate(history) * self.n
        expected_total_cooperators = recent_avg_cooperators
        return self.k / self.n * expected_total_cooperators

    def _expected_payoff_defection(self, history: PlayerHistory) -> float:
        """Estimate expected payoff if we defect based on recent trends."""
        if len(history.my_actions) == 0:
            return 1.0
        recent_avg_cooperators = self._calculate_recent_cooperation_rate(history) * self.n
        return 1.0 + self.k / self.n * (recent_avg_cooperators - 1)

class Strategy_AGGRESSIVE_75(BaseStrategy):
    """
    PREDATOR STRATEGY: An aggressive, opportunistic strategy that maximizes personal gain
    by exploiting cooperative opponents while minimizing personal risk through strategic
    reconnaissance, calculated exploitation, and endgame brutality.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.opponent_cooperation_rates = {}
        self.betrayal_counts = {}
        self.grudge_list = set()
        self.reconnaissance_rounds = min(3, max(1, self.n_rounds // 4))
        self.endgame_rounds = 2
        if self.n_players <= 4:
            self.cooperation_threshold = 0.75
            self.reconnaissance_rounds = min(4, self.n_rounds - 2)
        else:
            self.cooperation_threshold = 0.6
        if self.k > self.n_players * 0.7:
            self.high_k_bonus = True
        else:
            self.high_k_bonus = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if self.n_rounds <= 5:
            return self._short_game_strategy(history)
        if current_round < self.reconnaissance_rounds:
            return self._reconnaissance_phase(history)
        if current_round >= self.n_rounds - self.endgame_rounds:
            return Action.D
        return self._exploitation_phase(history)

    def _short_game_strategy(self, history: PlayerHistory) -> Action:
        """Strategy for games with 5 or fewer rounds"""
        if len(history.my_actions) == 0:
            return Action.D
        if len(history.opponent_actions) > 0:
            last_round_cooperators = sum(history.opponent_actions[-1, :])
            cooperation_rate = last_round_cooperators / self.n_players
            if cooperation_rate >= 0.6:
                return Action.C
        return Action.D

    def _reconnaissance_phase(self, history: PlayerHistory) -> Action:
        """Rounds 1-3: Gather intelligence while defecting"""
        self._update_opponent_tracking(history)
        return Action.D

    def _exploitation_phase(self, history: PlayerHistory) -> Action:
        """Main exploitation phase with calculated decisions"""
        self._update_opponent_tracking(history)
        if len(history.my_payoffs) > 0:
            avg_payoff = np.mean(history.my_payoffs)
            if avg_payoff < 1.5:
                return Action.D
        expected_cooperators = self._calculate_expected_cooperators(history)
        exploitable_count = self._count_exploitable_opponents(history)
        cooperation_threshold = self.n_players / 3 if self.high_k_bonus else self.n_players / 2
        if exploitable_count >= self.n_players / 3 and expected_cooperators >= 2:
            return self._maybe_inject_chaos(Action.C)
        elif expected_cooperators >= cooperation_threshold:
            return self._maybe_inject_chaos(Action.C)
        else:
            return Action.D

    def _update_opponent_tracking(self, history: PlayerHistory) -> None:
        """Update opponent behavior tracking"""
        if len(history.opponent_actions) == 0:
            return
        n_opponents = self.n_players - 1
        lookback = min(3, len(history.opponent_actions))
        recent_actions = history.opponent_actions[-lookback:, :]
        for i in range(n_opponents):
            opponent_recent = recent_actions[:, i]
            cooperation_rate = np.mean(opponent_recent)
            self.opponent_cooperation_rates[i] = cooperation_rate
            if len(history.my_actions) > 0:
                for round_idx in range(len(history.my_actions)):
                    if history.my_actions[round_idx] and (not history.opponent_actions[round_idx, i]):
                        self.betrayal_counts[i] = self.betrayal_counts.get(i, 0) + 1
                        if self.betrayal_counts[i] > 2:
                            self.grudge_list.add(i)

    def _calculate_expected_cooperators(self, history: PlayerHistory) -> int:
        """Calculate expected number of cooperators in next round"""
        expected = 0
        n_opponents = self.n_players - 1
        for i in range(n_opponents):
            if i in self.grudge_list:
                continue
            cooperation_rate = self.opponent_cooperation_rates.get(i, 0)
            if cooperation_rate > self.cooperation_threshold:
                expected += 1
        return expected

    def _count_exploitable_opponents(self, history: PlayerHistory) -> int:
        """Count opponents classified as exploitable"""
        if len(history.opponent_actions) < 3:
            return 0
        exploitable = 0
        n_opponents = self.n_players - 1
        for i in range(n_opponents):
            cooperation_rate = self.opponent_cooperation_rates.get(i, 0)
            if cooperation_rate >= 0.67:
                exploitable += 1
        return exploitable

    def _maybe_inject_chaos(self, intended_action: Action) -> Action:
        """Inject random defections to break patterns and confuse opponents"""
        if intended_action == Action.C:
            if random.random() < 0.2:
                return Action.D
        return intended_action

class Strategy_AGGRESSIVE_76(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "PREDATOR"
    
    Maximizes personal payoff by strategically free-riding on others' cooperation
    while minimizing own contributions. Uses conditional cooperation only when
    exploitation opportunities are high, with permanent defection in endgame.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.permanent_defection = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number + 1
        if current_round <= 3:
            return Action.D
        if current_round > self.r - 2:
            return Action.D
        if self.k / self.n <= 0.35:
            return Action.D
        cooperators_last_round = sum(history.opponent_actions[-1, :])
        ER = cooperators_last_round / (self.n - 1)
        if ER < 0.4:
            self.permanent_defection = True
        if self.permanent_defection:
            return Action.D
        cooperation_threshold = 0.6
        if self.n <= 4:
            cooperation_threshold = 0.75
        if self.k / self.n > 0.6:
            cooperation_threshold = 0.5
        my_last_action_was_defect = not history.my_actions[-1]
        if ER >= cooperation_threshold and my_last_action_was_defect and (self.k / self.n > 0.4):
            return Action.C
        else:
            return Action.D

class Strategy_AGGRESSIVE_77(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Predatory Defector"
    
    This strategy maximally exploits cooperation while minimizing own vulnerability.
    Defaults to defection unless compelling evidence suggests cooperation is clearly profitable.
    Features aggressive endgame defection and low cooperation thresholds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.defection_threshold = 0.4
        self.endgame_start = math.floor(game_description.n_rounds * 0.75)
        self.min_payoff_advantage = 0.2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round >= self.endgame_start:
            return Action.D
        if current_round <= 2:
            if current_round == 1:
                round_1_coop_rate = self._calculate_cooperation_rate(history, -1)
                if round_1_coop_rate < 0.75:
                    return Action.D
            else:
                recent_coop_rate = self._calculate_cooperation_rate(history, -1)
                if recent_coop_rate < 0.75:
                    return Action.D
        current_coop_rate = self._calculate_cooperation_rate(history, -1)
        stability = self._check_cooperation_stability(history)
        payoff_advantage = self._calculate_payoff_advantage(history, current_coop_rate)
        if current_coop_rate < 0.5:
            return Action.D
        if self._was_recently_exploited(history):
            return Action.D
        if current_coop_rate >= 0.6 and stability and (payoff_advantage >= self.min_payoff_advantage):
            return Action.C
        return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory, round_offset: int) -> float:
        """Calculate cooperation rate for a specific round (negative offset from current)."""
        if len(history.opponent_actions) == 0:
            return 0.0
        round_idx = max(0, len(history.opponent_actions) + round_offset)
        if round_idx >= len(history.opponent_actions):
            return 0.0
        cooperators = np.sum(history.opponent_actions[round_idx, :])
        return cooperators / self.game_description.n_players

    def _check_cooperation_stability(self, history: PlayerHistory) -> bool:
        """Check if cooperation has been stable or increasing over recent rounds."""
        if len(history.opponent_actions) < 2:
            return False
        rounds_to_check = min(3, len(history.opponent_actions))
        rates = []
        for i in range(rounds_to_check):
            rate = self._calculate_cooperation_rate(history, -(i + 1))
            rates.append(rate)
        if len(rates) >= 2:
            recent_rate = rates[0]
            older_rate = rates[-1]
            return recent_rate >= older_rate - 0.1
        return False

    def _calculate_payoff_advantage(self, history: PlayerHistory, coop_rate: float) -> float:
        """Calculate expected payoff advantage of cooperation over defection."""
        n = self.game_description.n_players
        k = self.game_description.k
        expected_cooperators_if_coop = coop_rate * n + 1
        expected_cooperators_if_defect = coop_rate * n
        payoff_coop = 0 + k / n * expected_cooperators_if_coop
        payoff_defect = 1 + k / n * expected_cooperators_if_defect
        if payoff_defect == 0:
            return 0
        return (payoff_coop - payoff_defect) / payoff_defect

    def _was_recently_exploited(self, history: PlayerHistory) -> bool:
        """Check if I was exploited in recent rounds (cooperated but got lower payoff)."""
        if len(history.my_actions) < 1:
            return False
        rounds_to_check = min(2, len(history.my_actions))
        for i in range(rounds_to_check):
            round_idx = len(history.my_actions) - 1 - i
            if history.my_actions[round_idx]:
                my_payoff = history.my_payoffs[round_idx]
                cooperators_in_round = np.sum(history.opponent_actions[round_idx, :])
                n = self.game_description.n_players
                k = self.game_description.k
                hypothetical_defect_payoff = 1 + k / n * cooperators_in_round
                if hypothetical_defect_payoff > my_payoff + 0.1:
                    return True
        return False

class Strategy_AGGRESSIVE_78(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "PREDATOR"
    
    Treats the public goods game as zero-sum competition, exploiting cooperative 
    players while minimizing personal contributions. Only cooperates when 
    mathematically profitable.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.opponent_cooperation_rates = None
        self.consecutive_defection_count = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if self.opponent_cooperation_rates is None:
            self.opponent_cooperation_rates = np.zeros(self.n - 1)
        for opponent_idx in range(self.n - 1):
            total_rounds = len(history.my_actions)
            cooperation_count = sum(history.opponent_actions[:, opponent_idx])
            self.opponent_cooperation_rates[opponent_idx] = cooperation_count / total_rounds
        if current_round >= self.r - 2:
            return Action.D
        exploitable_count = sum(self.opponent_cooperation_rates >= 0.7)
        reciprocators_likely_to_cooperate = 0
        if len(history.my_actions) >= 2:
            for opponent_idx in range(self.n - 1):
                if len(history.my_actions) >= 2:
                    my_prev_action = history.my_actions[-2]
                    opponent_current = history.opponent_actions[-1, opponent_idx]
                    if my_prev_action == opponent_current:
                        reciprocators_likely_to_cooperate += 0.5
        likely_cooperators = exploitable_count + reciprocators_likely_to_cooperate
        expected_public_good_return = self.k / self.n * likely_cooperators
        should_cooperate_threshold = expected_public_good_return > 1.0
        cooperation_cascade = False
        if len(history.my_actions) >= 2:
            recent_coop_rate = sum(history.opponent_actions[-1, :]) / (self.n - 1)
            prev_coop_rate = sum(history.opponent_actions[-2, :]) / (self.n - 1)
            if recent_coop_rate - prev_coop_rate > 0.3:
                cooperation_cascade = True
        if should_cooperate_threshold and current_round <= self.r - 2:
            self.consecutive_defection_count = 0
            return Action.C
        elif cooperation_cascade and expected_public_good_return > 0.8:
            self.consecutive_defection_count = 0
            return Action.C
        else:
            middle_game = 0.3 * self.r <= current_round <= 0.7 * self.r
            if middle_game and self.consecutive_defection_count >= 4 and (expected_public_good_return > 0.8):
                self.consecutive_defection_count = 0
                return Action.C
            else:
                self.consecutive_defection_count += 1
                return Action.D

class Strategy_AGGRESSIVE_79(BaseStrategy):
    """
    Aggressive Predatory Strategy: "Exploit-and-Punish"
    
    Maximizes personal gains through systematic exploitation and punishment of cooperators.
    Uses three phases: early aggression, predatory exploitation, and endgame punishment.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.early_phase_end = min(3, self.r // 3)
        self.endgame_start = self.r - max(2, self.r // 5)
        self.exploitation_mode = False
        self.exploitation_round_count = 0
        self.target_player = None
        self.high_coop_threshold = 0.6
        self.low_coop_threshold = 0.3
        self.target_coop_threshold = 0.7

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round <= self.early_phase_end:
            return Action.D
        if current_round >= self.endgame_start:
            return Action.D
        return self._predatory_exploitation_logic(history)

    def _predatory_exploitation_logic(self, history):
        if len(history.opponent_actions) > 0:
            last_round_cooperators = np.sum(history.opponent_actions[-1, :])
            if history.my_actions[-1]:
                last_round_cooperators += 1
            cooperation_rate = last_round_cooperators / self.n
        else:
            cooperation_rate = 0.0
        target_action = self._check_target_player(history)
        if target_action is not None:
            return target_action
        if self.exploitation_mode:
            return self._handle_exploitation_cycle(history, cooperation_rate)
        if cooperation_rate >= self.high_coop_threshold and self._should_enter_exploitation_mode(history):
            self.exploitation_mode = True
            self.exploitation_round_count = 1
            return Action.C
        if cooperation_rate < self.low_coop_threshold and history.round_number < self.endgame_start - 5:
            if random.random() < 0.2:
                return Action.C
        return Action.D

    def _check_target_player(self, history):
        if len(history.opponent_actions) < 5:
            return None
        recent_rounds = min(5, len(history.opponent_actions))
        for player_idx in range(self.n - 1):
            recent_actions = history.opponent_actions[-recent_rounds:, player_idx]
            coop_rate = np.mean(recent_actions)
            if coop_rate > self.target_coop_threshold:
                self.target_player = player_idx
                if history.opponent_actions[-1, player_idx]:
                    return Action.D
                else:
                    return Action.C
        self.target_player = None
        return None

    def _handle_exploitation_cycle(self, history, cooperation_rate):
        self.exploitation_round_count += 1
        if self.exploitation_round_count <= 3:
            if self.exploitation_round_count == 1:
                return Action.C
            else:
                return Action.D
        elif cooperation_rate >= self.high_coop_threshold:
            self.exploitation_round_count = 1
            return Action.C
        else:
            self.exploitation_mode = False
            return Action.D

    def _should_enter_exploitation_mode(self, history):
        if len(history.my_payoffs) == 0:
            return True
        my_total_payoff = np.sum(history.my_payoffs)
        opponent_total_payoffs = np.sum(history.opponent_payoffs, axis=0)
        players_ahead = np.sum(opponent_total_payoffs > my_total_payoff)
        my_rank = players_ahead + 1
        return my_rank > self.n / 2

class Strategy_AGGRESSIVE_80(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Opportunistic Predator"
    
    Maximizes individual payoff by exploiting cooperative behavior while minimizing personal risk.
    Treats cooperation as weakness to be punished and defection as strength to be rewarded.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.cooperation_threshold = self.k / self.n_players
        self.observation_window = min(5, max(1, self.n_rounds // 4))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round >= self.n_rounds - 1:
            return Action.D
        window_start = max(0, history.round_number - self.observation_window)
        recent_opponent_actions = history.opponent_actions[window_start:, :]
        total_recent_actions = recent_opponent_actions.size
        if total_recent_actions > 0:
            recent_group_cooperation = np.sum(recent_opponent_actions) / total_recent_actions
        else:
            recent_group_cooperation = 0.0
        if recent_group_cooperation >= self.cooperation_threshold:
            return Action.D
        high_cooperators = 0
        if history.round_number >= 3:
            for player_idx in range(self.n_players - 1):
                player_actions = history.opponent_actions[:, player_idx]
                cooperation_rate = np.mean(player_actions)
                if cooperation_rate > 0.6:
                    high_cooperators += 1
        if high_cooperators > 0 and random.random() < 0.9:
            return Action.D
        endgame_threshold = 0.8 * self.n_rounds
        if current_round > endgame_threshold:
            if random.random() < 0.95:
                return Action.D
        if recent_group_cooperation < 0.3:
            last_3_rounds = max(0, history.round_number - 3)
            recent_my_actions = history.my_actions[last_3_rounds:]
            personal_defection_rate = 1.0 - np.mean(recent_my_actions) if len(recent_my_actions) > 0 else 0.0
            if personal_defection_rate < 0.7 and current_round < self.n_rounds - 1:
                expected_total_cooperators = recent_group_cooperation * (self.n_players - 1)
                expected_coop_payoff = 0 + self.k / self.n_players * (expected_total_cooperators + 1)
                expected_defect_payoff = 1 + self.k / self.n_players * expected_total_cooperators
                if expected_coop_payoff > expected_defect_payoff * 1.1:
                    return Action.C
        return Action.D

class Strategy_AGGRESSIVE_81(BaseStrategy):
    """
    Aggressive Adaptive Strategy: "Opportunistic Punisher"
    
    This strategy aggressively exploits cooperative environments while punishing
    defectors. It starts with defection, adapts based on group cooperation patterns,
    and always defects in the final round to maximize payoffs.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.punishment_phase_remaining = 0
        self.exploitation_mode_remaining = 0
        self.failed_cooperation_count = 0
        self.base_coop_threshold = self.n * (self.n - self.k) / self.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if history is None:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        if self.punishment_phase_remaining > 0:
            self.punishment_phase_remaining -= 1
            return Action.D
        if self.exploitation_mode_remaining > 0:
            self.exploitation_mode_remaining -= 1
            return Action.D
        coop_threshold = self._calculate_cooperation_threshold(current_round)
        recent_coop_rate = self._get_recent_cooperation_rate(history)
        total_coop_rate = self._get_total_cooperation_rate(history)
        last_round_cooperators = self._count_last_round_cooperators(history)
        if self._detect_anti_coordination(history):
            self.exploitation_mode_remaining = 2
            return Action.D
        if last_round_cooperators >= coop_threshold:
            if history.my_actions[-1] and self._was_cooperation_profitable(history):
                return Action.C
            elif not history.my_actions[-1]:
                return Action.C
        if recent_coop_rate >= 0.6 and total_coop_rate >= 0.4:
            return Action.C
        if last_round_cooperators == max(0, coop_threshold - 1):
            return Action.C
        if history.my_actions[-1] and (not self._was_cooperation_profitable(history)):
            self._enter_punishment_phase()
        return Action.D

    def _calculate_cooperation_threshold(self, current_round):
        """Calculate dynamic cooperation threshold based on game phase and parameters."""
        threshold = self.base_coop_threshold
        if self.n <= 3:
            threshold = self.n
        elif self.n > 10:
            threshold = math.floor(threshold * 0.8)
        if self.k >= self.n - 0.5:
            threshold = max(1, threshold - 1)
        elif self.k <= 1.5:
            threshold = threshold + 1
        rounds_remaining = self.r - current_round
        if rounds_remaining <= self.r * 0.2:
            threshold = threshold * 1.5
        if rounds_remaining <= self.r * 0.1:
            threshold = threshold * 2.0
        threshold += self.failed_cooperation_count * 0.5
        return max(1, math.ceil(threshold))

    def _get_recent_cooperation_rate(self, history):
        """Get cooperation rate over last 3 rounds."""
        rounds_to_check = min(3, len(history.my_actions))
        if rounds_to_check == 0:
            return 0.0
        recent_cooperators = 0
        total_possible = 0
        for i in range(rounds_to_check):
            round_idx = -(i + 1)
            cooperators_in_round = np.sum(history.opponent_actions[round_idx, :])
            recent_cooperators += cooperators_in_round
            total_possible += self.n - 1
        return recent_cooperators / total_possible if total_possible > 0 else 0.0

    def _get_total_cooperation_rate(self, history):
        """Get overall cooperation rate from all completed rounds."""
        if len(history.my_actions) == 0:
            return 0.0
        total_cooperators = np.sum(history.opponent_actions)
        total_possible = len(history.my_actions) * (self.n - 1)
        return total_cooperators / total_possible if total_possible > 0 else 0.0

    def _count_last_round_cooperators(self, history):
        """Count cooperators (including self) in the last round."""
        if len(history.my_actions) == 0:
            return 0
        opponent_cooperators = np.sum(history.opponent_actions[-1, :])
        my_cooperation = 1 if history.my_actions[-1] else 0
        return opponent_cooperators + my_cooperation

    def _detect_anti_coordination(self, history):
        """Detect sudden spikes in cooperation that might indicate coordination."""
        if len(history.my_actions) < 2:
            return False
        current_coop_rate = np.sum(history.opponent_actions[-1, :]) / (self.n - 1)
        previous_coop_rate = np.sum(history.opponent_actions[-2, :]) / (self.n - 1)
        return current_coop_rate - previous_coop_rate > 0.4

    def _was_cooperation_profitable(self, history):
        """Check if cooperation in the last round was profitable compared to defection."""
        if len(history.my_actions) == 0 or not history.my_actions[-1]:
            return False
        cooperators_last_round = np.sum(history.opponent_actions[-1, :]) + 1
        actual_payoff = self.k / self.n * cooperators_last_round
        hypothetical_cooperators = cooperators_last_round - 1
        defect_payoff = 1 + self.k / self.n * hypothetical_cooperators
        return actual_payoff >= 0.5 * defect_payoff

    def _enter_punishment_phase(self):
        """Enter punishment phase for failed cooperation."""
        self.punishment_phase_remaining = 3 if self.k <= 1.5 else 2
        self.failed_cooperation_count += 1

class Strategy_AGGRESSIVE_82(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Opportunistic Predator"
    
    Maximizes personal payoff through ruthless exploitation of cooperative opponents
    while minimizing personal risk. Operates in three phases: initial exploitation,
    adaptive predation, and endgame exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        initial_phase_end = min(5, self.r // 3)
        if current_round < initial_phase_end:
            return Action.D
        endgame_phase_start = self.r - max(3, self.r // 5)
        if current_round >= endgame_phase_start:
            return Action.D
        return self._adaptive_predation_decision(history)

    def _adaptive_predation_decision(self, history: PlayerHistory) -> Action:
        cooperation_rate = self._calculate_recent_cooperation_rate(history)
        punishment_risk = self._calculate_punishment_risk(history)
        dei = cooperation_rate * self.k / self.n - punishment_risk
        if self._is_high_cooperation_environment(history):
            if self._should_cooperate_in_high_coop_env(history):
                return Action.C
        if self._has_naive_cooperators(history):
            return Action.D
        if dei > 0.7:
            return Action.C
        else:
            return Action.D

    def _calculate_recent_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate average cooperation rate of opponents over last 3 rounds"""
        rounds_to_check = min(3, history.round_number)
        if rounds_to_check == 0:
            return 0.0
        recent_rounds = history.opponent_actions[-rounds_to_check:]
        total_decisions = recent_rounds.size
        total_cooperations = np.sum(recent_rounds)
        return total_cooperations / total_decisions if total_decisions > 0 else 0.0

    def _calculate_punishment_risk(self, history: PlayerHistory) -> float:
        """Calculate punishment risk based on my recent defection rate"""
        rounds_to_check = min(5, history.round_number)
        if rounds_to_check == 0:
            return 0.0
        recent_my_actions = history.my_actions[-rounds_to_check:]
        defection_rate = 1.0 - np.sum(recent_my_actions) / len(recent_my_actions)
        return 0.3 if defection_rate > 0.8 else 0.0

    def _is_high_cooperation_environment(self, history: PlayerHistory) -> bool:
        """Check if we're in a high cooperation environment (>80%)"""
        if history.round_number == 0:
            return False
        all_opponent_actions = history.opponent_actions.flatten()
        cooperation_rate = np.sum(all_opponent_actions) / len(all_opponent_actions)
        return cooperation_rate > 0.8

    def _should_cooperate_in_high_coop_env(self, history: PlayerHistory) -> bool:
        """Decide whether to cooperate in high cooperation environment"""
        my_cooperation_rate = np.sum(history.my_actions) / len(history.my_actions)
        if my_cooperation_rate >= 0.25:
            return False
        return (history.round_number + 1) % 4 == 0

    def _has_naive_cooperators(self, history: PlayerHistory) -> bool:
        """Check for naive cooperators (>70% cooperation for 3+ rounds)"""
        if history.round_number < 3:
            return False
        recent_rounds = history.opponent_actions[-3:]
        for player_idx in range(recent_rounds.shape[1]):
            player_actions = recent_rounds[:, player_idx]
            cooperation_rate = np.sum(player_actions) / len(player_actions)
            if cooperation_rate > 0.7:
                return True
        return False

class Strategy_AGGRESSIVE_83(BaseStrategy):
    """
    Aggressive Predator Strategy: Maximizes personal gain through systematic exploitation
    of cooperative behavior while maintaining minimal cooperation to sustain exploitation opportunities.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.opponent_cooperation_counts = np.zeros(self.n - 1)
        self.consecutive_high_coop_rounds = 0
        self.threshold_adjustment = 0.0
        self.below_average_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number + 1
        if history is None or round_num <= 3:
            return Action.D
        if round_num > self.r - 2:
            return Action.D
        return self._exploitation_phase_decision(history)

    def _exploitation_phase_decision(self, history: PlayerHistory):
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        cooperation_rate = last_round_cooperators / (self.n - 1)
        self._update_opponent_tracking(history)
        base_threshold = max(0.3, (self.k - 1) / (self.n - 1))
        threshold = self._calculate_adjusted_threshold(base_threshold, history)
        if self._should_escalate_aggression(history):
            return Action.D
        if cooperation_rate > threshold:
            return Action.D
        elif cooperation_rate <= 0.2:
            return Action.D
        else:
            if self._should_target_cooperators():
                return Action.D
            return Action.C

    def _update_opponent_tracking(self, history: PlayerHistory):
        if len(history.opponent_actions) > 0:
            self.opponent_cooperation_counts += history.opponent_actions[-1, :]
        total_cooperation_rate = np.sum(history.opponent_actions[-1, :]) / (self.n - 1)
        if total_cooperation_rate > 0.5:
            self.consecutive_high_coop_rounds += 1
        else:
            self.consecutive_high_coop_rounds = 0

    def _calculate_adjusted_threshold(self, base_threshold, history):
        threshold = base_threshold + self.threshold_adjustment
        if self.n <= 4:
            threshold += 0.2
        if self.k < 1.5:
            threshold = 0.9
        if self.consecutive_high_coop_rounds >= 3:
            self.threshold_adjustment = max(self.threshold_adjustment - 0.1, -0.3)
            self.consecutive_high_coop_rounds = 0
        return min(threshold, 0.95)

    def _should_escalate_aggression(self, history):
        if len(history.my_payoffs) >= 2:
            recent_my_payoff = np.mean(history.my_payoffs[-2:])
            recent_opponent_avg = np.mean(history.opponent_payoffs[-2:, :])
            if recent_my_payoff < recent_opponent_avg:
                self.below_average_rounds += 1
                if self.below_average_rounds >= 2:
                    return True
            else:
                self.below_average_rounds = 0
        return False

    def _should_target_cooperators(self):
        if len(self.opponent_cooperation_counts) == 0:
            return False
        rounds_played = len(self.opponent_cooperation_counts) if hasattr(self, 'opponent_cooperation_counts') else 1
        if rounds_played == 0:
            return False
        cooperation_rates = self.opponent_cooperation_counts / max(rounds_played, 1)
        high_cooperators = np.sum(cooperation_rates > 0.6)
        return high_cooperators > (self.n - 1) / 2

class Strategy_AGGRESSIVE_84(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Predatory Opportunist"
    
    Maximizes personal payoff through aggressive exploitation of cooperative players
    while minimizing vulnerability to retaliation. Always defects in early rounds
    and endgame, only cooperating when highly profitable with strict safety margins.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        initial_phase_end = min(3, self.r // 3)
        if current_round < initial_phase_end:
            return Action.D
        if current_round >= self.r * 0.8:
            return Action.D
        consecutive_defections = self._count_my_recent_defections(history)
        if consecutive_defections < 2:
            return Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        cooperation_rate = last_round_cooperators / self.n
        cooperation_threshold = 0.6
        if self.n > 10:
            cooperation_threshold = 0.7
        if cooperation_rate < cooperation_threshold:
            return Action.D
        other_cooperators = sum(history.opponent_actions[-1, :])
        expected_coop_payoff = self.k / self.n * (other_cooperators + 1)
        expected_defect_payoff = 1 + self.k / self.n * other_cooperators
        safety_margin = 0.2
        if self._facing_coordinated_punishment(history):
            safety_margin = 0.4
        if self.k / self.n > 1.5:
            if self.k / self.n > 1.0 and expected_coop_payoff > expected_defect_payoff + 0.1:
                return Action.C
        if expected_coop_payoff > expected_defect_payoff + safety_margin:
            return Action.C
        else:
            return Action.D

    def _count_my_recent_defections(self, history: PlayerHistory) -> int:
        """Count consecutive defections at the end of my action history."""
        consecutive = 0
        for i in range(len(history.my_actions) - 1, -1, -1):
            if not history.my_actions[i]:
                consecutive += 1
            else:
                break
        return consecutive

    def _facing_coordinated_punishment(self, history: PlayerHistory) -> bool:
        """Check if facing coordinated punishment (>50% players switched from C to D after my defection)."""
        if len(history.my_actions) < 2:
            return False
        if len(history.opponent_actions) < 2:
            return False
        switchers = 0
        total_players = history.opponent_actions.shape[1]
        for player in range(total_players):
            if history.opponent_actions[-2, player] and (not history.opponent_actions[-1, player]):
                switchers += 1
        return switchers / total_players > 0.5

class Strategy_AGGRESSIVE_85(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Punitive Opportunist"
    
    This strategy operates on aggressive opportunism, seeking to maximize individual payoffs
    by exploiting cooperative opponents while brutally punishing defection. It starts with
    aggressive defection, then conditionally cooperates only when it can exploit others,
    and always defects in endgame scenarios.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.initial_aggression_rounds = min(3, max(1, self.n_rounds // 5))
        self.punishment_duration = 3
        self.consecutive_coop_limit = 2
        self.endgame_threshold = max(3, int(0.2 * self.n_rounds))
        self.consecutive_cooperations = 0
        self.punishment_rounds_remaining = 0
        self.recent_retaliation = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.consecutive_cooperations = 0
            return Action.D
        current_round = history.round_number + 1
        if current_round <= self.initial_aggression_rounds:
            return Action.D
        if current_round > self.n_rounds - self.endgame_threshold:
            return Action.D
        if self.punishment_rounds_remaining > 0:
            self.punishment_rounds_remaining -= 1
            self.consecutive_cooperations = 0
            return Action.D
        look_back = min(3, current_round - 1)
        if self.n_players >= 8:
            look_back = min(5, current_round - 1)
        recent_history_start = max(0, current_round - 1 - look_back)
        recent_opponent_actions = history.opponent_actions[recent_history_start:, :]
        recent_my_actions = history.my_actions[recent_history_start:]
        group_cooperation_rate = np.mean(recent_opponent_actions)
        my_defection_rate = 1 - np.mean(recent_my_actions)
        my_avg_payoff = np.mean(history.my_payoffs[-look_back:])
        opponent_avg_payoffs = np.mean(history.opponent_payoffs[-look_back:, :], axis=0)
        group_avg_payoff = np.mean(opponent_avg_payoffs)
        if self._should_punish(recent_opponent_actions, history, look_back, my_avg_payoff, group_avg_payoff):
            self.punishment_rounds_remaining = self.punishment_duration - 1
            self.consecutive_cooperations = 0
            return Action.D
        if self._can_exploit(group_cooperation_rate, my_defection_rate, my_avg_payoff, group_avg_payoff, current_round):
            if self.consecutive_cooperations >= self.consecutive_coop_limit:
                self.consecutive_cooperations = 0
                return Action.D
            coop_probability = min(0.7, group_cooperation_rate)
            if random.random() < coop_probability:
                self.consecutive_cooperations += 1
                return Action.C
        self.consecutive_cooperations = 0
        return Action.D

    def _should_punish(self, recent_opponent_actions, history, look_back, my_avg_payoff, group_avg_payoff):
        """Determine if punishment mode should be triggered"""
        for player_idx in range(self.n_players - 1):
            player_defection_rate = 1 - np.mean(recent_opponent_actions[:, player_idx])
            if player_defection_rate > 0.7:
                return True
        if len(history.my_actions) >= 2:
            last_i_cooperated = history.my_actions[-1]
            if last_i_cooperated:
                last_opponent_cooperation_rate = np.mean(history.opponent_actions[-1, :])
                if last_opponent_cooperation_rate < 0.5:
                    return True
        if len(history.opponent_actions) >= 6:
            early_coop_rate = np.mean(history.opponent_actions[-6:-3, :])
            recent_coop_rate = np.mean(history.opponent_actions[-3:, :])
            if recent_coop_rate < early_coop_rate - 0.1:
                return True
        if my_avg_payoff < group_avg_payoff:
            return True
        return False

    def _can_exploit(self, group_cooperation_rate, my_defection_rate, my_avg_payoff, group_avg_payoff, current_round):
        """Determine if conditions are right for exploitation"""
        if group_cooperation_rate >= 0.6 and my_defection_rate >= 0.8 and (my_avg_payoff >= group_avg_payoff):
            return True
        if self.n_players <= 4:
            return group_cooperation_rate >= 0.9
        if group_cooperation_rate >= 0.7 and current_round <= self.n_rounds - self.endgame_threshold:
            return True
        return False

class Strategy_AGGRESSIVE_86(BaseStrategy):
    """
    Aggressive Exploitation Strategy: Maximum exploitation with minimal vulnerability.
    Uses adaptive punishment and only cooperates when highly profitable.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.cooperation_threshold = max(0.4, (self.k - 1) / (self.n - 1))
        self.punished_opponents = set()

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        total_possible = history.round_number * (self.n - 1)
        total_cooperations = np.sum(history.opponent_actions)
        historical_coop_rate = total_cooperations / total_possible if total_possible > 0 else 0
        self._update_punishment_list(history)
        if self._majority_defectors(history):
            return Action.D
        momentum_decision = self._check_momentum(history)
        if momentum_decision is not None:
            return momentum_decision
        if historical_coop_rate > self.cooperation_threshold:
            return Action.C
        else:
            return Action.D

    def _update_punishment_list(self, history):
        """Update the list of opponents to permanently punish."""
        for opponent_idx in range(self.n - 1):
            if opponent_idx in self.punished_opponents:
                continue
            opponent_actions = history.opponent_actions[:, opponent_idx]
            defection_rate = np.sum(opponent_actions == 0) / len(opponent_actions)
            if defection_rate > 0.6:
                self.punished_opponents.add(opponent_idx)

    def _majority_defectors(self, history):
        """Check if majority of players are consistent defectors (>70% defection)."""
        consistent_defectors = 0
        for opponent_idx in range(self.n - 1):
            opponent_actions = history.opponent_actions[:, opponent_idx]
            defection_rate = np.sum(opponent_actions == 0) / len(opponent_actions)
            if defection_rate > 0.7:
                consistent_defectors += 1
        return consistent_defectors > (self.n - 1) / 2

    def _check_momentum(self, history):
        """Check recent cooperation trends and make momentum-based decisions."""
        if history.round_number < 3:
            return None
        recent_rounds = min(3, history.round_number)
        recent_actions = history.opponent_actions[-recent_rounds:, :]
        coop_rates = []
        for round_idx in range(recent_rounds):
            round_coops = np.sum(recent_actions[round_idx, :])
            coop_rate = round_coops / (self.n - 1)
            coop_rates.append(coop_rate)
        current_coop_rate = coop_rates[-1] if coop_rates else 0
        if len(coop_rates) >= 2:
            declining = all((coop_rates[i] >= coop_rates[i + 1] for i in range(len(coop_rates) - 1)))
            increasing = all((coop_rates[i] <= coop_rates[i + 1] for i in range(len(coop_rates) - 1)))
            if declining and current_coop_rate < 0.3:
                return Action.D
            if increasing and current_coop_rate > 0.6:
                return Action.C
        return None

class Strategy_AGGRESSIVE_87(BaseStrategy):
    """
    Aggressive Adaptive Punishment Strategy (AAPS) - A highly aggressive strategy
    that starts with defection, punishes severely for any perceived exploitation,
    and only cooperates under strict conditions with hair-trigger retaliation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.exploitation_scores = [0] * (self.n - 1)
        self.permanent_punishment = False
        self.momentum_punishment_counter = 0
        self.probation_counter = 0
        self.need_probation = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number + 1
        initial_aggression_rounds = max(3, self.r // 3)
        if current_round <= initial_aggression_rounds:
            return Action.D
        endgame_threshold = self.r - max(3, self.r // 5)
        if current_round > endgame_threshold:
            return Action.D
        self._update_exploitation_scores(history)
        if self.permanent_punishment or any((score > 2 for score in self.exploitation_scores)):
            self.permanent_punishment = True
            return Action.D
        if len(history.my_actions) > 0:
            i_cooperated_last = history.my_actions[-1]
            any_opponent_defected_last = not all(history.opponent_actions[-1, :])
            if i_cooperated_last and any_opponent_defected_last:
                self.permanent_punishment = True
                return Action.D
        if len(history.opponent_actions) > 0:
            last_round_cooperators = sum(history.opponent_actions[-1, :])
            cooperation_rate_last = last_round_cooperators / (self.n - 1)
            if cooperation_rate_last < 0.4:
                self.momentum_punishment_counter = 3
                self.need_probation = True
        if self.momentum_punishment_counter > 0:
            self.momentum_punishment_counter -= 1
            return Action.D
        if self.need_probation:
            if len(history.opponent_actions) > 0:
                last_round_cooperators = sum(history.opponent_actions[-1, :])
                cooperation_rate_last = last_round_cooperators / (self.n - 1)
                if cooperation_rate_last >= 0.9:
                    if self.probation_counter == 0:
                        self.probation_counter = 1
                    else:
                        self.need_probation = False
                        self.probation_counter = 0
                else:
                    self.probation_counter = 0
            if self.need_probation:
                return Action.D
        if len(history.opponent_actions) > 0:
            last_round_cooperators = sum(history.opponent_actions[-1, :])
            cooperation_rate_last = last_round_cooperators / (self.n - 1)
            total_opponent_cooperations = np.sum(history.opponent_actions)
            total_possible_cooperations = len(history.opponent_actions) * (self.n - 1)
            overall_cooperation_rate = total_opponent_cooperations / total_possible_cooperations
            recent_rounds = min(5, len(history.opponent_actions))
            opponent_defection_counts = []
            for opponent_idx in range(self.n - 1):
                defection_count = 0
                for round_idx in range(-recent_rounds, 0):
                    if round_idx < -len(history.opponent_actions):
                        continue
                    if not history.opponent_actions[round_idx, opponent_idx]:
                        defection_count += 1
                opponent_defection_counts.append(defection_count)
            cooperation_threshold = 0.75
            if self.n == 2:
                cooperation_threshold = 1.0
            elif self.k >= 0.8 * self.n:
                cooperation_threshold = 0.7
            conditions_met = cooperation_rate_last >= cooperation_threshold and overall_cooperation_rate >= 0.6 and all((count <= 1 for count in opponent_defection_counts))
            if conditions_met:
                return Action.C
        return Action.D

    def _update_exploitation_scores(self, history):
        """Update exploitation scores for each opponent based on their behavior."""
        if len(history.my_actions) == 0:
            return
        last_round_idx = -1
        i_cooperated_last = history.my_actions[last_round_idx]
        last_round_cooperators = sum(history.opponent_actions[last_round_idx, :])
        majority_cooperated = last_round_cooperators >= (self.n - 1) / 2
        for opponent_idx in range(self.n - 1):
            opponent_defected_last = not history.opponent_actions[last_round_idx, opponent_idx]
            if opponent_defected_last:
                if i_cooperated_last:
                    self.exploitation_scores[opponent_idx] += 3
                elif majority_cooperated:
                    self.exploitation_scores[opponent_idx] += 1

class Strategy_AGGRESSIVE_88(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Predatory Defector"
    
    This strategy treats cooperation as weakness to be exploited. It aggressively defects 
    while using sophisticated pattern recognition to identify and punish cooperative players,
    maximizing personal payoffs through calculated exploitation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        round_num = state.round_number
        prev_cooperation_rate = self._get_prev_cooperation_rate(history)
        avg_cooperation_rate = self._get_average_cooperation_rate(history)
        endgame_threshold = max(3, math.ceil(0.2 * self.r))
        if round_num >= self.r - endgame_threshold:
            return self._endgame_strategy(round_num, prev_cooperation_rate)
        return self._exploitation_strategy(history, prev_cooperation_rate, avg_cooperation_rate)

    def _get_prev_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate cooperation rate in the previous round including self."""
        if len(history.my_actions) == 0:
            return 0.0
        opponent_cooperators = sum(history.opponent_actions[-1, :])
        my_cooperation = int(history.my_actions[-1])
        total_cooperators = opponent_cooperators + my_cooperation
        return total_cooperators / self.n

    def _get_average_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate average cooperation rate across all completed rounds."""
        if len(history.my_actions) == 0:
            return 0.0
        total_cooperations = 0
        total_decisions = 0
        for round_idx in range(len(history.my_actions)):
            opponent_cooperators = sum(history.opponent_actions[round_idx, :])
            my_cooperation = int(history.my_actions[round_idx])
            total_cooperations += opponent_cooperators + my_cooperation
            total_decisions += self.n
        return total_cooperations / total_decisions if total_decisions > 0 else 0.0

    def _has_declining_cooperation_trend(self, history: PlayerHistory) -> bool:
        """Check if cooperation has been declining for 2+ consecutive rounds."""
        if len(history.my_actions) < 3:
            return False
        cooperation_rates = []
        for round_idx in range(len(history.my_actions)):
            opponent_cooperators = sum(history.opponent_actions[round_idx, :])
            my_cooperation = int(history.my_actions[round_idx])
            rate = (opponent_cooperators + my_cooperation) / self.n
            cooperation_rates.append(rate)
        if len(cooperation_rates) >= 3:
            return cooperation_rates[-1] < cooperation_rates[-2] and cooperation_rates[-2] < cooperation_rates[-3]
        return False

    def _endgame_strategy(self, round_num: int, prev_cooperation_rate: float) -> Action:
        """Strategy for endgame phase."""
        if round_num == self.r:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        if prev_cooperation_rate < 0.15:
            return Action.C
        return Action.D

    def _exploitation_strategy(self, history: PlayerHistory, prev_cooperation_rate: float, avg_cooperation_rate: float) -> Action:
        """Main exploitation strategy for middle rounds."""
        if prev_cooperation_rate >= 0.5:
            return Action.D
        if prev_cooperation_rate < 0.25 and self._has_declining_cooperation_trend(history):
            if avg_cooperation_rate > 0.4:
                threshold = 0.2
            else:
                threshold = 0.35
            if prev_cooperation_rate < threshold:
                return Action.C
        if prev_cooperation_rate < 0.3 and random.random() < 0.1:
            return Action.C
        return Action.D

class Strategy_AGGRESSIVE_89(BaseStrategy):
    """
    Aggressive Adaptive Exploitation Strategy (AAES)
    
    This strategy operates on aggressive exploitation with calculated cooperation.
    It maximizes personal payoff by exploiting cooperative opponents while 
    minimizing vulnerability to defectors through dynamic adaptation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.consecutive_defections = 1
            return Action.D
        current_round = history.round_number + 1
        if current_round <= 3:
            self.consecutive_defections += 1
            return Action.D
        if current_round > self.r - 2:
            self.consecutive_defections += 1
            return Action.D
        return self._adaptive_decision(history)

    def _adaptive_decision(self, history: PlayerHistory) -> Action:
        cooperation_rate = self._calculate_cooperation_rate(history)
        trend = self._calculate_trend(history)
        exploitation_potential = self._calculate_exploitation_potential(history, cooperation_rate)
        if self.consecutive_defections > 5 and cooperation_rate > 0.3 and (random.random() < 0.2):
            self.consecutive_defections = 0
            return Action.C
        if self._needs_recovery(history):
            if random.random() < 0.4:
                self.consecutive_defections = 0
                return Action.C
        if cooperation_rate >= 0.6 and trend != 'decreasing':
            self.consecutive_defections += 1
            return Action.D
        elif cooperation_rate >= 0.4 and exploitation_potential > 0.3:
            self.consecutive_defections += 1
            return Action.D
        elif cooperation_rate < 0.2 and trend == 'decreasing':
            if random.random() < 0.3:
                self.consecutive_defections = 0
                return Action.C
            else:
                self.consecutive_defections += 1
                return Action.D
        else:
            if len(history.opponent_actions) > 0:
                last_round_cooperators = np.sum(history.opponent_actions[-1, :])
                if last_round_cooperators >= self.n / 2:
                    self.consecutive_defections += 1
                    return Action.D
            self.consecutive_defections += 1
            return Action.D

    def _calculate_cooperation_rate(self, history: PlayerHistory) -> float:
        if len(history.opponent_actions) == 0:
            return 0.0
        total_actions = history.opponent_actions.size
        total_cooperations = np.sum(history.opponent_actions)
        return total_cooperations / total_actions if total_actions > 0 else 0.0

    def _calculate_trend(self, history: PlayerHistory) -> str:
        if len(history.opponent_actions) < 3:
            return 'stable'
        recent_rounds = history.opponent_actions[-3:, :]
        cooperation_rates = [np.mean(round_actions) for round_actions in recent_rounds]
        if cooperation_rates[-1] > cooperation_rates[0] + 0.1:
            return 'increasing'
        elif cooperation_rates[-1] < cooperation_rates[0] - 0.1:
            return 'decreasing'
        else:
            return 'stable'

    def _calculate_exploitation_potential(self, history: PlayerHistory, cooperation_rate: float) -> float:
        if len(history.opponent_actions) == 0:
            return 0.0
        expected_cooperators = cooperation_rate * (self.n - 1)
        payoff_defect = 1 + self.k / self.n * expected_cooperators
        payoff_cooperate = 0 + self.k / self.n * (expected_cooperators + 1)
        return max(0.0, payoff_defect - payoff_cooperate)

    def _needs_recovery(self, history: PlayerHistory) -> bool:
        if len(history.my_payoffs) == 0:
            return False
        current_average = np.mean(history.my_payoffs)
        return current_average < 1.2

class Strategy_AGGRESSIVE_90(BaseStrategy):
    """
    AGGRESSIVE EXPLOITATION STRATEGY: "PREDATOR"
    
    This strategy treats the public goods game as a zero-sum competition where the goal 
    is to maximize personal payoffs by exploiting others' cooperation while minimizing 
    own contributions. It aggressively free-rides on cooperative behavior and punishes 
    attempted coordination.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.permanent_defection_active = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if history is None:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        last_round_idx = history.round_number - 1
        my_last_action = history.my_actions[last_round_idx]
        opponent_last_actions = history.opponent_actions[last_round_idx, :]
        total_cooperators_last_round = sum(opponent_last_actions) + int(my_last_action)
        others_coop_rate = sum(opponent_last_actions) / (self.n - 1)
        if my_last_action and others_coop_rate < 0.5:
            self.permanent_defection_active = True
        if self.permanent_defection_active:
            return Action.D
        base_threshold = (self.n - self.k) / (self.n - 1)
        if current_round > 0.75 * self.r:
            threshold = base_threshold * 0.5
        else:
            threshold = base_threshold
        if self.n <= 4:
            if sum(opponent_last_actions) < self.n - 1:
                return Action.D
            else:
                return Action.C
        if self.k > 0.8 * self.n:
            if others_coop_rate < 0.8:
                return Action.D
            else:
                return Action.C
        if self.k < 1.5:
            if others_coop_rate < 0.9:
                return Action.D
            else:
                return Action.C
        if self.r <= 5:
            if current_round == 1 or current_round >= self.r - 1:
                return Action.D
            if others_coop_rate < 1.0:
                return Action.D
            else:
                return Action.C
        if others_coop_rate >= threshold:
            return Action.D
        else:
            return Action.C

class Strategy_AGGRESSIVE_91(BaseStrategy):
    """
    Predator Strategy: Opportunistic exploitation maximizing personal payoff through
    strategic cooperation only when advantageous and aggressive punishment of others.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.exploitation_ratio = self.k / self.n
        self.cooperation_threshold = math.ceil(self.n * self.n / self.k)
        self.retaliation_targets = set()

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number + 1
        if current_round == self.r:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        return self._adaptive_exploitation_decision(history, current_round)

    def _adaptive_exploitation_decision(self, history: PlayerHistory, current_round: int) -> Action:
        last_round_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        self._update_retaliation_targets(history)
        threshold = self._get_adjusted_threshold(history, current_round)
        if len(self.retaliation_targets) > 0:
            return Action.D
        if last_round_cooperators >= threshold + 1:
            return Action.C
        elif last_round_cooperators >= threshold:
            return Action.C if random.random() < 0.3 else Action.D
        else:
            return Action.D

    def _update_retaliation_targets(self, history: PlayerHistory):
        """Update targets for retaliation based on opponent behavior."""
        self.retaliation_targets.clear()
        if len(history.opponent_actions) < 2:
            return
        if len(history.opponent_actions) >= 2:
            prev_actions = history.opponent_actions[-2, :]
            curr_actions = history.opponent_actions[-1, :]
            for opponent_idx in range(len(prev_actions)):
                if prev_actions[opponent_idx] and (not curr_actions[opponent_idx]):
                    self.retaliation_targets.add(opponent_idx)
        if len(history.opponent_actions) >= 3:
            recent_rounds = min(3, len(history.opponent_actions))
            for opponent_idx in range(self.n - 1):
                cooperation_rate = np.mean(history.opponent_actions[-recent_rounds:, opponent_idx])
                if cooperation_rate > 0.7:
                    self.retaliation_targets.add(opponent_idx)

    def _get_adjusted_threshold(self, history: PlayerHistory, current_round: int) -> int:
        """Get dynamically adjusted cooperation threshold."""
        base_threshold = self.cooperation_threshold
        if current_round >= math.floor(0.75 * self.r):
            base_threshold += 2
        if len(history.opponent_actions) >= 3:
            recent_rounds = min(3, len(history.opponent_actions))
            avg_cooperation = np.mean(history.opponent_actions[-recent_rounds:, :])
            if avg_cooperation < 0.3:
                base_threshold = max(1, base_threshold - 1)
        return base_threshold

class Strategy_AGGRESSIVE_92(BaseStrategy):
    """
    Aggressive Exploit Strategy: Maximizes personal payoff by intelligently free-riding 
    on others' cooperation while using strategic cooperation to maintain an exploitable 
    cooperative environment.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.consecutive_defections = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.consecutive_defections = 1
            return Action.D
        current_round = history.round_number + 1
        if current_round == self.r:
            return Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        coop_rate = last_round_cooperators / self.n
        if not history.my_actions[-1]:
            self.consecutive_defections += 1
        else:
            self.consecutive_defections = 0
        late_game = current_round > 2 * self.r // 3
        threshold = self.k / self.n
        if late_game:
            threshold *= 0.8
        if coop_rate >= threshold:
            self.consecutive_defections += 1
            return Action.D
        if coop_rate < 0.3:
            self.consecutive_defections = 0
            return Action.C
        if self.consecutive_defections >= 3 and self._is_coop_rate_declining(history):
            self.consecutive_defections = 0
            return Action.C
        if self._detect_high_cooperation_trap(history):
            self.consecutive_defections += 1
            return Action.D
        if self._detect_all_defection(history):
            self.consecutive_defections = 0
            return Action.C
        self.consecutive_defections += 1
        return Action.D

    def _is_coop_rate_declining(self, history: PlayerHistory) -> bool:
        """Check if cooperation rate is declining over recent rounds"""
        if len(history.my_actions) < 3:
            return False
        recent_rates = []
        for i in range(-3, 0):
            round_cooperators = sum(history.opponent_actions[i, :])
            if history.my_actions[i]:
                round_cooperators += 1
            recent_rates.append(round_cooperators / self.n)
        return recent_rates[0] > recent_rates[1] > recent_rates[2]

    def _detect_high_cooperation_trap(self, history: PlayerHistory) -> bool:
        """Detect if cooperation rate > 0.8 for 3 consecutive rounds"""
        if len(history.my_actions) < 3:
            return False
        high_coop_count = 0
        for i in range(-3, 0):
            round_cooperators = sum(history.opponent_actions[i, :])
            if history.my_actions[i]:
                round_cooperators += 1
            if round_cooperators / self.n > 0.8:
                high_coop_count += 1
        return high_coop_count == 3

    def _detect_all_defection(self, history: PlayerHistory) -> bool:
        """Detect if cooperation rate = 0 for 2 consecutive rounds after round 3"""
        if len(history.my_actions) < 4:
            return False
        if len(history.my_actions) < 2:
            return False
        zero_coop_count = 0
        for i in range(-2, 0):
            round_cooperators = sum(history.opponent_actions[i, :])
            if history.my_actions[i]:
                round_cooperators += 1
            if round_cooperators == 0:
                zero_coop_count += 1
        return zero_coop_count == 2

class Strategy_AGGRESSIVE_93(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "PREDATOR"
    
    This strategy treats cooperation as weakness to be exploited and views defection as the 
    dominant path to victory. It aggressively punishes cooperators while maximizing personal 
    gain through calculated exploitation across three phases: exploitation setup, adaptive 
    predation, and endgame aggression.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.temporary_cooperation_countdown = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number + 1
        if self.temporary_cooperation_countdown > 0:
            self.temporary_cooperation_countdown -= 1
            return Action.C
        if current_round <= 3:
            return Action.D
        if current_round >= self.n_rounds - 1:
            return Action.D
        recent_rounds = min(3, history.round_number)
        start_idx = max(0, history.round_number - recent_rounds)
        recent_opponent_actions = history.opponent_actions[start_idx:, :]
        total_recent_actions = recent_opponent_actions.size
        cooperation_rate_last_3 = np.sum(recent_opponent_actions) / total_recent_actions if total_recent_actions > 0 else 0
        if cooperation_rate_last_3 >= 0.6:
            return Action.D
        if history.round_number >= 3:
            my_recent_defections = np.sum(history.my_actions[-3:] == False)
            my_recent_advantage = 0
            for i in range(max(0, history.round_number - 3), history.round_number):
                round_cooperators = np.sum(history.opponent_actions[i, :])
                if not history.my_actions[i]:
                    round_cooperators += 0
                else:
                    round_cooperators += 1
                if not history.my_actions[i]:
                    my_payoff = 1 + self.k / self.n_players * round_cooperators
                    coop_payoff = 0 + self.k / self.n_players * round_cooperators
                    my_recent_advantage += my_payoff - coop_payoff
            my_recent_advantage = my_recent_advantage / 3 if my_recent_defections > 0 else 0
            if my_recent_advantage > self.k / self.n_players:
                return Action.D
        if self._is_experiencing_coordinated_punishment(history):
            remaining_rounds = self.n_rounds - current_round
            temp_coop_rounds = min(2, max(1, remaining_rounds // 4))
            self.temporary_cooperation_countdown = temp_coop_rounds - 1
            return Action.C
        if cooperation_rate_last_3 < 0.1 and current_round < self.n_rounds * 0.75:
            return Action.C
        return Action.D

    def _is_experiencing_coordinated_punishment(self, history: PlayerHistory) -> bool:
        """Check if facing coordinated punishment (>70% of players defecting consistently)"""
        if history.round_number < 2:
            return False
        recent_rounds = min(2, history.round_number)
        start_idx = max(0, history.round_number - recent_rounds)
        recent_opponent_actions = history.opponent_actions[start_idx:, :]
        defection_rate = 1 - np.sum(recent_opponent_actions) / recent_opponent_actions.size
        overall_cooperation = np.sum(history.opponent_actions) / history.opponent_actions.size
        return defection_rate > 0.7 or (overall_cooperation < 0.2 and history.round_number >= 3)

class Strategy_AGGRESSIVE_94(BaseStrategy):
    """
    AGGRESSIVE EXPLOITATION STRATEGY: "PREDATOR"
    
    Treats the public goods game as a zero-sum competition, aggressively exploiting 
    cooperative behavior while minimizing own contributions. Adapts quickly to punish 
    retaliation attempts and maximizes relative advantage over opponents.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.peace_offering_due = False
        self.low_participation_mode = False
        self.high_retaliation_recovery_mode = False
        self.recovery_rounds_left = 0
        self.payoff_history = []
        self.threshold_adjustment = 0.0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        round_num = history.round_number + 1
        if round_num == self.r:
            return Action.D
        last_round_idx = history.round_number - 1
        my_last_action = history.my_actions[last_round_idx]
        opponent_cooperators = sum(history.opponent_actions[last_round_idx, :])
        total_cooperators = opponent_cooperators + (1 if my_last_action else 0)
        coop_rate = total_cooperators / self.n
        self._update_adaptive_modes(history)
        if self.high_retaliation_recovery_mode:
            if self.recovery_rounds_left > 0:
                self.recovery_rounds_left -= 1
                return Action.C
            else:
                self.high_retaliation_recovery_mode = False
        if self.peace_offering_due:
            self.peace_offering_due = False
            return Action.C
        base_threshold = (self.k - 1) / self.k
        if self.n <= 4:
            base_threshold = (self.k - 1.5) / self.k
        exploitation_threshold = base_threshold + self.threshold_adjustment
        exploitation_threshold = max(0.0, min(1.0, exploitation_threshold))
        if coop_rate >= exploitation_threshold:
            return Action.D
        if self._cooperation_increasing_trend(history):
            return Action.D
        if self._retaliation_detected(history):
            self.peace_offering_due = True
            return Action.C
        if self.low_participation_mode and round_num % 4 == 0:
            return Action.C
        return Action.D

    def _update_adaptive_modes(self, history):
        """Update adaptive mode flags based on game history"""
        rounds_completed = history.round_number
        if rounds_completed >= 3:
            total_coop_rate = 0
            for i in range(rounds_completed):
                my_action = history.my_actions[i]
                opponent_cooperators = sum(history.opponent_actions[i, :])
                total_cooperators = opponent_cooperators + (1 if my_action else 0)
                total_coop_rate += total_cooperators / self.n
            avg_coop_rate = total_coop_rate / rounds_completed
            self.low_participation_mode = avg_coop_rate < 0.2
            if rounds_completed >= 3:
                recent_coop_rates = []
                for i in range(max(0, rounds_completed - 3), rounds_completed):
                    my_action = history.my_actions[i]
                    opponent_cooperators = sum(history.opponent_actions[i, :])
                    total_cooperators = opponent_cooperators + (1 if my_action else 0)
                    recent_coop_rates.append(total_cooperators / self.n)
                if all((rate < 0.1 for rate in recent_coop_rates)):
                    self.high_retaliation_recovery_mode = True
                    self.recovery_rounds_left = 2
        if rounds_completed >= 3:
            my_avg_payoff = np.mean(history.my_payoffs)
            opponent_avg_payoffs = np.mean(history.opponent_payoffs, axis=0)
            overall_avg = np.mean(opponent_avg_payoffs)
            if my_avg_payoff < overall_avg - 0.1:
                self.threshold_adjustment = max(-0.3, self.threshold_adjustment - 0.1)
            elif my_avg_payoff > overall_avg + 0.2:
                self.threshold_adjustment = min(0.3, self.threshold_adjustment + 0.1)

    def _cooperation_increasing_trend(self, history):
        """Check if cooperation rate is increasing over the last 2 rounds"""
        rounds_completed = history.round_number
        if rounds_completed < 2:
            return False
        coop_rates = []
        for i in range(max(0, rounds_completed - 2), rounds_completed):
            my_action = history.my_actions[i]
            opponent_cooperators = sum(history.opponent_actions[i, :])
            total_cooperators = opponent_cooperators + (1 if my_action else 0)
            coop_rates.append(total_cooperators / self.n)
        return len(coop_rates) == 2 and coop_rates[1] > coop_rates[0]

    def _retaliation_detected(self, history):
        """Detect coordinated retaliation from opponents"""
        rounds_completed = history.round_number
        if rounds_completed < 2:
            return False
        prev_round_idx = rounds_completed - 2
        last_round_idx = rounds_completed - 1
        switches_to_defect = 0
        total_opponents = self.n - 1
        for player_idx in range(total_opponents):
            prev_action = history.opponent_actions[prev_round_idx, player_idx]
            last_action = history.opponent_actions[last_round_idx, player_idx]
            if prev_action and (not last_action):
                switches_to_defect += 1
        return switches_to_defect > total_opponents * 0.5

class Strategy_AGGRESSIVE_95(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "PREDATOR"
    
    This strategy operates as an aggressive exploiter that maximizes personal payoffs by 
    strategically punishing cooperation while minimizing its own contributions. It exploits
    cooperative players while occasionally seeding cooperation to create future exploitation
    opportunities.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.consecutive_low_cooperation_rounds = 0
        self.punishment_rounds_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.consecutive_low_cooperation_rounds = 0
            self.punishment_rounds_remaining = 0
            return Action.D
        current_round = state.round_number
        n = self.game_description.n_players
        k = self.game_description.k
        total_rounds = self.game_description.n_rounds
        if current_round >= total_rounds - 1:
            return Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        cooperation_rate = last_round_cooperators / n
        my_exploitation_benefit = cooperation_rate * (k / n)
        if cooperation_rate <= 0.15:
            self.consecutive_low_cooperation_rounds += 1
        else:
            self.consecutive_low_cooperation_rounds = 0
        if len(history.my_actions) >= 2:
            if history.my_actions[-1]:
                prev_round_cooperators = sum(history.opponent_actions[-2, :])
                if history.my_actions[-2]:
                    prev_round_cooperators += 1
                prev_cooperation_rate = prev_round_cooperators / n
                if cooperation_rate < prev_cooperation_rate:
                    self.punishment_rounds_remaining = 2
        if self.punishment_rounds_remaining > 0:
            self.punishment_rounds_remaining -= 1
            return Action.D
        if cooperation_rate > 0.6:
            return Action.D
        if self.consecutive_low_cooperation_rounds >= 3:
            self.consecutive_low_cooperation_rounds = 0
            return Action.C
        if cooperation_rate >= 0.4 and my_exploitation_benefit > 0.5:
            return Action.D
        elif cooperation_rate <= 0.2:
            return Action.C
        else:
            return Action.D

class Strategy_AGGRESSIVE_96(BaseStrategy):
    """
    Aggressive Exploitation Strategy "PREDATOR" - maximizes personal gain through 
    systematic exploitation of cooperators while minimizing vulnerability.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.base_threshold = self.k / self.n
        self.threshold_adjustment = 0.0
        self.cooperation_history = []
        self.was_only_cooperator_last = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number + 1
        if current_round == self.r:
            return Action.D
        if random.random() < 0.02:
            return Action.C if random.random() < 0.5 else Action.D
        last_round_opponents = history.opponent_actions[-1, :]
        others_cooperations = np.sum(last_round_opponents)
        coop_rate = others_cooperations / (self.n - 1)
        self.cooperation_history.append(coop_rate)
        adjusted_threshold = self.base_threshold + self.threshold_adjustment
        if coop_rate <= adjusted_threshold:
            return Action.D
        if len(self.cooperation_history) >= 3:
            recent_rates = self.cooperation_history[-3:]
            if recent_rates[0] > recent_rates[1] > recent_rates[2]:
                return Action.D
        if history.my_actions[-1] and others_cooperations == 0:
            self.was_only_cooperator_last = True
            return Action.D
        if len(self.cooperation_history) >= 5:
            avg_coop_rate = np.mean(self.cooperation_history[-5:])
            if avg_coop_rate > 0.8:
                profitable_rounds = sum((1 for i in range(-5, 0) if i < len(self.cooperation_history) and self.cooperation_history[i] > adjusted_threshold))
                if profitable_rounds > 0 and profitable_rounds % 3 == 0:
                    return Action.D
            elif avg_coop_rate < 0.2:
                if random.random() < 0.05:
                    return Action.C
                else:
                    return Action.D
        if current_round > 0.8 * self.r:
            late_game_factor = (current_round - 0.8 * self.r) / (0.2 * self.r)
            defection_boost = 0.1 * late_game_factor
            if random.random() < defection_boost:
                return Action.D
        if len(history.my_actions) >= 3:
            recent_my_actions = history.my_actions[-3:]
            recent_opponent_actions = history.opponent_actions[-3:, :]
            unrewarded_cooperations = 0
            total_cooperations = 0
            for i in range(3):
                if recent_my_actions[i]:
                    total_cooperations += 1
                    others_coop = np.sum(recent_opponent_actions[i, :])
                    if others_coop < (self.n - 1) * 0.5:
                        unrewarded_cooperations += 1
            if total_cooperations > 0 and unrewarded_cooperations / total_cooperations > 0.5:
                self.threshold_adjustment = min(0.1, self.threshold_adjustment + 0.02)
        if len(history.opponent_actions) >= 3:
            recent_actions = history.opponent_actions[-3:, :]
            coordination_detected = False
            for round_idx in range(3):
                round_actions = recent_actions[round_idx, :]
                if len(set(round_actions)) == 1:
                    coordination_detected = True
                    break
            if coordination_detected and coop_rate > 0.6:
                return Action.D
        return Action.C

class Strategy_AGGRESSIVE_97(BaseStrategy):
    """
    Aggressive Exploitative Strategy: 'The Predator'
    
    This strategy operates on the principle that cooperation is weakness to be exploited.
    It aggressively seeks to maximize personal payoff by free-riding on others' contributions
    while minimizing its own cooperative behavior through three phases:
    1. Early Exploitation: Always defect
    2. Calculated Parasitism: Minimal cooperation only when enough cooperators exist
    3. Endgame Exploitation: Always defect
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.phase1_end = max(1, math.floor(self.n_rounds / 3))
        self.phase2_end = max(2, math.floor(2 * self.n_rounds / 3))
        self.cooperation_threshold = max(1, math.floor(self.n_players / 3))

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round <= self.phase1_end:
            return Action.D
        if current_round > self.phase2_end:
            return Action.D
        return self._phase2_decision(history)

    def _phase2_decision(self, history: PlayerHistory) -> Action:
        """Apply Minimum Viable Cooperation rule in phase 2"""
        rounds_to_check = min(3, history.round_number)
        if rounds_to_check == 0:
            return Action.D
        recent_cooperators = 0
        for i in range(rounds_to_check):
            round_idx = history.round_number - 1 - i
            recent_cooperators += sum(history.opponent_actions[round_idx, :])
        avg_recent_cooperators = recent_cooperators / rounds_to_check
        total_cooperators = 0
        for round_idx in range(history.round_number):
            total_cooperators += sum(history.opponent_actions[round_idx, :])
        avg_cooperators = total_cooperators / history.round_number
        if avg_recent_cooperators >= self.cooperation_threshold and avg_cooperators >= self.cooperation_threshold:
            coop_prob = min(0.3, avg_recent_cooperators / self.n_players)
            total_cooperators_last_5 = 0
            rounds_to_check = min(5, history.round_number)
            for i in range(rounds_to_check):
                round_idx = history.round_number - 1 - i
                total_cooperators_last_5 += sum(history.opponent_actions[round_idx, :])
            avg_last_5 = total_cooperators_last_5 / rounds_to_check
            if avg_last_5 < self.n_players / 4:
                coop_prob *= 0.5
            elif avg_last_5 > 3 * self.n_players / 4:
                coop_prob = min(0.4, coop_prob * 1.5)
            if avg_cooperators > 0.9 * self.n_players:
                if avg_recent_cooperators >= self.n_players - 1:
                    coop_prob = 0.4
            if random.random() < coop_prob:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

class Strategy_AGGRESSIVE_98(BaseStrategy):
    """
    AGGRESSIVE EXPLOITATION STRATEGY: "PREDATOR"
    
    Treats the public goods game as zero-sum competition, aggressively exploiting
    cooperative behavior while minimizing contributions. Uses sophisticated pattern
    recognition to identify and punish threats across three phases:
    1. Initial Exploitation (rounds 1-3): Always defect
    2. Adaptive Predation (middle rounds): Conditional defection with punishment
    3. Endgame Extraction (final 2 rounds): Always defect
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.punishment_rounds_left = 0
        self.cooperation_threshold = self.k / self.n
        if self.k > self.n * 0.7:
            self.cooperation_threshold *= 0.8
        self.punishment_duration = 2
        if self.n > 8:
            self.punishment_duration = 3
        self.rounds_since_chaos = 0
        self.last_anti_grim_round = -10

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round < 3:
            return Action.D
        if current_round >= self.r - 2:
            return Action.D
        if self.punishment_rounds_left > 0:
            self.punishment_rounds_left -= 1
            return Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        cooperation_rate = last_round_cooperators / self.n
        if self._detect_retaliation_pattern(history):
            self.punishment_rounds_left = self.punishment_duration - 1
            return Action.D
        if len(history.my_actions) >= 3:
            recent_coop_rates = []
            for i in range(3):
                round_idx = -(i + 1)
                if abs(round_idx) <= len(history.opponent_actions):
                    round_cooperators = sum(history.opponent_actions[round_idx, :])
                    recent_coop_rates.append(round_cooperators / self.n)
            if len(recent_coop_rates) > 0 and np.mean(recent_coop_rates) > 0.4:
                return Action.D
        if cooperation_rate >= self.cooperation_threshold:
            return Action.D
        if self._check_anti_trigger_condition(history):
            return Action.C
        if self._should_strategically_cooperate(history, cooperation_rate, current_round):
            return Action.C
        if self._should_inject_chaos(current_round):
            self.rounds_since_chaos = 0
            return Action.D
        if current_round - self.last_anti_grim_round >= 7 + random.randint(0, 2):
            self.last_anti_grim_round = current_round
            return Action.C
        self.rounds_since_chaos += 1
        return Action.D

    def _detect_retaliation_pattern(self, history: PlayerHistory) -> bool:
        """Detect if any opponent shows retaliation pattern against us."""
        if len(history.my_actions) < 2:
            return False
        if history.my_actions[-1]:
            return False
        if len(history.opponent_actions) >= 2:
            for player_idx in range(self.n - 1):
                if len(history.opponent_actions) >= 2 and history.opponent_actions[-2, player_idx] and (not history.opponent_actions[-1, player_idx]):
                    return True
        return False

    def _check_anti_trigger_condition(self, history: PlayerHistory) -> bool:
        """Check if we need anti-trigger cooperation to restart exploitation cycle."""
        if len(history.opponent_actions) < 2:
            return False
        consecutive_zero_rounds = 0
        for i in range(min(3, len(history.opponent_actions))):
            round_idx = -(i + 1)
            round_cooperators = sum(history.opponent_actions[round_idx, :])
            if round_cooperators == 0:
                consecutive_zero_rounds += 1
            else:
                break
        return consecutive_zero_rounds >= 2

    def _should_strategically_cooperate(self, history: PlayerHistory, cooperation_rate: float, current_round: int) -> bool:
        """Determine if rare strategic cooperation is warranted."""
        if self.r < 8:
            return False
        if cooperation_rate < self.cooperation_threshold / 2 and current_round < self.r - 4:
            my_total_payoff = sum(history.my_payoffs) if len(history.my_payoffs) > 0 else 0
            rounds_played = len(history.my_payoffs)
            if rounds_played > 0:
                avg_payoff_per_round = my_total_payoff / rounds_played
                expected_min_payoff = 1.0
                return avg_payoff_per_round < expected_min_payoff * 0.8
        return False

    def _should_inject_chaos(self, current_round: int) -> bool:
        """Determine if chaos injection is needed for unpredictability."""
        if current_round < 4 or current_round >= self.r - 3:
            return False
        if self.rounds_since_chaos >= 8 + random.randint(0, 4):
            return random.random() < 0.3
        return False

class Strategy_AGGRESSIVE_99(BaseStrategy):
    """
    Aggressive Exploitation Strategy that maximizes extraction with minimal reciprocity.
    Exploits cooperative opponents while minimizing own contributions to public good.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.punishment_debt = {}

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        if current_round < 3:
            return Action.D
        n_opponents = self.n_players - 1
        if current_round > 0:
            recent_cooperators = sum(history.opponent_actions[-1, :])
        else:
            recent_cooperators = 0
        if current_round >= 3:
            self._update_punishment_debt(history)
            cooperator_count = 0
            for opponent_idx in range(n_opponents):
                opponent_history = history.opponent_actions[:, opponent_idx]
                cooperation_rate = np.mean(opponent_history)
                if cooperation_rate >= 0.67:
                    cooperator_count += 1
        cooperator_count = recent_cooperators
        if current_round > 0.8 * self.n_rounds:
            if current_round == self.n_rounds - 1:
                return Action.D
            else:
                public_good_value = cooperator_count * self.k / self.n_players
                if public_good_value > 2.0:
                    if random.random() < 0.2:
                        return Action.C
                return Action.D
        public_good_value = cooperator_count * self.k / self.n_players
        if public_good_value > 1.5:
            if current_round <= 0.8 * self.n_rounds:
                return Action.D
            else:
                return Action.D
        elif public_good_value > 1.2:
            if random.random() < 0.3:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _update_punishment_debt(self, history):
        """Update punishment debt tracking for opponents who defected when I cooperated."""
        if history.round_number < 1:
            return
        my_last_action = history.my_actions[-1]
        if my_last_action:
            for opponent_idx in range(self.n_players - 1):
                opponent_last_action = history.opponent_actions[-1, opponent_idx]
                if not opponent_last_action:
                    if opponent_idx not in self.punishment_debt:
                        self.punishment_debt[opponent_idx] = 0
                    self.punishment_debt[opponent_idx] += 2
        for opponent_idx in self.punishment_debt:
            self.punishment_debt[opponent_idx] = max(0, self.punishment_debt[opponent_idx] - 1)

class Strategy_AGGRESSIVE_100(BaseStrategy):
    """
    AGGRESSIVE EXPLOITATION STRATEGY: "RUTHLESS OPPORTUNIST"
    
    Operates on aggressive exploitation principles - maximizing personal payoff by 
    ruthlessly exploiting cooperative opponents while minimizing vulnerability.
    Uses three phases: ruthless probing, predatory exploitation, and endgame brutality.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        rounds_remaining = self.n_rounds - current_round
        if current_round <= 2:
            return Action.D
        if rounds_remaining <= self.n_rounds * 0.2:
            return Action.D
        cooperation_rate = self._calculate_others_cooperation_rate(history)
        if cooperation_rate >= 0.6:
            return Action.D
        elif cooperation_rate >= 0.3:
            if self._is_cooperation_trending_up(history):
                return Action.D
            else:
                return Action.D
        else:
            return Action.D

    def _calculate_others_cooperation_rate(self, history: PlayerHistory) -> float:
        """Calculate the cooperation rate of opponents in the most recent round."""
        if len(history.opponent_actions) == 0:
            return 0.0
        recent_actions = history.opponent_actions[-1, :]
        cooperators = np.sum(recent_actions)
        total_opponents = len(recent_actions)
        return cooperators / total_opponents if total_opponents > 0 else 0.0

    def _is_cooperation_trending_up(self, history: PlayerHistory) -> bool:
        """Check if opponent cooperation rate is increasing (exploitation opportunity)."""
        if len(history.opponent_actions) < 2:
            return False
        recent_rate = np.mean(history.opponent_actions[-1, :])
        previous_rate = np.mean(history.opponent_actions[-2, :])
        return recent_rate - previous_rate > 0.15

class Strategy_AGGRESSIVE_101(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "PREDATOR"
    
    This strategy treats the public goods game as a competitive environment,
    maximizing personal payoffs by exploiting others' cooperation while
    minimizing personal contributions. Uses dynamic thresholds, opponent
    classification, and ruthless endgame defection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.safety_margin = 0.1 * (self.k / self.n)
        self.cooperation_threshold = 1.0 + self.safety_margin
        self.exploitable_threshold = 0.6
        self.aggressive_threshold = 0.7
        self.retaliation_risk_threshold = 0.3
        self.min_reputation_rate = 0.15
        self.high_coop_threshold = 0.8
        self.low_coop_threshold = 0.2
        self.mass_cooperation_threshold = 0.75

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if history is None:
            return Action.D
        if round_num == self.r - 1:
            return Action.D
        endgame_threshold = max(math.floor(self.r * 0.8), self.r - 3)
        if round_num >= endgame_threshold:
            return Action.D
        current_round = history.round_number
        recent_cooperators = self._estimate_cooperation_rate(history)
        predicted_cooperators = recent_cooperators * (self.n - 1)
        early_rounds_end = min(5, math.floor(self.r / 4))
        if current_round < early_rounds_end:
            if current_round > 0:
                last_round_coop_rate = np.mean(history.opponent_actions[-1, :])
                if last_round_coop_rate > self.mass_cooperation_threshold:
                    my_coop_rate = np.mean(history.my_actions)
                    if my_coop_rate < 0.1:
                        return Action.C
            return Action.D
        expected_return = self.k / self.n * (predicted_cooperators + 1)
        if expected_return > self.cooperation_threshold:
            reputation_risk = self._calculate_retaliation_risk(history)
            my_coop_rate = np.mean(history.my_actions) if len(history.my_actions) > 0 else 0
            if reputation_risk < self.retaliation_risk_threshold:
                if recent_cooperators > self.high_coop_threshold:
                    if current_round % 4 == 0 or current_round % 3 == 0:
                        return Action.C
                elif my_coop_rate < self.min_reputation_rate and current_round > 5:
                    return Action.C
                elif recent_cooperators > 0.5:
                    return Action.C
        if recent_cooperators < self.low_coop_threshold:
            return Action.D
        return Action.D

    def _estimate_cooperation_rate(self, history: PlayerHistory) -> float:
        """Estimate recent cooperation rate of opponents with recency weighting."""
        if history.round_number == 0:
            return 0.0
        rounds_to_consider = min(5, history.round_number)
        recent_actions = history.opponent_actions[-rounds_to_consider:, :]
        weights = np.array([0.5 ** (rounds_to_consider - i - 1) for i in range(rounds_to_consider)])
        weighted_cooperation = np.average(np.mean(recent_actions, axis=1), weights=weights)
        return weighted_cooperation

    def _calculate_retaliation_risk(self, history: PlayerHistory) -> float:
        """Calculate risk of retaliation based on opponent patterns."""
        if history.round_number < 2:
            return 0.0
        retaliation_indicators = 0
        total_opportunities = 0
        for round_idx in range(1, history.round_number):
            my_prev_action = history.my_actions[round_idx - 1]
            for opponent_idx in range(self.n - 1):
                opponent_current = history.opponent_actions[round_idx, opponent_idx]
                opponent_prev = history.opponent_actions[round_idx - 1, opponent_idx]
                total_opportunities += 1
                if not my_prev_action and opponent_prev and (not opponent_current):
                    retaliation_indicators += 1
        if total_opportunities == 0:
            return 0.0
        return min(retaliation_indicators / total_opportunities, 1.0)

    def _classify_opponent(self, opponent_idx: int, history: PlayerHistory) -> str:
        """Classify opponent behavior pattern."""
        if history.round_number < 3:
            return 'UNKNOWN'
        opponent_actions = history.opponent_actions[:, opponent_idx]
        cooperation_rate = np.mean(opponent_actions)
        if cooperation_rate > self.exploitable_threshold:
            return 'EXPLOITABLE'
        elif cooperation_rate < 1 - self.aggressive_threshold:
            return 'AGGRESSIVE'
        else:
            retaliation_pattern = self._detect_tit_for_tat(opponent_idx, history)
            if retaliation_pattern:
                return 'RETALIATORY'
            else:
                return 'RANDOM'

    def _detect_tit_for_tat(self, opponent_idx: int, history: PlayerHistory) -> bool:
        """Detect if opponent follows tit-for-tat pattern."""
        if history.round_number < 3:
            return False
        matches = 0
        total_checks = 0
        for round_idx in range(1, history.round_number):
            my_prev_action = history.my_actions[round_idx - 1]
            opponent_current = history.opponent_actions[round_idx, opponent_idx]
            total_checks += 1
            if my_prev_action == opponent_current:
                matches += 1
        return matches / total_checks > 0.7 if total_checks > 0 else False

class Strategy_AGGRESSIVE_102(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "PREDATOR"
    
    This strategy treats the public goods game as a zero-sum competition,
    aggressively exploiting cooperative players while minimizing vulnerability.
    Always defects in first and last rounds, and uses adaptive thresholds
    to exploit cooperation waves while quickly abandoning unprofitable situations.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        cooperation_threshold = max(0.3, self.k / self.n - 0.1)
        if self.k > self.n - 1:
            cooperation_threshold = self.k / self.n - 0.2
        elif self.n <= 3:
            cooperation_threshold = self.k / self.n + 0.1
        last_round_idx = history.round_number - 1
        cooperators_last_round = sum(history.opponent_actions[last_round_idx, :])
        if history.my_actions[last_round_idx]:
            cooperators_last_round += 1
        coop_rate = cooperators_last_round / self.n
        if history.round_number >= 3:
            all_defection_streak = 0
            for i in range(min(3, history.round_number)):
                round_idx = history.round_number - 1 - i
                round_cooperators = sum(history.opponent_actions[round_idx, :])
                if history.my_actions[round_idx]:
                    round_cooperators += 1
                if round_cooperators == 0:
                    all_defection_streak += 1
                else:
                    break
            if all_defection_streak >= 3:
                return Action.D
        if history.round_number >= 3:
            coop_rates = []
            for i in range(3):
                round_idx = history.round_number - 1 - i
                round_cooperators = sum(history.opponent_actions[round_idx, :])
                if history.my_actions[round_idx]:
                    round_cooperators += 1
                coop_rates.append(round_cooperators / self.n)
            if len(coop_rates) >= 3:
                if coop_rates[0] > coop_rates[1] and coop_rates[1] > coop_rates[2]:
                    if coop_rate >= cooperation_threshold:
                        return Action.C
                if coop_rates[0] < coop_rates[1] and coop_rates[1] < coop_rates[2]:
                    return Action.D
        if self.r <= 3:
            if coop_rate >= 0.5:
                return Action.C
            else:
                return Action.D
        if coop_rate >= cooperation_threshold:
            return Action.C
        else:
            return Action.D

class Strategy_AGGRESSIVE_103(BaseStrategy):
    """
    AGGRESSIVE EXPLOITATION STRATEGY: "PREDATOR"
    
    Maximizes personal payoffs by strategically free-riding while punishing those who threaten 
    profitable cooperation levels. Always defects in first round and endgame, exploits high 
    cooperation, and maintains profitable cooperation levels through strategic punishment.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.high_coop_threshold = 0.6
        self.low_coop_threshold = 0.3
        self.defect_payoffs = []
        self.cooperate_payoffs = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if history is None:
            return Action.D
        endgame_threshold = max(1, math.floor(0.2 * self.r))
        if current_round >= self.r - endgame_threshold:
            return Action.D
        self._update_learning(history)
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        coop_rate = last_round_cooperators / self.n
        if self._check_defector_cascade(history):
            return Action.D
        if coop_rate >= self.high_coop_threshold:
            return Action.D
        elif coop_rate >= self.low_coop_threshold:
            return Action.C
        else:
            if coop_rate < 0.1:
                rounds_remaining = self.r - current_round
                if rounds_remaining >= 2 and (not self._cooperated_recently(history, 2)):
                    return Action.C
            return Action.D

    def _update_learning(self, history):
        """Update adaptive thresholds based on performance"""
        if len(history.my_actions) < 2:
            return
        last_action = history.my_actions[-1]
        last_payoff = history.my_payoffs[-1]
        if last_action:
            self.cooperate_payoffs.append(last_payoff)
        else:
            self.defect_payoffs.append(last_payoff)
        if len(history.my_actions) % 5 == 0 and len(self.cooperate_payoffs) > 0 and (len(self.defect_payoffs) > 0):
            avg_defect = np.mean(self.defect_payoffs)
            avg_cooperate = np.mean(self.cooperate_payoffs)
            if avg_cooperate > 0:
                exploit_success = avg_defect / avg_cooperate
                if exploit_success > 1.2:
                    self.high_coop_threshold = max(0.4, self.high_coop_threshold - 0.1)
                    self.low_coop_threshold = max(0.2, self.low_coop_threshold - 0.1)
                elif exploit_success < 0.9:
                    self.high_coop_threshold = min(0.8, self.high_coop_threshold + 0.1)
                    self.low_coop_threshold = min(0.5, self.low_coop_threshold + 0.1)

    def _check_defector_cascade(self, history):
        """Check if we should punish a defector cascade"""
        if len(history.my_actions) < 3:
            return False
        defector_count = 0
        lookback = min(3, len(history.my_actions))
        for player_idx in range(history.opponent_actions.shape[1]):
            recent_actions = history.opponent_actions[-lookback:, player_idx]
            cooperation_rate = sum(recent_actions) / len(recent_actions)
            if cooperation_rate <= 0.33:
                defector_count += 1
        my_recent_actions = history.my_actions[-lookback:]
        my_cooperation_rate = sum(my_recent_actions) / len(my_recent_actions)
        if my_cooperation_rate <= 0.33:
            defector_count += 1
        return defector_count / self.n >= 0.4

    def _cooperated_recently(self, history, rounds):
        """Check if we cooperated in the last N rounds"""
        if len(history.my_actions) < rounds:
            rounds = len(history.my_actions)
        recent_actions = history.my_actions[-rounds:]
        return any(recent_actions)

class Strategy_AGGRESSIVE_104(BaseStrategy):
    """
    AGGRESSIVE EXPLOITATION STRATEGY: "PREDATOR"
    
    This strategy treats the public goods game as a zero-sum competition where the goal is to maximize 
    personal payoff by exploiting cooperative opponents. Uses aggressive opening, strategic punishment,
    and adaptive exploitation to dominate the game.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.exploitation_threshold = max(1, self.n // 3)
        self.cooperation_threshold = math.ceil(self.n * 0.7)
        self.endgame_rounds = 2
        self.opponent_types = {}
        self.retaliation_counters = {}

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round >= self.r - self.endgame_rounds:
            return Action.D
        last_round_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        total_cooperators_last_round = last_round_cooperators
        if history.my_actions[-1]:
            total_cooperators_last_round += 1
        if last_round_cooperators >= self.exploitation_threshold:
            return Action.D
        if self._should_punish(history):
            return Action.D
        if self._should_bait_cooperation(history, current_round):
            return Action.C
        if last_round_cooperators >= math.ceil(self.n / 2):
            if random.random() < 0.3:
                return Action.C
        return Action.D

    def _should_punish(self, history: PlayerHistory) -> bool:
        """Determine if we should punish opponents for disrupting our exploitation."""
        if len(history.my_actions) < 2:
            return False
        current_cooperators = int(np.sum(history.opponent_actions[-1, :]))
        previous_cooperators = int(np.sum(history.opponent_actions[-2, :]))
        if previous_cooperators >= 2 and current_cooperators < previous_cooperators - 1:
            return True
        if history.my_actions[-1] and current_cooperators < math.ceil(self.n / 3):
            return True
        return False

    def _should_bait_cooperation(self, history: PlayerHistory, current_round: int) -> bool:
        """Determine if we should cooperate to bait others back into cooperation for future exploitation."""
        if len(history.my_actions) < 3:
            return False
        recent_rounds = min(3, len(history.my_actions))
        total_recent_cooperation = 0
        for i in range(recent_rounds):
            round_idx = -(i + 1)
            total_recent_cooperation += int(np.sum(history.opponent_actions[round_idx, :]))
            if history.my_actions[round_idx]:
                total_recent_cooperation += 1
        avg_cooperation_rate = total_recent_cooperation / (recent_rounds * self.n)
        if avg_cooperation_rate < 0.2 and current_round < self.r - 4 and (current_round % 4 == 0):
            return True
        return False

    def _count_recent_cooperators(self, history: PlayerHistory, rounds_back: int=1) -> int:
        """Count total cooperators in recent rounds."""
        if len(history.my_actions) < rounds_back:
            return 0
        total = 0
        for i in range(rounds_back):
            round_idx = -(i + 1)
            total += int(np.sum(history.opponent_actions[round_idx, :]))
            if history.my_actions[round_idx]:
                total += 1
        return total

    def _all_defected_recently(self, history: PlayerHistory, rounds_back: int=2) -> bool:
        """Check if everyone defected in recent rounds."""
        if len(history.my_actions) < rounds_back:
            return False
        for i in range(rounds_back):
            round_idx = -(i + 1)
            round_cooperators = int(np.sum(history.opponent_actions[round_idx, :]))
            if history.my_actions[round_idx]:
                round_cooperators += 1
            if round_cooperators > 0:
                return False
        return True

class Strategy_AGGRESSIVE_105(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Predator"
    
    Ruthlessly exploits cooperative players while minimizing personal contributions.
    Always defects in initial and endgame phases, only cooperates when forced by
    immediate punishment in the middle phase.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number + 1
        if current_round <= 3:
            return Action.D
        if current_round >= self.n_rounds - 1:
            return Action.D
        return self._main_phase_decision(history, current_round)

    def _main_phase_decision(self, history: PlayerHistory, current_round: int) -> Action:
        """
        Primary Rule: DEFECT unless forced to cooperate by immediate punishment
        """
        if history.my_actions[-1] != False:
            return Action.D
        last_round_opponent_defections = np.sum(history.opponent_actions[-1, :] == False)
        defection_rate = last_round_opponent_defections / (self.n_players - 1)
        if defection_rate < 0.75:
            return Action.D
        if len(history.my_payoffs) >= 3:
            recent_avg_payoff = np.mean(history.my_payoffs[-3:])
        else:
            recent_avg_payoff = np.mean(history.my_payoffs)
        if recent_avg_payoff >= 1.0:
            return Action.D
        if self.n_rounds - current_round < 3:
            return Action.D
        return Action.C

class Strategy_AGGRESSIVE_106(BaseStrategy):
    """
    AGGRESSIVE EXPLOITATION STRATEGY: "PREDATOR"
    
    A ruthless exploiter that maximizes personal gain by strategically manipulating cooperation dynamics.
    Treats other players as resources to be harvested through intelligence gathering, exploitation,
    and endgame extraction phases.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.base_threshold = max(2, math.floor(self.n * self.k / (2 * self.n - 1)))
        self.threshold = self.base_threshold
        self.player_coop_counts = np.zeros(self.n - 1)
        self.false_hope_counter = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        round_num = history.round_number
        if round_num == 1:
            return Action.D
        elif round_num == 2:
            return Action.C
        if round_num >= self.r - 2:
            return Action.D
        cooperators_last_round = sum(history.opponent_actions[-1, :])
        self.player_coop_counts += history.opponent_actions[-1, :]
        total_rounds_played = round_num
        if total_rounds_played > 0:
            avg_coop_rate = np.mean(history.opponent_actions) if history.opponent_actions.size > 0 else 0
            if avg_coop_rate > 0.6:
                self.threshold = max(1, self.base_threshold * 0.8)
            elif avg_coop_rate < 0.3:
                self.threshold = self.base_threshold * 1.2
        if self.k < 1.5:
            return Action.D
        adjusted_threshold = self.threshold
        if self.n > 6:
            adjusted_threshold *= 0.8
        if cooperators_last_round >= adjusted_threshold:
            return Action.D
        if round_num >= 2:
            prev_cooperators = sum(history.opponent_actions[-2, :])
            if cooperators_last_round > prev_cooperators and cooperators_last_round >= 2:
                return Action.D
        cooperation_rate_last = cooperators_last_round / (self.n - 1) if self.n > 1 else 0
        if cooperation_rate_last < 0.3:
            return Action.D
        if round_num >= 3:
            if round_num == 3:
                reciprocators = sum(history.opponent_actions[2, :])
                reciprocation_rate = reciprocators / (self.n - 1) if self.n > 1 else 0
                if reciprocation_rate >= 0.6:
                    cycle_position = (round_num - 3) % 3
                    if cycle_position == 0:
                        return Action.C
                    else:
                        return Action.D
        self.false_hope_counter += 1
        if self.false_hope_counter >= 5 and cooperation_rate_last < 0.4:
            self.false_hope_counter = 0
            return Action.C
        if round_num >= 2:
            recent_my_actions = history.my_actions[-2:]
            if len(recent_my_actions) >= 2 and all(recent_my_actions):
                return Action.D
        expected_cooperators = cooperators_last_round + 1
        expected_return = self.k / self.n * expected_cooperators
        cooperation_cost = 1
        if expected_return > cooperation_cost:
            return Action.C
        else:
            return Action.D

class Strategy_AGGRESSIVE_107(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "PREDATOR"
    
    This strategy treats the public goods game as a zero-sum competition,
    aggressively exploiting cooperative behaviors while minimizing contributions.
    Defaults to defection with strategic cooperation only when necessary to
    prevent system collapse that would hurt exploitation opportunities.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.theta = self.k / self.n
        self.punishment_rounds_left = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        endgame_threshold = self.r - math.ceil(0.2 * self.r)
        if current_round >= endgame_threshold:
            return Action.D
        if self.punishment_rounds_left > 0:
            self.punishment_rounds_left -= 1
            return Action.D
        if self._should_enter_punishment_mode(history):
            self.punishment_rounds_left = 2
            return Action.D
        last_round_coop_rate = self._get_cooperation_rate(history, -1)
        if last_round_coop_rate > self.theta + 0.1 or last_round_coop_rate <= self.theta - 0.1:
            return Action.D
        if self._cooperation_increasing(history, 3) or self._cooperation_stable(history, 3):
            return Action.D
        if self._should_cooperate_strategically(history, current_round):
            return Action.C
        return Action.D

    def _get_cooperation_rate(self, history: PlayerHistory, round_index: int) -> float:
        """Get cooperation rate for a specific round (including self)."""
        if round_index >= len(history.my_actions) or round_index < -len(history.my_actions):
            return 0.0
        my_cooperation = 1 if history.my_actions[round_index] else 0
        opponent_cooperation = sum(history.opponent_actions[round_index, :])
        total_cooperation = my_cooperation + opponent_cooperation
        return total_cooperation / self.n

    def _cooperation_increasing(self, history: PlayerHistory, window: int) -> bool:
        """Check if cooperation is increasing over the last 'window' rounds."""
        if len(history.my_actions) < window:
            return False
        rates = []
        for i in range(window):
            round_idx = -(i + 1)
            rates.append(self._get_cooperation_rate(history, round_idx))
        increases = sum((1 for i in range(len(rates) - 1) if rates[i] > rates[i + 1]))
        return increases >= max(1, window - 2)

    def _cooperation_stable(self, history: PlayerHistory, window: int) -> bool:
        """Check if cooperation is stable over the last 'window' rounds."""
        if len(history.my_actions) < window:
            return False
        rates = []
        for i in range(window):
            round_idx = -(i + 1)
            rates.append(self._get_cooperation_rate(history, round_idx))
        if len(rates) < 2:
            return True
        mean_rate = sum(rates) / len(rates)
        variance = sum(((r - mean_rate) ** 2 for r in rates)) / len(rates)
        return variance < 0.01

    def _cooperation_declining(self, history: PlayerHistory, consecutive_rounds: int) -> bool:
        """Check if cooperation has been declining for consecutive rounds."""
        if len(history.my_actions) < consecutive_rounds + 1:
            return False
        for i in range(consecutive_rounds):
            current_round = -(i + 1)
            previous_round = -(i + 2)
            current_rate = self._get_cooperation_rate(history, current_round)
            previous_rate = self._get_cooperation_rate(history, previous_round)
            if current_rate >= previous_rate:
                return False
        return True

    def _get_average_payoff_last_n_rounds(self, history: PlayerHistory, n: int) -> float:
        """Get average payoff over the last n rounds."""
        if len(history.my_payoffs) == 0:
            return 1.0
        rounds_to_check = min(n, len(history.my_payoffs))
        recent_payoffs = history.my_payoffs[-rounds_to_check:]
        return np.mean(recent_payoffs)

    def _should_enter_punishment_mode(self, history: PlayerHistory) -> bool:
        """Check if we should enter punishment mode due to low payoff."""
        if len(history.my_payoffs) == 0:
            return False
        return history.my_payoffs[-1] < 1.0

    def _should_cooperate_strategically(self, history: PlayerHistory, current_round: int) -> bool:
        """Check if all conditions are met for strategic cooperation."""
        rounds_remaining = self.r - current_round
        if rounds_remaining < 5:
            return False
        if not self._cooperation_declining(history, 2):
            return False
        avg_payoff = self._get_average_payoff_last_n_rounds(history, 5)
        if avg_payoff >= 1.5:
            return False
        return True

class Strategy_AGGRESSIVE_108(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "PREDATOR"
    
    Operates on aggressive opportunism - maximizing personal payoffs by exploiting 
    cooperative behavior while minimizing exposure to exploitation. Always defects 
    in first and last rounds, and uses dynamic thresholds based on group cooperation 
    rates with punishment escalation and free-rider detection.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.betrayals = 0
        self.punishment_rounds_left = 0
        self.base_threshold = max(0.1, (self.k - 1) / self.n + 0.15)
        self.cooperation_threshold = self.base_threshold
        self.free_riders = set()
        self.last_reputation_repair = -5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        current_round = state.round_number
        if history is None:
            return Action.D
        if current_round == self.r - 1:
            return Action.D
        cooperation_rate_last = self._get_last_round_cooperation_rate(history)
        avg_cooperation_so_far = self._get_average_cooperation_rate(history)
        my_cooperation_rate = self._get_my_cooperation_rate(history)
        self._update_free_rider_detection(history)
        self._adjust_threshold_by_environment(avg_cooperation_so_far)
        self._adjust_threshold_by_parameters()
        if self.r - 5 <= current_round <= self.r - 3:
            self.cooperation_threshold += 0.05
        if current_round == self.r - 2:
            return Action.D if cooperation_rate_last < 0.9 else Action.C
        if self.punishment_rounds_left > 0:
            self.punishment_rounds_left -= 1
            return Action.D
        if my_cooperation_rate < avg_cooperation_so_far - 0.2 and current_round - self.last_reputation_repair > 3:
            self.last_reputation_repair = current_round
            return Action.C
        effective_threshold = self.cooperation_threshold
        if len(self.free_riders) > 0:
            effective_threshold = max(effective_threshold, 0.8)
        if cooperation_rate_last >= effective_threshold:
            if len(history.my_actions) > 0 and history.my_actions[-1] == True and (cooperation_rate_last < 0.6):
                self.betrayals += 1
                self.punishment_rounds_left = 2
                if self.betrayals >= 2:
                    self.cooperation_threshold += 0.1
                return Action.D
            return Action.C
        else:
            return Action.D

    def _get_last_round_cooperation_rate(self, history: PlayerHistory) -> float:
        """Get cooperation rate in the most recent completed round."""
        if len(history.opponent_actions) == 0:
            return 0.0
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        if history.my_actions[-1]:
            last_round_cooperators += 1
        return last_round_cooperators / self.n

    def _get_average_cooperation_rate(self, history: PlayerHistory) -> float:
        """Get average cooperation rate across all completed rounds."""
        if len(history.opponent_actions) == 0:
            return 0.0
        total_cooperators = 0
        total_decisions = 0
        for round_idx in range(len(history.opponent_actions)):
            round_cooperators = np.sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                round_cooperators += 1
            total_cooperators += round_cooperators
            total_decisions += self.n
        return total_cooperators / total_decisions if total_decisions > 0 else 0.0

    def _get_my_cooperation_rate(self, history: PlayerHistory) -> float:
        """Get my cooperation rate so far."""
        if len(history.my_actions) == 0:
            return 0.0
        return np.sum(history.my_actions) / len(history.my_actions)

    def _update_free_rider_detection(self, history: PlayerHistory):
        """Update free rider detection based on opponent cooperation rates."""
        if len(history.opponent_actions) < 3:
            return
        for player_idx in range(self.n - 1):
            player_cooperations = np.sum(history.opponent_actions[:, player_idx])
            cooperation_rate = player_cooperations / len(history.opponent_actions)
            if cooperation_rate < 0.3:
                self.free_riders.add(player_idx)

    def _adjust_threshold_by_environment(self, avg_cooperation_rate: float):
        """Adjust cooperation threshold based on environmental assessment."""
        if avg_cooperation_rate > 0.7:
            self.cooperation_threshold = self.base_threshold * 0.9
        elif avg_cooperation_rate < 0.3:
            self.cooperation_threshold = self.base_threshold * 1.2
        else:
            self.cooperation_threshold = self.base_threshold

    def _adjust_threshold_by_parameters(self):
        """Make parameter-specific threshold adjustments."""
        if self.k > self.n / 2:
            self.cooperation_threshold = (self.k - 1) / self.n + 0.1
        elif self.k < self.n / 3:
            self.cooperation_threshold = (self.k - 1) / self.n + 0.25
        if self.n > 8:
            self.cooperation_threshold = max(self.cooperation_threshold, 0.8)

class Strategy_AGGRESSIVE_109(BaseStrategy):
    """
    Aggressive Conditional Defection Strategy (ACDS) - A ruthless exploitation strategy
    that aims to maximize individual payoffs by strategically free-riding on others'
    cooperation while minimizing its own contributions.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.opponent_cooperation_rates = np.zeros(self.n - 1)
        self.my_cumulative_advantage = 0.0
        self.base_aggression = 0.7

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        if current_round == self.r - 1:
            return Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        exploitation_potential = last_round_cooperators * (self.k / self.n)
        aggression_bonus = 0.5 + current_round / self.r * 0.3
        cooperation_threshold = self.n * (1 / self.k) + aggression_bonus
        if current_round > 0:
            for i in range(self.n - 1):
                total_rounds = current_round
                cooperations = sum(history.opponent_actions[:, i])
                self.opponent_cooperation_rates[i] = cooperations / total_rounds
        consistent_cooperators = sum((1 for rate in self.opponent_cooperation_rates if rate > 0.7))
        if consistent_cooperators > 0:
            return Action.D
        if last_round_cooperators < (self.n - 1) / 2:
            if current_round >= 2:
                recent_total_cooperation = sum(history.opponent_actions[-1, :]) + int(history.my_actions[-1])
                prev_total_cooperation = sum(history.opponent_actions[-2, :]) + int(history.my_actions[-2])
                if recent_total_cooperation < prev_total_cooperation:
                    return Action.D
        if current_round >= 0.8 * self.r:
            if random.random() < 0.3:
                return Action.D
        for i, coop_rate in enumerate(self.opponent_cooperation_rates):
            if coop_rate > 0.9 and current_round > 2:
                return Action.D
        round_factor = current_round / self.r * 0.2
        if current_round > 0:
            my_avg_payoff = np.mean(history.my_payoffs)
            opponent_avg_payoffs = np.mean(history.opponent_payoffs, axis=0)
            overall_opponent_avg = np.mean(opponent_avg_payoffs)
            advantage = my_avg_payoff - overall_opponent_avg
            exploitation_factor = max(0, advantage / current_round) * 0.1
        else:
            exploitation_factor = 0
        aggression_factor = self.base_aggression + round_factor + exploitation_factor
        if self.n <= 4:
            aggression_factor += 0.2
        elif self.n >= 10:
            aggression_factor += 0.1
        if self.k <= 1.5:
            aggression_factor += 0.2
        elif self.k >= self.n - 0.5:
            aggression_factor -= 0.1
        if exploitation_potential > cooperation_threshold:
            return Action.D
        elif random.random() < aggression_factor:
            return Action.D
        elif current_round % 5 == 0 and last_round_cooperators > 0:
            return Action.C
        else:
            return Action.D

class Strategy_AGGRESSIVE_110(BaseStrategy):
    """
    Aggressive Adaptive Defection Strategy (AADS) - A ruthless exploitation strategy
    that maximizes personal gain while minimizing risk exposure. Only cooperates
    when there's clear strategic advantage with multiple safety conditions.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.punishment_memory = set()
        self.cooperation_threshold = 0.75

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        round_num = state.round_number
        if history is None or round_num <= 2:
            return Action.D
        if round_num >= self.r - 2:
            return Action.D
        if self.r <= 5:
            return Action.D
        return self._strategic_decision(history, round_num)

    def _strategic_decision(self, history: PlayerHistory, round_num: int) -> Action:
        """Make strategic decision based on opponent behavior analysis."""
        last_round_coop_rate = self._get_last_round_cooperation_rate(history)
        recent_coop_rate = self._get_recent_cooperation_rate(history, 3)
        if self._was_recently_exploited(history):
            self.cooperation_threshold = min(0.85, self.cooperation_threshold + 0.05)
            return Action.D
        if self._should_immediately_defect(history, last_round_coop_rate):
            return Action.D
        if self._should_cooperate(history, last_round_coop_rate, recent_coop_rate, round_num):
            return Action.C
        return Action.D

    def _get_last_round_cooperation_rate(self, history: PlayerHistory) -> float:
        """Get cooperation rate of opponents in the most recent round."""
        if len(history.opponent_actions) == 0:
            return 0.0
        last_round_actions = history.opponent_actions[-1, :]
        return np.mean(last_round_actions)

    def _get_recent_cooperation_rate(self, history: PlayerHistory, num_rounds: int) -> float:
        """Get cooperation rate over the last num_rounds."""
        if len(history.opponent_actions) == 0:
            return 0.0
        start_idx = max(0, len(history.opponent_actions) - num_rounds)
        recent_actions = history.opponent_actions[start_idx:, :]
        return np.mean(recent_actions)

    def _was_recently_exploited(self, history: PlayerHistory) -> bool:
        """Check if any opponent defected in the last round while I cooperated."""
        if len(history.my_actions) == 0:
            return False
        if history.my_actions[-1]:
            last_round_actions = history.opponent_actions[-1, :]
            if not np.all(last_round_actions):
                return True
        return False

    def _should_immediately_defect(self, history: PlayerHistory, last_round_coop_rate: float) -> bool:
        """Check immediate defection triggers."""
        if last_round_coop_rate < 0.5:
            return True
        if self._detect_sucker_pattern(history):
            return True
        return False

    def _detect_sucker_pattern(self, history: PlayerHistory) -> bool:
        """Detect if opponents are alternating to exploit cooperators."""
        if len(history.opponent_actions) < 3:
            return False
        recent_rates = []
        for i in range(min(3, len(history.opponent_actions))):
            round_idx = len(history.opponent_actions) - 1 - i
            rate = np.mean(history.opponent_actions[round_idx, :])
            recent_rates.append(rate)
        if len(recent_rates) >= 2:
            rate_variance = np.var(recent_rates)
            return rate_variance > 0.2
        return False

    def _should_cooperate(self, history: PlayerHistory, last_round_coop_rate: float, recent_coop_rate: float, round_num: int) -> bool:
        """Check if all cooperation conditions are satisfied."""
        if last_round_coop_rate < self.cooperation_threshold:
            return False
        if recent_coop_rate < 0.6:
            return False
        if round_num >= self.r - 3:
            return False
        if not self._is_cooperation_profitable(history, last_round_coop_rate):
            return False
        if self.n == 2:
            return self._handle_two_player_case(history)
        return True

    def _is_cooperation_profitable(self, history: PlayerHistory, expected_coop_rate: float) -> bool:
        """Check if cooperation is expected to be profitable enough."""
        estimated_cooperators = 1 + (self.n - 1) * expected_coop_rate
        expected_payoff_coop = self.k / self.n * estimated_cooperators
        estimated_cooperators_defect = (self.n - 1) * expected_coop_rate
        expected_payoff_defect = 1 + self.k / self.n * estimated_cooperators_defect
        return expected_payoff_coop > 1.2 * expected_payoff_defect

    def _handle_two_player_case(self, history: PlayerHistory) -> bool:
        """Special handling for n=2 case - pure aggressive approach."""
        if self.k <= 1.5:
            return False
        if len(history.opponent_actions) < 5:
            return False
        last_5_actions = history.opponent_actions[-5:, 0]
        return np.all(last_5_actions)

class Strategy_AGGRESSIVE_111(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Predatory Defector"
    
    This strategy operates on aggressive exploitation while maintaining strategic flexibility.
    It aims to maximize personal payoff by exploiting cooperative players while quickly
    punishing any attempts at retaliation.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n_players = game_description.n_players
        self.n_rounds = game_description.n_rounds
        self.k = game_description.k
        self.max_resets = max(1, int(0.1 * self.n_rounds))
        self.resets_used = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.n_rounds - 1:
            return Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        cooperation_rate = last_round_cooperators / self.n_players
        if self.n_players <= 3:
            if len(history.my_actions) >= 3:
                recent_coop_rates = []
                for i in range(min(3, len(history.my_actions))):
                    round_idx = -(i + 1)
                    round_cooperators = sum(history.opponent_actions[round_idx, :])
                    recent_coop_rates.append(round_cooperators / self.n_players)
                if all((rate == 1.0 for rate in recent_coop_rates)):
                    if random.random() < 0.3:
                        return Action.C
            return Action.D
        if cooperation_rate >= 0.4:
            return Action.D
        elif cooperation_rate >= 0.2:
            if len(history.my_actions) >= 3:
                recent_rates = []
                for i in range(min(3, len(history.my_actions))):
                    round_idx = -(i + 1)
                    round_cooperators = sum(history.opponent_actions[round_idx, :])
                    recent_rates.append(round_cooperators / self.n_players)
                if len(recent_rates) >= 2:
                    recent_trend = recent_rates[0] - recent_rates[-1]
                    if recent_trend > 0:
                        return Action.D
            return Action.D
        elif cooperation_rate == 0:
            return Action.D
        else:
            return Action.D
        if len(history.my_actions) >= 2:
            prev_cooperators = sum(history.opponent_actions[-2, :]) / self.n_players
            if cooperation_rate > prev_cooperators and prev_cooperators > 0:
                return Action.D
        if len(history.my_actions) >= 2:
            prev_cooperation_rate = sum(history.opponent_actions[-2, :]) / self.n_players
            if prev_cooperation_rate > cooperation_rate and prev_cooperation_rate - cooperation_rate > 0.5:
                consecutive_drops = 0
                for i in range(1, min(4, len(history.my_actions))):
                    if len(history.my_actions) >= i + 1:
                        curr_rate = sum(history.opponent_actions[-i, :]) / self.n_players
                        prev_rate = sum(history.opponent_actions[-(i + 1), :]) / self.n_players
                        if prev_rate > curr_rate:
                            consecutive_drops += 1
                        else:
                            break
                if consecutive_drops >= 2 and self.resets_used < self.max_resets and (random.random() < 0.3):
                    self.resets_used += 1
                    return Action.C
        if self.k > 0.8 * self.n_players and cooperation_rate > 0.8:
            if random.random() < 0.1:
                return Action.C
        return Action.D

class Strategy_AGGRESSIVE_112(BaseStrategy):
    """
    AGGRESSIVE EXPLOITATION STRATEGY: "PREDATOR"
    
    This strategy treats the public goods game as a zero-sum competition where maximizing 
    personal gain takes absolute priority. It aggressively exploits cooperative behavior 
    while minimizing its own contributions through a dynamic exploitation engine based on 
    a Cooperation Exploitation Index (CEI).
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.consecutive_cooperations = 0
        self.cei_threshold_adjustment = 0.0
        self.last_cooperation_round = -10

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.consecutive_cooperations = 0
            return Action.D
        current_round = history.round_number
        total_rounds = self.game_description.n_rounds
        if current_round >= 0.8 * total_rounds:
            self.consecutive_cooperations = 0
            return Action.D
        cei = self._calculate_cei(history)
        adjusted_cei_high = 0.4 + self.cei_threshold_adjustment
        adjusted_cei_low = 0.15 + self.cei_threshold_adjustment
        if self._should_inject_false_signal(current_round):
            self.last_cooperation_round = current_round
            self.consecutive_cooperations = 1
            return Action.C
        if cei >= adjusted_cei_high:
            self.consecutive_cooperations = 0
            return Action.D
        elif cei > adjusted_cei_low:
            if random.random() < 0.8:
                self.consecutive_cooperations = 0
                return Action.D
            else:
                self.consecutive_cooperations += 1
                return Action.C
        elif self.consecutive_cooperations < 2:
            self.consecutive_cooperations += 1
            return Action.C
        else:
            self.consecutive_cooperations = 0
            return Action.D

    def _calculate_cei(self, history: PlayerHistory) -> float:
        """Calculate Cooperation Exploitation Index for last 3 rounds"""
        if history.round_number == 0:
            return 0.0
        lookback = min(3, history.round_number)
        recent_rounds = history.opponent_actions[-lookback:, :]
        total_cooperations = np.sum(recent_rounds)
        max_cooperations = (self.game_description.n_players - 1) * lookback
        if max_cooperations == 0:
            return 0.0
        cei = total_cooperations / max_cooperations
        self._update_threshold_adjustment(history)
        return cei

    def _update_threshold_adjustment(self, history: PlayerHistory):
        """Adjust CEI thresholds based on recent performance"""
        if history.round_number < 4:
            return
        recent_payoffs = history.my_payoffs[-4:]
        avg_payoff = np.mean(recent_payoffs)
        if avg_payoff < 1.2:
            self.cei_threshold_adjustment = max(-0.2, self.cei_threshold_adjustment - 0.1)
        elif avg_payoff > 1.8:
            self.cei_threshold_adjustment = min(0.15, self.cei_threshold_adjustment + 0.05)

    def _should_inject_false_signal(self, current_round: int) -> bool:
        """Determine if should inject false cooperation signal"""
        rounds_since_last = current_round - self.last_cooperation_round
        if rounds_since_last >= 5:
            if rounds_since_last == 5:
                return random.random() < 0.1
            elif rounds_since_last == 6:
                return random.random() < 0.3
            elif rounds_since_last >= 7:
                return random.random() < 0.6
        return False

class Strategy_AGGRESSIVE_113(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Opportunistic Defector"
    
    Maximizes personal payoff through aggressive exploitation while maintaining just enough
    cooperation to keep others contributing when profitable. Always defects in first and
    last two rounds, uses dynamic thresholds for middle rounds.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.punishment_rounds_left = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number + 1
        if current_round >= r - 1:
            return Action.D
        if self.punishment_rounds_left > 0:
            self.punishment_rounds_left -= 1
            return Action.D
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        cooperation_rate = last_round_cooperators / (n - 1)
        if len(history.my_actions) >= 2:
            prev_cooperators = np.sum(history.opponent_actions[-2, :])
            trend = last_round_cooperators - prev_cooperators
            predicted_cooperators = max(0, min(n - 1, last_round_cooperators + trend * 0.5))
        else:
            predicted_cooperators = last_round_cooperators
        expected_benefit = k / n * (predicted_cooperators + 1)
        if len(history.my_actions) >= 2:
            if history.my_actions[-2] == True:
                prev_round_cooperators = np.sum(history.opponent_actions[-2, :]) if len(history.my_actions) >= 2 else last_round_cooperators
                cooperation_drop = prev_round_cooperators - last_round_cooperators
                if cooperation_drop > (n - 1) * 0.5:
                    self.punishment_rounds_left = 2
                    return Action.D
        lookback = min(5, len(history.my_actions))
        my_recent_defections = np.sum(history.my_actions[-lookback:] == False)
        consecutive_defections = 0
        consecutive_cooperations = 0
        for i in range(len(history.my_actions) - 1, -1, -1):
            if history.my_actions[i] == False:
                consecutive_defections += 1
            else:
                break
        for i in range(len(history.my_actions) - 1, -1, -1):
            if history.my_actions[i] == True:
                consecutive_cooperations += 1
            else:
                break
        profit_threshold = 1.2
        if k > 1.8:
            profit_threshold = 1.15
        elif k < 1.4:
            profit_threshold = 1.3
        if expected_benefit > profit_threshold:
            return Action.C
        if cooperation_rate > 0.9:
            return Action.C
        if cooperation_rate > 0.7 and my_recent_defections > 3:
            return Action.C
        if consecutive_defections > 5 and cooperation_rate > 0.6:
            return Action.C
        if consecutive_cooperations > 2:
            return Action.D
        return Action.D

class Strategy_AGGRESSIVE_114(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Opportunistic Predator"
    
    Exploits cooperative opponents through systematic defection while maintaining
    strategic flexibility to avoid severe punishment scenarios.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.punishment_avoidance_used = False

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round <= 3:
            return Action.D
        if current_round >= self.r - 1:
            return Action.D
        return self._adaptive_predation_decision(history)

    def _adaptive_predation_decision(self, history: PlayerHistory) -> Action:
        total_player_rounds = self.n * history.round_number
        total_cooperations = np.sum(history.opponent_actions) + np.sum(history.my_actions)
        cooperation_rate = total_cooperations / total_player_rounds
        if cooperation_rate >= 0.4 or cooperation_rate < 0.15:
            return Action.D
        if self._recent_cooperation_increase(history):
            return Action.D
        if self._was_only_defector_last_round(history) and (not self.punishment_avoidance_used):
            self.punishment_avoidance_used = True
            return Action.C
        return Action.D

    def _recent_cooperation_increase(self, history: PlayerHistory) -> bool:
        """Check if cooperation increased in last 2 rounds"""
        if history.round_number < 3:
            return False
        recent_rounds = min(3, history.round_number)
        cooperation_counts = []
        for i in range(recent_rounds):
            round_idx = history.round_number - 1 - i
            round_cooperations = np.sum(history.opponent_actions[round_idx, :])
            if history.my_actions[round_idx]:
                round_cooperations += 1
            cooperation_counts.append(round_cooperations)
        if len(cooperation_counts) >= 3:
            return cooperation_counts[0] > cooperation_counts[2] and cooperation_counts[1] > cooperation_counts[2]
        elif len(cooperation_counts) >= 2:
            return cooperation_counts[0] > cooperation_counts[1]
        return False

    def _was_only_defector_last_round(self, history: PlayerHistory) -> bool:
        """Check if this player was the only defector in the last round"""
        if history.round_number == 0:
            return False
        last_round_idx = history.round_number - 1
        if history.my_actions[last_round_idx]:
            return False
        all_opponents_cooperated = np.all(history.opponent_actions[last_round_idx, :])
        return all_opponents_cooperated

class Strategy_AGGRESSIVE_115(BaseStrategy):
    """
    Aggressive Exploiter Strategy: Systematically exploits cooperative behavior
    while contributing minimally. Defects first round, only cooperates when almost
    everyone else cooperated, and becomes increasingly aggressive toward game end.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        n = self.game_description.n_players
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == r:
            return Action.D
        opponent_cooperators = sum(history.opponent_actions[-1, :])
        my_last_action = history.my_actions[-1]
        total_cooperators = opponent_cooperators + (1 if my_last_action else 0)
        prev_coop_rate = total_cooperators / n
        if current_round >= r - 2:
            if prev_coop_rate >= 0.9:
                return Action.C if random.random() < 0.1 else Action.D
            return Action.D
        exploitation_threshold = (n - 1) / n
        if prev_coop_rate >= exploitation_threshold:
            return Action.C
        if len(history.my_actions) >= 2:
            prev_opponent_cooperators = sum(history.opponent_actions[-2, :])
            prev_my_action = history.my_actions[-2]
            prev_total_cooperators = prev_opponent_cooperators + (1 if prev_my_action else 0)
            prev_prev_coop_rate = prev_total_cooperators / n
            if prev_coop_rate < prev_prev_coop_rate:
                return Action.D
        low_coop_streak = self._count_consecutive_low_cooperation(history, n, threshold=0.3)
        if low_coop_streak >= 3 and current_round % 4 == 0:
            return Action.C
        return Action.D

    def _count_consecutive_low_cooperation(self, history: PlayerHistory, n: int, threshold: float) -> int:
        """Count consecutive rounds with low cooperation rates from the end."""
        streak = 0
        for i in range(len(history.my_actions) - 1, -1, -1):
            opponent_cooperators = sum(history.opponent_actions[i, :])
            my_action = history.my_actions[i]
            total_cooperators = opponent_cooperators + (1 if my_action else 0)
            coop_rate = total_cooperators / n
            if coop_rate < threshold:
                streak += 1
            else:
                break
        return streak

class Strategy_AGGRESSIVE_116(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Predatory Switcher"
    
    This strategy maximizes personal payoffs by aggressively exploiting cooperative players
    while minimizing vulnerability. Always defects in first and last rounds, and only
    cooperates when the mathematical benefit clearly exceeds the cost.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        recent_rounds = min(3, history.round_number)
        if recent_rounds == 0:
            recent_coop_rate = 0.0
        else:
            recent_opponent_actions = history.opponent_actions[-recent_rounds:, :]
            total_decisions = recent_opponent_actions.size
            total_cooperations = np.sum(recent_opponent_actions)
            recent_coop_rate = total_cooperations / total_decisions if total_decisions > 0 else 0.0
        if self._detect_exploitation_attempt(history):
            return Action.D
        if current_round > 0 and current_round % 6 == 0:
            return self._opposite_of_recent_pattern(history)
        exploitation_bonus = 0.2
        cooperation_threshold = 1.0 + exploitation_bonus
        expected_benefit = recent_coop_rate * self.k / self.n
        if recent_coop_rate >= 0.6:
            if expected_benefit > cooperation_threshold:
                return Action.C
            else:
                return Action.D
        elif recent_coop_rate >= 0.3:
            if recent_coop_rate >= 0.8 or current_round % 4 == 0:
                return Action.C
            else:
                return Action.D
        else:
            return Action.D

    def _detect_exploitation_attempt(self, history: PlayerHistory) -> bool:
        """Detect if others are exploiting our cooperation."""
        if history.round_number < 3:
            return False
        my_recent_actions = history.my_actions[-3:]
        my_coop_rate = np.mean(my_recent_actions)
        if my_coop_rate <= 0.5:
            return False
        if history.round_number < 6:
            return False
        recent_3_opponent_actions = history.opponent_actions[-3:, :]
        previous_3_opponent_actions = history.opponent_actions[-6:-3, :]
        recent_others_coop_rate = np.mean(recent_3_opponent_actions)
        previous_others_coop_rate = np.mean(previous_3_opponent_actions)
        return previous_others_coop_rate - recent_others_coop_rate > 0.2

    def _opposite_of_recent_pattern(self, history: PlayerHistory) -> Action:
        """Return opposite of recent pattern for unpredictability."""
        if history.round_number < 2:
            return Action.D
        recent_actions = history.my_actions[-2:]
        if np.all(recent_actions):
            return Action.D
        elif not np.any(recent_actions):
            return Action.C
        else:
            return Action.D

class Strategy_AGGRESSIVE_117(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "PREDATOR"
    
    Operates on aggressive exploitation - maximizing personal payoff by strategically 
    free-riding while punishing those who attempt to exploit us. Uses strategic 
    deception in round 1, then adaptively exploits cooperative environments while 
    maintaining punishment mechanisms.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.punishment_rounds_remaining = 0
        self.grudge_list = set()

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.punishment_rounds_remaining = 0
            return Action.C
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        last_round_idx = history.round_number - 1
        cooperators_last_round = sum(history.opponent_actions[last_round_idx, :])
        my_last_action = history.my_actions[last_round_idx]
        if my_last_action and self.punishment_rounds_remaining == 0:
            defectors_against_me = sum(1 - history.opponent_actions[last_round_idx, :])
            if defectors_against_me > 0:
                self.punishment_rounds_remaining = 2
                for i in range(self.n - 1):
                    if not history.opponent_actions[last_round_idx, i]:
                        self.grudge_list.add(i)
        if self.punishment_rounds_remaining > 0:
            self.punishment_rounds_remaining -= 1
            return Action.D
        total_players = self.n
        if cooperators_last_round >= total_players / 2:
            return Action.D
        if cooperators_last_round >= 2:
            if random.random() < 0.8:
                return Action.D
            else:
                return Action.C
        if cooperators_last_round < 2 and (not my_last_action):
            consecutive_defects = 0
            for round_idx in range(max(0, history.round_number - 3), history.round_number):
                if round_idx >= 0:
                    round_cooperators = sum(history.opponent_actions[round_idx, :])
                    my_action_that_round = history.my_actions[round_idx]
                    if round_cooperators == 0 and (not my_action_that_round):
                        consecutive_defects += 1
                    else:
                        break
            if consecutive_defects >= 3:
                return Action.C
        if history.round_number >= 2:
            prev_cooperators = sum(history.opponent_actions[last_round_idx - 1, :])
            if cooperators_last_round > prev_cooperators:
                return Action.D
        if history.round_number > 0:
            total_cooperation_rate = 0
            for round_idx in range(history.round_number):
                round_cooperators = sum(history.opponent_actions[round_idx, :])
                total_cooperation_rate += round_cooperators / (self.n - 1)
            avg_cooperation_rate = total_cooperation_rate / history.round_number
            if avg_cooperation_rate > 0.6:
                return Action.D
            elif avg_cooperation_rate < 0.3:
                if random.random() < 0.2:
                    return Action.C
        if self.n <= 4:
            if random.random() < 0.9:
                return Action.D
        if self.n >= 8:
            if cooperators_last_round >= 0.8 * (self.n - 1):
                return Action.D
        if self.k > 1.5 * self.n:
            if cooperators_last_round >= 0.8 * (self.n - 1):
                if random.random() < 0.3:
                    return Action.C
        recent_cooperators = history.opponent_actions[last_round_idx, :]
        for grudge_player in self.grudge_list:
            if grudge_player < len(recent_cooperators) and recent_cooperators[grudge_player]:
                if random.random() < 0.9:
                    return Action.D
        return Action.D

class Strategy_AGGRESSIVE_118(BaseStrategy):
    """
    Aggressive Predator Strategy: Maximizes personal gain while minimizing cooperation.
    Exploits cooperative players while protecting against exploitation by aggressive opponents.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.betrayal_count = [0] * (self.n - 1)
        self.punishment_rounds_remaining = 0
        self.exploitability_scores = [0.0] * (self.n - 1)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        if current_round >= self.r - 3:
            return Action.D
        if self.punishment_rounds_remaining > 0:
            self.punishment_rounds_remaining -= 1
            return Action.D
        if len(history.my_actions) > 0 and history.my_actions[-1]:
            betrayers = sum((1 for i in range(self.n - 1) if not history.opponent_actions[-1, i]))
            if betrayers > 0:
                self.punishment_rounds_remaining = 2
                for i in range(self.n - 1):
                    if not history.opponent_actions[-1, i]:
                        self.betrayal_count[i] += 1
                return Action.D
        self._update_exploitability_scores(history)
        if self._should_crush_momentum(history):
            return Action.D
        expected_cooperators = sum((1 for score in self.exploitability_scores if score > 0.6))
        cooperation_threshold = math.ceil(self.n / self.k)
        exploitation_benefit = self.k / self.n * expected_cooperators
        if expected_cooperators >= cooperation_threshold and exploitation_benefit > 1.2:
            return Action.C
        else:
            return Action.D

    def _update_exploitability_scores(self, history):
        """Update exploitability scores for each opponent based on recent behavior."""
        current_round = history.round_number
        window_size = min(5, max(1, current_round // 2))
        for i in range(self.n - 1):
            start_round = max(0, current_round - window_size)
            recent_actions = history.opponent_actions[start_round:current_round, i]
            if len(recent_actions) > 0:
                cooperation_rate = np.mean(recent_actions)
                recent_trend_bonus = 0.0
                if len(recent_actions) >= 3:
                    last_3 = recent_actions[-3:]
                    if np.mean(last_3) > 0.66:
                        recent_trend_bonus = 0.1
                self.exploitability_scores[i] = cooperation_rate * (1 + recent_trend_bonus)
                if self.betrayal_count[i] >= 2:
                    self.exploitability_scores[i] *= 0.5

    def _should_crush_momentum(self, history):
        """Check if we should break cooperative momentum."""
        current_round = history.round_number
        if current_round < 3:
            return False
        last_3_rounds = history.opponent_actions[-3:, :]
        overall_cooperation_rate = np.mean(last_3_rounds)
        return overall_cooperation_rate > 0.7

class Strategy_AGGRESSIVE_119(BaseStrategy):
    """
    Aggressive Predator Strategy: Maximizes personal payoffs by exploiting cooperative players 
    while minimizing own contributions. Treats cooperation as weakness and defection as strength.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.aggression_bonus = 0.1

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r - 1:
            return Action.D
        last_round_cooperators = int(sum(history.opponent_actions[-1, :]))
        if last_round_cooperators > self.n / 2:
            return Action.D
        if last_round_cooperators >= (self.n - 1) / 2:
            return Action.D
        elif last_round_cooperators <= self.n / 4:
            return Action.D
        rounds_available = min(3, len(history.my_actions))
        if rounds_available >= 2:
            cooperation_trend = self._analyze_trend(history, rounds_available)
            if cooperation_trend > 0:
                return Action.D
            elif cooperation_trend < 0 and last_round_cooperators > 1:
                return Action.D
            elif cooperation_trend == 0 and last_round_cooperators <= 2:
                if last_round_cooperators == 1:
                    if self._payoff_threshold_check(last_round_cooperators):
                        return Action.C
        if current_round >= self.r - 3:
            return Action.D
        return Action.D

    def _analyze_trend(self, history: PlayerHistory, rounds_to_check: int) -> int:
        """Analyze cooperation trend over last few rounds. Returns 1 (increasing), 0 (stable), -1 (decreasing)"""
        cooperation_counts = []
        for i in range(rounds_to_check):
            round_idx = -(i + 1)
            cooperators = int(sum(history.opponent_actions[round_idx, :]))
            cooperation_counts.append(cooperators)
        cooperation_counts.reverse()
        if len(cooperation_counts) < 2:
            return 0
        increasing = 0
        decreasing = 0
        for i in range(1, len(cooperation_counts)):
            if cooperation_counts[i] > cooperation_counts[i - 1]:
                increasing += 1
            elif cooperation_counts[i] < cooperation_counts[i - 1]:
                decreasing += 1
        if increasing > decreasing:
            return 1
        elif decreasing > increasing:
            return -1
        else:
            return 0

    def _payoff_threshold_check(self, predicted_cooperators: int) -> bool:
        """Check if cooperation would be profitable enough to overcome aggression bias"""
        expected_payoff_cooperate = self.k / self.n * (predicted_cooperators + 1)
        expected_payoff_defect = 1 + self.k / self.n * predicted_cooperators
        return expected_payoff_cooperate > expected_payoff_defect + self.aggression_bonus

class Strategy_AGGRESSIVE_120(BaseStrategy):
    """
    AGGRESSIVE EXPLOITATION STRATEGY: "PREDATOR"
    
    This strategy operates on the principle that cooperation is a weakness to be exploited.
    It aggressively seeks to maximize individual payoff by free-riding on others' cooperation
    while contributing as little as possible to the public good.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.punishment_rounds_remaining = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.punishment_rounds_remaining = 0
            return Action.D
        n = self.game_description.n_players
        k = self.game_description.k
        r = self.game_description.n_rounds
        current_round = state.round_number
        if current_round == r - 1:
            return Action.D
        last_round_idx = history.round_number - 1
        last_round_cooperators = sum(history.opponent_actions[last_round_idx, :])
        if history.my_actions[last_round_idx]:
            last_round_cooperators += 1
        last_round_coop_rate = last_round_cooperators / n
        my_last_payoff = history.my_payoffs[last_round_idx]
        if last_round_coop_rate >= k / n:
            return Action.D
        if my_last_payoff < 1.0:
            punishment_duration = 3 if n <= 4 else 2
            self.punishment_rounds_remaining = punishment_duration
        if self.punishment_rounds_remaining > 0:
            self.punishment_rounds_remaining -= 1
            return Action.D
        if history.round_number >= 3:
            recent_rounds = min(3, history.round_number)
            total_coop_rate = 0
            for i in range(recent_rounds):
                round_idx = history.round_number - 1 - i
                round_cooperators = sum(history.opponent_actions[round_idx, :])
                if history.my_actions[round_idx]:
                    round_cooperators += 1
                total_coop_rate += round_cooperators / n
            recent_coop_rate = total_coop_rate / recent_rounds
            coop_threshold = 0.6
            if r <= 5:
                coop_threshold = 0.75
            elif k > n - 1:
                coop_threshold = 0.5
            if recent_coop_rate >= coop_threshold:
                return Action.C
        return Action.D

class Strategy_AGGRESSIVE_121(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "PREDATOR"
    
    Treats the public goods game as zero-sum competition, aggressively exploiting 
    cooperative behavior while minimizing own contributions. Adapts quickly to 
    opponent patterns to maintain dominance through systematic defection with 
    strategic cooperation only when highly profitable.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        if current_round < 3:
            return Action.D
        if current_round >= self.r - 2:
            return Action.D
        return self._adaptive_predation_decision(history)

    def _adaptive_predation_decision(self, history: PlayerHistory) -> Action:
        current_round = history.round_number
        recent_rounds = min(3, current_round)
        recent_cooperators = []
        for i in range(recent_rounds):
            round_idx = current_round - 1 - i
            cooperators_in_round = np.sum(history.opponent_actions[round_idx, :])
            recent_cooperators.append(cooperators_in_round)
        avg_cooperators = np.mean(recent_cooperators)
        cer = avg_cooperators * self.k / self.n
        cer_threshold = 1.5 if self.n <= 4 else 1.2
        if self.k > self.n - 1:
            return self._fake_cooperator_mode(history)
        if self.k < 1.5:
            return Action.D
        if cer > cer_threshold:
            return Action.D
        elif 0.8 <= cer <= cer_threshold:
            return self._punishment_protocol(history)
        else:
            return Action.D

    def _punishment_protocol(self, history: PlayerHistory) -> Action:
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        total_opponents = self.n - 1
        cooperation_rate = last_round_cooperators / total_opponents
        if cooperation_rate > 0.6:
            return Action.C
        elif cooperation_rate >= 0.4:
            return Action.D if random.random() < 0.7 else Action.C
        else:
            return Action.D

    def _fake_cooperator_mode(self, history: PlayerHistory) -> Action:
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        total_opponents = self.n - 1
        cooperation_rate = last_round_cooperators / total_opponents
        if cooperation_rate > 0.8:
            return Action.C
        else:
            return Action.D

    def _detect_momentum(self, history: PlayerHistory) -> float:
        current_round = history.round_number
        if current_round < 3:
            return 0.0
        current_cooperators = np.sum(history.opponent_actions[-1, :])
        old_cooperators = np.sum(history.opponent_actions[-4, :]) if current_round >= 4 else current_cooperators
        momentum = (current_cooperators - old_cooperators) / 3.0
        return momentum

    def _calculate_expected_payoffs(self, history: PlayerHistory) -> tuple:
        recent_cooperators = np.sum(history.opponent_actions[-1, :])
        expected_payoff_cooperate = self.k / self.n * (recent_cooperators + 1)
        expected_payoff_defect = 1 + self.k / self.n * recent_cooperators
        return (expected_payoff_cooperate, expected_payoff_defect)

class Strategy_AGGRESSIVE_122(BaseStrategy):
    """
    Predatory Adaptive Defection (PAD) - An aggressive exploitation strategy that maximizes 
    personal payoffs by exploiting cooperative opponents while punishing those who threaten 
    profitability. Always defects in first and last rounds, and uses adaptive thresholds 
    to decide when cooperation is profitable in between.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.punishment_rounds_remaining = 0
        self.last_coop_rates = []

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        if current_round == self.r:
            return Action.D
        last_round_actions = np.concatenate([[history.my_actions[-1]], history.opponent_actions[-1, :]])
        cooperators_last_round = np.sum(last_round_actions)
        coop_rate = cooperators_last_round / self.n
        self.last_coop_rates.append(coop_rate)
        if len(self.last_coop_rates) > 3:
            self.last_coop_rates.pop(0)
        if current_round == self.r - 1:
            return Action.C if coop_rate >= 0.8 else Action.D
        if self.punishment_rounds_remaining > 0:
            self.punishment_rounds_remaining -= 1
            return Action.D
        if self._should_punish_exploiters(history):
            self.punishment_rounds_remaining = 1
            return Action.D
        if self.n <= 4:
            threshold = 0.75
        elif self.k > 0.8 * self.n:
            threshold = (self.n - self.k) / (self.n + 0.5)
        else:
            threshold = (self.n - self.k) / (self.n - 1)
        if self._has_positive_momentum():
            return Action.C
        if self._has_negative_momentum():
            return Action.D
        if cooperators_last_round == 0:
            return Action.D
        if cooperators_last_round == 1 and history.my_actions[-1]:
            self.punishment_rounds_remaining = 2
            return Action.D
        if coop_rate >= threshold:
            if random.random() < 0.05:
                return Action.D
            return Action.C
        else:
            return Action.D

    def _should_punish_exploiters(self, history: PlayerHistory) -> bool:
        """Check if any opponent has defected for 2+ consecutive rounds while I cooperated."""
        if len(history.my_actions) < 2:
            return False
        if not (history.my_actions[-1] and history.my_actions[-2]):
            return False
        for player_idx in range(history.opponent_actions.shape[1]):
            if not history.opponent_actions[-1, player_idx] and (not history.opponent_actions[-2, player_idx]):
                return True
        return False

    def _has_positive_momentum(self) -> bool:
        """Check if cooperation rate has been increasing for 2+ rounds and is > 0.6."""
        if len(self.last_coop_rates) < 3:
            return False
        recent_rates = self.last_coop_rates[-3:]
        is_increasing = recent_rates[1] > recent_rates[0] and recent_rates[2] > recent_rates[1]
        is_high = recent_rates[-1] > 0.6
        return is_increasing and is_high

    def _has_negative_momentum(self) -> bool:
        """Check if cooperation rate has been decreasing for 2+ rounds."""
        if len(self.last_coop_rates) < 3:
            return False
        recent_rates = self.last_coop_rates[-3:]
        return recent_rates[1] < recent_rates[0] and recent_rates[2] < recent_rates[1]

class Strategy_AGGRESSIVE_123(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Opportunistic Predator"
    
    Maximizes personal payoff by exploiting cooperative players while minimizing own contributions.
    Always defects in round 1 and final round, with adaptive exploitation in between based on
    cooperation rates and momentum patterns.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.my_advantage = self.k / self.n - 1
        self.punishment_rounds_remaining = 0
        self.declining_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            self.punishment_rounds_remaining = 0
            self.declining_rounds = 0
            return Action.D
        current_round = state.round_number + 1
        if current_round == self.r:
            return Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        total_players_last_round = self.n
        my_last_action = history.my_actions[-1]
        if my_last_action:
            total_cooperators_last_round = last_round_cooperators + 1
        else:
            total_cooperators_last_round = last_round_cooperators
        coop_rate = total_cooperators_last_round / self.n
        if len(history.my_actions) >= 2:
            prev_round_cooperators = sum(history.opponent_actions[-2, :])
            if history.my_actions[-2]:
                prev_total_cooperators = prev_round_cooperators + 1
            else:
                prev_total_cooperators = prev_round_cooperators
            prev_coop_rate = prev_total_cooperators / self.n
            if coop_rate < prev_coop_rate:
                self.declining_rounds += 1
            else:
                self.declining_rounds = 0
        if self.punishment_rounds_remaining > 0:
            self.punishment_rounds_remaining -= 1
            return Action.D
        if self.declining_rounds >= 2:
            return Action.D
        if len(history.my_actions) >= 1 and history.my_actions[-1]:
            if last_round_cooperators < self.n - 2:
                self.punishment_rounds_remaining = 1
                return Action.D
        if current_round > 0.8 * self.r:
            return Action.D
        if current_round <= 3:
            if current_round == 2 and coop_rate < 1.0:
                return Action.D
            if current_round == 3 and coop_rate < 0.8:
                return Action.D
        cooperation_threshold = (self.n - 1) / self.n
        if coop_rate >= cooperation_threshold and current_round <= self.r / 2:
            if self.k / self.n > 0.8:
                if coop_rate >= 0.9:
                    return Action.C
            elif self.k / self.n < 0.3:
                if coop_rate >= 0.95:
                    return Action.C
            elif coop_rate >= cooperation_threshold:
                return Action.C
        if coop_rate > 0.8 and current_round <= 0.6 * self.r:
            my_defections = sum((1 for action in history.my_actions if not action))
            my_defection_rate = my_defections / len(history.my_actions)
            total_opponent_defections = 0
            total_opponent_actions = 0
            for round_idx in range(len(history.my_actions)):
                opponent_defections = sum((1 for action in history.opponent_actions[round_idx, :] if not action))
                total_opponent_defections += opponent_defections
                total_opponent_actions += self.n - 1
            avg_opponent_defection_rate = total_opponent_defections / total_opponent_actions if total_opponent_actions > 0 else 0
            if my_defection_rate <= avg_opponent_defection_rate and coop_rate > 0.85:
                return Action.C
        return Action.D

class Strategy_AGGRESSIVE_124(BaseStrategy):
    """
    AGGRESSIVE EXPLOITATION STRATEGY: "PREDATOR"
    
    Operates on aggressive exploitation principle - maximizing personal payoff while minimizing
    opportunities for opponents to exploit us. Always defects first round, uses high cooperation
    thresholds, detects and punishes exploiters, and switches to permanent defection in endgame.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.base_threshold = max(0.7, (self.n - 1) / self.n)
        k_n_ratio = self.k / self.n
        if k_n_ratio > 0.4:
            self.aggression_threshold = 0.6
        elif k_n_ratio < 0.3:
            self.aggression_threshold = 0.8
        else:
            self.aggression_threshold = self.base_threshold
        self.permanent_defection_mode = False
        self.punishment_rounds_remaining = 0
        self.exploiter_marks = np.zeros(self.n - 1, dtype=bool)

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        endgame_threshold = max(2, int(0.2 * self.r))
        if current_round >= self.r - endgame_threshold:
            return Action.D
        if self.permanent_defection_mode:
            return Action.D
        if self.punishment_rounds_remaining > 0:
            self.punishment_rounds_remaining -= 1
            return Action.D
        self._update_exploiter_detection(history)
        if np.sum(self.exploiter_marks) >= (self.n - 1) * 0.5:
            self.permanent_defection_mode = True
            return Action.D
        last_round_cooperators = np.sum(history.opponent_actions[-1, :])
        last_round_coop_rate = last_round_cooperators / self.n
        if self._check_sucker_threshold(history, last_round_cooperators):
            self.punishment_rounds_remaining = 1
            return Action.D
        if last_round_coop_rate >= self.aggression_threshold:
            if last_round_cooperators == self.n - 1:
                return Action.C
            elif last_round_coop_rate >= self.aggression_threshold:
                return Action.C
        return Action.D

    def _update_exploiter_detection(self, history: PlayerHistory):
        """Track opponent cooperation rates over sliding window and mark exploiters"""
        rounds_completed = history.round_number
        if rounds_completed < 3:
            return
        window_size = min(3, rounds_completed)
        recent_actions = history.opponent_actions[-window_size:, :]
        for opp_idx in range(self.n - 1):
            coop_rate = np.mean(recent_actions[:, opp_idx])
            if coop_rate < 0.5:
                self.exploiter_marks[opp_idx] = True

    def _check_sucker_threshold(self, history: PlayerHistory, last_round_cooperators: int) -> bool:
        """Check if we were suckered in the last round and should trigger punishment"""
        if history.round_number == 0:
            return False
        if not history.my_actions[-1]:
            return False
        expected_cooperators = last_round_cooperators + 1
        sucker_threshold = self.k / self.n * (expected_cooperators - 1)
        last_payoff = history.my_payoffs[-1]
        return last_payoff < sucker_threshold

class Strategy_AGGRESSIVE_125(BaseStrategy):
    """
    Ruthless Opportunist strategy that maximizes exploitation with minimal cooperation.
    Always defects in first round, tracks opponent exploitability, and uses aggressive
    end-game defection while disrupting cooperative coalitions.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.punishment_rounds_left = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        if current_round == self.r - 1:
            return Action.D
        if self.punishment_rounds_left > 0:
            self.punishment_rounds_left -= 1
            return Action.D
        exploitability_scores = []
        for player_idx in range(self.n - 1):
            cooperations = sum(history.opponent_actions[:, player_idx])
            rounds_played = len(history.opponent_actions)
            es = cooperations / rounds_played if rounds_played > 0 else 0
            exploitability_scores.append(es)
        avg_exploitability = np.mean(exploitability_scores) if exploitability_scores else 0
        if len(history.opponent_actions) > 0:
            recent_coop_rate = np.mean(history.opponent_actions[-1, :])
            expected_cooperators = recent_coop_rate * (self.n - 1)
        else:
            expected_cooperators = 0
        if len(history.opponent_actions) > 0:
            last_round_cooperators = sum(history.opponent_actions[-1, :])
            if last_round_cooperators < 0.4 * (self.n - 1):
                self.punishment_rounds_left = 2
                return Action.D
        remaining_rounds = self.r - current_round
        if remaining_rounds <= max(1, int(0.2 * self.r)):
            if remaining_rounds <= 3:
                return Action.D
            if random.random() < 0.5:
                return Action.D
        personal_benefit_if_defect = 1.0 + self.k / self.n * expected_cooperators
        personal_benefit_if_coop = 0.0 + self.k / self.n * (expected_cooperators + 1)
        exploitation_threshold = 1.0
        if personal_benefit_if_coop >= exploitation_threshold * 0.9 and avg_exploitability > 0.5:
            min_cooperators_needed = self.n * self.k / (self.k + self.n)
            if expected_cooperators >= min_cooperators_needed:
                if self.n <= 4:
                    if avg_exploitability > 0.7:
                        return Action.C
                else:
                    consistent_cooperators = 0
                    if len(history.opponent_actions) >= 3:
                        for player_idx in range(self.n - 1):
                            recent_actions = history.opponent_actions[-3:, player_idx]
                            if sum(recent_actions) == 3:
                                consistent_cooperators += 1
                    if consistent_cooperators >= 3:
                        if random.random() < 0.3:
                            return Action.C
                    else:
                        return Action.C
        if self.k / self.n > 0.8:
            if avg_exploitability > 0.7:
                return Action.C
        if self.k / self.n < 0.3:
            if avg_exploitability < 0.8:
                return Action.D
        if current_round < int(0.25 * self.r):
            recent_coop_rate = np.mean(history.opponent_actions) if len(history.opponent_actions) > 0 else 0
            if recent_coop_rate > 0.6:
                if random.random() < 0.2:
                    return Action.C
        return Action.D

class Strategy_AGGRESSIVE_126(BaseStrategy):
    """
    AGGRESSIVE EXPLOITATION STRATEGY: "PREDATOR"
    
    This strategy treats the public goods game as a zero-sum competition, maximizing 
    personal payoff by exploiting others' cooperation while minimizing contributions.
    Uses adaptive punishment mechanisms and aggressive opportunism.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.exploitation_threshold = (self.k - 1) / self.k
        self.collapse_threshold = 0.3
        self.profit_threshold = 1.5
        self.mark_threshold = 0.7
        self.cooperation_budget = 0.2

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        if current_round >= self.r - 1:
            return Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        coop_rate = last_round_cooperators / self.n
        my_cooperation_rate = sum(history.my_actions) / len(history.my_actions)
        if coop_rate >= self.exploitation_threshold or coop_rate < self.collapse_threshold:
            return Action.D
        if len(history.my_payoffs) > 0 and history.my_payoffs[-1] >= self.profit_threshold:
            return Action.D if not history.my_actions[-1] else Action.C
        if len(history.opponent_actions) >= 2:
            recent_coop_rate = (sum(history.opponent_actions[-1, :]) + sum(history.opponent_actions[-2, :])) / (2 * self.n)
            if recent_coop_rate > 0.5:
                return Action.D
        avg_cooperation = np.mean(history.opponent_actions)
        theoretical_free_rider = 1 + self.k * avg_cooperation / self.n
        my_avg_payoff = np.mean(history.my_payoffs)
        if my_avg_payoff < theoretical_free_rider:
            return Action.D
        if len(history.opponent_actions) >= 3:
            for player_idx in range(self.n):
                player_coop_rate = sum(history.opponent_actions[:, player_idx]) / len(history.opponent_actions)
                if player_coop_rate > self.mark_threshold:
                    return Action.D
        aggression_multiplier = 1.5 if current_round > self.r // 2 else 1.0
        adjusted_threshold = self.exploitation_threshold * aggression_multiplier
        if coop_rate >= adjusted_threshold:
            return Action.D
        if len(history.opponent_actions) >= 2:
            if not history.my_actions[-1]:
                prev_coop = sum(history.opponent_actions[-2, :]) / self.n if len(history.opponent_actions) >= 2 else 0
                if coop_rate >= prev_coop:
                    return Action.D
        remaining_rounds = self.r - current_round
        if remaining_rounds <= self.r // 4:
            if coop_rate >= 0.2:
                return Action.D
        if my_cooperation_rate < self.cooperation_budget:
            if random.random() < 0.1 and coop_rate > 0.4:
                return Action.C
        return Action.D

class Strategy_AGGRESSIVE_127(BaseStrategy):
    """
    Aggressive Predator Strategy: An exploitative approach that maximizes personal gain 
    while punishing cooperation and preventing stable cooperative equilibria through 
    adaptive aggression and psychological warfare tactics.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k
        self.opponent_types = ['unknown'] * (self.n - 1)
        self.punishment_rounds_left = 0
        self.anti_coordination_mode = 0
        self.base_aggression = 0.7

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = history.round_number
        rounds_remaining = self.r - current_round - 1
        if rounds_remaining == 0:
            return Action.D
        last_round_opponents = history.opponent_actions[-1, :]
        total_cooperators_last = sum(last_round_opponents)
        cooperation_rate = total_cooperators_last / self.n
        my_last_action = history.my_actions[-1]
        self._update_opponent_types(history)
        if self.punishment_rounds_left > 0:
            self.punishment_rounds_left -= 1
            return Action.D
        if my_last_action and sum(last_round_opponents) < len(last_round_opponents):
            self.punishment_rounds_left = random.choice([1, 2, 3])
            return Action.D
        if current_round >= 2:
            prev_round = history.opponent_actions[-2, :]
            switches = sum(prev_round != last_round_opponents)
            if switches > self.n * 0.5:
                self.anti_coordination_mode = 3
        if self.anti_coordination_mode > 0:
            self.anti_coordination_mode -= 1
            return Action.D
        my_avg_payoff = np.mean(history.my_payoffs)
        opponent_avg_payoffs = np.mean(history.opponent_payoffs, axis=0)
        my_ranking = sum((my_avg_payoff >= opp_avg for opp_avg in opponent_avg_payoffs)) + 1
        aggression_factor = self.base_aggression + 0.3 * my_ranking / self.n
        aggression_threshold = 0.4
        if self.n <= 4:
            aggression_threshold = 0.1
        elif self.n >= 10:
            aggression_threshold = 0.3
        if self.k > self.n * 0.8:
            aggression_threshold = 0.3
        elif self.k < 1.5:
            aggression_threshold = 0.5
        if cooperation_rate >= aggression_threshold:
            return Action.D
        if cooperation_rate < 0.2 and rounds_remaining >= 3:
            if rounds_remaining == 2 and random.random() < 0.3:
                return Action.C
            if random.random() < 0.3:
                return Action.C
        return Action.D

    def _update_opponent_types(self, history):
        """Update opponent classifications based on cooperation rates"""
        if history.round_number < 3:
            return
        for i in range(self.n - 1):
            coop_rate = np.mean(history.opponent_actions[:, i])
            if coop_rate > 0.6:
                self.opponent_types[i] = 'sheep'
            elif coop_rate < 0.4:
                self.opponent_types[i] = 'wolves'
            else:
                self.opponent_types[i] = 'chameleons'

class Strategy_AGGRESSIVE_128(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "PREDATOR"
    
    Operates as an aggressive exploiter that maximizes personal payoff by strategically
    timing cooperation and defection. Views cooperation as a tool for manipulation,
    using it only to extract maximum value from others' reciprocal behavior.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.punishment_defect_rounds = 0

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        round_num = history.round_number + 1
        n_rounds = self.game_description.n_rounds
        if round_num == 2:
            round1_cooperators = sum(history.opponent_actions[0, :])
            cooperation_rate = round1_cooperators / self.game_description.n_players
            return Action.C if cooperation_rate < 0.5 else Action.D
        if round_num > n_rounds - 3:
            return Action.D
        if self.punishment_defect_rounds > 0:
            self.punishment_defect_rounds -= 1
            return Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        cooperation_rate_last = last_round_cooperators / self.game_description.n_players
        k = self.game_description.k
        n = self.game_description.n_players
        predicted_cooperators = last_round_cooperators
        expected_payoff_cooperate = k / n * (predicted_cooperators + 1)
        expected_payoff_defect = 1 + k / n * predicted_cooperators
        if cooperation_rate_last > 0.6:
            return Action.D
        elif cooperation_rate_last < 0.3:
            if round_num >= 4:
                my_recent_payoffs = history.my_payoffs[-3:]
                avg_recent_payoff = np.mean(my_recent_payoffs)
                max_possible_payoff = 1 + k
                if avg_recent_payoff < max_possible_payoff * 0.8:
                    return Action.C
                else:
                    return Action.D
            else:
                return Action.D
        else:
            if round_num >= 4:
                prev_round_cooperators = sum(history.opponent_actions[-2, :])
                prev_cooperation_rate = prev_round_cooperators / n
                trend_increasing = cooperation_rate_last > prev_cooperation_rate
                if trend_increasing:
                    return Action.D
                if history.my_actions[-1] and cooperation_rate_last < prev_cooperation_rate:
                    self.punishment_defect_rounds = 1
                    return Action.D
            if expected_payoff_defect > expected_payoff_cooperate * 1.1:
                return Action.D
            else:
                return Action.C


class Strategy_AGGRESSIVE_2(BaseStrategy):
    """
    Aggressive Exploitation Strategy: "Predator"
    
    This strategy exploits cooperative opponents while strategically contributing only when 
    necessary to maintain profitable public goods production. It defects in round 1 to gather
    information, then adapts based on cooperation levels and trends.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.k = game_description.k
        self.r = game_description.n_rounds
        self.min_threshold = self.n / self.k
        self.cooperation_threshold = 0.6
        if self.k > self.n * 0.8:
            self.min_threshold = 0.4
        elif self.k < 1.5:
            self.cooperation_threshold = 0.8
        if self.n > 10:
            self.cooperation_threshold = 0.7
        elif self.n <= 4:
            self.cooperation_threshold = 0.5

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        round_num = state.round_number
        if round_num == self.r - 1:
            return Action.D
        last_round_cooperators = sum(history.opponent_actions[-1, :])
        cooperation_rate = last_round_cooperators / self.n
        if cooperation_rate >= self.cooperation_threshold:
            return Action.D
        if cooperation_rate < self.min_threshold / self.n:
            return Action.D
        if cooperation_rate >= self.min_threshold / self.n and cooperation_rate < self.cooperation_threshold:
            if round_num >= 3:
                recent_cooperation_rates = []
                for i in range(min(3, round_num)):
                    round_idx = -(i + 1)
                    round_cooperators = sum(history.opponent_actions[round_idx, :])
                    recent_cooperation_rates.append(round_cooperators / self.n)
                if len(recent_cooperation_rates) >= 2:
                    declining_count = 0
                    for i in range(1, len(recent_cooperation_rates)):
                        if recent_cooperation_rates[i - 1] > recent_cooperation_rates[i]:
                            declining_count += 1
                    if declining_count >= 2:
                        return Action.D
            final_phase_start = math.ceil(self.r * 0.8)
            if round_num >= final_phase_start:
                end_game_factor = (round_num - final_phase_start + 1) * 0.1
                if random.random() < end_game_factor:
                    return Action.D
            if round_num >= 4:
                switches = 0
                for player in range(len(history.opponent_actions[0, :])):
                    player_switches = 0
                    for round_idx in range(-4, -1):
                        if history.opponent_actions[round_idx, player] != history.opponent_actions[round_idx + 1, player]:
                            player_switches += 1
                    if player_switches >= 2:
                        switches += 1
                if switches >= self.n * 0.5:
                    return Action.D
            if round_num >= 5:
                consistent_cooperators = 0
                my_defection_rate = 1 - sum(history.my_actions) / len(history.my_actions)
                if my_defection_rate > 0.6:
                    for player in range(len(history.opponent_actions[0, :])):
                        player_coop_rate = sum(history.opponent_actions[:, player]) / round_num
                        if player_coop_rate > 0.8:
                            consistent_cooperators += 1
                    if consistent_cooperators > 0 and round_num % 4 == 0:
                        return Action.C
            return Action.C
        return Action.D

class Strategy_AGGRESSIVE_74(BaseStrategy):
    """
    AGGRESSIVE EXPLOITATION STRATEGY: "PREDATOR"
    
    Operates on maximum exploitation with strategic cooperation. Defects by default,
    cooperates only when mathematically advantageous or strategically necessary
    to maintain exploitable relationships.
    """

    def __init__(self, game_description: PublicGoodsDescription):
        self.game_description = game_description
        self.n = game_description.n_players
        self.r = game_description.n_rounds
        self.k = game_description.k

    def __call__(self, state: GameState, history: None | PlayerHistory) -> Action:
        if history is None:
            return Action.D
        current_round = state.round_number
        rounds_elapsed = history.round_number
        if current_round == 1:
            return Action.D
        total_cooperations = np.sum(history.opponent_actions)
        total_possible = (self.n - 1) * rounds_elapsed
        cooperation_rate = total_cooperations / total_possible if total_possible > 0 else 0
        my_cooperations = np.sum(history.my_actions)
        my_cooperation_rate = my_cooperations / rounds_elapsed if rounds_elapsed > 0 else 0
        recent_rounds = min(3, rounds_elapsed)
        recent_cooperations = np.sum(history.opponent_actions[-recent_rounds:])
        recent_total_possible = (self.n - 1) * recent_rounds
        recent_cooperation_rate = recent_cooperations / recent_total_possible if recent_total_possible > 0 else 0
        retaliation_strength = 0
        if rounds_elapsed >= 2:
            for round_idx in range(1, rounds_elapsed):
                if not history.my_actions[round_idx - 1]:
                    for opponent_idx in range(self.n - 1):
                        if round_idx >= 2 and history.opponent_actions[round_idx - 2, opponent_idx] and (not history.opponent_actions[round_idx - 1, opponent_idx]):
                            retaliation_strength += 1 / (self.n - 1)
        rounds_remaining = self.r - current_round
        if rounds_remaining <= max(3, self.r // 4):
            if rounds_remaining <= 3:
                return Action.D
            else:
                current_round_cooperations = np.sum(history.opponent_actions[-1]) if rounds_elapsed > 0 else 0
                current_round_coop_rate = current_round_cooperations / (self.n - 1)
                if current_round_coop_rate >= 0.6:
                    return Action.D
                else:
                    return Action.D
        elif current_round <= self.r // 3:
            if cooperation_rate >= 0.7:
                return Action.D
            elif cooperation_rate >= 0.4:
                return Action.C if random.random() < 0.3 else Action.D
            else:
                return Action.D
        else:
            cooperation_prob_modifier = 1.0
            if self.k >= 0.8 * self.n:
                cooperation_prob_modifier *= self.k / self.n - 0.5 + 1
            if self.k <= 1.5:
                cooperation_prob_modifier *= 0.5
            if self.n >= 8:
                cooperation_rate -= 0.1
                recent_cooperation_rate -= 0.1
            if recent_cooperation_rate > 0.9:
                return Action.D
            if recent_cooperation_rate >= 0.8 and retaliation_strength < 0.3:
                return Action.D
            elif recent_cooperation_rate >= 0.5 and my_cooperation_rate < 0.2:
                return Action.C
            elif recent_cooperation_rate < 0.3:
                return Action.D
            else:
                coop_prob = min(0.4, recent_cooperation_rate - 0.1) * cooperation_prob_modifier
                return Action.C if random.random() < coop_prob else Action.D